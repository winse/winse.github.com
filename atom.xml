<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-06-21T09:20:27+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用Puppet安装配置Ganglia]]></title>
    <link href="http://winseliu.com/blog/2016/06/17/ganglia-install-on-centos-with-puppet/"/>
    <updated>2016-06-17T09:30:50+08:00</updated>
    <id>http://winseliu.com/blog/2016/06/17/ganglia-install-on-centos-with-puppet</id>
    <content type="html"><![CDATA[<p>前面写过完全纯手工和用yum安装依赖来安装ganglia的文章，最近生产安装了puppet，既然已经手上已有牛杀鸡就不用再取菜刀了。今天记录下前几天使用puppet安装ganglia的经历。</p>

<h2>前提（自己操作过）</h2>

<ul>
<li>配置过私有仓库 (createrepo)</li>
<li>安装好puppet</li>
<li>编译过自己的rpm (rpmbuild)</li>
</ul>


<h2>编译gmetad，gmond，gweb</h2>

<ul>
<li><a href="http://winseliu.com/files/ganglia-puppet/gmetad.spec">gmetad.spec</a></li>
<li><a href="http://winseliu.com/files/ganglia-puppet/gmond.spec">gmond.spec</a></li>
<li><a href="http://winseliu.com/files/ganglia-puppet/gweb.spec">gweb.spec</a></li>
</ul>


<p>内容通过附件下载。</p>

<p>然后编译打包（使用rpmbuild必须保证能正常编译安装ganglia的，rpmbuild包括编译安装！！可以先手动编译）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir ganglia-build
</span><span class='line'>cd ganglia-build
</span><span class='line'>mkdir BUILD RPMS SOURCES SPECS SRPMS
</span><span class='line'>
</span><span class='line'># ganglia-web-3.7.1.tar.gz的makefile、conf_default.php.in修改下，根据等下要配置gmetad的参数进行修改
</span><span class='line'>
</span><span class='line'>less ganglia-web-3.7.1/Makefile 
</span><span class='line'>  # Location where gweb should be installed to (excluding conf, dwoo dirs).
</span><span class='line'>  GDESTDIR = /var/www/html/ganglia
</span><span class='line'>
</span><span class='line'>  # Location where default apache configuration should be installed to.
</span><span class='line'>  GCONFDIR = /usr/local/ganglia/etc/
</span><span class='line'>
</span><span class='line'>  # Gweb statedir (where conf dir and Dwoo templates dir are stored)
</span><span class='line'>  GWEB_STATEDIR = /var/www/html/ganglia
</span><span class='line'>
</span><span class='line'>  # Gmetad rootdir (parent location of rrd folder)
</span><span class='line'>  GMETAD_ROOTDIR = /data/ganglia
</span><span class='line'>
</span><span class='line'>  APACHE_USER = apache
</span><span class='line'>
</span><span class='line'># 连外网太慢，下载放到本地
</span><span class='line'>less ganglia-web-3.7.1/conf_default.php.in 
</span><span class='line'>  #$conf['cubism_js_path'] = "js/cubism.v1.min.js";
</span><span class='line'>  $conf['jquery_js_path'] = "js/jquery.min.js";
</span><span class='line'>  $conf['jquerymobile_js_path'] = "js/jquery.mobile.min.js";
</span><span class='line'>  $conf['jqueryui_js_path'] = "js/jquery-ui.min.js";
</span><span class='line'>  $conf['rickshaw_js_path'] = "js/rickshaw.min.js";
</span><span class='line'>  $conf['cubism_js_path'] = "js/cubism.v1.min.js";
</span><span class='line'>  $conf['d3_js_path'] = "js/d3.min.js";
</span><span class='line'>  $conf['protovis_js_path'] = "js/protovis.min.js";
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 把文件放到SOURCES目录下，
</span><span class='line'>ls SOURCES/
</span><span class='line'>  ganglia-3.7.2.tar.gz  ganglia-web-3.7.1.tar.gz
</span><span class='line'>
</span><span class='line'>rpmbuild -v -ba SPECS/gmetad.spec 
</span><span class='line'>rpmbuild -v -ba SPECS/gmond.spec 
</span><span class='line'>rpmbuild -v -ba SPECS/gweb.spec 
</span><span class='line'>
</span><span class='line'># 查看内容
</span><span class='line'>rpm -qpl RPMS/x86_64/ganglia-3.7.2-1.el6.x86_64.rpm </span></code></pre></td></tr></table></div></figure>


<h2>本地仓库</h2>

<p><strong>先安装httpd、createrepo</strong>，然后按照下面的步骤创建本地仓库</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 系统带的可以从光盘拷贝，直接映射到httpd的目录下即可
</span><span class='line'>[hadoop@hadoop-master1 rhel6.3]$ ls 
</span><span class='line'>Packages  repodata
</span><span class='line'>[hadoop@hadoop-master1 html]$ pwd
</span><span class='line'>/var/www/html
</span><span class='line'>[hadoop@hadoop-master1 html]$ ll
</span><span class='line'>lrwxrwxrwx.  1 root root   20 2月  15 2014 rhel6.3 -&gt; /opt/rhel6.3
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mkdir -p /opt/dta/repo
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd /opt/dta/repo
</span><span class='line'>[hadoop@hadoop-master1 repo]$ ls *.rpm
</span><span class='line'>gmetad-3.7.2-1.el6.x86_64.rpm  gmond-3.7.2-1.el6.x86_64.rpm  gweb-3.7.1-1.el6.x86_64.rpm  libconfuse-2.7-4.el6.x86_64.rpm
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 repo]$ sudo createrepo .
</span><span class='line'>3/3 - libconfuse-2.7-4.el6.x86_64.rpm                                           
</span><span class='line'>Saving Primary metadata
</span><span class='line'>Saving file lists metadata
</span><span class='line'>Saving other metadata
</span><span class='line'>
</span><span class='line'># 映射到httpd目录下
</span><span class='line'>[hadoop@hadoop-master1 yum.repos.d]$ cd /var/www/html/
</span><span class='line'>[hadoop@hadoop-master1 html]$ sudo ln -s /opt/dta/repo dta
</span><span class='line'>
</span><span class='line'># 加入本地仓库源
</span><span class='line'>[hadoop@hadoop-master1 yum.repos.d]$ sudo cp puppet.repo dta.repo
</span><span class='line'>[hadoop@hadoop-master1 yum.repos.d]$ sudo vi dta.repo 
</span><span class='line'>[dta]
</span><span class='line'>name=DTA Local
</span><span class='line'>baseurl=http://hadoop-master1:801/dta
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span></code></pre></td></tr></table></div></figure>


<p>安装找不到gmond时，可以先清理yum的缓冲： <code>yum clean all</code></p>

<h2>puppet模块</h2>

<p>添加了三个模块，用于主机添加repo配置和sudo配置，以及安装配置gmond。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 modules]# tree $PWD
</span><span class='line'>/etc/puppetlabs/code/environments/production/modules
</span><span class='line'>├── dtarepo
</span><span class='line'>│   ├── manifests
</span><span class='line'>│   │   └── init.pp
</span><span class='line'>│   └── templates
</span><span class='line'>│       └── dta.repo
</span><span class='line'>├── gmond
</span><span class='line'>│   ├── manifests
</span><span class='line'>│   │   └── init.pp
</span><span class='line'>│   └── templates
</span><span class='line'>│       └── gmond.conf
</span><span class='line'>└── sudo
</span><span class='line'>    ├── manifests
</span><span class='line'>    │   └── init.pp
</span><span class='line'>    └── templates
</span><span class='line'>        └── sudo.erb</span></code></pre></td></tr></table></div></figure>


<p>都比较简单，通过init.pp来进行配置，然后加载模板，写入到同步主机本地文件中。</p>

<ul>
<li>dtarepo</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./dtarepo/manifests/init.pp
</span><span class='line'>class dtarepo {
</span><span class='line'>
</span><span class='line'>file{'/etc/yum.repos.d/dta.repo':
</span><span class='line'>  ensure =&gt; file,
</span><span class='line'>  content =&gt; template('dtarepo/dta.repo'),
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>./dtarepo/templates/dta.repo
</span><span class='line'>[dta]
</span><span class='line'>name=DTA Local
</span><span class='line'>baseurl=http://hadoop-master1:801/dta
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0</span></code></pre></td></tr></table></div></figure>


<ul>
<li>sudo</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./sudo/manifests/init.pp
</span><span class='line'>class sudo {
</span><span class='line'>
</span><span class='line'>if ( $::hostname =~ /(^cu-omc)/ ) {
</span><span class='line'>  $user = 'omc'
</span><span class='line'>} elsif ( $::hostname =~ /(^cu-uc)/ ) {
</span><span class='line'>  $user = 'uc'
</span><span class='line'>} elsif ( $::hostname =~ /(^cu-ud)/ ) {
</span><span class='line'>  $user = 'ud'
</span><span class='line'>} elsif ( $::hostname =~ /(^cu-db)/ ) {
</span><span class='line'>  $user = 'mysql'
</span><span class='line'>} else {
</span><span class='line'>  $user = 'hadoop'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>file { "/etc/sudoers.d/10_$user":
</span><span class='line'>  ensure =&gt; file,
</span><span class='line'>  mode =&gt; '0440', 
</span><span class='line'>  content =&gt; template('sudo/sudo.erb'),
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>./sudo/templates/sudo.erb
</span><span class='line'>&lt;%= scope.lookupvar('sudo::user') %&gt; ALL=(ALL) NOPASSWD: ALL</span></code></pre></td></tr></table></div></figure>


<ul>
<li>gmond</li>
</ul>


<p>gmond.conf的仅修改两个地方: globals.deaf, cluster.name</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./gmond/manifests/init.pp
</span><span class='line'>class gmond {
</span><span class='line'>
</span><span class='line'>$deaf = $::hostname ? {
</span><span class='line'>  'hadoop-master1' =&gt; 'no',
</span><span class='line'>  'cu-omc1' =&gt; 'no',
</span><span class='line'>  default =&gt; 'yes',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>if ( $::hostname =~ /(^cu-)/ ) {
</span><span class='line'>  $cluster_name = 'CU'
</span><span class='line'>} else {
</span><span class='line'>  $cluster_name = 'HADOOP'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>package { 'gmond':
</span><span class='line'>  ensure =&gt; present,
</span><span class='line'>  before =&gt; File['/usr/local/ganglia/etc/gmond.conf'],
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>file { '/usr/local/ganglia/etc/gmond.conf':
</span><span class='line'>  ensure =&gt; file,
</span><span class='line'>  content =&gt; template('gmond/gmond.conf'),
</span><span class='line'>  notify =&gt; Service['gmond'],
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>service { 'gmond':
</span><span class='line'>  ensure    =&gt; running,
</span><span class='line'>  enable    =&gt; true,
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>./gmond/templates/gmond.conf
</span><span class='line'>/* This configuration is as close to 2.5.x default behavior as possible
</span><span class='line'>   The values closely match ./gmond/metric.h definitions in 2.5.x */
</span><span class='line'>globals {
</span><span class='line'>...
</span><span class='line'>  mute = no
</span><span class='line'>  deaf = &lt;%= scope.lookupvar('gmond::deaf') %&gt;
</span><span class='line'>  allow_extra_data = yes
</span><span class='line'>...
</span><span class='line'>cluster {
</span><span class='line'>  name = "&lt;%= scope.lookupvar('gmond::cluster_name') %&gt;"</span></code></pre></td></tr></table></div></figure>


<p>参考下逻辑即可（也可以通过hiera配置）。</p>

<p>最后就是加载module：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 modules]# cd ../manifests/
</span><span class='line'>[root@hadoop-master1 manifests]# cat site.pp 
</span><span class='line'>file{'/etc/puppetlabs/mcollective/facts.yaml':
</span><span class='line'>  owner    =&gt; root,
</span><span class='line'>  group    =&gt; root,
</span><span class='line'>  mode     =&gt; '400',
</span><span class='line'>  loglevel =&gt; debug, # reduce noise in Puppet reports
</span><span class='line'>  content  =&gt; inline_template("&lt;%= scope.to_hash.reject { |k,v| k.to_s =~ /(uptime_seconds|timestamp|free)/ }.to_yaml %&gt;"), # exclude rapidly changing facts
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>include dtarepo
</span><span class='line'>include gmond
</span><span class='line'>
</span><span class='line'># include sudo
</span></code></pre></td></tr></table></div></figure>


<h2>一键安装</h2>

<p>首先在主机上安装gmetad，gmetad配置由于只有一台机器，配置这里手动弄。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 dtarepo]# mco rpc package install package=gmetad -I cu-omc1
</span><span class='line'>
</span><span class='line'># 主机多网卡时可能需要添加route
</span><span class='line'>[root@cu-omc1 ~]# route add -host 239.2.11.71 dev bond0
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 ~]# /etc/ganglia/gmetad.conf 注意!! 这里的rrd_rootdir配置与上面gweb/makefile是对应的！！
</span><span class='line'>data_source "HADOOP" hadoop-master1
</span><span class='line'>data_source "CU" cu-omc1
</span><span class='line'>gridname "CQCU"
</span><span class='line'>rrd_rootdir "/data/ganglia/rrds"
</span></code></pre></td></tr></table></div></figure>


<p>在cu-omc2上安装gmond（正则表达式，你想怎么匹配就怎么写）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 production]# mco shell -I /^cu-omc2/ run -- "/opt/puppetlabs/bin/puppet agent -t"</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[读读书]Apache Spark源码剖析-Shell]]></title>
    <link href="http://winseliu.com/blog/2016/05/08/rrc-apache-spark-source-inside-shell/"/>
    <updated>2016-05-08T21:41:01+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/08/rrc-apache-spark-source-inside-shell</id>
    <content type="html"><![CDATA[<p>本来第二篇应该是与 [第1章 初识Spark] 有关，但是通过 spark-shell 跑个helloworld出结果了，我还是不知道那些脚本干了啥，整个的运行逻辑是什么样的？而且，在开发环境运行shell来启动总觉得怪怪的，哪调试怎么调呢？</p>

<p>所以，我准备把 spark/bin 目录下面的脚本理清楚，然后再去写开发环境的helloworld。<strong> 其实每个大数据的框架，shell脚本都是通用出口，也是研读源码的第一个突破口 </strong>。</p>

<p>官网 <strong> Quick Start </strong> 提供的简短例子都是通过 spark-shell 来运行的。还有另一种，自己打包一个jar通过 spark-submit 提交任务给集群。</p>

<p>spark-shell，spark-submit 就是两个非常重要的脚本，这里就来理一下这些脚本。</p>

<p>1) spark-shell - [3.1 spark-shell]</p>

<p>spark-shell 脚本的内容相对多一些，主要代码如下（其他代码都是为了兼容cygwin弄的，我们这里不关注）：</p>

<pre><code>SPARK_SUBMIT_OPTS="$SPARK_SUBMIT_OPTS -Dscala.usejavacp=true"
trap onExit INT # 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl C)时发出 来自: http://man.linuxde.net/trap

export SPARK_SUBMIT_OPTS
"${SPARK_HOME}"/bin/spark-submit --class org.apache.spark.repl.Main --name "Spark shell" "$@"
</code></pre>

<p>最终调用 spark-submit 脚本。</p>

<p>提交我们自己helloworld命令如下：</p>

<pre><code>$ YOUR_SPARK_HOME/bin/spark-submit \
  --class "SimpleApp" \
  --master local[4] \
  target/scala-2.10/simple-project_2.10-1.0.jar
</code></pre>

<p>其实 spark-shell 与我们自己提交程序一样，不过 spark-shell 提交运行的类是spark自带，不需要额外的jar 。</p>

<p>2) spark-submit</p>

<p>submit脚本其实就是在输入参数前面添加 org.apache.spark.deploy.SparkSubmit ，然后传递给 spark-class 。</p>

<pre><code>exec "${SPARK_HOME}"/bin/spark-class org.apache.spark.deploy.SparkSubmit "$@"
</code></pre>

<p>3) spark-class</p>

<p>spark-shell 调用 spark-submit ， spark-submit 又调用 spark-class 。</p>

<p>spark-class脚本最终启动 java 调用 launcher模块(org.apache.spark.launcher.Main)解析参数计算出 <strong> 最终执行的命令 </strong>，然后通过 exec 来运行。</p>

<p>bin路径下脚本之间调用关系：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-sql
</span><span class='line'>spark-shell
</span><span class='line'>  spark-submit
</span><span class='line'>      spark-class
</span><span class='line'>          (java)org.apache.spark.launcher.Main</span></code></pre></td></tr></table></div></figure>


<p>要讲清楚 spark-shell 相对复杂点，通过 <strong>脚本</strong> 和 <strong>程序</strong> 两部分来分别说明。</p>

<p>3.1 脚本</p>

<p>脚本的主要作用是调用 <strong>Launcher模块</strong> 代码产生最终的执行命令(N行字符串)，然后把输出的字符串数组提供给 exec 执行。</p>

<p>spark-class先加载环境变量配置文件，再获取assembly.jar位置，然后调用 org.apache.spark.launcher.Main ， Main类根据环境变量和传入参数算出真正执行的命令。</p>

<p>这里把核心的脚本内容列出来：</p>

<pre><code>. "${SPARK_HOME}"/bin/load-spark-env.sh # 我这里把它展开
    . "${user_conf_dir}/spark-env.sh"

    # 通过ASSEMBLY路径来判断SPARK_SCALA_VERSION，通过tar打包不需要这个变量
    ASSEMBLY_DIR1="${SPARK_HOME}/assembly/target/scala-2.10" 
    export SPARK_SCALA_VERSION="2.10"

RUNNER="${JAVA_HOME}/bin/java"

SPARK_ASSEMBLY_JAR=
if [ -f "${SPARK_HOME}/RELEASE" ]; then
  ASSEMBLY_DIR="${SPARK_HOME}/lib"
else
  ASSEMBLY_DIR="${SPARK_HOME}/assembly/target/scala-$SPARK_SCALA_VERSION"
fi
ASSEMBLY_JARS="$(ls -1 "$ASSEMBLY_DIR" | grep "^spark-assembly.*hadoop.*\.jar$" || true)"
SPARK_ASSEMBLY_JAR="${ASSEMBLY_DIR}/${ASSEMBLY_JARS}"
LAUNCH_CLASSPATH="$SPARK_ASSEMBLY_JAR"

export _SPARK_ASSEMBLY="$SPARK_ASSEMBLY_JAR"

CMD=()
while IFS= read -d '' -r ARG; do
  CMD+=("$ARG")
done &lt; &lt;("$RUNNER" -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@")
exec "${CMD[@]}"
</code></pre>

<p>前面的脚本内容都是准备环境变量，就最后几行代码比较复杂。我这里debug一下，在脚本 while 循环打印每个输出的值看下 Main类 输出的是什么：</p>

<pre><code># 修改后的效果
[hadoop@cu2 spark-1.6.0-bin-2.6.3]$ tail bin/spark-class
CMD=()
while IFS= read -d '' -r ARG; do
  echo "[DEBUG] $ARG"
  CMD+=("$ARG")
done &lt; &lt;(set -x; "$RUNNER" -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@")
echo "${CMD[@]}"
exec "${CMD[@]}"

# 启动 spark-shell 查看输出的调试信息
[hadoop@cu2 spark-1.6.0-bin-2.6.3]$ bin/spark-shell 
++ /opt/jdk1.8.0/bin/java -cp /home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar org.apache.spark.launcher.Main org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name 'Spark shell'
[DEBUG] /opt/jdk1.8.0/bin/java
[DEBUG] -cp
[DEBUG] /home/hadoop/spark/lib/mysql-connector-java-5.1.34.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/conf/:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-rdbms-3.2.9.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-core-3.2.10.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/hadoop/etc/hadoop/
[DEBUG] -Dscala.usejavacp=true
[DEBUG] -Xms512m
[DEBUG] -Xmx512m
[DEBUG] org.apache.spark.deploy.SparkSubmit
[DEBUG] --class
[DEBUG] org.apache.spark.repl.Main
[DEBUG] --name
[DEBUG] Spark shell
[DEBUG] spark-shell
/opt/jdk1.8.0/bin/java -cp /home/hadoop/spark/lib/mysql-connector-java-5.1.34.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/conf/:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-rdbms-3.2.9.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-core-3.2.10.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/hadoop/etc/hadoop/ -Dscala.usejavacp=true -Xms512m -Xmx512m org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name 'Spark shell' spark-shell
...
</code></pre>

<p>org.apache.spark.launcher.Main 把环境变量和传入参数整理后重新输出，输出的内容被脚本保存到 CMD[@] 数组中，最后使用exec来执行。</p>

<p>使用上面 spark-shell 最终调用的类和参数其实就可以在idea里面启动了：</p>

<p><img src="http://winseliu.com/images/blogs/idea-spark-shell.png" alt="" /></p>

<p>3.2 Launcher模块</p>

<p>launcher模块功能其实用shell完全可以全部功能的。如果shell和launcher的代码你都看了的话，会发现 shell 和 java代码 功能逻辑非常类似。如下面获取java路径的代码：</p>

<pre><code>  List&lt;String&gt; buildJavaCommand(String extraClassPath) throws IOException {
    ...
    if (javaHome != null) {
      cmd.add(join(File.separator, javaHome, "bin", "java"));
    } else if ((envJavaHome = System.getenv("JAVA_HOME")) != null) {
        cmd.add(join(File.separator, envJavaHome, "bin", "java"));
    } else {
        cmd.add(join(File.separator, System.getProperty("java.home"), "bin", "java"));
    }
    ...
  }
</code></pre>

<p>shell脚本里面是这么写的：</p>

<pre><code># Find the java binary
if [ -n "${JAVA_HOME}" ]; then
  RUNNER="${JAVA_HOME}/bin/java"
else
  if [ `command -v java` ]; then
    RUNNER="java"
  else
    echo "JAVA_HOME is not set" &gt;&amp;2
    exit 1
  fi
fi
</code></pre>

<p>对比两者，其实是用脚本更加直观。但是使用java编写的 launcher模块 更便于管理和扩展，稍微调整下就能复用代码：如输出给windows-cmd脚本、还有为了兼容多个操作系统多语言(python，r 等)，所以提取一个公共 launcher模块 出来其实是个挺不错的选择。同时对于不是很熟悉shell的程序员来说也方便一些来了解系统。</p>

<p>按照功能可以分为 CommandBuilder 和 SparkLauncher 两个部分。</p>

<p>3.2.1 CommandBuilder</p>

<p>SparkSubmitCommandBuilder解析用户输入的参数并输出命令给脚本使用，而SparkClassCommandBuilder主要为后台进程产生启动命令（sbin目录下面的脚本）。</p>

<p>主要的类以及参数：</p>

<ul>
<li>Main ： 统一入口</li>
<li>AbstractCommandBuilder : 提供构造命令的公共方法

<ul>
<li>buildJavaCommand

<ul>
<li>buildClassPath

<ul>
<li>SPARK_CLASSPATH</li>
<li>extraClassPath</li>
<li>getConfDir : 等于环境变量 $SPARK_CONF_DIR 或者 $SPARK_HOME/conf 的值</li>
<li>classes

<ul>
<li>SPARK_PREPEND_CLASSES</li>
<li>SPARK_TESTING</li>
</ul>
</li>
<li>findAssembly : 获取 spark-assembly-1.6.0-hadoop2.6.3.jar 的路径，lib 或者 assembly/target/scala-$SPARK_SCALA_VERSION 路径下

<ul>
<li>_SPARK_ASSEMBLY</li>
</ul>
</li>
<li>datanucleus-* : 从 lib / lib_managed/jars 目录下获取</li>
<li>HADOOP_CONF_DIR</li>
<li>YARN_CONF_DIR</li>
<li>SPARK_DIST_CLASSPATH</li>
</ul>
</li>
</ul>
</li>
<li>getEffectiveConfig : 获取 spark-defaults.conf 的内容</li>
</ul>
</li>
<li>SparkSubmitCommandBuilder

<ul>
<li>构造函数调用OptionParser解析参数，解析handle有处理specialClasses！</li>
<li>buildSparkSubmitCommand

<ul>
<li>getEffectiveConfig</li>
<li>extraClassPath : spark.driver.extraClassPath</li>
<li>SPARK_SUBMIT_OPTS</li>
<li>SPARK_JAVA_OPTS</li>
<li>client模式下加载配置

<ul>
<li>spark.driver.memory / SPARK_DRIVER_MEMORY / SPARK_MEM / DEFAULT_MEM(1g)</li>
<li>DRIVER_EXTRA_JAVA_OPTIONS</li>
<li>DRIVER_EXTRA_LIBRARY_PATH</li>
</ul>
</li>
<li>buildSparkSubmitArgs ： 把参数键值对存储List，用于输出</li>
</ul>
</li>
</ul>
</li>
<li>SparkSubmitCommandBuilder$OptionParser -> SparkSubmitOptionParser(子类需要实现handle方法)

<ul>
<li><code>bin/spark-submit -h</code> 帮助文档会输出可以<strong>设置的参数</strong></li>
<li>或者直接查看<a href="http://spark.apache.org/docs/latest/submitting-applications.html">官网文档</a></li>
</ul>
</li>
<li>SparkClassCommandBuilder

<ul>
<li>org.apache.spark.deploy.master.Master

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_MASTER_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.worker.Worker

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_WORKER_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.history.HistoryServer

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_HISTORY_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.executor.CoarseGrainedExecutorBackend

<ul>
<li>SPARK_JAVA_OPTS</li>
<li>SPARK_EXECUTOR_OPTS</li>
<li>SPARK_EXECUTOR_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.executor.MesosExecutorBackend

<ul>
<li>SPARK_EXECUTOR_OPTS</li>
<li>SPARK_EXECUTOR_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.ExternalShuffleService / org.apache.spark.deploy.mesos.MesosExternalShuffleService

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_SHUFFLE_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.tools.

<ul>
<li>extraClassPath : spark-tools_.*.jar</li>
<li>SPARK_JAVA_OPTS</li>
<li>DEFAULT_MEM(1g)</li>
</ul>
</li>
<li>other

<ul>
<li>SPARK_JAVA_OPTS</li>
<li>SPARK_DRIVER_MEMORY</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>3.2.2 SparkLauncher</p>

<p>SparkLauncher提供了在程序中提交application的方式。通过Driver端的支持获取程序执行动态，为实现后端管理应用提供一种可行的方式。</p>

<p>launcher提交还是使用spark-submit脚本，绕一圈又回到上面的参数解析生成命令然后exec执行。但是launcher中通过启动 LauncherServer(socketserver)，Driver(LauncherBackend)监听这个端口会把程序的最新状态通过socket推给launcher。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-launcher.jpg" alt="" /></p>

<p>代码包括：</p>

<pre><code>* SparkLauncher
* LauncherServer
* LauncherConnection
* LauncherProtocol
* ChildProcAppHandle : SparkAppHandle
</code></pre>

<p>具体调试可以下载 <a href="https://github.com/winse/spark-examples/blob/master/src/main/scala/com/github/winse/spark/HelloWorldLauncher.scala">HelloWorldLauncher.scala</a> 代码，然后本地调试一步步的查看。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[读读书]Apache Spark源码剖析-序]]></title>
    <link href="http://winseliu.com/blog/2016/05/07/rrc-apache-spark-source-inside-preface/"/>
    <updated>2016-05-07T23:58:57+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/07/rrc-apache-spark-source-inside-preface</id>
    <content type="html"><![CDATA[<p>今天去广州图书馆办了证，借了几本关于大数据的书。老实说，国家提供的便民基础设施应该发挥她的价值，国家建那么多公共设施，还有很多人在后台让这些服务运作起来。借书是一种最高性价比学习的方式，第一：不能乱写乱画必须做笔记或者背下来，把最有价值的东西汇集；第二：有时间限制，好书逼着我们持续的去读；第三：自然是读到烂书也不用花钱，有价值的书必然也是最多人看的，看到翻的很旧的新书你就借了吧。</p>

<p>其中一个《Apache Spark源码剖析-徐鹏》，大致翻了一下，老实说作者很牛逼啊，从那么多的代码里面挑出和主题相关的，不比鸡蛋里面挑石头容易，跟着作者的思路去读应该不错。打算每天读点代码，同时把看书和看代码也记录下来，每天一小结，同时希望对别人有些参考作用。</p>

<p>Spark更新的很快，书本介绍的是 spark-1.0 ，不过书中介绍的主要是思路，我们这里选择比较新的版本 1.6.0 来读（生产用的是1.6）。</p>

<p><strong> 说到思路，如果你对Redis也感兴趣，强烈推荐读读 《Redis设计与实现-黄建宏》 </strong></p>

<h3>使用环境说明</h3>

<p>和作者不同，我选择直接在windows来读/调试代码，为了读个代码还得整一套linux的开发环境挺累的（原来也试过整linux开发环境后来放弃了），Windows 积累的经验已经可以让我自由调试和看代码了。</p>

<p>吐槽下sbt，很讨厌这玩意又慢还用ivy，我X，大数据不都用 maven 嘛，难道我还得为 spark 整一套完全一样的jar本地缓冲？不过还好 spark-1.6 已经是用 maven 来管理了。</p>

<ul>
<li>win10 + cygwin</li>
<li>jdk8_x64（内存可以调到大于1G）</li>
<li>maven3</li>
<li>scala_2.10</li>
<li>spark_1.6.0</li>
<li>hive_1.2.1</li>
<li>hadoop_2.6.3</li>
<li>JetBrains idea 看代码确实不错</li>
</ul>


<h3>Spark开发环境搭建 - [附录A Spark源码调试]</h3>

<p>1) 配置 idea-scala</p>

<p>1.1 优化idea启动参数</p>

<p>安装 <strong>最新版idea</strong> (当前最新版本是15.0.5)。在程序安装的 bin 目录下，有x64配置文件 idea64.exe.vmoptions ，在配置文件开头添加jdk8内存配置：</p>

<pre><code>-server
-Xms1g
-Xmx2g
-XX:MetaspaceSize=256m
-XX:MaxMetaspaceSize=256m
</code></pre>

<p>由于机器 eclipse 原来使用的 jdk_x86，为了兼容，单独编写 idea64.exe 的启动脚本 <strong> idea.bat </strong>：</p>

<pre><code>set JAVA_HOME=D:\Java\jdk1.8.0_40
D:
cd "D:\Program Files\JetBrains\IntelliJ IDEA Community Edition 15.0.5\bin"
start idea64.exe"

exit
</code></pre>

<p><strong> 快键：idea可以适配eclipse的快键集，通过 Settings -> Keymap -> Keymaps 设置。 </strong></p>

<p>1.2 安装scala插件</p>

<p>第一种方式，当然最好就是通过plugins的搜索框就能安装，但这在中国得看运气。 第二种方式，首先下载好插件，然后选择从硬盘安装插件。</p>

<ul>
<li>A 从网络安装</li>
</ul>


<p>打开 plugins 管理页面：（也可以通过 File -> Settings&hellip; -> Plugins 打开）</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-start-configure.png" alt="" /></p>

<p>弹出的 Plugins 对话框显示了当前已经安装的插件：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-plugins-list.png" alt="" /></p>

<p>在 Plugins 对话框页面选择 <strong> Browse repositories&hellip; </strong> 按钮，再在弹出的对话框中查找 Scala 相关的插件：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-browse-plugins.png" alt="" /></p>

<p>选择安装 Scala ，当然你也可以同时安装上 SBT 。</p>

<ul>
<li>B 从硬盘安装</li>
</ul>


<p>运气好就算可以直接从网络安装，但是下载过程其实也挺慢的。我们还可以先自己下载好插件再安装（或者从其他同学获取、迅雷分分钟下完）。</p>

<p>首先需要查看自己 idea 的版本，再在 <a href="https://plugins.jetbrains.com/?idea_ce">https://plugins.jetbrains.com/?idea_ce</a> 查找下载符合自己版本的 <a href="https://plugins.jetbrains.com/plugin/1347?pr=idea_ce">scala 插件</a>，最后通过 <code>Install plugin from disk...</code> 安装，然后重启idea即可。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-version.png" alt="" />
<img src="http://winseliu.com/images/blogs/rrc-spark/download-scala-plugin.png" alt="" />
<img src="http://winseliu.com/images/blogs/rrc-spark/idea-scala-from-disk.png" alt="" /></p>

<p>2) 下载 spark 源码，并导入idea</p>

<p>2.1 下载源码，检出 1.6.0 版本</p>

<pre><code>$ git clone https://github.com/apache/spark.git
$ git checkout v1.6.0
</code></pre>

<p>如果你只想看 1.6.0 的内容，可以直接在clone命令添加参数指定版本：</p>

<pre><code>$ git clone https://github.com/apache/spark.git -b v1.6.0
</code></pre>

<p>2.2 导入idea</p>

<p>导入之前先要生成arvo的java类(这里直接package编译一下)：</p>

<pre><code>E:\git\spark\external\flume-sink&gt;mvn package -DskipTests
</code></pre>

<p>由于我使用 hadoop-2.6.3 ，并且导入的时刻不能修改环境变量，直接修改 pom.xml 里面 hadoop.version 属性的值。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-hadoop-version.png" alt="" /></p>

<p>启动idea，使用 <strong> Import Project </strong> 导入源代码； 然后选择 E:/git/spark （刚刚下载的源码位置）；然后选择导入maven项目；在 profile 页把必要的都选上（当然也可以后期通过 <code>Maven Projects</code> 面板来修改）：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-import-profile.png" alt="" /></p>

<p>导入完成后，依赖关系maven已经处理好了，直接就能用了。也可以 Make Projects 再编译一次，并把运行application的make去掉，免得浪费编译时间）。</p>

<p><strong> 注意：mvn idea:idea 其实不咋的，生成的配置不是很兼容最好不要用！！ </strong></p>

<p>2.3 调试/测试</p>

<p>在调试运行之前，先了解和解决 idea maven-provided 的问题：在idea里面直接运行 src/main/java 下面的类会被当做在生产环境运行，所以idea不会把这些 provided的依赖 加入到运行的classpath。</p>

<ul>
<li><a href="https://youtrack.jetbrains.com/issue/IDEA-54595">https://youtrack.jetbrains.com/issue/IDEA-54595</a></li>
<li><a href="http://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij">http://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij</a></li>
</ul>


<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-maven-provided.png" alt="" /></p>

<p>idea运行时从 examples/spark-examples_2.10.iml 文件中读取classpath的配置，所以我们直接把 spark-examples_2.10.iml 中的 <code>scope="PROVIDED"</code> 全部删掉（也可以说是替换成空格）。</p>

<pre><code># 一次全部删掉！
winse@Lenovo-PC ~/git/spark
$ find . -name "*.iml"  | xargs -I{} sed -i 's/scope="PROVIDED"//' {}
</code></pre>

<p>首先右键 <strong> Run &lsquo;LogQuery&rsquo; </strong> 运行（由于缺少master的配置会报错的），生成启动的 LogQuery Configuration：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-logquery-firststart.png" alt="" /></p>

<p>然后选择上图中的 <strong> Edit Configurations&hellip; </strong> 下拉选项，在弹出配置对话框为中为 LogQuery 添加 <strong> VM options </strong> 配置: <code>-Dspark.master=local</code> ，最后就可以打断点Debug调试了。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-logquery-config.png" alt="" /></p>

<p>运行结果如下：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-logquery-result.png" alt="" /></p>

<p>遇到idea导入maven依赖有问题的，可以参考下 <a href="http://stackoverflow.com/questions/11454822/import-maven-dependencies-in-intellij-idea">Import Maven dependencies in IntelliJ IDEA</a> 。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hdfs异构存储实操]]></title>
    <link href="http://winseliu.com/blog/2016/05/05/hdfs-heterogeneous-storage/"/>
    <updated>2016-05-05T21:41:39+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/05/hdfs-heterogeneous-storage</id>
    <content type="html"><![CDATA[<p>[注意] 查看官方文档一定要和自己使用的环境对应！操作 storagepolicies 不同版本对应的命令不同（2.6.3<->2.7.2）！</p>

<p>我这里测试环境使用的是 2.6.3 <a href="https://hadoop.apache.org/docs/r2.6.3/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Heterogeneous Storage: Archival Storage, SSD &amp; Memory</a></p>

<h2>配置</h2>

<p>直接把内存盘放到 /dev/shm 下，单独挂载一个 tmpfs 的效果也差不多。<a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">r2.7.2 Memory Storage Support in HDFS</a> 2.6.3没有这个文档 概念都适应的。</p>

<p>1 调节系统参数</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi /etc/security/limits.conf
</span><span class='line'>
</span><span class='line'>  hadoop           -       nofile          65535
</span><span class='line'>  hadoop           -       nproc           65535
</span><span class='line'>  hadoop           -       memlock         268435456
</span></code></pre></td></tr></table></div></figure>


<p>需要调节memlock的大小，否则启动datanode报错。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-05-05 19:22:22,674 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
</span><span class='line'>java.lang.RuntimeException: Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) of 134217728 bytes is more than the datanode's available RLIMIT_MEMLOCK ulimit of 65536 bytes.
</span><span class='line'>        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1067)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.datanode.DataNode.&lt;init&gt;(DataNode.java:417)
</span></code></pre></td></tr></table></div></figure>


<p>2 添加RAM_DISK</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi hdfs-site.xml
</span><span class='line'>
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;/data/bigdata/hadoop/dfs/data,[RAM_DISK]/dev/shm/dfs/data&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>  &lt;name&gt;dfs.datanode.max.locked.memory&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;134217728&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>  </span></code></pre></td></tr></table></div></figure>


<p>注意内存盘的写法，<code>[RAM_DISK]</code> 必须这些写，不然datanode不知道指定路径的storage的类型(默认是 DISK )。<a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html#Storage_Types_and_Storage_Policies">Storage_Types_and_Storage_Policies</a></p>

<blockquote><p>The default storage type of a datanode storage location will be DISK if it does not have a storage type tagged explicitly.</p></blockquote>

<p>3 同步配置并重启dfs</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# scp /etc/security/limits.conf cu3:/etc/security/
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ rsync -vaz etc cu3:~/hadoop-2.6.3/ 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3] sbin/stop-dfs.sh
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3] sbin/start-dfs.sh</span></code></pre></td></tr></table></div></figure>


<p>可以去到datanode查看日志，可以看到 /dev/shm/dfs/data 路径 <strong>StorageType</strong> 为 <strong>RAM_DISK</strong> ：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-05-05 19:33:39,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /data/bigdata/hadoop/dfs/data/current
</span><span class='line'>2016-05-05 19:33:39,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /data/bigdata/hadoop/dfs/data/current, StorageType: DISK
</span><span class='line'>2016-05-05 19:33:39,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /dev/shm/dfs/data/current
</span><span class='line'>2016-05-05 19:33:39,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /dev/shm/dfs/data/current, StorageType: RAM_DISK</span></code></pre></td></tr></table></div></figure>


<p>同时查看 内存盘 的路径内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ ssh cu3 tree /dev/shm/dfs
</span><span class='line'>/dev/shm/dfs
</span><span class='line'>└── data
</span><span class='line'>    ├── current
</span><span class='line'>    │   ├── BP-1108852639-192.168.0.148-1452322889531
</span><span class='line'>    │   │   ├── current
</span><span class='line'>    │   │   │   ├── finalized
</span><span class='line'>    │   │   │   ├── rbw
</span><span class='line'>    │   │   │   └── VERSION
</span><span class='line'>    │   │   └── tmp
</span><span class='line'>    │   └── VERSION
</span><span class='line'>    └── in_use.lock
</span><span class='line'>
</span><span class='line'>7 directories, 3 files</span></code></pre></td></tr></table></div></figure>


<h2>测试使用</h2>

<p>通过三个例子对比，简单描述下使用。首先，使用默认的方式(主要用于对比)，第二个例子写文件是添加参数，第三个设置目录的存储类型（目录/文件会继承父目录的存储类型）</p>

<p>1 测试1</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -put README.txt /tmp/
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs fsck /tmp/README.txt -files -blocks -locations
</span><span class='line'>...
</span><span class='line'>/tmp/README.txt 1366 bytes, 1 block(s):  OK
</span><span class='line'>0. BP-1108852639-192.168.0.148-1452322889531:blk_1073752574_11776 len=1366 repl=1 [192.168.0.148:50010]
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 hadoop-2.6.3]$ find /data/bigdata/hadoop/dfs/data/ /dev/shm/dfs/data/ -name "*1073752574*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir41/blk_1073752574_11776.meta
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir41/blk_1073752574</span></code></pre></td></tr></table></div></figure>


<p>2 写文件时添加 lazy_persist 标识</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 添加 -l 参数，后台代码会加上 LAZY_PERSIST 标识。
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -help put 
</span><span class='line'>-put [-f] [-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt; :
</span><span class='line'>  Copy files from the local file system into fs. Copying fails if the file already
</span><span class='line'>  exists, unless the -f flag is given.
</span><span class='line'>  Flags:
</span><span class='line'>                                                                       
</span><span class='line'>  -p  Preserves access and modification times, ownership and the mode. 
</span><span class='line'>  -f  Overwrites the destination if it already exists.                 
</span><span class='line'>  -l  Allow DataNode to lazily persist the file to disk. Forces        
</span><span class='line'>         replication factor of 1. This flag will result in reduced
</span><span class='line'>         durability. Use with care.
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/storage-lazy.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># -l 参数会把 replication 强制设置成数字1 ！
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -put -l README.txt /tmp/readme.txt2
</span><span class='line'>
</span><span class='line'># 查看namenode的日志，可以看到文件写入到 RAM_DISK 类型的存储
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ less logs/hadoop-hadoop-namenode-cu2.log 
</span><span class='line'>
</span><span class='line'>  2016-05-05 20:38:36,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/readme.txt2._COPYING_. BP-1108852639-192.168.0.148-1452322889531 blk_1073752578_11780{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-dcb2673f-3297-4bd7-af1c-ac0ee3eebaf9:NORMAL:192.168.0.30:50010|RBW]]}
</span><span class='line'>  2016-05-05 20:38:36,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.0.30:50010 is added to blk_1073752578_11780{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[RAM_DISK]DS-bf1ab64f-7eb3-41e0-8466-43287de9893d:NORMAL:192.168.0.30:50010|FINALIZED]]} size 0
</span><span class='line'>  2016-05-05 20:38:36,594 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/readme.txt2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1388277364_1
</span><span class='line'>
</span><span class='line'># 具体的内容所在位置
</span><span class='line'>[hadoop@cu4 ~]$ tree /dev/shm/dfs/data/
</span><span class='line'>/dev/shm/dfs/data/
</span><span class='line'>├── current
</span><span class='line'>│   ├── BP-1108852639-192.168.0.148-1452322889531
</span><span class='line'>│   │   ├── current
</span><span class='line'>│   │   │   ├── finalized
</span><span class='line'>│   │   │   │   └── subdir0
</span><span class='line'>│   │   │   │       └── subdir42
</span><span class='line'>│   │   │   │           ├── blk_1073752578
</span><span class='line'>│   │   │   │           └── blk_1073752578_11780.meta
</span><span class='line'>│   │   │   ├── rbw
</span><span class='line'>│   │   │   └── VERSION
</span><span class='line'>│   │   └── tmp
</span><span class='line'>│   └── VERSION
</span><span class='line'>└── in_use.lock
</span></code></pre></td></tr></table></div></figure>


<p>3 设置目录的存储类型</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -mkdir /ramdisk
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -setStoragePolicy /ramdisk LAZY_PERSIST 
</span><span class='line'>Set storage policy LAZY_PERSIST on /ramdisk
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -put README.txt /ramdisk
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk
</span><span class='line'>The storage policy of /ramdisk:
</span><span class='line'>BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}
</span><span class='line'>
</span><span class='line'># 不支持通配符
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk/*
</span><span class='line'>getStoragePolicy: File/Directory does not exist: /ramdisk/*
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk/README.txt
</span><span class='line'>The storage policy of /ramdisk/README.txt:
</span><span class='line'>BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 添加replication参数，再测试多个备份只有一个写ram_disk
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -Ddfs.replication=3 -put README.txt /ramdisk/readme.txt2
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk/readme.txt2
</span><span class='line'>The storage policy of /ramdisk/readme.txt2:
</span><span class='line'>BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs fsck /ramdisk/readme.txt2 -files -blocks -locations
</span><span class='line'>
</span><span class='line'>  /ramdisk/readme.txt2 1366 bytes, 1 block(s):  OK
</span><span class='line'>  0. BP-1108852639-192.168.0.148-1452322889531:blk_1073752580_11782 len=1366 repl=3 [192.168.0.30:50010, 192.168.0.174:50010, 192.168.0.148:50010]
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 ~]$ find /data/bigdata/hadoop/dfs/data /dev/shm/dfs/data -name "*1073752580*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>
</span><span class='line'># 已经把ram_disk的内容持久化到磁盘了("Lazy_Persist")
</span><span class='line'>[hadoop@cu4 ~]$ find /data/bigdata/hadoop/dfs/data /dev/shm/dfs/data -name "*1073752580*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/lazypersist/subdir0/subdir42/blk_1073752580
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/lazypersist/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>/dev/shm/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580
</span><span class='line'>/dev/shm/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 ~]$ find /data/bigdata/hadoop/dfs/data /dev/shm/dfs/data -name "*1073752580*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580
</span></code></pre></td></tr></table></div></figure>


<p>[设想] 对于那些处理完就删除的临时文件，可以把持久化的时间设置的久一点 <code>dfs.datanode.lazywriter.interval.sec</code>。这样就不需要写磁盘了。</p>

<p>不要妄想了，反正都会持久化！就是缓冲的效果，其他没有了！！一次性存储并且不需要持久化的还是用alluxio吧。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.LazyWriter#saveNextReplica
</span><span class='line'>  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RamDiskAsyncLazyPersistService#submitLazyPersistTask</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li>挺详细的<a href="http://blog.csdn.net/androidlushangderen/article/details/51105876">HDFS异构存储</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetboard Install]]></title>
    <link href="http://winseliu.com/blog/2016/05/05/puppetboard-install/"/>
    <updated>2016-05-05T10:54:26+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/05/puppetboard-install</id>
    <content type="html"><![CDATA[<p>对于我这样的python小白来说，有网络来安装 puppetboard 还是比较容易的（离线安装依赖处理可能比较麻烦）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://fedoraproject.org/wiki/EPEL/zh-cn
</span><span class='line'>[root@cu2 ~]# yum search epel
</span><span class='line'>[root@cu2 ~]# yum install epel-release
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# yum repolist
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.skyshe.cn
</span><span class='line'> * centosplus: mirrors.pubyun.com
</span><span class='line'> * epel: mirror01.idc.hinet.net
</span><span class='line'> * extras: mirrors.skyshe.cn
</span><span class='line'> * updates: mirrors.skyshe.cn
</span><span class='line'>193 packages excluded due to repository priority protections
</span><span class='line'>repo id                                   repo name                                                                   status
</span><span class='line'>base                                      CentOS-6 - Base                                                                  6,575
</span><span class='line'>centosplus                                CentOS-6 - Centosplus                                                             0+76
</span><span class='line'>epel                                      Extra Packages for Enterprise Linux 6 - x86_64                              12,127+117
</span><span class='line'>extras                                    CentOS-6 - Extras                                                                   62
</span><span class='line'>puppet-local                              Puppet Local                                                                         5
</span><span class='line'>updates                                   CentOS-6 - Updates                                                               1,607
</span><span class='line'>repolist: 20,376
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# yum install python-pip -y
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# pip install puppetboard
</span><span class='line'>/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
</span><span class='line'>  InsecurePlatformWarning
</span><span class='line'>You are using pip version 7.1.0, however version 8.1.1 is available.
</span><span class='line'>You should consider upgrading via the 'pip install --upgrade pip' command.
</span><span class='line'>Collecting puppetboard
</span><span class='line'>/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
</span><span class='line'>  InsecurePlatformWarning
</span><span class='line'>  Downloading puppetboard-0.1.3.tar.gz (598kB)
</span><span class='line'>    100% |████████████████████████████████| 602kB 726kB/s 
</span><span class='line'>Collecting Flask&gt;=0.10.1 (from puppetboard)
</span><span class='line'>  Downloading Flask-0.10.1.tar.gz (544kB)
</span><span class='line'>    100% |████████████████████████████████| 544kB 734kB/s 
</span><span class='line'>Collecting Flask-WTF&lt;=0.9.5,&gt;=0.9.4 (from puppetboard)
</span><span class='line'>  Downloading Flask-WTF-0.9.5.tar.gz (245kB)
</span><span class='line'>    100% |████████████████████████████████| 249kB 320kB/s 
</span><span class='line'>Collecting WTForms&lt;2.0 (from puppetboard)
</span><span class='line'>  Downloading WTForms-1.0.5.zip (355kB)
</span><span class='line'>    100% |████████████████████████████████| 356kB 1.3MB/s 
</span><span class='line'>Collecting pypuppetdb&lt;0.3.0,&gt;=0.2.1 (from puppetboard)
</span><span class='line'>  Downloading pypuppetdb-0.2.1.tar.gz
</span><span class='line'>Collecting Werkzeug&gt;=0.7 (from Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading Werkzeug-0.11.9-py2.py3-none-any.whl (306kB)
</span><span class='line'>    100% |████████████████████████████████| 307kB 1.5MB/s 
</span><span class='line'>Collecting Jinja2&gt;=2.4 (from Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading Jinja2-2.8-py2.py3-none-any.whl (263kB)
</span><span class='line'>    100% |████████████████████████████████| 266kB 2.3MB/s 
</span><span class='line'>Collecting itsdangerous&gt;=0.21 (from Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading itsdangerous-0.24.tar.gz (46kB)
</span><span class='line'>    100% |████████████████████████████████| 49kB 7.2MB/s 
</span><span class='line'>Collecting requests&gt;=1.2.3 (from pypuppetdb&lt;0.3.0,&gt;=0.2.1-&gt;puppetboard)
</span><span class='line'>  Downloading requests-2.10.0-py2.py3-none-any.whl (506kB)
</span><span class='line'>    100% |████████████████████████████████| 507kB 920kB/s 
</span><span class='line'>Collecting MarkupSafe (from Jinja2&gt;=2.4-&gt;Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading MarkupSafe-0.23.tar.gz
</span><span class='line'>Installing collected packages: Werkzeug, MarkupSafe, Jinja2, itsdangerous, Flask, WTForms, Flask-WTF, requests, pypuppetdb, puppetboard
</span><span class='line'>  Running setup.py install for MarkupSafe
</span><span class='line'>  Running setup.py install for itsdangerous
</span><span class='line'>  Running setup.py install for Flask
</span><span class='line'>  Running setup.py install for WTForms
</span><span class='line'>  Running setup.py install for Flask-WTF
</span><span class='line'>  Running setup.py install for pypuppetdb
</span><span class='line'>  Running setup.py install for puppetboard
</span><span class='line'>Successfully installed Flask-0.10.1 Flask-WTF-0.9.5 Jinja2-2.8 MarkupSafe-0.23 WTForms-1.0.5 Werkzeug-0.11.9 itsdangerous-0.24 puppetboard-0.1.3 pypuppetdb-0.2.1 requests-2.10.0
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# pip show puppetboard
</span><span class='line'>You are using pip version 7.1.0, however version 8.1.1 is available.
</span><span class='line'>You should consider upgrading via the 'pip install --upgrade pip' command.
</span><span class='line'>---
</span><span class='line'>Metadata-Version: 1.0
</span><span class='line'>Name: puppetboard
</span><span class='line'>Version: 0.1.3
</span><span class='line'>Summary: Web frontend for PuppetDB
</span><span class='line'>Home-page: https://github.com/puppet-community/puppetboard
</span><span class='line'>Author: Daniele Sluijters
</span><span class='line'>Author-email: daniele.sluijters+pypi@gmail.com
</span><span class='line'>License: Apache License 2.0
</span><span class='line'>Location: /usr/lib/python2.6/site-packages
</span><span class='line'>Requires: Flask, Flask-WTF, WTForms, pypuppetdb
</span><span class='line'>[root@cu2 ~]# ll /usr/lib/python2.6/site-packages/puppetboard
</span><span class='line'>total 100
</span><span class='line'>-rw-r--r-- 1 root root 31629 May  5 09:12 app.py
</span><span class='line'>-rw-r--r-- 1 root root 30481 May  5 09:12 app.pyc
</span><span class='line'>-rw-r--r-- 1 root root  1206 May  5 09:12 default_settings.py
</span><span class='line'>-rw-r--r-- 1 root root  1477 May  5 09:12 default_settings.pyc
</span><span class='line'>-rw-r--r-- 1 root root  1025 May  5 09:12 forms.py
</span><span class='line'>-rw-r--r-- 1 root root  1982 May  5 09:12 forms.pyc
</span><span class='line'>-rw-r--r-- 1 root root     0 May  5 09:12 __init__.py
</span><span class='line'>-rw-r--r-- 1 root root   143 May  5 09:12 __init__.pyc
</span><span class='line'>drwxr-xr-x 9 root root  4096 May  5 09:12 static
</span><span class='line'>drwxr-xr-x 2 root root  4096 May  5 09:12 templates
</span><span class='line'>-rw-r--r-- 1 root root  2155 May  5 09:12 utils.py
</span><span class='line'>-rw-r--r-- 1 root root  3433 May  5 09:12 utils.pyc
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# pip install uwsgi
</span><span class='line'>You are using pip version 7.1.0, however version 8.1.1 is available.
</span><span class='line'>You should consider upgrading via the 'pip install --upgrade pip' command.
</span><span class='line'>Collecting uwsgi
</span><span class='line'>/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
</span><span class='line'>  InsecurePlatformWarning
</span><span class='line'>  Downloading uwsgi-2.0.12.tar.gz (784kB)
</span><span class='line'>    100% |████████████████████████████████| 786kB 143kB/s 
</span><span class='line'>Installing collected packages: uwsgi
</span><span class='line'>  Running setup.py install for uwsgi
</span><span class='line'>Successfully installed uwsgi-2.0.12
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# mkdir -p /var/www/puppetboard
</span><span class='line'>[root@cu2 ~]# cd /var/www/puppetboard/
</span><span class='line'>[root@cu2 puppetboard]# cp /usr/lib/python2.6/site-packages/puppetboard/default_settings.py ./settings.py
</span><span class='line'># 修改配置 
</span><span class='line'># https://github.com/voxpupuli/puppetboard#settings
</span><span class='line'>PUPPETDB_HOST = 'cu3'
</span><span class='line'>PUPPETDB_PORT = 8080
</span><span class='line'>REPORTS_COUNT = 21
</span><span class='line'>ENABLE_CATALOG = True
</span><span class='line'>
</span><span class='line'>[root@cu2 puppetboard]# vi wsgi.py 
</span><span class='line'>from __future__ import absolute_import
</span><span class='line'>import os
</span><span class='line'>
</span><span class='line'>os.environ['PUPPETDOARD_SETTINGS'] = '/var/www/puppetboard/settings.py'
</span><span class='line'>from puppetboard.app import app as application
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># A 直接用uwsgi-http
</span><span class='line'># http://yongqing.is-programmer.com/posts/43688.html
</span><span class='line'>[root@cu2 puppetboard]# uwsgi --http :9091 --wsgi-file /var/www/puppetboard/wsgi.py 
</span><span class='line'>
</span><span class='line'># 使用 supervisord 管理
</span><span class='line'>[root@cu2 supervisord.d]# cat uwsgi.ini 
</span><span class='line'>[program:puppetboard]
</span><span class='line'>command=uwsgi --http :9091 --wsgi-file /var/www/puppetboard/wsgi.py 
</span><span class='line'>[root@cu2 supervisord.d]# supervisorctl update
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># B nginx + uwsgi-socket
</span><span class='line'># 需要对应到 / ，新增一个9091的server
</span><span class='line'>[root@cu2 puppetboard]# vi /home/hadoop/nginx/conf/nginx.conf
</span><span class='line'>server {
</span><span class='line'>  listen 9091;
</span><span class='line'>
</span><span class='line'>  location /static {
</span><span class='line'>    alias /usr/lib/python2.6/site-packages/puppetboard/static;
</span><span class='line'>  }
</span><span class='line'>  location / {
</span><span class='line'>    include uwsgi_params;
</span><span class='line'>    uwsgi_pass 127.0.0.1:9090;
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@cu2 puppetboard]# uwsgi --socket :9090 --wsgi-file /var/www/puppetboard/wsgi.py 
</span><span class='line'>
</span><span class='line'>[root@cu2 puppetboard]# /home/hadoop/nginx/sbin/nginx -s reload
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/puppetboard-install.png" alt="" /></p>

<p>配置SSL访问需要把ssl_verify设置为false。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 2.7.9+网上说好像就没问题
</span><span class='line'># http://stackoverflow.com/questions/29099404/ssl-insecureplatform-error-when-using-requests-package
</span><span class='line'># https://github.com/pypa/pip/issues/2681
</span><span class='line'>[root@cu2 ~]# yum install -y  libffi-devel libffi 
</span><span class='line'>[root@cu2 ~]# pip install 'requests[security]'
</span><span class='line'>
</span><span class='line'># [重要] 两个链接内容一样的：
</span><span class='line'># * https://groups.google.com/forum/#!msg/puppet-users/m7Sakf4bQ7Q/y6uAa0AUsZIJ
</span><span class='line'># * http://grokbase.com/t/gg/puppet-users/1428vjkncr/puppetboard-and-ssl
</span><span class='line'># You have two choices now, set SSL_VERIFY to False and trust that you're
</span><span class='line'># always talking to your actual PuppetDB or copy from the Puppet CA
</span><span class='line'># $vardir/ssl/ca_crt.pem to /etc/puppetboard and set SSL_VERIFY to the path
</span><span class='line'># of ca_crt.pem. In that case the file SSL_VERIFY points to will be used to
</span><span class='line'># verify PuppetDB's server certificate instead of the OS truststore.
</span><span class='line'>[root@cu2 puppetboard]# vi settings.py 
</span><span class='line'>PUPPETDB_HOST = 'cu3.eshore.cn'
</span><span class='line'>PUPPETDB_PORT = 8081
</span><span class='line'>PUPPETDB_SSL_VERIFY = False  # 这里设置为false
</span><span class='line'>PUPPETDB_KEY = '/etc/puppetlabs/puppet/ssl/private_keys/cu2.eshore.cn.pem'
</span><span class='line'>PUPPETDB_CERT = '/etc/puppetlabs/puppet/ssl/ca/signed/cu2.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'># 重启uwsgi-http服务
</span><span class='line'>[root@cu2 ~]# supervisorctl restart puppetboard
</span></code></pre></td></tr></table></div></figure>


<p>如果 puppetboard 和 puppetdb 安装在同一机器，可以使用 puppetdb/ssl 路径下的ssl文件（puppetdb/ssl也是从puppet/ssl拷贝过来的）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# puppetdb ssl-setup -f
</span><span class='line'>PEM files in /etc/puppetlabs/puppetdb/ssl are missing, we will move them into place for you
</span><span class='line'>Copying files: /etc/puppetlabs/puppet/ssl/certs/ca.pem, /etc/puppetlabs/puppet/ssl/private_keys/cu3.eshore.cn.pem and /etc/puppetlabs/puppet/ssl/certs/cu3.eshore.cn.pem to /etc/puppetlabs/puppetdb/ssl
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# tree /etc/puppetlabs/puppetdb/ssl/
</span><span class='line'>/etc/puppetlabs/puppetdb/ssl/
</span><span class='line'>├── ca.pem
</span><span class='line'>├── private.pem
</span><span class='line'>└── public.pem
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hiera and Facts]]></title>
    <link href="http://winseliu.com/blog/2016/05/03/hiera-and-facts/"/>
    <updated>2016-05-03T18:30:41+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/03/hiera-and-facts</id>
    <content type="html"><![CDATA[<p>为什么用hiera： <a href="https://docs.puppet.com/hiera/3.1/#why-hiera">https://docs.puppet.com/hiera/3.1/#why-hiera</a></p>

<ul>
<li>hierarchy层级体系。可以设置公共属性，也可以覆写！</li>
<li>&ldquo;注入&#8221;设置 class 中的属性值。</li>
<li>hiera_include 通过配置来完成site.pp同样的功能，并且比 <code>node</code> 更加强大灵活（数组值可以合并）。</li>
</ul>


<p>基本概念：</p>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/configuring.html">hiera.yaml</a> 默认配置文件放在 $codedir/hiera.yaml 。 结合puppet使用时可以通过修改 puppet.conf 的 hiera_config 自定义配置的文件。</li>
<li><a href="https://docs.puppet.com/hiera/3.1/hierarchy.html">hierarchy</a> hierarchy定义好可以简化很多工作量。如需要根据操作系统 %{::osfamily} 进行适配。</li>
<li><a href="https://docs.puppet.com/hiera/3.1/data_sources.html#yaml">datasource</a> yaml格式介绍。</li>
</ul>


<h2>windows cygwin命令行环境配置</h2>

<pre><code>winse@Lenovo-PC ~
$ cat bin/hiera
#!/bin/sh

# default puppetlabs config in c:\Users\winse\Puppetlabs
export HOME=/cygdrive/c/Users/winse

name=`basename $0`

# execute
"C:/Progra~1/Puppet~1/Puppet/bin"/$name.bat "$@"


winse@Lenovo-PC ~
$ cat .bash_profile
...
function hiera_look(){
  code_dir=`puppet config print codedir | sed 's/\r//' `
  ~/bin/hiera -c "$code_dir/hiera.yaml" --debug "$@" ::environment=production
}
</code></pre>

<h2>HelloWorld</h2>

<pre><code>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat /cygdrive/c/Users/winse/.puppetlabs/etc/puppet/puppet.conf
[main]
codedir = D:/eshore-shells/puppet/dta/code
hiera_config = $codedir/hiera.yaml

certname = winse

winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat hiera.yaml
---
:backends:
  - yaml
:hierarchy:
  - "nodes/%{::trusted.certname}"
  - common

:yaml:
  :datadir: "D:/eshore-shells/puppet/dta/code/environments/%{::environment}/hieradata"


winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat environments/production/hieradata/common.yaml
whoami: winse


winse@Lenovo-PC ~
$ hiera_look whoami
DEBUG: 2016-05-03 11:27:41 +0100: Hiera YAML backend starting
DEBUG: 2016-05-03 11:27:41 +0100: Looking up whoami in YAML backend
DEBUG: 2016-05-03 11:27:41 +0100: Looking for data source common
DEBUG: 2016-05-03 11:27:41 +0100: Found whoami in common
winse
</code></pre>

<h2><strong>与Puppet结合使用</strong></h2>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/puppet.html">https://docs.puppet.com/hiera/3.1/puppet.html</a></li>
<li><a href="https://docs.puppet.com/hiera/3.1/puppet.html#assigning-classes-to-nodes-with-hiera-hierainclude">https://docs.puppet.com/hiera/3.1/puppet.html#assigning-classes-to-nodes-with-hiera-hierainclude</a></li>
<li>单值属性重复优先级：就近原则 <a href="https://docs.puppet.com/hiera/3.1/hierarchy.html#example">https://docs.puppet.com/hiera/3.1/hierarchy.html#example</a></li>
</ul>


<h4>参考案例</h4>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/complete_example.html">https://docs.puppet.com/hiera/3.1/complete_example.html</a></li>
<li><a href="https://kisspuppet.gitbooks.io/puppet/content/puppet_learning_ext1.html">https://kisspuppet.gitbooks.io/puppet/content/puppet_learning_ext1.html</a></li>
</ul>


<h4>主要功能</h4>

<ul>
<li>hiera获取puppet-facts的属性</li>
<li>puppet读取hiera中的属性</li>
<li>hiera注入设置puppet-module的属性：
  获取到第一个就返回了(类似于hiera)，对于strings, arrays, hashes类型 cannot merge values from multiple hierarchy levels; 需要使用来 hiera_array or hiera_hash 代替。</li>
<li>hiera_include</li>
</ul>


<h4>动手实践</h4>

<pre><code>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code/environments/production
$ tree .
.
├── hieradata
│   ├── common.yaml
│   └── nodes
│       └── winse.yaml
├── manifests
│   └── site.pp
└── modules
    └── helloworld
        └── manifests
            └── init.pp

$ cat hieradata/common.yaml
whoami: "%{calling_module} - %{calling_class} - %{calling_class_path} - %{::domain}"

$ cat hieradata/nodes/winse.yaml  | iconv -f gbk -t utf8
---
classes:
  - helloworld::hello
  - helloworld::world

# 文件编码需要与环境匹配，windows要GBK的
helloworld::hello::hello: 你好

$ cat modules/helloworld/manifests/init.pp

class helloworld::hello ($hello = "hello"){

  notify {$hello :
  }

}

class helloworld::world {

  notify {hiera('whoami') : # 不推荐在module中使用hiera方法，这里仅为了演示获取calling_module等
  }

}

$ cat manifests/site.pp

hiera_include('classes')

$ puppet apply environments/production/manifests/site.pp
Notice: Compiled catalog for winse in environment production in 0.28 seconds
Notice: 你好
Notice: /Stage[main]/Helloworld::Hello/Notify[你好]/message: defined 'message' as '你好'
Notice: helloworld - helloworld::world - helloworld/world - DHCP HOST
Notice: /Stage[main]/Helloworld::World/Notify[helloworld - helloworld::world - helloworld/world - DHCP HOST]/message: defined 'message' as 'helloworld - helloworld::world - helloworld/world - DHCP HOST'
Notice: Applied catalog in 0.02 seconds

# 测试获取hiera变量
$ puppet apply -e "notice(hiera('whoami'))"
Notice: Scope(Class[main]):  -  -  - DHCP HOST
Notice: Compiled catalog for winse in environment production in 0.05 seconds
Notice: Applied catalog in 0.03 seconds

$ puppet apply -e "notice(hiera('classes'))"
Notice: Scope(Class[main]): [helloworld::hello, helloworld::world]
Notice: Compiled catalog for winse in environment production in 0.05 seconds
Notice: Applied catalog in 0.02 seconds
</code></pre>

<h2>facts</h2>

<ul>
<li><a href="https://docs.puppet.com/facter/3.1/">https://docs.puppet.com/facter/3.1/</a></li>
<li>系统自带指标 <a href="https://docs.puppet.com/facter/3.1/core_facts.html">https://docs.puppet.com/facter/3.1/core_facts.html</a></li>
</ul>


<h4>自定义指标</h4>

<ul>
<li><a href="https://docs.puppet.com/facter/3.1/custom_facts.html">https://docs.puppet.com/facter/3.1/custom_facts.html</a></li>
<li>Example <a href="https://docs.puppet.com/facter/3.1/fact_overview.html">https://docs.puppet.com/facter/3.1/fact_overview.html</a></li>
<li>《Learning Puppet4》</li>
</ul>


<p>三种方式：</p>

<ul>
<li>文件: yaml/json/txt。推荐放置到 modules/[name]/facts.d 目录下</li>
<li>可执行脚本输出键值对。推荐放置到 modules/[name]/facts.d 目录下，可执行脚本！</li>
<li>ruby。放置到 modules/[name]/lib/facter 。<a href="https://docs.puppet.com/guides/plugins_in_modules.html">custom facts should go in lib/facter/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cat environments/production/modules/helloworld/facts.d/simple_facts.yaml
</span><span class='line'>---
</span><span class='line'>my_fact: my_value
</span><span class='line'>
</span><span class='line'>$ puppet facts find --debug | grep -iE "my_fact|helloworld"
</span><span class='line'>Debug: Loading external facts from D:/eshore-shells/puppet/dta/code/environments/production/modules/helloworld/facts.d
</span><span class='line'>Debug: Facter: searching "D:/eshore-shells\puppet\dta\code\environments\production\modules\helloworld\facts.d" for external facts.
</span><span class='line'>Debug: Facter: resolving facts from YAML file "D:/eshore-shells\puppet\dta\code\environments\production\modules\helloworld\facts.d\simple_facts.yaml".
</span><span class='line'>Debug: Facter: fact "my_fact" has resolved to "my_value".
</span><span class='line'>Debug: Facter: completed resolving facts from YAML file "D:/eshore-shells\puppet\dta\code\environments\production\modules\helloworld\facts.d\simple_facts.yaml".
</span><span class='line'>    "my_fact": "my_value",
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
</span><span class='line'>$ cat environments/production/modules/helloworld/lib/facter/users.rb
</span><span class='line'>Facter.add('users') do
</span><span class='line'>  setcode do
</span><span class='line'>    ["winse", "winseliu"]
</span><span class='line'>  end
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>$ puppet facts | grep -3 users
</span><span class='line'>    "uptime_days": 0,
</span><span class='line'>    "uptime_hours": 1,
</span><span class='line'>    "uptime_seconds": 6980,
</span><span class='line'>    "users": [
</span><span class='line'>      "winse",
</span><span class='line'>      "winseliu"
</span><span class='line'>    ],
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MCollective Plugins]]></title>
    <link href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/"/>
    <updated>2016-04-28T21:37:51+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/28/mcollective-plugins</id>
    <content type="html"><![CDATA[<p>上一篇介绍了mcollective的安装。乘着这股热情把 mco 命令行和插件的安装弄通，记录下来。</p>

<h2>基本命令使用</h2>

<ul>
<li><a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html">https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  rpc             Generic RPC agent client application
</span></code></pre></td></tr></table></div></figure>


<p>自带的插件只能用来查看环境情况(下面列出来的命令<a href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/#cli-simple-usage">上一篇:MCollective安装配置</a>都已记录过)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mco ping
</span><span class='line'>mco inventory [server_host]
</span><span class='line'>mco facts [fact]</span></code></pre></td></tr></table></div></figure>


<p>mcollective 的 filter（适配节点）功能很强大，具体查看文档：<a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html#selecting-request-targets-using-filters">Selecting Request Targets Using Filters</a></p>

<p><strong> 使用filter功能需要结合facts，需要先把节点的信息写入到mcollective/facts.yaml文件 </strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco ping -I /^hadoop/
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco puppet runall 8 -I /^hadoop/
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco service iptables status -I "/cu-ud.*/"
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 manifests]# mco ping -S "hostname=hadoop-master2"
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco ping -S 'hostname=/hadoop.*/'
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco facts hostname</span></code></pre></td></tr></table></div></figure>


<h2>插件安装</h2>

<ul>
<li><a href="https://docs.puppet.com/mcollective/deploy/standard.html#install-agent-plugins">https://docs.puppet.com/mcollective/deploy/standard.html#install-agent-plugins</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/plugins.html">Installing Plugins</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/plugins.html#example">https://docs.puppet.com/mcollective/deploy/plugins.html#example</a></li>
</ul>


<p>文档中描述了 <code>Use packages</code> 和 <code>Put files directly into the libdir</code> 两种安装插件的方式。但是 Packages 都是放在 <a href="http://yum.puppetlabs.com/el/6/products/x86_64/">旧的repo</a> 里面，我们这里使用第二种方式把github下载源码放到libdir来安装。</p>

<h4>安装mcollective-puppet-agent</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 使用文档 https://github.com/puppetlabs/mcollective-puppet-agent#readme
</span><span class='line'># 直接下载release版本 
</span><span class='line'>[root@hadoop-master2 ~]# cd /usr/libexec/mcollective/
</span><span class='line'>[root@hadoop-master2 mcollective]# ll
</span><span class='line'>total 44
</span><span class='line'>-rw-r--r-- 1 root root 44759 Apr 29 11:53 mcollective-puppet-agent-1.10.0.tar.gz
</span><span class='line'>[root@hadoop-master2 mcollective]# tar zxf mcollective-puppet-agent-1.10.0.tar.gz  
</span><span class='line'>[root@hadoop-master2 mcollective]# ll mcollective-puppet-agent-1.10.0
</span><span class='line'>total 60
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 agent
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 aggregate
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 application
</span><span class='line'>-rw-rw-r-- 1 root root  3456 Apr 13  2015 CHANGELOG.md
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 data
</span><span class='line'>drwxrwxr-x 4 root root  4096 Apr 13  2015 ext
</span><span class='line'>-rw-rw-r-- 1 root root   349 Apr 13  2015 Gemfile
</span><span class='line'>-rw-rw-r-- 1 root root  3036 Apr 13  2015 Rakefile
</span><span class='line'>-rw-rw-r-- 1 root root 14739 Apr 13  2015 README.md
</span><span class='line'>drwxrwxr-x 9 root root  4096 Apr 13  2015 spec
</span><span class='line'>drwxrwxr-x 3 root root  4096 Apr 13  2015 util
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 validator
</span><span class='line'># 官网提供example有区分服务端和客户端文件。反正多了没问题，直接全部放就行咯。。。
</span><span class='line'>[root@hadoop-master2 mcollective]# mv mcollective-puppet-agent-1.10.0 mcollective
</span><span class='line'>
</span><span class='line'># 验证
</span><span class='line'># 多了puppet的命令！
</span><span class='line'>[root@hadoop-master2 mcollective]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  puppet          Schedule runs, enable, disable and interrogate the Puppet Agent
</span><span class='line'>  rpc             Generic RPC agent client application
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 同步到mcollective-servers （172.17.0.2对应hadoop-slaver1）
</span><span class='line'>[root@hadoop-master2 mcollective]# rsync -az /usr/libexec/mcollective 172.17.0.2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># mcollective-server添加插件后，重启mcollective服务
</span><span class='line'># 也可以使用 reload-agents 来重新加载agents： service mcollective reload-agents
</span><span class='line'>[root@hadoop-slaver1 libexec]# service mcollective restart
</span><span class='line'>Shutting down mcollective:                                 [  OK  ]
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 验证server，已经可以看到新添加的puppet命令了
</span><span class='line'>[root@hadoop-master2 mcollective]# mco inventory hadoop-slaver1
</span><span class='line'>Inventory for hadoop-slaver1:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-04-29 12:01:40 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 123
</span><span class='line'>               Total Messages: 1
</span><span class='line'>      Messages Passed Filters: 1
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 0
</span><span class='line'>         Total Processor Time: 0.67 seconds
</span><span class='line'>                  System Time: 0.8 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       puppet          rpcutil        
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat           puppet          resource       
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco help puppet
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco puppet status    
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-slaver1: Currently stopped; last completed run 10 hours 57 minutes 20 seconds ago
</span><span class='line'>   hadoop-master1: Currently stopped; last completed run 11 hours 1 minutes 05 seconds ago
</span><span class='line'>   hadoop-slaver2: Currently stopped; last completed run 10 hours 57 minutes 16 seconds ago
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 配置server.conf
</span><span class='line'># 注意：真正要执行puppet命令，为了适配puppet4需要添加/修改配置
</span><span class='line'>-bash-4.1# cat /etc/puppetlabs/mcollective/server.cfg 
</span><span class='line'>...
</span><span class='line'>plugin.puppet.command = /opt/puppetlabs/bin/puppet agent
</span><span class='line'>plugin.puppet.config = /etc/puppetlabs/puppet/puppet.conf
</span><span class='line'>
</span><span class='line'># 重启所有mcollective（重新加载agent也可以不重启，使用 mco shell run service mcollective reload-agents 来重新加载）
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco puppet runall 1
</span><span class='line'>2016-04-29 16:52:46: Running all nodes with a concurrency of 1
</span><span class='line'>2016-04-29 16:52:46: Discovering enabled Puppet nodes to manage
</span><span class='line'>2016-04-29 16:52:49: Found 3 enabled nodes
</span><span class='line'>2016-04-29 16:52:50: hadoop-slaver1 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:55: hadoop-slaver2 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:59: hadoop-master1 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:59: Iteration complete. Initiated a Puppet run on 3 nodes.
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# mco puppet status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-master1: Currently stopped; last completed run 10 seconds ago
</span><span class='line'>   hadoop-slaver1: Currently stopped; last completed run 15 seconds ago
</span><span class='line'>   hadoop-slaver2: Currently stopped; last completed run 04 seconds ago
</span><span class='line'>...
</span><span class='line'># 或者通过 puppetexplorer 查看节点最后的更新时间
</span></code></pre></td></tr></table></div></figure>


<h4>安装 package / service 插件</h4>

<p>为了更好的管理，再添加 package 和 service 两个插件</p>

<ul>
<li><a href="https://github.com/puppetlabs/mcollective-package-agent#readme">https://github.com/puppetlabs/mcollective-package-agent#readme</a></li>
<li><a href="https://github.com/puppetlabs/mcollective-service-agent#readme">https://github.com/puppetlabs/mcollective-service-agent#readme</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://stackoverflow.com/questions/8488253/how-to-force-cp-to-overwrite-without-confirmation
</span><span class='line'>[root@hadoop-master2 mcollective]# unalias cp
</span><span class='line'>[root@hadoop-master2 mcollective]# cp -rf mcollective-service-agent-3.1.3/* mcollective/   
</span><span class='line'>[root@hadoop-master2 mcollective]# cp -rf mcollective-package-agent-4.4.0/* mcollective/
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# rsync -az /usr/libexec/mcollective 172.17.0.2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># 重启mcollective服务（或者 mco shell run service mcollective reload-agents 重新加载）
</span><span class='line'>
</span><span class='line'># updated 2016-5-11 17:15:08
</span><span class='line'># 还是重启比较好，reload-agents Data Plugins 没有重新加载
</span><span class='line'>[root@hadoop-master1 puppet]# mco inventory hadoop-master2
</span><span class='line'>Inventory for hadoop-master2:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-05-11 17:12:45 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 39878
</span><span class='line'>               Total Messages: 1
</span><span class='line'>      Messages Passed Filters: 1
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 0
</span><span class='line'>         Total Processor Time: 1.17 seconds
</span><span class='line'>                  System Time: 0.1 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       package         puppet         
</span><span class='line'>      rpcutil         service         shell          
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat           puppet          resource       
</span><span class='line'>      service                                        
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>[root@hadoop-master1 puppet]# mco inventory hadoop-slaver2
</span><span class='line'>Inventory for hadoop-slaver2:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-05-11 16:56:09 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 14062
</span><span class='line'>               Total Messages: 9
</span><span class='line'>      Messages Passed Filters: 7
</span><span class='line'>            Messages Filtered: 2
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 6
</span><span class='line'>         Total Processor Time: 1.31 seconds
</span><span class='line'>                  System Time: 0.23 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       package         puppet         
</span><span class='line'>      rpcutil         service         shell          
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat                                          
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>验证下package的实力：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 mcollective]# mco package lrzsz status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-slaver1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-master1: -purged.
</span><span class='line'>   hadoop-slaver2: -purged.
</span><span class='line'>
</span><span class='line'>Summary of Arch:
</span><span class='line'>
</span><span class='line'>   x86_64 = 1
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>             purged = 2
</span><span class='line'>   0.12.20-27.1.el6 = 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 1488.41 ms
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco rpc package install package=lrzsz
</span><span class='line'>Discovering hosts using the mc method for 2 second(s) .... 3
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>hadoop-slaver1                           Unknown Request Status
</span><span class='line'>   Package is already installed
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>   0.12.20-27.1.el6 = 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 14525.03 ms
</span><span class='line'>[root@hadoop-master2 mcollective]# mco package lrzsz status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-master1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-slaver2: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-slaver1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>
</span><span class='line'>Summary of Arch:
</span><span class='line'>
</span><span class='line'>   x86_64 = 3
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>   0.12.20-27.1.el6 = 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 572.13 ms
</span></code></pre></td></tr></table></div></figure>


<p>还有很多的插件：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/plugin_directory/index.html">https://docs.puppet.com/mcollective/plugin_directory/index.html</a></li>
<li>shell插件也不错，安装的时刻注意一下目录结构！<a href="https://github.com/puppetlabs/mcollective-shell-agent">https://github.com/puppetlabs/mcollective-shell-agent</a></li>
</ul>


<p>添加了 service，package，shell，puppet 插件后，用 mco 来执行管理集群太爽了！！</p>

<h4>后期统一安装</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 mcollective]# ll
</span><span class='line'>total 100
</span><span class='line'>-rw-r--r-- 1 root root 17101 Apr 29 12:15 mcollective-package-agent-4.4.0.tar.gz
</span><span class='line'>-rw-r--r-- 1 root root 44759 Apr 29 11:53 mcollective-puppet-agent-1.10.0.tar.gz
</span><span class='line'>-rw-r--r-- 1 root root 12483 Apr 29 12:15 mcollective-service-agent-3.1.3.tar.gz
</span><span class='line'>-rw-r--r-- 1 root root 17984 Apr 29 19:24 mcollective-shell-agent-0.0.2.tar.gz
</span><span class='line'>[root@hadoop-master1 mcollective]# ls | xargs -I{} tar zxf {}
</span><span class='line'>
</span><span class='line'># TODO 可以考虑打包成rpm
</span><span class='line'>[root@hadoop-master1 mcollective]# mkdir mcollective
</span><span class='line'>[root@hadoop-master1 mcollective]# unalias cp
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-package-agent-4.4.0/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-puppet-agent-1.10.0/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-service-agent-3.1.3/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-shell-agent-0.0.2/lib/mcollective/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# rm -rf mcollective-*
</span><span class='line'>
</span><span class='line'># 验证
</span><span class='line'>[root@hadoop-master1 mcollective]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  package         Install, uninstall, update, purge and perform other actions to packages
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  puppet          Schedule runs, enable, disable and interrogate the Puppet Agent
</span><span class='line'>  rpc             Generic RPC agent client application
</span><span class='line'>  service         Manages system services
</span><span class='line'>  shell           Run shell commands
</span><span class='line'>
</span><span class='line'># 同步
</span><span class='line'>[root@hadoop-master1 mcollective]# cd ..
</span><span class='line'>[root@hadoop-master1 libexec]# rsync -az mcollective hadoop-master2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># filter
</span><span class='line'>[root@hadoop-master1 manifests]# mco shell run hostname -S "hostname=hadoop-master2"
</span><span class='line'>[root@hadoop-master1 manifests]# mco ping -S "not hostname=hadoop-master1"
</span><span class='line'>[root@hadoop-master1 manifests]# mco ping -S "! hostname=hadoop-master1"
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco shell --sort -I /cu-ud[1234]{1}$/ run -- ' ls /home/ud/ftpxdr | wc -l  '
</span><span class='line'>
</span><span class='line'># 少配置了
</span><span class='line'>[root@hadoop-master1 manifests]# mco shell run "echo -e '\n\nplugin.puppet.command = /opt/puppetlabs/bin/puppet agent\nplugin.puppet.config = /etc/puppetlabs/puppet/puppet.conf' &gt;&gt; /etc/puppetlabs/mcollective/server.cfg" 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 重启 mcollective 服务
</span><span class='line'>[root@hadoop-master1 manifests]# mco shell run "echo service mcollective restart &gt;/tmp/mcollective_restart.sh ; nohup sh /tmp/mcollective_restart.sh "
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># ---
</span><span class='line'>[root@hadoop-master1 dtarepo]# mco rpc package install package=lrzsz -I cu-omc1
</span><span class='line'>[root@hadoop-master1 dtarepo]# mco rpc package install package=gmetad -I cu-omc1
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 gmond]# mco shell -I cu-ud2 run -- "/opt/puppetlabs/bin/puppet agent -t"
</span><span class='line'>[root@hadoop-master1 production]# mco shell -I /^cu-omc2/ run -- "/opt/puppetlabs/bin/puppet agent -t"
</span><span class='line'>
</span><span class='line'># gmond 多网卡情况确认
</span><span class='line'>[root@hadoop-master1 production]# route add -host 239.2.11.71 dev bond0
</span><span class='line'>
</span><span class='line'># puppet 基本语法
</span><span class='line'># https://docs.puppet.com/puppet/latest/reference/lang_conditional.html#if-statements
</span><span class='line'># https://docs.puppet.com/puppet/latest/reference/lang_relationships.html
</span><span class='line'>
</span><span class='line'># puppet使用tag可以更灵活的使用
</span><span class='line'># https://docs.puppet.com/puppet/latest/reference/lang_tags.html
</span><span class='line'>apache::vhost {'docs.puppetlabs.com':
</span><span class='line'>  port =&gt; 80,
</span><span class='line'>  tag  =&gt; ['us_mirror1', 'us_mirror2'],
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>$ sudo puppet agent --test --tags apache,us_mirror1
</span></code></pre></td></tr></table></div></figure>


<p>再次强调Filter ： <a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html#selecting-request-targets-using-filters">Selecting Request Targets Using Filters</a></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MCollective安装配置]]></title>
    <link href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/"/>
    <updated>2016-04-28T08:39:23+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/28/mcollective-quick-start</id>
    <content type="html"><![CDATA[<p>puppet agent 通过定时拉取的方式来更新本地系统，但无法满足实时更新的需求。 mcollective 通过 <strong>消息中间件</strong> 的方式，mclient/mservers通过消息的推送/订阅，实现mservers实时执行mclient提交的请求。（添加 m 说明是mcollective的组件！）</p>

<p>最新版的安装除了官网，没有其他可以直接学习的资料（只能参考）。先看官网的资料：</p>

<ul>
<li>组件功能(必须看看) <a href="https://docs.puppet.com/mcollective/overview_components.html">https://docs.puppet.com/mcollective/overview_components.html</a></li>
<li>部署 <a href="https://docs.puppet.com/mcollective/deploy/install.html">https://docs.puppet.com/mcollective/deploy/install.html</a></li>
<li>部署规范/准则 <a href="https://docs.puppet.com/mcollective/deploy/standard.html">https://docs.puppet.com/mcollective/deploy/standard.html</a></li>
</ul>


<p>摘录官网安装描述：[Installing MCollective requires the following steps]</p>

<ul>
<li>Make sure your middleware is up and running and your firewalls are in order.</li>
<li>Install the mcollective package on servers, then make sure the mcollective service is running.</li>
<li>Install the mcollective-client package on admin workstations.</li>
<li>Most Debian-like and Red Hat-like systems can use the official Puppet Labs packages. Enable the Puppet Labs repos, or import the packages into your own repos.

<ul>
<li>If you’re on Debian/Ubuntu, mind the missing package dependency.</li>
</ul>
</li>
<li>If your systems can’t use the official packages, check the system requirements and either build your own or run from source.</li>
</ul>


<p>mcollective对于puppet来说是一个锦上添花的组件，没有puppet一样正常运转。部署主要由两个部分组成：</p>

<ul>
<li>部署消息中间件</li>
<li>配置mcollective(puppet4.4 agent已经安装该功能，redhat也自带装了Stomp包：<code>/opt/puppetlabs/puppet/lib/ruby/gems/2.1.0/gems/</code> 目录下面)

<ul>
<li>配置mclient/mserver</li>
<li>配置Stomp with TLS</li>
<li>配置security</li>
</ul>
</li>
</ul>


<p>本文先简单实现连接远程主机，然后配置安全功能，最后用puppet来重新实现 mcollective 的安装和配置。</p>

<h1>环境说明</h1>

<ul>
<li>hadoop-master2:

<ul>
<li>172.17.42.1</li>
<li>puppetserver, activemq-server, mcollective-client</li>
</ul>
</li>
<li>hadoop-master1/hadoop-slaver1/hadoop-slaver2:

<ul>
<li>172.17.0.2/&frac34;</li>
<li>puppet-agent, mcollective-server</li>
</ul>
</li>
</ul>


<h1>ActiveMQ部署</h1>

<p>activemq的服务端是一个spring-jetty项目，直接解压运行启动脚本即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://activemq.apache.org/download-archives.html
</span><span class='line'># 直接下载最新的 tar.gz
</span><span class='line'>
</span><span class='line'># 解压，启动
</span><span class='line'>On Unix:
</span><span class='line'>From a command shell, change to the installation directory and run ActiveMQ as a foregroud process:
</span><span class='line'>cd [activemq_install_dir]/bin
</span><span class='line'>./activemq console
</span><span class='line'>From a command shell, change to the installation directory and run ActiveMQ as a daemon process:
</span><span class='line'>cd [activemq_install_dir]/bin
</span><span class='line'>./activemq start
</span><span class='line'>
</span><span class='line'># 确认
</span><span class='line'>URL: http://127.0.0.1:8161/admin/
</span><span class='line'>Login: admin
</span><span class='line'>Passwort: admin
</span><span class='line'># 起了好多端口，随便试一个
</span><span class='line'>netstat -nl|grep 61616
</span><span class='line'>netstat -anp|grep PID
</span><span class='line'>
</span><span class='line'># 数据/日志目录
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# ll data/
</span><span class='line'>total 16
</span><span class='line'>-rw-r--r-- 1 root users 4276 Apr 27 21:36 activemq.log
</span><span class='line'>-rw-r--r-- 1 root root     5 Apr 27 21:36 activemq.pid
</span><span class='line'>-rw-r--r-- 1 root root     0 Apr 27 21:36 audit.log
</span><span class='line'>drwxr-xr-x 2 root root  4096 Apr 27 21:36 kahadb</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/mcollective-activemq.png" alt="" /></p>

<p>查看连接密码：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 conf]# cat credentials.properties
</span><span class='line'>...
</span><span class='line'>activemq.username=system
</span><span class='line'>activemq.password=manager
</span><span class='line'>guest.password=password[root@hadoop-master2 conf]# 
</span></code></pre></td></tr></table></div></figure>


<h1>简单配置(unencrypted Stomp) <a name="cli-simple-usage"></a></h1>

<p>安装puppet4.4后，mcollective已经安装好了！直接修改配置连接到activemq即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 puppetlabs]# chkconfig --list | grep mco
</span><span class='line'>mcollective     0:off   1:off   2:off   3:off   4:off   5:off   6:off
</span><span class='line'>
</span><span class='line'># puppetserver作为mcollective-client
</span><span class='line'>[root@hadoop-master2 mcollective]# cat client.cfg                    
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61613
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>No responses received
</span><span class='line'>
</span><span class='line'># puppet agent作为mcollective-server
</span><span class='line'>-bash-4.1# cat server.cfg 
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61613
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>-bash-4.1# service mcollective start
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>-bash-4.1# service mcollective status
</span><span class='line'>mcollectived (pid  202) is running...
</span><span class='line'>
</span><span class='line'># 其他两台agent机器一样的配置操作
</span><span class='line'>
</span><span class='line'># 1. mcollective-client(puppetserver) 测试
</span><span class='line'>[root@hadoop-master2 ~]# mco find
</span><span class='line'>hadoop-master1
</span><span class='line'>hadoop-slaver2
</span><span class='line'>hadoop-slaver1
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping
</span><span class='line'>hadoop-master1                           time=148.29 ms
</span><span class='line'>hadoop-slaver2                           time=187.99 ms
</span><span class='line'>hadoop-slaver1                           time=190.21 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 190.21 min: 148.29 avg: 175.50 
</span><span class='line'>
</span><span class='line'># 2. 先查看/扫描节点状态。（如果配置了facts后，会输出一长串的Facts！）
</span><span class='line'>[root@hadoop-master2 ssl]# mco inventory hadoop-master1
</span><span class='line'>Inventory for hadoop-master1:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-04-29 00:21:31 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 155
</span><span class='line'>               Total Messages: 13
</span><span class='line'>      Messages Passed Filters: 3
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 2
</span><span class='line'>         Total Processor Time: 2.32 seconds
</span><span class='line'>                  System Time: 0.3 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       rpcutil                        
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat                                          
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>
</span><span class='line'># 3. 获取节点facts，需要配合puppet一起来使用
</span><span class='line'># puppetserver节点 配置更新agent facts.yaml信息
</span><span class='line'>[root@hadoop-master2 manifests]# cat site.pp 
</span><span class='line'>file{'/etc/puppetlabs/mcollective/facts.yaml':
</span><span class='line'>  owner    =&gt; root,
</span><span class='line'>  group    =&gt; root,
</span><span class='line'>  mode     =&gt; '400',
</span><span class='line'>  loglevel =&gt; debug, # reduce noise in Puppet reports
</span><span class='line'>  content  =&gt; inline_template("&lt;%= scope.to_hash.reject { |k,v| k.to_s =~ /(uptime_seconds|timestamp|free)/ }.to_yaml %&gt;"), # exclude rapidly changing facts
</span><span class='line'>}
</span><span class='line'># 读取facts
</span><span class='line'>[root@hadoop-master2 manifests]# mco facts hostname
</span><span class='line'>Report for fact: hostname
</span><span class='line'>
</span><span class='line'>        hadoop-master1                           found 1 times
</span><span class='line'>        hadoop-slaver1                           found 1 times
</span><span class='line'>        hadoop-slaver2                           found 1 times
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 579.93 ms
</span></code></pre></td></tr></table></div></figure>


<p>自带的插件功能比较少，要真正把 mcollective 用起来需要安装插件：puppet, service, package等等。这篇主要记录安装过程，<a href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/">插件安装以及使用</a>后面具体实践了再写。</p>

<p>我觉得内网生产环境安装，到这一步已经差不多了！下面的安全配置就当深入学习吧。</p>

<h1>Stomp with TLS 配置</h1>

<ul>
<li><a href="https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html">https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html">https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html</a></li>
</ul>


<p><strong>Anonymous TLS</strong> 步骤简单一点，这里就不列出来了，自己去看官网的文档: <a href="https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html#anonymous-tls">Anonymous TLS</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># CA-Verified TLS
</span><span class='line'>
</span><span class='line'># 1 手动配置activemq
</span><span class='line'>
</span><span class='line'># 1.1 可以直接用puppet的cert/private-keys，我这里新生成一个activemq的证书
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet master --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'># 一个不冲突的名称即可，不需要是hostname/FQDN
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet cert generate activemq
</span><span class='line'>Notice: activemq has a waiting certificate request
</span><span class='line'>Notice: Signed certificate request for activemq
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest activemq at '/etc/puppetlabs/puppet/ssl/ca/requests/activemq.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest activemq at '/etc/puppetlabs/puppet/ssl/certificate_requests/activemq.pem'
</span><span class='line'>[root@hadoop-master2 puppetlabs]# tree /etc/puppetlabs/puppet/ssl/
</span><span class='line'>/etc/puppetlabs/puppet/ssl/
</span><span class='line'>...
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── activemq.pem
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── hadoop-master2.example.com.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   ├── activemq.pem
</span><span class='line'>│   └── hadoop-master2.example.com.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    ├── activemq.pem
</span><span class='line'>    └── hadoop-master2.example.com.pem
</span><span class='line'>
</span><span class='line'>9 directories, 22 files
</span><span class='line'>
</span><span class='line'># certs/activemq.pem, certs/ca.pem, private_keys/activemq.pem 就是我们需要的。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.2 创建Truststore
</span><span class='line'>[root@hadoop-master2 puppetlabs]# which keytool
</span><span class='line'>/opt/jdk1.7.0_60/bin/keytool
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cd /etc/puppetlabs/puppet/ssl            
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -import -alias "CU CA" -file certs/ca.pem -keystore truststore.jks
</span><span class='line'>Enter keystore password:  
</span><span class='line'>Re-enter new password: 
</span><span class='line'>Owner: CN=Puppet CA: hadoop-master2.example.com
</span><span class='line'>Issuer: CN=Puppet CA: hadoop-master2.example.com
</span><span class='line'>...
</span><span class='line'>Trust this certificate? [no]:  y
</span><span class='line'>Certificate was added to keystore
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 32
</span><span class='line'>drwxr-xr-x 5 puppet puppet 4096 Apr 23 00:01 ca
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 certificate_requests
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 certs
</span><span class='line'>-rw-r--r-- 1 puppet puppet  979 Apr 28 10:33 crl.pem
</span><span class='line'>drwxr-x--- 2 puppet puppet 4096 Apr 22 23:51 private
</span><span class='line'>drwxr-x--- 2 puppet puppet 4096 Apr 28 19:53 private_keys
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 public_keys
</span><span class='line'>-rw-r--r-- 1 root   root   1496 Apr 28 20:01 truststore.jks
</span><span class='line'># 验证下指纹fingerprints
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -list -keystore truststore.jks 
</span><span class='line'>Enter keystore password:  
</span><span class='line'>
</span><span class='line'>Keystore type: JKS
</span><span class='line'>Keystore provider: SUN
</span><span class='line'>
</span><span class='line'>Your keystore contains 1 entry
</span><span class='line'>
</span><span class='line'>cu ca, Apr 28, 2016, trustedCertEntry, 
</span><span class='line'>Certificate fingerprint (SHA1): 40:2C:45:37:6B:C7:9C:92:E7:4D:1E:4F:2B:C4:17:F4:A3:5F:EB:56
</span><span class='line'>[root@hadoop-master2 ssl]# openssl x509 -in certs/ca.pem -fingerprint -sha1
</span><span class='line'>SHA1 Fingerprint=40:2C:45:37:6B:C7:9C:92:E7:4D:1E:4F:2B:C4:17:F4:A3:5F:EB:56
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.3 创建Keystore
</span><span class='line'>[root@hadoop-master2 ssl]# cat private_keys/activemq.pem certs/activemq.pem &gt;activemq.pem
</span><span class='line'># 所有密码都需一致！！ All of these passwords must be the same.
</span><span class='line'>[root@hadoop-master2 ssl]# openssl pkcs12 -export -in activemq.pem -out activemq.p12 -name activemq      
</span><span class='line'>Enter Export Password:
</span><span class='line'>Verifying - Enter Export Password:
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -importkeystore -destkeystore keystore.jks -srckeystore activemq.p12 \
</span><span class='line'>&gt; -srcstoretype PKCS12 -alias activemq
</span><span class='line'>Enter destination keystore password:  XXX
</span><span class='line'>Re-enter new password: XXX
</span><span class='line'>Enter source keystore password:  XXX
</span><span class='line'>[root@hadoop-master2 ssl]# ll -t
</span><span class='line'>total 52
</span><span class='line'>-rw-r--r-- 1 root   root   3918 Apr 28 20:12 keystore.jks
</span><span class='line'>-rw-r--r-- 1 root   root   4230 Apr 28 20:08 activemq.p12
</span><span class='line'>-rw-r--r-- 1 root   root   5203 Apr 28 20:07 activemq.pem
</span><span class='line'>-rw-r--r-- 1 root   root   1496 Apr 28 20:01 truststore.jks
</span><span class='line'>...
</span><span class='line'># 验证指纹
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -list -keystore keystore.jks 
</span><span class='line'>Enter keystore password:  
</span><span class='line'>
</span><span class='line'>Keystore type: JKS
</span><span class='line'>Keystore provider: SUN
</span><span class='line'>
</span><span class='line'>Your keystore contains 1 entry
</span><span class='line'>
</span><span class='line'>activemq, Apr 28, 2016, PrivateKeyEntry, 
</span><span class='line'>Certificate fingerprint (SHA1): 4F:DF:DE:64:13:36:0E:74:8B:7F:D3:61:78:29:C4:AA:4F:A4:ED:D8
</span><span class='line'>[root@hadoop-master2 ssl]# openssl x509 -in certs/activemq.pem -fingerprint -sha1
</span><span class='line'>SHA1 Fingerprint=4F:DF:DE:64:13:36:0E:74:8B:7F:D3:61:78:29:C4:AA:4F:A4:ED:D8
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.4 配置activemq
</span><span class='line'># http://activemq.apache.org/how-do-i-use-ssl.html
</span><span class='line'># https://docs.puppet.com/mcollective/deploy/middleware/activemq.html#tls-credentials
</span><span class='line'># https://docs.puppet.com/mcollective/deploy/middleware/activemq.html#stomp
</span><span class='line'>[root@hadoop-master2 ssl]# mv keystore.jks truststore.jks /opt/puppetlabs/apache-activemq-5.13.2/conf
</span><span class='line'>[root@hadoop-master2 ssl]# cd /opt/puppetlabs/apache-activemq-5.13.2/conf/
</span><span class='line'># 填上面步骤设置的密码
</span><span class='line'>[root@hadoop-master2 conf]# vi activemq.xml 
</span><span class='line'>...
</span><span class='line'>&lt;sslContext&gt;
</span><span class='line'>  &lt;sslContext keyStore="keystore.jks" keyStorePassword="XXXX"
</span><span class='line'>              trustStrore="truststore.jks" trustStorePassword="XXXX" /&gt;
</span><span class='line'>&lt;/sslContext&gt;
</span><span class='line'>
</span><span class='line'>&lt;transportConnectors&gt;
</span><span class='line'>  &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt;
</span><span class='line'>  &lt;transportConnector name="stomp+nio+ssl" uri="stomp+nio+ssl://0.0.0.0:61614?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600&amp;needClientAuth=true&amp;transport.enabledProtocols=TLSv1,TLSv1.1,TLSv1.2"/&gt;
</span><span class='line'>&lt;/transportConnectors&gt;
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# chmod 600 conf/activemq.xml 
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# bin/activemq stop
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# bin/activemq start
</span><span class='line'># 日志查看
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# less data/activemq.log 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 2 puppetserver(mcollective client)
</span><span class='line'># https://docs.puppet.com/mcollective/configure/client.html
</span><span class='line'>[root@hadoop-master2 ~]# cd /etc/puppetlabs/mcollective/
</span><span class='line'>[root@hadoop-master2 mcollective]# cat client.cfg
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61614
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>plugin.activemq.pool.1.ssl = true
</span><span class='line'>plugin.activemq.pool.1.ssl.ca = /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.key = /etc/puppetlabs/puppet/ssl/private_keys/hadoop-master2.example.com.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.cert = /etc/puppetlabs/puppet/ssl/certs/hadoop-master2.example.com.pem
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping -v
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>No responses received
</span><span class='line'>
</span><span class='line'># 3 puppet agents(mcollective servers)
</span><span class='line'># https://docs.puppet.com/mcollective/configure/server.html
</span><span class='line'>-bash-4.1# puppet agent --configprint confdir
</span><span class='line'>/etc/puppetlabs/puppet
</span><span class='line'>-bash-4.1# puppet agent --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>-bash-4.1# puppet agent --configprint hostprivkey
</span><span class='line'>/etc/puppetlabs/puppet/ssl/private_keys/hadoop-master1.example.com.pem
</span><span class='line'>-bash-4.1# puppet agent --configprint hostcert
</span><span class='line'>/etc/puppetlabs/puppet/ssl/certs/hadoop-master1.example.com.pem
</span><span class='line'>-bash-4.1# puppet agent --configprint localcacert
</span><span class='line'>/etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>
</span><span class='line'>-bash-4.1# cd /etc/puppetlabs/mcollective/
</span><span class='line'>-bash-4.1# cat server.cfg 
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61614
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>plugin.activemq.pool.1.ssl = true
</span><span class='line'>plugin.activemq.pool.1.ssl.ca = /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.key = /etc/puppetlabs/puppet/ssl/private_keys/hadoop-master1.example.com.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.cert = /etc/puppetlabs/puppet/ssl/certs/hadoop-master1.example.com.pem
</span><span class='line'>...
</span><span class='line'>-bash-4.1# service mcollective restart
</span><span class='line'>Shutting down mcollective: 
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>
</span><span class='line'># 其他两台机器一样的操作
</span><span class='line'>
</span><span class='line'># 测试
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping -v
</span><span class='line'>hadoop-master1                           time=41.99 ms
</span><span class='line'>hadoop-slaver2                           time=84.87 ms
</span><span class='line'>hadoop-slaver1                           time=85.46 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 85.46 min: 41.99 avg: 70.77 
</span></code></pre></td></tr></table></div></figure>


<p>更多activemq的设置查看官方文档： <a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq.html">ActiveMQ Config Reference for MCollective Users</a> <a href="https://raw.github.com/puppetlabs/marionette-collective/master/ext/activemq/examples/single-broker/activemq.xml">example activemq.xml</a></p>

<h1>SSL Security plugin</h1>

<p>Stomp with TLS (安全传输层协议)用于加密数据。而 security plugin 主要功能有：</p>

<ul>
<li>mcollective server要授权才会执行 client 发送的请求。</li>
<li>create a token that uniquely identify the client - based on the filename of the public key。</li>
<li>在请求中添加创建时间和TTL保证数据的完整性(不被拦截、篡改以及重复)。</li>
</ul>


<p>参考：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/configure/client.html#security-plugin-settings">https://docs.puppet.com/mcollective/configure/client.html#security-plugin-settings</a></li>
<li><a href="https://docs.puppet.com/mcollective/security.html">https://docs.puppet.com/mcollective/security.html</a></li>
<li><a href="https://docs.puppet.com/mcollective/reference/plugins/security_ssl.html">https://docs.puppet.com/mcollective/reference/plugins/security_ssl.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 1 生成server秘钥(公钥、私钥)
</span><span class='line'>[root@hadoop-master2 mcollective-security]# openssl genrsa -out server-private.pem 1024
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 mcollective-security]# openssl rsa -in server-private.pem -out server-public.pem -outform PEM -pubout  
</span><span class='line'>writing RSA key
</span><span class='line'>[root@hadoop-master2 mcollective-security]# ll
</span><span class='line'>total 12
</span><span class='line'>-rw-r--r-- 1 root root 7915 Apr 29 00:06 server-private.pem
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:07 server-public.pem
</span><span class='line'>
</span><span class='line'># 把 private/public 复制到所有的mcollective-servers节点
</span><span class='line'># 把 public 复制到mcollective-clients节点
</span><span class='line'>[root@hadoop-master2 mcollective-security]# ssh 172.17.0.2 mkdir -p /etc/puppetlabs/mcollective/ssl/clients
</span><span class='line'>[root@hadoop-master2 mcollective-security]# scp * 172.17.0.2:/etc/puppetlabs/mcollective/ssl/
</span><span class='line'>server-private.pem   100% 7915     7.7KB/s   00:00    
</span><span class='line'>server-public.pem    100% 1836     1.8KB/s   00:00    
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective-security]# mkdir -p /etc/puppetlabs/mcollective/ssl
</span><span class='line'>[root@hadoop-master2 mcollective-security]# cp server-public.pem /etc/puppetlabs/mcollective/ssl/
</span><span class='line'>
</span><span class='line'># 2 配置mcollective-servers。节点间配置不能同步，TLS配置的证书名称是不一样的！！
</span><span class='line'>-bash-4.1# vi /etc/puppetlabs/mcollective/server.cfg 
</span><span class='line'>...
</span><span class='line'># Plugins
</span><span class='line'>#securityprovider = psk
</span><span class='line'>#plugin.psk = unset
</span><span class='line'>
</span><span class='line'>securityprovider = ssl
</span><span class='line'>plugin.ssl_server_private = /etc/puppetlabs/mcollective/ssl/server-private.pem
</span><span class='line'>plugin.ssl_server_public = /etc/puppetlabs/mcollective/ssl/server-public.pem
</span><span class='line'>plugin.ssl_client_cert_dir = /etc/puppetlabs/mcollective/ssl/clients/
</span><span class='line'>plugin.ssl.enfore_ttl = 0
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>-bash-4.1# service mcollective restart
</span><span class='line'>Shutting down mcollective:                                 [  OK  ]
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'># 可以通过 /var/log/puppetlabs/mcollective.log 查看详细日志
</span><span class='line'>
</span><span class='line'># 配置一个节点后，mco ping已经不再显示hadoop-master1了！！
</span><span class='line'>
</span><span class='line'># 3 生成client秘钥
</span><span class='line'>[root@hadoop-master2 mcollective-security]# cd /etc/puppetlabs/mcollective/ssl
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x 2 root root 4096 Apr 29 00:15 clients
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:15 server-public.pem
</span><span class='line'>[root@hadoop-master2 ssl]# openssl genrsa -out winse-private.pem 1024    
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 ssl]# openssl rsa -in winse-private.pem -out winse-public.pem -outform PEM -pubout
</span><span class='line'>writing RSA key
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 16
</span><span class='line'>drwxr-xr-x 2 root root 4096 Apr 29 00:15 clients
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:15 server-public.pem
</span><span class='line'>-rw-r--r-- 1 root root  887 Apr 29 00:26 winse-private.pem
</span><span class='line'>-rw-r--r-- 1 root root  272 Apr 29 00:26 winse-public.pem
</span><span class='line'>
</span><span class='line'># 把client用户的公钥拷贝到所有mcollective-servers的ssl/clients目录下
</span><span class='line'>[root@hadoop-master2 ssl]# scp winse-public.pem 172.17.0.2:/etc/puppetlabs/mcollective/ssl/clients
</span><span class='line'>winse-public.pem 100%  272     0.3KB/s   00:00    
</span><span class='line'>
</span><span class='line'># 4 配置clients
</span><span class='line'>[root@hadoop-master2 ~]# vi /etc/puppetlabs/mcollective/client.cfg 
</span><span class='line'>...
</span><span class='line'># Plugins
</span><span class='line'>#securityprovider = psk
</span><span class='line'>#plugin.psk = unset
</span><span class='line'>securityprovider = ssl
</span><span class='line'>plugin.ssl_server_public = /etc/puppetlabs/mcollective/ssl/server-public.pem
</span><span class='line'>plugin.ssl_client_private = /etc/puppetlabs/mcollective/ssl/winse-private.pem
</span><span class='line'>plugin.ssl_client_public = /etc/puppetlabs/mcollective/ssl/winse-public.pem
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'># mcollective-server不需要重启！客户端连接测试
</span><span class='line'>[root@hadoop-master2 ssl]# mco ping -v
</span><span class='line'>hadoop-master1                           time=561.29 ms
</span><span class='line'>hadoop-slaver2                           time=601.91 ms
</span><span class='line'>hadoop-slaver1                           time=608.31 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 608.31 min: 561.29 avg: 590.50 
</span></code></pre></td></tr></table></div></figure>


<p>理解了功能后，再按条理配置其实感觉就不是那么难了。遇到问题先查看日志！！</p>

<h1>最佳实践</h1>

<p>官网推荐使用 站点管理工具 统一来安装管理，如puppet。下面使用puppet来配置mcollective：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/deploy/install.html#example">https://docs.puppet.com/mcollective/deploy/install.html#example</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html#creating-keystores-with-puppet">https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html#creating-keystores-with-puppet</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/standard.html#write-the-server-config-file">https://docs.puppet.com/mcollective/deploy/standard.html#write-the-server-config-file</a></li>
</ul>


<p>TODO</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[整理] Hadoop入门]]></title>
    <link href="http://winseliu.com/blog/2016/04/23/hadoop-guide-catalog/"/>
    <updated>2016-04-23T15:45:34+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/23/hadoop-guide-catalog</id>
    <content type="html"><![CDATA[<h2>1. 环境准备</h2>

<p>工欲善事其必先利其器。不要吝啬硬件上投入，找一个适合自己的环境！</p>

<ul>
<li>Windows

<ul>
<li><a href="http://winseliu.com/blog/2014/02/23/quickly-open-program-in-windows/">快速打开程序</a></li>
<li>Cygwin：Windows本地编译需要，执行命令比 cmd 更方便</li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2011/02/28/win7-install-fedora-linux/">Windows + Linux双系统</a></li>
<li>Linux

<ul>
<li><a href="http://winseliu.com/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a></li>
<li><a href="http://winseliu.com/blog/2015/09/13/review-linux-101-hacks/">【linux 101 Hacks】读后感</a>

<ul>
<li><a href="http://winseliu.com/images/blogs/linux-101-hacks-review-securecrt-config.png">Socket5代理</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/03/11/install-and-config-openvpn/">OpenVPN</a></li>
<li>docker

<ul>
<li><a href="http://winseliu.com/blog/2014/09/27/docker-start-guide-on-centos/">Docker入门</a></li>
<li><a href="http://winseliu.com/blog/2014/09/30/docker-ssh-on-centos/">配置ssh</a></li>
<li><a href="http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster/">Dnsmasq</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>2. 安装部署hadoop/spark</h2>

<h4>编译安装</h4>

<ul>
<li>Hadoop安装与升级:

<ul>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/">Docker中安装</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/">2.2升级到2.6</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/">HA配置</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/">HA升级</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6/">Centos6 Build hadoop2.6</a></li>
<li><a href="http://winseliu.com/blog/2015/03/09/windows-build-hadoop-2-dot-6/">Windows Build hadoop2.6</a></li>
<li><a href="http://winseliu.com/blog/2014/10/16/spark-build-and-configuration/">各版本Spark编译/搭建环境</a></li>
</ul>


<h4>功能优化</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/01/hadoop2-mapreduce-compress/">Hadoop2 Mapreduce输入输出压缩</a></li>
<li><a href="http://winseliu.com/blog/2014/07/29/hadoop2-use-shortcircuit-local-reading/">Hadoop2 ShortCircuit Local Reading</a></li>
<li><a href="http://winseliu.com/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>

<ul>
<li><a href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/05/05/hdfs-heterogeneous-storage.markdown">HDFS RamDisk内存缓冲</a></li>
</ul>


<h4>维护</h4>

<ul>
<li><a href="http://winseliu.com/blog/2013/02/22/hadoop-cluster-increases-nodes/">Hadoop集群增加节点</a></li>
<li><a href="http://winseliu.com/blog/2014/07/29/safely-remove-datanode/">安全的关闭datanode</a></li>
<li><a href="http://winseliu.com/blog/2015/03/25/deploy-separated-yarn-on-exists-hdfs-cluster/">已有HDFS上部署yarn</a></li>
<li><a href="http://winseliu.com/blog/2015/06/10/hadoop-deploy-spark-diff-version-yarn-and-hdfs/">Hadoop不同版本yarn和hdfs混搭，spark-yarn环境配置</a></li>
</ul>


<h4>旧版本安装</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a></li>
<li><a href="http://winseliu.com/blog/2013/03/24/pseudo-distributed-hadoop-in-windows/"><del>Windows配置hadoop伪分布式环境(续)</del></a> 不再推荐cygwin下部署Hadoop。</li>
<li><a href="http://winseliu.com/blog/2013/03/02/quickly-build-a-second-hadoop-cluster/">快速搭建第二个hadoop分布式集群环境</a></li>
<li><a href="http://winseliu.com/blog/2013/03/27/run-on-hadoop-on-ant/"><del>Ant实现hadoop插件Run-on-Hadoop</del></a></li>
</ul>


<h2>3. 进阶</h2>

<h4>配置深入理解</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/08/02/hadoop-datanode-config-should-equals/">Hadoop的datanode数据节点机器配置</a></li>
<li><a href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/">Hadoop内存环境变量和参数</a></li>
<li><a href="http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate/">Spark-on-yarn内存分配</a></li>
<li><a href="http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn/">SparkSQL-on-YARN的Executors池(动态)配置</a></li>
</ul>


<h4>问题定位</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/17/windows-hadoop2-test-your-mapreduce-feature/">在windows开发测试mapreduce几种方式</a></li>
<li><a href="http://winseliu.com/blog/2014/04/22/remote-debug-hadoop2/">远程调试hadoop2以及错误处理方法</a></li>
<li><a href="http://winseliu.com/blog/2014/08/25/step-by-step-found-java-oom-error/">逐步定位Java程序OOM的异常</a></li>
</ul>


<h4>读码</h4>

<ul>
<li>Hadoop2 Balancer磁盘空间平衡

<ul>
<li><a href="http://winseliu.com/blog/2014/08/06/read-hadoop-balancer-source-part1/">上</a></li>
<li><a href="http://winseliu.com/blog/2014/09/05/read-hadoop-balancer-source-part2/">中</a></li>
<li><a href="http://winseliu.com/blog/2014/09/05/read-hadoop-balancer-source-part3/">下</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2015/03/13/hadoop-distcp/">Hadoop Distcp</a></li>
</ul>


<h4>其他</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/12/scala-wordcount-on-hadoop/">Scala Wordcount on Hadoop2</a></li>
<li><a href="http://winseliu.com/blog/2014/12/07/hadoop-mr-rest-api/">MR Rest接口</a></li>
</ul>


<h2>4. Hadoop平台</h2>

<ul>
<li>zookeeper</li>
<li>hive

<ul>
<li><a href="http://winseliu.com/blog/2014/06/21/upgrade-hive/">Upgrade Hive: 0.12.0 to 0.13.1</a></li>
<li>tez:

<ul>
<li><a href="http://winseliu.com/blog/2014/06/18/hadoop-tez-firststep/">Tez编译及使用</a></li>
<li><a href="http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run/">配置TEZ-UI</a></li>
</ul>
</li>
<li>hive on spark

<ul>
<li><a href="http://winseliu.com/blog/2016/03/28/hive-on-spark/">Hive on Spark</a></li>
<li><a href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a></li>
<li><a href="http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive/">Limit on Sparksql and Hive</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/04/08/dbcp-parameters/">DBCP参数在Hive JDBC上的实践</a></li>
<li><a href="http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0/">Hiveserver2 Ui and Upgrade hive2.0.0</a></li>
</ul>
</li>
<li>kafka

<ul>
<li><a href="http://winseliu.com/blog/2015/01/08/kafka-guide/">Kafka快速入门</a></li>
</ul>
</li>
<li>alluxio(tachyon)

<ul>
<li><a href="http://winseliu.com/blog/2015/04/15/tachyon-quickstart/">Tachyon入门指南</a></li>
<li><a href="http://winseliu.com/blog/2015/04/18/tachyon-deep-source/">Tachyon剖析</a></li>
<li><a href="http://winseliu.com/blog/2016/04/15/alluxio-quickstart2/">Alluxio入门大全2</a></li>
</ul>
</li>
</ul>


<h2>5. 监控与自动化部署</h2>

<h4>监控</h4>

<ul>
<li><a href="http://winseliu.com/blog/2013/02/26/linux-top-command-mannual/">top</a></li>
<li>nagios

<ul>
<li><a href="http://winseliu.com/blog/2015/09/25/nagios-start-guide/">Nagios监控主机</a></li>
</ul>
</li>
<li><del>cacti</del>    Ganglia更简单

<ul>
<li><a href="http://winseliu.com/blog/2015/09/22/cacti-start-guide/">Cacti监控主机</a></li>
<li><a href="http://winseliu.com/blog/2015/10/13/cacti-batch-adding-configurations/">Cacti批量添加配置</a></li>
</ul>
</li>
<li>ganglia

<ul>
<li><a href="http://winseliu.com/blog/2014/07/18/install-ganglia-on-redhat/"><del>Install Ganglia on Redhat5+</del></a> 手动安装依赖太麻烦了！</li>
<li><a href="http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a></li>
<li><a href="http://winseliu.com/blog/2016/02/01/ganglia-python-extension/">Ganglia扩展-Python</a></li>
<li><a href="http://winseliu.com/blog/2016/02/25/ganglia-web-ui-views/">Ganglia页自定义视图</a></li>
</ul>
</li>
</ul>


<h4>自动化</h4>

<ul>
<li>git:

<ul>
<li><a href="http://winseliu.com/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a></li>
<li><a href="http://winseliu.com/blog/2014/02/19/maven-package-dependent-git-projects/">打包依赖的git项目</a></li>
<li><a href="http://winseliu.com/blog/2013/05/27/handle-git-conflict/">处理git冲突</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2014/09/07/expect-automate-and-batch-config-ssh/">expect-批量实现SSH无密钥登录</a></li>
<li>puppet

<ul>
<li><a href="http://winseliu.com/blog/2016/04/08/puppet-install/">puppet4.4.1入门安装</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn/">puppet入门之域名证书</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/">puppetdb安装配置</a>

<ul>
<li><a href="http://winseliu.com/blog/2015/12/13/postgresql-start-guide/">postgresql入门</a></li>
</ul>
</li>
<li>puppet-ui

<ul>
<li><a href="http://winseliu.com/blog/2016/05/05/puppetboard-install/">puppetboard安装</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppetexplorer-setting/">puppetexplorer设置</a></li>
<li>foreman</li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/">RPM打包</a></li>
<li>puppet基本使用以及配置集群</li>
<li>mcollective

<ul>
<li><a href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/">安装配置</a></li>
<li><a href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/">插件安装</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/05/03/hiera-and-facts/">Hiera</a></li>
</ul>
</li>
</ul>


<p>&hellip;</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet Basic]]></title>
    <link href="http://winseliu.com/blog/2016/04/22/puppet-basic/"/>
    <updated>2016-04-22T15:33:59+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/22/puppet-basic</id>
    <content type="html"><![CDATA[<h1>简单使用</h1>

<h2>安装</h2>

<h2>quick</h2>

<ul>
<li>Puppet的一些概念 <a href="https://docs.puppet.com/puppet/latest/reference/lang_summary.html">https://docs.puppet.com/puppet/latest/reference/lang_summary.html</a></li>
<li>快速入门 <a href="https://docs.puppet.com/puppet/4.4/reference/quick_start.html">https://docs.puppet.com/puppet/4.4/reference/quick_start.html</a></li>
</ul>


<h2>simple example</h2>

<p><a href="https://docs.puppet.com/puppet/4.4/reference/quick_start_user_group.html">https://docs.puppet.com/puppet/4.4/reference/quick_start_user_group.html</a></p>

<pre><code>puppet apply -e "user { 'jargyle': ensure =&gt; present, }"
puppet apply -e "group { 'web': ensure =&gt; present, }"

puppet resource -e group web
puppet resource -e user jargyle

cd /etc/puppetlabs/code/environments/production/manifests

[root@cu2 manifests]# vi site.pp
group { 'web':
  ensure =&gt; present, # absent, present
}

user { 'jargyle':
  ensure =&gt; present,
  home =&gt; '/home/jargyle',
  shell =&gt; '/bin/bash',
  password_max_age =&gt; '99999',
  password_min_age =&gt; '0',
  groups =&gt; web,
}

puppet parser validate site.pp
</code></pre>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/type.html">https://docs.puppet.com/puppet/4.4/reference/type.html</a></li>
</ul>


<h2>module helloworld</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/quick_start_helloworld.html">https://docs.puppet.com/puppet/4.4/reference/quick_start_helloworld.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/quick_start_adding_classes_nix.html">https://docs.puppet.com/puppet/4.4/reference/quick_start_adding_classes_nix.html</a></li>
<li><p><a href="https://docs.puppet.com/puppet/4.4/reference/modules_metadata.html">https://docs.puppet.com/puppet/4.4/reference/modules_metadata.html</a></p>

<p>  [root@cu2 modules]# mkdir -p  helloworld/manifests
  [root@cu2 manifests]# vi init.pp
  class helloworld {
    notify { &lsquo;Hello World&rsquo;: }
  }
  [root@cu2 manifests]# vi motd.pp
  class helloworld::motd {</p>

<pre><code>file { '/etc/motd':
  owner =&gt; 'root',
  group =&gt; 'root',
  mode =&gt; '0644',
  content =&gt; "Hello World!\n",
}
</code></pre>

<p>  }</p>

<p>  [root@cu2 manifests]# vi ../../../manifests/site.pp
  node default {
    class { &lsquo;helloworld&rsquo;: }
    class { &lsquo;helloworld::motd&rsquo;: }
  }
  [root@cu2 manifests]# puppet parser validate ../../../manifests/site.pp</p>

<p>  [root@cu2 manifests]# cat site.pp
node default {</p>

<p>file { &lsquo;/etc/cron.hourly&rsquo;:
  ensure => directory,
}</p>

<p>package { [&lsquo;ntp&rsquo;, &lsquo;ntpdate&rsquo;]:
  ensure => installed,
}</p></li>
</ul>


<p>/<em>
if $fqdn != &lsquo;cu2.eshore.cn&rsquo; {
  class { &lsquo;ntp&rsquo;:
    runmode => &lsquo;cron&rsquo;,
    cron_command => &lsquo;ntpdate cu2&rsquo;,
    require => [ Package[&lsquo;ntp&rsquo;, &lsquo;ntpdate&rsquo;], File[&lsquo;/etc/cron.hourly&rsquo;] ],
  }
}
</em>/</p>

<p>/<em> 多网卡的时刻需要注意
class { &lsquo;hosts&rsquo;:
  dynamic_mode => true,
  dynamic_ip   => $::ipaddress_bond0
}
</em>/
  if $fqdn =~ /.*.ds.ctyun/  {
    class { &lsquo;hosts&rsquo;:
      dynamic_mode => true,
    }
  }</p>

<p>  cron {&lsquo;run-puppet&rsquo;:
    command => &ldquo;source /etc/profile; puppet agent &ndash;test >/tmp/puppet-cron.log 2>&amp;1&rdquo;,
    minute => inline_template(&lsquo;&lt;%= @hostname.hash.abs % 60 %>&rsquo;),
  }</p>

<p>  file{&lsquo;/etc/puppetlabs/mcollective/facts.yaml&rsquo;:
  owner    => root,
  group    => root,
  mode     => &lsquo;400&rsquo;,
  loglevel => debug, # reduce noise in Puppet reports
  content  => inline_template(&ldquo;&lt;%= scope.to_hash.reject { |k,v| k.to_s =~ /(uptime_seconds|timestamp|free)/ }.to_yaml %>&rdquo;), # exclude rapidly changing facts
  }
}</p>

<h2>modules install</h2>

<p><a href="https://docs.puppet.com/puppet/latest/reference/modules_installing.html">https://docs.puppet.com/puppet/latest/reference/modules_installing.html</a></p>

<blockquote><p>The full name of a Forge module is formatted as username-modulename.</p></blockquote>

<p><a href="https://docs.puppet.com/puppet/latest/reference/modules_fundamentals.html#writing-modules">https://docs.puppet.com/puppet/latest/reference/modules_fundamentals.html#writing-modules</a></p>

<pre><code>[root@cu2 code]# cd environments/production/modules/
[root@cu2 modules]# puppet module generate --skip-interview winse-hello

[root@cu2 modules]# puppet module install puppetlabs-stdlib
Notice: Preparing to install into /etc/puppetlabs/code/environments/production/modules ...
Notice: Downloading from https://forgeapi.puppetlabs.com ...
Notice: Installing -- do not interrupt ...
/etc/puppetlabs/code/environments/production/modules
└── puppetlabs-stdlib (v4.11.0)
[root@cu2 modules]# puppet module list
/etc/puppetlabs/code/environments/production/modules
├── puppetlabs-stdlib (v4.11.0)
└── winse-hello (v0.1.0)
/etc/puppetlabs/code/modules (no modules installed)
/opt/puppetlabs/puppet/modules (no modules installed)
</code></pre>

<p>sudo puppet module install ~/puppetlabs-apache-0.10.0.tar.gz &ndash;ignore-dependencies</p>

<p>Listing Installed Modules
Use the module tool’s list action to see which modules you have installed (and which directory they’re installed in).</p>

<p>Use the &ndash;tree option to view the modules arranged by dependency instead of by location on disk.</p>

<ul>
<li><p>hosts</p></li>
<li><p><a href="https://github.com/example42/puppi/releases">https://github.com/example42/puppi/releases</a></p></li>
<li><a href="https://github.com/example42/puppet-hosts">https://github.com/example42/puppet-hosts</a></li>
</ul>


<p>puppet4 插件同步选项默认是开启的 pluginsync=true，不需要额外的操作。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://github.com/example42/puppet-nrpe/issues/1
</span><span class='line'>[root@cu2 modules]# tar zxvf puppet-hosts-2.0.18.tar.gz  
</span><span class='line'>[root@cu2 modules]# tar zxvf puppi-2.1.12.tar.gz 
</span><span class='line'>[root@cu2 modules]# ll
</span><span class='line'>total 16
</span><span class='line'>drwxr-xr-x 3 root root 4096 Apr 22 14:37 helloworld
</span><span class='line'>drwxrwxr-x 6 root root 4096 Aug 10  2015 hosts
</span><span class='line'>drwxrwxr-x 7 root root 4096 Aug  8  2015 puppi
</span><span class='line'>drwxr-xr-x 6 root root 4096 Jan 12 19:08 stdlib
</span><span class='line'>
</span><span class='line'>[root@cu2 modules]# vi /etc/puppetlabs/code/environments/production/manifests/site.pp 
</span><span class='line'>node default {
</span><span class='line'>  class { 'hosts': 
</span><span class='line'>    dynamic_mode =&gt; true,
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># 效果。好像要活跃的主机才会添加，顺序执行两边 agent -t 就可以把所有的agent全部加到hosts文件
</span><span class='line'>[root@hadoop-slaver3 ~]# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Loading facts
</span><span class='line'>Info: Caching catalog for hadoop-slaver3.ds.ctyun
</span><span class='line'>Info: Applying configuration version '1461309849'
</span><span class='line'>Notice: Applied catalog in 0.06 seconds
</span><span class='line'>[root@hadoop-slaver3 ~]# cat /etc/hosts
</span><span class='line'># HEADER: This file was autogenerated at 2016-04-22 07:23:45 +0000
</span><span class='line'># HEADER: by puppet.  While it can still be managed manually, it
</span><span class='line'># HEADER: is definitely not recommended.
</span><span class='line'>172.17.0.5      hadoop-slaver3
</span><span class='line'>127.0.0.1       localhost
</span><span class='line'>::1     localhost       ip6-localhost ip6-loopback
</span><span class='line'>fe00::0 ip6-localnet
</span><span class='line'>ff00::0 ip6-mcastprefix
</span><span class='line'>ff02::1 ip6-allnodes
</span><span class='line'>ff02::2 ip6-allrouters
</span><span class='line'>
</span><span class='line'>172.17.42.1     cu2     cu2.eshore.cn
</span><span class='line'>172.17.0.5      hadoop-slaver3.ds.ctyun hadoop-slaver3
</span><span class='line'>172.17.0.1      hadoop-master1.ds.ctyun hadoop-master1
</span><span class='line'>172.17.0.2      hadoop-master2.ds.ctyun hadoop-master2
</span><span class='line'>172.17.0.3      hadoop-slaver1.ds.ctyun hadoop-slaver1
</span><span class='line'>172.17.0.4      hadoop-slaver2.ds.ctyun hadoop-slaver2
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>ntp</li>
</ul>


<p>docker不能修改系统时间！！</p>

<p><a href="https://github.com/example42/puppet-ntp">https://github.com/example42/puppet-ntp</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /etc/puppetlabs/code/environments/production/modules/
</span><span class='line'>[root@cu2 modules]# ll
</span><span class='line'>total 20
</span><span class='line'>drwxr-xr-x 3 root root 4096 Apr 22 14:37 helloworld
</span><span class='line'>drwxrwxr-x 6 root root 4096 Aug 10  2015 hosts
</span><span class='line'>drwxrwxr-x 5 root root 4096 Oct 30 00:24 ntp
</span><span class='line'>drwxrwxr-x 7 root root 4096 Aug  8  2015 puppi
</span><span class='line'>drwxr-xr-x 6 root root 4096 Jan 12 19:08 stdlib
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# cat /etc/puppetlabs/code/environments/production/manifests/site.pp 
</span><span class='line'>node default {
</span><span class='line'>
</span><span class='line'>  file { '/etc/cron.hourly':
</span><span class='line'>    ensure =&gt; directory,
</span><span class='line'>  }
</span><span class='line'> 
</span><span class='line'>  package { ['ntp', 'ntpdate']:
</span><span class='line'>    ensure =&gt; installed,
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  class { 'ntp':
</span><span class='line'>    runmode =&gt; 'cron',
</span><span class='line'>    cron_command =&gt; 'ntpdate cu2',
</span><span class='line'>    require =&gt; [ Package['ntp', 'ntpdate'], File['/etc/cron.hourly'] ],
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  if $fqdn =~ /.*\.ds\.ctyun/  {
</span><span class='line'>    class { 'hosts':
</span><span class='line'>      dynamic_mode =&gt; true,
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet agent -t
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 puppetlabs]# ll /etc/cron.hourly/
</span><span class='line'>total 4
</span><span class='line'>-rwxr-xr-x 1 root root 197 Apr 22 08:59 ntpdate
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cat /etc/cron.hourly/ntpdate 
</span><span class='line'>#!/bin/bash
</span><span class='line'># Managed by Puppet
</span><span class='line'>export PATH=$PATH:/usr/bin:/usr/sbin:/bin:/sbin
</span><span class='line'>
</span><span class='line'># Wait up to 600 seconds 
</span><span class='line'>randomsec=$RANDOM
</span><span class='line'>let "randomsec %= 600"
</span><span class='line'>sleep $randomsec
</span><span class='line'>
</span><span class='line'>ntpdate cu2 &gt;/dev/null
</span><span class='line'>
</span><span class='line'>exit 0
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>sudo</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 modules]# mv saz-sudo-3.1.0 sudo
</span><span class='line'>[root@cu2 modules]# ll
</span><span class='line'>total 20
</span><span class='line'>drwxrwxr-x 6 hadoop root  4096 Aug 10  2015 hosts
</span><span class='line'>drwxrwxr-x 5 hadoop root  4096 Oct 30  2015 ntp
</span><span class='line'>drwxrwxr-x 7 hadoop root  4096 Aug  8  2015 puppi
</span><span class='line'>drwxr-xr-x 6 hadoop root  4096 Jan 12 19:08 stdlib
</span><span class='line'>drwxr-xr-x 8 hadoop games 4096 Jun  6  2015 sudo
</span><span class='line'>[root@cu2 modules]# puppet apply -e "include sudo
</span><span class='line'>&gt; sudo::conf { 'hadoop':
</span><span class='line'>&gt; content =&gt; 'hadoop ALL=(ALL) NOPASSWD: ALL',
</span><span class='line'>&gt; }
</span><span class='line'>&gt; "
</span><span class='line'>Notice: Compiled catalog for cu2.eshore.cn in environment production in 0.64 seconds
</span><span class='line'>Notice: /Stage[main]/Sudo/File[/etc/sudoers]/content: content changed '{md5}d31d7fefba87710cfaf3be96d81104d3' to '{md5}dc7c9180ad39e78a8c91291f4743437b'
</span><span class='line'>Notice: /Stage[main]/Sudo/File[/etc/sudoers.d/]/mode: mode changed '0750' to '0550'
</span><span class='line'>Notice: /Stage[main]/Main/Sudo::Conf[hadoop]/File[10_hadoop]/ensure: defined content as '{md5}627f25fd210c1351a6ed664c93b5be37'
</span><span class='line'>Notice: /Stage[main]/Main/Sudo::Conf[hadoop]/Exec[sudo-syntax-check for file /etc/sudoers.d/10_hadoop]: Triggered 'refresh' from 1 events
</span><span class='line'>Notice: Applied catalog in 0.43 seconds</span></code></pre></td></tr></table></div></figure>


<p>上面简单的列出了 puppet 的简单使用，但是如果有大文件。。。</p>

<h2>文件</h2>

<ul>
<li><a href="https://docs.puppet.com/guides/file_serving.html">https://docs.puppet.com/guides/file_serving.html</a></li>
<li><a href="https://docs.puppet.com/puppet/latest/reference/config_file_fileserver.html">https://docs.puppet.com/puppet/latest/reference/config_file_fileserver.html</a></li>
<li><a href="https://docs.puppet.com/guides/scaling.html">https://docs.puppet.com/guides/scaling.html</a> rsync or NFS</li>
<li><a href="https://ask.puppet.com/question/14565/can-we-transfer-a-4gb-patch-file-to-agents-using-puppet-fileserver/">https://ask.puppet.com/question/14565/can-we-transfer-a-4gb-patch-file-to-agents-using-puppet-fileserver/</a></li>
</ul>


<h2>模板</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/latest/reference/lang_template.html">https://docs.puppet.com/puppet/latest/reference/lang_template.html</a></li>
<li><a href="https://docs.puppet.com/puppet/latest/reference/lang_template_epp.html">https://docs.puppet.com/puppet/latest/reference/lang_template_epp.html</a></li>
<li><a href="https://docs.puppet.com/puppet/latest/reference/lang_template_erb.html">https://docs.puppet.com/puppet/latest/reference/lang_template_erb.html</a>
<a href="https://docs.puppet.com/puppet/latest/reference/modules_fundamentals.html">https://docs.puppet.com/puppet/latest/reference/modules_fundamentals.html</a></li>
</ul>


<p><a href="https://docs.puppet.com/puppet/latest/reference/lang_relationships.html#ordering-and-notification">https://docs.puppet.com/puppet/latest/reference/lang_relationships.html#ordering-and-notification</a></p>

<h2>节点定义</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/lang_node_definitions.html">https://docs.puppet.com/puppet/4.4/reference/lang_node_definitions.html</a></li>
<li><a href="https://docs.puppet.com/guides/external_nodes.html">https://docs.puppet.com/guides/external_nodes.html</a>
<a href="http://activemq.apache.org/getting-started.html">http://activemq.apache.org/getting-started.html</a></li>
</ul>


<h2>官网文档</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/lang_conditional.html">Conditional Statements and Expressions</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/lang_facts_and_builtin_vars.html">Facts and Built-in Variables</a></li>
<li></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetexplorer设置]]></title>
    <link href="http://winseliu.com/blog/2016/04/21/puppetexplorer-setting/"/>
    <updated>2016-04-21T14:28:11+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/21/puppetexplorer-setting</id>
    <content type="html"><![CDATA[<p>注意： 使用 <a href="https://github.com/spotify/puppetexplorer/releases">PuppetExplorer</a> 的前提是已经安装 PuppetDB （安装参考：<a href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/">Puppetdb安装配置</a>）。</p>

<p>PuppetDB 提供的8080界面太过于简单，其实8080主要提供非常多的接口。PuppetExplorer 就是使用这些 restful 查询接口来进行展示。比默认的 PuppetDB-UI 更具体和详细。</p>

<p>配置 PuppetExplorer 有两种方式：</p>

<ul>
<li>两个服务在 <strong>同一个域</strong> 下面，配置 /api 跳转到 PuppetDB:8080</li>
<li>两个服务，<strong>配置各自的地址</strong> 。修改config.js，同时处理跨域的问题。</li>
</ul>


<blockquote><p><a href="https://github.com/spotify/puppetexplorer">https://github.com/spotify/puppetexplorer</a></p>

<ul>
<li>The recommended way to install it is on the same host as your PuppetDB instance. Then proxy /api to port 8080 of your PuppetDB instance (except the /commands endpoint). This avoids the need for any CORS headers.</li>
<li>It is possible to have it on a separate domain from your PuppetDB though. If you do, make sure you have the correct Access-Control-Allow-Origin header and a Access-Control-Expose-Headers: X-Records header.</li>
</ul>
</blockquote>

<h2>适配 PuppetDB4</h2>

<p>官网的版本已经几个月没有更新，新的 API 接口略有不同：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># puppetdb-4.0
</span><span class='line'>/metrics/v1/mbeans/puppetlabs.puppetdb.population:name=num-active-nodes
</span><span class='line'>
</span><span class='line'># puppetexplorer-2.0.0
</span><span class='line'>/metrics/v1/mbeans/puppetlabs.puppetdb.query.population:type=default,name=num-nodes</span></code></pre></td></tr></table></div></figure>


<p>修改 app.js 拼接链接的字符串即可，删除 <strong>.query.</strong> 和 <strong>type=default</strong> :</p>

<p><img src="http://winseliu.com/images/blogs/puppetdb4-puppetexplorer.png" alt="" /></p>

<p>配置好后的效果：</p>

<p><img src="http://winseliu.com/images/blogs/puppetexplorer.png" alt="" /></p>

<h1>同一服务器下访问配置</h1>

<p>使用 nginx 作为html的服务器，同时 proxy_pass 代理跳转到 cu3:8080(PuppetDB服务) :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 puppetexplorer-2.0.0]$ mv config.js.example config.js
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 nginx]$ vi conf/nginx.conf
</span><span class='line'>...
</span><span class='line'># 路径最后带上 / ！！
</span><span class='line'>location /api/ {
</span><span class='line'>  proxy_pass http://cu3:8080/;
</span><span class='line'>  proxy_set_header X-Real-IP $remote_addr;
</span><span class='line'>    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
</span><span class='line'>    proxy_set_header Host $http_host;
</span><span class='line'>}
</span><span class='line'>location /puppetexplorer {
</span><span class='line'>  alias /opt/puppetlabs/puppetexplorer-2.0.0;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 nginx]$ sbin/nginx -s reload
</span></code></pre></td></tr></table></div></figure>


<p>然后打开网页访问 <a href="http://cu2:8888/puppetexplorer">http://cu2:8888/puppetexplorer</a> 即可。</p>

<p>nginx的配置参考： <a href="http://wangwei007.blog.51cto.com/68019/1103734">Nginx配置proxy_pass转发的/路径问题</a>, <a href="http://stackoverflow.com/questions/20730858/how-do-i-configure-nginx-as-proxy-to-jetty">nginx as proxy to jetty</a></p>

<p>apache配置</p>

<ul>
<li><a href="https://httpd.apache.org/docs/2.2/mod/mod_proxy.html#x-headers">https://httpd.apache.org/docs/2.2/mod/mod_proxy.html#x-headers</a></li>
<li><a href="http://www.tech126.com/apache2-proxypass-header/">http://www.tech126.com/apache2-proxypass-header/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 html]# vi /etc/httpd/conf/httpd.conf 
</span><span class='line'>...
</span><span class='line'># puppetdb
</span><span class='line'>ProxyPass /puppetdb/api/ http://hadoop-master1:8080/
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 html]# vi puppetexplorer/config.js 
</span><span class='line'>...
</span><span class='line'>PUPPETDB_SERVERS = [
</span><span class='line'>  ['production', '/puppetdb/api'],
</span><span class='line'>  ['testing', '/puppetdb/api']</span></code></pre></td></tr></table></div></figure>


<h1>不同服务器，跨域访问</h1>

<p>老实说，完全不推荐这种做法。但是跨域的设置震惊到我了，原来自认为的方式完全不对。例如A javascript访问B，<strong>跨域头设置在B服务</strong>，是要B容许A访问！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 puppetexplorer]# vi config.js 
</span><span class='line'>// List of PuppetDB servers, pairs of name, URL and $http config object
</span><span class='line'>// The first one will be used as the default server
</span><span class='line'>PUPPETDB_SERVERS = [
</span><span class='line'>  ['production', 'http://cu2:8888'],
</span><span class='line'>  ['testing', 'http://cu2:8888']
</span><span class='line'>];
</span><span class='line'>
</span><span class='line'># Nginx配置，加上跨域访问源范围控制
</span><span class='line'>location ~ /(metrics|pdb) {
</span><span class='line'>add_header "Access-Control-Allow-Origin" "*";
</span><span class='line'>proxy_pass http://cu3:8080;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://www.html5rocks.com/en/tutorials/cors/?redirect_from_locale=zh">http://www.html5rocks.com/en/tutorials/cors/?redirect_from_locale=zh</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#Requests_with_credentials">https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#Requests_with_credentials</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">https://en.wikipedia.org/wiki/Cross-origin_resource_sharing</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetdb安装配置]]></title>
    <link href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/"/>
    <updated>2016-04-21T00:39:11+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config</id>
    <content type="html"><![CDATA[<p>安装 PuppetDB 后，还得修改 PuppetServer 的配置。由于测试环境机器硬件一般般，把 PuppetDB 安装在 cu3。</p>

<ul>
<li>cu2: master server, ca server, postgresql</li>
<li>cu3: puppetdb, agent</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 puppet]# puppetdb -v
</span><span class='line'>puppetdb version: 4.0.0
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1
</span><span class='line'>[root@cu2 ~]# puppet -V
</span><span class='line'>4.4.1
</span></code></pre></td></tr></table></div></figure>


<p>原来老的版本有资源(清单)导出的功能，到了Puppet4后被PuppetDB取代了。见官网文档: <a href="https://docs.puppet.com/guides/inventory_service.html">Inventory Service</a></p>

<p>同时老版本用ruby写的 puppet-dashboard 也没有必要安装了，前后端分离大势所趋：后端提供接口，前端用ajax来展现。</p>

<h1>安装PuppetDB</h1>

<p><a href="https://docs.puppetlabs.com/puppetdb/latest/install_from_packages.html">https://docs.puppetlabs.com/puppetdb/latest/install_from_packages.html</a></p>

<p>由于天朝特殊环境，本地repo的创建参考第一篇文章: <a href="http://winseliu.com/blog/2016/04/08/puppet-install">puppet4.4.1入门安装</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# yum install puppetdb
</span><span class='line'>Loaded plugins: fastestmirror
</span><span class='line'>Setting up Install Process
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package puppetdb.noarch 0:4.0.0-1.el6 will be installed
</span><span class='line'>--&gt; Processing Dependency: java-1.8.0-openjdk-headless for package: puppetdb-4.0.0-1.el6.noarch
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7 will be installed
</span><span class='line'>--&gt; Processing Dependency: tzdata-java &gt;= 2014f-1 for package: 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64
</span><span class='line'>--&gt; Processing Dependency: jpackage-utils for package: 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package jpackage-utils.noarch 0:1.7.5-3.14.el6 will be installed
</span><span class='line'>---&gt; Package tzdata-java.noarch 0:2016c-1.el6 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>===========================================================================================================================================================================================
</span><span class='line'> Package                                                Arch                              Version                                            Repository                               Size
</span><span class='line'>===========================================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> puppetdb                                               noarch                            4.0.0-1.el6                                        puppet-local                             21 M
</span><span class='line'>Installing for dependencies:
</span><span class='line'> java-1.8.0-openjdk-headless                            x86_64                            1:1.8.0.77-0.b03.el6_7                             updates                                  32 M
</span><span class='line'> jpackage-utils                                         noarch                            1.7.5-3.14.el6                                     base                                     60 k
</span><span class='line'> tzdata-java                                            noarch                            2016c-1.el6                                        updates                                 179 k
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>===========================================================================================================================================================================================
</span><span class='line'>Install       4 Package(s)
</span><span class='line'>
</span><span class='line'>Total size: 53 M
</span><span class='line'>Total download size: 53 M
</span><span class='line'>Installed size: 126 M
</span><span class='line'>Is this ok [y/N]: y
</span><span class='line'>Downloading Packages:
</span><span class='line'>(1/3): java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64.rpm                                                                                                  |  32 MB     00:00     
</span><span class='line'>(2/3): puppetdb-4.0.0-1.el6.noarch.rpm                                                                                                                              |  21 MB     00:00     
</span><span class='line'>(3/3): tzdata-java-2016c-1.el6.noarch.rpm                                                                                                                           | 179 kB     00:00     
</span><span class='line'>-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class='line'>Total                                                                                                                                                       32 MB/s |  53 MB     00:01     
</span><span class='line'>Running rpm_check_debug
</span><span class='line'>Running Transaction Test
</span><span class='line'>Transaction Test Succeeded
</span><span class='line'>Running Transaction
</span><span class='line'>  Installing : tzdata-java-2016c-1.el6.noarch                                                                                                                                          1/4 
</span><span class='line'>  Installing : jpackage-utils-1.7.5-3.14.el6.noarch                                                                                                                                    2/4 
</span><span class='line'>  Installing : 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64                                                                                                               3/4 
</span><span class='line'>  Installing : puppetdb-4.0.0-1.el6.noarch                                                                                                                                             4/4 
</span><span class='line'>Config archive not found. Not proceeding with migration
</span><span class='line'>PEM files in /etc/puppetlabs/puppetdb/ssl are missing, we will move them into place for you
</span><span class='line'>Warning: Unable to find all puppet certificates to copy
</span><span class='line'>
</span><span class='line'>  This tool requires the following certificates to exist:
</span><span class='line'>
</span><span class='line'>  * /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>  * /etc/puppetlabs/puppet/ssl/private_keys/cu3.eshore.cn.pem
</span><span class='line'>  * /etc/puppetlabs/puppet/ssl/certs/cu3.eshore.cn.pem
</span><span class='line'>
</span><span class='line'>  These files may be missing due to the fact that your host's Puppet
</span><span class='line'>  certificates may not have been signed yet, probably due to the
</span><span class='line'>  lack of a complete Puppet agent run. Try running puppet first, for
</span><span class='line'>  example:
</span><span class='line'>
</span><span class='line'>      puppet agent --test
</span><span class='line'>
</span><span class='line'>  Afterwards re-run this tool then restart PuppetDB to complete the SSL
</span><span class='line'>  setup:
</span><span class='line'>
</span><span class='line'>      puppetdb ssl-setup -f
</span><span class='line'>  Verifying  : jpackage-utils-1.7.5-3.14.el6.noarch                                                                                                                                    1/4 
</span><span class='line'>  Verifying  : tzdata-java-2016c-1.el6.noarch                                                                                                                                          2/4 
</span><span class='line'>  Verifying  : puppetdb-4.0.0-1.el6.noarch                                                                                                                                             3/4 
</span><span class='line'>  Verifying  : 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64                                                                                                               4/4 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  puppetdb.noarch 0:4.0.0-1.el6                                                                                                                                                            
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7                   jpackage-utils.noarch 0:1.7.5-3.14.el6                   tzdata-java.noarch 0:2016c-1.el6                  
</span><span class='line'>
</span><span class='line'>Complete!
</span></code></pre></td></tr></table></div></figure>


<p>PuppetDB 需要与 puppetserver 通信，需要签名证书。如果安装之前本机 Puppet-agent 证书已签名，安装会自动把证书拷贝到 puppetdb/ssl 目录下。我们这里先签名agent再配置 puppetdb-ssl 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu3.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 16:CB:A3:6D:21:69:78:D0:0D:37:1F:A7:C1:86:2E:55:7F:B1:60:77:05:EC:F5:37:81:12:28:73:61:1A:4F:20
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'># 服务端签名: puppet cert sign cu3.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu3.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461159906'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>[root@cu3 ~]# puppetdb ssl-setup -f
</span><span class='line'>PEM files in /etc/puppetlabs/puppetdb/ssl are missing, we will move them into place for you
</span><span class='line'>Copying files: /etc/puppetlabs/puppet/ssl/certs/ca.pem, /etc/puppetlabs/puppet/ssl/private_keys/cu3.eshore.cn.pem and /etc/puppetlabs/puppet/ssl/certs/cu3.eshore.cn.pem to /etc/puppetlabs/puppetdb/ssl
</span><span class='line'>Backing up /etc/puppetlabs/puppetdb/conf.d/jetty.ini to /etc/puppetlabs/puppetdb/conf.d/jetty.ini.bak.1461159930 before making changes
</span><span class='line'>Updated default settings from package installation for ssl-host in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-port in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-key in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-cert in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-ca-cert in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>[root@cu3 ~]# </span></code></pre></td></tr></table></div></figure>


<h1>安装Postgres</h1>

<p>配置好 ssl 后，下一步就是连接数据库。puppet4.4 默认配置里面只有 postgres 数据库。直接用 yum 安装，这里简单列出配置过程。</p>

<p><a href="https://docs.puppetlabs.com/puppetdb/latest/configure.html#using-postgresql">https://docs.puppetlabs.com/puppetdb/latest/configure.html#using-postgresql</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# yum localinstall http://yum.postgresql.org/9.4/redhat/rhel-6-x86_64/pgdg-centos94-9.4-1.noarch.rpm
</span><span class='line'>[root@cu2 ~]# yum install postgresql94-server
</span><span class='line'>[root@cu2 ~]# yum install postgresql94-contrib
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# service postgresql-9.4 initdb
</span><span class='line'>Initializing database:                                     [  OK  ]
</span><span class='line'>[root@cu2 ~]# service postgresql-9.4 status
</span><span class='line'>postgresql-9.4 is stopped
</span><span class='line'>[root@cu2 ~]# service postgresql-9.4 start
</span><span class='line'>Starting postgresql-9.4 service:                           [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 先查看 PGDATA 的目录！！
</span><span class='line'>[root@cu2 data]# grep "PGDATA=" /etc/init.d/postgresql-9.4 
</span><span class='line'>PGDATA=/usr/local/pgsql/data
</span><span class='line'>OLDPGDATA=` sed -n 's/^PGDATA=//p' /etc/init.d/postgresql-$PGPREVMAJORVERSION`
</span><span class='line'>NEWPGDATA=` sed -n 's/^PGDATA=//p' /etc/init.d/postgresql-$PGMAJORVERSION`
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 切换到 postgres 用户，先验证环境变量 PGDATA 是否正确！！否则自己修改 .bash_profile 文件！！
</span><span class='line'>[root@cu2 puppet]# su - postgres
</span><span class='line'>-bash-4.1$ echo $PGDATA
</span><span class='line'>/usr/local/pgsql/data
</span><span class='line'>
</span><span class='line'># 创建用户
</span><span class='line'>-bash-4.1$ createuser -DRSP puppetdb
</span><span class='line'>Enter password for new role: 
</span><span class='line'>Enter it again: 
</span><span class='line'>-bash-4.1$ 
</span><span class='line'>-bash-4.1$ createdb -E utf8 -O puppetdb puppetdb
</span><span class='line'>
</span><span class='line'>-bash-4.1$ psql puppetdb -c 'create extension pg_trgm'
</span><span class='line'>CREATE EXTENSION
</span><span class='line'>
</span><span class='line'># 配置连接选项（相当于mysql的privilege）
</span><span class='line'>-bash-4.1$ vi $PGDATA/pg_hba.conf 
</span><span class='line'>host    all             all              0.0.0.0/0               md5
</span><span class='line'>
</span><span class='line'># 重启
</span><span class='line'>[root@cu2 puppet]# service postgresql-9.4 restart
</span><span class='line'>Stopping postgresql-9.4 service:                           [  OK  ]
</span><span class='line'>Starting postgresql-9.4 service:                           [  OK  ]
</span><span class='line'>
</span><span class='line'># 测试 
</span><span class='line'>[root@cu2 puppet]# psql -h localhost puppetdb puppetdb
</span><span class='line'>psql (9.4.5)
</span><span class='line'>Type "help" for help.
</span><span class='line'>
</span><span class='line'>puppetdb=&gt; 
</span><span class='line'>puppetdb=&gt; \q
</span></code></pre></td></tr></table></div></figure>


<p>查看 postgres 的端口:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 puppet]# netstat -anp | grep post
</span><span class='line'>tcp        0      0 0.0.0.0:5432                0.0.0.0:*                   LISTEN      8126/postmaster     
</span><span class='line'>tcp        0      0 :::5432                     :::*                        LISTEN      8126/postmaster     
</span><span class='line'>udp        0      0 ::1:39400                   ::1:39400                   ESTABLISHED 8126/postmaster     
</span><span class='line'>unix  2      [ ACC ]     STREAM     LISTENING     954965338 8126/postmaster     /tmp/.s.PGSQL.5432
</span><span class='line'>
</span><span class='line'># 有客户端连上来后：
</span><span class='line'>[root@cu2 ~]# netstat -anp | grep post
</span><span class='line'>tcp        0      0 0.0.0.0:5432                0.0.0.0:*                   LISTEN      8126/postmaster     
</span><span class='line'>tcp        0      0 192.168.0.214:5432          192.168.0.148:60626         ESTABLISHED 20589/postgres 
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h1>启动PuppetDB</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# vi /etc/puppetlabs/puppetdb/conf.d/database.ini 
</span><span class='line'>[database]
</span><span class='line'>classname = org.postgresql.Driver
</span><span class='line'>subprotocol = postgresql
</span><span class='line'>
</span><span class='line'># The database address, i.e. //HOST:PORT/DATABASE_NAME
</span><span class='line'>subname = //cu2:5432/puppetdb
</span><span class='line'>
</span><span class='line'># Connect as a specific user
</span><span class='line'>username = puppetdb
</span><span class='line'>
</span><span class='line'># Use a specific password
</span><span class='line'>password = puppetdb
</span><span class='line'>
</span><span class='line'># How often (in minutes) to compact the database
</span><span class='line'># gc-interval = 60
</span><span class='line'># 通过api/name=num-active-nodes查询不到了，但是pgsql数据库中还没有删除。也可以通过 puppet node deactivate 手动执行
</span><span class='line'># node-ttl = 30d
</span><span class='line'># 默认没有设置，disabled。格式与node-ttl一样
</span><span class='line'># node-purge-ttl = 
</span><span class='line'># report-ttl = 14d
</span><span class='line'>
</span><span class='line'># Number of seconds before any SQL query is considered 'slow'; offending
</span><span class='line'># queries will not be interrupted, but will be logged at the WARN log level.
</span><span class='line'>log-slow-statements = 10
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 注意修改，不然web-ui就只能localhost访问了！！
</span><span class='line'>[root@cu3 ~]# vi /etc/puppetlabs/puppetdb/conf.d/jetty.ini
</span><span class='line'>...
</span><span class='line'>host = 0.0.0.0
</span><span class='line'>
</span><span class='line'># JVM 参数修改
</span><span class='line'>[root@cu3 ~]# less /etc/sysconfig/puppetdb 
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# service puppetdb start
</span><span class='line'>Starting puppetdb:                                         [  OK  ]
</span><span class='line'>[root@cu3 ~]# 
</span><span class='line'>[root@cu3 ~]# service puppetdb status
</span><span class='line'>puppetdb (pid  8452) is running...
</span><span class='line'>
</span><span class='line'># 8081 为 puppetserver 写数据的https接口。8080 为http web-ui端口
</span><span class='line'>[root@cu3 ~]# netstat -anp | grep 8081
</span><span class='line'>tcp        0      0 :::8081                     :::*                        LISTEN      8794/java           
</span></code></pre></td></tr></table></div></figure>


<p>查看 8080 端口通过网页查看集群的状态，现在还什么数据都获取不到，需要配置服务端把数据发送给puppetdb。</p>

<h1>服务端配置</h1>

<p><a href="https://docs.puppet.com/puppetdb/latest/connect_puppet_master.html">https://docs.puppet.com/puppetdb/latest/connect_puppet_master.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 安装Plug-in
</span><span class='line'># 服务端还要安装 puppetdb-termini ，不然会报错。
</span><span class='line'>[root@cu2 puppet]# yum install puppetdb-termini
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Setting up Install Process
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * epel: mirrors.opencas.cn
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package puppetdb-termini.noarch 0:3.2.4-1.el6 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>==========================================================================================================================================================================
</span><span class='line'> Package                                      Arch                               Version                                   Repository                                Size
</span><span class='line'>==========================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> puppetdb-termini                             noarch                             3.2.4-1.el6                               puppet-local                              25 k
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>==========================================================================================================================================================================
</span><span class='line'>Install       1 Package(s)
</span><span class='line'>
</span><span class='line'>Total download size: 25 k
</span><span class='line'>Installed size: 69 k
</span><span class='line'>Is this ok [y/N]: y
</span><span class='line'>Downloading Packages:
</span><span class='line'>puppetdb-termini-3.2.4-1.el6.noarch.rpm                                                                                                            |  25 kB     00:00     
</span><span class='line'>Running rpm_check_debug
</span><span class='line'>Running Transaction Test
</span><span class='line'>Transaction Test Succeeded
</span><span class='line'>Running Transaction
</span><span class='line'>  Installing : puppetdb-termini-3.2.4-1.el6.noarch                                                                                                                    1/1 
</span><span class='line'>  Verifying  : puppetdb-termini-3.2.4-1.el6.noarch                                                                                                                    1/1 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  puppetdb-termini.noarch 0:3.2.4-1.el6                                                                                                                                   
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 注意这里URL的域名，要与CA中的名称对应！！ 设置成 cu3 是不正确的！！
</span><span class='line'>[root@cu2 puppet]# vi puppetdb.conf 
</span><span class='line'>[main]
</span><span class='line'>server_urls = https://cu3.eshore.cn:8081
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# vi puppet.conf 
</span><span class='line'># This file can be used to override the default puppet settings.
</span><span class='line'># See the following links for more details on what settings are available:
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/config_about_settings.html
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/config_file_main.html
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/configuration.html
</span><span class='line'>[master]
</span><span class='line'>vardir = /opt/puppetlabs/server/data/puppetserver
</span><span class='line'>logdir = /var/log/puppetlabs/puppetserver
</span><span class='line'>rundir = /var/run/puppetlabs/puppetserver
</span><span class='line'>pidfile = /var/run/puppetlabs/puppetserver/puppetserver.pid
</span><span class='line'>codedir = /etc/puppetlabs/code
</span><span class='line'>
</span><span class='line'>storeconfigs = true
</span><span class='line'>storeconfigs_backend = puppetdb
</span><span class='line'>reports = store,puppetdb
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet master --configprint route_file
</span><span class='line'>/etc/puppetlabs/puppet/routes.yaml
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppet]# cat routes.yaml 
</span><span class='line'>---
</span><span class='line'>master:
</span><span class='line'>  facts:
</span><span class='line'>    terminus: puppetdb
</span><span class='line'>    cache: yaml
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# service puppetserver restart
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet agent --server cu2.eshore.cn --test 
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu2.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461162748'
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span></code></pre></td></tr></table></div></figure>


<p>如果 puppet-agent 服务没有启动，分别在各台机器上面执行 &ndash;test 连一下 PuppetServer，就可以在8080 puppetdb页面看到主机的数量了。</p>

<p><img src="http://winseliu.com/images/blogs/puppetdb-ui.png" alt="" /></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet入门之域名证书]]></title>
    <link href="http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn/"/>
    <updated>2016-04-21T00:06:06+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn</id>
    <content type="html"><![CDATA[<p>说 Puppet 入门配置过程中 90% 的问题与有关毫不为过！！因为节点之间的通信都需要证书验证，而证书验证和域名绑定。</p>

<p>主要讲讲 FQDN(Fully Qualified Domain Name) 查看和配置，以及 <strong>Puppet4.4</strong> 认证相关的操作。</p>

<h1>环境说明</h1>

<p>测试环境是几台云主机 ，主机名根据项目情况命名（也就是说云主机内网域名解析是不行的）。操作系统没特殊说明那么使用的是 Centos6 。</p>

<ul>
<li>cu2： 服务端master，证书服务器ca</li>
<li>cu1/cu3/cu4/cu5:  agent</li>
</ul>


<p>这里列出来的是部署之前的域名情况。一步步的处理域名代码的麻烦。如果想避免不必要的烦恼，请使用 FQDN 加上 <strong>域</strong> 。</p>

<h1>服务节点证书重新签名</h1>

<p>安装后直接测试，默认连接的服务器是 puppet 。所以要么指定 puppet 对应主机，要么加上 &ndash;server 参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 默认的 puppet 服务器找不到对应的主机
</span><span class='line'>[root@cu2 ~]# puppet agent --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: getaddrinfo: Name or service not known
</span><span class='line'>Error: Could not retrieve catalog from remote server: getaddrinfo: Name or service not known
</span><span class='line'>Warning: Not using cache on failed catalog
</span><span class='line'>Error: Could not retrieve catalog; skipping run
</span><span class='line'>Error: Could not send report: getaddrinfo: Name or service not known
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 加上 域 后不通，DNS服务器不识别自定义的主机名
</span><span class='line'>[root@cu2 ~]# cat /etc/resolv.conf 
</span><span class='line'>; generated by /sbin/dhclient-script
</span><span class='line'>search ds.ctyun
</span><span class='line'>nameserver 192.168.0.1
</span><span class='line'>[root@cu2 ~]# puppet agent --server cu2.ds.ctyun --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: getaddrinfo: Name or service not known
</span><span class='line'>Error: Could not retrieve catalog from remote server: getaddrinfo: Name or service not known
</span><span class='line'>Warning: Not using cache on failed catalog
</span><span class='line'>Error: Could not retrieve catalog; skipping run
</span><span class='line'>Error: Could not send report: getaddrinfo: Name or service not known
</span><span class='line'>[root@cu2 ~]# ping cu2.ds.ctyun
</span><span class='line'>ping: unknown host cu2.ds.ctyun
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 传说中用的 -f 参数没L用
</span><span class='line'>[root@cu2 ~]# hostname -i
</span><span class='line'>192.168.0.x
</span><span class='line'>[root@cu2 ~]# hostname -f
</span><span class='line'>cu2
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 加自定义 域 ，并重新设定 FQDN hostname。 修改主机hostname的步骤可以替换成在 /etc/resolv.conf 加 **domain eshore.cn**
</span><span class='line'>[root@cu2 ~]# vi /etc/hosts
</span><span class='line'>192.168.0.x cu1 cu1.eshore.cn
</span><span class='line'>192.168.0.x cu2 cu2.eshore.cn
</span><span class='line'>
</span><span class='line'>192.168.0.x cu3 cu3.eshore.cn
</span><span class='line'>192.168.0.x cu4 cu4.eshore.cn
</span><span class='line'>192.168.0.x cu5 cu5.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# vi /etc/sysconfig/network
</span><span class='line'>NETWORKING=yes
</span><span class='line'>HOSTNAME=cu2.eshore.cn
</span><span class='line'>[root@cu2 ~]# hostname cu2.eshore.cn
</span><span class='line'>[root@cu2 ~]# hostname
</span><span class='line'>cu2.eshore.cn
</span><span class='line'>
</span><span class='line'># 确认
</span><span class='line'>[root@cu2 ~]# puppet config print certname
</span><span class='line'>cu2.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# dnsdomainname -v
</span><span class='line'>gethostname()=`cu2.eshore.cn'
</span><span class='line'>Resolving `cu2.eshore.cn' ...
</span><span class='line'>Result: h_name=`cu2'
</span><span class='line'>Result: h_aliases=`cu2.eshore.cn'
</span><span class='line'>Result: h_addr_list=`192.168.0.214'
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# hostname -f -v
</span><span class='line'>gethostname()=`cu2.eshore.cn'
</span><span class='line'>Resolving `cu2.eshore.cn' ...
</span><span class='line'>Result: h_name=`cu2'
</span><span class='line'>Result: h_aliases=`cu2.eshore.cn'
</span><span class='line'>Result: h_addr_list=`192.168.0.214'
</span><span class='line'>cu2
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 清理已经为本机签发的证书
</span><span class='line'>[root@cu2 ~]# puppet cert list -all
</span><span class='line'>+ "cu2.ds.ctyun" (SHA256) A6:30:6D:80:A8:04:60:56:4C:F3:D5:3C:9A:5C:2A:11:6C:A6:A9:F7:6E:5E:A5:37:59:28:5B:B6:E3:D3:73:D5 (alt names: "DNS:puppet", "DNS:cu2.ds.ctyun")
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# puppet cert clean cu2.ds.ctyun
</span><span class='line'>Notice: Revoked certificate with serial 2
</span><span class='line'>Notice: Removing file Puppet::SSL::Certificate cu2.ds.ctyun at '/etc/puppetlabs/puppet/ssl/ca/signed/cu2.ds.ctyun.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::Certificate cu2.ds.ctyun at '/etc/puppetlabs/puppet/ssl/certs/cu2.ds.ctyun.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::Key cu2.ds.ctyun at '/etc/puppetlabs/puppet/ssl/private_keys/cu2.ds.ctyun.pem'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 由于是server节点的证书变更，重启puppetserver会重新生成/签发证书
</span><span class='line'>[root@cu2 ~]# service puppetserver restart
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# tree /etc/puppetlabs/puppet/ssl
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>├── ca
</span><span class='line'>│   ├── ca_crl.pem
</span><span class='line'>│   ├── ca_crt.pem
</span><span class='line'>│   ├── ca_key.pem
</span><span class='line'>│   ├── ca_pub.pem
</span><span class='line'>│   ├── inventory.txt
</span><span class='line'>│   ├── private
</span><span class='line'>│   ├── requests
</span><span class='line'>│   ├── serial
</span><span class='line'>│   └── signed
</span><span class='line'>│       └── cu2.eshore.cn.pem
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    └── cu2.eshore.cn.pem
</span><span class='line'>
</span><span class='line'>9 directories, 12 files
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu2.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461149778'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span></code></pre></td></tr></table></div></figure>


<h1>Agent 重新签名</h1>

<p>涉及到客户端域名错误，需要服务端配合清理签名请求等操作。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 首先同步 /etc/hosts 到所有agent节点
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># cu1 连接 服务器cu2
</span><span class='line'>[root@cu1 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu1.ds.ctyun
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu1.ds.ctyun
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 4F:D6:DC:25:22:D9:44:E5:70:9F:9B:B1:0F:99:B2:AC:F5:5F:50:CE:B7:C3:AF:65:F4:E2:DF:D5:2D:6F:96:07
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 在没有修改 域 的情况下，已经发送了 ds.ctyun 域 的签名请求
</span><span class='line'># 修改主机域，再发送请求
</span><span class='line'>[root@cu1 ~]# vi /etc/resolv.conf 
</span><span class='line'>; generated by /sbin/dhclient-script
</span><span class='line'>domain eshore.cn
</span><span class='line'>search ds.ctyun
</span><span class='line'>nameserver 192.168.0.1
</span><span class='line'>
</span><span class='line'>[root@cu1 ~]#  puppet config print certname
</span><span class='line'>cu1.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu1 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu1.eshore.cn
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu1.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): B8:A1:65:B6:FE:02:87:B1:8D:0A:62:2E:FE:30:DD:B3:3B:C9:A2:B2:A1:50:11:D3:FE:03:6A:81:A6:84:C0:6B
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 此时服务端cu2已包括了 cu1 的两个签名请求信息
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>  "cu1.ds.ctyun"  (SHA256) 4F:D6:DC:25:22:D9:44:E5:70:9F:9B:B1:0F:99:B2:AC:F5:5F:50:CE:B7:C3:AF:65:F4:E2:DF:D5:2D:6F:96:07
</span><span class='line'>  "cu1.eshore.cn" (SHA256) B8:A1:65:B6:FE:02:87:B1:8D:0A:62:2E:FE:30:DD:B3:3B:C9:A2:B2:A1:50:11:D3:FE:03:6A:81:A6:84:C0:6B
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) 3D:8E:4E:18:45:F4:8C:9B:71:7C:13:45:0D:8A:6F:A5:6E:22:D5:0E:B1:B0:54:29:47:02:AE:95:8B:E6:A6:B7 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 本地清理 无效的签名请求 或者直接删除ssl目录： rm -rf /var/lib/puppet/ssl
</span><span class='line'>[root@cu1 ~]# puppet certificate_request destroy cu1.ds.ctyun
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu1.ds.ctyun at '/etc/puppetlabs/puppet/ssl/certificate_requests/cu1.ds.ctyun.pem'
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 服务端清理 特定客户端无效请求
</span><span class='line'># http://serverfault.com/questions/574976/puppet-trying-to-configure-puppet-client-for-first-use-but-got-some-problems-wi
</span><span class='line'>[root@cu2 puppet]# puppet node clean cu1.ds.ctyun 
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu1.ds.ctyun at '/etc/puppetlabs/puppet/ssl/ca/requests/cu1.ds.ctyun.pem'
</span><span class='line'>cu1.ds.ctyun
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 服务端签名，客户端agent同步manifest
</span><span class='line'>[root@cu2 puppet]# puppet cert sign cu1.eshore.cn
</span><span class='line'>Notice: Signed certificate request for cu1.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu1.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu1.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'>[root@cu1 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu1.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461156849'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span></code></pre></td></tr></table></div></figure>


<p>其他修改主机域后统一签名：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 puppet]# puppet cert list 
</span><span class='line'>  "cu3.eshore.cn" (SHA256) 16:CB:A3:6D:21:69:78:D0:0D:37:1F:A7:C1:86:2E:55:7F:B1:60:77:05:EC:F5:37:81:12:28:73:61:1A:4F:20
</span><span class='line'>  "cu4.eshore.cn" (SHA256) CB:80:64:BD:B8:56:56:43:90:11:D4:B2:A9:7B:D8:DC:E4:0C:8D:5A:71:0B:FF:97:65:20:F5:B4:D7:15:11:B6
</span><span class='line'>  "cu5.eshore.cn" (SHA256) D6:9A:B0:93:98:94:D2:D2:E3:A9:55:24:EC:7A:E0:13:48:5B:26:16:6C:5A:B6:11:F5:7C:F2:56:E4:DA:D8:31
</span><span class='line'>[root@cu2 puppet]# puppet cert sign --all
</span><span class='line'>Notice: Signed certificate request for cu5.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu5.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu5.eshore.cn.pem'
</span><span class='line'>Notice: Signed certificate request for cu4.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu4.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu4.eshore.cn.pem'
</span><span class='line'>Notice: Signed certificate request for cu3.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu3.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu3.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 最终效果
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>+ "cu1.eshore.cn" (SHA256) 46:69:EE:A8:E5:F9:FB:E3:59:63:C5:FC:52:AF:14:43:70:EF:D0:42:70:C4:0E:D2:14:E4:1C:D9:94:F8:9E:E7
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) 3D:8E:4E:18:45:F4:8C:9B:71:7C:13:45:0D:8A:6F:A5:6E:22:D5:0E:B1:B0:54:29:47:02:AE:95:8B:E6:A6:B7 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>+ "cu3.eshore.cn" (SHA256) 58:ED:A3:CC:B9:53:34:4B:64:3C:2A:B4:91:AD:0D:8F:AF:EA:B0:5C:A7:73:06:F1:A7:4B:D2:E2:06:B5:21:39
</span><span class='line'>+ "cu4.eshore.cn" (SHA256) DD:A2:B9:86:53:29:DB:12:A3:0C:AA:9C:11:68:72:70:72:E2:16:36:8E:20:AC:E5:48:12:36:E2:80:6C:F0:E6
</span><span class='line'>+ "cu5.eshore.cn" (SHA256) EE:E6:FB:D2:1A:04:AD:C3:5B:1F:4F:79:C3:B6:36:15:B5:AC:8B:8B:5D:CB:A4:AA:AF:7B:FB:50:0B:83:7E:38
</span></code></pre></td></tr></table></div></figure>


<h1>自动签名配置文件</h1>

<p>反正都是学习，在无尽的折腾成长。如果是生产环境最好不要清理服务端的已签名证书，不但客户端要重新签，如果安装了puppetdb等其他程序需要签名都得重新配置签名。</p>

<p>注意： 如果已经安装官网的步骤安装 PuppetDB ，清理服务端的证书建议通过命令 puppet cert clean DOMAIN 来清理。否则 PuppetDB 中还有对应的证书缓存信息。</p>

<p><img src="http://winseliu.com/images/blogs/puppet-puppetdb-resign.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://tickets.puppetlabs.com/browse/PUP-1426
</span><span class='line'># 貌似不支持全部清除已签名证书
</span><span class='line'>[root@cu2 ~]# puppet cert clean --all 
</span><span class='line'>Error: Refusing to revoke all certs, provide an explicit list of certs to revoke
</span><span class='line'>
</span><span class='line'># 直接删掉ssl目录
</span><span class='line'>[root@cu2 ~]# puppet master --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# cd /etc/puppetlabs/puppet
</span><span class='line'>[root@cu2 puppet]# ll
</span><span class='line'>...
</span><span class='line'>drwxrwx--x 8 puppet puppet 4096 Apr 20 15:10 ssl
</span><span class='line'>
</span><span class='line'># 注意ssl目录的权限。这里仅删除目录里面的文件
</span><span class='line'>[root@cu2 puppet]# service puppetserver stop
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>[root@cu2 puppet]# 
</span><span class='line'>[root@cu2 puppet]# rm -rf ssl/*
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 先启动服务看看原来已签名的再连服务器是什么情况
</span><span class='line'>[root@cu2 puppet]# service puppetserver start
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# tree ssl/
</span><span class='line'>ssl/
</span><span class='line'>├── ca
</span><span class='line'>│   ├── ca_crl.pem
</span><span class='line'>│   ├── ca_crt.pem
</span><span class='line'>│   ├── ca_key.pem
</span><span class='line'>│   ├── ca_pub.pem
</span><span class='line'>│   ├── inventory.txt
</span><span class='line'>│   ├── requests
</span><span class='line'>│   ├── serial
</span><span class='line'>│   └── signed
</span><span class='line'>│       └── cu2.eshore.cn.pem
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    └── cu2.eshore.cn.pem
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># agent 再请求，会报错。删除 ssl 后，再签名
</span><span class='line'>[root@cu3 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Error: Could not retrieve catalog from remote server: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Warning: Not using cache on failed catalog
</span><span class='line'>Error: Could not retrieve catalog; skipping run
</span><span class='line'>Error: Could not send report: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# puppet agent --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>[root@cu3 ~]# cd /etc/puppetlabs/puppet
</span><span class='line'>[root@cu3 puppet]# rm -rf ssl/*
</span><span class='line'>[root@cu3 puppet]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu3.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 9D:58:14:C0:CA:DD:51:77:0B:3F:EB:09:02:9B:D6:67:04:FD:48:7A:6E:CB:83:43:8D:5B:A9:78:0C:89:90:5B
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>  "cu3.eshore.cn" (SHA256) 9D:58:14:C0:CA:DD:51:77:0B:3F:EB:09:02:9B:D6:67:04:FD:48:7A:6E:CB:83:43:8D:5B:A9:78:0C:89:90:5B
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) BA:C4:C9:CC:92:6E:45:2E:B1:7F:BC:15:49:0A:2C:BB:5F:C6:B0:73:EB:6C:21:EA:C8:A6:DD:2D:FE:DF:67:70 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>[root@cu2 puppet]# puppet cert sign --all
</span><span class='line'>Notice: Signed certificate request for cu3.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu3.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu3.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'>[root@cu3 puppet]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu3.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461205206'
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 配置autosign
</span><span class='line'># https://docs.puppet.com/puppet/4.4/reference/ssl_autosign.html
</span><span class='line'># 在CA的服务器配置的master节点下配置autosign: Naïve Autosigning
</span><span class='line'>[root@cu2 puppet]# vi puppet.conf 
</span><span class='line'>...
</span><span class='line'>autosign = true
</span><span class='line'># 或者添加配置文件: Basic Autosigning (autosign.conf)
</span><span class='line'>[root@cu2 puppet]# vi autosign.conf
</span><span class='line'>*.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# service puppetserver restart
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># agent 自动重新签名
</span><span class='line'>[root@cu1 ~]# cd /etc/puppetlabs/puppet/
</span><span class='line'>[root@cu1 puppet]# rm -rf ssl/*
</span><span class='line'>[root@cu1 puppet]# 
</span><span class='line'>[root@cu1 puppet]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu1.eshore.cn
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu1.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): D1:F5:6D:A4:91:57:DF:92:47:98:B7:C6:78:E5:C5:E0:AA:DA:70:90:0D:68:48:09:81:FA:65:98:02:F0:84:A9
</span><span class='line'>Info: Caching certificate for cu1.eshore.cn
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu1.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461205750'
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>+ "cu1.eshore.cn" (SHA256) F9:48:1D:85:A7:44:78:71:AA:44:02:3F:98:20:DB:20:B1:DA:10:EC:3A:6A:AE:85:D4:37:EC:9E:20:AB:84:AA
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) BA:C4:C9:CC:92:6E:45:2E:B1:7F:BC:15:49:0A:2C:BB:5F:C6:B0:73:EB:6C:21:EA:C8:A6:DD:2D:FE:DF:67:70 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>+ "cu3.eshore.cn" (SHA256) BA:00:57:50:1D:91:40:0D:7D:E4:C5:99:6F:3F:77:D6:E8:C4:71:5B:8D:8C:AB:FA:D0:D4:5C:36:5D:AB:A7:1B
</span><span class='line'>+ "cu4.eshore.cn" (SHA256) 96:64:4A:73:EC:D7:A6:0D:73:37:82:33:2D:0D:B3:BF:A6:A8:6B:9B:D4:05:D0:2C:46:3B:E2:22:6E:43:39:91
</span><span class='line'>+ "cu5.eshore.cn" (SHA256) 54:48:34:BF:C9:60:8C:4C:D2:9D:C9:A3:52:2E:EB:29:AC:2E:84:2E:9E:34:F1:A3:30:83:46:0E:BF:A9:5D:9A
</span></code></pre></td></tr></table></div></figure>


<p>autosign 除了使用 autosign.conf 配置，还可以使用 shell/命令 来进行适配，具体查看官网文档： <a href="https://docs.puppet.com/puppet/4.4/reference/ssl_autosign.html">https://docs.puppet.com/puppet/4.4/reference/ssl_autosign.html</a></p>

<p>agent执行同步命令每次都要指定server很麻烦，可以修改 puppet.conf 配置，每次执行是从配置文件读取：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 plugins]# vi /etc/puppetlabs/puppet/puppet.conf 
</span><span class='line'>...
</span><span class='line'>[agent]
</span><span class='line'>server = cu2.eshore.cn
</span><span class='line'>certname = cu2.eshore.cn  # 主机名不确定情况下，可以通过这个来指定当前机器的主机名！！每台机器根据主机单独设置！
</span></code></pre></td></tr></table></div></figure>


<h1>命令合集</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>puppet agent --server cu2.eshore.cn --test
</span><span class='line'>
</span><span class='line'>puppet cert list -all
</span><span class='line'>
</span><span class='line'>puppet node clean cu1.ds.ctyun 
</span><span class='line'>puppet cert clean cu2.ds.ctyun
</span><span class='line'>puppet certificate_request destroy cu1.ds.ctyun
</span><span class='line'>
</span><span class='line'>puppet cert sign cu1.eshore.cn
</span><span class='line'>puppet cert sign --all
</span><span class='line'>
</span><span class='line'>puppet config print certname
</span><span class='line'>puppet master --configprint ssldir
</span><span class='line'>puppet agent --configprint ssldir
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Alluxio入门大全2]]></title>
    <link href="http://winseliu.com/blog/2016/04/15/alluxio-quickstart2/"/>
    <updated>2016-04-15T00:41:12+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/15/alluxio-quickstart2</id>
    <content type="html"><![CDATA[<p>alluxio就是原来的tachyon。老大是华人，文档自然就有福利，把en改成cn就可以查看中文版的文档了。</p>

<p><a href="http://alluxio.org/documentation/master/cn/Architecture.html">http://alluxio.org/documentation/master/cn/Architecture.html</a></p>

<p>注意：docker暂时不能部署alluxio： <strong>mount: permission denied</strong></p>

<p>首先介绍alluxio的编译，然后进行本地和集群两种方式的部署，同时介绍HDFS底层存储系统配置和一些常用命令行的使用，最后通过代码和spark读写Alluxio数据，以及升级到V1.1查看系统的Metrics指标来了解存储系统使用情况。</p>

<p>回头看：Alluxio启动时会挂载一个Mem内存盘，其实可以把内存盘路径指定到 /dev/shm 。其他操作就很简单了，也不需要root权限。</p>

<h1>编译</h1>

<ul>
<li><a href="http://alluxio.org/documentation/master/en/Building-Alluxio-Master-Branch.html">http://alluxio.org/documentation/master/en/Building-Alluxio-Master-Branch.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Alluxio-Locally.html">http://alluxio.org/documentation/master/en/Running-Alluxio-Locally.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Alluxio-on-a-Cluster.html">http://alluxio.org/documentation/master/en/Running-Alluxio-on-a-Cluster.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 下载官网打包的bin.tar.gz。不推荐去github下v1.0.1，编译时findbug检查server有两个bug
</span><span class='line'>http://alluxio.org/downloads/files/1.0.1/alluxio-1.0.1-bin.tar.gz
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ cd ~/sources/alluxio-1.0.1/
</span><span class='line'>[hadoop@cu2 alluxio-1.0.1]$ export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"
</span><span class='line'>[hadoop@cu2 alluxio-1.0.1]$ mvn clean package assembly:single -Phadoop-2.6 -Dhadoop.version=2.6.3 -Pyarn,spark -Dmaven.test.skip=true -Dmaven.javadoc.skip=true
</span></code></pre></td></tr></table></div></figure>


<p>编译成功后会生成 assembly/target/alluxio-1.0.1.tar.gz 文件。部署的时刻直接用编译好的 tar.gz 就行了，内容比较简洁和清晰。</p>

<p>还有一个问题，不要加Profile <strong>compileJsp</strong> ，编译没问题但是部署后访问网页抛 ClassNotFound 异常。</p>

<p>windows alluxio-1.1-snapshot 编译需要注意下。打包 assembly 的时刻换行符没有格式化，还有 mvn 编译时需要用到 test 项目(改成skipTests)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git diff assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>diff --git a/assembly/src/main/assembly/alluxio-dist.xml b/assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>index 14ecd19..06ddd51 100644
</span><span class='line'>--- a/assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>+++ b/assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>@@ -11,6 +11,7 @@
</span><span class='line'>       &lt;outputDirectory&gt;/bin&lt;/outputDirectory&gt;
</span><span class='line'>       &lt;fileMode&gt;0755&lt;/fileMode&gt;
</span><span class='line'>       &lt;directoryMode&gt;0755&lt;/directoryMode&gt;
</span><span class='line'>+      &lt;lineEnding&gt;unix&lt;/lineEnding&gt;
</span><span class='line'>     &lt;/fileSet&gt;
</span><span class='line'>     &lt;fileSet&gt;
</span><span class='line'>       &lt;directory&gt;${basedir}/../conf&lt;/directory&gt;
</span><span class='line'>@@ -19,6 +20,7 @@
</span><span class='line'>     &lt;fileSet&gt;
</span><span class='line'>       &lt;directory&gt;${basedir}/../libexec&lt;/directory&gt;
</span><span class='line'>       &lt;outputDirectory&gt;/libexec&lt;/outputDirectory&gt;
</span><span class='line'>+      &lt;lineEnding&gt;unix&lt;/lineEnding&gt;
</span><span class='line'>     &lt;/fileSet&gt;
</span><span class='line'>     &lt;fileSet&gt;
</span><span class='line'>       &lt;directory&gt;${basedir}/..&lt;/directory&gt;
</span><span class='line'>
</span><span class='line'>E:\git\alluxio&gt;set MAVEN_OPTS="-Xmx2g"
</span><span class='line'>E:\git\alluxio&gt;mvn clean package assembly:single -Phadoop-2.6 -Dhadoop.version=2.6.3 -Pyarn,spark -DskipTests -Dmaven.javadoc.skip=true</span></code></pre></td></tr></table></div></figure>


<h1>Local部署配置</h1>

<p><a href="http://alluxio.org/documentation/master/cn/Running-Alluxio-Locally.html">http://alluxio.org/documentation/master/cn/Running-Alluxio-Locally.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ tar zxf alluxio-1.0.1.tar.gz  
</span><span class='line'>[hadoop@hadoop-master2 ~]$ cd alluxio-1.0.1/conf/
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp alluxio-env.sh.template alluxio-env.sh
</span><span class='line'>[hadoop@hadoop-master2 conf]$ vi alluxio-env.sh
</span><span class='line'>...
</span><span class='line'>JAVA_HOME=/opt/jdk1.7.0_60
</span><span class='line'>ALLUXIO_UNDERFS_ADDRESS=/home/hadoop/tmp
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cd ..
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
</span><span class='line'>Connecting to localhost as hadoop...
</span><span class='line'>Formatting Alluxio Worker @ hadoop-master2
</span><span class='line'>Connection to localhost closed.
</span><span class='line'>Formatting Alluxio Master @ localhost
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ 
</span><span class='line'>
</span><span class='line'># 把hadoop用户加入sudo
</span><span class='line'>[root@hadoop-master2 ~]# visudo 
</span><span class='line'>...
</span><span class='line'>hadoop        ALL=(ALL)       NOPASSWD: ALL
</span><span class='line'>
</span><span class='line'># 机器原来部署过hadoop，localhost已经可以无密钥登录。
</span><span class='line'>
</span><span class='line'># 启动
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh local
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Connecting to localhost as hadoop...
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Connection to localhost closed.
</span><span class='line'>Formatting RamFS: /mnt/ramdisk (1gb)
</span><span class='line'>Starting master @ localhost. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>Starting worker @ hadoop-master2. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ 
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ jps
</span><span class='line'>3780 AlluxioMaster
</span><span class='line'>3845 Jps
</span><span class='line'>3807 AlluxioWorker
</span><span class='line'>
</span><span class='line'># localhost:19999 通过web页查看集群状态
</span><span class='line'>
</span><span class='line'># 关闭
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-stop.sh all
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Connecting to localhost as hadoop...
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Connection to localhost closed.</span></code></pre></td></tr></table></div></figure>


<p>这里完全安装官网的步骤来弄，正式环境的时刻可以用 root 来 mount 内存盘。下面集群部署再介绍。</p>

<p><img src="http://winseliu.com/images/blogs/alluxio-local.png" alt="" /></p>

<h1>集群部署</h1>

<ul>
<li><a href="http://alluxio.org/documentation/master/cn/Running-Alluxio-on-a-Cluster.html">http://alluxio.org/documentation/master/cn/Running-Alluxio-on-a-Cluster.html</a></li>
<li>HA <a href="http://alluxio.org/documentation/master/en/Running-Alluxio-Fault-Tolerant.html">http://alluxio.org/documentation/master/en/Running-Alluxio-Fault-Tolerant.html</a></li>
</ul>


<p>步骤和Local类似。把程序部署到workers节点，所有workers节点都 mount 内存盘，然后调用 start.sh 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master 和 workers 的无密钥登录。部署过apache-hadoop的肯定都已经弄过了
</span><span class='line'>
</span><span class='line'># 修改配置
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/workers 
</span><span class='line'>bigdata1
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/alluxio-env.sh
</span><span class='line'>ALLUXIO_MASTER_ADDRESS=hadoop-master2
</span><span class='line'>
</span><span class='line'># 部署程序
</span><span class='line'># bin/alluxio copyDir &lt;dirname&gt; 慎用，会把logs目录也同步过去的，
</span><span class='line'># 当然可以修改alluxio的脚本，反正要知道脚本的作用
</span><span class='line'>[hadoop@hadoop-master2 ~]$ rsync -az alluxio-1.0.1 bigdata1:~/ --exclude=logs --exclude=/*/src --exclude=underfs --exclude=journal
</span><span class='line'>
</span><span class='line'># 使用root用户挂载(workers)节点的内存盘
</span><span class='line'># 当然还有最简单的方式，直接把 ALLUXIO_RAM_FOLDER=/dev/shm 指定到系统的tmpfs，系统的tmpfs其实也主要用的是内存。
</span><span class='line'># 变量 ALLUXIO_WORKER_MEMORY_SIZE=512MB 修改内存盘的大小，小于 /dev/shm 的空间大小。
</span><span class='line'>[root@hadoop-master2 ~]# cd /home/hadoop/alluxio-1.0.1
</span><span class='line'>[root@hadoop-master2 alluxio-1.0.1]# bin/alluxio-mount.sh Mount workers
</span><span class='line'>Connecting to bigdata1 as root...
</span><span class='line'>Warning: Permanently added 'bigdata1,192.168.191.133' (RSA) to the list of known hosts.
</span><span class='line'>Formatting RamFS: /mnt/ramdisk (1gb)
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>
</span><span class='line'># worker节点确认
</span><span class='line'>[hadoop@bigdata1 ~]$ mount
</span><span class='line'>/dev/mapper/VolGroup-lv_root on / type ext4 (rw)
</span><span class='line'>proc on /proc type proc (rw)
</span><span class='line'>sysfs on /sys type sysfs (rw)
</span><span class='line'>devpts on /dev/pts type devpts (rw,gid=5,mode=620)
</span><span class='line'>tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
</span><span class='line'>/dev/sda1 on /boot type ext4 (rw)
</span><span class='line'>none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
</span><span class='line'>ramfs on /mnt/ramdisk type ramfs (rw,size=1gb)
</span><span class='line'>
</span><span class='line'># 格式化：主要是清理/创建JOURNAL目录，清理workers本地缓存(tiered-storage)目录数据
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
</span><span class='line'>Connecting to bigdata1 as hadoop...
</span><span class='line'>Formatting Alluxio Worker @ bigdata1
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>Formatting Alluxio Master @ localhost
</span><span class='line'>
</span><span class='line'># 启动
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh all NoMount
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Connecting to bigdata1 as hadoop...
</span><span class='line'>Killed 0 processes on bigdata1
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>Starting master @ localhost. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>Connecting to bigdata1 as hadoop...
</span><span class='line'>Starting worker @ bigdata1. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ jps
</span><span class='line'>5164 AlluxioMaster
</span><span class='line'>5219 Jps
</span><span class='line'>
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ jps
</span><span class='line'>1849 Jps
</span><span class='line'>1829 AlluxioWorker
</span></code></pre></td></tr></table></div></figure>


<p>通过网页查看，如果 <strong>Running Workers</strong> 为 <strong>0</strong> ，到workers节点 alluxio-1.0.1/logs 下面去看日志然后定位问题。防火墙没开放？还是其他配置不正确，如hosts等等。</p>

<h1>命令行HelloWorld</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs copyFromLocal conf/alluxio-env.sh /
</span><span class='line'>Copied conf/alluxio-env.sh to /
</span><span class='line'>
</span><span class='line'># worker节点查看内容（当前只有这一个文件啊，查看方便），block-id可以通过网页或者 fs fileInfo查看
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ tail -1 /mnt/ramdisk/alluxioworker/117440512 
</span><span class='line'>export ALLUXIO_WORKER_JAVA_OPTS="${ALLUXIO_JAVA_OPTS}"
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 在master机器上调用 persist ，在worker节点没找到对应的数据。竟然直接存储在执行命令的节点了，囧！！！
</span><span class='line'># alluxio.client.file.FileSystemUtils#persistFile
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs persist /alluxio-env.sh
</span><span class='line'>persisted file /alluxio-env.sh with size 5493
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ ll /home/hadoop/tmp/
</span><span class='line'>total 28
</span><span class='line'>-rwxrwxrwx  1 hadoop hadoop 5493 Apr 15 03:33 alluxio-env.sh
</span><span class='line'>
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ bin/alluxio fs persist /alluxio-env.sh
</span><span class='line'>/alluxio-env.sh is already persisted
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ ll /home/hadoop/tmp
</span><span class='line'>总用量 0</span></code></pre></td></tr></table></div></figure>


<p>在master调用 persist 后，再在worker节点调用 persist 竟然提示 <strong>already persisted</strong> 了。如果在分布式的情况下，本地磁盘 <strong>不适合</strong> 用于做 underfs ！！官网也是说 <strong>单节点</strong> <strong>本地文件系统</strong>。</p>

<blockquote><p>Alluxio提供了通用接口以简化插入不同的底层存储系统。目前我们支持Amazon S3，OpenStack Swift，Apache HDFS，GlusterFS以及单节点本地文件系统</p></blockquote>

<h1>使用HDFS作为底层存储</h1>

<p><a href="http://alluxio.org/documentation/master/en/Configuring-Alluxio-with-HDFS.html">http://alluxio.org/documentation/master/en/Configuring-Alluxio-with-HDFS.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/alluxio-env.sh
</span><span class='line'>...
</span><span class='line'>JAVA_HOME=/opt/jdk1.7.0_60
</span><span class='line'>HADOOP_HOME=/home/hadoop/hadoop-2.6.3
</span><span class='line'>
</span><span class='line'># source $HADOOP_HOME/libexec/hadoop-config.sh
</span><span class='line'>JAVA_LIBRARY_PATH="$HADOOP_HOME/lib/native"
</span><span class='line'>ALLUXIO_JAVA_OPTS="$ALLUXIO_JAVA_OPTS -Djava.library.path=$JAVA_LIBRARY_PATH"
</span><span class='line'>LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$JAVA_LIBRARY_PATH
</span><span class='line'>
</span><span class='line'>ALLUXIO_CLASSPATH=$HADOOP_HOME/etc/hadoop:$ALLUXIO_CLASSPATH
</span><span class='line'>ALLUXIO_UNDERFS_ADDRESS=hdfs:///alluxio                       # 配置一个alluxio子路径比较好管理
</span><span class='line'>ALLUXIO_MASTER_ADDRESS=hadoop-master2
</span><span class='line'>
</span><span class='line'># 清理/创建元数据目录和workers节点本地缓冲存储的数据
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh master
</span><span class='line'>
</span><span class='line'># master启动正常后，启动workers节点
</span><span class='line'># 上面已经用root mount了内存盘了，没有的用root执行 bin/alluxio-mount.sh Mount workers
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh workers NoMount</span></code></pre></td></tr></table></div></figure>


<ul>
<li>使用</li>
</ul>


<p><a href="http://alluxio.org/documentation/master/en/Command-Line-Interface.html">http://alluxio.org/documentation/master/en/Command-Line-Interface.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs copyFromLocal  ~/hadoop-2.6.3/README.txt /
</span><span class='line'>Copied /home/hadoop/hadoop-2.6.3/README.txt to /
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs location /README.txt
</span><span class='line'>/README.txt with file id 33554431 is on nodes: 
</span><span class='line'>bigdata1
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs persist /README.txt
</span><span class='line'>/README.txt is already persisted
</span><span class='line'>
</span><span class='line'># 默认文件只写到 Cache ，可以修改配置来进行修改
</span><span class='line'># alluxio.client.WriteType
</span><span class='line'>[hadoop@hadoop-master2 alluxio]$ export ALLUXIO_JAVA_OPTS="-Dalluxio.user.file.writetype.default=CACHE_THROUGH"
</span><span class='line'>[hadoop@hadoop-master2 alluxio]$ bin/alluxio fs copyFromLocal ~/hadoop-2.6.3/README.txt /                      
</span><span class='line'>Copied /home/hadoop/hadoop-2.6.3/README.txt to /
</span><span class='line'>[hadoop@hadoop-master2 alluxio]$ bin/alluxio fs fileInfo /README.txt                                           
</span><span class='line'>FileInfo{fileId=452984831, name=README.txt, path=/README.txt, ufsPath=hdfs:///alluxio/README.txt, length=1366, blockSizeBytes=536870912, creationTimeMs=1460765370996, completed=true, folder=false, pinned=false, cacheable=true, persisted=true, blockIds=[436207616], inMemoryPercentage=100, lastModificationTimesMs=1460765372423, ttl=-1, userName=, groupName=, permission=0, persistenceState=PERSISTED, mountPoint=false}
</span><span class='line'>Containing the following blocks: 
</span><span class='line'>BlockInfo{id=436207616, length=1366, locations=[BlockLocation{workerId=1, address=WorkerNetAddress{host=bigdata1, rpcPort=29998, dataPort=29999, webPort=30000}, tierAlias=MEM}]}
</span><span class='line'>
</span><span class='line'># Creates a 0 byte file. The file will be written to the under file system. 
</span><span class='line'># For example, touch can be used to create a file signifying the compeletion of analysis on a directory.
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs touch /1234.txt    
</span><span class='line'>/1234.txt has been created
</span><span class='line'>
</span><span class='line'># 已经persist的文件，重命名后，hdfs上面的文件也立即改变了
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs mv /1234.txt /4321.txt
</span><span class='line'>Renamed /1234.txt to /4321.txt
</span><span class='line'>
</span><span class='line'># 空文件没有分配实际的存储，只有元数据
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs location /4321.txt    
</span><span class='line'>/4321.txt with file id 67108863 is on nodes: 
</span><span class='line'>
</span><span class='line'># free掉memory，然后删掉underfs目录下的文件
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs free /
</span><span class='line'>/ was successfully freed from memory.
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs dfs -rmr /alluxio/*
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /  
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  Not In Memory  /README.txt
</span><span class='line'>0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs tail /README.txt
</span><span class='line'>File does not exist: /alluxio/README.txt
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:66)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1893)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1834)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1814)
</span><span class='line'>
</span><span class='line'># 按照文件名把 README.txt 放到 underfs 目录下面
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs dfs -put *.txt /alluxio/ 
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs tail /README.txt
</span><span class='line'>...
</span><span class='line'>software:
</span><span class='line'>  Hadoop Core uses the SSL libraries from the Jetty project written 
</span><span class='line'>by mortbay.org.
</span><span class='line'>
</span><span class='line'># 数据载入内存
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs load /
</span><span class='line'>/README.txt loaded
</span><span class='line'>/ loaded
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /  
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
</span><span class='line'>0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
</span><span class='line'>
</span><span class='line'># 载入underfs的目录结构
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio loadufs / hdfs:///alluxio 
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
</span><span class='line'>0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
</span><span class='line'>15.07KB   04-15-2016 10:12:33:176  Not In Memory  /LICENSE.txt
</span><span class='line'>101.00B   04-15-2016 10:12:33:190  Not In Memory  /NOTICE.txt
</span><span class='line'>
</span><span class='line'># 通过 fileInfo 查看信息； fileId, ufsPath, 和分区blocks信息
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs fileInfo /README.txt
</span><span class='line'>
</span><span class='line'># 通配符要这么写，也是醉鸟
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs rm /\\*
</span><span class='line'>/4321.txt has been removed
</span><span class='line'>/LICENSE.txt has been removed
</span><span class='line'>/NOTICE.txt has been removed
</span><span class='line'>/README.md has been removed
</span><span class='line'>/README.txt has been removed
</span><span class='line'>
</span><span class='line'># alluxio系统中没有的文件，但是underfs包括的文件，读取一遍后元数据会载入alluxio
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs ls /
</span><span class='line'>1366.00B  04-16-2016 08:09:30:996  In Memory      /README.txt
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs cat /LICENSE.txt
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs ls /
</span><span class='line'>1366.00B  04-16-2016 08:09:30:996  In Memory      /README.txt
</span><span class='line'>15.07KB   04-16-2016 08:26:22:495  Not In Memory  /LICENSE.txt</span></code></pre></td></tr></table></div></figure>


<p>文件结构大概搞明白了，从 underfs 加载目录结构(loadufs)，文件载入alluxio内存(fs load)，alluxio文件持久化(fs persist)都有对应的命令。
理解 <a href="http://alluxio.org/documentation/master/en/Unified-and-Transparent-Namespace.html">mount</a> 和linux的mount类似，把 underfs 当做一个硬盘设备去理解。</p>

<p>但是好像没有修改文件的API，难道不支持修改？？暂时好像没有(2016-4-15 23:06:20 v1.1)</p>

<blockquote><p><a href="http://alluxio.org/documentation/master/en/Key-Value-System-API.html">http://alluxio.org/documentation/master/en/Key-Value-System-API.html</a>
Like files in Alluxio filesystem, the semantics of key-value system are also write-once</p></blockquote>

<h1>FileSystem API</h1>

<ul>
<li><a href="http://docs.scala-lang.org/tutorials/scala-with-maven.html">http://docs.scala-lang.org/tutorials/scala-with-maven.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/File-System-API.html">http://alluxio.org/documentation/master/en/File-System-API.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># scala
</span><span class='line'>object App {
</span><span class='line'>
</span><span class='line'>  def using[A &lt;: {def close() : Unit}, B](resource: A)(f: A =&gt; B): B =
</span><span class='line'>    try { f(resource) } finally { resource.close() }
</span><span class='line'>
</span><span class='line'>  def main(args: Array[String]) {
</span><span class='line'>    // @see alluxio.Configuration.Configuration(boolean)
</span><span class='line'>    System.setProperty(Constants.MASTER_HOSTNAME, "192.168.191.132")
</span><span class='line'>    System.setProperty("HADOOP_USER_NAME", "hadoop")
</span><span class='line'>
</span><span class='line'>    val fs = FileSystem.Factory.get();
</span><span class='line'>    val path = new AlluxioURI("/README.md");
</span><span class='line'>    using(fs.createFile(path, CreateFileOptions.defaults().setWriteType(WriteType.THROUGH))){ out =&gt;
</span><span class='line'>      val content =
</span><span class='line'>"""FileSystem API Write.
</span><span class='line'>   -------------------------
</span><span class='line'>   Hello World!
</span><span class='line'>"""
</span><span class='line'>      out.write(content.getBytes)
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    using(fs.openFile(path)) { in =&gt;
</span><span class='line'>      val buffer = new Array[Byte](1024)
</span><span class='line'>      val size = in.read(buffer)
</span><span class='line'>      System.out.println(new String(buffer, 0, size))
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># THROUGH 仅写入到underfs
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /README.md
</span><span class='line'>115.00B   04-15-2016 20:36:57:345  Not In Memory  /README.md
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ ~/hadoop-2.6.3/bin/hadoop fs -cat /alluxio/README.md
</span><span class='line'>FileSystem API Write.
</span><span class='line'>   -------------------------
</span><span class='line'>   Hello World!
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ </span></code></pre></td></tr></table></div></figure>


<p>程序在win10系统运行，需要把 core-site.xml 加到 src/main/resources 下面（前面配置为了省事直接写 <strong>hdfs:///alluxio</strong>, 不加载配置的话程序不知道namenode）</p>

<p>如果<strong>把WriteType设置为 CACHE_THROUGH ，写 underfs 的同时也会写本地缓存</strong>。提交成功后，文件的状态为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs ls /README.md
</span><span class='line'>115.00B   04-15-2016 23:48:33:749  In Memory      /README.md
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs fileInfo /README.md
</span><span class='line'>FileInfo{fileId=318767103, name=README.md, path=/README.md, ufsPath=hdfs:///alluxio/README.md, length=115, blockSizeBytes=536870912, creationTimeMs=1460735313749, completed=true, folder=false, pinned=false, cacheable=true, persisted=true, blockIds=[301989888], inMemoryPercentage=100, lastModificationTimesMs=1460735315749, ttl=-1, userName=, groupName=, permission=0, persistenceState=PERSISTED, mountPoint=false}
</span><span class='line'>Containing the following blocks: 
</span><span class='line'>BlockInfo{id=301989888, length=115, locations=[BlockLocation{workerId=1, address=WorkerNetAddress{host=bigdata1, rpcPort=29998, dataPort=29999, webPort=30000}, tierAlias=MEM}]}
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ ~/hadoop-2.6.3/bin/hadoop fs -ls /alluxio/ 
</span><span class='line'>Found 4 items
</span><span class='line'>-rw-r--r--   1 hadoop supergroup      15429 2016-04-15 09:57 /alluxio/LICENSE.txt
</span><span class='line'>-rw-r--r--   1 hadoop supergroup        101 2016-04-15 09:57 /alluxio/NOTICE.txt
</span><span class='line'>-rwxrwxrwx   1 hadoop supergroup        115 2016-04-15 23:48 /alluxio/README.md</span></code></pre></td></tr></table></div></figure>


<h1>大数据程序中使用Alluxio</h1>

<p>hadoop2通过 <code>org.apache.hadoop.fs.FileSystem</code> services获取绑定的对象，所以<strong>不需要</strong>在core-site.xml里面配置 <strong>fs.alluxio.impl</strong> 和 <strong>fs.alluxio-ft.impl</strong></p>

<ul>
<li><a href="http://alluxio.org/documentation/master/en/Running-Spark-on-Alluxio.html">http://alluxio.org/documentation/master/en/Running-Spark-on-Alluxio.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Hadoop-MapReduce-on-Alluxio.html">http://alluxio.org/documentation/master/en/Running-Hadoop-MapReduce-on-Alluxio.html</a></li>
</ul>


<p>其实都是通过 <strong>Hadoop FileSystem API</strong> 来访问Alluxio的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># .bash_profile加环境变量
</span><span class='line'>[hadoop@hadoop-master2 ~]$ vi ~/.bash_profile 
</span><span class='line'>...
</span><span class='line'>HADOOP_HOME=~/hadoop
</span><span class='line'>SPARK_HOME=~/spark
</span><span class='line'>ALLUXIO_HOME=~/alluxio
</span><span class='line'>
</span><span class='line'>PATH=$HADOOP_HOME/bin:$SPARK_HOME/bin:$ALLUXIO_HOME/bin:$MAVEN_HOME/bin:$ANT_HOME/bin:$PATH
</span><span class='line'># 这里没有 export HADOOP_HOME SPARK_HOME 
</span><span class='line'># 因为在hadoop/spark的启动脚本也定义了这些变量。如果export，也需要把软链接同步到slaves节点
</span><span class='line'>export PATH ANT_HOME MAVEN_HOME
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s hadoop-2.6.3 hadoop
</span><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s alluxio-1.1.0-SNAPSHOT alluxio
</span><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s spark-1.6.0-bin-2.6.3 spark
</span><span class='line'>[hadoop@hadoop-master2 ~]$ . .bash_profile 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ export SPARK_CLASSPATH=\
</span><span class='line'>&gt; ~/alluxio/core/client/target/alluxio-core-client-1.1.0-SNAPSHOT-jar-with-dependencies.jar 
</span><span class='line'>[hadoop@hadoop-master2 ~]$ 
</span><span class='line'>[hadoop@hadoop-master2 ~]$ spark-shell --master local
</span><span class='line'>scala&gt; val file=sc.textFile("alluxio://hadoop-master2:19998/README.txt")
</span><span class='line'>file: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:27
</span><span class='line'>
</span><span class='line'>scala&gt; file.count()
</span><span class='line'>res0: Long = 31
</span><span class='line'>
</span><span class='line'>scala&gt; file.take(2)
</span><span class='line'>res1: Array[String] = Array(For the latest information about Hadoop, please visit our website at:, "")
</span><span class='line'>
</span><span class='line'># wordcount
</span><span class='line'>scala&gt; val op = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)
</span><span class='line'># word sort asc
</span><span class='line'>scala&gt; op.sortByKey().take(10)
</span><span class='line'># count sort desc
</span><span class='line'>scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).take(10)
</span><span class='line'>
</span><span class='line'>scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).saveAsTextFile("alluxio://hadoop-master2:19998/output/")
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs cat /output/*
</span><span class='line'>(,18)
</span><span class='line'>(the,8)
</span><span class='line'>(and,6)
</span><span class='line'>(of,5)
</span><span class='line'>(The,4)
</span><span class='line'>(this,3)
</span><span class='line'>(encryption,3)
</span><span class='line'>(for,3)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>如果运行在集群，在slave的节点也需要与主节点一样的目录结构。 或者按照<a href="http://spark.apache.org/docs/latest/programming-guide.html#using-the-shell">官网的教程</a>操作。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># spark_classpath 会被带到 task 的启动环境变量里面
</span><span class='line'>[hadoop@hadoop-master2 ~]$ rsync -az alluxio bigdata1:~/
</span><span class='line'>[hadoop@hadoop-master2 ~]$ export SPARK_CLASSPATH=\
</span><span class='line'>&gt; ~/alluxio/core/client/target/alluxio-core-client-1.1.0-SNAPSHOT-jar-with-dependencies.jar
</span><span class='line'> 
</span><span class='line'>[hadoop@hadoop-master2 ~]$ spark-shell --master spark://hadoop-master2:7077
</span><span class='line'>scala&gt; val file=sc.textFile("alluxio://hadoop-master2:19998/README.txt")
</span><span class='line'>file: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:27
</span><span class='line'>
</span><span class='line'>scala&gt; val op = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)
</span><span class='line'>op: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:29
</span><span class='line'>
</span><span class='line'>scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).saveAsTextFile("alluxio://hadoop-master2:19998/output2/")
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/alluxio-spark-word-count.png" alt="" /></p>

<h1>Metrics</h1>

<p><a href="http://www.alluxio.org/documentation/master/cn/Metrics-System.html">http://www.alluxio.org/documentation/master/cn/Metrics-System.html</a></p>

<p>v1.0.1有对应的api，可以通过 <a href="http://hadoop-master2:19999/metrics/json/">http://hadoop-master2:19999/metrics/json/</a> 查看。当前master主干分支v1.1.0可以在网页上面查看这些指标。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 拷贝配置
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ cd conf
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/alluxio-env.sh ./
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/log4j.properties ./
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/workers ./ 
</span><span class='line'>
</span><span class='line'># 启动master（使用原来的元数据）
</span><span class='line'># 共享元数据，在 alluxio-env.sh 修改环境变量 ALLUXIO_JAVA_OPTS 
</span><span class='line'># 添加 -Dalluxio.master.journal.folder=${ALLUXIO_JOURNAL_FOLDER} / ALLUXIO_JOURNAL_FOLDER=/home/hadoop/journal
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio-start.sh master
</span><span class='line'>Starting master @ hadoop-master2. Logging to /home/hadoop/alluxio-1.1.0-SNAPSHOT/logs</span></code></pre></td></tr></table></div></figure>


<p>v1.1.0 页面多了 Metrics 页签：</p>

<p><img src="http://winseliu.com/images/blogs/alluxio-metrics.png" alt="" /></p>

<h1>其他文档</h1>

<ul>
<li>配置alluxio-default.properties <a href="http://alluxio.org/documentation/master/en/Configuration-Settings.html">http://alluxio.org/documentation/master/en/Configuration-Settings.html</a></li>
<li>分层本地缓存 <a href="http://alluxio.org/documentation/master/en/Tiered-Storage-on-Alluxio.html">http://alluxio.org/documentation/master/en/Tiered-Storage-on-Alluxio.html</a></li>
<li><a href="https://dzone.com/articles/Accelerate-In-Memory-Processing-with-Spark-from-Hours-to-Seconds-With-Tachyon">https://dzone.com/articles/Accelerate-In-Memory-Processing-with-Spark-from-Hours-to-Seconds-With-Tachyon</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hiveserver2 Ui and Upgrade hive2.0.0]]></title>
    <link href="http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0/"/>
    <updated>2016-04-13T12:03:43+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0</id>
    <content type="html"><![CDATA[<p>升级hive的标准动作：</p>

<ul>
<li>更新metadata，就是执行sql语句。更新前先备份原来的库！！</li>
<li>调整依赖，我这里是升级spark，编译参考<a href="http://winseliu.com/blog/2016/03/28/hive-on-spark/">spark-without-hive</a></li>
<li>修改参数(hive/spark/hadoop)来适应新版本</li>
<li>hiveserver2 ui：启动hiveserver2服务，访问10002端口即可。<a href="https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-WebUIforHiveServer2">UI配置</a></li>
</ul>


<p>环境说明：</p>

<ul>
<li>centos5</li>
<li>hadoop-2.6.3</li>
<li>spark-1.6.0-without-hive</li>
<li>hive-2.0.0</li>
</ul>


<h2>操作详情</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 备份
</span><span class='line'>[hadoop@file1 tools]$ mysqldump -uroot -p hive &gt;hive1.2.1-20160413.backup.sql
</span><span class='line'>
</span><span class='line'># 准备好程序后的目录结构
</span><span class='line'>[hadoop@file1 ~]$ ll
</span><span class='line'>总计 20
</span><span class='line'>drwxrwxr-x 3 hadoop hadoop 4096 04-13 11:59 collect
</span><span class='line'>drwx------ 3 hadoop hadoop 4096 04-07 16:43 dfs
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   18 04-11 10:09 hadoop -&gt; tools/hadoop-2.6.3
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   40 04-13 10:26 hive -&gt; /home/hadoop/tools/apache-hive-2.0.0-bin
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   42 04-13 10:52 spark -&gt; tools/spark-1.6.0-bin-hadoop2-without-hive
</span><span class='line'>drwxrwxr-x 6 hadoop hadoop 4096 04-13 12:10 tmp
</span><span class='line'>drwxrwxr-x 9 hadoop hadoop 4096 04-13 11:48 tools
</span><span class='line'>[hadoop@file1 tools]$ ll
</span><span class='line'>总计 84
</span><span class='line'>drwxrwxr-x  8 hadoop hadoop  4096 04-08 09:25 apache-hive-1.2.1-bin
</span><span class='line'>drwxrwxr-x  8 hadoop hadoop  4096 04-13 10:16 apache-hive-2.0.0-bin
</span><span class='line'>drwxr-xr-x 11 hadoop hadoop  4096 04-07 16:34 hadoop-2.6.3
</span><span class='line'>-rw-rw-r--  1 hadoop hadoop 46879 04-13 10:11 hive1.2.1-20160413.backup.sql
</span><span class='line'>drwxrwxr-x  2 hadoop hadoop  4096 03-31 15:28 mysql
</span><span class='line'>lrwxrwxrwx  1 hadoop hadoop    36 04-13 10:17 spark -&gt; spark-1.6.0-bin-hadoop2-without-hive
</span><span class='line'>drwxrwxr-x 11 hadoop hadoop  4096 04-07 18:23 spark-1.3.1-bin-hadoop2.6.3-without-hive
</span><span class='line'>drwxrwxr-x 11 hadoop hadoop  4096 03-28 11:15 spark-1.6.0-bin-hadoop2-without-hive
</span><span class='line'>drwxr-xr-x 11 hadoop hadoop  4096 03-31 16:14 zookeeper-3.4.6
</span><span class='line'>
</span><span class='line'># 环境变量我直接加载的是link软链接的，我这直接修改软链就行了。根据情况调整。
</span><span class='line'># apache-hive-2.0.0-bin同级目录建立spark软链接，或者再hive-env.sh中指定SPARK_HOME的位置
</span><span class='line'>
</span><span class='line'># hive-1.2.1并没有txn的表，所有要单独执行下hive-txn-schema-2.0.0.mysql.sql，
</span><span class='line'># 然后再更新（后面的Duplicate column的错没问题的）
</span><span class='line'>[hadoop@file1 tools]$ cd apache-hive-2.0.0-bin/scripts/metastore/upgrade/mysql/
</span><span class='line'>[hadoop@file1 mysql]$ mysql -uroot -p
</span><span class='line'>Enter password: 
</span><span class='line'>Welcome to the MySQL monitor.  Commands end with ; or \g.
</span><span class='line'>Your MySQL connection id is 10765
</span><span class='line'>Server version: 5.5.48 MySQL Community Server (GPL)
</span><span class='line'>
</span><span class='line'>Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.
</span><span class='line'>
</span><span class='line'>Oracle is a registered trademark of Oracle Corporation and/or its
</span><span class='line'>affiliates. Other names may be trademarks of their respective
</span><span class='line'>owners.
</span><span class='line'>
</span><span class='line'>Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
</span><span class='line'>
</span><span class='line'>mysql&gt; use hive;
</span><span class='line'>Reading table information for completion of table and column names
</span><span class='line'>You can turn off this feature to get a quicker startup with -A
</span><span class='line'>
</span><span class='line'>Database changed
</span><span class='line'>mysql&gt; source hive-txn-schema-2.0.0.mysql.sql
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.04 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.03 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.04 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.03 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>mysql&gt; source upgrade-1.2.0-to-2.0.0.mysql.sql
</span><span class='line'>+------------------------------------------------+
</span><span class='line'>|                                                |
</span><span class='line'>+------------------------------------------------+
</span><span class='line'>| Upgrading MetaStore schema from 1.2.0 to 2.0.0 |
</span><span class='line'>+------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------------------------------+
</span><span class='line'>|                                                                                                               |
</span><span class='line'>+---------------------------------------------------------------------------------------------------------------+
</span><span class='line'>| &lt; HIVE-7018 Remove Table and Partition tables column LINK_TARGET_ID from Mysql for other DBs do not have it &gt; |
</span><span class='line'>+---------------------------------------------------------------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected, 1 warning (0.03 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>+---------------------------------+
</span><span class='line'>| Completed remove LINK_TARGET_ID |
</span><span class='line'>+---------------------------------+
</span><span class='line'>| Completed remove LINK_TARGET_ID |
</span><span class='line'>+---------------------------------+
</span><span class='line'>1 row in set (0.02 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.02 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 31 rows affected (0.01 sec)
</span><span class='line'>Records: 31  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.05 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.02 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.03 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'CQ_HIGHEST_TXN_ID'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'CQ_META_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'CQ_HADOOP_JOB_ID'
</span><span class='line'>ERROR 1050 (42S01): Table 'COMPLETED_COMPACTIONS' already exists
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'TXN_AGENT_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'TXN_HEARTBEAT_COUNT'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_HEARTBEAT_COUNT'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'TXN_META_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_AGENT_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_BLOCKEDBY_EXT_ID'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_BLOCKEDBY_INT_ID'
</span><span class='line'>ERROR 1050 (42S01): Table 'AUX_TABLE' already exists
</span><span class='line'>Query OK, 1 row affected (0.01 sec)
</span><span class='line'>Rows matched: 1  Changed: 1  Warnings: 0
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------+
</span><span class='line'>|                                                         |
</span><span class='line'>+---------------------------------------------------------+
</span><span class='line'>| Finished upgrading MetaStore schema from 1.2.0 to 2.0.0 |
</span><span class='line'>+---------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'># 拷贝hive原来的配置和依赖jar
</span><span class='line'>
</span><span class='line'>[hadoop@file1 mysql]$ cd ~/tools/apache-hive-2.0.0-bin/conf/
</span><span class='line'>[hadoop@file1 conf]$ cp ~/tools/apache-hive-1.2.1-bin/conf/hive-site.xml ./
</span><span class='line'>[hadoop@file1 conf]$ cp ~/tools/apache-hive-1.2.1-bin/conf/spark-defaults.conf ./
</span><span class='line'>[hadoop@file1 conf]$ cp ~/tools/apache-hive-1.2.1-bin/conf/hive-env.sh ./
</span><span class='line'>
</span><span class='line'># 用到spark需要加大PermSize
</span><span class='line'>[hadoop@file1 hive]$ vi conf/hive-env.sh
</span><span class='line'>export HADOOP_USER_CLASSPATH_FIRST=true
</span><span class='line'>export HADOOP_OPTS="$HADOOP_OPTS -XX:MaxPermSize=256m"
</span><span class='line'>
</span><span class='line'>[hadoop@file1 conf]$ cd ../lib/
</span><span class='line'>[hadoop@file1 lib]$ cp ~/tools/apache-hive-1.2.1-bin/lib/mysql-connector-java-5.1.34.jar ./
</span><span class='line'>
</span><span class='line'># centos5需要删除下面两个jar，centos6没必要删
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ rm lib/hive-jdbc-2.0.0-standalone.jar 
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ rm lib/snappy-java-1.0.5.jar 
</span><span class='line'>
</span><span class='line'># spark-1.6.0更新
</span><span class='line'>
</span><span class='line'># http://spark.apache.org/docs/latest/hadoop-provided.html
</span><span class='line'># http://stackoverflow.com/questions/30906412/noclassdeffounderror-com-apache-hadoop-fs-fsdatainputstream-when-execute-spark-s
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ cd ~/tools/spark-1.6.0-bin-hadoop2-without-hive/conf/
</span><span class='line'>[hadoop@file1 conf]$ cp spark-env.sh.template spark-env.sh
</span><span class='line'>[hadoop@file1 conf]$ vi spark-env.sh
</span><span class='line'>HADOOP_HOME=/home/hadoop/hadoop
</span><span class='line'>SPARK_DIST_CLASSPATH=`$HADOOP_HOME/bin/hadoop classpath`
</span><span class='line'>
</span><span class='line'>[hadoop@file1 ~]$ cp ~/tools/spark-1.6.0-bin-hadoop2-without-hive/lib/spark-1.6.0-yarn-shuffle.jar ~/tools/hadoop-2.6.3/share/hadoop/yarn/
</span><span class='line'>[hadoop@file1 ~]$ rm ~/tools/hadoop-2.6.3/share/hadoop/yarn/spark-1.3.1-yarn-shuffle.jar 
</span><span class='line'>
</span><span class='line'>[hadoop@file1 ~]$ rsync -vaz --delete ~/tools/hadoop-2.6.3/share file2:~/tools/hadoop-2.6.3/ 
</span><span class='line'>[hadoop@file1 ~]$ rsync -vaz --delete ~/tools/hadoop-2.6.3/share file3:~/tools/hadoop-2.6.3/ 
</span><span class='line'>
</span><span class='line'>[hadoop@file1 ~]$ hdfs dfs -put ~/tools/spark-1.6.0-bin-hadoop2-without-hive/lib/spark-assembly-1.6.0-hadoop2.6.3.jar /spark/
</span><span class='line'>
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ vi conf/spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.6.0-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'># 重启yarn（如果你用hiveserver2，先往下看，后面还会修改配置重启的）
</span><span class='line'>
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ cd ~/tools/hadoop-2.6.3/
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/stop-yarn.sh 
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/start-yarn.sh 
</span></code></pre></td></tr></table></div></figure>


<p>更新到这里，执行hive命令是ok了的。但是hiveserver还有问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 启动hiveserver2
</span><span class='line'>[hadoop@file1 hive]$ nohup bin/hiveserver2 &
</span><span class='line'>
</span><span class='line'># 启动spark historyserver
</span><span class='line'>[hadoop@file1 spark]$ cat start-historyserver.sh 
</span><span class='line'>source $HADOOP_HOME/libexec/hadoop-config.sh
</span><span class='line'>sbin/start-history-server.sh hdfs:///spark-eventlogs
</span><span class='line'>
</span><span class='line'>[hadoop@file1 hive]$ bin/beeline -u jdbc:hive2://file1:10000/ -n hadoop -p hadoop
</span><span class='line'>which: no hbase in (/home/hadoop/hadoop/bin:/home/hadoop/hive/bin:/opt/jdk1.7.0_60/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin:/home/hadoop/tools/hadoop-2.6.3/bin:/home/hadoop/tools/hadoop-2.6.3:/home/hadoop/tools/apache-hive-1.2.1-bin:/home/hadoop/bin)
</span><span class='line'>ls: /home/hadoop/hive/lib/hive-jdbc-*-standalone.jar: 没有那个文件或目录
</span><span class='line'>SLF4J: Class path contains multiple SLF4J bindings.
</span><span class='line'>SLF4J: Found binding in [jar:file:/home/hadoop/tools/apache-hive-2.0.0-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
</span><span class='line'>SLF4J: Found binding in [jar:file:/home/hadoop/tools/hadoop-2.6.3/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
</span><span class='line'>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
</span><span class='line'>SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
</span><span class='line'>Connecting to jdbc:hive2://file1:10000/
</span><span class='line'>Error: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: hadoop is not allowed to impersonate hadoop (state=,code=0)
</span><span class='line'>Beeline version 2.0.0 by Apache Hive
</span><span class='line'>beeline&gt; </span></code></pre></td></tr></table></div></figure>


<p>Beeline连接hiveserver2失败，模拟的hadoop用户授权失败。需要修改hadoop的参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://community.hortonworks.com/questions/4905/error-while-running-hive-queries-from-zeppelin.html
</span><span class='line'># http://stackoverflow.com/questions/25073792/error-e0902-exception-occured-user-root-is-not-allowed-to-impersonate-root
</span><span class='line'># core-site.xml添加，并重启集群hdfs & yarn
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/stop-all.sh
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/start-all.sh 
</span><span class='line'>
</span><span class='line'>[hadoop@file1 hive]$ bin/beeline -u jdbc:hive2://file1:10000 -n hadoop -p hadoop
</span><span class='line'>...
</span><span class='line'>0: jdbc:hive2://file1:10000/&gt; set hive.execution.engine=spark;
</span><span class='line'>No rows affected (0.019 seconds)
</span><span class='line'>0: jdbc:hive2://file1:10000/&gt; select count(*) from t_info where edate=20160413;
</span><span class='line'>INFO  : Compiling command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea): select count(*) from t_info where edate=20160413
</span><span class='line'>INFO  : Semantic Analysis Completed
</span><span class='line'>INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:c0, type:bigint, comment:null)], properties:null)
</span><span class='line'>INFO  : Completed compiling command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea); Time taken: 0.523 seconds
</span><span class='line'>INFO  : Executing command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea): select count(*) from t_info where edate=20160413
</span><span class='line'>INFO  : Query ID = hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea
</span><span class='line'>INFO  : Total jobs = 1
</span><span class='line'>INFO  : Launching Job 1 out of 1
</span><span class='line'>INFO  : Starting task [Stage-1:MAPRED] in serial mode
</span><span class='line'>
</span><span class='line'>INFO  : 
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>INFO  : 0
</span><span class='line'>INFO  : 1
</span><span class='line'>INFO  : 
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>INFO  : Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>INFO  : 2016-04-13 11:41:20,519 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:23,577 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:26,817 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:29,858 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:32,903 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:35,942 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:37,969 Stage-0_0: 0(+9)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:38,981 Stage-0_0: 1(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:39,994 Stage-0_0: 3(+7)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:43,030 Stage-0_0: 3(+7)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:45,056 Stage-0_0: 5(+5)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:46,072 Stage-0_0: 6(+4)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:47,085 Stage-0_0: 8(+2)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:48,096 Stage-0_0: 9(+1)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:51,125 Stage-0_0: 9(+1)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:52,134 Stage-0_0: 10/10 Finished       Stage-1_0: 1/1 Finished
</span><span class='line'>INFO  : Status: Finished successfully in 64.78 seconds
</span><span class='line'>INFO  : Completed executing command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea); Time taken: 71.767 seconds
</span><span class='line'>INFO  : OK
</span><span class='line'>+-----------+--+
</span><span class='line'>|    c0     |
</span><span class='line'>+-----------+--+
</span><span class='line'>| 89867722  |
</span><span class='line'>+-----------+--+
</span><span class='line'>1 row selected (72.45 seconds)
</span></code></pre></td></tr></table></div></figure>


<p>本来升级是想看看UI长什么样子，有点失望，功能太少了。只能看当前执行的SQL和session，历史记录不能查看。期待新版本UI更强大。</p>

<p>升级后beeline上下键切换历史的也不起作用了，hive-2.0.0没也啥吸引的功能（<strong>hive2准备淘汰mr了</strong>），觉得不爽可以直接替换 软链 退回hive1.2.1-spark1.3.1（实践后没问题，spark.yarn.jar记得改）</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark-on-yarn内存分配]]></title>
    <link href="http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate/"/>
    <updated>2016-04-11T19:44:51+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate</id>
    <content type="html"><![CDATA[<p>上次写了一篇关于配置参数是如何影响mapreduce的实际调度的<a href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/">参考</a>：</p>

<ul>
<li>opts（yarn.app.mapreduce.am.command-opts、mapreduce.map.java.opts、mapreduce.reduce.java.opts）是实际运行程序是内存参数。</li>
<li>memory（yarn.app.mapreduce.am.resource.mb、mapreduce.map.memory.mb、mapreduce.reduce.memory.mb）是用于ResourceManager计算集群资源使用和调度。</li>
</ul>


<p>了解参数区别，就没有再深究task内存的问题了。</p>

<h2>新问题-内存分配</h2>

<p>这次又遇到内存问题：spark使用yarn-client的方式运行时，spark有memoryOverhead的设置，但是加了额外的内存后，再经过集群调度内存浪费严重，对于本来就小内存的集群来说完全无法接受。</p>

<ul>
<li>am默认是512加上384 overhead，也就是896m。但是调度后am分配内存资源为1024。</li>
<li>executor默认是1024加上384，等于1408M。单调度后executor分配内存资源为2048。</li>
</ul>


<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-0.png" alt="" /></p>

<p>从appmaster的日志可以看出来请求的内存大小是1408：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-1.png" alt="" /></p>

<p><strong>一个executor就浪费了500M，本来可以跑4个executor的但现在只能执行3个！</strong></p>

<p>关于内存参数的具体含义查看官网： <a href="http://spark.apache.org/docs/latest/running-on-yarn.html">spark-on-yarn</a> 和 <a href="http://hadoop.apache.org/docs/r2.6.4/hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a></p>

<table>
<thead>
<tr>
<th></th>
<th style="text-align:center;"> <em>参数</em>                                  </th>
<th></th>
<th style="text-align:left;"> <em>值</em></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.am.memory                    </td>
<td></td>
<td style="text-align:left;"> 512m</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.driver.memory                     </td>
<td></td>
<td style="text-align:left;"> 1g</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.executor.memoryOverhead      </td>
<td></td>
<td style="text-align:left;"> executorMemory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.driver.memoryOverhead        </td>
<td></td>
<td style="text-align:left;"> driverMemory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.am.memoryOverhead            </td>
<td></td>
<td style="text-align:left;"> AM memory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.nodemanager.resource.memory-mb     </td>
<td></td>
<td style="text-align:left;"> 8192</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.scheduler.minimum-allocation-mb    </td>
<td></td>
<td style="text-align:left;"> 1024</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.scheduler.maximum-allocation-mb    </td>
<td></td>
<td style="text-align:left;"> 8192</td>
</tr>
</tbody>
</table>


<p>分配的内存看着像是 <strong>最小分配内存</strong> 的整数倍。把 <code>yarn.scheduler.minimum-allocation-mb</code> 修改为512，重启yarn再运行，executor的分配的内存果真减少到1536(<strong>512*3</strong>)。</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-3.png" alt="" /></p>

<p>同时 <a href="http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html">http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html</a> 这篇文章也讲 <strong>在YARN中，Container申请的内存大小必须为yarn.scheduler.minimum-allocation-mb的整数倍</strong> 。我们不去猜，调试下调度代码，看看究竟是什么情况。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ sbin/yarn-daemon.sh stop resourcemanager 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ grep "minimum-allocation-mb" -1 yarn-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;&lt;value&gt;512&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ export YARN_RESOURCEMANAGER_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000"
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ sbin/yarn-daemon.sh start resourcemanager </span></code></pre></td></tr></table></div></figure>


<p>本地eclipse在 <code>CapacityScheduler#allocate</code> 打断点，然后跑任务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2 where month=201512;</span></code></pre></td></tr></table></div></figure>


<p>AppMaster内存分配：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-appmaster.png" alt="" /></p>

<p>Executor内存分配：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-executor.png" alt="" /></p>

<p>request进到allocate后，最终调用 <code>DefaultResourceCalculator.normalize</code> 重新计算了一遍请求需要的资源，把内存调整了。默认的DefaultResourceCalculator可以通过 capacity-scheduler.xml 的 <code>yarn.scheduler.capacity.resource-calculator</code> 来修改。</p>

<p>具体代码调度过程如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public Allocation allocate(ApplicationAttemptId applicationAttemptId,
</span><span class='line'>      List&lt;ResourceRequest&gt; ask, List&lt;ContainerId&gt; release, 
</span><span class='line'>      List&lt;String&gt; blacklistAdditions, List&lt;String&gt; blacklistRemovals) {
</span><span class='line'>    ...
</span><span class='line'>    // Sanity check
</span><span class='line'>    SchedulerUtils.normalizeRequests(
</span><span class='line'>        ask, getResourceCalculator(), getClusterResource(),
</span><span class='line'>        getMinimumResourceCapability(), maximumAllocation);
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static void normalizeRequest(
</span><span class='line'>      ResourceRequest ask, 
</span><span class='line'>      ResourceCalculator resourceCalculator, 
</span><span class='line'>      Resource clusterResource,
</span><span class='line'>      Resource minimumResource,
</span><span class='line'>      Resource maximumResource,
</span><span class='line'>      Resource incrementResource) {
</span><span class='line'>    Resource normalized = 
</span><span class='line'>        Resources.normalize(
</span><span class='line'>            resourceCalculator, ask.getCapability(), minimumResource,
</span><span class='line'>            maximumResource, incrementResource);
</span><span class='line'>    ask.setCapability(normalized);
</span><span class='line'>  }   
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static Resource normalize(
</span><span class='line'>      ResourceCalculator calculator, Resource lhs, Resource min,
</span><span class='line'>      Resource max, Resource increment) {
</span><span class='line'>    return calculator.normalize(lhs, min, max, increment);
</span><span class='line'>  }
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public Resource normalize(Resource r, Resource minimumResource,
</span><span class='line'>      Resource maximumResource, Resource stepFactor) {
</span><span class='line'>    int normalizedMemory = Math.min(
</span><span class='line'>        roundUp(
</span><span class='line'>            Math.max(r.getMemory(), minimumResource.getMemory()),
</span><span class='line'>            stepFactor.getMemory()),
</span><span class='line'>            maximumResource.getMemory());
</span><span class='line'>    return Resources.createResource(normalizedMemory);
</span><span class='line'>  }
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static int roundUp(int a, int b) {
</span><span class='line'>    return divideAndCeil(a, b) * b;
</span><span class='line'>  }
</span><span class='line'>  </span></code></pre></td></tr></table></div></figure>


<p></p>

<h2>小结</h2>

<p>今天又重新认识一个yarn参数 <code>yarn.scheduler.minimum-allocation-mb</code> ，不仅仅是最小分配的内存，同时分配的资源也是minimum-allocation-mb的整数倍，还告诉我们 <code>yarn.nodemanager.resource.memory-mb</code> 也最好是minimum-allocation-mb的整数倍。</p>

<p>间接的学习了新的参数，可以通过 <code>yarn.scheduler.capacity.resource-calculator</code> 参数 来修改 CapacityScheduler 调度器的资源计算类。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive-on-spark Snappy on Centos5]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/"/>
    <updated>2016-04-08T22:27:06+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark</id>
    <content type="html"><![CDATA[<p>hive的assembly包就是一个坑货！既然是一个单独的可运行的jar放到lib包下面干嘛呢！！纯属记录工作过程总的经历，想找干货的飘过吧！！</p>

<p><br/></p>

<p>上周支撑部门其他项目的hadoop项目，由于 <strong>hive mr</strong> 比较慢，想用spark试一试看能不能优化。但是系统使用Centos5，我们项目使用的是Centos6。按部就班的编译呗，hive-on-saprk启用SNAPPY的必要条件：</p>

<ul>
<li>hadoop使用snappy需要native的支持，首先当然是Centos5上编译hadoop。(现在看来可以不必要，但每次hdfs命令都提示我native的错误就很不爽)</li>
<li>hive增加spark。</li>
</ul>


<p>各程序版本信息：</p>

<ul>
<li>hadoop-2.6.3</li>
<li>hive-1.2.1</li>
<li>spark-1.3.1</li>
<li>centos5.4</li>
</ul>


<h2>编译hadoop-snappy</h2>

<ul>
<li>centos5手动</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost snappy-1.1.3]# ./autogen.sh 
</span><span class='line'>Remember to add `AC_PROG_LIBTOOL' to `configure.ac'.
</span><span class='line'>You should update your `aclocal.m4' by running aclocal.
</span><span class='line'>libtoolize: `config.guess' exists: use `--force' to overwrite
</span><span class='line'>libtoolize: `config.sub' exists: use `--force' to overwrite
</span><span class='line'>libtoolize: `ltmain.sh' exists: use `--force' to overwrite
</span><span class='line'>Makefile.am:4: Libtool library used but `LIBTOOL' is undefined
</span><span class='line'>Makefile.am:4: 
</span><span class='line'>Makefile.am:4: The usual way to define `LIBTOOL' is to add `AC_PROG_LIBTOOL'
</span><span class='line'>Makefile.am:4: to `configure.ac' and run `aclocal' and `autoconf' again.
</span><span class='line'>Makefile.am:20: `dist_doc_DATA' is used but `docdir' is undefined</span></code></pre></td></tr></table></div></figure>


<p>在centos5上面手动编译搞不定，不是专业写C的，这些问题就是天书啊(查了很多资料，试了很多方法都没通)！！ <strong>Snappy可以在centos6上面编译，编译好以后再centos5上面也能用，编译hadoop-snappy也是ok的</strong> 。</p>

<ul>
<li>centos5-rpm</li>
</ul>


<p>这里直接用rpm安装snappy。觉得创建虚拟机麻烦的话，也可以用docker。docker不同版本的centos下载： <a href="https://github.com/CentOS/sig-cloud-instance-images/">https://github.com/CentOS/sig-cloud-instance-images/</a> 。然后docker共享host主机的文件： <code>docker run -ti -v /home/hadoop:/home/hadoop -v /opt:/opt -v /data:/data centos:centos5 /bin/bash</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@8fb11f6b3ced ~]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 5.11 (Final)
</span><span class='line'>
</span><span class='line'>https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy
</span><span class='line'>https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy-devel
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ivh snappy-1.0.5-1.el5.x86_64.rpm 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ivh snappy-devel-1.0.5-1.el5.x86_64.rpm                                                                                  
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ql snappy-devel snappy
</span><span class='line'>/usr/include/snappy-c.h
</span><span class='line'>/usr/include/snappy-sinksource.h
</span><span class='line'>/usr/include/snappy-stubs-public.h
</span><span class='line'>/usr/include/snappy.h
</span><span class='line'>/usr/lib64/libsnappy.so
</span><span class='line'>/usr/share/doc/snappy-devel-1.0.5
</span><span class='line'>/usr/share/doc/snappy-devel-1.0.5/format_description.txt
</span><span class='line'>/usr/lib64/libsnappy.so.1
</span><span class='line'>/usr/lib64/libsnappy.so.1.1.3
</span><span class='line'>/usr/share/doc/snappy-1.0.5
</span><span class='line'>/usr/share/doc/snappy-1.0.5/AUTHORS
</span><span class='line'>/usr/share/doc/snappy-1.0.5/COPYING
</span><span class='line'>/usr/share/doc/snappy-1.0.5/ChangeLog
</span><span class='line'>/usr/share/doc/snappy-1.0.5/NEWS
</span><span class='line'>/usr/share/doc/snappy-1.0.5/README
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export JAVA_HOME=/opt/jdk1.7.0_17
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export MAVEN_HOME=/opt/apache-maven-3.3.9
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]#  
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# yum install which gcc gcc-c++ zlib-devel make -y
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd protobuf-2.5.0
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# ./configure 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# make && make install
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# which protoc
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# yum install cmake openssl openssl-devel -y
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-2.6.3-src/
</span><span class='line'># bundle.snappy和snappy.lib一起使用，可以把系统的snappy.so文件拷贝到lib/native下面（方便拷贝）
</span><span class='line'># &lt;http://grepcode.com/file/repo1.maven.org/maven2/org.apache.hadoop/hadoop-project-dist/2.6.0/META-INF/maven/org.apache.hadoop/hadoop-project-dist/pom.xml&gt;
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# mvn clean package -Dmaven.javadoc.skip=true -DskipTests -Drequire.snappy=true -Dbundle.snappy=true -Dsnappy.lib=/usr/lib64 -Pdist,native
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# ll hadoop-dist/target/hadoop-2.6.3/lib/native/
</span><span class='line'>total 3808
</span><span class='line'>-rw-r--r-- 1 root root 1036552 Apr 12 09:35 libhadoop.a
</span><span class='line'>-rw-r--r-- 1 root root 1212600 Apr 12 09:36 libhadooppipes.a
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libhadoop.so -&gt; libhadoop.so.1.0.0
</span><span class='line'>-rwxr-xr-x 1 root root  613267 Apr 12 09:35 libhadoop.so.1.0.0
</span><span class='line'>-rw-r--r-- 1 root root  401836 Apr 12 09:36 libhadooputils.a
</span><span class='line'>-rw-r--r-- 1 root root  364026 Apr 12 09:35 libhdfs.a
</span><span class='line'>lrwxrwxrwx 1 root root      16 Apr 12 09:35 libhdfs.so -&gt; libhdfs.so.0.0.0
</span><span class='line'>-rwxr-xr-x 1 root root  229672 Apr 12 09:35 libhdfs.so.0.0.0
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libsnappy.so -&gt; libsnappy.so.1.1.3
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libsnappy.so.1 -&gt; libsnappy.so.1.1.3
</span><span class='line'>-rwxr-xr-x 1 root root   21568 Apr 12 09:35 libsnappy.so.1.1.3
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-dist/target/hadoop-2.6.3/
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3]# bin/hadoop checknative -a
</span><span class='line'>16/04/12 09:38:29 WARN bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version
</span><span class='line'>16/04/12 09:38:29 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
</span><span class='line'>Native library checking:
</span><span class='line'>hadoop:  true /data/bigdata/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3/lib/native/libhadoop.so.1.0.0
</span><span class='line'>zlib:    true /lib64/libz.so.1
</span><span class='line'>snappy:  true /data/bigdata/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3/lib/native/libsnappy.so.1
</span><span class='line'>lz4:     true revision:99
</span><span class='line'>bzip2:   false 
</span><span class='line'>openssl: false org.apache.hadoop.crypto.OpensslCipher.initIDs()V
</span><span class='line'>16/04/12 09:38:29 INFO util.ExitUtil: Exiting with status 1</span></code></pre></td></tr></table></div></figure>


<p>把native下面的打tar包，然后替换生产的。一切都是正常的。接下来坑爹的是spark-snappy，具体的说应该是hive-assmably坑！！</p>

<h2>hive-on-spark snappy</h2>

<p>spark官网也没讲使用snappy需要做什么额外的配置（默认spark.io.compression.codec默认为snappy）。部署后设置 <code>hive.execution.engine=spark</code> 执行spark查询，立马就报错了 <strong> Caused by: java.lang.UnsatisfiedLinkError: /tmp/snappy-1.0.5-libsn
appyjava.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9&#8217; not found (required by /tmp/snappy-1.0.5-libsnappyjava.so)</strong> 从错误堆栈看与hadoop-native-snappy没关系，而是一个snappy-java的包。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX
</span><span class='line'>GLIBCXX_3.4
</span><span class='line'>GLIBCXX_3.4.1
</span><span class='line'>GLIBCXX_3.4.2
</span><span class='line'>GLIBCXX_3.4.3
</span><span class='line'>GLIBCXX_3.4.4
</span><span class='line'>GLIBCXX_3.4.5
</span><span class='line'>GLIBCXX_3.4.6
</span><span class='line'>GLIBCXX_3.4.7
</span><span class='line'>GLIBCXX_3.4.8
</span><span class='line'>GLIBCXX_FORCE_NEW</span></code></pre></td></tr></table></div></figure>


<p>确实缺少GLIBCXX_3.4.9，最新版本的centos5.11也是一样输出的。</p>

<p>spark的配置为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.3.1-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'>spark.master  yarn-client
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.minExecutors    2 
</span><span class='line'>spark.dynamicAllocation.maxExecutors    18
</span><span class='line'>
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>spark.master=yarn-client
</span><span class='line'>spark.driver.memory=5g
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address file1:18080
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span><span class='line'>spark.kryoserializer.buffer.max    512m</span></code></pre></td></tr></table></div></figure>


<p>报错的具体信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- 16/04/12 20:20:08 INFO storage.BlockManagerMaster: Registered BlockManager
</span><span class='line'>- java.lang.reflect.InvocationTargetException
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>-        at java.lang.reflect.Method.invoke(Method.java:606)
</span><span class='line'>-        at org.xerial.snappy.SnappyLoader.loadNativeLibrary(SnappyLoader.java:322)
</span><span class='line'>-        at org.xerial.snappy.SnappyLoader.load(SnappyLoader.java:229)
</span><span class='line'>-        at org.xerial.snappy.Snappy.&lt;clinit&gt;(Snappy.java:48)
</span><span class='line'>-        at org.apache.spark.io.SnappyCompressionCodec.&lt;init&gt;(CompressionCodec.scala:150)
</span><span class='line'>-        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
</span><span class='line'>-        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
</span><span class='line'>-        at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:68)
</span><span class='line'>-        at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:60)
</span><span class='line'>-        at org.apache.spark.scheduler.EventLoggingListener.&lt;init&gt;(EventLoggingListener.scala:67)
</span><span class='line'>-        at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:400)
</span><span class='line'>-        at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:61)
</span><span class='line'>-        at org.apache.hive.spark.client.RemoteDriver.&lt;init&gt;(RemoteDriver.java:169)
</span><span class='line'>-        at org.apache.hive.spark.client.RemoteDriver.main(RemoteDriver.java:556)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>-        at java.lang.reflect.Method.invoke(Method.java:606)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
</span><span class='line'>- Caused by: java.lang.UnsatisfiedLinkError: /tmp/snappy-1.0.5-libsnappyjava.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9' not found (required by /tmp/snappy-1.0.5-libs
</span><span class='line'>-        at java.lang.ClassLoader$NativeLibrary.load(Native Method)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary1(ClassLoader.java:1965)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1890)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1851)
</span><span class='line'>-        at java.lang.Runtime.load0(Runtime.java:795)
</span><span class='line'>-        at java.lang.System.load(System.java:1062)
</span><span class='line'>-        at org.xerial.snappy.SnappyNativeLoader.load(SnappyNativeLoader.java:39)
</span><span class='line'>-        ... 28 more</span></code></pre></td></tr></table></div></figure>


<p>spark用到了snappy-java来处理snappy的解压缩。用jinfo获取SparkSubmit进程的classpath，用这个classpath跑helloworld确实是报错的，但是单独用hadoop-common下面的 snappy-java-1.0.4.1.jar 是没问题的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 snappy-java-test]$ cat Hello.java 
</span><span class='line'>import org.xerial.snappy.Snappy;
</span><span class='line'>
</span><span class='line'>public class Hello { 
</span><span class='line'>public static void main(String[] args) throws Exception {
</span><span class='line'>String input = "Hello snappy-java!";
</span><span class='line'>
</span><span class='line'>byte[] compressed = Snappy.compress(input.getBytes("utf-8"));
</span><span class='line'>byte[] uncompressed = Snappy.uncompress(compressed);
</span><span class='line'>
</span><span class='line'>String result = new String(uncompressed, "utf-8");
</span><span class='line'>System.out.println(result);
</span><span class='line'>}
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[hadoop@file1 snappy-java-test]$ java -cp .:/home/hadoop/tools/hadoop-2.6.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar Hello
</span><span class='line'>Hello snappy-java!</span></code></pre></td></tr></table></div></figure>


<p>而而而，classpath中就只有hadoop-common和hadoop-mapreduce下面有snappy-java包，并且都是1.0.4.1，那TMD的使用SparkSubmit-classpath加载Snappy是哪个jar里面的呢？</p>

<p>调整后的helloworld为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 snappy-java-test]$ cat Hello.java 
</span><span class='line'>import org.xerial.snappy.Snappy;
</span><span class='line'>
</span><span class='line'>public class Hello { 
</span><span class='line'>public static void main(String[] args) throws Exception {
</span><span class='line'>String input = "Hello snappy-java!";
</span><span class='line'>
</span><span class='line'>System.out.println(Snappy.class.getProtectionDomain());
</span><span class='line'>byte[] compressed = Snappy.compress(input.getBytes("utf-8"));
</span><span class='line'>byte[] uncompressed = Snappy.uncompress(compressed);
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>String result = new String(uncompressed, "utf-8");
</span><span class='line'>System.out.println(result);
</span><span class='line'>}
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>添加getProtectionDomain查看加载类的jar。再编译跑一次，这次终于找到真凶了！！hive-assembly，assembly包还放在lib下面就tmd的是一个坑货！！hive-exec的guava已经坑了很多人了，这次换hive-jdbc了！！(我这里的环境是centos5，centos6是没有这个问题的！！)</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-centos5-snappy-hive-jdbc.png" alt="" /></p>

<p>如果指定使用hadoop编译依赖的snappy.so.1.1.3动态链接库会出现版本不兼容的问题。还是干掉hive-jdbc-standalone吧。。。囧</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 查看源码SnappyLoader#loadSnappySystemProperties，可以通过配置指定使用系统动态链接库
</span><span class='line'>[hadoop@file1 snappy-java-test]$ cat org-xerial-snappy.properties 
</span><span class='line'>org.xerial.snappy.use.systemlib=true
</span><span class='line'>[hadoop@file1 snappy-java-test]$ ln -s /home/hadoop/tools/hadoop-2.6.3/lib/native/libsnappy.so libsnappyjava.so
</span><span class='line'>[hadoop@file1 snappy-java-test]$ ll
</span><span class='line'>总计 1240
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop     854 04-08 10:11 Hello.class
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop     408 04-08 10:11 Hello.java
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop      55 04-12 19:37 libsnappyjava.so -&gt; /home/hadoop/tools/hadoop-2.6.3/lib/native/libsnappy.so
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop      37 04-12 19:15 org-xerial-snappy.properties
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 1251514 2014-04-29 snappy-java-1.0.5.jar
</span><span class='line'>[hadoop@file1 snappy-java-test]$ java -cp .:snappy-java-1.0.5.jar -Djava.library.path=. Hello
</span><span class='line'>ProtectionDomain  (file:/home/hadoop/snappy-java-test/snappy-java-1.0.5.jar &lt;no signer certificates&gt;)
</span><span class='line'> sun.misc.Launcher$AppClassLoader@333cb1eb
</span><span class='line'> &lt;no principals&gt;
</span><span class='line'> java.security.Permissions@7377711 (
</span><span class='line'> ("java.io.FilePermission" "/home/hadoop/snappy-java-test/snappy-java-1.0.5.jar" "read")
</span><span class='line'> ("java.lang.RuntimePermission" "exitVM")
</span><span class='line'>)
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Exception in thread "main" java.lang.UnsatisfiedLinkError: org.xerial.snappy.SnappyNative.maxCompressedLength(I)I
</span><span class='line'>        at org.xerial.snappy.SnappyNative.maxCompressedLength(Native Method)
</span><span class='line'>        at org.xerial.snappy.Snappy.maxCompressedLength(Snappy.java:320)
</span><span class='line'>        at org.xerial.snappy.Snappy.rawCompress(Snappy.java:333)
</span><span class='line'>        at org.xerial.snappy.Snappy.compress(Snappy.java:92)
</span><span class='line'>        at Hello.main(Hello.java:8)
</span><span class='line'>      </span></code></pre></td></tr></table></div></figure>


<p>删掉jdbc-standalone后，hive-on-spark就ok了。如果你无法下手删除 hive-jdbc-1.2.1-standalone.jar ，那就把 <code>spark.io.compression.codec</code> 改成 <code>lz4</code> 等压缩也是可以的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/home/hadoop/tools/apache-hive-1.2.1-bin/conf/hive-log4j.properties
</span><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_info where edate=20160411;
</span><span class='line'>Query ID = hadoop_20160412205338_2c95c5fd-af50-42ba-8681-e154e4b74cb1
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 69afc030-fa1f-4fdf-81ef-12bdca411a4f
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-04-12 20:54:11,367 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:14,421 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:17,457 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:19,486 Stage-0_0: 2(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:20,497 Stage-0_0: 3(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:21,509 Stage-0_0: 5(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:22,520 Stage-0_0: 6(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:23,532 Stage-0_0: 7(+2)/234    Stage-1_0: 0/1</span></code></pre></td></tr></table></div></figure>


<h2>小结</h2>

<p>第一，hive的assembly的包太tmd的坑了。第二，以后找java具体加载那个类，可以通过 class.getProtectionDomain 来获取了。第三，又多尝试一个环境部署hadoop。呵呵</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[puppet4.4.1入门安装]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/puppet-install/"/>
    <updated>2016-04-08T19:49:32+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/puppet-install</id>
    <content type="html"><![CDATA[<p>网上资料比较多比较老，基本操作可以借鉴。安装Puppet最简单的方式就是用yum来安装(操作系统centos6），由于天朝的特殊环境最好建立本地仓库。本文记录我自己安装过程的过程，先介绍本地仓库创建，然后介绍Puppet环境的搭建。</p>

<p>操作系统：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.5 (Final)</span></code></pre></td></tr></table></div></figure>


<h2>更新</h2>

<p>2016-4-28 15:42:32 - rpm强制安装puppetserver。依赖jdk8有点麻烦，自己安装jdk7就好了。
2016-5-3 09:39:40  - 更新puppetserver性能的部分，运行在Jetty之上不需要再折腾passenger了。见文章最后。</p>

<h2>本地仓库搭建</h2>

<p>Puppet4所有依赖都进行统一打包，其实通过rpm就能直接安装。为了体现下高大山、并且Puppet内部的项目之间是有依赖的。这里先使用createrepo创建本地库。</p>

<p>createrepo其实就是用来创建目录下rpm文件的索引数据(repodata)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# yum install createrepo
</span><span class='line'>
</span><span class='line'># 下载系统对应的puppet-pc1的包: https://yum.puppetlabs.com/el/6/PC1/x86_64/ 全部最新版本
</span><span class='line'>[root@hadoop-master2 repo]# ls -1
</span><span class='line'>puppet-agent-1.4.1-1.el6.x86_64.rpm
</span><span class='line'>puppet-dashboard-1.2.23-0.1rc3.el6.noarch.rpm
</span><span class='line'>puppetdb-4.0.0-1.el6.noarch.rpm
</span><span class='line'>puppetdb-termini-3.2.4-1.el6.noarch.rpm
</span><span class='line'>puppetdb-terminus-3-1.el6.noarch.rpm
</span><span class='line'>puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# createrepo .
</span><span class='line'>Spawning worker 0 with 6 pkgs
</span><span class='line'>Workers Finished
</span><span class='line'>Gathering worker results
</span><span class='line'>
</span><span class='line'>Saving Primary metadata
</span><span class='line'>Saving file lists metadata
</span><span class='line'>Saving other metadata
</span><span class='line'>Generating sqlite DBs
</span><span class='line'>Sqlite DBs complete
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=file:///opt/puppetlabs/repo
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span></code></pre></td></tr></table></div></figure>


<p>查看local下的rpm包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 repo]# yum clean all
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Cleaning repos: base epel extras pgdg94 puppet-local updates
</span><span class='line'>Cleaning up Everything
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum list all | grep "puppet-local"
</span><span class='line'>puppet-agent.x86_64                         1.4.1-1.el6                  @puppet-local
</span><span class='line'>puppet-dashboard.noarch                     1.2.23-0.1rc3.el6            @puppet-local
</span><span class='line'>puppetdb.noarch                             4.0.0-1.el6                  @puppet-local
</span><span class='line'>puppetdb-termini.noarch                     3.2.4-1.el6                  @puppet-local
</span><span class='line'>puppetserver.noarch                         2.3.1-1.el6                  @puppet-local
</span><span class='line'>puppetdb-terminus.noarch                    3-1.el6                      puppet-local
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum search puppet</span></code></pre></td></tr></table></div></figure>


<p>网上资料还有安装 <code>yum-priorities</code> 来设置repo优先级的。我这里没有包冲突问题所以并没有安装这个。</p>

<h2>单机安装</h2>

<p>安装前翻一翻官网的文档： <a href="https://docs.puppet.com/puppetserver/latest/install_from_packages.html">https://docs.puppet.com/puppetserver/latest/install_from_packages.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先看看 puppet-agent 和 puppetserver 的依赖
</span><span class='line'>[root@hadoop-master2 repo]# yum deplist puppet-agent
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.aliyun.com
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'> * extras: mirrors.aliyun.com
</span><span class='line'> * updates: mirrors.aliyun.com
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: tar
</span><span class='line'>   provider: tar.x86_64 2:1.23-13.el6
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: readline
</span><span class='line'>   provider: readline.i686 6.0-4.el6
</span><span class='line'>   provider: readline.x86_64 6.0-4.el6
</span><span class='line'>  dependency: util-linux
</span><span class='line'>   provider: util-linux-ng.i686 2.17.2-12.18.el6
</span><span class='line'>   provider: util-linux-ng.x86_64 2.17.2-12.18.el6
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum deplist puppetserver
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.aliyun.com
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'> * extras: mirrors.aliyun.com
</span><span class='line'> * updates: mirrors.aliyun.com
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppetserver.noarch 2.3.1-1.el6
</span><span class='line'>  dependency: /bin/bash
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: java-1.8.0-openjdk-headless
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.45-35.b13.el6
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-0.b16.el6_6
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-1.b16.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-3.b16.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.65-0.b17.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.71-1.b15.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7
</span><span class='line'>  dependency: puppet-agent &gt;= 1.4.0
</span><span class='line'>   provider: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: net-tools
</span><span class='line'>   provider: net-tools.x86_64 1.60-110.el6_2
</span><span class='line'>  dependency: /usr/bin/env
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6_7.3
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>
</span><span class='line'># 安装
</span><span class='line'>[root@hadoop-master2 repo]# yum install puppetserver
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# netstat -anp | grep 4526
</span><span class='line'>tcp        0      0 :::8140                     :::*                        LISTEN      4526/java           
</span><span class='line'>
</span><span class='line'># 安装好后，查看各版本软件版本信息
</span><span class='line'>[root@hadoop-master2 repo]# puppet -V
</span><span class='line'>4.4.1
</span><span class='line'>[root@hadoop-master2 repo]# facter -v
</span><span class='line'>3.1.5 (commit b5c2cf9b2ac290cb17fcadea19b467a39e17c1fd)
</span><span class='line'>[root@hadoop-master2 repo]# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1</span></code></pre></td></tr></table></div></figure>


<p>puppetserver依赖puppet-agent，而puppet-agent是一个all-in-one的assembly的包。所以服务端安装puppetserver就行了。客户端仅安装puppet-agent即可。</p>

<p>Puppet4的目录进行比较大的调整，程序路径为 <code>/opt/puppetlabs</code> ，配置路径为 <code>/etc/puppetlabs</code> 。如果你看的是puppet3资料，对照查看官网 <a href="https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html">Where Did Everything Go in Puppet 4.x?</a> 了解各程序的目录位置。</p>

<p>如果你单独安装了jdk(依赖的是jdk8也是挺烦的)，也可以使用rpm强制安装puppetserver，然后指定java程序的路径：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# yum deplist puppetserver
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * centos-local: 172.17.42.1:8888
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppetserver.noarch 2.3.1-1.el6
</span><span class='line'>  dependency: /bin/bash
</span><span class='line'>   provider: bash.x86_64 4.1.2-29.el6
</span><span class='line'>  dependency: java-1.8.0-openjdk-headless
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1.8.0.20-3.b26.el6
</span><span class='line'>  dependency: puppet-agent &gt;= 1.4.0
</span><span class='line'>   provider: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: net-tools
</span><span class='line'>   provider: net-tools.x86_64 1.60-110.el6_2
</span><span class='line'>  dependency: /usr/bin/env
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-29.el6
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-2.el6_4.1
</span><span class='line'>
</span><span class='line'>bash-4.1# rpm -ivh http://172.17.42.1:8888/centos6/puppet/puppetserver-2.3.1-1.el6.noarch.rpm --nodeps --force
</span><span class='line'>Retrieving http://172.17.42.1:8888/centos6/puppet/puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>warning: /var/tmp/rpm-tmp.7CAtn8: Header V4 RSA/SHA1 Signature, key ID 4bd6ec30: NOKEY
</span><span class='line'>Preparing...                ########################################### [100%]
</span><span class='line'>usermod: no changes
</span><span class='line'>   1:puppetserver           ########################################### [100%]
</span><span class='line'>usermod: no changes
</span><span class='line'>bash-4.1# chkconfig --list | grep puppetserver
</span><span class='line'>puppetserver    0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span><span class='line'>
</span><span class='line'>bash-4.1# cat /etc/sysconfig/puppetserver 
</span><span class='line'>...
</span><span class='line'>JAVA_BIN="/opt/jdk1.7.0_60/bin/java"
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>bash-4.1# netstat -a
</span><span class='line'>Active Internet connections (servers and established)
</span><span class='line'>Proto Recv-Q Send-Q Local Address               Foreign Address             State      
</span><span class='line'>tcp        0      0 *:8140                      *:*                         LISTEN      
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h2>单机版HelloWorld</h2>

<p>单机模式不需要认证，当做学习调试环境挺好的：方便简单。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 manifests]# vi helloworld.pp
</span><span class='line'>notify { 'greeting':
</span><span class='line'>  message =&gt; 'Hello, world!'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 manifests]# puppet apply helloworld.pp 
</span><span class='line'>Notice: Compiled catalog for hadoop-master2.localdomain in environment production in 0.03 seconds
</span><span class='line'>Notice: Hello, world!
</span><span class='line'>Notice: /Stage[main]/Main/Notify[greeting]/message: defined 'message' as 'Hello, world!'
</span><span class='line'>Notice: Applied catalog in 0.04 seconds
</span><span class='line'>
</span><span class='line'># 可以用resource根据当前环境生成配置
</span><span class='line'>[root@hadoop-master2 manifests]# puppet resource user hadoop
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  gid              =&gt; '500',
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; 'XXXXXX',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  uid              =&gt; '500',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># 状态变更
</span><span class='line'>[root@hadoop-master2 puppetlabs]# bin/puppet resource service puppet ensure=running enable=false
</span><span class='line'>Notice: /Service[puppet]/enable: enable changed 'true' to 'false'
</span><span class='line'>service { 'puppet':
</span><span class='line'>  ensure =&gt; 'running',
</span><span class='line'>  enable =&gt; 'false',
</span><span class='line'>}
</span><span class='line'>[root@hadoop-master2 puppetlabs]# chkconfig --list | grep puppet
</span><span class='line'>puppet          0:off   1:off   2:off   3:off   4:off   5:off   6:off
</span><span class='line'>puppetserver    0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span></code></pre></td></tr></table></div></figure>


<h2>CS模式配置</h2>

<p>这里完全模拟生产环境情况(内网)，首先搭建两个本地仓库：centos，puppet。puppet依赖RPM根据具体情况下载即可，我这里用的是centos6.5。</p>

<p>搭建私有仓库：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>增加 java-1.8.0-openjdk-headless 和 tzdata-java-2014g(iso带的2013g不适配)
</span><span class='line'>[root@hadoop-master2 repo]# ll
</span><span class='line'>total 142344
</span><span class='line'>-rw-r--r-- 1 root root 33135156 Apr  9 21:47 java-1.8.0-openjdk-headless-1.8.0.51-3.b16.el6_7.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root 26740012 Apr  9 11:29 puppet-agent-1.4.1-1.el6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  4509000 Apr  9 11:29 puppet-dashboard-1.2.23-0.1rc3.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 21866876 Apr  9 11:29 puppetdb-4.0.0-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root    25516 Apr  9 11:29 puppetdb-termini-3.2.4-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root     3676 Apr  9 11:29 puppetdb-terminus-3-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 33412844 Apr  9 11:29 puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>drwxr-xr-x 2 root root     4096 Apr  9 22:56 repodata
</span><span class='line'>-rw-r--r-- 1 root root   181196 Sep 17  2014 tzdata-java-2014g-1.el6.noarch.rpm
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 ~]# mount -t iso9660 -o loop CentOS-6.5-x86_64-bin-DVD1.iso /mnt/cdrom
</span><span class='line'># httpd 我的系统已经安装了
</span><span class='line'>[root@hadoop-master2 ~]# cd /var/www/html/
</span><span class='line'>[root@hadoop-master2 html]# ll
</span><span class='line'>total 820
</span><span class='line'>lrwxrwxrwx  1 root root     10 Apr  9 21:54 centos6_5 -&gt; /mnt/cdrom
</span><span class='line'>lrwxrwxrwx  1 root root     20 Mar 30 17:11 puppet -&gt; /opt/puppetlabs/repo</span></code></pre></td></tr></table></div></figure>


<p>启动docker实例，参考 <a href="http://www.winseliu.com/blog/2014/09/30/docker-ssh-on-centos/">docker的安装</a>。由于centos和puppet中有包冲突，需要安装 <code>yum-priorities</code> 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 repo]# docker run -i -t centos:centos6 /bin/bash
</span><span class='line'>bash-4.1# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.5 (Final)
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install yum-plugin-priorities-1.1.30-30.el6.noarch.rpm 
</span><span class='line'>
</span><span class='line'># 把默认的repo清理掉，添加puppet和centos
</span><span class='line'>bash-4.1# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=http://172.17.42.1/puppet
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>priority=1
</span><span class='line'>bash-4.1# cat /etc/yum.repos.d/centos-local.repo 
</span><span class='line'>[centos-local]
</span><span class='line'>name=Centos Local
</span><span class='line'>baseurl=http://172.17.42.1/centos6_5
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>priority=2
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install puppetserver
</span><span class='line'>
</span><span class='line'># 加载环境变量
</span><span class='line'>bash-4.1# source /etc/profile.d/puppet-agent.sh
</span><span class='line'># 查看puppet各程序版本
</span><span class='line'>bash-4.1# puppet -V
</span><span class='line'>4.4.1
</span><span class='line'>bash-4.1# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1
</span><span class='line'>bash-4.1# facter -v
</span><span class='line'>3.1.5 (commit b5c2cf9b2ac290cb17fcadea19b467a39e17c1fd)</span></code></pre></td></tr></table></div></figure>


<p>Agent安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=http://172.17.42.1/puppet
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>[centos-local]
</span><span class='line'>name=Centos Local
</span><span class='line'>baseurl=http://172.17.42.1/centos6_5
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install puppet-agent -y</span></code></pre></td></tr></table></div></figure>


<p>配置：</p>

<ul>
<li>添加hosts</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# cat /etc/hosts
</span><span class='line'>172.17.0.4 puppet
</span><span class='line'>172.17.0.5 agent1
</span><span class='line'>172.17.0.6 agent2</span></code></pre></td></tr></table></div></figure>


<ul>
<li>master自测</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 3e4b2ba27563.localdomain
</span><span class='line'>Info: Applying configuration version '1460222292'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds</span></code></pre></td></tr></table></div></figure>


<ul>
<li>agent连接服务器</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Creating a new SSL key for 5a56be361905.localdomain
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for 5a56be361905.localdomain
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 58:1A:2E:28:D3:D7:C5:7B:E3:1A:C2:0F:70:D0:46:C0:34:39:7F:EC:98:65:B1:09:96:D3:4B:A7:4B:32:A6:C6
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'># master查看/认证
</span><span class='line'>bash-4.1# puppet cert list
</span><span class='line'>  "5a56be361905.localdomain" (SHA256) 58:1A:2E:28:D3:D7:C5:7B:E3:1A:C2:0F:70:D0:46:C0:34:39:7F:EC:98:65:B1:09:96:D3:4B:A7:4B:32:A6:C6
</span><span class='line'>  "6516b8d0538b.localdomain" (SHA256) F7:49:CC:93:EA:5D:D9:A2:90:33:01:A9:74:86:97:0C:20:0C:EB:24:3A:13:85:64:5C:32:A8:D7:36:91:3C:77
</span><span class='line'>bash-4.1# puppet cert sign --all 
</span><span class='line'>Notice: Signed certificate request for 6516b8d0538b.localdomain
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest 6516b8d0538b.localdomain at '/etc/puppetlabs/puppet/ssl/ca/requests/6516b8d0538b.localdomain.pem'
</span><span class='line'>Notice: Signed certificate request for 5a56be361905.localdomain
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest 5a56be361905.localdomain at '/etc/puppetlabs/puppet/ssl/ca/requests/5a56be361905.localdomain.pem'
</span><span class='line'>
</span><span class='line'># agent再连
</span><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Caching certificate for 5a56be361905.localdomain
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for 5a56be361905.localdomain
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 5a56be361905.localdomain
</span><span class='line'>Info: Applying configuration version '1460222614'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.02 seconds</span></code></pre></td></tr></table></div></figure>


<p>相比puppet那么多配置项，安装还是相对简单的。安装写到这些也差不多了，接下来要研究下监控和puppet的配置。</p>

<p>安装过程中也遇到一些问题，主要都是DNS导致。一开始 <strong>直接用hosts</strong> 来配置是最简便的，把server的ip指定为puppet域名。</p>

<p>再来个Hello：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master
</span><span class='line'>bash-4.1# cd /etc/puppetlabs/code/environments/production/
</span><span class='line'>bash-4.1# ls
</span><span class='line'>environment.conf  hieradata  manifests  modules
</span><span class='line'>bash-4.1# cd manifests/
</span><span class='line'>bash-4.1# cat helloworld.pp 
</span><span class='line'>notify { 'Hello World' : 
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># agent
</span><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 5a56be361905.localdomain
</span><span class='line'>Info: Applying configuration version '1460223248'
</span><span class='line'>Notice: Hello World
</span><span class='line'>Notice: /Stage[main]/Main/Notify[Hello World]/message: defined 'message' as 'Hello World'
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>bash-4.1# </span></code></pre></td></tr></table></div></figure>


<h2>最后说说PuppetServer性能</h2>

<ul>
<li><a href="https://docs.puppet.com/puppetserver/latest/">https://docs.puppet.com/puppetserver/latest/</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/puppetserver_vs_passenger.html">puppetserver_vs_passenger</a></li>
<li>master与ca分离 <a href="https://docs.puppet.com/puppetserver/latest/external_ca_configuration.html">https://docs.puppet.com/puppetserver/latest/external_ca_configuration.html</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/ssl_server_certificate_change_and_virtual_ips.html">https://docs.puppet.com/puppetserver/latest/ssl_server_certificate_change_and_virtual_ips.html</a></li>
</ul>


<p>晚上很多资料都是旧的，一般都是 puppetmaster + apache/nginx + passenger 。新版本使用puppetserver后，服务运行在JVM之上（ Puppet Server is hosted by a Jetty web server ），性能比原来ruby的方式更好（<a href="https://docs.puppet.com/puppetserver/latest/puppetserver_vs_passenger.html">反正官网是这么说的</a>）。所以没必要折腾其他ruby的东西了。</p>

<p><strong>题外话</strong>：搭上JVM（java）的车，对于大家都好^_^，现在大数据HADOOP都是基于java的，spark的scala也是运行在JVM之上。</p>

<blockquote><p>Because Puppet Server runs on the JVM, it takes a bit longer than the Apache/Passenger stack to start and get ready to accept HTTP connections.</p>

<p>Overall, Puppet Server performance is significantly better than a Puppet master running on the Apache/Passenger stack, but the initial startup is definitely slower.</p></blockquote>

<h2>参考</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/">https://docs.puppet.com/puppet/4.4/reference/</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/install_pre.html">https://docs.puppetlabs.com/puppet/latest/reference/install_pre.html</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/install_from_packages.html">https://docs.puppet.com/puppetserver/latest/install_from_packages.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html">https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html</a></li>
<li><a href="https://github.com/puppetlabs/puppet-specifications/blob/master/file_paths.md">https://github.com/puppetlabs/puppet-specifications/blob/master/file_paths.md</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/install_linux.html#installing-release-packages-on-yum-based-systems">https://docs.puppet.com/puppet/4.4/reference/install_linux.html#installing-release-packages-on-yum-based-systems</a></li>
<li><a href="https://yum.puppetlabs.com/el/6/PC1/x86_64/">https://yum.puppetlabs.com/el/6/PC1/x86_64/</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/type.html#file">https://docs.puppetlabs.com/puppet/latest/reference/type.html#file</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html">https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppetdb/4.0/install_from_packages.html">https://docs.puppetlabs.com/puppetdb/4.0/install_from_packages.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/4.4/reference/config_file_auth.html">https://docs.puppetlabs.com/puppet/4.4/reference/config_file_auth.html</a></li>
<li><p><a href="https://docs.puppetlabs.com/puppet/4.4/reference/config_file_autosign.html">https://docs.puppetlabs.com/puppet/4.4/reference/config_file_autosign.html</a></p></li>
<li><p>yum配置与各种使用 <a href="http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html">http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html</a></p></li>
<li><a href="http://kisspuppet.com/2014/01/26/puppet_create_repo/">http://kisspuppet.com/2014/01/26/puppet_create_repo/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DBCP参数在Hive JDBC上的实践]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/dbcp-parameters/"/>
    <updated>2016-04-08T19:48:01+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/dbcp-parameters</id>
    <content type="html"><![CDATA[<p>查询程序一开始只是简单使用dbcp来做连接的限制。在实践的过程中遇到各种问题，本文记录DBCP的参数优化提高程序健壮性的两次过程。</p>

<p>最开始的DBCP的配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>  destroy-method="close" 
</span><span class='line'>  p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>  p:url="${hiveUrl}" 
</span><span class='line'>  p:username="${hiveUsername}" 
</span><span class='line'>  p:password="${hivePassword}"
</span><span class='line'>  p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>  p:maxWait="${hiveMaxWait}" 
</span><span class='line'>  p:maxActive="${hiveMaxActive}" /&gt;
</span><span class='line'>
</span><span class='line'>&lt;bean id="hiveTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt;
</span><span class='line'>  &lt;property name="dataSource"&gt;
</span><span class='line'>      &lt;ref bean="hiveDataSource" /&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>&lt;/bean&gt;</span></code></pre></td></tr></table></div></figure>


<p>第一个遇到的问题，就是每次hiveserver2重启后，这个查询程序也得重启。在实际使用过程中非常的麻烦！！</p>

<h4>重启问题（连接断开后不能重连）</h4>

<p>首先给出学习的链接 <a href="http://elf8848.iteye.com/blog/1931778">http://elf8848.iteye.com/blog/1931778</a> 巨详细，同时问题的场景都一模一样啊！！</p>

<p>添加三个参数：</p>

<ul>
<li>testOnBorrow = &ldquo;true&rdquo;       借出连接时不要测试，否则很影响性能</li>
<li>testWhileIdle = &ldquo;true&rdquo;       指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除.</li>
<li>validationQuery = &ldquo;show databases&rdquo; 验证连接是否可用，使用的SQL语句</li>
</ul>


<p>解释：</p>

<p>testWhileIdle = &ldquo;true&rdquo; 表示每 {timeBetweenEvictionRunsMillis} (默认-1，不执行)秒，取出 {numTestsPerEvictionRun} (默认值3)条连接，使用 {validationQuery} 进行测试 ，测试不成功就销毁连接。销毁连接后，连接数量就少了，如果小于minIdle数量，就新建连接。</p>

<p>testOnBorrow = &ldquo;true&rdquo; 它的默认值是true，如果测试失败会drop掉然后再borrow。false表示每次从连接池中取出连接时，不需要执行 {validationQuery} 中的SQL进行测试。若配置为true,对性能有非常大的影响，性能会下降7-10倍。所在一定要配置为false.</p>

<p>调整参数后hiveserver2重启，查询再连会先报错然后再连。在每次取连接的时刻使用 <code>show databases</code> 测试，如果失败则从pool中删掉这个连接，重新再取，实现了重连的效果。这里不用 <code>select 1</code> hive里面执行很慢， 同时testWhileIdle并没有生效，因为没有配置timeBetweenEvictionRunsMillis参数。</p>

<p>调整后的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>destroy-method="close" 
</span><span class='line'>p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>p:url="${hiveUrl}" 
</span><span class='line'>p:username="${hiveUsername}" 
</span><span class='line'>p:password="${hivePassword}"
</span><span class='line'>p:testOnBorrow="${hiveTestOnBorrow}"
</span><span class='line'>p:testWhileIdle="${hiveTestWhileIdle}" 
</span><span class='line'>p:validationQuery="${hiveValidationQuery}"
</span><span class='line'>p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>p:maxWait="${hiveMaxWait}" 
</span><span class='line'>p:maxActive="${hiveMaxActive}" 
</span><span class='line'>/&gt;</span></code></pre></td></tr></table></div></figure>


<p>问题又来了，由于测试切换tez和spark才配置了上面的重连。但是切换到spark后，启动的spark会一直保持(连接创建的session不会主动关闭)，直到hiveserver2 session超时(默认6h检查一次，7h idle就关闭)。</p>

<p>注意：有个隐忧，hive-on-spark每个连接都创建一个SESSION，这就退化到MR操作了。不能完全利用SPARK的优势！！例如业务中，即查询count、又获取一页数据，这里就是两个单独的spark程序！！N个session就N个 <strong>hive on spark</strong> 啊！！</p>

<h4>第二个问题，服务端session强制关闭</h4>

<p>问题其实和参考中的: <strong>MySQL8小时问题，Mysql服务器默认连接的“wait_timeout”是8小时，也就是说一个connection空闲超过8个小时，Mysql将自动断开该 connection</strong> 一模一样的。在增加 <strong>minEvictableIdleTimeMillis</strong> 和 <strong>timeBetweenEvictionRunsMillis</strong> 设置检查和回收的时间。</p>

<ul>
<li>timeBetweenEvictionRunsMillis = &ldquo;1800000&rdquo;  每30分钟运行一次空闲连接回收器，没必要那么频繁。</li>
<li>minEvictableIdleTimeMillis = &ldquo;3600000&rdquo;  池中的连接空闲1个小时后被回收，如果1个半小时没有操作，这个session就会被客户端关闭。可以通过yarn-8088的scheduler页面查看。</li>
</ul>


<p>设置后的最终效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>destroy-method="close" 
</span><span class='line'>p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>p:url="${hiveUrl}" 
</span><span class='line'>p:username="${hiveUsername}" 
</span><span class='line'>p:password="${hivePassword}"
</span><span class='line'>p:testOnBorrow="${hiveTestOnBorrow}"
</span><span class='line'>p:validationQuery="${hiveValidationQuery}"
</span><span class='line'>p:maxWait="${hiveMaxWait}" 
</span><span class='line'>p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>p:maxActive="${hiveMaxActive}" 
</span><span class='line'>p:testWhileIdle="${hiveTestWhileIdle}" 
</span><span class='line'>p:timeBetweenEvictionRunsMillis="${hiveTimeBetweenEvictionRunsMillis}" 
</span><span class='line'>p:minEvictableIdleTimeMillis="${hiveMinEvictableIdleTimeMillis}" 
</span><span class='line'>p:removeAbandoned="true"
</span><span class='line'>p:logAbandoned="true"
</span><span class='line'>/&gt;</span></code></pre></td></tr></table></div></figure>


<p>很多程序都有很多参数，大部分能通过文档明白，但是一些参数不到实践真的很难真正体会它的含义。参考的文章两次改进我查看了，但是第一次看的时刻根本没去加其他参数，因为对我来说没用，解决当前问题用不到嘛。</p>

<p>hadoop的参数更多，core/hdfs/mapred/yarn需要多用才能发现参数的功能和妙用。<strong>纸上得来终觉浅，绝知此事要躬行</strong> 。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RPM打包]]></title>
    <link href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/"/>
    <updated>2016-04-04T16:07:21+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/04/rpm-build-your-package</id>
    <content type="html"><![CDATA[<h2>资料</h2>

<ul>
<li><a href="http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html">http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html</a></li>
<li><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn">https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/index.html">用 RPM 打包软件-打包教程</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part3/index.html">用 RPM 打包软件-高级部分：安装前后控制</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-rpm/index.html">RPM 打包技术与典型 SPEC 文件分析-各变量含义</a></li>
<li><a href="http://hlee.iteye.com/blog/343499">http://hlee.iteye.com/blog/343499</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/indent-2.spec">案例</a></li>
<li><p><a href="https://github.com/apache/zookeeper/tree/release-3.4.8/src/packages">zookeeper打包案例</a></p></li>
<li><p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html">http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html</a></p></li>
</ul>


<h2>实践</h2>

<ul>
<li>系统配置准备</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 新建一个docker实例，来测试、学习
</span><span class='line'>[root@cu1 ~]# docker run -ti centos:centos6 /bin/bash
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.6 (Final)
</span><span class='line'>
</span><span class='line'># 安装编译环境所需的软件
</span><span class='line'>yum install which tree lrzsz tar gcc rpm-build
</span><span class='line'># wget编译的依赖
</span><span class='line'>yum install -y gnutls gnutls-devel</span></code></pre></td></tr></table></div></figure>


<ul>
<li>步骤</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bdc25400cc63 home]# mkdir mywget 
</span><span class='line'>[root@bdc25400cc63 home]# cd mywget/
</span><span class='line'>[root@bdc25400cc63 mywget]# mkdir BUILD RPMS SOURCES SPECS SRPMS
</span><span class='line'>[root@bdc25400cc63 mywget]# cd SOURCES/
</span><span class='line'>[root@bdc25400cc63 SOURCES]# mv /home/wget-1.17.tar.gz .
</span><span class='line'>[root@bdc25400cc63 SOURCES]# ls
</span><span class='line'>wget-1.17.tar.gz
</span><span class='line'>[root@bdc25400cc63 SOURCES]# cd ..
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# rpmbuild --showrc
</span><span class='line'>[test@bdc25400cc63 mywget]$ rpm --eval "%{_topdir}"
</span><span class='line'>
</span><span class='line'>[test@bdc25400cc63 mywget]$ grep -i _topdir /usr/lib/rpm/rpmrc /usr/lib/rpm/redhat/rpmrc /usr/lib/rpm/macros /usr/lib/rpm/redhat/macros  | less
</span><span class='line'>/usr/lib/rpm/macros:%_builddir          %{_topdir}/BUILD
</span><span class='line'>/usr/lib/rpm/macros:%_rpmdir            %{_topdir}/RPMS
</span><span class='line'>/usr/lib/rpm/macros:%_sourcedir         %{_topdir}/SOURCES
</span><span class='line'>/usr/lib/rpm/macros:%_specdir           %{_topdir}/SPECS
</span><span class='line'>/usr/lib/rpm/macros:%_srcrpmdir         %{_topdir}/SRPMS
</span><span class='line'>/usr/lib/rpm/macros:%_buildrootdir              %{_topdir}/BUILDROOT
</span><span class='line'>/usr/lib/rpm/macros:%_topdir            %{getenv:HOME}/rpmbuild
</span><span class='line'>
</span><span class='line'>[test@bdc25400cc63 mywget]$ cat ~/.rpmmacros 
</span><span class='line'>%_topdir /home/mywget/rpm
</span><span class='line'>
</span><span class='line'># 2016-5-12 15:28:35
</span><span class='line'># spec里面有define和global，应该是这个导致的！用global应该即可以了？
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# vi SPECS/wget.spec
</span><span class='line'>  # this is a sample spec file for wget
</span><span class='line'>  
</span><span class='line'>  %define _topdir /home/mywget
</span><span class='line'>  %define name    wget
</span><span class='line'>  %define release 2
</span><span class='line'>  %define version 1.17
</span><span class='line'>  # 定义 _buildrootdir 不起作用，不知道为啥??? 在 .rpmmacros 定义了 %_topdir，root转到 /home/mywget/rpm/BUILDROOT 了。
</span><span class='line'>  
</span><span class='line'>  %define _unpackaged_files_terminate_build 0
</span><span class='line'>  
</span><span class='line'>  Summary:   GNU wget
</span><span class='line'>  License:   GPL
</span><span class='line'>  Name:      %{name}
</span><span class='line'>  Version:   %{version}
</span><span class='line'>  Release:   %{release}
</span><span class='line'>  Source:    %{name}-%{version}.tar.gz
</span><span class='line'>  Prefix:    /usr/local/wget
</span><span class='line'>  Group:     Development/Tools
</span><span class='line'>  
</span><span class='line'>  %description
</span><span class='line'>  The GNU wget program downloads files from the Internet using the command-line.
</span><span class='line'>  
</span><span class='line'>  %prep
</span><span class='line'>  %setup -q
</span><span class='line'>  
</span><span class='line'>  %build
</span><span class='line'>  ./configure
</span><span class='line'>  make
</span><span class='line'>  
</span><span class='line'>  %install
</span><span class='line'>  make install prefix=$RPM_BUILD_ROOT/usr/local/wget # or use DESTDIR=$RPM_BUILD_ROOT
</span><span class='line'>  
</span><span class='line'>  %post
</span><span class='line'>  echo "hello world"
</span><span class='line'>  
</span><span class='line'>  %preun
</span><span class='line'>  echo "bye"
</span><span class='line'>  
</span><span class='line'>  %clean
</span><span class='line'>  rm -rf $RPM_BUILD_ROOT
</span><span class='line'>  
</span><span class='line'>  %files
</span><span class='line'>  %defattr(-, root, root)
</span><span class='line'>  /usr/local/wget/bin/wget
</span><span class='line'>  
</span><span class='line'>[root@bdc25400cc63 mywget]# rpmbuild -vv -bb --clean SPECS/wget.spec 
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# tree .
</span><span class='line'>.
</span><span class='line'>├── BUILD
</span><span class='line'>├── RPMS
</span><span class='line'>│   └── x86_64
</span><span class='line'>│       ├── wget-1.17-2.x86_64.rpm
</span><span class='line'>│       └── wget-debuginfo-1.17-2.x86_64.rpm
</span><span class='line'>├── SOURCES
</span><span class='line'>│   └── wget-1.17.tar.gz
</span><span class='line'>├── SPECS
</span><span class='line'>│   └── wget.spec
</span><span class='line'>└── SRPMS
</span><span class='line'>
</span><span class='line'>6 directories, 4 files
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# rpm -qpl RPMS/x86_64/wget-1.17-2.x86_64.rpm  
</span><span class='line'>/usr/local/wget/bin/wget
</span></code></pre></td></tr></table></div></figure>


<p>接下来就可以直接拿到这个包到其他机器上安装了，如果自己建立了本地库，使用createrepo更新下，就可以使用yum安装最新打的包了。</p>

<p>注： <code>%pre</code> , <code>%post</code> 和 <code>%preun</code> , <code>%postun</code> 可以在安装前后执行一些脚本。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia-build]# mkdir BUILD RPMS SOURCES SPECS SRPMS
</span><span class='line'>[root@cu2 ganglia-build]# cd SOURCES/
</span><span class='line'>[root@cu2 SOURCES]# ll
</span><span class='line'>total 1272
</span><span class='line'>-rw-r--r-- 1 root root 1302320 Jan 20 09:35 ganglia-3.7.2.tar.gz
</span><span class='line'>[root@cu2 SOURCES]# cd ..
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia-build]# ll
</span><span class='line'>total 20
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jun 15 10:25 BUILD
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jun 15 10:25 RPMS
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jun 15 10:25 SOURCES
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jun 15 10:25 SPECS
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jun 15 10:25 SRPMS
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia-build]# cd SPECS/
</span><span class='line'>[root@cu2 SPECS]# vi gmetad.spec
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia-build]# rpmbuild --clean -v -ba SPECS/gmetad.spec 
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia-build]# rpm -qpl RPMS/x86_64/ganglia-3.7.2-1.el6.x86_64.rpm </span></code></pre></td></tr></table></div></figure>


<h2>重新打包已有rpm</h2>

<p>下载源码包，再修改内容，最后使用rpm-build重新打包。</p>

<p>这里以puppetserver为例，使用jdk7即可但官网打包的依赖是jdk8，这里修改依赖然后重新打包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 rpmbuild]# rpm -ivh puppetserver-2.3.1-1.el6.src.rpm 
</span><span class='line'>warning: puppetserver-2.3.1-1.el6.src.rpm: Header V4 RSA/SHA1 Signature, key ID 4bd6ec30: NOKEY
</span><span class='line'>   1:puppetserver           warning: user mockbuild does not exist - using root
</span><span class='line'>warning: group mockbuild does not exist - using root
</span><span class='line'>########################################### [100%]
</span><span class='line'>warning: user mockbuild does not exist - using root
</span><span class='line'>warning: group mockbuild does not exist - using root
</span><span class='line'>[root@cu2 rpmbuild]# ll
</span><span class='line'>total 32904
</span><span class='line'>-rw-r--r-- 1 root root 33681889 May 10 17:44 puppetserver-2.3.1-1.el6.src.rpm
</span><span class='line'>drwxr-xr-x 2 root root     4096 May 10 17:55 SOURCES
</span><span class='line'>drwxr-xr-x 2 root root     4096 May 10 17:55 SPECS
</span><span class='line'>
</span><span class='line'>#-- 注释掉jdk8的部分
</span><span class='line'>[root@cu2 rpmbuild]# grep -3 jdk SPECS/puppetserver.spec 
</span><span class='line'>
</span><span class='line'># java 1.8.0 is available starting in fedora 20 and el 6
</span><span class='line'>#%if 0%{?fedora} &gt;= 20 || 0%{?rhel} &gt;= 6
</span><span class='line'>#%global open_jdk          java-1.8.0-openjdk-headless
</span><span class='line'>#%else
</span><span class='line'>%global open_jdk          java-1.7.0-openjdk
</span><span class='line'>#%endif
</span><span class='line'>
</span><span class='line'>[root@cu2 rpmbuild]# yum install -y ruby
</span><span class='line'>[root@cu2 rpmbuild]# rpmbuild -v -bb --clean SPECS/puppetserver.spec 
</span><span class='line'>
</span><span class='line'>[root@cu2 rpmbuild]# yum deplist RPMS/noarch/puppetserver-2.3.1-1.el6.noarch.rpm 
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Finding dependencies: 
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: centos.ustc.edu.cn
</span><span class='line'> * centosplus: centos.ustc.edu.cn
</span><span class='line'> * epel: mirror01.idc.hinet.net
</span><span class='line'> * extras: centos.ustc.edu.cn
</span><span class='line'> * updates: centos.ustc.edu.cn
</span><span class='line'>193 packages excluded due to repository priority protections
</span><span class='line'>package: puppetserver.noarch 2.3.1-1.el6
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>  dependency: /bin/bash
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: java-1.7.0-openjdk
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.79-2.5.5.4.el6
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.101-2.6.6.1.el6_7
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.85-2.6.1.3.el6_6
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.85-2.6.1.3.el6_7
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.91-2.6.2.2.el6_7
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.95-2.6.4.0.el6_7
</span><span class='line'>   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.99-2.6.5.0.el6_7
</span><span class='line'>  dependency: puppet-agent &gt;= 1.4.0
</span><span class='line'>   provider: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: net-tools
</span><span class='line'>   provider: net-tools.x86_64 1.60-110.el6_2
</span><span class='line'>  dependency: /usr/bin/env
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6_7.3
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: config(puppetserver) = 2.3.1-1.el6
</span><span class='line'>   provider: puppetserver.noarch 2.3.1-1.el6 
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
