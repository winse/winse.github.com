<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-05-03T21:36:40+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hiera and Facts]]></title>
    <link href="http://winseliu.com/blog/2016/05/03/hiera-and-facts/"/>
    <updated>2016-05-03T18:30:41+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/03/hiera-and-facts</id>
    <content type="html"><![CDATA[<p>为什么用hiera： <a href="https://docs.puppet.com/hiera/3.1/#why-hiera">https://docs.puppet.com/hiera/3.1/#why-hiera</a></p>

<ul>
<li>hierarchy层级体系。可以设置公共属性，也可以覆写！</li>
<li>&ldquo;注入&#8221;设置 class 中的属性值。</li>
<li>hiera_include 通过配置来完成site.pp同样的功能，并且比 <code>node</code> 更加强大灵活（数组对象可以合并）。</li>
</ul>


<p>基本概念：</p>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/configuring.html">hiera.yaml</a> 默认配置文件放在 $codedir/hiera.yaml 。 结合puppet使用时可以通过修改 puppet.conf 的 hiera_config 自定义配置的文件。</li>
<li><a href="https://docs.puppet.com/hiera/3.1/hierarchy.html">hierarchy</a> hierarchy定义好可以简化很多工作量。如需要根据操作系统 %{::osfamily} 进行适配。</li>
<li><a href="https://docs.puppet.com/hiera/3.1/data_sources.html#yaml">datasource</a> yaml格式介绍。</li>
</ul>


<h2>windows cygwin命令行环境配置</h2>

<pre><code>winse@Lenovo-PC ~
$ cat bin/hiera
#!/bin/sh

# default puppetlabs config in c:\Users\winse\Puppetlabs
export HOME=/cygdrive/c/Users/winse

name=`basename $0`

# execute
"C:/Progra~1/Puppet~1/Puppet/bin"/$name.bat "$@"


winse@Lenovo-PC ~
$ cat .bash_profile
...
function hiera_look(){
  code_dir=`puppet config print codedir | sed 's/\r//' `
  ~/bin/hiera -c "$code_dir/hiera.yaml" --debug "$@" ::environment=production
}
</code></pre>

<h2>HelloWorld</h2>

<pre><code>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat /cygdrive/c/Users/winse/.puppetlabs/etc/puppet/puppet.conf
[main]
codedir = D:/eshore-shells/puppet/dta/code
hiera_config = $codedir/hiera.yaml

certname = winse

winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat hiera.yaml
---
:backends:
  - yaml
:hierarchy:
  - "nodes/%{::trusted.certname}"
  - common

:yaml:
  :datadir: "D:/eshore-shells/puppet/dta/code/environments/%{::environment}/hieradata"


winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat environments/production/hieradata/common.yaml
whoami: winse


winse@Lenovo-PC ~
$ hiera_look whoami
DEBUG: 2016-05-03 11:27:41 +0100: Hiera YAML backend starting
DEBUG: 2016-05-03 11:27:41 +0100: Looking up whoami in YAML backend
DEBUG: 2016-05-03 11:27:41 +0100: Looking for data source common
DEBUG: 2016-05-03 11:27:41 +0100: Found whoami in common
winse
</code></pre>

<h2><strong>与Puppet结合使用</strong></h2>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/puppet.html">https://docs.puppet.com/hiera/3.1/puppet.html</a></li>
<li><a href="https://docs.puppet.com/hiera/3.1/puppet.html#assigning-classes-to-nodes-with-hiera-hierainclude">https://docs.puppet.com/hiera/3.1/puppet.html#assigning-classes-to-nodes-with-hiera-hierainclude</a></li>
<li>单值属性重复优先级：就近原则 <a href="https://docs.puppet.com/hiera/3.1/hierarchy.html#example">https://docs.puppet.com/hiera/3.1/hierarchy.html#example</a></li>
</ul>


<h4>参考案例</h4>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/complete_example.html">https://docs.puppet.com/hiera/3.1/complete_example.html</a></li>
<li><a href="https://kisspuppet.gitbooks.io/puppet/content/puppet_learning_ext1.html">https://kisspuppet.gitbooks.io/puppet/content/puppet_learning_ext1.html</a></li>
</ul>


<h4>主要功能</h4>

<ul>
<li>hiera获取puppet-facts的属性</li>
<li>puppet读取hiera中的属性</li>
<li>hiera注入设置puppet-module的属性：
  获取到第一个就返回了(类似于hiera)，对于strings, arrays, hashes类型 cannot merge values from multiple hierarchy levels; 需要使用来 hiera_array or hiera_hash 代替。</li>
<li>hiera_include</li>
</ul>


<h4>动手实践</h4>

<pre><code>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code/environments/production
$ tree .
.
├── hieradata
│   ├── common.yaml
│   └── nodes
│       └── winse.yaml
├── manifests
│   └── site.pp
└── modules
    └── helloworld
        └── manifests
            └── init.pp

$ cat hieradata/common.yaml
whoami: "%{calling_module} - %{calling_class} - %{calling_class_path} - %{::domain}"

$ cat hieradata/nodes/winse.yaml  | iconv -f gbk -t utf8
---
classes:
  - helloworld::hello
  - helloworld::world

# 文件编码需要要环境匹配，windows要GBK的
helloworld::hello::hello: 你好

$ cat modules/helloworld/manifests/init.pp

class helloworld::hello ($hello = "hello"){

  notify {$hello :
  }

}

class helloworld::world {

  notify {hiera('whoami') : # 不推荐在module中使用hiera方法，这里仅为了演示获取calling_module等
  }

}

$ cat manifests/site.pp

hiera_include('classes')

$ puppet apply environments/production/manifests/site.pp
Notice: Compiled catalog for winse in environment production in 0.28 seconds
Notice: 你好
Notice: /Stage[main]/Helloworld::Hello/Notify[你好]/message: defined 'message' as '你好'
Notice: helloworld - helloworld::world - helloworld/world - DHCP HOST
Notice: /Stage[main]/Helloworld::World/Notify[helloworld - helloworld::world - helloworld/world - DHCP HOST]/message: defined 'message' as 'helloworld - helloworld::world - helloworld/world - DHCP HOST'
Notice: Applied catalog in 0.02 seconds

# 测试获取hiera变量
$ puppet apply -e "notice(hiera('whoami'))"
Notice: Scope(Class[main]):  -  -  - DHCP HOST
Notice: Compiled catalog for winse in environment production in 0.05 seconds
Notice: Applied catalog in 0.03 seconds

$ puppet apply -e "notice(hiera('classes'))"
Notice: Scope(Class[main]): [helloworld::hello, helloworld::world]
Notice: Compiled catalog for winse in environment production in 0.05 seconds
Notice: Applied catalog in 0.02 seconds
</code></pre>

<h2>facts</h2>

<ul>
<li><a href="https://docs.puppet.com/facter/3.1/">https://docs.puppet.com/facter/3.1/</a></li>
<li>系统自带指标 <a href="https://docs.puppet.com/facter/3.1/core_facts.html">https://docs.puppet.com/facter/3.1/core_facts.html</a></li>
</ul>


<h4>自定义指标</h4>

<ul>
<li><a href="https://docs.puppet.com/facter/3.1/custom_facts.html">https://docs.puppet.com/facter/3.1/custom_facts.html</a></li>
<li>Example <a href="https://docs.puppet.com/facter/3.1/fact_overview.html">https://docs.puppet.com/facter/3.1/fact_overview.html</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MCollective Plugins]]></title>
    <link href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/"/>
    <updated>2016-04-28T21:37:51+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/28/mcollective-plugins</id>
    <content type="html"><![CDATA[<p>上一篇介绍了mcollective的安装。乘着这股热情把 mco 命令行和插件的安装弄通，记录下来。</p>

<h2>基本命令使用</h2>

<ul>
<li><a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html">https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  rpc             Generic RPC agent client application
</span></code></pre></td></tr></table></div></figure>


<p>自带的插件只能用来查看环境情况(下面列出来的命令<a href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/#cli-simple-usage">上一篇:MCollective安装配置</a>都已记录过)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mco ping
</span><span class='line'>mco inventory [server_host]
</span><span class='line'>mco facts [fact]</span></code></pre></td></tr></table></div></figure>


<p>mcollective 的 filter（适配节点）功能很强大，具体查看文档：<a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html#selecting-request-targets-using-filters">Selecting Request Targets Using Filters</a></p>

<h2>插件安装</h2>

<ul>
<li><a href="https://docs.puppet.com/mcollective/deploy/standard.html#install-agent-plugins">https://docs.puppet.com/mcollective/deploy/standard.html#install-agent-plugins</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/plugins.html">Installing Plugins</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/plugins.html#example">https://docs.puppet.com/mcollective/deploy/plugins.html#example</a></li>
</ul>


<p>文档中描述了 Use packages 和 Put files directly into the libdir 两种安装插件的方式。但是 Packages 都是放在<a href="http://yum.puppetlabs.com/el/6/products/x86_64/">旧的repo</a>里面，我们这里使用第二种方式把github下载源码放到libdir来安装。</p>

<h4>安装mcollective-puppet-agent</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 使用文档 https://github.com/puppetlabs/mcollective-puppet-agent#readme
</span><span class='line'># 直接下载release版本 
</span><span class='line'>[root@hadoop-master2 ~]# cd /usr/libexec/mcollective/
</span><span class='line'>[root@hadoop-master2 mcollective]# ll
</span><span class='line'>total 44
</span><span class='line'>-rw-r--r-- 1 root root 44759 Apr 29 11:53 mcollective-puppet-agent-1.10.0.tar.gz
</span><span class='line'>[root@hadoop-master2 mcollective]# tar zxf mcollective-puppet-agent-1.10.0.tar.gz  
</span><span class='line'>[root@hadoop-master2 mcollective]# ll mcollective-puppet-agent-1.10.0
</span><span class='line'>total 60
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 agent
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 aggregate
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 application
</span><span class='line'>-rw-rw-r-- 1 root root  3456 Apr 13  2015 CHANGELOG.md
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 data
</span><span class='line'>drwxrwxr-x 4 root root  4096 Apr 13  2015 ext
</span><span class='line'>-rw-rw-r-- 1 root root   349 Apr 13  2015 Gemfile
</span><span class='line'>-rw-rw-r-- 1 root root  3036 Apr 13  2015 Rakefile
</span><span class='line'>-rw-rw-r-- 1 root root 14739 Apr 13  2015 README.md
</span><span class='line'>drwxrwxr-x 9 root root  4096 Apr 13  2015 spec
</span><span class='line'>drwxrwxr-x 3 root root  4096 Apr 13  2015 util
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 validator
</span><span class='line'># 官网提供example有区分服务端和客户端文件。反正多了没问题，直接全部放就行咯。。。
</span><span class='line'>[root@hadoop-master2 mcollective]# mv mcollective-puppet-agent-1.10.0 mcollective
</span><span class='line'>
</span><span class='line'># 验证
</span><span class='line'># 多了puppet的命令！
</span><span class='line'>[root@hadoop-master2 mcollective]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  puppet          Schedule runs, enable, disable and interrogate the Puppet Agent
</span><span class='line'>  rpc             Generic RPC agent client application
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 同步到mcollective-servers （172.17.0.2对应hadoop-slaver1）
</span><span class='line'>[root@hadoop-master2 mcollective]# rsync -az /usr/libexec/mcollective 172.17.0.2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># mcollective-server添加插件后，重启mcollective服务
</span><span class='line'># 也可以使用 reload-agents 来重新加载agents： service mcollective reload-agents
</span><span class='line'>[root@hadoop-slaver1 libexec]# service mcollective restart
</span><span class='line'>Shutting down mcollective:                                 [  OK  ]
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 验证server，已经可以看到新添加的puppet命令了
</span><span class='line'>[root@hadoop-master2 mcollective]# mco inventory hadoop-slaver1
</span><span class='line'>Inventory for hadoop-slaver1:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-04-29 12:01:40 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 123
</span><span class='line'>               Total Messages: 1
</span><span class='line'>      Messages Passed Filters: 1
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 0
</span><span class='line'>         Total Processor Time: 0.67 seconds
</span><span class='line'>                  System Time: 0.8 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       puppet          rpcutil        
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat           puppet          resource       
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco help puppet
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco puppet status    
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-slaver1: Currently stopped; last completed run 10 hours 57 minutes 20 seconds ago
</span><span class='line'>   hadoop-master1: Currently stopped; last completed run 11 hours 1 minutes 05 seconds ago
</span><span class='line'>   hadoop-slaver2: Currently stopped; last completed run 10 hours 57 minutes 16 seconds ago
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 配置server.conf
</span><span class='line'># 注意：真正要执行puppet命令，为了适配puppet4需要添加/修改配置
</span><span class='line'>-bash-4.1# cat /etc/puppetlabs/mcollective/server.cfg 
</span><span class='line'>...
</span><span class='line'>plugin.puppet.command = /opt/puppetlabs/bin/puppet agent
</span><span class='line'>plugin.puppet.config = /etc/puppetlabs/puppet/puppet.conf
</span><span class='line'>
</span><span class='line'># 重启所有mcollective（也可以不重启，重新加载agent即可： 使用 mco shell run service mcollective reload-agents 来重新加载）
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco puppet runall 1
</span><span class='line'>2016-04-29 16:52:46: Running all nodes with a concurrency of 1
</span><span class='line'>2016-04-29 16:52:46: Discovering enabled Puppet nodes to manage
</span><span class='line'>2016-04-29 16:52:49: Found 3 enabled nodes
</span><span class='line'>2016-04-29 16:52:50: hadoop-slaver1 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:55: hadoop-slaver2 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:59: hadoop-master1 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:59: Iteration complete. Initiated a Puppet run on 3 nodes.
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# mco puppet status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-master1: Currently stopped; last completed run 10 seconds ago
</span><span class='line'>   hadoop-slaver1: Currently stopped; last completed run 15 seconds ago
</span><span class='line'>   hadoop-slaver2: Currently stopped; last completed run 04 seconds ago
</span><span class='line'>...
</span><span class='line'># 或者通过 puppetexplorer 查看节点最后的更新时间
</span></code></pre></td></tr></table></div></figure>


<h4>安装 package / service 插件</h4>

<p>为了更好的管理，再添加 package 和 service 两个插件</p>

<ul>
<li><a href="https://github.com/puppetlabs/mcollective-package-agent#readme">https://github.com/puppetlabs/mcollective-package-agent#readme</a></li>
<li><a href="https://github.com/puppetlabs/mcollective-service-agent#readme">https://github.com/puppetlabs/mcollective-service-agent#readme</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://stackoverflow.com/questions/8488253/how-to-force-cp-to-overwrite-without-confirmation
</span><span class='line'>[root@hadoop-master2 mcollective]# unalias cp
</span><span class='line'>[root@hadoop-master2 mcollective]# cp -rf mcollective-service-agent-3.1.3/* mcollective/   
</span><span class='line'>[root@hadoop-master2 mcollective]# cp -rf mcollective-package-agent-4.4.0/* mcollective/
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# rsync -az /usr/libexec/mcollective 172.17.0.2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># 重启mcollective服务（或者 mco shell run service mcollective reload-agents 重新加载）
</span></code></pre></td></tr></table></div></figure>


<p>验证下package的实力：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 mcollective]# mco package lrzsz status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-slaver1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-master1: -purged.
</span><span class='line'>   hadoop-slaver2: -purged.
</span><span class='line'>
</span><span class='line'>Summary of Arch:
</span><span class='line'>
</span><span class='line'>   x86_64 = 1
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>             purged = 2
</span><span class='line'>   0.12.20-27.1.el6 = 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 1488.41 ms
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco rpc package install package=lrzsz
</span><span class='line'>Discovering hosts using the mc method for 2 second(s) .... 3
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>hadoop-slaver1                           Unknown Request Status
</span><span class='line'>   Package is already installed
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>   0.12.20-27.1.el6 = 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 14525.03 ms
</span><span class='line'>[root@hadoop-master2 mcollective]# mco package lrzsz status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-master1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-slaver2: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-slaver1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>
</span><span class='line'>Summary of Arch:
</span><span class='line'>
</span><span class='line'>   x86_64 = 3
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>   0.12.20-27.1.el6 = 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 572.13 ms
</span></code></pre></td></tr></table></div></figure>


<p>还有很多的插件：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/plugin_directory/index.html">https://docs.puppet.com/mcollective/plugin_directory/index.html</a></li>
<li>shell插件也不错，安装的时刻注意一下目录结构！<a href="https://github.com/puppetlabs/mcollective-shell-agent">https://github.com/puppetlabs/mcollective-shell-agent</a></li>
</ul>


<p>添加了 service，package，shell，puppet 插件后，用 mco 来执行管理集群太爽了！！</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MCollective安装配置]]></title>
    <link href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/"/>
    <updated>2016-04-28T08:39:23+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/28/mcollective-quick-start</id>
    <content type="html"><![CDATA[<p>puppet agent 通过定时拉取的方式来更新本地系统，但无法满足实时更新的需求。 mcollective 通过 <strong>消息中间件</strong> 的方式，mclient/mservers通过消息的推送/订阅，实现mservers实时执行mclient提交的请求。（添加 m 说明是mcollective的组件！）</p>

<p>最新版的安装除了官网，没有其他可以直接学习的资料（只能参考）。先看官网的资料：</p>

<ul>
<li>组件功能(必须看看) <a href="https://docs.puppet.com/mcollective/overview_components.html">https://docs.puppet.com/mcollective/overview_components.html</a></li>
<li>部署 <a href="https://docs.puppet.com/mcollective/deploy/install.html">https://docs.puppet.com/mcollective/deploy/install.html</a></li>
<li>部署规范/准则 <a href="https://docs.puppet.com/mcollective/deploy/standard.html">https://docs.puppet.com/mcollective/deploy/standard.html</a></li>
</ul>


<p>摘录官网安装描述：[Installing MCollective requires the following steps]</p>

<ul>
<li>Make sure your middleware is up and running and your firewalls are in order.</li>
<li>Install the mcollective package on servers, then make sure the mcollective service is running.</li>
<li>Install the mcollective-client package on admin workstations.</li>
<li>Most Debian-like and Red Hat-like systems can use the official Puppet Labs packages. Enable the Puppet Labs repos, or import the packages into your own repos.

<ul>
<li>If you’re on Debian/Ubuntu, mind the missing package dependency.</li>
</ul>
</li>
<li>If your systems can’t use the official packages, check the system requirements and either build your own or run from source.</li>
</ul>


<p>mcollective对于puppet来说是一个锦上添花的组件，没有puppet一样正常运转。部署主要由两个部分组成：</p>

<ul>
<li>部署消息中间件</li>
<li>配置mcollective(puppet4.4 agent已经安装该功能，redhat也自带装了Stomp包：<code>/opt/puppetlabs/puppet/lib/ruby/gems/2.1.0/gems/</code> 目录下面)

<ul>
<li>配置mclient/mserver</li>
<li>配置Stomp with TLS</li>
<li>配置security</li>
</ul>
</li>
</ul>


<p>本文先简单实现连接远程主机，然后配置安全功能，最后用puppet来重新实现 mcollective 的安装和配置。</p>

<h1>环境说明</h1>

<ul>
<li>hadoop-master2:

<ul>
<li>172.17.42.1</li>
<li>puppetserver, activemq-server, mcollective-client</li>
</ul>
</li>
<li>hadoop-master1/hadoop-slaver1/hadoop-slaver2:

<ul>
<li>172.17.0.2/&frac34;</li>
<li>puppet-agent, mcollective-server</li>
</ul>
</li>
</ul>


<h1>ActiveMQ部署</h1>

<p>activemq的服务端是一个spring-jetty项目，直接解压运行启动脚本即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://activemq.apache.org/download-archives.html
</span><span class='line'># 直接下载最新的 tar.gz
</span><span class='line'>
</span><span class='line'># 解压，启动
</span><span class='line'>On Unix:
</span><span class='line'>From a command shell, change to the installation directory and run ActiveMQ as a foregroud process:
</span><span class='line'>cd [activemq_install_dir]/bin
</span><span class='line'>./activemq console
</span><span class='line'>From a command shell, change to the installation directory and run ActiveMQ as a daemon process:
</span><span class='line'>cd [activemq_install_dir]/bin
</span><span class='line'>./activemq start
</span><span class='line'>
</span><span class='line'># 确认
</span><span class='line'>URL: http://127.0.0.1:8161/admin/
</span><span class='line'>Login: admin
</span><span class='line'>Passwort: admin
</span><span class='line'># 起了好多端口，随便试一个
</span><span class='line'>netstat -nl|grep 61616
</span><span class='line'>netstat -anp|grep PID
</span><span class='line'>
</span><span class='line'># 数据/日志目录
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# ll data/
</span><span class='line'>total 16
</span><span class='line'>-rw-r--r-- 1 root users 4276 Apr 27 21:36 activemq.log
</span><span class='line'>-rw-r--r-- 1 root root     5 Apr 27 21:36 activemq.pid
</span><span class='line'>-rw-r--r-- 1 root root     0 Apr 27 21:36 audit.log
</span><span class='line'>drwxr-xr-x 2 root root  4096 Apr 27 21:36 kahadb</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/mcollective-activemq.png" alt="" /></p>

<p>查看连接密码：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 conf]# cat credentials.properties
</span><span class='line'>...
</span><span class='line'>activemq.username=system
</span><span class='line'>activemq.password=manager
</span><span class='line'>guest.password=password[root@hadoop-master2 conf]# 
</span></code></pre></td></tr></table></div></figure>


<h1>简单配置(unencrypted Stomp) <a name="cli-simple-usage"></a></h1>

<p>安装puppet4.4后，mcollective已经安装好了！直接修改配置连接到activemq即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 puppetlabs]# chkconfig --list | grep mco
</span><span class='line'>mcollective     0:off   1:off   2:off   3:off   4:off   5:off   6:off
</span><span class='line'>
</span><span class='line'># puppetserver作为mcollective-client
</span><span class='line'>[root@hadoop-master2 mcollective]# cat client.cfg                    
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61613
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>No responses received
</span><span class='line'>
</span><span class='line'># puppet agent作为mcollective-server
</span><span class='line'>-bash-4.1# cat server.cfg 
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61613
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>-bash-4.1# service mcollective start
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>-bash-4.1# service mcollective status
</span><span class='line'>mcollectived (pid  202) is running...
</span><span class='line'>
</span><span class='line'># 其他两台agent机器一样的配置操作
</span><span class='line'>
</span><span class='line'># 1. mcollective-client(puppetserver) 测试
</span><span class='line'>[root@hadoop-master2 ~]# mco find
</span><span class='line'>hadoop-master1
</span><span class='line'>hadoop-slaver2
</span><span class='line'>hadoop-slaver1
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping
</span><span class='line'>hadoop-master1                           time=148.29 ms
</span><span class='line'>hadoop-slaver2                           time=187.99 ms
</span><span class='line'>hadoop-slaver1                           time=190.21 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 190.21 min: 148.29 avg: 175.50 
</span><span class='line'>
</span><span class='line'># 2. 先查看/扫描节点状态。（如果配置了facts后，会输出一长串的Facts！）
</span><span class='line'>[root@hadoop-master2 ssl]# mco inventory hadoop-master1
</span><span class='line'>Inventory for hadoop-master1:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-04-29 00:21:31 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 155
</span><span class='line'>               Total Messages: 13
</span><span class='line'>      Messages Passed Filters: 3
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 2
</span><span class='line'>         Total Processor Time: 2.32 seconds
</span><span class='line'>                  System Time: 0.3 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       rpcutil                        
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat                                          
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>
</span><span class='line'># 3. 获取节点facts，需要配合puppet一起来使用
</span><span class='line'># puppetserver 配置更新agent facts.yaml信息
</span><span class='line'>[root@hadoop-master2 manifests]# cat site.pp 
</span><span class='line'>file{'/etc/puppetlabs/mcollective/facts.yaml':
</span><span class='line'>  owner    =&gt; root,
</span><span class='line'>  group    =&gt; root,
</span><span class='line'>  mode     =&gt; '400',
</span><span class='line'>  loglevel =&gt; debug, # reduce noise in Puppet reports
</span><span class='line'>  content  =&gt; inline_template("&lt;%= scope.to_hash.reject { |k,v| k.to_s =~ /(uptime_seconds|timestamp|free)/ }.to_yaml %&gt;"), # exclude rapidly changing facts
</span><span class='line'>}
</span><span class='line'># 读取facts
</span><span class='line'>[root@hadoop-master2 manifests]# mco facts hostname
</span><span class='line'>Report for fact: hostname
</span><span class='line'>
</span><span class='line'>        hadoop-master1                           found 1 times
</span><span class='line'>        hadoop-slaver1                           found 1 times
</span><span class='line'>        hadoop-slaver2                           found 1 times
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 579.93 ms
</span></code></pre></td></tr></table></div></figure>


<p>自带的插件功能比较少，要真正把 mcollective 用起来需要安装插件：puppet, service, package等等。这篇主要记录安装过程，<a href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/">插件安装以及使用</a>后面具体实践了再写。</p>

<p>我觉得内网生产环境安装，到这一步已经差不多了！下面的安全配置就当深入学习吧。</p>

<h1>Stomp with TLS 配置</h1>

<ul>
<li><a href="https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html">https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html">https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html</a></li>
</ul>


<p><strong>Anonymous TLS</strong> 步骤简单一点，这里就不列出来了，自己去看官网的文档: <a href="https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html#anonymous-tls">Anonymous TLS</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># CA-Verified TLS
</span><span class='line'>
</span><span class='line'># 1 手动配置activemq
</span><span class='line'>
</span><span class='line'># 1.1 可以直接用puppet的cert/private-keys，我这里新生成一个activemq的证书
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet master --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'># 一个不冲突的名称即可，不需要是hostname/FQDN
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet cert generate activemq
</span><span class='line'>Notice: activemq has a waiting certificate request
</span><span class='line'>Notice: Signed certificate request for activemq
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest activemq at '/etc/puppetlabs/puppet/ssl/ca/requests/activemq.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest activemq at '/etc/puppetlabs/puppet/ssl/certificate_requests/activemq.pem'
</span><span class='line'>[root@hadoop-master2 puppetlabs]# tree /etc/puppetlabs/puppet/ssl/
</span><span class='line'>/etc/puppetlabs/puppet/ssl/
</span><span class='line'>...
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── activemq.pem
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── hadoop-master2.example.com.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   ├── activemq.pem
</span><span class='line'>│   └── hadoop-master2.example.com.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    ├── activemq.pem
</span><span class='line'>    └── hadoop-master2.example.com.pem
</span><span class='line'>
</span><span class='line'>9 directories, 22 files
</span><span class='line'>
</span><span class='line'># certs/activemq.pem, certs/ca.pem, private_keys/activemq.pem 就是我们需要的。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.2 创建Truststore
</span><span class='line'>[root@hadoop-master2 puppetlabs]# which keytool
</span><span class='line'>/opt/jdk1.7.0_60/bin/keytool
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cd /etc/puppetlabs/puppet/ssl            
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -import -alias "CU CA" -file certs/ca.pem -keystore truststore.jks
</span><span class='line'>Enter keystore password:  
</span><span class='line'>Re-enter new password: 
</span><span class='line'>Owner: CN=Puppet CA: hadoop-master2.example.com
</span><span class='line'>Issuer: CN=Puppet CA: hadoop-master2.example.com
</span><span class='line'>...
</span><span class='line'>Trust this certificate? [no]:  y
</span><span class='line'>Certificate was added to keystore
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 32
</span><span class='line'>drwxr-xr-x 5 puppet puppet 4096 Apr 23 00:01 ca
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 certificate_requests
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 certs
</span><span class='line'>-rw-r--r-- 1 puppet puppet  979 Apr 28 10:33 crl.pem
</span><span class='line'>drwxr-x--- 2 puppet puppet 4096 Apr 22 23:51 private
</span><span class='line'>drwxr-x--- 2 puppet puppet 4096 Apr 28 19:53 private_keys
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 public_keys
</span><span class='line'>-rw-r--r-- 1 root   root   1496 Apr 28 20:01 truststore.jks
</span><span class='line'># 验证下指纹fingerprints
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -list -keystore truststore.jks 
</span><span class='line'>Enter keystore password:  
</span><span class='line'>
</span><span class='line'>Keystore type: JKS
</span><span class='line'>Keystore provider: SUN
</span><span class='line'>
</span><span class='line'>Your keystore contains 1 entry
</span><span class='line'>
</span><span class='line'>cu ca, Apr 28, 2016, trustedCertEntry, 
</span><span class='line'>Certificate fingerprint (SHA1): 40:2C:45:37:6B:C7:9C:92:E7:4D:1E:4F:2B:C4:17:F4:A3:5F:EB:56
</span><span class='line'>[root@hadoop-master2 ssl]# openssl x509 -in certs/ca.pem -fingerprint -sha1
</span><span class='line'>SHA1 Fingerprint=40:2C:45:37:6B:C7:9C:92:E7:4D:1E:4F:2B:C4:17:F4:A3:5F:EB:56
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.3 创建Keystore
</span><span class='line'>[root@hadoop-master2 ssl]# cat private_keys/activemq.pem certs/activemq.pem &gt;activemq.pem
</span><span class='line'># 所有密码都需一致！！ All of these passwords must be the same.
</span><span class='line'>[root@hadoop-master2 ssl]# openssl pkcs12 -export -in activemq.pem -out activemq.p12 -name activemq      
</span><span class='line'>Enter Export Password:
</span><span class='line'>Verifying - Enter Export Password:
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -importkeystore -destkeystore keystore.jks -srckeystore activemq.p12 \
</span><span class='line'>&gt; -srcstoretype PKCS12 -alias activemq
</span><span class='line'>Enter destination keystore password:  
</span><span class='line'>Re-enter new password: 
</span><span class='line'>Enter source keystore password:  
</span><span class='line'>[root@hadoop-master2 ssl]# ll -t
</span><span class='line'>total 52
</span><span class='line'>-rw-r--r-- 1 root   root   3918 Apr 28 20:12 keystore.jks
</span><span class='line'>-rw-r--r-- 1 root   root   4230 Apr 28 20:08 activemq.p12
</span><span class='line'>-rw-r--r-- 1 root   root   5203 Apr 28 20:07 activemq.pem
</span><span class='line'>-rw-r--r-- 1 root   root   1496 Apr 28 20:01 truststore.jks
</span><span class='line'>...
</span><span class='line'># 验证指纹
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -list -keystore keystore.jks 
</span><span class='line'>Enter keystore password:  
</span><span class='line'>
</span><span class='line'>Keystore type: JKS
</span><span class='line'>Keystore provider: SUN
</span><span class='line'>
</span><span class='line'>Your keystore contains 1 entry
</span><span class='line'>
</span><span class='line'>activemq, Apr 28, 2016, PrivateKeyEntry, 
</span><span class='line'>Certificate fingerprint (SHA1): 4F:DF:DE:64:13:36:0E:74:8B:7F:D3:61:78:29:C4:AA:4F:A4:ED:D8
</span><span class='line'>[root@hadoop-master2 ssl]# openssl x509 -in certs/activemq.pem -fingerprint -sha1
</span><span class='line'>SHA1 Fingerprint=4F:DF:DE:64:13:36:0E:74:8B:7F:D3:61:78:29:C4:AA:4F:A4:ED:D8
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.4 配置activemq
</span><span class='line'># http://activemq.apache.org/how-do-i-use-ssl.html
</span><span class='line'># https://docs.puppet.com/mcollective/deploy/middleware/activemq.html#tls-credentials
</span><span class='line'># https://docs.puppet.com/mcollective/deploy/middleware/activemq.html#stomp
</span><span class='line'>[root@hadoop-master2 ssl]# mv keystore.jks truststore.jks /opt/puppetlabs/apache-activemq-5.13.2/conf
</span><span class='line'>[root@hadoop-master2 ssl]# cd /opt/puppetlabs/apache-activemq-5.13.2/conf/
</span><span class='line'># 填上面步骤设置的密码
</span><span class='line'>[root@hadoop-master2 conf]# vi activemq.xml 
</span><span class='line'>...
</span><span class='line'>&lt;sslContext&gt;
</span><span class='line'>  &lt;sslContext keyStore="keystore.jks" keyStorePassword="XXXX"
</span><span class='line'>              trustStrore="truststore.jks" trustStorePassword="XXXX" /&gt;
</span><span class='line'>&lt;/sslContext&gt;
</span><span class='line'>
</span><span class='line'>&lt;transportConnectors&gt;
</span><span class='line'>  &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt;
</span><span class='line'>  &lt;transportConnector name="stomp+nio+ssl" uri="stomp+nio+ssl://0.0.0.0:61614?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600&amp;needClientAuth=true&amp;transport.enabledProtocols=TLSv1,TLSv1.1,TLSv1.2"/&gt;
</span><span class='line'>&lt;/transportConnectors&gt;
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# chmod 600 conf/activemq.xml 
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# bin/activemq stop
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# bin/activemq start
</span><span class='line'># 日志查看
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# less data/activemq.log 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 2 puppetserver(mcollective client)
</span><span class='line'># https://docs.puppet.com/mcollective/configure/client.html
</span><span class='line'>[root@hadoop-master2 ~]# cd /etc/puppetlabs/mcollective/
</span><span class='line'>[root@hadoop-master2 mcollective]# cat client.cfg
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61614
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>plugin.activemq.pool.1.ssl = true
</span><span class='line'>plugin.activemq.pool.1.ssl.ca = /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.key = /etc/puppetlabs/puppet/ssl/private_keys/hadoop-master2.example.com.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.cert = /etc/puppetlabs/puppet/ssl/certs/hadoop-master2.example.com.pem
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping -v
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>No responses received
</span><span class='line'>
</span><span class='line'># 3 puppet agents(mcollective servers)
</span><span class='line'># https://docs.puppet.com/mcollective/configure/server.html
</span><span class='line'>-bash-4.1# puppet agent --configprint confdir
</span><span class='line'>/etc/puppetlabs/puppet
</span><span class='line'>-bash-4.1# puppet agent --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>-bash-4.1# puppet agent --configprint hostprivkey
</span><span class='line'>/etc/puppetlabs/puppet/ssl/private_keys/hadoop-master1.example.com.pem
</span><span class='line'>-bash-4.1# puppet agent --configprint hostcert
</span><span class='line'>/etc/puppetlabs/puppet/ssl/certs/hadoop-master1.example.com.pem
</span><span class='line'>-bash-4.1# puppet agent --configprint localcacert
</span><span class='line'>/etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>
</span><span class='line'>-bash-4.1# cd /etc/puppetlabs/mcollective/
</span><span class='line'>-bash-4.1# cat server.cfg 
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61614
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>plugin.activemq.pool.1.ssl = true
</span><span class='line'>plugin.activemq.pool.1.ssl.ca = /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.key = /etc/puppetlabs/puppet/ssl/private_keys/hadoop-master1.example.com.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.cert = /etc/puppetlabs/puppet/ssl/certs/hadoop-master1.example.com.pem
</span><span class='line'>...
</span><span class='line'>-bash-4.1# service mcollective restart
</span><span class='line'>Shutting down mcollective: 
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>
</span><span class='line'># 其他两台机器一样的操作
</span><span class='line'>
</span><span class='line'># 测试
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping -v
</span><span class='line'>hadoop-master1                           time=41.99 ms
</span><span class='line'>hadoop-slaver2                           time=84.87 ms
</span><span class='line'>hadoop-slaver1                           time=85.46 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 85.46 min: 41.99 avg: 70.77 
</span></code></pre></td></tr></table></div></figure>


<p>更多activemq的设置查看官方文档： <a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq.html">ActiveMQ Config Reference for MCollective Users</a> <a href="https://raw.github.com/puppetlabs/marionette-collective/master/ext/activemq/examples/single-broker/activemq.xml">example activemq.xml</a></p>

<h1>SSL Security plugin</h1>

<p>Stomp with TLS (安全传输层协议)用于加密数据。而 security plugin 主要功能有：</p>

<ul>
<li>mcollective server要授权才会执行 client 发送的请求。</li>
<li>create a token that uniquely identify the client - based on the filename of the public key。</li>
<li>在请求中添加创建时间和TTL保证数据的完整性(不被拦截、篡改以及重复)。</li>
</ul>


<p>参考：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/configure/client.html#security-plugin-settings">https://docs.puppet.com/mcollective/configure/client.html#security-plugin-settings</a></li>
<li><a href="https://docs.puppet.com/mcollective/security.html">https://docs.puppet.com/mcollective/security.html</a></li>
<li><a href="https://docs.puppet.com/mcollective/reference/plugins/security_ssl.html">https://docs.puppet.com/mcollective/reference/plugins/security_ssl.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 1 生成server秘钥(公钥、私钥)
</span><span class='line'>[root@hadoop-master2 mcollective-security]# openssl genrsa -out server-private.pem 1024
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 mcollective-security]# openssl rsa -in server-private.pem -out server-public.pem -outform PEM -pubout  
</span><span class='line'>writing RSA key
</span><span class='line'>[root@hadoop-master2 mcollective-security]# ll
</span><span class='line'>total 12
</span><span class='line'>-rw-r--r-- 1 root root 7915 Apr 29 00:06 server-private.pem
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:07 server-public.pem
</span><span class='line'>
</span><span class='line'># 把 private/public 复制到所有的mcollective-servers节点
</span><span class='line'># 把 public 复制到mcollective-clients节点
</span><span class='line'>[root@hadoop-master2 mcollective-security]# ssh 172.17.0.2 mkdir -p /etc/puppetlabs/mcollective/ssl/clients
</span><span class='line'>[root@hadoop-master2 mcollective-security]# scp * 172.17.0.2:/etc/puppetlabs/mcollective/ssl/
</span><span class='line'>server-private.pem   100% 7915     7.7KB/s   00:00    
</span><span class='line'>server-public.pem    100% 1836     1.8KB/s   00:00    
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective-security]# mkdir -p /etc/puppetlabs/mcollective/ssl
</span><span class='line'>[root@hadoop-master2 mcollective-security]# cp server-public.pem /etc/puppetlabs/mcollective/ssl/
</span><span class='line'>
</span><span class='line'># 2 配置mcollective-servers。节点间配置不能同步，TLS配置的证书名称是不一样的！！
</span><span class='line'>-bash-4.1# vi /etc/puppetlabs/mcollective/server.cfg 
</span><span class='line'>...
</span><span class='line'># Plugins
</span><span class='line'>#securityprovider = psk
</span><span class='line'>#plugin.psk = unset
</span><span class='line'>
</span><span class='line'>securityprovider = ssl
</span><span class='line'>plugin.ssl_server_private = /etc/puppetlabs/mcollective/ssl/server-private.pem
</span><span class='line'>plugin.ssl_server_public = /etc/puppetlabs/mcollective/ssl/server-public.pem
</span><span class='line'>plugin.ssl_client_cert_dir = /etc/puppetlabs/mcollective/ssl/clients/
</span><span class='line'>plugin.ssl.enfore_ttl = 0
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>-bash-4.1# service mcollective restart
</span><span class='line'>Shutting down mcollective:                                 [  OK  ]
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'># 可以通过 /var/log/puppetlabs/mcollective.log 查看详细日志
</span><span class='line'>
</span><span class='line'># 配置一个节点后，mco ping已经不再显示hadoop-master1了！！
</span><span class='line'>
</span><span class='line'># 3 生成client秘钥
</span><span class='line'>[root@hadoop-master2 mcollective-security]# cd /etc/puppetlabs/mcollective/ssl
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x 2 root root 4096 Apr 29 00:15 clients
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:15 server-public.pem
</span><span class='line'>[root@hadoop-master2 ssl]# openssl genrsa -out winse-private.pem 1024    
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 ssl]# openssl rsa -in winse-private.pem -out winse-public.pem -outform PEM -pubout
</span><span class='line'>writing RSA key
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 16
</span><span class='line'>drwxr-xr-x 2 root root 4096 Apr 29 00:15 clients
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:15 server-public.pem
</span><span class='line'>-rw-r--r-- 1 root root  887 Apr 29 00:26 winse-private.pem
</span><span class='line'>-rw-r--r-- 1 root root  272 Apr 29 00:26 winse-public.pem
</span><span class='line'>
</span><span class='line'># 把client用户的公钥拷贝到所有mcollective-servers的ssl/clients目录下
</span><span class='line'>[root@hadoop-master2 ssl]# scp winse-public.pem 172.17.0.2:/etc/puppetlabs/mcollective/ssl/clients
</span><span class='line'>winse-public.pem 100%  272     0.3KB/s   00:00    
</span><span class='line'>
</span><span class='line'># 4 配置clients
</span><span class='line'>[root@hadoop-master2 ~]# vi /etc/puppetlabs/mcollective/client.cfg 
</span><span class='line'>...
</span><span class='line'># Plugins
</span><span class='line'>#securityprovider = psk
</span><span class='line'>#plugin.psk = unset
</span><span class='line'>securityprovider = ssl
</span><span class='line'>plugin.ssl_server_public = /etc/puppetlabs/mcollective/ssl/server-public.pem
</span><span class='line'>plugin.ssl_client_private = /etc/puppetlabs/mcollective/ssl/winse-private.pem
</span><span class='line'>plugin.ssl_client_public = /etc/puppetlabs/mcollective/ssl/winse-public.pem
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'># mcollective-server不需要重启！客户端连接测试
</span><span class='line'>[root@hadoop-master2 ssl]# mco ping -v
</span><span class='line'>hadoop-master1                           time=561.29 ms
</span><span class='line'>hadoop-slaver2                           time=601.91 ms
</span><span class='line'>hadoop-slaver1                           time=608.31 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 608.31 min: 561.29 avg: 590.50 
</span></code></pre></td></tr></table></div></figure>


<p>理解了功能后，再按条理配置其实感觉就不是那么难了。遇到问题先查看日志！！</p>

<h1>最佳实践</h1>

<p>官网推荐使用 站点管理工具 统一来安装管理，如puppet。下面使用puppet来配置mcollective：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/deploy/install.html#example">https://docs.puppet.com/mcollective/deploy/install.html#example</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html#creating-keystores-with-puppet">https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html#creating-keystores-with-puppet</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/standard.html#write-the-server-config-file">https://docs.puppet.com/mcollective/deploy/standard.html#write-the-server-config-file</a></li>
</ul>


<p>TODO</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[整理] Hadoop入门]]></title>
    <link href="http://winseliu.com/blog/2016/04/23/hadoop-guide-catalog/"/>
    <updated>2016-04-23T15:45:34+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/23/hadoop-guide-catalog</id>
    <content type="html"><![CDATA[<h2>1. 环境准备</h2>

<p>工欲善事其必先利其器。不要吝啬硬件上投入，找一个适合自己的环境！</p>

<ul>
<li>Windows

<ul>
<li><a href="http://winseliu.com/blog/2014/02/23/quickly-open-program-in-windows/">快速打开程序</a></li>
<li>Cygwin：Windows本地编译需要，执行命令比 cmd 更方便</li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2011/02/28/win7-install-fedora-linux/">Windows + Linux双系统</a></li>
<li>Linux

<ul>
<li><a href="http://winseliu.com/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a></li>
<li><a href="http://winseliu.com/blog/2015/09/13/review-linux-101-hacks/">【linux 101 Hacks】读后感</a>

<ul>
<li><a href="http://winseliu.com/images/blogs/linux-101-hacks-review-securecrt-config.png">Socket5代理</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/03/11/install-and-config-openvpn/">OpenVPN</a></li>
<li>docker

<ul>
<li><a href="http://winseliu.com/blog/2014/09/27/docker-start-guide-on-centos/">Docker入门</a></li>
<li><a href="http://winseliu.com/blog/2014/09/30/docker-ssh-on-centos/">配置ssh</a></li>
<li><a href="http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster/">Dnsmasq</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>2. 安装部署hadoop/spark</h2>

<h4>编译安装</h4>

<ul>
<li>Hadoop安装与升级:

<ul>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/">Docker中安装</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/">2.2升级到2.6</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/">HA配置</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/">HA升级</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6/">Centos6 Build hadoop2.6</a></li>
<li><a href="http://winseliu.com/blog/2015/03/09/windows-build-hadoop-2-dot-6/">Windows Build hadoop2.6</a></li>
<li><a href="http://winseliu.com/blog/2014/10/16/spark-build-and-configuration/">各版本Spark编译/搭建环境</a></li>
</ul>


<h4>功能优化</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/01/hadoop2-mapreduce-compress/">Hadoop2 Mapreduce输入输出压缩</a></li>
<li><a href="http://winseliu.com/blog/2014/07/29/hadoop2-use-shortcircuit-local-reading/">Hadoop2 ShortCircuit Local Reading</a></li>
<li><a href="http://winseliu.com/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>

<ul>
<li><a href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a></li>
</ul>
</li>
</ul>


<h4>维护</h4>

<ul>
<li><a href="http://winseliu.com/blog/2013/02/22/hadoop-cluster-increases-nodes/">Hadoop集群增加节点</a></li>
<li><a href="http://winseliu.com/blog/2014/07/29/safely-remove-datanode/">安全的关闭datanode</a></li>
<li><a href="http://winseliu.com/blog/2015/03/25/deploy-separated-yarn-on-exists-hdfs-cluster/">已有HDFS上部署yarn</a></li>
<li><a href="http://winseliu.com/blog/2015/06/10/hadoop-deploy-spark-diff-version-yarn-and-hdfs/">Hadoop不同版本yarn和hdfs混搭，spark-yarn环境配置</a></li>
</ul>


<h4>旧版本安装</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a></li>
<li><a href="http://winseliu.com/blog/2013/03/24/pseudo-distributed-hadoop-in-windows/"><del>Windows配置hadoop伪分布式环境(续)</del></a> 不再推荐cygwin下部署Hadoop。</li>
<li><a href="http://winseliu.com/blog/2013/03/02/quickly-build-a-second-hadoop-cluster/">快速搭建第二个hadoop分布式集群环境</a></li>
<li><a href="http://winseliu.com/blog/2013/03/27/run-on-hadoop-on-ant/"><del>Ant实现hadoop插件Run-on-Hadoop</del></a></li>
</ul>


<h2>3. 进阶</h2>

<h4>配置深入理解</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/08/02/hadoop-datanode-config-should-equals/">Hadoop的datanode数据节点机器配置</a></li>
<li><a href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/">Hadoop内存环境变量和参数</a></li>
<li><a href="http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate/">Spark-on-yarn内存分配</a></li>
<li><a href="http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn/">SparkSQL-on-YARN的Executors池(动态)配置</a></li>
</ul>


<h4>问题定位</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/17/windows-hadoop2-test-your-mapreduce-feature/">在windows开发测试mapreduce几种方式</a></li>
<li><a href="http://winseliu.com/blog/2014/04/22/remote-debug-hadoop2/">远程调试hadoop2以及错误处理方法</a></li>
<li><a href="http://winseliu.com/blog/2014/08/25/step-by-step-found-java-oom-error/">逐步定位Java程序OOM的异常</a></li>
</ul>


<h4>读码</h4>

<ul>
<li>Hadoop2 Balancer磁盘空间平衡

<ul>
<li><a href="http://winseliu.com/blog/2014/08/06/read-hadoop-balancer-source-part1/">上</a></li>
<li><a href="http://winseliu.com/blog/2014/09/05/read-hadoop-balancer-source-part2/">中</a></li>
<li><a href="http://winseliu.com/blog/2014/09/05/read-hadoop-balancer-source-part3/">下</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2015/03/13/hadoop-distcp/">Hadoop Distcp</a></li>
</ul>


<h4>其他</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/12/scala-wordcount-on-hadoop/">Scala Wordcount on Hadoop2</a></li>
<li><a href="http://winseliu.com/blog/2014/12/07/hadoop-mr-rest-api/">MR Rest接口</a></li>
</ul>


<h2>4. Hadoop平台</h2>

<ul>
<li>zookeeper</li>
<li>hive

<ul>
<li><a href="http://winseliu.com/blog/2014/06/21/upgrade-hive/">Upgrade Hive: 0.12.0 to 0.13.1</a></li>
<li>tez:

<ul>
<li><a href="http://winseliu.com/blog/2014/06/18/hadoop-tez-firststep/">Tez编译及使用</a></li>
<li><a href="http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run/">配置TEZ-UI</a></li>
</ul>
</li>
<li>hive on spark

<ul>
<li><a href="http://winseliu.com/blog/2016/03/28/hive-on-spark/">Hive on Spark</a></li>
<li><a href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a></li>
<li><a href="http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive/">Limit on Sparksql and Hive</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/04/08/dbcp-parameters/">DBCP参数在Hive JDBC上的实践</a></li>
<li><a href="http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0/">Hiveserver2 Ui and Upgrade hive2.0.0</a></li>
</ul>
</li>
<li>kafka

<ul>
<li><a href="http://winseliu.com/blog/2015/01/08/kafka-guide/">Kafka快速入门</a></li>
</ul>
</li>
<li>alluxio(tachyon)

<ul>
<li><a href="http://winseliu.com/blog/2015/04/15/tachyon-quickstart/">Tachyon入门指南</a></li>
<li><a href="http://winseliu.com/blog/2015/04/18/tachyon-deep-source/">Tachyon剖析</a></li>
<li><a href="http://winseliu.com/blog/2016/04/15/alluxio-quickstart2/">Alluxio入门大全2</a></li>
</ul>
</li>
</ul>


<h2>5. 监控与自动化部署</h2>

<h4>监控</h4>

<ul>
<li><a href="http://winseliu.com/blog/2013/02/26/linux-top-command-mannual/">top</a></li>
<li>nagios

<ul>
<li><a href="http://winseliu.com/blog/2015/09/25/nagios-start-guide/">Nagios监控主机</a></li>
</ul>
</li>
<li><del>cacti</del>    Ganglia更简单

<ul>
<li><a href="http://winseliu.com/blog/2015/09/22/cacti-start-guide/">Cacti监控主机</a></li>
<li><a href="http://winseliu.com/blog/2015/10/13/cacti-batch-adding-configurations/">Cacti批量添加配置</a></li>
</ul>
</li>
<li>ganglia

<ul>
<li><a href="http://winseliu.com/blog/2014/07/18/install-ganglia-on-redhat/"><del>Install Ganglia on Redhat5+</del></a> 手动安装依赖太麻烦了！</li>
<li><a href="http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a></li>
<li><a href="http://winseliu.com/blog/2016/02/01/ganglia-python-extension/">Ganglia扩展-Python</a></li>
<li><a href="http://winseliu.com/blog/2016/02/25/ganglia-web-ui-views/">Ganglia页自定义视图</a></li>
</ul>
</li>
</ul>


<h4>自动化</h4>

<ul>
<li>git:

<ul>
<li><a href="http://winseliu.com/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a></li>
<li><a href="http://winseliu.com/blog/2014/02/19/maven-package-dependent-git-projects/">打包依赖的git项目</a></li>
<li><a href="http://winseliu.com/blog/2013/05/27/handle-git-conflict/">处理git冲突</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2014/09/07/expect-automate-and-batch-config-ssh/">expect-批量实现SSH无密钥登录</a></li>
<li>puppet

<ul>
<li><a href="http://winseliu.com/blog/2016/04/08/puppet-install/">puppet4.4.1入门安装</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn/">puppet入门之域名证书</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/">puppetdb安装配置</a>

<ul>
<li><a href="http://winseliu.com/blog/2015/12/13/postgresql-start-guide/">postgresql入门</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppetexplorer-setting/">puppetexplorer设置</a></li>
<li><a href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/">RPM打包</a></li>
<li>mcollective

<ul>
<li><a href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/">安装配置</a></li>
<li><a href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/">插件安装</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/05/03/hiera-and-facts/">Hiera</a></li>
</ul>
</li>
</ul>


<p>&hellip;</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetexplorer设置]]></title>
    <link href="http://winseliu.com/blog/2016/04/21/puppetexplorer-setting/"/>
    <updated>2016-04-21T14:28:11+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/21/puppetexplorer-setting</id>
    <content type="html"><![CDATA[<p>注意： 使用 <a href="https://github.com/spotify/puppetexplorer/releases">PuppetExplorer</a> 的前提是已经安装 PuppetDB （安装参考：<a href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/">Puppetdb安装配置</a>）。</p>

<p>PuppetDB 提供的8080界面太过于简单，其实8080主要提供非常多的接口。PuppetExplorer 就是使用这些 restful 查询接口来进行展示。比默认的 PuppetDB-UI 更具体和详细。</p>

<p>配置 PuppetExplorer 有两种方式：</p>

<ul>
<li>两个服务在 <strong>同一个域</strong> 下面，配置 /api 跳转到 PuppetDB:8080</li>
<li>两个服务，<strong>配置各自的地址</strong> 。修改config.js，同时处理跨域的问题。</li>
</ul>


<blockquote><p><a href="https://github.com/spotify/puppetexplorer">https://github.com/spotify/puppetexplorer</a></p>

<ul>
<li>The recommended way to install it is on the same host as your PuppetDB instance. Then proxy /api to port 8080 of your PuppetDB instance (except the /commands endpoint). This avoids the need for any CORS headers.</li>
<li>It is possible to have it on a separate domain from your PuppetDB though. If you do, make sure you have the correct Access-Control-Allow-Origin header and a Access-Control-Expose-Headers: X-Records header.</li>
</ul>
</blockquote>

<h2>适配 PuppetDB4</h2>

<p>官网的版本已经几个月没有更新，新的 API 接口略有不同：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># puppetdb-4.0
</span><span class='line'>/metrics/v1/mbeans/puppetlabs.puppetdb.population:name=num-active-nodes
</span><span class='line'>
</span><span class='line'># puppetexplorer-2.0.0
</span><span class='line'>/metrics/v1/mbeans/puppetlabs.puppetdb.query.population:type=default,name=num-nodes</span></code></pre></td></tr></table></div></figure>


<p>修改 app.js 拼接链接的字符串即可，删除 <strong>.query.</strong> 和 <strong>type=default</strong> :</p>

<p><img src="http://winseliu.com/images/blogs/puppetdb4-puppetexplorer.png" alt="" /></p>

<p>配置好后的效果：</p>

<p><img src="http://winseliu.com/images/blogs/puppetexplorer.png" alt="" /></p>

<h1>同一服务器下访问配置</h1>

<p>使用 nginx 作为html的服务器，同时 proxy_pass 代理跳转到 cu3:8080(PuppetDB服务) :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 puppetexplorer-2.0.0]$ mv config.js.example config.js
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 nginx]$ vi conf/nginx.conf
</span><span class='line'>...
</span><span class='line'># 路径最后带上 / ！！
</span><span class='line'>location /api/ {
</span><span class='line'>  proxy_pass http://cu3:8080/;
</span><span class='line'>  proxy_set_header X-Real-IP $remote_addr;
</span><span class='line'>    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
</span><span class='line'>    proxy_set_header Host $http_host;
</span><span class='line'>}
</span><span class='line'>location /puppetexplorer {
</span><span class='line'>  alias /opt/puppetlabs/puppetexplorer-2.0.0;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 nginx]$ sbin/nginx -s reload
</span></code></pre></td></tr></table></div></figure>


<p>然后打开网页访问 <a href="http://cu2:8888/puppetexplorer">http://cu2:8888/puppetexplorer</a> 即可。</p>

<p>nginx的配置参考： <a href="http://wangwei007.blog.51cto.com/68019/1103734">Nginx配置proxy_pass转发的/路径问题</a>, <a href="http://stackoverflow.com/questions/20730858/how-do-i-configure-nginx-as-proxy-to-jetty">nginx as proxy to jetty</a></p>

<h1>不同服务器，跨域访问</h1>

<p>老实说，完全不推荐这种做法。但是跨域的设置震惊到我了，原来自认为的方式完全不对。例如A javascript访问B，<strong>跨域头设置在B服务</strong>，是要B容许A访问！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 puppetexplorer]# vi config.js 
</span><span class='line'>// List of PuppetDB servers, pairs of name, URL and $http config object
</span><span class='line'>// The first one will be used as the default server
</span><span class='line'>PUPPETDB_SERVERS = [
</span><span class='line'>  ['production', 'http://cu2:8888'],
</span><span class='line'>  ['testing', 'http://cu2:8888']
</span><span class='line'>];
</span><span class='line'>
</span><span class='line'># Nginx配置，加上跨域访问源范围控制
</span><span class='line'>location ~ /(metrics|pdb) {
</span><span class='line'>add_header "Access-Control-Allow-Origin" "*";
</span><span class='line'>proxy_pass http://cu3:8080;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://www.html5rocks.com/en/tutorials/cors/?redirect_from_locale=zh">http://www.html5rocks.com/en/tutorials/cors/?redirect_from_locale=zh</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#Requests_with_credentials">https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#Requests_with_credentials</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">https://en.wikipedia.org/wiki/Cross-origin_resource_sharing</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetdb安装配置]]></title>
    <link href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/"/>
    <updated>2016-04-21T00:39:11+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config</id>
    <content type="html"><![CDATA[<p>安装 PuppetDB 后，还得修改 PuppetServer 的配置。由于测试环境机器硬件一般般，把 PuppetDB 安装在 cu3。</p>

<ul>
<li>cu2: master server, ca server, postgresql</li>
<li>cu3: puppetdb, agent</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 puppet]# puppetdb -v
</span><span class='line'>puppetdb version: 4.0.0
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1
</span><span class='line'>[root@cu2 ~]# puppet -V
</span><span class='line'>4.4.1
</span></code></pre></td></tr></table></div></figure>


<p>原来老的版本有资源(清单)导出的功能，到了Puppet4后被PuppetDB取代了。见官网文档: <a href="https://docs.puppet.com/guides/inventory_service.html">Inventory Service</a></p>

<p>同时老版本用ruby写的 puppet-dashboard 也没有必要安装了，前后端分离大势所趋：后端提供接口，前端用ajax来展现。</p>

<h1>安装PuppetDB</h1>

<p><a href="https://docs.puppetlabs.com/puppetdb/latest/install_from_packages.html">https://docs.puppetlabs.com/puppetdb/latest/install_from_packages.html</a></p>

<p>由于天朝特殊环境，本地repo的创建参考第一篇文章: <a href="http://winseliu.com/blog/2016/04/08/puppet-install">puppet4.4.1入门安装</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# yum install puppetdb
</span><span class='line'>Loaded plugins: fastestmirror
</span><span class='line'>Setting up Install Process
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package puppetdb.noarch 0:4.0.0-1.el6 will be installed
</span><span class='line'>--&gt; Processing Dependency: java-1.8.0-openjdk-headless for package: puppetdb-4.0.0-1.el6.noarch
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7 will be installed
</span><span class='line'>--&gt; Processing Dependency: tzdata-java &gt;= 2014f-1 for package: 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64
</span><span class='line'>--&gt; Processing Dependency: jpackage-utils for package: 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package jpackage-utils.noarch 0:1.7.5-3.14.el6 will be installed
</span><span class='line'>---&gt; Package tzdata-java.noarch 0:2016c-1.el6 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>===========================================================================================================================================================================================
</span><span class='line'> Package                                                Arch                              Version                                            Repository                               Size
</span><span class='line'>===========================================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> puppetdb                                               noarch                            4.0.0-1.el6                                        puppet-local                             21 M
</span><span class='line'>Installing for dependencies:
</span><span class='line'> java-1.8.0-openjdk-headless                            x86_64                            1:1.8.0.77-0.b03.el6_7                             updates                                  32 M
</span><span class='line'> jpackage-utils                                         noarch                            1.7.5-3.14.el6                                     base                                     60 k
</span><span class='line'> tzdata-java                                            noarch                            2016c-1.el6                                        updates                                 179 k
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>===========================================================================================================================================================================================
</span><span class='line'>Install       4 Package(s)
</span><span class='line'>
</span><span class='line'>Total size: 53 M
</span><span class='line'>Total download size: 53 M
</span><span class='line'>Installed size: 126 M
</span><span class='line'>Is this ok [y/N]: y
</span><span class='line'>Downloading Packages:
</span><span class='line'>(1/3): java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64.rpm                                                                                                  |  32 MB     00:00     
</span><span class='line'>(2/3): puppetdb-4.0.0-1.el6.noarch.rpm                                                                                                                              |  21 MB     00:00     
</span><span class='line'>(3/3): tzdata-java-2016c-1.el6.noarch.rpm                                                                                                                           | 179 kB     00:00     
</span><span class='line'>-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class='line'>Total                                                                                                                                                       32 MB/s |  53 MB     00:01     
</span><span class='line'>Running rpm_check_debug
</span><span class='line'>Running Transaction Test
</span><span class='line'>Transaction Test Succeeded
</span><span class='line'>Running Transaction
</span><span class='line'>  Installing : tzdata-java-2016c-1.el6.noarch                                                                                                                                          1/4 
</span><span class='line'>  Installing : jpackage-utils-1.7.5-3.14.el6.noarch                                                                                                                                    2/4 
</span><span class='line'>  Installing : 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64                                                                                                               3/4 
</span><span class='line'>  Installing : puppetdb-4.0.0-1.el6.noarch                                                                                                                                             4/4 
</span><span class='line'>Config archive not found. Not proceeding with migration
</span><span class='line'>PEM files in /etc/puppetlabs/puppetdb/ssl are missing, we will move them into place for you
</span><span class='line'>Warning: Unable to find all puppet certificates to copy
</span><span class='line'>
</span><span class='line'>  This tool requires the following certificates to exist:
</span><span class='line'>
</span><span class='line'>  * /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>  * /etc/puppetlabs/puppet/ssl/private_keys/cu3.eshore.cn.pem
</span><span class='line'>  * /etc/puppetlabs/puppet/ssl/certs/cu3.eshore.cn.pem
</span><span class='line'>
</span><span class='line'>  These files may be missing due to the fact that your host's Puppet
</span><span class='line'>  certificates may not have been signed yet, probably due to the
</span><span class='line'>  lack of a complete Puppet agent run. Try running puppet first, for
</span><span class='line'>  example:
</span><span class='line'>
</span><span class='line'>      puppet agent --test
</span><span class='line'>
</span><span class='line'>  Afterwards re-run this tool then restart PuppetDB to complete the SSL
</span><span class='line'>  setup:
</span><span class='line'>
</span><span class='line'>      puppetdb ssl-setup -f
</span><span class='line'>  Verifying  : jpackage-utils-1.7.5-3.14.el6.noarch                                                                                                                                    1/4 
</span><span class='line'>  Verifying  : tzdata-java-2016c-1.el6.noarch                                                                                                                                          2/4 
</span><span class='line'>  Verifying  : puppetdb-4.0.0-1.el6.noarch                                                                                                                                             3/4 
</span><span class='line'>  Verifying  : 1:java-1.8.0-openjdk-headless-1.8.0.77-0.b03.el6_7.x86_64                                                                                                               4/4 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  puppetdb.noarch 0:4.0.0-1.el6                                                                                                                                                            
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7                   jpackage-utils.noarch 0:1.7.5-3.14.el6                   tzdata-java.noarch 0:2016c-1.el6                  
</span><span class='line'>
</span><span class='line'>Complete!
</span></code></pre></td></tr></table></div></figure>


<p>PuppetDB 需要与 puppetserver 通信，需要签名证书。如果安装之前本机 Puppet-agent 证书已签名，安装会自动把证书拷贝到 puppetdb/ssl 目录下。我们这里先签名agent再配置 puppetdb-ssl 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu3.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 16:CB:A3:6D:21:69:78:D0:0D:37:1F:A7:C1:86:2E:55:7F:B1:60:77:05:EC:F5:37:81:12:28:73:61:1A:4F:20
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'># 服务端签名: puppet cert sign cu3.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu3.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461159906'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>[root@cu3 ~]# puppetdb ssl-setup -f
</span><span class='line'>PEM files in /etc/puppetlabs/puppetdb/ssl are missing, we will move them into place for you
</span><span class='line'>Copying files: /etc/puppetlabs/puppet/ssl/certs/ca.pem, /etc/puppetlabs/puppet/ssl/private_keys/cu3.eshore.cn.pem and /etc/puppetlabs/puppet/ssl/certs/cu3.eshore.cn.pem to /etc/puppetlabs/puppetdb/ssl
</span><span class='line'>Backing up /etc/puppetlabs/puppetdb/conf.d/jetty.ini to /etc/puppetlabs/puppetdb/conf.d/jetty.ini.bak.1461159930 before making changes
</span><span class='line'>Updated default settings from package installation for ssl-host in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-port in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-key in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-cert in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>Updated default settings from package installation for ssl-ca-cert in /etc/puppetlabs/puppetdb/conf.d/jetty.ini.
</span><span class='line'>[root@cu3 ~]# </span></code></pre></td></tr></table></div></figure>


<h1>安装Postgres</h1>

<p>配置好 ssl 后，下一步就是连接数据库。puppet4.4 默认配置里面只有 postgres 数据库。直接用 yum 安装，这里简单列出配置过程。</p>

<p><a href="https://docs.puppetlabs.com/puppetdb/latest/configure.html#using-postgresql">https://docs.puppetlabs.com/puppetdb/latest/configure.html#using-postgresql</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# yum localinstall http://yum.postgresql.org/9.4/redhat/rhel-6-x86_64/pgdg-centos94-9.4-1.noarch.rpm
</span><span class='line'>[root@cu2 ~]# yum install postgresql94-server
</span><span class='line'>[root@cu2 ~]# yum install postgresql94-contrib
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# service postgresql-9.4 initdb
</span><span class='line'>Initializing database:                                     [  OK  ]
</span><span class='line'>[root@cu2 ~]# service postgresql-9.4 status
</span><span class='line'>postgresql-9.4 is stopped
</span><span class='line'>[root@cu2 ~]# service postgresql-9.4 start
</span><span class='line'>Starting postgresql-9.4 service:                           [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 先查看 PGDATA 的目录！！
</span><span class='line'>[root@cu2 data]# grep "PGDATA=" /etc/init.d/postgresql-9.4 
</span><span class='line'>PGDATA=/usr/local/pgsql/data
</span><span class='line'>OLDPGDATA=` sed -n 's/^PGDATA=//p' /etc/init.d/postgresql-$PGPREVMAJORVERSION`
</span><span class='line'>NEWPGDATA=` sed -n 's/^PGDATA=//p' /etc/init.d/postgresql-$PGMAJORVERSION`
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 切换到 postgres 用户，先验证环境变量 PGDATA 是否正确！！否则自己修改 .bash_profile 文件！！
</span><span class='line'>[root@cu2 puppet]# su - postgres
</span><span class='line'>-bash-4.1$ echo $PGDATA
</span><span class='line'>/usr/local/pgsql/data
</span><span class='line'>
</span><span class='line'># 创建用户
</span><span class='line'>-bash-4.1$ createuser -DRSP puppetdb
</span><span class='line'>Enter password for new role: 
</span><span class='line'>Enter it again: 
</span><span class='line'>-bash-4.1$ 
</span><span class='line'>-bash-4.1$ createdb -E utf8 -O puppetdb puppetdb
</span><span class='line'>
</span><span class='line'>-bash-4.1$ psql puppetdb -c 'create extension pg_trgm'
</span><span class='line'>CREATE EXTENSION
</span><span class='line'>
</span><span class='line'># 配置连接选项（相当于mysql的privilege）
</span><span class='line'>-bash-4.1$ vi $PGDATA/pg_hba.conf 
</span><span class='line'>host    all             all              0.0.0.0/0               md5
</span><span class='line'>
</span><span class='line'># 重启
</span><span class='line'>[root@cu2 puppet]# service postgresql-9.4 restart
</span><span class='line'>Stopping postgresql-9.4 service:                           [  OK  ]
</span><span class='line'>Starting postgresql-9.4 service:                           [  OK  ]
</span><span class='line'>
</span><span class='line'># 测试 
</span><span class='line'>[root@cu2 puppet]# psql -h localhost puppetdb puppetdb
</span><span class='line'>psql (9.4.5)
</span><span class='line'>Type "help" for help.
</span><span class='line'>
</span><span class='line'>puppetdb=&gt; 
</span><span class='line'>puppetdb=&gt; \q
</span></code></pre></td></tr></table></div></figure>


<p>查看 postgres 的端口:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 puppet]# netstat -anp | grep post
</span><span class='line'>tcp        0      0 0.0.0.0:5432                0.0.0.0:*                   LISTEN      8126/postmaster     
</span><span class='line'>tcp        0      0 :::5432                     :::*                        LISTEN      8126/postmaster     
</span><span class='line'>udp        0      0 ::1:39400                   ::1:39400                   ESTABLISHED 8126/postmaster     
</span><span class='line'>unix  2      [ ACC ]     STREAM     LISTENING     954965338 8126/postmaster     /tmp/.s.PGSQL.5432
</span><span class='line'>
</span><span class='line'># 有客户端连上来后：
</span><span class='line'>[root@cu2 ~]# netstat -anp | grep post
</span><span class='line'>tcp        0      0 0.0.0.0:5432                0.0.0.0:*                   LISTEN      8126/postmaster     
</span><span class='line'>tcp        0      0 192.168.0.214:5432          192.168.0.148:60626         ESTABLISHED 20589/postgres 
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h1>启动PuppetDB</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# vi /etc/puppetlabs/puppetdb/conf.d/database.ini 
</span><span class='line'>[database]
</span><span class='line'>classname = org.postgresql.Driver
</span><span class='line'>subprotocol = postgresql
</span><span class='line'>
</span><span class='line'># The database address, i.e. //HOST:PORT/DATABASE_NAME
</span><span class='line'>subname = //cu2:5432/puppetdb
</span><span class='line'>
</span><span class='line'># Connect as a specific user
</span><span class='line'>username = puppetdb
</span><span class='line'>
</span><span class='line'># Use a specific password
</span><span class='line'>password = puppetdb
</span><span class='line'>
</span><span class='line'># How often (in minutes) to compact the database
</span><span class='line'># gc-interval = 60
</span><span class='line'># 通过api/name=num-active-nodes查询不到了，但是pgsql数据库中还没有删除。也可以通过 puppet node deactivate 手动执行
</span><span class='line'># node-ttl = 30d
</span><span class='line'># 默认没有设置，disabled。格式与node-ttl一样
</span><span class='line'># node-purge-ttl = 
</span><span class='line'># report-ttl = 14d
</span><span class='line'>
</span><span class='line'># Number of seconds before any SQL query is considered 'slow'; offending
</span><span class='line'># queries will not be interrupted, but will be logged at the WARN log level.
</span><span class='line'>log-slow-statements = 10
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 注意修改，不然web-ui就只能localhost访问了！！
</span><span class='line'>[root@cu3 ~]# vi /etc/puppetlabs/puppetdb/conf.d/jetty.ini
</span><span class='line'>...
</span><span class='line'>host = 0.0.0.0
</span><span class='line'>
</span><span class='line'># JVM 参数修改
</span><span class='line'>[root@cu3 ~]# less /etc/sysconfig/puppetdb 
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# service puppetdb start
</span><span class='line'>Starting puppetdb:                                         [  OK  ]
</span><span class='line'>[root@cu3 ~]# 
</span><span class='line'>[root@cu3 ~]# service puppetdb status
</span><span class='line'>puppetdb (pid  8452) is running...
</span><span class='line'>
</span><span class='line'># 8081 为 puppetserver 写数据的https接口。8080 为http web-ui端口
</span><span class='line'>[root@cu3 ~]# netstat -anp | grep 8081
</span><span class='line'>tcp        0      0 :::8081                     :::*                        LISTEN      8794/java           
</span></code></pre></td></tr></table></div></figure>


<p>查看 8080 端口通过网页查看集群的状态，现在还什么数据都获取不到，需要配置服务端把数据发送给puppetdb。</p>

<h1>服务端配置</h1>

<p><a href="https://docs.puppet.com/puppetdb/latest/connect_puppet_master.html">https://docs.puppet.com/puppetdb/latest/connect_puppet_master.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 安装Plug-in
</span><span class='line'># 服务端还要安装 puppetdb-termini ，不然会报错。
</span><span class='line'>[root@cu2 puppet]# yum install puppetdb-termini
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Setting up Install Process
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * epel: mirrors.opencas.cn
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package puppetdb-termini.noarch 0:3.2.4-1.el6 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>==========================================================================================================================================================================
</span><span class='line'> Package                                      Arch                               Version                                   Repository                                Size
</span><span class='line'>==========================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> puppetdb-termini                             noarch                             3.2.4-1.el6                               puppet-local                              25 k
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>==========================================================================================================================================================================
</span><span class='line'>Install       1 Package(s)
</span><span class='line'>
</span><span class='line'>Total download size: 25 k
</span><span class='line'>Installed size: 69 k
</span><span class='line'>Is this ok [y/N]: y
</span><span class='line'>Downloading Packages:
</span><span class='line'>puppetdb-termini-3.2.4-1.el6.noarch.rpm                                                                                                            |  25 kB     00:00     
</span><span class='line'>Running rpm_check_debug
</span><span class='line'>Running Transaction Test
</span><span class='line'>Transaction Test Succeeded
</span><span class='line'>Running Transaction
</span><span class='line'>  Installing : puppetdb-termini-3.2.4-1.el6.noarch                                                                                                                    1/1 
</span><span class='line'>  Verifying  : puppetdb-termini-3.2.4-1.el6.noarch                                                                                                                    1/1 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  puppetdb-termini.noarch 0:3.2.4-1.el6                                                                                                                                   
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 注意这里URL的域名，要与CA中的名称对应！！ 设置成 cu3 是不正确的！！
</span><span class='line'>[root@cu2 puppet]# vi puppetdb.conf 
</span><span class='line'>[main]
</span><span class='line'>server_urls = https://cu3.eshore.cn:8081
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# vi puppet.conf 
</span><span class='line'># This file can be used to override the default puppet settings.
</span><span class='line'># See the following links for more details on what settings are available:
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/config_about_settings.html
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/config_file_main.html
</span><span class='line'># - https://docs.puppetlabs.com/puppet/latest/reference/configuration.html
</span><span class='line'>[master]
</span><span class='line'>vardir = /opt/puppetlabs/server/data/puppetserver
</span><span class='line'>logdir = /var/log/puppetlabs/puppetserver
</span><span class='line'>rundir = /var/run/puppetlabs/puppetserver
</span><span class='line'>pidfile = /var/run/puppetlabs/puppetserver/puppetserver.pid
</span><span class='line'>codedir = /etc/puppetlabs/code
</span><span class='line'>
</span><span class='line'>storeconfigs = true
</span><span class='line'>storeconfigs_backend = puppetdb
</span><span class='line'>reports = store,puppetdb
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet master --configprint route_file
</span><span class='line'>/etc/puppetlabs/puppet/routes.yaml
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppet]# cat routes.yaml 
</span><span class='line'>---
</span><span class='line'>master:
</span><span class='line'>  facts:
</span><span class='line'>    terminus: puppetdb
</span><span class='line'>    cache: yaml
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# service puppetserver restart
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet agent --server cu2.eshore.cn --test 
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu2.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461162748'
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span></code></pre></td></tr></table></div></figure>


<p>如果 puppet-agent 服务没有启动，分别在各台机器上面执行 &ndash;test 连一下 PuppetServer，就可以在8080 puppetdb页面看到主机的数量了。</p>

<p><img src="http://winseliu.com/images/blogs/puppetdb-ui.png" alt="" /></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet入门之域名证书]]></title>
    <link href="http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn/"/>
    <updated>2016-04-21T00:06:06+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn</id>
    <content type="html"><![CDATA[<p>说 Puppet 入门配置过程中 90% 的问题与有关毫不为过！！因为节点之间的通信都需要证书验证，而证书验证和域名绑定。</p>

<p>主要讲讲 FQDN(Fully Qualified Domain Name) 查看和配置，以及 <strong>Puppet4.4</strong> 认证相关的操作。</p>

<h1>环境说明</h1>

<p>测试环境是几台云主机 ，主机名根据项目情况命名（也就是说云主机内网域名解析是不行的）。操作系统没特殊说明那么使用的是 Centos6 。</p>

<ul>
<li>cu2： 服务端master，证书服务器ca</li>
<li>cu1/cu3/cu4/cu5:  agent</li>
</ul>


<p>这里列出来的是部署之前的域名情况。一步步的处理域名代码的麻烦。如果想避免不必要的烦恼，请使用 FQDN 加上 <strong>域</strong> 。</p>

<h1>服务节点证书重新签名</h1>

<p>安装后直接测试，默认连接的服务器是 puppet 。所以要么指定 puppet 对应主机，要么加上 &ndash;server 参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 默认的 puppet 服务器找不到对应的主机
</span><span class='line'>[root@cu2 ~]# puppet agent --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: getaddrinfo: Name or service not known
</span><span class='line'>Error: Could not retrieve catalog from remote server: getaddrinfo: Name or service not known
</span><span class='line'>Warning: Not using cache on failed catalog
</span><span class='line'>Error: Could not retrieve catalog; skipping run
</span><span class='line'>Error: Could not send report: getaddrinfo: Name or service not known
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 加上 域 后不通，DNS服务器不识别自定义的主机名
</span><span class='line'>[root@cu2 ~]# cat /etc/resolv.conf 
</span><span class='line'>; generated by /sbin/dhclient-script
</span><span class='line'>search ds.ctyun
</span><span class='line'>nameserver 192.168.0.1
</span><span class='line'>[root@cu2 ~]# puppet agent --server cu2.ds.ctyun --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: getaddrinfo: Name or service not known
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: getaddrinfo: Name or service not known
</span><span class='line'>Error: Could not retrieve catalog from remote server: getaddrinfo: Name or service not known
</span><span class='line'>Warning: Not using cache on failed catalog
</span><span class='line'>Error: Could not retrieve catalog; skipping run
</span><span class='line'>Error: Could not send report: getaddrinfo: Name or service not known
</span><span class='line'>[root@cu2 ~]# ping cu2.ds.ctyun
</span><span class='line'>ping: unknown host cu2.ds.ctyun
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 传说中用的 -f 参数没L用
</span><span class='line'>[root@cu2 ~]# hostname -i
</span><span class='line'>192.168.0.x
</span><span class='line'>[root@cu2 ~]# hostname -f
</span><span class='line'>cu2
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 加自定义 域 ，并重新设定 FQDN hostname。 修改主机hostname的步骤可以替换成在 /etc/resolv.conf 加 **domain eshore.cn**
</span><span class='line'>[root@cu2 ~]# vi /etc/hosts
</span><span class='line'>192.168.0.x cu1 cu1.eshore.cn
</span><span class='line'>192.168.0.x cu2 cu2.eshore.cn
</span><span class='line'>
</span><span class='line'>192.168.0.x cu3 cu3.eshore.cn
</span><span class='line'>192.168.0.x cu4 cu4.eshore.cn
</span><span class='line'>192.168.0.x cu5 cu5.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# vi /etc/sysconfig/network
</span><span class='line'>NETWORKING=yes
</span><span class='line'>HOSTNAME=cu2.eshore.cn
</span><span class='line'>[root@cu2 ~]# hostname cu2.eshore.cn
</span><span class='line'>[root@cu2 ~]# hostname
</span><span class='line'>cu2.eshore.cn
</span><span class='line'>
</span><span class='line'># 确认
</span><span class='line'>[root@cu2 ~]# puppet config print certname
</span><span class='line'>cu2.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# dnsdomainname -v
</span><span class='line'>gethostname()=`cu2.eshore.cn'
</span><span class='line'>Resolving `cu2.eshore.cn' ...
</span><span class='line'>Result: h_name=`cu2'
</span><span class='line'>Result: h_aliases=`cu2.eshore.cn'
</span><span class='line'>Result: h_addr_list=`192.168.0.214'
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# hostname -f -v
</span><span class='line'>gethostname()=`cu2.eshore.cn'
</span><span class='line'>Resolving `cu2.eshore.cn' ...
</span><span class='line'>Result: h_name=`cu2'
</span><span class='line'>Result: h_aliases=`cu2.eshore.cn'
</span><span class='line'>Result: h_addr_list=`192.168.0.214'
</span><span class='line'>cu2
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 清理已经为本机签发的证书
</span><span class='line'>[root@cu2 ~]# puppet cert list -all
</span><span class='line'>+ "cu2.ds.ctyun" (SHA256) A6:30:6D:80:A8:04:60:56:4C:F3:D5:3C:9A:5C:2A:11:6C:A6:A9:F7:6E:5E:A5:37:59:28:5B:B6:E3:D3:73:D5 (alt names: "DNS:puppet", "DNS:cu2.ds.ctyun")
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# puppet cert clean cu2.ds.ctyun
</span><span class='line'>Notice: Revoked certificate with serial 2
</span><span class='line'>Notice: Removing file Puppet::SSL::Certificate cu2.ds.ctyun at '/etc/puppetlabs/puppet/ssl/ca/signed/cu2.ds.ctyun.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::Certificate cu2.ds.ctyun at '/etc/puppetlabs/puppet/ssl/certs/cu2.ds.ctyun.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::Key cu2.ds.ctyun at '/etc/puppetlabs/puppet/ssl/private_keys/cu2.ds.ctyun.pem'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 由于是server节点的证书变更，重启puppetserver会重新生成/签发证书
</span><span class='line'>[root@cu2 ~]# service puppetserver restart
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# tree /etc/puppetlabs/puppet/ssl
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>├── ca
</span><span class='line'>│   ├── ca_crl.pem
</span><span class='line'>│   ├── ca_crt.pem
</span><span class='line'>│   ├── ca_key.pem
</span><span class='line'>│   ├── ca_pub.pem
</span><span class='line'>│   ├── inventory.txt
</span><span class='line'>│   ├── private
</span><span class='line'>│   ├── requests
</span><span class='line'>│   ├── serial
</span><span class='line'>│   └── signed
</span><span class='line'>│       └── cu2.eshore.cn.pem
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    └── cu2.eshore.cn.pem
</span><span class='line'>
</span><span class='line'>9 directories, 12 files
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu2.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461149778'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span></code></pre></td></tr></table></div></figure>


<h1>Agent 重新签名</h1>

<p>涉及到客户端域名错误，需要服务端配合清理签名请求等操作。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 首先同步 /etc/hosts 到所有agent节点
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># cu1 连接 服务器cu2
</span><span class='line'>[root@cu1 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu1.ds.ctyun
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu1.ds.ctyun
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 4F:D6:DC:25:22:D9:44:E5:70:9F:9B:B1:0F:99:B2:AC:F5:5F:50:CE:B7:C3:AF:65:F4:E2:DF:D5:2D:6F:96:07
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 在没有修改 域 的情况下，已经发送了 ds.ctyun 域 的签名请求
</span><span class='line'># 修改主机域，再发送请求
</span><span class='line'>[root@cu1 ~]# vi /etc/resolv.conf 
</span><span class='line'>; generated by /sbin/dhclient-script
</span><span class='line'>domain eshore.cn
</span><span class='line'>search ds.ctyun
</span><span class='line'>nameserver 192.168.0.1
</span><span class='line'>
</span><span class='line'>[root@cu1 ~]#  puppet config print certname
</span><span class='line'>cu1.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu1 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu1.eshore.cn
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu1.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): B8:A1:65:B6:FE:02:87:B1:8D:0A:62:2E:FE:30:DD:B3:3B:C9:A2:B2:A1:50:11:D3:FE:03:6A:81:A6:84:C0:6B
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 此时服务端cu2已包括了 cu1 的两个签名请求信息
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>  "cu1.ds.ctyun"  (SHA256) 4F:D6:DC:25:22:D9:44:E5:70:9F:9B:B1:0F:99:B2:AC:F5:5F:50:CE:B7:C3:AF:65:F4:E2:DF:D5:2D:6F:96:07
</span><span class='line'>  "cu1.eshore.cn" (SHA256) B8:A1:65:B6:FE:02:87:B1:8D:0A:62:2E:FE:30:DD:B3:3B:C9:A2:B2:A1:50:11:D3:FE:03:6A:81:A6:84:C0:6B
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) 3D:8E:4E:18:45:F4:8C:9B:71:7C:13:45:0D:8A:6F:A5:6E:22:D5:0E:B1:B0:54:29:47:02:AE:95:8B:E6:A6:B7 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 本地清理 无效的签名请求 或者直接删除ssl目录： rm -rf /var/lib/puppet/ssl
</span><span class='line'>[root@cu1 ~]# puppet certificate_request destroy cu1.ds.ctyun
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu1.ds.ctyun at '/etc/puppetlabs/puppet/ssl/certificate_requests/cu1.ds.ctyun.pem'
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 服务端清理 特定客户端无效请求
</span><span class='line'># http://serverfault.com/questions/574976/puppet-trying-to-configure-puppet-client-for-first-use-but-got-some-problems-wi
</span><span class='line'>[root@cu2 puppet]# puppet node clean cu1.ds.ctyun 
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu1.ds.ctyun at '/etc/puppetlabs/puppet/ssl/ca/requests/cu1.ds.ctyun.pem'
</span><span class='line'>cu1.ds.ctyun
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 服务端签名，客户端agent同步manifest
</span><span class='line'>[root@cu2 puppet]# puppet cert sign cu1.eshore.cn
</span><span class='line'>Notice: Signed certificate request for cu1.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu1.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu1.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'>[root@cu1 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu1.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461156849'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span></code></pre></td></tr></table></div></figure>


<p>其他修改主机域后统一签名：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 puppet]# puppet cert list 
</span><span class='line'>  "cu3.eshore.cn" (SHA256) 16:CB:A3:6D:21:69:78:D0:0D:37:1F:A7:C1:86:2E:55:7F:B1:60:77:05:EC:F5:37:81:12:28:73:61:1A:4F:20
</span><span class='line'>  "cu4.eshore.cn" (SHA256) CB:80:64:BD:B8:56:56:43:90:11:D4:B2:A9:7B:D8:DC:E4:0C:8D:5A:71:0B:FF:97:65:20:F5:B4:D7:15:11:B6
</span><span class='line'>  "cu5.eshore.cn" (SHA256) D6:9A:B0:93:98:94:D2:D2:E3:A9:55:24:EC:7A:E0:13:48:5B:26:16:6C:5A:B6:11:F5:7C:F2:56:E4:DA:D8:31
</span><span class='line'>[root@cu2 puppet]# puppet cert sign --all
</span><span class='line'>Notice: Signed certificate request for cu5.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu5.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu5.eshore.cn.pem'
</span><span class='line'>Notice: Signed certificate request for cu4.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu4.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu4.eshore.cn.pem'
</span><span class='line'>Notice: Signed certificate request for cu3.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu3.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu3.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 最终效果
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>+ "cu1.eshore.cn" (SHA256) 46:69:EE:A8:E5:F9:FB:E3:59:63:C5:FC:52:AF:14:43:70:EF:D0:42:70:C4:0E:D2:14:E4:1C:D9:94:F8:9E:E7
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) 3D:8E:4E:18:45:F4:8C:9B:71:7C:13:45:0D:8A:6F:A5:6E:22:D5:0E:B1:B0:54:29:47:02:AE:95:8B:E6:A6:B7 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>+ "cu3.eshore.cn" (SHA256) 58:ED:A3:CC:B9:53:34:4B:64:3C:2A:B4:91:AD:0D:8F:AF:EA:B0:5C:A7:73:06:F1:A7:4B:D2:E2:06:B5:21:39
</span><span class='line'>+ "cu4.eshore.cn" (SHA256) DD:A2:B9:86:53:29:DB:12:A3:0C:AA:9C:11:68:72:70:72:E2:16:36:8E:20:AC:E5:48:12:36:E2:80:6C:F0:E6
</span><span class='line'>+ "cu5.eshore.cn" (SHA256) EE:E6:FB:D2:1A:04:AD:C3:5B:1F:4F:79:C3:B6:36:15:B5:AC:8B:8B:5D:CB:A4:AA:AF:7B:FB:50:0B:83:7E:38
</span></code></pre></td></tr></table></div></figure>


<h1>自动签名配置文件</h1>

<p>反正都是学习，在无尽的折腾成长。如果是生产环境最好不要清理服务端的已签名证书，不但客户端要重新签，如果安装了puppetdb等其他程序需要签名都得重新配置签名。</p>

<p>注意： 如果已经安装官网的步骤安装 PuppetDB ，清理服务端的证书建议通过命令 puppet cert clean DOMAIN 来清理。否则 PuppetDB 中还有对应的证书缓存信息。</p>

<p><img src="http://winseliu.com/images/blogs/puppet-puppetdb-resign.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://tickets.puppetlabs.com/browse/PUP-1426
</span><span class='line'># 貌似不支持全部清除已签名证书
</span><span class='line'>[root@cu2 ~]# puppet cert clean --all 
</span><span class='line'>Error: Refusing to revoke all certs, provide an explicit list of certs to revoke
</span><span class='line'>
</span><span class='line'># 直接删掉ssl目录
</span><span class='line'>[root@cu2 ~]# puppet master --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# cd /etc/puppetlabs/puppet
</span><span class='line'>[root@cu2 puppet]# ll
</span><span class='line'>...
</span><span class='line'>drwxrwx--x 8 puppet puppet 4096 Apr 20 15:10 ssl
</span><span class='line'>
</span><span class='line'># 注意ssl目录的权限。这里仅删除目录里面的文件
</span><span class='line'>[root@cu2 puppet]# service puppetserver stop
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>[root@cu2 puppet]# 
</span><span class='line'>[root@cu2 puppet]# rm -rf ssl/*
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 先启动服务看看原来已签名的再连服务器是什么情况
</span><span class='line'>[root@cu2 puppet]# service puppetserver start
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# tree ssl/
</span><span class='line'>ssl/
</span><span class='line'>├── ca
</span><span class='line'>│   ├── ca_crl.pem
</span><span class='line'>│   ├── ca_crt.pem
</span><span class='line'>│   ├── ca_key.pem
</span><span class='line'>│   ├── ca_pub.pem
</span><span class='line'>│   ├── inventory.txt
</span><span class='line'>│   ├── requests
</span><span class='line'>│   ├── serial
</span><span class='line'>│   └── signed
</span><span class='line'>│       └── cu2.eshore.cn.pem
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   └── cu2.eshore.cn.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    └── cu2.eshore.cn.pem
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># agent 再请求，会报错。删除 ssl 后，再签名
</span><span class='line'>[root@cu3 ~]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Warning: Unable to fetch my node definition, but the agent run will continue:
</span><span class='line'>Warning: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/facts.d]: Could not evaluate: Could not retrieve file metadata for puppet:///pluginfacts: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Failed to generate additional resources using 'eval_generate': SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Error: /File[/opt/puppetlabs/puppet/cache/lib]: Could not evaluate: Could not retrieve file metadata for puppet:///plugins: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Error: Could not retrieve catalog from remote server: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>Warning: Not using cache on failed catalog
</span><span class='line'>Error: Could not retrieve catalog; skipping run
</span><span class='line'>Error: Could not send report: SSL_connect returned=1 errno=0 state=error: certificate verify failed: [unable to get local issuer certificate for /CN=cu2.eshore.cn]
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# puppet agent --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>[root@cu3 ~]# cd /etc/puppetlabs/puppet
</span><span class='line'>[root@cu3 puppet]# rm -rf ssl/*
</span><span class='line'>[root@cu3 puppet]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu3.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 9D:58:14:C0:CA:DD:51:77:0B:3F:EB:09:02:9B:D6:67:04:FD:48:7A:6E:CB:83:43:8D:5B:A9:78:0C:89:90:5B
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>  "cu3.eshore.cn" (SHA256) 9D:58:14:C0:CA:DD:51:77:0B:3F:EB:09:02:9B:D6:67:04:FD:48:7A:6E:CB:83:43:8D:5B:A9:78:0C:89:90:5B
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) BA:C4:C9:CC:92:6E:45:2E:B1:7F:BC:15:49:0A:2C:BB:5F:C6:B0:73:EB:6C:21:EA:C8:A6:DD:2D:FE:DF:67:70 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>[root@cu2 puppet]# puppet cert sign --all
</span><span class='line'>Notice: Signed certificate request for cu3.eshore.cn
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest cu3.eshore.cn at '/etc/puppetlabs/puppet/ssl/ca/requests/cu3.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'>[root@cu3 puppet]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for cu3.eshore.cn
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu3.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461205206'
</span><span class='line'>Notice: Applied catalog in 0.01 seconds
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 配置autosign
</span><span class='line'># https://docs.puppet.com/puppet/4.4/reference/ssl_autosign.html
</span><span class='line'># 在CA的服务器配置的master节点下配置autosign: Naïve Autosigning
</span><span class='line'>[root@cu2 puppet]# vi puppet.conf 
</span><span class='line'>...
</span><span class='line'>autosign = true
</span><span class='line'># 或者添加配置文件: Basic Autosigning (autosign.conf)
</span><span class='line'>[root@cu2 puppet]# vi autosign.conf
</span><span class='line'>*.eshore.cn
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# service puppetserver restart
</span><span class='line'>Stopping puppetserver:                                     [  OK  ]
</span><span class='line'>Starting puppetserver:                                     [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># agent 自动重新签名
</span><span class='line'>[root@cu1 ~]# cd /etc/puppetlabs/puppet/
</span><span class='line'>[root@cu1 puppet]# rm -rf ssl/*
</span><span class='line'>[root@cu1 puppet]# 
</span><span class='line'>[root@cu1 puppet]# puppet agent --server cu2.eshore.cn --test
</span><span class='line'>Info: Creating a new SSL key for cu1.eshore.cn
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for cu1.eshore.cn
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): D1:F5:6D:A4:91:57:DF:92:47:98:B7:C6:78:E5:C5:E0:AA:DA:70:90:0D:68:48:09:81:FA:65:98:02:F0:84:A9
</span><span class='line'>Info: Caching certificate for cu1.eshore.cn
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for cu1.eshore.cn
</span><span class='line'>Info: Applying configuration version '1461205750'
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>
</span><span class='line'>[root@cu2 puppet]# puppet cert list -all
</span><span class='line'>+ "cu1.eshore.cn" (SHA256) F9:48:1D:85:A7:44:78:71:AA:44:02:3F:98:20:DB:20:B1:DA:10:EC:3A:6A:AE:85:D4:37:EC:9E:20:AB:84:AA
</span><span class='line'>+ "cu2.eshore.cn" (SHA256) BA:C4:C9:CC:92:6E:45:2E:B1:7F:BC:15:49:0A:2C:BB:5F:C6:B0:73:EB:6C:21:EA:C8:A6:DD:2D:FE:DF:67:70 (alt names: "DNS:puppet", "DNS:cu2.eshore.cn")
</span><span class='line'>+ "cu3.eshore.cn" (SHA256) BA:00:57:50:1D:91:40:0D:7D:E4:C5:99:6F:3F:77:D6:E8:C4:71:5B:8D:8C:AB:FA:D0:D4:5C:36:5D:AB:A7:1B
</span><span class='line'>+ "cu4.eshore.cn" (SHA256) 96:64:4A:73:EC:D7:A6:0D:73:37:82:33:2D:0D:B3:BF:A6:A8:6B:9B:D4:05:D0:2C:46:3B:E2:22:6E:43:39:91
</span><span class='line'>+ "cu5.eshore.cn" (SHA256) 54:48:34:BF:C9:60:8C:4C:D2:9D:C9:A3:52:2E:EB:29:AC:2E:84:2E:9E:34:F1:A3:30:83:46:0E:BF:A9:5D:9A
</span></code></pre></td></tr></table></div></figure>


<p>autosign 除了使用 autosign.conf 配置，还可以使用 shell/命令 来进行适配，具体查看官网文档： <a href="https://docs.puppet.com/puppet/4.4/reference/ssl_autosign.html">https://docs.puppet.com/puppet/4.4/reference/ssl_autosign.html</a></p>

<p>agent执行同步命令每次都要指定server很麻烦，可以修改 puppet.conf 配置，每次执行是从配置文件读取：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 plugins]# vi /etc/puppetlabs/puppet/puppet.conf 
</span><span class='line'>...
</span><span class='line'>[agent]
</span><span class='line'>server = cu2.eshore.cn
</span><span class='line'>certname = cu2.eshore.cn  # 主机名不确定情况下，可以通过这个来指定当前机器的主机名！！每台机器根据主机单独设置！
</span></code></pre></td></tr></table></div></figure>


<h1>命令合集</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>puppet agent --server cu2.eshore.cn --test
</span><span class='line'>
</span><span class='line'>puppet cert list -all
</span><span class='line'>
</span><span class='line'>puppet node clean cu1.ds.ctyun 
</span><span class='line'>puppet cert clean cu2.ds.ctyun
</span><span class='line'>puppet certificate_request destroy cu1.ds.ctyun
</span><span class='line'>
</span><span class='line'>puppet cert sign cu1.eshore.cn
</span><span class='line'>puppet cert sign --all
</span><span class='line'>
</span><span class='line'>puppet config print certname
</span><span class='line'>puppet master --configprint ssldir
</span><span class='line'>puppet agent --configprint ssldir
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Alluxio入门大全2]]></title>
    <link href="http://winseliu.com/blog/2016/04/15/alluxio-quickstart2/"/>
    <updated>2016-04-15T00:41:12+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/15/alluxio-quickstart2</id>
    <content type="html"><![CDATA[<p>alluxio就是原来的tachyon。老大是华人，文档自然就有福利，把en改成cn就可以查看中文版的文档了。</p>

<p><a href="http://alluxio.org/documentation/master/cn/Architecture.html">http://alluxio.org/documentation/master/cn/Architecture.html</a></p>

<p>注意：docker暂时不能部署alluxio： <strong>mount: permission denied</strong></p>

<p>首先介绍alluxio的编译，然后进行本地和集群两种方式的部署，同时介绍HDFS底层存储系统配置和一些常用命令行的使用，最后通过代码和spark读写Alluxio数据，以及升级到V1.1查看系统的Metrics指标来了解存储系统使用情况。</p>

<p>回头看：Alluxio启动时会挂载一个Mem内存盘，其实可以把内存盘路径指定到 /dev/shm 。其他操作就很简单了，也不需要root权限。</p>

<h1>编译</h1>

<ul>
<li><a href="http://alluxio.org/documentation/master/en/Building-Alluxio-Master-Branch.html">http://alluxio.org/documentation/master/en/Building-Alluxio-Master-Branch.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Alluxio-Locally.html">http://alluxio.org/documentation/master/en/Running-Alluxio-Locally.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Alluxio-on-a-Cluster.html">http://alluxio.org/documentation/master/en/Running-Alluxio-on-a-Cluster.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 下载官网打包的bin.tar.gz。不推荐去github下v1.0.1，编译时findbug检查server有两个bug
</span><span class='line'>http://alluxio.org/downloads/files/1.0.1/alluxio-1.0.1-bin.tar.gz
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ cd ~/sources/alluxio-1.0.1/
</span><span class='line'>[hadoop@cu2 alluxio-1.0.1]$ export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"
</span><span class='line'>[hadoop@cu2 alluxio-1.0.1]$ mvn clean package assembly:single -Phadoop-2.6 -Dhadoop.version=2.6.3 -Pyarn,spark -Dmaven.test.skip=true -Dmaven.javadoc.skip=true
</span></code></pre></td></tr></table></div></figure>


<p>编译成功后会生成 assembly/target/alluxio-1.0.1.tar.gz 文件。部署的时刻直接用编译好的 tar.gz 就行了，内容比较简洁和清晰。</p>

<p>还有一个问题，不要加Profile <strong>compileJsp</strong> ，编译没问题但是部署后访问网页抛 ClassNotFound 异常。</p>

<p>windows alluxio-1.1-snapshot 编译需要注意下。打包 assembly 的时刻换行符没有格式化，还有 mvn 编译时需要用到 test 项目(改成skipTests)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git diff assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>diff --git a/assembly/src/main/assembly/alluxio-dist.xml b/assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>index 14ecd19..06ddd51 100644
</span><span class='line'>--- a/assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>+++ b/assembly/src/main/assembly/alluxio-dist.xml
</span><span class='line'>@@ -11,6 +11,7 @@
</span><span class='line'>       &lt;outputDirectory&gt;/bin&lt;/outputDirectory&gt;
</span><span class='line'>       &lt;fileMode&gt;0755&lt;/fileMode&gt;
</span><span class='line'>       &lt;directoryMode&gt;0755&lt;/directoryMode&gt;
</span><span class='line'>+      &lt;lineEnding&gt;unix&lt;/lineEnding&gt;
</span><span class='line'>     &lt;/fileSet&gt;
</span><span class='line'>     &lt;fileSet&gt;
</span><span class='line'>       &lt;directory&gt;${basedir}/../conf&lt;/directory&gt;
</span><span class='line'>@@ -19,6 +20,7 @@
</span><span class='line'>     &lt;fileSet&gt;
</span><span class='line'>       &lt;directory&gt;${basedir}/../libexec&lt;/directory&gt;
</span><span class='line'>       &lt;outputDirectory&gt;/libexec&lt;/outputDirectory&gt;
</span><span class='line'>+      &lt;lineEnding&gt;unix&lt;/lineEnding&gt;
</span><span class='line'>     &lt;/fileSet&gt;
</span><span class='line'>     &lt;fileSet&gt;
</span><span class='line'>       &lt;directory&gt;${basedir}/..&lt;/directory&gt;
</span><span class='line'>
</span><span class='line'>E:\git\alluxio&gt;set MAVEN_OPTS="-Xmx2g"
</span><span class='line'>E:\git\alluxio&gt;mvn clean package assembly:single -Phadoop-2.6 -Dhadoop.version=2.6.3 -Pyarn,spark -DskipTests -Dmaven.javadoc.skip=true</span></code></pre></td></tr></table></div></figure>


<h1>Local部署配置</h1>

<p><a href="http://alluxio.org/documentation/master/cn/Running-Alluxio-Locally.html">http://alluxio.org/documentation/master/cn/Running-Alluxio-Locally.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ tar zxf alluxio-1.0.1.tar.gz  
</span><span class='line'>[hadoop@hadoop-master2 ~]$ cd alluxio-1.0.1/conf/
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp alluxio-env.sh.template alluxio-env.sh
</span><span class='line'>[hadoop@hadoop-master2 conf]$ vi alluxio-env.sh
</span><span class='line'>...
</span><span class='line'>JAVA_HOME=/opt/jdk1.7.0_60
</span><span class='line'>ALLUXIO_UNDERFS_ADDRESS=/home/hadoop/tmp
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cd ..
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
</span><span class='line'>Connecting to localhost as hadoop...
</span><span class='line'>Formatting Alluxio Worker @ hadoop-master2
</span><span class='line'>Connection to localhost closed.
</span><span class='line'>Formatting Alluxio Master @ localhost
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ 
</span><span class='line'>
</span><span class='line'># 把hadoop用户加入sudo
</span><span class='line'>[root@hadoop-master2 ~]# visudo 
</span><span class='line'>...
</span><span class='line'>hadoop        ALL=(ALL)       NOPASSWD: ALL
</span><span class='line'>
</span><span class='line'># 机器原来部署过hadoop，localhost已经可以无密钥登录。
</span><span class='line'>
</span><span class='line'># 启动
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh local
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Connecting to localhost as hadoop...
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Connection to localhost closed.
</span><span class='line'>Formatting RamFS: /mnt/ramdisk (1gb)
</span><span class='line'>Starting master @ localhost. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>Starting worker @ hadoop-master2. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ 
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ jps
</span><span class='line'>3780 AlluxioMaster
</span><span class='line'>3845 Jps
</span><span class='line'>3807 AlluxioWorker
</span><span class='line'>
</span><span class='line'># localhost:19999 通过web页查看集群状态
</span><span class='line'>
</span><span class='line'># 关闭
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-stop.sh all
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Connecting to localhost as hadoop...
</span><span class='line'>Killed 0 processes on hadoop-master2
</span><span class='line'>Connection to localhost closed.</span></code></pre></td></tr></table></div></figure>


<p>这里完全安装官网的步骤来弄，正式环境的时刻可以用 root 来 mount 内存盘。下面集群部署再介绍。</p>

<p><img src="http://winseliu.com/images/blogs/alluxio-local.png" alt="" /></p>

<h1>集群部署</h1>

<ul>
<li><a href="http://alluxio.org/documentation/master/cn/Running-Alluxio-on-a-Cluster.html">http://alluxio.org/documentation/master/cn/Running-Alluxio-on-a-Cluster.html</a></li>
<li>HA <a href="http://alluxio.org/documentation/master/en/Running-Alluxio-Fault-Tolerant.html">http://alluxio.org/documentation/master/en/Running-Alluxio-Fault-Tolerant.html</a></li>
</ul>


<p>步骤和Local类似。把程序部署到workers节点，所有workers节点都 mount 内存盘，然后调用 start.sh 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master 和 workers 的无密钥登录。部署过apache-hadoop的肯定都已经弄过了
</span><span class='line'>
</span><span class='line'># 修改配置
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/workers 
</span><span class='line'>bigdata1
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/alluxio-env.sh
</span><span class='line'>ALLUXIO_MASTER_ADDRESS=hadoop-master2
</span><span class='line'>
</span><span class='line'># 部署程序
</span><span class='line'># bin/alluxio copyDir &lt;dirname&gt; 慎用，会把logs目录也同步过去的，
</span><span class='line'># 当然可以修改alluxio的脚本，反正要知道脚本的作用
</span><span class='line'>[hadoop@hadoop-master2 ~]$ rsync -az alluxio-1.0.1 bigdata1:~/ --exclude=logs --exclude=/*/src --exclude=underfs --exclude=journal
</span><span class='line'>
</span><span class='line'># 使用root用户挂载(workers)节点的内存盘
</span><span class='line'># 当然还有最简单的方式，直接把 ALLUXIO_RAM_FOLDER=/dev/shm 指定到系统的tmpfs，系统的tmpfs其实也主要用的是内存。
</span><span class='line'># 变量 ALLUXIO_WORKER_MEMORY_SIZE=512MB 修改内存盘的大小，小于 /dev/shm 的空间大小。
</span><span class='line'>[root@hadoop-master2 ~]# cd /home/hadoop/alluxio-1.0.1
</span><span class='line'>[root@hadoop-master2 alluxio-1.0.1]# bin/alluxio-mount.sh Mount workers
</span><span class='line'>Connecting to bigdata1 as root...
</span><span class='line'>Warning: Permanently added 'bigdata1,192.168.191.133' (RSA) to the list of known hosts.
</span><span class='line'>Formatting RamFS: /mnt/ramdisk (1gb)
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>
</span><span class='line'># worker节点确认
</span><span class='line'>[hadoop@bigdata1 ~]$ mount
</span><span class='line'>/dev/mapper/VolGroup-lv_root on / type ext4 (rw)
</span><span class='line'>proc on /proc type proc (rw)
</span><span class='line'>sysfs on /sys type sysfs (rw)
</span><span class='line'>devpts on /dev/pts type devpts (rw,gid=5,mode=620)
</span><span class='line'>tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
</span><span class='line'>/dev/sda1 on /boot type ext4 (rw)
</span><span class='line'>none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
</span><span class='line'>ramfs on /mnt/ramdisk type ramfs (rw,size=1gb)
</span><span class='line'>
</span><span class='line'># 格式化：主要是清理/创建JOURNAL目录，清理workers本地缓存(tiered-storage)目录数据
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
</span><span class='line'>Connecting to bigdata1 as hadoop...
</span><span class='line'>Formatting Alluxio Worker @ bigdata1
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>Formatting Alluxio Master @ localhost
</span><span class='line'>
</span><span class='line'># 启动
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh all NoMount
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Killed 1 processes on hadoop-master2
</span><span class='line'>Connecting to bigdata1 as hadoop...
</span><span class='line'>Killed 0 processes on bigdata1
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>Starting master @ localhost. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>Connecting to bigdata1 as hadoop...
</span><span class='line'>Starting worker @ bigdata1. Logging to /home/hadoop/alluxio-1.0.1/logs
</span><span class='line'>Connection to bigdata1 closed.
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ jps
</span><span class='line'>5164 AlluxioMaster
</span><span class='line'>5219 Jps
</span><span class='line'>
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ jps
</span><span class='line'>1849 Jps
</span><span class='line'>1829 AlluxioWorker
</span></code></pre></td></tr></table></div></figure>


<p>通过网页查看，如果 <strong>Running Workers</strong> 为 <strong>0</strong> ，到workers节点 alluxio-1.0.1/logs 下面去看日志然后定位问题。防火墙没开放？还是其他配置不正确，如hosts等等。</p>

<h1>命令行HelloWorld</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs copyFromLocal conf/alluxio-env.sh /
</span><span class='line'>Copied conf/alluxio-env.sh to /
</span><span class='line'>
</span><span class='line'># worker节点查看内容（当前只有这一个文件啊，查看方便），block-id可以通过网页或者 fs fileInfo查看
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ tail -1 /mnt/ramdisk/alluxioworker/117440512 
</span><span class='line'>export ALLUXIO_WORKER_JAVA_OPTS="${ALLUXIO_JAVA_OPTS}"
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 在master机器上调用 persist ，在worker节点没找到对应的数据。竟然直接存储在执行命令的节点了，囧！！！
</span><span class='line'># alluxio.client.file.FileSystemUtils#persistFile
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs persist /alluxio-env.sh
</span><span class='line'>persisted file /alluxio-env.sh with size 5493
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ ll /home/hadoop/tmp/
</span><span class='line'>total 28
</span><span class='line'>-rwxrwxrwx  1 hadoop hadoop 5493 Apr 15 03:33 alluxio-env.sh
</span><span class='line'>
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ bin/alluxio fs persist /alluxio-env.sh
</span><span class='line'>/alluxio-env.sh is already persisted
</span><span class='line'>[hadoop@bigdata1 alluxio-1.0.1]$ ll /home/hadoop/tmp
</span><span class='line'>总用量 0</span></code></pre></td></tr></table></div></figure>


<p>在master调用 persist 后，再在worker节点调用 persist 竟然提示 <strong>already persisted</strong> 了。如果在分布式的情况下，本地磁盘 <strong>不适合</strong> 用于做 underfs ！！官网也是说 <strong>单节点</strong> <strong>本地文件系统</strong>。</p>

<blockquote><p>Alluxio提供了通用接口以简化插入不同的底层存储系统。目前我们支持Amazon S3，OpenStack Swift，Apache HDFS，GlusterFS以及单节点本地文件系统</p></blockquote>

<h1>使用HDFS作为底层存储</h1>

<p><a href="http://alluxio.org/documentation/master/en/Configuring-Alluxio-with-HDFS.html">http://alluxio.org/documentation/master/en/Configuring-Alluxio-with-HDFS.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/alluxio-env.sh
</span><span class='line'>...
</span><span class='line'>JAVA_HOME=/opt/jdk1.7.0_60
</span><span class='line'>HADOOP_HOME=/home/hadoop/hadoop-2.6.3
</span><span class='line'>
</span><span class='line'># source $HADOOP_HOME/libexec/hadoop-config.sh
</span><span class='line'>JAVA_LIBRARY_PATH="$HADOOP_HOME/lib/native"
</span><span class='line'>ALLUXIO_JAVA_OPTS="$ALLUXIO_JAVA_OPTS -Djava.library.path=$JAVA_LIBRARY_PATH"
</span><span class='line'>LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$JAVA_LIBRARY_PATH
</span><span class='line'>
</span><span class='line'>ALLUXIO_CLASSPATH=$HADOOP_HOME/etc/hadoop:$ALLUXIO_CLASSPATH
</span><span class='line'>ALLUXIO_UNDERFS_ADDRESS=hdfs:///alluxio                       # 配置一个alluxio子路径比较好管理
</span><span class='line'>ALLUXIO_MASTER_ADDRESS=hadoop-master2
</span><span class='line'>
</span><span class='line'># 清理/创建元数据目录和workers节点本地缓冲存储的数据
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh master
</span><span class='line'>
</span><span class='line'># master启动正常后，启动workers节点
</span><span class='line'># 上面已经用root mount了内存盘了，没有的用root执行 bin/alluxio-mount.sh Mount workers
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh workers NoMount</span></code></pre></td></tr></table></div></figure>


<ul>
<li>使用</li>
</ul>


<p><a href="http://alluxio.org/documentation/master/en/Command-Line-Interface.html">http://alluxio.org/documentation/master/en/Command-Line-Interface.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs copyFromLocal  ~/hadoop-2.6.3/README.txt /
</span><span class='line'>Copied /home/hadoop/hadoop-2.6.3/README.txt to /
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs location /README.txt
</span><span class='line'>/README.txt with file id 33554431 is on nodes: 
</span><span class='line'>bigdata1
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs persist /README.txt
</span><span class='line'>/README.txt is already persisted
</span><span class='line'>
</span><span class='line'># 默认文件只写到 Cache ，可以修改配置来进行修改
</span><span class='line'># alluxio.client.WriteType
</span><span class='line'>[hadoop@hadoop-master2 alluxio]$ export ALLUXIO_JAVA_OPTS="-Dalluxio.user.file.writetype.default=CACHE_THROUGH"
</span><span class='line'>[hadoop@hadoop-master2 alluxio]$ bin/alluxio fs copyFromLocal ~/hadoop-2.6.3/README.txt /                      
</span><span class='line'>Copied /home/hadoop/hadoop-2.6.3/README.txt to /
</span><span class='line'>[hadoop@hadoop-master2 alluxio]$ bin/alluxio fs fileInfo /README.txt                                           
</span><span class='line'>FileInfo{fileId=452984831, name=README.txt, path=/README.txt, ufsPath=hdfs:///alluxio/README.txt, length=1366, blockSizeBytes=536870912, creationTimeMs=1460765370996, completed=true, folder=false, pinned=false, cacheable=true, persisted=true, blockIds=[436207616], inMemoryPercentage=100, lastModificationTimesMs=1460765372423, ttl=-1, userName=, groupName=, permission=0, persistenceState=PERSISTED, mountPoint=false}
</span><span class='line'>Containing the following blocks: 
</span><span class='line'>BlockInfo{id=436207616, length=1366, locations=[BlockLocation{workerId=1, address=WorkerNetAddress{host=bigdata1, rpcPort=29998, dataPort=29999, webPort=30000}, tierAlias=MEM}]}
</span><span class='line'>
</span><span class='line'># Creates a 0 byte file. The file will be written to the under file system. 
</span><span class='line'># For example, touch can be used to create a file signifying the compeletion of analysis on a directory.
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs touch /1234.txt    
</span><span class='line'>/1234.txt has been created
</span><span class='line'>
</span><span class='line'># 已经persist的文件，重命名后，hdfs上面的文件也立即改变了
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs mv /1234.txt /4321.txt
</span><span class='line'>Renamed /1234.txt to /4321.txt
</span><span class='line'>
</span><span class='line'># 空文件没有分配实际的存储，只有元数据
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs location /4321.txt    
</span><span class='line'>/4321.txt with file id 67108863 is on nodes: 
</span><span class='line'>
</span><span class='line'># free掉memory，然后删掉underfs目录下的文件
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs free /
</span><span class='line'>/ was successfully freed from memory.
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs dfs -rmr /alluxio/*
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /  
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  Not In Memory  /README.txt
</span><span class='line'>0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs tail /README.txt
</span><span class='line'>File does not exist: /alluxio/README.txt
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:66)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1893)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1834)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1814)
</span><span class='line'>
</span><span class='line'># 按照文件名把 README.txt 放到 underfs 目录下面
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs dfs -put *.txt /alluxio/ 
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs tail /README.txt
</span><span class='line'>...
</span><span class='line'>software:
</span><span class='line'>  Hadoop Core uses the SSL libraries from the Jetty project written 
</span><span class='line'>by mortbay.org.
</span><span class='line'>
</span><span class='line'># 数据载入内存
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs load /
</span><span class='line'>/README.txt loaded
</span><span class='line'>/ loaded
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /  
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
</span><span class='line'>0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
</span><span class='line'>
</span><span class='line'># 载入underfs的目录结构
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio loadufs / hdfs:///alluxio 
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /
</span><span class='line'>1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
</span><span class='line'>0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
</span><span class='line'>15.07KB   04-15-2016 10:12:33:176  Not In Memory  /LICENSE.txt
</span><span class='line'>101.00B   04-15-2016 10:12:33:190  Not In Memory  /NOTICE.txt
</span><span class='line'>
</span><span class='line'># 通过 fileInfo 查看信息； fileId, ufsPath, 和分区blocks信息
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs fileInfo /README.txt
</span><span class='line'>
</span><span class='line'># 通配符要这么写，也是醉鸟
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs rm /\\*
</span><span class='line'>/4321.txt has been removed
</span><span class='line'>/LICENSE.txt has been removed
</span><span class='line'>/NOTICE.txt has been removed
</span><span class='line'>/README.md has been removed
</span><span class='line'>/README.txt has been removed
</span><span class='line'>
</span><span class='line'># alluxio系统中没有的文件，但是underfs包括的文件，读取一遍后元数据会载入alluxio
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs ls /
</span><span class='line'>1366.00B  04-16-2016 08:09:30:996  In Memory      /README.txt
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs cat /LICENSE.txt
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs ls /
</span><span class='line'>1366.00B  04-16-2016 08:09:30:996  In Memory      /README.txt
</span><span class='line'>15.07KB   04-16-2016 08:26:22:495  Not In Memory  /LICENSE.txt</span></code></pre></td></tr></table></div></figure>


<p>文件结构大概搞明白了，从 underfs 加载目录结构(loadufs)，文件载入alluxio内存(fs load)，alluxio文件持久化(fs persist)都有对应的命令。
理解 <a href="http://alluxio.org/documentation/master/en/Unified-and-Transparent-Namespace.html">mount</a> 和linux的mount类似，把 underfs 当做一个硬盘设备去理解。</p>

<p>但是好像没有修改文件的API，难道不支持修改？？暂时好像没有(2016-4-15 23:06:20 v1.1)</p>

<blockquote><p><a href="http://alluxio.org/documentation/master/en/Key-Value-System-API.html">http://alluxio.org/documentation/master/en/Key-Value-System-API.html</a>
Like files in Alluxio filesystem, the semantics of key-value system are also write-once</p></blockquote>

<h1>FileSystem API</h1>

<ul>
<li><a href="http://docs.scala-lang.org/tutorials/scala-with-maven.html">http://docs.scala-lang.org/tutorials/scala-with-maven.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/File-System-API.html">http://alluxio.org/documentation/master/en/File-System-API.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># scala
</span><span class='line'>object App {
</span><span class='line'>
</span><span class='line'>  def using[A &lt;: {def close() : Unit}, B](resource: A)(f: A =&gt; B): B =
</span><span class='line'>    try { f(resource) } finally { resource.close() }
</span><span class='line'>
</span><span class='line'>  def main(args: Array[String]) {
</span><span class='line'>    // @see alluxio.Configuration.Configuration(boolean)
</span><span class='line'>    System.setProperty(Constants.MASTER_HOSTNAME, "192.168.191.132")
</span><span class='line'>    System.setProperty("HADOOP_USER_NAME", "hadoop")
</span><span class='line'>
</span><span class='line'>    val fs = FileSystem.Factory.get();
</span><span class='line'>    val path = new AlluxioURI("/README.md");
</span><span class='line'>    using(fs.createFile(path, CreateFileOptions.defaults().setWriteType(WriteType.THROUGH))){ out =&gt;
</span><span class='line'>      val content =
</span><span class='line'>"""FileSystem API Write.
</span><span class='line'>   -------------------------
</span><span class='line'>   Hello World!
</span><span class='line'>"""
</span><span class='line'>      out.write(content.getBytes)
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    using(fs.openFile(path)) { in =&gt;
</span><span class='line'>      val buffer = new Array[Byte](1024)
</span><span class='line'>      val size = in.read(buffer)
</span><span class='line'>      System.out.println(new String(buffer, 0, size))
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># THROUGH 仅写入到underfs
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /README.md
</span><span class='line'>115.00B   04-15-2016 20:36:57:345  Not In Memory  /README.md
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ ~/hadoop-2.6.3/bin/hadoop fs -cat /alluxio/README.md
</span><span class='line'>FileSystem API Write.
</span><span class='line'>   -------------------------
</span><span class='line'>   Hello World!
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.0.1]$ </span></code></pre></td></tr></table></div></figure>


<p>程序在win10系统运行，需要把 core-site.xml 加到 src/main/resources 下面（前面配置为了省事直接写 <strong>hdfs:///alluxio</strong>, 不加载配置的话程序不知道namenode）</p>

<p>如果<strong>把WriteType设置为 CACHE_THROUGH ，写 underfs 的同时也会写本地缓存</strong>。提交成功后，文件的状态为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs ls /README.md
</span><span class='line'>115.00B   04-15-2016 23:48:33:749  In Memory      /README.md
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs fileInfo /README.md
</span><span class='line'>FileInfo{fileId=318767103, name=README.md, path=/README.md, ufsPath=hdfs:///alluxio/README.md, length=115, blockSizeBytes=536870912, creationTimeMs=1460735313749, completed=true, folder=false, pinned=false, cacheable=true, persisted=true, blockIds=[301989888], inMemoryPercentage=100, lastModificationTimesMs=1460735315749, ttl=-1, userName=, groupName=, permission=0, persistenceState=PERSISTED, mountPoint=false}
</span><span class='line'>Containing the following blocks: 
</span><span class='line'>BlockInfo{id=301989888, length=115, locations=[BlockLocation{workerId=1, address=WorkerNetAddress{host=bigdata1, rpcPort=29998, dataPort=29999, webPort=30000}, tierAlias=MEM}]}
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ ~/hadoop-2.6.3/bin/hadoop fs -ls /alluxio/ 
</span><span class='line'>Found 4 items
</span><span class='line'>-rw-r--r--   1 hadoop supergroup      15429 2016-04-15 09:57 /alluxio/LICENSE.txt
</span><span class='line'>-rw-r--r--   1 hadoop supergroup        101 2016-04-15 09:57 /alluxio/NOTICE.txt
</span><span class='line'>-rwxrwxrwx   1 hadoop supergroup        115 2016-04-15 23:48 /alluxio/README.md</span></code></pre></td></tr></table></div></figure>


<h1>大数据程序中使用Alluxio</h1>

<p>hadoop2通过 <code>org.apache.hadoop.fs.FileSystem</code> services获取绑定的对象，所以<strong>不需要</strong>在core-site.xml里面配置 <strong>fs.alluxio.impl</strong> 和 <strong>fs.alluxio-ft.impl</strong></p>

<ul>
<li><a href="http://alluxio.org/documentation/master/en/Running-Spark-on-Alluxio.html">http://alluxio.org/documentation/master/en/Running-Spark-on-Alluxio.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Hadoop-MapReduce-on-Alluxio.html">http://alluxio.org/documentation/master/en/Running-Hadoop-MapReduce-on-Alluxio.html</a></li>
</ul>


<p>其实都是通过 <strong>Hadoop FileSystem API</strong> 来访问Alluxio的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># .bash_profile加环境变量
</span><span class='line'>[hadoop@hadoop-master2 ~]$ vi ~/.bash_profile 
</span><span class='line'>...
</span><span class='line'>HADOOP_HOME=~/hadoop
</span><span class='line'>SPARK_HOME=~/spark
</span><span class='line'>ALLUXIO_HOME=~/alluxio
</span><span class='line'>
</span><span class='line'>PATH=$HADOOP_HOME/bin:$SPARK_HOME/bin:$ALLUXIO_HOME/bin:$MAVEN_HOME/bin:$ANT_HOME/bin:$PATH
</span><span class='line'># 这里没有 export HADOOP_HOME SPARK_HOME 
</span><span class='line'># 因为在hadoop/spark的启动脚本也定义了这些变量。如果export，也需要把软链接同步到slaves节点
</span><span class='line'>export PATH ANT_HOME MAVEN_HOME
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s hadoop-2.6.3 hadoop
</span><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s alluxio-1.1.0-SNAPSHOT alluxio
</span><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s spark-1.6.0-bin-2.6.3 spark
</span><span class='line'>[hadoop@hadoop-master2 ~]$ . .bash_profile 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ export SPARK_CLASSPATH=\
</span><span class='line'>&gt; ~/alluxio/core/client/target/alluxio-core-client-1.1.0-SNAPSHOT-jar-with-dependencies.jar 
</span><span class='line'>[hadoop@hadoop-master2 ~]$ 
</span><span class='line'>[hadoop@hadoop-master2 ~]$ spark-shell --master local
</span><span class='line'>scala&gt; val file=sc.textFile("alluxio://hadoop-master2:19998/README.txt")
</span><span class='line'>file: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:27
</span><span class='line'>
</span><span class='line'>scala&gt; file.count()
</span><span class='line'>res0: Long = 31
</span><span class='line'>
</span><span class='line'>scala&gt; file.take(2)
</span><span class='line'>res1: Array[String] = Array(For the latest information about Hadoop, please visit our website at:, "")
</span><span class='line'>
</span><span class='line'># wordcount
</span><span class='line'>scala&gt; val op = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)
</span><span class='line'># word sort asc
</span><span class='line'>scala&gt; op.sortByKey().take(10)
</span><span class='line'># count sort desc
</span><span class='line'>scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).take(10)
</span><span class='line'>
</span><span class='line'>scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).saveAsTextFile("alluxio://hadoop-master2:19998/output/")
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ alluxio fs cat /output/*
</span><span class='line'>(,18)
</span><span class='line'>(the,8)
</span><span class='line'>(and,6)
</span><span class='line'>(of,5)
</span><span class='line'>(The,4)
</span><span class='line'>(this,3)
</span><span class='line'>(encryption,3)
</span><span class='line'>(for,3)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>如果运行在集群，在slave的节点也需要与主节点一样的目录结构。 或者按照<a href="http://spark.apache.org/docs/latest/programming-guide.html#using-the-shell">官网的教程</a>操作。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># spark_classpath 会被带到 task 的启动环境变量里面
</span><span class='line'>[hadoop@hadoop-master2 ~]$ rsync -az alluxio bigdata1:~/
</span><span class='line'>[hadoop@hadoop-master2 ~]$ export SPARK_CLASSPATH=\
</span><span class='line'>&gt; ~/alluxio/core/client/target/alluxio-core-client-1.1.0-SNAPSHOT-jar-with-dependencies.jar
</span><span class='line'> 
</span><span class='line'>[hadoop@hadoop-master2 ~]$ spark-shell --master spark://hadoop-master2:7077
</span><span class='line'>scala&gt; val file=sc.textFile("alluxio://hadoop-master2:19998/README.txt")
</span><span class='line'>file: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:27
</span><span class='line'>
</span><span class='line'>scala&gt; val op = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)
</span><span class='line'>op: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:29
</span><span class='line'>
</span><span class='line'>scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).saveAsTextFile("alluxio://hadoop-master2:19998/output2/")
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/alluxio-spark-word-count.png" alt="" /></p>

<h1>Metrics</h1>

<p><a href="http://www.alluxio.org/documentation/master/cn/Metrics-System.html">http://www.alluxio.org/documentation/master/cn/Metrics-System.html</a></p>

<p>v1.0.1有对应的api，可以通过 <a href="http://hadoop-master2:19999/metrics/json/">http://hadoop-master2:19999/metrics/json/</a> 查看。当前master主干分支v1.1.0可以在网页上面查看这些指标。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 拷贝配置
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ cd conf
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/alluxio-env.sh ./
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/log4j.properties ./
</span><span class='line'>[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/workers ./ 
</span><span class='line'>
</span><span class='line'># 启动master（使用原来的元数据）
</span><span class='line'># 共享元数据，在 alluxio-env.sh 修改环境变量 ALLUXIO_JAVA_OPTS 
</span><span class='line'># 添加 -Dalluxio.master.journal.folder=${ALLUXIO_JOURNAL_FOLDER} / ALLUXIO_JOURNAL_FOLDER=/home/hadoop/journal
</span><span class='line'>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio-start.sh master
</span><span class='line'>Starting master @ hadoop-master2. Logging to /home/hadoop/alluxio-1.1.0-SNAPSHOT/logs</span></code></pre></td></tr></table></div></figure>


<p>v1.1.0 页面多了 Metrics 页签：</p>

<p><img src="http://winseliu.com/images/blogs/alluxio-metrics.png" alt="" /></p>

<h1>其他文档</h1>

<ul>
<li>配置alluxio-default.properties <a href="http://alluxio.org/documentation/master/en/Configuration-Settings.html">http://alluxio.org/documentation/master/en/Configuration-Settings.html</a></li>
<li>分层本地缓存 <a href="http://alluxio.org/documentation/master/en/Tiered-Storage-on-Alluxio.html">http://alluxio.org/documentation/master/en/Tiered-Storage-on-Alluxio.html</a></li>
<li><a href="https://dzone.com/articles/Accelerate-In-Memory-Processing-with-Spark-from-Hours-to-Seconds-With-Tachyon">https://dzone.com/articles/Accelerate-In-Memory-Processing-with-Spark-from-Hours-to-Seconds-With-Tachyon</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hiveserver2 Ui and Upgrade hive2.0.0]]></title>
    <link href="http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0/"/>
    <updated>2016-04-13T12:03:43+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0</id>
    <content type="html"><![CDATA[<p>升级hive的标准动作：</p>

<ul>
<li>更新metadata，就是执行sql语句。更新前先备份原来的库！！</li>
<li>调整依赖，我这里是升级spark，编译参考<a href="http://winseliu.com/blog/2016/03/28/hive-on-spark/">spark-without-hive</a></li>
<li>修改参数(hive/spark/hadoop)来适应新版本</li>
<li>hiveserver2 ui：启动hiveserver2服务，访问10002端口即可。<a href="https://cwiki.apache.org/confluence/display/Hive/Setting+Up+HiveServer2#SettingUpHiveServer2-WebUIforHiveServer2">UI配置</a></li>
</ul>


<p>环境说明：</p>

<ul>
<li>centos5</li>
<li>hadoop-2.6.3</li>
<li>spark-1.6.0-without-hive</li>
<li>hive-2.0.0</li>
</ul>


<h2>操作详情</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 备份
</span><span class='line'>[hadoop@file1 tools]$ mysqldump -uroot -p hive &gt;hive1.2.1-20160413.backup.sql
</span><span class='line'>
</span><span class='line'># 准备好程序后的目录结构
</span><span class='line'>[hadoop@file1 ~]$ ll
</span><span class='line'>总计 20
</span><span class='line'>drwxrwxr-x 3 hadoop hadoop 4096 04-13 11:59 collect
</span><span class='line'>drwx------ 3 hadoop hadoop 4096 04-07 16:43 dfs
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   18 04-11 10:09 hadoop -&gt; tools/hadoop-2.6.3
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   40 04-13 10:26 hive -&gt; /home/hadoop/tools/apache-hive-2.0.0-bin
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   42 04-13 10:52 spark -&gt; tools/spark-1.6.0-bin-hadoop2-without-hive
</span><span class='line'>drwxrwxr-x 6 hadoop hadoop 4096 04-13 12:10 tmp
</span><span class='line'>drwxrwxr-x 9 hadoop hadoop 4096 04-13 11:48 tools
</span><span class='line'>[hadoop@file1 tools]$ ll
</span><span class='line'>总计 84
</span><span class='line'>drwxrwxr-x  8 hadoop hadoop  4096 04-08 09:25 apache-hive-1.2.1-bin
</span><span class='line'>drwxrwxr-x  8 hadoop hadoop  4096 04-13 10:16 apache-hive-2.0.0-bin
</span><span class='line'>drwxr-xr-x 11 hadoop hadoop  4096 04-07 16:34 hadoop-2.6.3
</span><span class='line'>-rw-rw-r--  1 hadoop hadoop 46879 04-13 10:11 hive1.2.1-20160413.backup.sql
</span><span class='line'>drwxrwxr-x  2 hadoop hadoop  4096 03-31 15:28 mysql
</span><span class='line'>lrwxrwxrwx  1 hadoop hadoop    36 04-13 10:17 spark -&gt; spark-1.6.0-bin-hadoop2-without-hive
</span><span class='line'>drwxrwxr-x 11 hadoop hadoop  4096 04-07 18:23 spark-1.3.1-bin-hadoop2.6.3-without-hive
</span><span class='line'>drwxrwxr-x 11 hadoop hadoop  4096 03-28 11:15 spark-1.6.0-bin-hadoop2-without-hive
</span><span class='line'>drwxr-xr-x 11 hadoop hadoop  4096 03-31 16:14 zookeeper-3.4.6
</span><span class='line'>
</span><span class='line'># 环境变量我直接加载的是link软链接的，我这直接修改软链就行了。根据情况调整。
</span><span class='line'># apache-hive-2.0.0-bin同级目录建立spark软链接，或者再hive-env.sh中指定SPARK_HOME的位置
</span><span class='line'>
</span><span class='line'># hive-1.2.1并没有txn的表，所有要单独执行下hive-txn-schema-2.0.0.mysql.sql，
</span><span class='line'># 然后再更新（后面的Duplicate column的错没问题的）
</span><span class='line'>[hadoop@file1 tools]$ cd apache-hive-2.0.0-bin/scripts/metastore/upgrade/mysql/
</span><span class='line'>[hadoop@file1 mysql]$ mysql -uroot -p
</span><span class='line'>Enter password: 
</span><span class='line'>Welcome to the MySQL monitor.  Commands end with ; or \g.
</span><span class='line'>Your MySQL connection id is 10765
</span><span class='line'>Server version: 5.5.48 MySQL Community Server (GPL)
</span><span class='line'>
</span><span class='line'>Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.
</span><span class='line'>
</span><span class='line'>Oracle is a registered trademark of Oracle Corporation and/or its
</span><span class='line'>affiliates. Other names may be trademarks of their respective
</span><span class='line'>owners.
</span><span class='line'>
</span><span class='line'>Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
</span><span class='line'>
</span><span class='line'>mysql&gt; use hive;
</span><span class='line'>Reading table information for completion of table and column names
</span><span class='line'>You can turn off this feature to get a quicker startup with -A
</span><span class='line'>
</span><span class='line'>Database changed
</span><span class='line'>mysql&gt; source hive-txn-schema-2.0.0.mysql.sql
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.04 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.03 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.04 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.03 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>
</span><span class='line'>mysql&gt; source upgrade-1.2.0-to-2.0.0.mysql.sql
</span><span class='line'>+------------------------------------------------+
</span><span class='line'>|                                                |
</span><span class='line'>+------------------------------------------------+
</span><span class='line'>| Upgrading MetaStore schema from 1.2.0 to 2.0.0 |
</span><span class='line'>+------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------------------------------+
</span><span class='line'>|                                                                                                               |
</span><span class='line'>+---------------------------------------------------------------------------------------------------------------+
</span><span class='line'>| &lt; HIVE-7018 Remove Table and Partition tables column LINK_TARGET_ID from Mysql for other DBs do not have it &gt; |
</span><span class='line'>+---------------------------------------------------------------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected, 1 warning (0.03 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>
</span><span class='line'>+---------------------------------+
</span><span class='line'>| Completed remove LINK_TARGET_ID |
</span><span class='line'>+---------------------------------+
</span><span class='line'>| Completed remove LINK_TARGET_ID |
</span><span class='line'>+---------------------------------+
</span><span class='line'>1 row in set (0.02 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.02 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 31 rows affected (0.01 sec)
</span><span class='line'>Records: 31  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.05 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.02 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.03 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.00 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'CQ_HIGHEST_TXN_ID'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'CQ_META_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'CQ_HADOOP_JOB_ID'
</span><span class='line'>ERROR 1050 (42S01): Table 'COMPLETED_COMPACTIONS' already exists
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'TXN_AGENT_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'TXN_HEARTBEAT_COUNT'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_HEARTBEAT_COUNT'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'TXN_META_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_AGENT_INFO'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_BLOCKEDBY_EXT_ID'
</span><span class='line'>ERROR 1060 (42S21): Duplicate column name 'HL_BLOCKEDBY_INT_ID'
</span><span class='line'>ERROR 1050 (42S01): Table 'AUX_TABLE' already exists
</span><span class='line'>Query OK, 1 row affected (0.01 sec)
</span><span class='line'>Rows matched: 1  Changed: 1  Warnings: 0
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------+
</span><span class='line'>|                                                         |
</span><span class='line'>+---------------------------------------------------------+
</span><span class='line'>| Finished upgrading MetaStore schema from 1.2.0 to 2.0.0 |
</span><span class='line'>+---------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'># 拷贝hive原来的配置和依赖jar
</span><span class='line'>
</span><span class='line'>[hadoop@file1 mysql]$ cd ~/tools/apache-hive-2.0.0-bin/conf/
</span><span class='line'>[hadoop@file1 conf]$ cp ~/tools/apache-hive-1.2.1-bin/conf/hive-site.xml ./
</span><span class='line'>[hadoop@file1 conf]$ cp ~/tools/apache-hive-1.2.1-bin/conf/spark-defaults.conf ./
</span><span class='line'>[hadoop@file1 conf]$ cp ~/tools/apache-hive-1.2.1-bin/conf/hive-env.sh ./
</span><span class='line'>
</span><span class='line'># 用到spark需要加大PermSize
</span><span class='line'>[hadoop@file1 hive]$ vi conf/hive-env.sh
</span><span class='line'>export HADOOP_USER_CLASSPATH_FIRST=true
</span><span class='line'>export HADOOP_OPTS="$HADOOP_OPTS -XX:MaxPermSize=256m"
</span><span class='line'>
</span><span class='line'>[hadoop@file1 conf]$ cd ../lib/
</span><span class='line'>[hadoop@file1 lib]$ cp ~/tools/apache-hive-1.2.1-bin/lib/mysql-connector-java-5.1.34.jar ./
</span><span class='line'>
</span><span class='line'># centos5需要删除下面两个jar，centos6没必要删
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ rm lib/hive-jdbc-2.0.0-standalone.jar 
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ rm lib/snappy-java-1.0.5.jar 
</span><span class='line'>
</span><span class='line'># spark-1.6.0更新
</span><span class='line'>
</span><span class='line'># http://spark.apache.org/docs/latest/hadoop-provided.html
</span><span class='line'># http://stackoverflow.com/questions/30906412/noclassdeffounderror-com-apache-hadoop-fs-fsdatainputstream-when-execute-spark-s
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ cd ~/tools/spark-1.6.0-bin-hadoop2-without-hive/conf/
</span><span class='line'>[hadoop@file1 conf]$ cp spark-env.sh.template spark-env.sh
</span><span class='line'>[hadoop@file1 conf]$ vi spark-env.sh
</span><span class='line'>HADOOP_HOME=/home/hadoop/hadoop
</span><span class='line'>SPARK_DIST_CLASSPATH=`$HADOOP_HOME/bin/hadoop classpath`
</span><span class='line'>
</span><span class='line'>[hadoop@file1 ~]$ cp ~/tools/spark-1.6.0-bin-hadoop2-without-hive/lib/spark-1.6.0-yarn-shuffle.jar ~/tools/hadoop-2.6.3/share/hadoop/yarn/
</span><span class='line'>[hadoop@file1 ~]$ rm ~/tools/hadoop-2.6.3/share/hadoop/yarn/spark-1.3.1-yarn-shuffle.jar 
</span><span class='line'>
</span><span class='line'>[hadoop@file1 ~]$ rsync -vaz --delete ~/tools/hadoop-2.6.3/share file2:~/tools/hadoop-2.6.3/ 
</span><span class='line'>[hadoop@file1 ~]$ rsync -vaz --delete ~/tools/hadoop-2.6.3/share file3:~/tools/hadoop-2.6.3/ 
</span><span class='line'>
</span><span class='line'>[hadoop@file1 ~]$ hdfs dfs -put ~/tools/spark-1.6.0-bin-hadoop2-without-hive/lib/spark-assembly-1.6.0-hadoop2.6.3.jar /spark/
</span><span class='line'>
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ vi conf/spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.6.0-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'># 重启yarn（如果你用hiveserver2，先往下看，后面还会修改配置重启的）
</span><span class='line'>
</span><span class='line'>[hadoop@file1 apache-hive-2.0.0-bin]$ cd ~/tools/hadoop-2.6.3/
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/stop-yarn.sh 
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/start-yarn.sh 
</span></code></pre></td></tr></table></div></figure>


<p>更新到这里，执行hive命令是ok了的。但是hiveserver还有问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 启动hiveserver2
</span><span class='line'>[hadoop@file1 hive]$ nohup bin/hiveserver2 &
</span><span class='line'>
</span><span class='line'># 启动spark historyserver
</span><span class='line'>[hadoop@file1 spark]$ cat start-historyserver.sh 
</span><span class='line'>source $HADOOP_HOME/libexec/hadoop-config.sh
</span><span class='line'>sbin/start-history-server.sh hdfs:///spark-eventlogs
</span><span class='line'>
</span><span class='line'>[hadoop@file1 hive]$ bin/beeline -u jdbc:hive2://file1:10000/ -n hadoop -p hadoop
</span><span class='line'>which: no hbase in (/home/hadoop/hadoop/bin:/home/hadoop/hive/bin:/opt/jdk1.7.0_60/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin:/home/hadoop/tools/hadoop-2.6.3/bin:/home/hadoop/tools/hadoop-2.6.3:/home/hadoop/tools/apache-hive-1.2.1-bin:/home/hadoop/bin)
</span><span class='line'>ls: /home/hadoop/hive/lib/hive-jdbc-*-standalone.jar: 没有那个文件或目录
</span><span class='line'>SLF4J: Class path contains multiple SLF4J bindings.
</span><span class='line'>SLF4J: Found binding in [jar:file:/home/hadoop/tools/apache-hive-2.0.0-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
</span><span class='line'>SLF4J: Found binding in [jar:file:/home/hadoop/tools/hadoop-2.6.3/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
</span><span class='line'>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
</span><span class='line'>SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
</span><span class='line'>Connecting to jdbc:hive2://file1:10000/
</span><span class='line'>Error: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: hadoop is not allowed to impersonate hadoop (state=,code=0)
</span><span class='line'>Beeline version 2.0.0 by Apache Hive
</span><span class='line'>beeline&gt; </span></code></pre></td></tr></table></div></figure>


<p>Beeline连接hiveserver2失败，模拟的hadoop用户授权失败。需要修改hadoop的参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://community.hortonworks.com/questions/4905/error-while-running-hive-queries-from-zeppelin.html
</span><span class='line'># http://stackoverflow.com/questions/25073792/error-e0902-exception-occured-user-root-is-not-allowed-to-impersonate-root
</span><span class='line'># core-site.xml添加，并重启集群hdfs & yarn
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/stop-all.sh
</span><span class='line'>[hadoop@file1 hadoop-2.6.3]$ sbin/start-all.sh 
</span><span class='line'>
</span><span class='line'>[hadoop@file1 hive]$ bin/beeline -u jdbc:hive2://file1:10000 -n hadoop -p hadoop
</span><span class='line'>...
</span><span class='line'>0: jdbc:hive2://file1:10000/&gt; set hive.execution.engine=spark;
</span><span class='line'>No rows affected (0.019 seconds)
</span><span class='line'>0: jdbc:hive2://file1:10000/&gt; select count(*) from t_info where edate=20160413;
</span><span class='line'>INFO  : Compiling command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea): select count(*) from t_info where edate=20160413
</span><span class='line'>INFO  : Semantic Analysis Completed
</span><span class='line'>INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:c0, type:bigint, comment:null)], properties:null)
</span><span class='line'>INFO  : Completed compiling command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea); Time taken: 0.523 seconds
</span><span class='line'>INFO  : Executing command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea): select count(*) from t_info where edate=20160413
</span><span class='line'>INFO  : Query ID = hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea
</span><span class='line'>INFO  : Total jobs = 1
</span><span class='line'>INFO  : Launching Job 1 out of 1
</span><span class='line'>INFO  : Starting task [Stage-1:MAPRED] in serial mode
</span><span class='line'>
</span><span class='line'>INFO  : 
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>INFO  : 0
</span><span class='line'>INFO  : 1
</span><span class='line'>INFO  : 
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>INFO  : Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>INFO  : 2016-04-13 11:41:20,519 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:23,577 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:26,817 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:29,858 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:32,903 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:35,942 Stage-0_0: 0(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:37,969 Stage-0_0: 0(+9)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:38,981 Stage-0_0: 1(+8)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:39,994 Stage-0_0: 3(+7)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:43,030 Stage-0_0: 3(+7)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:45,056 Stage-0_0: 5(+5)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:46,072 Stage-0_0: 6(+4)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:47,085 Stage-0_0: 8(+2)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:48,096 Stage-0_0: 9(+1)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:51,125 Stage-0_0: 9(+1)/10     Stage-1_0: 0/1
</span><span class='line'>INFO  : 2016-04-13 11:41:52,134 Stage-0_0: 10/10 Finished       Stage-1_0: 1/1 Finished
</span><span class='line'>INFO  : Status: Finished successfully in 64.78 seconds
</span><span class='line'>INFO  : Completed executing command(queryId=hadoop_20160413114039_f930d3e7-af83-4b12-a536-404a4e20eeea); Time taken: 71.767 seconds
</span><span class='line'>INFO  : OK
</span><span class='line'>+-----------+--+
</span><span class='line'>|    c0     |
</span><span class='line'>+-----------+--+
</span><span class='line'>| 89867722  |
</span><span class='line'>+-----------+--+
</span><span class='line'>1 row selected (72.45 seconds)
</span></code></pre></td></tr></table></div></figure>


<p>本来升级是想看看UI长什么样子，有点失望，功能太少了。只能看当前执行的SQL和session，历史记录不能查看。期待新版本UI更强大。</p>

<p>升级后beeline上下键切换历史的也不起作用了，hive-2.0.0没也啥吸引的功能（<strong>hive2准备淘汰mr了</strong>），觉得不爽可以直接替换 软链 退回hive1.2.1-spark1.3.1（实践后没问题，spark.yarn.jar记得改）</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark-on-yarn内存分配]]></title>
    <link href="http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate/"/>
    <updated>2016-04-11T19:44:51+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate</id>
    <content type="html"><![CDATA[<p>上次写了一篇关于配置参数是如何影响mapreduce的实际调度的<a href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/">参考</a>：</p>

<ul>
<li>opts（yarn.app.mapreduce.am.command-opts、mapreduce.map.java.opts、mapreduce.reduce.java.opts）是实际运行程序是内存参数。</li>
<li>memory（yarn.app.mapreduce.am.resource.mb、mapreduce.map.memory.mb、mapreduce.reduce.memory.mb）是用于ResourceManager计算集群资源使用和调度。</li>
</ul>


<p>了解参数区别，就没有再深究task内存的问题了。</p>

<h2>新问题-内存分配</h2>

<p>这次又遇到内存问题：spark使用yarn-client的方式运行时，spark有memoryOverhead的设置，但是加了额外的内存后，再经过集群调度内存浪费严重，对于本来就小内存的集群来说完全无法接受。</p>

<ul>
<li>am默认是512加上384 overhead，也就是896m。但是调度后am分配内存资源为1024。</li>
<li>executor默认是1024加上384，等于1408M。单调度后executor分配内存资源为2048。</li>
</ul>


<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-0.png" alt="" /></p>

<p>从appmaster的日志可以看出来请求的内存大小是1408：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-1.png" alt="" /></p>

<p><strong>一个executor就浪费了500M，本来可以跑4个executor的但现在只能执行3个！</strong></p>

<p>关于内存参数的具体含义查看官网： <a href="http://spark.apache.org/docs/latest/running-on-yarn.html">spark-on-yarn</a> 和 <a href="http://hadoop.apache.org/docs/r2.6.4/hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a></p>

<table>
<thead>
<tr>
<th></th>
<th style="text-align:center;"> <em>参数</em>                                  </th>
<th></th>
<th style="text-align:left;"> <em>值</em></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.am.memory                    </td>
<td></td>
<td style="text-align:left;"> 512m</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.driver.memory                     </td>
<td></td>
<td style="text-align:left;"> 1g</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.executor.memoryOverhead      </td>
<td></td>
<td style="text-align:left;"> executorMemory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.driver.memoryOverhead        </td>
<td></td>
<td style="text-align:left;"> driverMemory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.am.memoryOverhead            </td>
<td></td>
<td style="text-align:left;"> AM memory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.nodemanager.resource.memory-mb     </td>
<td></td>
<td style="text-align:left;"> 8192</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.scheduler.minimum-allocation-mb    </td>
<td></td>
<td style="text-align:left;"> 1024</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.scheduler.maximum-allocation-mb    </td>
<td></td>
<td style="text-align:left;"> 8192</td>
</tr>
</tbody>
</table>


<p>分配的内存看着像是 <strong>最小分配内存</strong> 的整数倍。把 <code>yarn.scheduler.minimum-allocation-mb</code> 修改为512，重启yarn再运行，executor的分配的内存果真减少到1536(<strong>512*3</strong>)。</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-3.png" alt="" /></p>

<p>同时 <a href="http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html">http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html</a> 这篇文章也讲 <strong>在YARN中，Container申请的内存大小必须为yarn.scheduler.minimum-allocation-mb的整数倍</strong> 。我们不去猜，调试下调度代码，看看究竟是什么情况。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ sbin/yarn-daemon.sh stop resourcemanager 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ grep "minimum-allocation-mb" -1 yarn-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;&lt;value&gt;512&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ export YARN_RESOURCEMANAGER_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000"
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ sbin/yarn-daemon.sh start resourcemanager </span></code></pre></td></tr></table></div></figure>


<p>本地eclipse在 <code>CapacityScheduler#allocate</code> 打断点，然后跑任务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2 where month=201512;</span></code></pre></td></tr></table></div></figure>


<p>AppMaster内存分配：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-appmaster.png" alt="" /></p>

<p>Executor内存分配：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-executor.png" alt="" /></p>

<p>request进到allocate后，最终调用 <code>DefaultResourceCalculator.normalize</code> 重新计算了一遍请求需要的资源，把内存调整了。默认的DefaultResourceCalculator可以通过 capacity-scheduler.xml 的 <code>yarn.scheduler.capacity.resource-calculator</code> 来修改。</p>

<p>具体代码调度过程如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public Allocation allocate(ApplicationAttemptId applicationAttemptId,
</span><span class='line'>      List&lt;ResourceRequest&gt; ask, List&lt;ContainerId&gt; release, 
</span><span class='line'>      List&lt;String&gt; blacklistAdditions, List&lt;String&gt; blacklistRemovals) {
</span><span class='line'>    ...
</span><span class='line'>    // Sanity check
</span><span class='line'>    SchedulerUtils.normalizeRequests(
</span><span class='line'>        ask, getResourceCalculator(), getClusterResource(),
</span><span class='line'>        getMinimumResourceCapability(), maximumAllocation);
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static void normalizeRequest(
</span><span class='line'>      ResourceRequest ask, 
</span><span class='line'>      ResourceCalculator resourceCalculator, 
</span><span class='line'>      Resource clusterResource,
</span><span class='line'>      Resource minimumResource,
</span><span class='line'>      Resource maximumResource,
</span><span class='line'>      Resource incrementResource) {
</span><span class='line'>    Resource normalized = 
</span><span class='line'>        Resources.normalize(
</span><span class='line'>            resourceCalculator, ask.getCapability(), minimumResource,
</span><span class='line'>            maximumResource, incrementResource);
</span><span class='line'>    ask.setCapability(normalized);
</span><span class='line'>  }   
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static Resource normalize(
</span><span class='line'>      ResourceCalculator calculator, Resource lhs, Resource min,
</span><span class='line'>      Resource max, Resource increment) {
</span><span class='line'>    return calculator.normalize(lhs, min, max, increment);
</span><span class='line'>  }
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public Resource normalize(Resource r, Resource minimumResource,
</span><span class='line'>      Resource maximumResource, Resource stepFactor) {
</span><span class='line'>    int normalizedMemory = Math.min(
</span><span class='line'>        roundUp(
</span><span class='line'>            Math.max(r.getMemory(), minimumResource.getMemory()),
</span><span class='line'>            stepFactor.getMemory()),
</span><span class='line'>            maximumResource.getMemory());
</span><span class='line'>    return Resources.createResource(normalizedMemory);
</span><span class='line'>  }
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static int roundUp(int a, int b) {
</span><span class='line'>    return divideAndCeil(a, b) * b;
</span><span class='line'>  }
</span><span class='line'>  </span></code></pre></td></tr></table></div></figure>


<p></p>

<h2>小结</h2>

<p>今天又重新认识一个yarn参数 <code>yarn.scheduler.minimum-allocation-mb</code> ，不仅仅是最小分配的内存，同时分配的资源也是minimum-allocation-mb的整数倍，还告诉我们 <code>yarn.nodemanager.resource.memory-mb</code> 也最好是minimum-allocation-mb的整数倍。</p>

<p>间接的学习了新的参数，可以通过 <code>yarn.scheduler.capacity.resource-calculator</code> 参数 来修改 CapacityScheduler 调度器的资源计算类。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive-on-spark Snappy on Centos5]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/"/>
    <updated>2016-04-08T22:27:06+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark</id>
    <content type="html"><![CDATA[<p>hive的assembly包就是一个坑货！既然是一个单独的可运行的jar放到lib包下面干嘛呢！！纯属记录工作过程总的经历，想找干货的飘过吧！！</p>

<p><br/></p>

<p>上周支撑部门其他项目的hadoop项目，由于 <strong>hive mr</strong> 比较慢，想用spark试一试看能不能优化。但是系统使用Centos5，我们项目使用的是Centos6。按部就班的编译呗，hive-on-saprk启用SNAPPY的必要条件：</p>

<ul>
<li>hadoop使用snappy需要native的支持，首先当然是Centos5上编译hadoop。(现在看来可以不必要，但每次hdfs命令都提示我native的错误就很不爽)</li>
<li>hive增加spark。</li>
</ul>


<p>各程序版本信息：</p>

<ul>
<li>hadoop-2.6.3</li>
<li>hive-1.2.1</li>
<li>spark-1.3.1</li>
<li>centos5.4</li>
</ul>


<h2>编译hadoop-snappy</h2>

<ul>
<li>centos5手动</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost snappy-1.1.3]# ./autogen.sh 
</span><span class='line'>Remember to add `AC_PROG_LIBTOOL' to `configure.ac'.
</span><span class='line'>You should update your `aclocal.m4' by running aclocal.
</span><span class='line'>libtoolize: `config.guess' exists: use `--force' to overwrite
</span><span class='line'>libtoolize: `config.sub' exists: use `--force' to overwrite
</span><span class='line'>libtoolize: `ltmain.sh' exists: use `--force' to overwrite
</span><span class='line'>Makefile.am:4: Libtool library used but `LIBTOOL' is undefined
</span><span class='line'>Makefile.am:4: 
</span><span class='line'>Makefile.am:4: The usual way to define `LIBTOOL' is to add `AC_PROG_LIBTOOL'
</span><span class='line'>Makefile.am:4: to `configure.ac' and run `aclocal' and `autoconf' again.
</span><span class='line'>Makefile.am:20: `dist_doc_DATA' is used but `docdir' is undefined</span></code></pre></td></tr></table></div></figure>


<p>在centos5上面手动编译搞不定，不是专业写C的，这些问题就是天书啊(查了很多资料，试了很多方法都没通)！！ <strong>Snappy可以在centos6上面编译，编译好以后再centos5上面也能用，编译hadoop-snappy也是ok的</strong> 。</p>

<ul>
<li>centos5-rpm</li>
</ul>


<p>这里直接用rpm安装snappy。觉得创建虚拟机麻烦的话，也可以用docker。docker不同版本的centos下载： <a href="https://github.com/CentOS/sig-cloud-instance-images/">https://github.com/CentOS/sig-cloud-instance-images/</a> 。然后docker共享host主机的文件： <code>docker run -ti -v /home/hadoop:/home/hadoop -v /opt:/opt -v /data:/data centos:centos5 /bin/bash</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@8fb11f6b3ced ~]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 5.11 (Final)
</span><span class='line'>
</span><span class='line'>https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy
</span><span class='line'>https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy-devel
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ivh snappy-1.0.5-1.el5.x86_64.rpm 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ivh snappy-devel-1.0.5-1.el5.x86_64.rpm                                                                                  
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ql snappy-devel snappy
</span><span class='line'>/usr/include/snappy-c.h
</span><span class='line'>/usr/include/snappy-sinksource.h
</span><span class='line'>/usr/include/snappy-stubs-public.h
</span><span class='line'>/usr/include/snappy.h
</span><span class='line'>/usr/lib64/libsnappy.so
</span><span class='line'>/usr/share/doc/snappy-devel-1.0.5
</span><span class='line'>/usr/share/doc/snappy-devel-1.0.5/format_description.txt
</span><span class='line'>/usr/lib64/libsnappy.so.1
</span><span class='line'>/usr/lib64/libsnappy.so.1.1.3
</span><span class='line'>/usr/share/doc/snappy-1.0.5
</span><span class='line'>/usr/share/doc/snappy-1.0.5/AUTHORS
</span><span class='line'>/usr/share/doc/snappy-1.0.5/COPYING
</span><span class='line'>/usr/share/doc/snappy-1.0.5/ChangeLog
</span><span class='line'>/usr/share/doc/snappy-1.0.5/NEWS
</span><span class='line'>/usr/share/doc/snappy-1.0.5/README
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export JAVA_HOME=/opt/jdk1.7.0_17
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export MAVEN_HOME=/opt/apache-maven-3.3.9
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]#  
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# yum install which gcc gcc-c++ zlib-devel make -y
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd protobuf-2.5.0
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# ./configure 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# make && make install
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# which protoc
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# yum install cmake openssl openssl-devel -y
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-2.6.3-src/
</span><span class='line'># bundle.snappy和snappy.lib一起使用，可以把系统的snappy.so文件拷贝到lib/native下面（方便拷贝）
</span><span class='line'># &lt;http://grepcode.com/file/repo1.maven.org/maven2/org.apache.hadoop/hadoop-project-dist/2.6.0/META-INF/maven/org.apache.hadoop/hadoop-project-dist/pom.xml&gt;
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# mvn clean package -Dmaven.javadoc.skip=true -DskipTests -Drequire.snappy=true -Dbundle.snappy=true -Dsnappy.lib=/usr/lib64 -Pdist,native
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# ll hadoop-dist/target/hadoop-2.6.3/lib/native/
</span><span class='line'>total 3808
</span><span class='line'>-rw-r--r-- 1 root root 1036552 Apr 12 09:35 libhadoop.a
</span><span class='line'>-rw-r--r-- 1 root root 1212600 Apr 12 09:36 libhadooppipes.a
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libhadoop.so -&gt; libhadoop.so.1.0.0
</span><span class='line'>-rwxr-xr-x 1 root root  613267 Apr 12 09:35 libhadoop.so.1.0.0
</span><span class='line'>-rw-r--r-- 1 root root  401836 Apr 12 09:36 libhadooputils.a
</span><span class='line'>-rw-r--r-- 1 root root  364026 Apr 12 09:35 libhdfs.a
</span><span class='line'>lrwxrwxrwx 1 root root      16 Apr 12 09:35 libhdfs.so -&gt; libhdfs.so.0.0.0
</span><span class='line'>-rwxr-xr-x 1 root root  229672 Apr 12 09:35 libhdfs.so.0.0.0
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libsnappy.so -&gt; libsnappy.so.1.1.3
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libsnappy.so.1 -&gt; libsnappy.so.1.1.3
</span><span class='line'>-rwxr-xr-x 1 root root   21568 Apr 12 09:35 libsnappy.so.1.1.3
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-dist/target/hadoop-2.6.3/
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3]# bin/hadoop checknative -a
</span><span class='line'>16/04/12 09:38:29 WARN bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version
</span><span class='line'>16/04/12 09:38:29 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
</span><span class='line'>Native library checking:
</span><span class='line'>hadoop:  true /data/bigdata/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3/lib/native/libhadoop.so.1.0.0
</span><span class='line'>zlib:    true /lib64/libz.so.1
</span><span class='line'>snappy:  true /data/bigdata/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3/lib/native/libsnappy.so.1
</span><span class='line'>lz4:     true revision:99
</span><span class='line'>bzip2:   false 
</span><span class='line'>openssl: false org.apache.hadoop.crypto.OpensslCipher.initIDs()V
</span><span class='line'>16/04/12 09:38:29 INFO util.ExitUtil: Exiting with status 1</span></code></pre></td></tr></table></div></figure>


<p>把native下面的打tar包，然后替换生成的。一切都是正常的。接下来坑爹的是spark-snappy，具体的说应该是hive-assmably坑！！</p>

<h2>hive-on-spark snappy</h2>

<p>spark官网也没讲使用snappy需要做什么额外的配置（默认spark.io.compression.codec默认为snappy）。部署后设置 <code>hive.execution.engine=spark</code> 执行spark查询，立马就报错了 <strong> Caused by: java.lang.UnsatisfiedLinkError: /tmp/snappy-1.0.5-libsn
appyjava.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9&#8217; not found (required by /tmp/snappy-1.0.5-libsnappyjava.so)</strong> 从错误堆栈看与hadoop-native-snappy没关系，而是一个snappy-java的包。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX
</span><span class='line'>GLIBCXX_3.4
</span><span class='line'>GLIBCXX_3.4.1
</span><span class='line'>GLIBCXX_3.4.2
</span><span class='line'>GLIBCXX_3.4.3
</span><span class='line'>GLIBCXX_3.4.4
</span><span class='line'>GLIBCXX_3.4.5
</span><span class='line'>GLIBCXX_3.4.6
</span><span class='line'>GLIBCXX_3.4.7
</span><span class='line'>GLIBCXX_3.4.8
</span><span class='line'>GLIBCXX_FORCE_NEW</span></code></pre></td></tr></table></div></figure>


<p>确实缺少GLIBCXX_3.4.9，最新版本的centos5.11也是一样输出的。</p>

<p>spark的配置为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.3.1-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'>spark.master  yarn-client
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.minExecutors    2 
</span><span class='line'>spark.dynamicAllocation.maxExecutors    18
</span><span class='line'>
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>spark.master=yarn-client
</span><span class='line'>spark.driver.memory=5g
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address file1:18080
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span><span class='line'>spark.kryoserializer.buffer.max    512m</span></code></pre></td></tr></table></div></figure>


<p>报错的具体信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- 16/04/12 20:20:08 INFO storage.BlockManagerMaster: Registered BlockManager
</span><span class='line'>- java.lang.reflect.InvocationTargetException
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>-        at java.lang.reflect.Method.invoke(Method.java:606)
</span><span class='line'>-        at org.xerial.snappy.SnappyLoader.loadNativeLibrary(SnappyLoader.java:322)
</span><span class='line'>-        at org.xerial.snappy.SnappyLoader.load(SnappyLoader.java:229)
</span><span class='line'>-        at org.xerial.snappy.Snappy.&lt;clinit&gt;(Snappy.java:48)
</span><span class='line'>-        at org.apache.spark.io.SnappyCompressionCodec.&lt;init&gt;(CompressionCodec.scala:150)
</span><span class='line'>-        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
</span><span class='line'>-        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
</span><span class='line'>-        at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:68)
</span><span class='line'>-        at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:60)
</span><span class='line'>-        at org.apache.spark.scheduler.EventLoggingListener.&lt;init&gt;(EventLoggingListener.scala:67)
</span><span class='line'>-        at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:400)
</span><span class='line'>-        at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:61)
</span><span class='line'>-        at org.apache.hive.spark.client.RemoteDriver.&lt;init&gt;(RemoteDriver.java:169)
</span><span class='line'>-        at org.apache.hive.spark.client.RemoteDriver.main(RemoteDriver.java:556)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>-        at java.lang.reflect.Method.invoke(Method.java:606)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
</span><span class='line'>- Caused by: java.lang.UnsatisfiedLinkError: /tmp/snappy-1.0.5-libsnappyjava.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9' not found (required by /tmp/snappy-1.0.5-libs
</span><span class='line'>-        at java.lang.ClassLoader$NativeLibrary.load(Native Method)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary1(ClassLoader.java:1965)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1890)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1851)
</span><span class='line'>-        at java.lang.Runtime.load0(Runtime.java:795)
</span><span class='line'>-        at java.lang.System.load(System.java:1062)
</span><span class='line'>-        at org.xerial.snappy.SnappyNativeLoader.load(SnappyNativeLoader.java:39)
</span><span class='line'>-        ... 28 more</span></code></pre></td></tr></table></div></figure>


<p>spark用到了snappy-java来处理snappy的解压缩。用jinfo查看SparkSubmit进程的classpath，用这个classpath跑helloworld确实是报错的，但是单独用hadoop-common下面的 snappy-java-1.0.4.1.jar 是没问题的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 snappy-java-test]$ cat Hello.java 
</span><span class='line'>import org.xerial.snappy.Snappy;
</span><span class='line'>
</span><span class='line'>public class Hello { 
</span><span class='line'>public static void main(String[] args) throws Exception {
</span><span class='line'>String input = "Hello snappy-java!";
</span><span class='line'>
</span><span class='line'>byte[] compressed = Snappy.compress(input.getBytes("utf-8"));
</span><span class='line'>byte[] uncompressed = Snappy.uncompress(compressed);
</span><span class='line'>
</span><span class='line'>String result = new String(uncompressed, "utf-8");
</span><span class='line'>System.out.println(result);
</span><span class='line'>}
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[hadoop@file1 snappy-java-test]$ java -cp .:/home/hadoop/tools/hadoop-2.6.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar Hello
</span><span class='line'>Hello snappy-java!</span></code></pre></td></tr></table></div></figure>


<p>而而而，classpath中就只有hadoop-common和hadoop-mapreduce下面有snappy-java包，并且都是1.0.4.1，那TMD的使用SparkSubmit-classpath加载Snappy是哪个jar里面的呢？</p>

<p>调整后的helloworld为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 snappy-java-test]$ cat Hello.java 
</span><span class='line'>import org.xerial.snappy.Snappy;
</span><span class='line'>
</span><span class='line'>public class Hello { 
</span><span class='line'>public static void main(String[] args) throws Exception {
</span><span class='line'>String input = "Hello snappy-java!";
</span><span class='line'>
</span><span class='line'>System.out.println(Snappy.class.getProtectionDomain());
</span><span class='line'>byte[] compressed = Snappy.compress(input.getBytes("utf-8"));
</span><span class='line'>byte[] uncompressed = Snappy.uncompress(compressed);
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>String result = new String(uncompressed, "utf-8");
</span><span class='line'>System.out.println(result);
</span><span class='line'>}
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>添加getProtectionDomain查看加载类的jar。再编译跑一次，这次终于找到真凶了！！hive-assembly，assembly包还放在lib下面就tmd的是一个坑货！！hive-exec的guava已经坑了很多人了，这次换hive-jdbc了！！(我这里的环境是centos5，centos6是没有这个问题的！！)</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-centos5-snappy-hive-jdbc.png" alt="" /></p>

<p>如果指定使用hadoop编译依赖的snappy.so.1.1.3动态链接库会出现版本不兼容的问题。还是干掉hive-jdbc-standalone吧。。。囧</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 查看源码SnappyLoader#loadSnappySystemProperties，可以通过配置指定使用系统动态链接库
</span><span class='line'>[hadoop@file1 snappy-java-test]$ cat org-xerial-snappy.properties 
</span><span class='line'>org.xerial.snappy.use.systemlib=true
</span><span class='line'>[hadoop@file1 snappy-java-test]$ ln -s /home/hadoop/tools/hadoop-2.6.3/lib/native/libsnappy.so libsnappyjava.so
</span><span class='line'>[hadoop@file1 snappy-java-test]$ ll
</span><span class='line'>总计 1240
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop     854 04-08 10:11 Hello.class
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop     408 04-08 10:11 Hello.java
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop      55 04-12 19:37 libsnappyjava.so -&gt; /home/hadoop/tools/hadoop-2.6.3/lib/native/libsnappy.so
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop      37 04-12 19:15 org-xerial-snappy.properties
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 1251514 2014-04-29 snappy-java-1.0.5.jar
</span><span class='line'>[hadoop@file1 snappy-java-test]$ java -cp .:snappy-java-1.0.5.jar -Djava.library.path=. Hello
</span><span class='line'>ProtectionDomain  (file:/home/hadoop/snappy-java-test/snappy-java-1.0.5.jar &lt;no signer certificates&gt;)
</span><span class='line'> sun.misc.Launcher$AppClassLoader@333cb1eb
</span><span class='line'> &lt;no principals&gt;
</span><span class='line'> java.security.Permissions@7377711 (
</span><span class='line'> ("java.io.FilePermission" "/home/hadoop/snappy-java-test/snappy-java-1.0.5.jar" "read")
</span><span class='line'> ("java.lang.RuntimePermission" "exitVM")
</span><span class='line'>)
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Exception in thread "main" java.lang.UnsatisfiedLinkError: org.xerial.snappy.SnappyNative.maxCompressedLength(I)I
</span><span class='line'>        at org.xerial.snappy.SnappyNative.maxCompressedLength(Native Method)
</span><span class='line'>        at org.xerial.snappy.Snappy.maxCompressedLength(Snappy.java:320)
</span><span class='line'>        at org.xerial.snappy.Snappy.rawCompress(Snappy.java:333)
</span><span class='line'>        at org.xerial.snappy.Snappy.compress(Snappy.java:92)
</span><span class='line'>        at Hello.main(Hello.java:8)
</span><span class='line'>      </span></code></pre></td></tr></table></div></figure>


<p>删掉jdbc-standalone后，hive-on-spark就ok了。如果你无法下手删除 hive-jdbc-1.2.1-standalone.jar ，那就把 <code>spark.io.compression.codec</code> 改成 <code>lz4</code> 等压缩也是可以的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/home/hadoop/tools/apache-hive-1.2.1-bin/conf/hive-log4j.properties
</span><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_info where edate=20160411;
</span><span class='line'>Query ID = hadoop_20160412205338_2c95c5fd-af50-42ba-8681-e154e4b74cb1
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 69afc030-fa1f-4fdf-81ef-12bdca411a4f
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-04-12 20:54:11,367 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:14,421 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:17,457 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:19,486 Stage-0_0: 2(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:20,497 Stage-0_0: 3(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:21,509 Stage-0_0: 5(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:22,520 Stage-0_0: 6(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:23,532 Stage-0_0: 7(+2)/234    Stage-1_0: 0/1</span></code></pre></td></tr></table></div></figure>


<h2>小结</h2>

<p>第一，hive的assembly的包太tmd的坑了。第二，以后找java具体加载那个类，可以通过 class.getProtectionDomain 来获取了。第三，又多尝试一个环境部署hadoop。呵呵</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[puppet4.4.1入门安装]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/puppet-install/"/>
    <updated>2016-04-08T19:49:32+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/puppet-install</id>
    <content type="html"><![CDATA[<p>网上资料比较多比较老，基本操作可以借鉴。安装Puppet最简单的方式就是用yum来安装(操作系统centos6），由于天朝的特殊环境最好建立本地仓库。本文记录我自己安装过程的过程，先介绍本地仓库创建，然后介绍Puppet环境的搭建。</p>

<p>操作系统：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.5 (Final)</span></code></pre></td></tr></table></div></figure>


<h2>更新</h2>

<p>2016-4-28 15:42:32 - rpm强制安装puppetserver。依赖jdk8有点麻烦，自己安装jdk7就好了。
2016-5-3 09:39:40  - 更新puppetserver性能的部分，运行在Jetty之上不需要再折腾passenger了。见文章最后。</p>

<h2>本地仓库搭建</h2>

<p>Puppet4所有依赖都进行统一打包，其实通过rpm就能直接安装。为了体现下高大山、并且Puppet内部的项目之间是有依赖的。这里先使用createrepo创建本地库。</p>

<p>createrepo其实就是用来创建目录下rpm文件的索引数据(repodata)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# yum install createrepo
</span><span class='line'>
</span><span class='line'># 下载系统对应的puppet-pc1的包: https://yum.puppetlabs.com/el/6/PC1/x86_64/ 全部最新版本
</span><span class='line'>[root@hadoop-master2 repo]# ls -1
</span><span class='line'>puppet-agent-1.4.1-1.el6.x86_64.rpm
</span><span class='line'>puppet-dashboard-1.2.23-0.1rc3.el6.noarch.rpm
</span><span class='line'>puppetdb-4.0.0-1.el6.noarch.rpm
</span><span class='line'>puppetdb-termini-3.2.4-1.el6.noarch.rpm
</span><span class='line'>puppetdb-terminus-3-1.el6.noarch.rpm
</span><span class='line'>puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# createrepo .
</span><span class='line'>Spawning worker 0 with 6 pkgs
</span><span class='line'>Workers Finished
</span><span class='line'>Gathering worker results
</span><span class='line'>
</span><span class='line'>Saving Primary metadata
</span><span class='line'>Saving file lists metadata
</span><span class='line'>Saving other metadata
</span><span class='line'>Generating sqlite DBs
</span><span class='line'>Sqlite DBs complete
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=file:///opt/puppetlabs/repo
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span></code></pre></td></tr></table></div></figure>


<p>查看local下的rpm包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 repo]# yum clean all
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Cleaning repos: base epel extras pgdg94 puppet-local updates
</span><span class='line'>Cleaning up Everything
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum list all | grep "puppet-local"
</span><span class='line'>puppet-agent.x86_64                         1.4.1-1.el6                  @puppet-local
</span><span class='line'>puppet-dashboard.noarch                     1.2.23-0.1rc3.el6            @puppet-local
</span><span class='line'>puppetdb.noarch                             4.0.0-1.el6                  @puppet-local
</span><span class='line'>puppetdb-termini.noarch                     3.2.4-1.el6                  @puppet-local
</span><span class='line'>puppetserver.noarch                         2.3.1-1.el6                  @puppet-local
</span><span class='line'>puppetdb-terminus.noarch                    3-1.el6                      puppet-local
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum search puppet</span></code></pre></td></tr></table></div></figure>


<p>网上资料还有安装 <code>yum-priorities</code> 来设置repo优先级的。我这里没有包冲突问题所以并没有安装这个。</p>

<h2>单机安装</h2>

<p>安装前翻一翻官网的文档： <a href="https://docs.puppet.com/puppetserver/latest/install_from_packages.html">https://docs.puppet.com/puppetserver/latest/install_from_packages.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先看看 puppet-agent 和 puppetserver 的依赖
</span><span class='line'>[root@hadoop-master2 repo]# yum deplist puppet-agent
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.aliyun.com
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'> * extras: mirrors.aliyun.com
</span><span class='line'> * updates: mirrors.aliyun.com
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: tar
</span><span class='line'>   provider: tar.x86_64 2:1.23-13.el6
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: readline
</span><span class='line'>   provider: readline.i686 6.0-4.el6
</span><span class='line'>   provider: readline.x86_64 6.0-4.el6
</span><span class='line'>  dependency: util-linux
</span><span class='line'>   provider: util-linux-ng.i686 2.17.2-12.18.el6
</span><span class='line'>   provider: util-linux-ng.x86_64 2.17.2-12.18.el6
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum deplist puppetserver
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.aliyun.com
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'> * extras: mirrors.aliyun.com
</span><span class='line'> * updates: mirrors.aliyun.com
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppetserver.noarch 2.3.1-1.el6
</span><span class='line'>  dependency: /bin/bash
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: java-1.8.0-openjdk-headless
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.45-35.b13.el6
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-0.b16.el6_6
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-1.b16.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-3.b16.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.65-0.b17.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.71-1.b15.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7
</span><span class='line'>  dependency: puppet-agent &gt;= 1.4.0
</span><span class='line'>   provider: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: net-tools
</span><span class='line'>   provider: net-tools.x86_64 1.60-110.el6_2
</span><span class='line'>  dependency: /usr/bin/env
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6_7.3
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>
</span><span class='line'># 安装
</span><span class='line'>[root@hadoop-master2 repo]# yum install puppetserver
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# netstat -anp | grep 4526
</span><span class='line'>tcp        0      0 :::8140                     :::*                        LISTEN      4526/java           
</span><span class='line'>
</span><span class='line'># 安装好后，查看各版本软件版本信息
</span><span class='line'>[root@hadoop-master2 repo]# puppet -V
</span><span class='line'>4.4.1
</span><span class='line'>[root@hadoop-master2 repo]# facter -v
</span><span class='line'>3.1.5 (commit b5c2cf9b2ac290cb17fcadea19b467a39e17c1fd)
</span><span class='line'>[root@hadoop-master2 repo]# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1</span></code></pre></td></tr></table></div></figure>


<p>puppetserver依赖puppet-agent，而puppet-agent是一个all-in-one的assembly的包。所以服务端安装puppetserver就行了。客户端仅安装puppet-agent即可。</p>

<p>Puppet4的目录进行比较大的调整，程序路径为 <code>/opt/puppetlabs</code> ，配置路径为 <code>/etc/puppetlabs</code> 。如果你看的是puppet3资料，对照查看官网 <a href="https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html">Where Did Everything Go in Puppet 4.x?</a> 了解各程序的目录位置。</p>

<p>如果你单独安装了jdk(依赖的是jdk8也是挺烦的)，也可以使用rpm强制安装puppetserver，然后指定java程序的路径：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# yum deplist puppetserver
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * centos-local: 172.17.42.1:8888
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppetserver.noarch 2.3.1-1.el6
</span><span class='line'>  dependency: /bin/bash
</span><span class='line'>   provider: bash.x86_64 4.1.2-29.el6
</span><span class='line'>  dependency: java-1.8.0-openjdk-headless
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1.8.0.20-3.b26.el6
</span><span class='line'>  dependency: puppet-agent &gt;= 1.4.0
</span><span class='line'>   provider: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: net-tools
</span><span class='line'>   provider: net-tools.x86_64 1.60-110.el6_2
</span><span class='line'>  dependency: /usr/bin/env
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-29.el6
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-2.el6_4.1
</span><span class='line'>
</span><span class='line'>bash-4.1# rpm -ivh http://172.17.42.1:8888/centos6/puppet/puppetserver-2.3.1-1.el6.noarch.rpm --nodeps --force
</span><span class='line'>Retrieving http://172.17.42.1:8888/centos6/puppet/puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>warning: /var/tmp/rpm-tmp.7CAtn8: Header V4 RSA/SHA1 Signature, key ID 4bd6ec30: NOKEY
</span><span class='line'>Preparing...                ########################################### [100%]
</span><span class='line'>usermod: no changes
</span><span class='line'>   1:puppetserver           ########################################### [100%]
</span><span class='line'>usermod: no changes
</span><span class='line'>bash-4.1# chkconfig --list | grep puppetserver
</span><span class='line'>puppetserver    0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span><span class='line'>
</span><span class='line'>bash-4.1# cat /etc/sysconfig/puppetserver 
</span><span class='line'>...
</span><span class='line'>JAVA_BIN="/opt/jdk1.7.0_60/bin/java"
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>bash-4.1# netstat -a
</span><span class='line'>Active Internet connections (servers and established)
</span><span class='line'>Proto Recv-Q Send-Q Local Address               Foreign Address             State      
</span><span class='line'>tcp        0      0 *:8140                      *:*                         LISTEN      
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h2>单机版HelloWorld</h2>

<p>单机模式不需要认证，当做学习调试环境挺好的：方便简单。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 manifests]# vi helloworld.pp
</span><span class='line'>notify { 'greeting':
</span><span class='line'>  message =&gt; 'Hello, world!'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 manifests]# puppet apply helloworld.pp 
</span><span class='line'>Notice: Compiled catalog for hadoop-master2.localdomain in environment production in 0.03 seconds
</span><span class='line'>Notice: Hello, world!
</span><span class='line'>Notice: /Stage[main]/Main/Notify[greeting]/message: defined 'message' as 'Hello, world!'
</span><span class='line'>Notice: Applied catalog in 0.04 seconds
</span><span class='line'>
</span><span class='line'># 可以用resource根据当前环境生成配置
</span><span class='line'>[root@hadoop-master2 manifests]# puppet resource user hadoop
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  gid              =&gt; '500',
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; 'XXXXXX',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  uid              =&gt; '500',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># 状态变更
</span><span class='line'>[root@hadoop-master2 puppetlabs]# bin/puppet resource service puppet ensure=running enable=false
</span><span class='line'>Notice: /Service[puppet]/enable: enable changed 'true' to 'false'
</span><span class='line'>service { 'puppet':
</span><span class='line'>  ensure =&gt; 'running',
</span><span class='line'>  enable =&gt; 'false',
</span><span class='line'>}
</span><span class='line'>[root@hadoop-master2 puppetlabs]# chkconfig --list | grep puppet
</span><span class='line'>puppet          0:off   1:off   2:off   3:off   4:off   5:off   6:off
</span><span class='line'>puppetserver    0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span></code></pre></td></tr></table></div></figure>


<h2>CS模式配置</h2>

<p>这里完全模拟生产环境情况(内网)，首先搭建两个本地仓库：centos，puppet。puppet依赖RPM根据具体情况下载即可，我这里用的是centos6.5。</p>

<p>搭建私有仓库：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>增加 java-1.8.0-openjdk-headless 和 tzdata-java-2014g(iso带的2013g不适配)
</span><span class='line'>[root@hadoop-master2 repo]# ll
</span><span class='line'>total 142344
</span><span class='line'>-rw-r--r-- 1 root root 33135156 Apr  9 21:47 java-1.8.0-openjdk-headless-1.8.0.51-3.b16.el6_7.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root 26740012 Apr  9 11:29 puppet-agent-1.4.1-1.el6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  4509000 Apr  9 11:29 puppet-dashboard-1.2.23-0.1rc3.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 21866876 Apr  9 11:29 puppetdb-4.0.0-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root    25516 Apr  9 11:29 puppetdb-termini-3.2.4-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root     3676 Apr  9 11:29 puppetdb-terminus-3-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 33412844 Apr  9 11:29 puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>drwxr-xr-x 2 root root     4096 Apr  9 22:56 repodata
</span><span class='line'>-rw-r--r-- 1 root root   181196 Sep 17  2014 tzdata-java-2014g-1.el6.noarch.rpm
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 ~]# mount -t iso9660 -o loop CentOS-6.5-x86_64-bin-DVD1.iso /mnt/cdrom
</span><span class='line'># httpd 我的系统已经安装了
</span><span class='line'>[root@hadoop-master2 ~]# cd /var/www/html/
</span><span class='line'>[root@hadoop-master2 html]# ll
</span><span class='line'>total 820
</span><span class='line'>lrwxrwxrwx  1 root root     10 Apr  9 21:54 centos6_5 -&gt; /mnt/cdrom
</span><span class='line'>lrwxrwxrwx  1 root root     20 Mar 30 17:11 puppet -&gt; /opt/puppetlabs/repo</span></code></pre></td></tr></table></div></figure>


<p>启动docker实例，参考 <a href="http://www.winseliu.com/blog/2014/09/30/docker-ssh-on-centos/">docker的安装</a>。由于centos和puppet中有包冲突，需要安装 <code>yum-priorities</code> 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 repo]# docker run -i -t centos:centos6 /bin/bash
</span><span class='line'>bash-4.1# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.5 (Final)
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install yum-plugin-priorities-1.1.30-30.el6.noarch.rpm 
</span><span class='line'>
</span><span class='line'># 把默认的repo清理掉，添加puppet和centos
</span><span class='line'>bash-4.1# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=http://172.17.42.1/puppet
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>priority=1
</span><span class='line'>bash-4.1# cat /etc/yum.repos.d/centos-local.repo 
</span><span class='line'>[centos-local]
</span><span class='line'>name=Centos Local
</span><span class='line'>baseurl=http://172.17.42.1/centos6_5
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>priority=2
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install puppetserver
</span><span class='line'>
</span><span class='line'># 加载环境变量
</span><span class='line'>bash-4.1# source /etc/profile.d/puppet-agent.sh
</span><span class='line'># 查看puppet各程序版本
</span><span class='line'>bash-4.1# puppet -V
</span><span class='line'>4.4.1
</span><span class='line'>bash-4.1# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1
</span><span class='line'>bash-4.1# facter -v
</span><span class='line'>3.1.5 (commit b5c2cf9b2ac290cb17fcadea19b467a39e17c1fd)</span></code></pre></td></tr></table></div></figure>


<p>Agent安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=http://172.17.42.1/puppet
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>[centos-local]
</span><span class='line'>name=Centos Local
</span><span class='line'>baseurl=http://172.17.42.1/centos6_5
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install puppet-agent -y</span></code></pre></td></tr></table></div></figure>


<p>配置：</p>

<ul>
<li>添加hosts</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# cat /etc/hosts
</span><span class='line'>172.17.0.4 puppet
</span><span class='line'>172.17.0.5 agent1
</span><span class='line'>172.17.0.6 agent2</span></code></pre></td></tr></table></div></figure>


<ul>
<li>master自测</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 3e4b2ba27563.localdomain
</span><span class='line'>Info: Applying configuration version '1460222292'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds</span></code></pre></td></tr></table></div></figure>


<ul>
<li>agent连接服务器</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Creating a new SSL key for 5a56be361905.localdomain
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for 5a56be361905.localdomain
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 58:1A:2E:28:D3:D7:C5:7B:E3:1A:C2:0F:70:D0:46:C0:34:39:7F:EC:98:65:B1:09:96:D3:4B:A7:4B:32:A6:C6
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'># master查看/认证
</span><span class='line'>bash-4.1# puppet cert list
</span><span class='line'>  "5a56be361905.localdomain" (SHA256) 58:1A:2E:28:D3:D7:C5:7B:E3:1A:C2:0F:70:D0:46:C0:34:39:7F:EC:98:65:B1:09:96:D3:4B:A7:4B:32:A6:C6
</span><span class='line'>  "6516b8d0538b.localdomain" (SHA256) F7:49:CC:93:EA:5D:D9:A2:90:33:01:A9:74:86:97:0C:20:0C:EB:24:3A:13:85:64:5C:32:A8:D7:36:91:3C:77
</span><span class='line'>bash-4.1# puppet cert sign --all 
</span><span class='line'>Notice: Signed certificate request for 6516b8d0538b.localdomain
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest 6516b8d0538b.localdomain at '/etc/puppetlabs/puppet/ssl/ca/requests/6516b8d0538b.localdomain.pem'
</span><span class='line'>Notice: Signed certificate request for 5a56be361905.localdomain
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest 5a56be361905.localdomain at '/etc/puppetlabs/puppet/ssl/ca/requests/5a56be361905.localdomain.pem'
</span><span class='line'>
</span><span class='line'># agent再连
</span><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Caching certificate for 5a56be361905.localdomain
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for 5a56be361905.localdomain
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 5a56be361905.localdomain
</span><span class='line'>Info: Applying configuration version '1460222614'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.02 seconds</span></code></pre></td></tr></table></div></figure>


<p>相比puppet那么多配置项，安装还是相对简单的。安装写到这些也差不多了，接下来要研究下监控和puppet的配置。</p>

<p>安装过程中也遇到一些问题，主要都是DNS导致。一开始 <strong>直接用hosts</strong> 来配置是最简便的，把server的ip指定为puppet域名。</p>

<p>再来个Hello：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master
</span><span class='line'>bash-4.1# cd /etc/puppetlabs/code/environments/production/
</span><span class='line'>bash-4.1# ls
</span><span class='line'>environment.conf  hieradata  manifests  modules
</span><span class='line'>bash-4.1# cd manifests/
</span><span class='line'>bash-4.1# cat helloworld.pp 
</span><span class='line'>notify { 'Hello World' : 
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># agent
</span><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 5a56be361905.localdomain
</span><span class='line'>Info: Applying configuration version '1460223248'
</span><span class='line'>Notice: Hello World
</span><span class='line'>Notice: /Stage[main]/Main/Notify[Hello World]/message: defined 'message' as 'Hello World'
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>bash-4.1# </span></code></pre></td></tr></table></div></figure>


<h2>最后说说PuppetServer性能</h2>

<ul>
<li><a href="https://docs.puppet.com/puppetserver/latest/">https://docs.puppet.com/puppetserver/latest/</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/puppetserver_vs_passenger.html">puppetserver_vs_passenger</a></li>
<li>master与ca分离 <a href="https://docs.puppet.com/puppetserver/latest/external_ca_configuration.html">https://docs.puppet.com/puppetserver/latest/external_ca_configuration.html</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/ssl_server_certificate_change_and_virtual_ips.html">https://docs.puppet.com/puppetserver/latest/ssl_server_certificate_change_and_virtual_ips.html</a></li>
</ul>


<p>晚上很多资料都是旧的，一般都是 puppetmaster + apache/nginx + passenger 。新版本使用puppetserver后，服务运行在JVM之上（ Puppet Server is hosted by a Jetty web server ），性能比原来ruby的方式更好（<a href="https://docs.puppet.com/puppetserver/latest/puppetserver_vs_passenger.html">反正官网是这么说的</a>）。所以没必要折腾其他ruby的东西了。</p>

<p><strong>题外话</strong>：搭上JVM（java）的车，对于大家都好^_^，现在大数据HADOOP都是基于java的，spark的scala也是运行在JVM之上。</p>

<blockquote><p>Because Puppet Server runs on the JVM, it takes a bit longer than the Apache/Passenger stack to start and get ready to accept HTTP connections.</p>

<p>Overall, Puppet Server performance is significantly better than a Puppet master running on the Apache/Passenger stack, but the initial startup is definitely slower.</p></blockquote>

<h2>参考</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/">https://docs.puppet.com/puppet/4.4/reference/</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/install_pre.html">https://docs.puppetlabs.com/puppet/latest/reference/install_pre.html</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/install_from_packages.html">https://docs.puppet.com/puppetserver/latest/install_from_packages.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html">https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html</a></li>
<li><a href="https://github.com/puppetlabs/puppet-specifications/blob/master/file_paths.md">https://github.com/puppetlabs/puppet-specifications/blob/master/file_paths.md</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/install_linux.html#installing-release-packages-on-yum-based-systems">https://docs.puppet.com/puppet/4.4/reference/install_linux.html#installing-release-packages-on-yum-based-systems</a></li>
<li><a href="https://yum.puppetlabs.com/el/6/PC1/x86_64/">https://yum.puppetlabs.com/el/6/PC1/x86_64/</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/type.html#file">https://docs.puppetlabs.com/puppet/latest/reference/type.html#file</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html">https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppetdb/4.0/install_from_packages.html">https://docs.puppetlabs.com/puppetdb/4.0/install_from_packages.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/4.4/reference/config_file_auth.html">https://docs.puppetlabs.com/puppet/4.4/reference/config_file_auth.html</a></li>
<li><p><a href="https://docs.puppetlabs.com/puppet/4.4/reference/config_file_autosign.html">https://docs.puppetlabs.com/puppet/4.4/reference/config_file_autosign.html</a></p></li>
<li><p>yum配置与各种使用 <a href="http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html">http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html</a></p></li>
<li><a href="http://kisspuppet.com/2014/01/26/puppet_create_repo/">http://kisspuppet.com/2014/01/26/puppet_create_repo/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DBCP参数在Hive JDBC上的实践]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/dbcp-parameters/"/>
    <updated>2016-04-08T19:48:01+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/dbcp-parameters</id>
    <content type="html"><![CDATA[<p>查询程序一开始只是简单使用dbcp来做连接的限制。在实践的过程中遇到各种问题，本文记录DBCP的参数优化提高程序健壮性的两次过程。</p>

<p>最开始的DBCP的配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>  destroy-method="close" 
</span><span class='line'>  p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>  p:url="${hiveUrl}" 
</span><span class='line'>  p:username="${hiveUsername}" 
</span><span class='line'>  p:password="${hivePassword}"
</span><span class='line'>  p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>  p:maxWait="${hiveMaxWait}" 
</span><span class='line'>  p:maxActive="${hiveMaxActive}" /&gt;
</span><span class='line'>
</span><span class='line'>&lt;bean id="hiveTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt;
</span><span class='line'>  &lt;property name="dataSource"&gt;
</span><span class='line'>      &lt;ref bean="hiveDataSource" /&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>&lt;/bean&gt;</span></code></pre></td></tr></table></div></figure>


<p>第一个遇到的问题，就是每次hiveserver2重启后，这个查询程序也得重启。在实际使用过程中非常的麻烦！！</p>

<h4>重启问题（连接断开后不能重连）</h4>

<p>首先给出学习的链接 <a href="http://elf8848.iteye.com/blog/1931778">http://elf8848.iteye.com/blog/1931778</a> 巨详细，同时问题的场景都一模一样啊！！</p>

<p>添加三个参数：</p>

<ul>
<li>testOnBorrow = &ldquo;true&rdquo;       借出连接时不要测试，否则很影响性能</li>
<li>testWhileIdle = &ldquo;true&rdquo;       指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除.</li>
<li>validationQuery = &ldquo;show databases&rdquo; 验证连接是否可用，使用的SQL语句</li>
</ul>


<p>解释：</p>

<p>testWhileIdle = &ldquo;true&rdquo; 表示每 {timeBetweenEvictionRunsMillis} (默认-1，不执行)秒，取出 {numTestsPerEvictionRun} (默认值3)条连接，使用 {validationQuery} 进行测试 ，测试不成功就销毁连接。销毁连接后，连接数量就少了，如果小于minIdle数量，就新建连接。</p>

<p>testOnBorrow = &ldquo;true&rdquo; 它的默认值是true，如果测试失败会drop掉然后再borrow。false表示每次从连接池中取出连接时，不需要执行 {validationQuery} 中的SQL进行测试。若配置为true,对性能有非常大的影响，性能会下降7-10倍。所在一定要配置为false.</p>

<p>调整参数后hiveserver2重启，查询再连会先报错然后再连。在每次取连接的时刻使用 <code>show databases</code> 测试，如果失败则从pool中删掉这个连接，重新再取，实现了重连的效果。这里不用 <code>select 1</code> hive里面执行很慢， 同时testWhileIdle并没有生效，因为没有配置timeBetweenEvictionRunsMillis参数。</p>

<p>调整后的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>destroy-method="close" 
</span><span class='line'>p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>p:url="${hiveUrl}" 
</span><span class='line'>p:username="${hiveUsername}" 
</span><span class='line'>p:password="${hivePassword}"
</span><span class='line'>p:testOnBorrow="${hiveTestOnBorrow}"
</span><span class='line'>p:testWhileIdle="${hiveTestWhileIdle}" 
</span><span class='line'>p:validationQuery="${hiveValidationQuery}"
</span><span class='line'>p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>p:maxWait="${hiveMaxWait}" 
</span><span class='line'>p:maxActive="${hiveMaxActive}" 
</span><span class='line'>/&gt;</span></code></pre></td></tr></table></div></figure>


<p>问题又来了，由于测试切换tez和spark才配置了上面的重连。但是切换到spark后，启动的spark会一直保持(连接创建的session不会主动关闭)，直到hiveserver2 session超时(默认6h检查一次，7h idle就关闭)。</p>

<p>注意：有个隐忧，hive-on-spark每个连接都创建一个SESSION，这就退化到MR操作了。不能完全利用SPARK的优势！！例如业务中，即查询count、又获取一页数据，这里就是两个单独的spark程序！！N个session就N个 <strong>hive on spark</strong> 啊！！</p>

<h4>第二个问题，服务端session强制关闭</h4>

<p>问题其实和参考中的: <strong>MySQL8小时问题，Mysql服务器默认连接的“wait_timeout”是8小时，也就是说一个connection空闲超过8个小时，Mysql将自动断开该 connection</strong> 一模一样的。在增加 <strong>minEvictableIdleTimeMillis</strong> 和 <strong>timeBetweenEvictionRunsMillis</strong> 设置检查和回收的时间。</p>

<ul>
<li>timeBetweenEvictionRunsMillis = &ldquo;1800000&rdquo;  每30分钟运行一次空闲连接回收器，没必要那么频繁。</li>
<li>minEvictableIdleTimeMillis = &ldquo;3600000&rdquo;  池中的连接空闲1个小时后被回收，如果1个半小时没有操作，这个session就会被客户端关闭。可以通过yarn-8088的scheduler页面查看。</li>
</ul>


<p>设置后的最终效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>destroy-method="close" 
</span><span class='line'>p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>p:url="${hiveUrl}" 
</span><span class='line'>p:username="${hiveUsername}" 
</span><span class='line'>p:password="${hivePassword}"
</span><span class='line'>p:testOnBorrow="${hiveTestOnBorrow}"
</span><span class='line'>p:validationQuery="${hiveValidationQuery}"
</span><span class='line'>p:maxWait="${hiveMaxWait}" 
</span><span class='line'>p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>p:maxActive="${hiveMaxActive}" 
</span><span class='line'>p:testWhileIdle="${hiveTestWhileIdle}" 
</span><span class='line'>p:timeBetweenEvictionRunsMillis="${hiveTimeBetweenEvictionRunsMillis}" 
</span><span class='line'>p:minEvictableIdleTimeMillis="${hiveMinEvictableIdleTimeMillis}" 
</span><span class='line'>p:removeAbandoned="true"
</span><span class='line'>p:logAbandoned="true"
</span><span class='line'>/&gt;</span></code></pre></td></tr></table></div></figure>


<p>很多程序都有很多参数，大部分能通过文档明白，但是一些参数不到实践真的很难真正体会它的含义。参考的文章两次改进我查看了，但是第一次看的时刻根本没去加其他参数，因为对我来说没用，解决当前问题用不到嘛。</p>

<p>hadoop的参数更多，core/hdfs/mapred/yarn需要多用才能发现参数的功能和妙用。<strong>纸上得来终觉浅，绝知此事要躬行</strong> 。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RPM打包]]></title>
    <link href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/"/>
    <updated>2016-04-04T16:07:21+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/04/rpm-build-your-package</id>
    <content type="html"><![CDATA[<h2>资料</h2>

<ul>
<li><a href="http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html">http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/index.html">用 RPM 打包软件-打包教程</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part3/index.html">用 RPM 打包软件-高级部分：安装前后控制</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-rpm/index.html">RPM 打包技术与典型 SPEC 文件分析-各变量含义</a></li>
<li><a href="http://hlee.iteye.com/blog/343499">http://hlee.iteye.com/blog/343499</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/indent-2.spec">案例</a></li>
<li><p><a href="https://github.com/apache/zookeeper/tree/release-3.4.8/src/packages">zookeeper打包案例</a></p></li>
<li><p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html">http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html</a></p></li>
</ul>


<h2>实践</h2>

<ul>
<li>系统配置准备</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 新建一个docker实例，来测试、学习
</span><span class='line'>[root@cu1 ~]# docker run -ti centos:centos6 /bin/bash
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.6 (Final)
</span><span class='line'>
</span><span class='line'># 安装编译环境所需的软件
</span><span class='line'>yum install which tree lrzsz tar gcc rpm-build
</span><span class='line'># wget编译的依赖
</span><span class='line'>yum install -y gnutls gnutls-devel</span></code></pre></td></tr></table></div></figure>


<ul>
<li>步骤</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bdc25400cc63 home]# mkdir mywget 
</span><span class='line'>[root@bdc25400cc63 home]# cd mywget/
</span><span class='line'>[root@bdc25400cc63 mywget]# mkdir BUILD RPMS SOURCES SPECS SRPMS
</span><span class='line'>[root@bdc25400cc63 mywget]# cd SOURCES/
</span><span class='line'>[root@bdc25400cc63 SOURCES]# mv /home/wget-1.17.tar.gz .
</span><span class='line'>[root@bdc25400cc63 SOURCES]# ls
</span><span class='line'>wget-1.17.tar.gz
</span><span class='line'>[root@bdc25400cc63 SOURCES]# cd ..
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# rpmbuild --showrc
</span><span class='line'>[test@bdc25400cc63 mywget]$ rpm --eval "%{_topdir}"
</span><span class='line'>
</span><span class='line'>[test@bdc25400cc63 mywget]$ grep -i _topdir /usr/lib/rpm/rpmrc /usr/lib/rpm/redhat/rpmrc /usr/lib/rpm/macros /usr/lib/rpm/redhat/macros  | less
</span><span class='line'>/usr/lib/rpm/macros:%_builddir          %{_topdir}/BUILD
</span><span class='line'>/usr/lib/rpm/macros:%_rpmdir            %{_topdir}/RPMS
</span><span class='line'>/usr/lib/rpm/macros:%_sourcedir         %{_topdir}/SOURCES
</span><span class='line'>/usr/lib/rpm/macros:%_specdir           %{_topdir}/SPECS
</span><span class='line'>/usr/lib/rpm/macros:%_srcrpmdir         %{_topdir}/SRPMS
</span><span class='line'>/usr/lib/rpm/macros:%_buildrootdir              %{_topdir}/BUILDROOT
</span><span class='line'>/usr/lib/rpm/macros:%_topdir            %{getenv:HOME}/rpmbuild
</span><span class='line'>
</span><span class='line'>[test@bdc25400cc63 mywget]$ cat ~/.rpmmacros 
</span><span class='line'>%_topdir /home/mywget/rpm
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# vi SPECS/wget.spec
</span><span class='line'>  # this is a sample spec file for wget
</span><span class='line'>  
</span><span class='line'>  %define _topdir /home/mywget
</span><span class='line'>  %define name    wget
</span><span class='line'>  %define release 2
</span><span class='line'>  %define version 1.17
</span><span class='line'>  # 定义 _buildrootdir 不起作用，不知道为啥??? 在 .rpmmacros 定义了 %_topdir，root转到 /home/mywget/rpm/BUILDROOT 了。
</span><span class='line'>  
</span><span class='line'>  %define _unpackaged_files_terminate_build 0
</span><span class='line'>  
</span><span class='line'>  Summary:   GNU wget
</span><span class='line'>  License:   GPL
</span><span class='line'>  Name:      %{name}
</span><span class='line'>  Version:   %{version}
</span><span class='line'>  Release:   %{release}
</span><span class='line'>  Source:    %{name}-%{version}.tar.gz
</span><span class='line'>  Prefix:    /usr/local/wget
</span><span class='line'>  Group:     Development/Tools
</span><span class='line'>  
</span><span class='line'>  %description
</span><span class='line'>  The GNU wget program downloads files from the Internet using the command-line.
</span><span class='line'>  
</span><span class='line'>  %prep
</span><span class='line'>  %setup -q
</span><span class='line'>  
</span><span class='line'>  %build
</span><span class='line'>  ./configure
</span><span class='line'>  make
</span><span class='line'>  
</span><span class='line'>  %install
</span><span class='line'>  make install prefix=$RPM_BUILD_ROOT/usr/local/wget # or use DESTDIR=$RPM_BUILD_ROOT
</span><span class='line'>  
</span><span class='line'>  %post
</span><span class='line'>  echo "hello world"
</span><span class='line'>  
</span><span class='line'>  %preun
</span><span class='line'>  echo "bye"
</span><span class='line'>  
</span><span class='line'>  %clean
</span><span class='line'>  rm -rf $RPM_BUILD_ROOT
</span><span class='line'>  
</span><span class='line'>  %files
</span><span class='line'>  %defattr(-, root, root)
</span><span class='line'>  /usr/local/wget/bin/wget
</span><span class='line'>  
</span><span class='line'>[root@bdc25400cc63 mywget]# rpmbuild -vv -bb --clean SPECS/wget.spec 
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# tree .
</span><span class='line'>.
</span><span class='line'>├── BUILD
</span><span class='line'>├── RPMS
</span><span class='line'>│   └── x86_64
</span><span class='line'>│       ├── wget-1.17-2.x86_64.rpm
</span><span class='line'>│       └── wget-debuginfo-1.17-2.x86_64.rpm
</span><span class='line'>├── SOURCES
</span><span class='line'>│   └── wget-1.17.tar.gz
</span><span class='line'>├── SPECS
</span><span class='line'>│   └── wget.spec
</span><span class='line'>└── SRPMS
</span><span class='line'>
</span><span class='line'>6 directories, 4 files
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# rpm -qpl RPMS/x86_64/wget-1.17-2.x86_64.rpm  
</span><span class='line'>/usr/local/wget/bin/wget
</span></code></pre></td></tr></table></div></figure>


<p>接下来就可以直接拿到这个包到其他机器上安装了，如果自己建立了本地库，使用createrepo更新下，就可以使用yum安装最新打的包了。</p>

<p>注： <code>%pre</code> , <code>%post</code> 和 <code>%preun</code> , <code>%postun</code> 可以在安装前后执行一些脚本。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parquet学习]]></title>
    <link href="http://winseliu.com/blog/2016/03/29/parquet-simple-view/"/>
    <updated>2016-03-29T19:13:53+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/29/parquet-simple-view</id>
    <content type="html"><![CDATA[<h2>经典文章</h2>

<ul>
<li><a href="http://parquet.apache.org/documentation/latest/">http://parquet.apache.org/documentation/latest/</a></li>
<li><a href="https://blog.twitter.com/2013/dremel-made-simple-with-parquet">https://blog.twitter.com/2013/dremel-made-simple-with-parquet</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></li>
</ul>


<h2>概念</h2>

<ul>
<li>Row Group

<ul>
<li>Column Chunk

<ul>
<li>Page

<ul>
<li>Definition Levels: To support nested records we need to store the level for which the field is null. This is what the definition level is for: from 0 at the root of the schema up to the maximum level for this column. When a field is defined then all its parents are defined too, but <strong>when it is null we need to record the level at which it started being null to be able to reconstruct the record</strong>.</li>
<li>Repetition Levels: To support repeated fields we need to store when new lists are starting in a column of values. This is what repetition level is for: it is the level at which we have to create a new list for the current value. <strong>In other words, the repetition level can be seen as a marker of when to start a new list and at which level</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>FileMetaData</li>
</ul>


<p>The definition and repetition levels are optional, based on the schema definition. If the column is not nested (i.e. the path to the column has length 1), we do not encode the repetition levels (it would always have the value 1). For data that is required, the definition levels are skipped (if encoded, it will always have the value of the max definition level).</p>

<p>For example, in the case where the column is non-nested and required, the data in the page is only the encoded values.</p>

<p><strong>An optimized read setup would be: 1GB row groups, 1GB HDFS block size, 1 HDFS block per HDFS file.</strong></p>

<h2>texfile转parquet</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ cd apache-hive-1.2.1-bin/
</span><span class='line'>[hadoop@hadoop-master2 apache-hive-1.2.1-bin]$ bin/hive
</span><span class='line'>hive&gt; CREATE TABLE `t_ods_access_log2_parquet`(   `houseid` string,    `sourceip` string,    `destinationip` string,    `sourceport` string,    `destinationport` string,    `domain` string,    `url` string,    `accesstime` string,    `logid` string,    `sourceipnum` bigint,    `timedetected` string,    `protocol` string,    `duration` string) ROW FORMAT DELIMITED    FIELDS TERMINATED BY '|'  STORED AS PARQUET LOCATION   '/user/hive/t_ods_access_log2_parquet'</span></code></pre></td></tr></table></div></figure>


<p>关键 <strong>STORED AS PARQUET</strong>。</p>

<p>关于压缩，可以通过mapreduce参数设置（ <code>mapreduce.output.fileoutputformat.compress</code> 和 <code>mapreduce.output.fileoutputformat.compress.codec</code> ），但是推荐使用 <code>parquet.compression</code> 属性来指定。</p>

<p>reader/writer都会从 <code>CodecConfig.getCodec()</code> 获取压缩编码。代码中会从parquet属性和mapreduce获取压缩参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>alter table t_ods_access_log2_parquet SET TBLPROPERTIES ('parquet.compression' = 'SNAPPY' );
</span><span class='line'>
</span><span class='line'>create table t_ods_access_log2_parquet_none like t_ods_access_log2_parquet TBLPROPERTIES ('parquet.compression' = 'UNCOMPRESSED' );
</span><span class='line'>create table t_ods_access_log2_parquet_gzip like t_ods_access_log2_parquet TBLPROPERTIES ('parquet.compression' = 'GZIP' );</span></code></pre></td></tr></table></div></figure>


<p>直接使用hive的insert into语句就可以把原来的textfile的文件转成parquet格式。同时也转成gzip和uncompress比较了一下：</p>

<table>
<thead>
<tr>
<th style="text-align:left;">文件格式     </th>
<th style="text-align:left;"> 压缩       </th>
<th style="text-align:left;"> 大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">textfile     </td>
<td style="text-align:left;"> snappy     </td>
<td style="text-align:left;"> 4.1G</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> snappy     </td>
<td style="text-align:left;"> 3.6G</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> uncompress </td>
<td style="text-align:left;"> 7.2G</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> gzip       </td>
<td style="text-align:left;"> 2.2G</td>
</tr>
</tbody>
</table>


<p>直接count整个数据表，使用parquet的输入1M不到数据，太环保了！！（文件都是几十M的，一个文件都在一台机器上）。</p>

<table>
<thead>
<tr>
<th style="text-align:left;">文件格式     </th>
<th style="text-align:left;"> 运行引擎       </th>
<th style="text-align:left;"> 大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">textfile     </td>
<td style="text-align:left;"> tez            </td>
<td style="text-align:left;"> HDFS_BYTES_READ    4,454,071,542</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> tez            </td>
<td style="text-align:left;"> HDFS_BYTES_READ    415,870</td>
</tr>
<tr>
<td style="text-align:left;">textfile     </td>
<td style="text-align:left;"> sparksql       </td>
<td style="text-align:left;"> Input  4.1 GB</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> sparksql       </td>
<td style="text-align:left;"> Input  384.9 KB</td>
</tr>
</tbody>
</table>


<p>用sparksql跑textfile尽让更快。果然内存大暴力也很牛啊！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; insert into t_ods_access_log2_back select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 ;
</span><span class='line'>Query ID = hadoop_20160329200414_96f1de35-48c5-4b38-977f-05de8554f388
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3955)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    152        152        0        0       1       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 01/01  [==========================&gt;&gt;] 100%  ELAPSED TIME: 341.56 s   
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Loading data to table default.t_ods_access_log2_back
</span><span class='line'>Table default.t_ods_access_log2_back stats: [numFiles=152, numRows=57688987, totalSize=4454071542, rawDataSize=11018516544]
</span><span class='line'>OK
</span><span class='line'>Time taken: 347.997 seconds
</span><span class='line'>hive&gt; insert into t_ods_access_log2_parquet select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 ;
</span><span class='line'>Query ID = hadoop_20160329212157_57b66595-5dfc-4fc9-9ad1-398e2b8ade6b
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>Tez session was closed. Reopening...
</span><span class='line'>Session re-established.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3992)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    152        152        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 01/01  [==========================&gt;&gt;] 100%  ELAPSED TIME: 237.28 s   
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Loading data to table default.t_ods_access_log2_parquet
</span><span class='line'>Table default.t_ods_access_log2_parquet stats: [numFiles=0, numRows=1305035789, totalSize=0, rawDataSize=16965465257]
</span><span class='line'>OK
</span><span class='line'>Time taken: 260.515 seconds
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>Query ID = hadoop_20160329212644_da8e7997-5bcc-41ab-8b63-f1a5919c5a2f
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3992)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    107        107        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 59.01 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 59.768 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>Query ID = hadoop_20160329212813_2fb8dafa-5c9a-40e8-a904-13e7cf865ec6
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3992)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    106        106        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 45.82 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 47.275 seconds, Fetched: 1 row(s)
</span><span class='line'>
</span><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; set spark.master=yarn-client;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>Query ID = hadoop_20160329214550_a58d1056-9c91-4bbe-be7d-122ec3efdd8d
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 3a03d432-83a4-4d5a-a878-c9e52aa94bed
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:46:26,523 Stage-0_0: 0(+114)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:27,535 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:30,563 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:33,582 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:36,606 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:39,624 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:41,637 Stage-0_0: 0(+118)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:42,644 Stage-0_0: 4(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:43,651 Stage-0_0: 110(+41)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:44,658 Stage-0_0: 124(+28)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:45,665 Stage-0_0: 128(+24)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:46,671 Stage-0_0: 138(+14)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:47,677 Stage-0_0: 142(+10)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:48,684 Stage-0_0: 144(+8)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:49,691 Stage-0_0: 147(+5)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:50,698 Stage-0_0: 148(+4)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:51,705 Stage-0_0: 149(+3)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:52,712 Stage-0_0: 150(+2)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:55,731 Stage-0_0: 151(+1)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:58,750 Stage-0_0: 151(+1)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:47:01,769 Stage-0_0: 151(+1)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:47:02,776 Stage-0_0: 152/152 Finished     Stage-1_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:05,793 Stage-0_0: 152/152 Finished     Stage-1_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 70.33 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 75.211 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>Query ID = hadoop_20160329214723_9663eaf7-7014-46b1-b2ca-811ba64fc55c
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = f2dbcd55-b23c-4eb3-9439-8f1c825fbac3
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[1] stages:
</span><span class='line'>2
</span><span class='line'>3
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[1])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:47:24,449 Stage-2_0: 0(+122)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:25,455 Stage-2_0: 96(+56)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:26,462 Stage-2_0: 123(+29)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:27,469 Stage-2_0: 128(+24)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:28,476 Stage-2_0: 132(+20)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:29,483 Stage-2_0: 137(+15)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:30,489 Stage-2_0: 145(+7)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:31,495 Stage-2_0: 146(+6)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:32,500 Stage-2_0: 150(+2)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:33,506 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:36,524 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:39,540 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:42,557 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:45,573 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:48,589 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:49,594 Stage-2_0: 152/152 Finished     Stage-3_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 26.15 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 26.392 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>Query ID = hadoop_20160329214758_25084e25-fdaf-4ef8-9c1a-2573515caca6
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 4360be5c-4188-49c4-a2a7-e5bb80164646
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[2] stages:
</span><span class='line'>5
</span><span class='line'>4
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[2])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:47:59,472 Stage-4_0: 0(+63)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:00,478 Stage-4_0: 1(+62)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:01,486 Stage-4_0: 49(+14)/65   Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:02,492 Stage-4_0: 51(+14)/65   Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:03,498 Stage-4_0: 57(+8)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:04,505 Stage-4_0: 62(+3)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:05,511 Stage-4_0: 63(+2)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:06,518 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:09,537 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:12,556 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:15,574 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:18,592 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:21,608 Stage-4_0: 65/65 Finished       Stage-5_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 23.14 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 23.376 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>Query ID = hadoop_20160329214826_173311b1-0083-4e11-9a29-fe13f48bb649
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = c452b02b-c68f-4c68-bc28-cb9748d7dcb2
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[3] stages:
</span><span class='line'>6
</span><span class='line'>7
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[3])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:48:27,332 Stage-6_0: 3(+60)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:28,338 Stage-6_0: 53(+10)/65   Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:29,343 Stage-6_0: 60(+3)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:30,349 Stage-6_0: 61(+4)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:31,354 Stage-6_0: 63(+2)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:32,360 Stage-6_0: 65/65 Finished       Stage-7_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:35,377 Stage-6_0: 65/65 Finished       Stage-7_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:38,393 Stage-6_0: 65/65 Finished       Stage-7_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:40,404 Stage-6_0: 65/65 Finished       Stage-7_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 14.08 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 14.306 seconds, Fetched: 1 row(s)
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 spark-1.6.0-bin-2.6.3]$ bin/spark-sql --master yarn-client --hiveconf hive.execution.engine=mr 
</span><span class='line'>         &gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>57688987
</span><span class='line'>16/03/29 22:19:51 INFO CliDriver: Time taken: 21.82 seconds, Fetched 1 row(s)
</span><span class='line'>
</span><span class='line'>         &gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>57688987
</span><span class='line'>16/03/29 22:20:44 INFO CliDriver: Time taken: 6.634 seconds, Fetched 1 row(s)
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Limit on Sparksql and Hive]]></title>
    <link href="http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive/"/>
    <updated>2016-03-29T15:27:03+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive</id>
    <content type="html"><![CDATA[<p>前一篇提到sparksql查询limit的时刻会提前返回，不需要查询所有的数据。hive是死算，sparksql递增数据量的一次次的试。sparksql可以这么做的，毕竟算好的数据在内存里面放着。</p>

<p>把日志记录下面：</p>

<h2>hive1.2.1-on-spark1.3.1</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 and sourceip='118.112.188.17' limit 10;
</span><span class='line'>Query ID = hadoop_20160329151420_25fe9497-e223-4f48-980e-e7fe859848ce
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 9036c8d7-62b6-4b9a-b6d3-2d8b5eed6bf9
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[2] stages:
</span><span class='line'>3
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[2])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 15:14:22,053 Stage-3_0: 0(+160)/942
</span><span class='line'>2016-03-29 15:14:23,059 Stage-3_0: 47(+160)/942
</span><span class='line'>2016-03-29 15:14:24,064 Stage-3_0: 131(+160)/942
</span><span class='line'>2016-03-29 15:14:25,069 Stage-3_0: 266(+160)/942
</span><span class='line'>2016-03-29 15:14:26,075 Stage-3_0: 382(+160)/942
</span><span class='line'>2016-03-29 15:14:27,080 Stage-3_0: 497(+152)/942
</span><span class='line'>2016-03-29 15:14:28,085 Stage-3_0: 607(+142)/942
</span><span class='line'>2016-03-29 15:14:29,090 Stage-3_0: 714(+125)/942
</span><span class='line'>2016-03-29 15:14:30,094 Stage-3_0: 794(+91)/942
</span><span class='line'>2016-03-29 15:14:31,099 Stage-3_0: 846(+61)/942
</span><span class='line'>2016-03-29 15:14:32,103 Stage-3_0: 868(+47)/942
</span><span class='line'>2016-03-29 15:14:33,107 Stage-3_0: 886(+35)/942
</span><span class='line'>2016-03-29 15:14:34,112 Stage-3_0: 895(+26)/942
</span><span class='line'>2016-03-29 15:14:35,116 Stage-3_0: 902(+21)/942
</span><span class='line'>2016-03-29 15:14:36,120 Stage-3_0: 904(+19)/942
</span><span class='line'>2016-03-29 15:14:37,124 Stage-3_0: 906(+17)/942
</span><span class='line'>2016-03-29 15:14:38,128 Stage-3_0: 910(+15)/942
</span><span class='line'>2016-03-29 15:14:39,132 Stage-3_0: 914(+13)/942
</span><span class='line'>2016-03-29 15:14:40,137 Stage-3_0: 920(+9)/942
</span><span class='line'>2016-03-29 15:14:41,141 Stage-3_0: 921(+8)/942
</span><span class='line'>2016-03-29 15:14:44,155 Stage-3_0: 928(+14)/942
</span><span class='line'>2016-03-29 15:14:45,159 Stage-3_0: 934(+8)/942
</span><span class='line'>2016-03-29 15:14:46,164 Stage-3_0: 936(+6)/942
</span><span class='line'>2016-03-29 15:14:47,169 Stage-3_0: 937(+5)/942
</span><span class='line'>2016-03-29 15:14:50,180 Stage-3_0: 938(+4)/942
</span><span class='line'>2016-03-29 15:14:52,188 Stage-3_0: 939(+3)/942
</span><span class='line'>2016-03-29 15:14:54,196 Stage-3_0: 941(+1)/942
</span><span class='line'>2016-03-29 15:14:57,206 Stage-3_0: 941(+1)/942
</span><span class='line'>2016-03-29 15:15:00,215 Stage-3_0: 942/942 Finished
</span><span class='line'>Status: Finished successfully in 39.17 seconds</span></code></pre></td></tr></table></div></figure>


<h2>sparksql1.6.0</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-sql&gt; select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 and sourceip='118.112.188.17' limit 10;
</span><span class='line'>16/03/29 15:15:16 INFO parse.ParseDriver: Parsing command: select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 and sourceip='118.112.188.17' limit 10
</span><span class='line'>16/03/29 15:15:16 INFO parse.ParseDriver: Parse Completed
</span><span class='line'>16/03/29 15:15:16 INFO metastore.HiveMetaStore: 0: get_table : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:16 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_table : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:17 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 543.3 KB, free 9.7 MB)
</span><span class='line'>16/03/29 15:15:17 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 44.1 KB, free 9.8 MB)
</span><span class='line'>16/03/29 15:15:17 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.32.12:51590 (size: 44.1 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:17 INFO spark.SparkContext: Created broadcast 6 from processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:17 INFO metastore.HiveMetaStore: 0: get_partitions : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_partitions : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:18 INFO mapred.FileInputFormat: Total input paths to process : 942
</span><span class='line'>16/03/29 15:15:18 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Got job 4 (processCmd at CliDriver.java:376) with 1 output partitions
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:18 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.9 MB, free 13.7 MB)
</span><span class='line'>16/03/29 15:15:18 INFO storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 318.8 KB, free 14.0 MB)
</span><span class='line'>16/03/29 15:15:18 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:18 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:18 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 1260, hadoop-slaver135, partition 0,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:19 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on hadoop-slaver135:59376 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:20 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver135:59376 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 1260) in 3273 ms on hadoop-slaver135 (1/1)
</span><span class='line'>16/03/29 15:15:21 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: ResultStage 5 (processCmd at CliDriver.java:376) finished in 3.276 s
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Job 4 finished: processCmd at CliDriver.java:376, took 3.475462 s
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@57e08525
</span><span class='line'>16/03/29 15:15:21 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: task runtime:(count: 1, mean: 3273.000000, stdev: 0.000000, max: 3273.000000, min: 3273.000000)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Got job 5 (processCmd at CliDriver.java:376) with 2 output partitions
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: task result size:(count: 1, mean: 3763.000000, stdev: 0.000000, max: 3763.000000, min: 3763.000000)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: executor (non-fetch) time pct: (count: 1, mean: 51.879010, stdev: 0.000000, max: 51.879010, min: 51.879010)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   52 %    52 %    52 %    52 %    52 %    52 %    52 %    52 %    52 %
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: other time pct: (count: 1, mean: 48.120990, stdev: 0.000000, max: 48.120990, min: 48.120990)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   48 %    48 %    48 %    48 %    48 %    48 %    48 %    48 %    48 %
</span><span class='line'>16/03/29 15:15:21 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.9 MB, free 17.9 MB)
</span><span class='line'>16/03/29 15:15:21 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 318.8 KB, free 18.2 MB)
</span><span class='line'>16/03/29 15:15:21 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:21 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:21 INFO cluster.YarnScheduler: Adding task set 6.0 with 2 tasks
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 1261, hadoop-slaver67, partition 1,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 1262, hadoop-slaver121, partition 2,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:21 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on hadoop-slaver67:49600 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver67:49600 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on hadoop-slaver121:57614 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver121:57614 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 1261) in 930 ms on hadoop-slaver67 (1/2)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 1262) in 1207 ms on hadoop-slaver121 (2/2)
</span><span class='line'>16/03/29 15:15:23 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: ResultStage 6 (processCmd at CliDriver.java:376) finished in 1.210 s
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Job 5 finished: processCmd at CliDriver.java:376, took 1.378783 s
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@573e5329
</span><span class='line'>16/03/29 15:15:23 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: task runtime:(count: 2, mean: 1068.500000, stdev: 138.500000, max: 1207.000000, min: 930.000000)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   930.0 ms        930.0 ms        930.0 ms        930.0 ms        1.2 s   1.2 s   1.2 s   1.2 s   1.2 s
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Got job 6 (processCmd at CliDriver.java:376) with 7 output partitions
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: task result size:(count: 2, mean: 2267.500000, stdev: 0.500000, max: 2268.000000, min: 2267.000000)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: executor (non-fetch) time pct: (count: 2, mean: 73.649411, stdev: 11.511880, max: 85.161290, min: 62.137531)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   62 %    62 %    62 %    62 %    85 %    85 %    85 %    85 %    85 %
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: other time pct: (count: 2, mean: 26.350589, stdev: 11.511880, max: 37.862469, min: 14.838710)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   15 %    15 %    15 %    15 %    38 %    38 %    38 %    38 %    38 %
</span><span class='line'>16/03/29 15:15:23 INFO storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.9 MB, free 22.1 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 318.8 KB, free 22.4 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:23 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Submitting 7 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:23 INFO cluster.YarnScheduler: Adding task set 7.0 with 7 tasks
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 7.0 (TID 1263, hadoop-slaver158, partition 9,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 1264, hadoop-slaver82, partition 3,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 7.0 (TID 1265, hadoop-slaver68, partition 8,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 1266, hadoop-slaver120, partition 4,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 7.0 (TID 1267, hadoop-slaver14, partition 5,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 7.0 (TID 1268, hadoop-slaver137, partition 7,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 7.0 (TID 1269, hadoop-slaver70, partition 6,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver68:45281 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver70:34080 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver137:45760 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver82:36935 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver158:39852 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver14:40126 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver120:46667 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver68:45281 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver120:46667 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver70:34080 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver82:36935 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver14:40126 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver137:45760 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver158:39852 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 1266) in 780 ms on hadoop-slaver120 (1/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 1264) in 943 ms on hadoop-slaver82 (2/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 7.0 (TID 1265) in 999 ms on hadoop-slaver68 (3/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 7.0 (TID 1269) in 1047 ms on hadoop-slaver70 (4/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 7.0 (TID 1268) in 1123 ms on hadoop-slaver137 (5/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 7.0 (TID 1267) in 1413 ms on hadoop-slaver14 (6/7)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 7.0 (TID 1263) in 2229 ms on hadoop-slaver158 (7/7)
</span><span class='line'>16/03/29 15:15:25 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: ResultStage 7 (processCmd at CliDriver.java:376) finished in 2.231 s
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Job 6 finished: processCmd at CliDriver.java:376, took 2.399044 s
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@5210a024
</span><span class='line'>16/03/29 15:15:25 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: task runtime:(count: 7, mean: 1219.142857, stdev: 449.417537, max: 2229.000000, min: 780.000000)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   780.0 ms        780.0 ms        780.0 ms        943.0 ms        1.0 s   1.4 s   2.2 s   2.2 s   2.2 s
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: task result size:(count: 7, mean: 2267.428571, stdev: 0.494872, max: 2268.000000, min: 2267.000000)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Got job 7 (processCmd at CliDriver.java:376) with 25 output partitions
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: executor (non-fetch) time pct: (count: 7, mean: 83.082955, stdev: 4.773503, max: 92.418125, min: 77.114871)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   77 %    77 %    77 %    78 %    83 %    86 %    92 %    92 %    92 %
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: other time pct: (count: 7, mean: 16.917045, stdev: 4.773503, max: 22.885129, min: 7.581875)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:    8 %     8 %     8 %    14 %    17 %    22 %    23 %    23 %    23 %
</span><span class='line'>16/03/29 15:15:25 INFO storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.9 MB, free 26.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 318.8 KB, free 26.6 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:25 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Submitting 25 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:25 INFO cluster.YarnScheduler: Adding task set 8.0 with 25 tasks
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 19.0 in stage 8.0 (TID 1270, hadoop-slaver61, partition 29,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 8.0 (TID 1271, hadoop-slaver100, partition 12,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 8.0 (TID 1272, hadoop-slaver34, partition 19,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 8.0 (TID 1273, hadoop-slaver76, partition 20,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 8.0 (TID 1274, hadoop-slaver84, partition 24,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 8.0 (TID 1275, hadoop-slaver96, partition 27,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 8.0 (TID 1276, hadoop-slaver38, partition 14,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 8.0 (TID 1277, hadoop-slaver11, partition 23,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 8.0 (TID 1278, hadoop-slaver98, partition 25,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 1279, hadoop-slaver136, partition 11,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 8.0 (TID 1280, hadoop-slaver44, partition 17,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 20.0 in stage 8.0 (TID 1281, hadoop-slaver120, partition 30,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 8.0 (TID 1282, hadoop-slaver141, partition 21,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 23.0 in stage 8.0 (TID 1283, hadoop-slaver82, partition 33,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 24.0 in stage 8.0 (TID 1284, hadoop-slaver159, partition 34,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 18.0 in stage 8.0 (TID 1285, hadoop-slaver15, partition 28,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 8.0 (TID 1286, hadoop-slaver1, partition 16,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 8.0 (TID 1287, hadoop-slaver145, partition 18,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 22.0 in stage 8.0 (TID 1288, hadoop-slaver142, partition 32,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 8.0 (TID 1289, hadoop-slaver31, partition 26,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 8.0 (TID 1290, hadoop-slaver75, partition 15,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 8.0 (TID 1291, hadoop-slaver97, partition 22,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 21.0 in stage 8.0 (TID 1292, hadoop-slaver149, partition 31,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 1293, hadoop-slaver163, partition 10,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 8.0 (TID 1294, hadoop-slaver91, partition 13,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver34:54432 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver120:46667 (size: 318.8 KB, free: 510.0 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver15:58396 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver82:36935 (size: 318.8 KB, free: 510.0 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver31:37685 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver1:38813 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver100:56851 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver61:37705 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver98:60144 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver38:57228 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver76:40021 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver44:37682 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver149:59628 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver159:40160 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver11:44070 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver91:47206 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver75:50788 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver97:54552 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver34:54432 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver75:50788 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver38:57228 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver100:56851 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver98:60144 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver149:59628 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver44:37682 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver97:54552 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver1:38813 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver91:47206 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver76:40021 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver31:37685 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver159:40160 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver15:58396 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver145:37716 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver61:37705 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver141:60941 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver136:33234 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver96:53017 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver96:53017 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver141:60941 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver163:50662 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver145:37716 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver84:34548 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 20.0 in stage 8.0 (TID 1281) in 762 ms on hadoop-slaver120 (1/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 8.0 (TID 1278) in 873 ms on hadoop-slaver98 (2/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 8.0 (TID 1271) in 892 ms on hadoop-slaver100 (3/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 8.0 (TID 1291) in 911 ms on hadoop-slaver97 (4/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 8.0 (TID 1290) in 914 ms on hadoop-slaver75 (5/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 8.0 (TID 1276) in 938 ms on hadoop-slaver38 (6/25)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver163:50662 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 8.0 (TID 1280) in 955 ms on hadoop-slaver44 (7/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 8.0 (TID 1273) in 963 ms on hadoop-slaver76 (8/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 8.0 (TID 1286) in 974 ms on hadoop-slaver1 (9/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 8.0 (TID 1272) in 1019 ms on hadoop-slaver34 (10/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 8.0 (TID 1282) in 1186 ms on hadoop-slaver141 (11/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 23.0 in stage 8.0 (TID 1283) in 1187 ms on hadoop-slaver82 (12/25)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver11:44070 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 8.0 (TID 1287) in 1260 ms on hadoop-slaver145 (13/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 21.0 in stage 8.0 (TID 1292) in 1349 ms on hadoop-slaver149 (14/25)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver136:33234 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver142:59911 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 19.0 in stage 8.0 (TID 1270) in 1569 ms on hadoop-slaver61 (15/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 1293) in 1598 ms on hadoop-slaver163 (16/25)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver84:34548 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver142:59911 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 8.0 (TID 1277) in 1958 ms on hadoop-slaver11 (17/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 8.0 (TID 1294) in 2018 ms on hadoop-slaver91 (18/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 8.0 (TID 1274) in 2267 ms on hadoop-slaver84 (19/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 8.0 (TID 1275) in 2717 ms on hadoop-slaver96 (20/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 8.0 (TID 1289) in 2733 ms on hadoop-slaver31 (21/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 18.0 in stage 8.0 (TID 1285) in 2864 ms on hadoop-slaver15 (22/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 1279) in 3129 ms on hadoop-slaver136 (23/25)
</span><span class='line'>16/03/29 15:15:29 INFO scheduler.TaskSetManager: Finished task 22.0 in stage 8.0 (TID 1288) in 3308 ms on hadoop-slaver142 (24/25)
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 8.0 (TID 1284) in 5445 ms on hadoop-slaver159 (25/25)
</span><span class='line'>16/03/29 15:15:31 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.DAGScheduler: ResultStage 8 (processCmd at CliDriver.java:376) finished in 5.448 s
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.DAGScheduler: Job 7 finished: processCmd at CliDriver.java:376, took 5.621305 s
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@1251c1a
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener: task runtime:(count: 25, mean: 1751.560000, stdev: 1086.831729, max: 5445.000000, min: 762.000000)
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   762.0 ms        873.0 ms        892.0 ms        955.0 ms        1.3 s   2.3 s   3.1 s   3.3 s   5.4 s
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener: task result size:(count: 25, mean: 2501.840000, stdev: 410.074401, max: 3304.000000, min: 2266.000000)
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.6 KB  3.2 KB  3.2 KB  3.2 KB</span></code></pre></td></tr></table></div></figure>


<p>一共弄了4次: <code>1 -&gt; 2 -&gt; 7 -&gt; 25</code></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive on Spark]]></title>
    <link href="http://winseliu.com/blog/2016/03/28/hive-on-spark/"/>
    <updated>2016-03-28T18:20:46+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/28/hive-on-spark</id>
    <content type="html"><![CDATA[<p>先看官网的资源<a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started">Hive on Spark: Getting Started</a> 。文档是值得信任和有保证的，但是有前提：<strong>Spark版本</strong>得是hive/pom.xml中指定的。</p>

<h2>重新编译spark(assembly包中去掉hive、hadoop)</h2>

<p>这里hive-1.2.1用的是spark-1.3.1 !!!</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 spark-1.3.1]$ ./make-distribution.sh --name "hadoop2.6.3-without-hive" --tgz --mvn "$(which mvn)" -Pyarn,hadoop-provided,hadoop-2.6,parquet-provided -Dhadoop.version=2.6.3 -Dmaven.test.skip=true -Dmaven.javadoc.skip=true -DskipTests
</span></code></pre></td></tr></table></div></figure>


<p>拷贝打包好的 spark-1.3.1-bin-hadoop2.6.3-without-hive.tgz 到服务器。解压并做一个软链接到spark(或者指定 <strong>SPARK_HOME</strong> 环境变量 )，Hive不遗余力啊，把所有想的jar通过各种办法拿到 ( <code>sparkHome=$(readlink -f $bin/../../spark)</code> )。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s spark-1.3.1-bin-hadoop2.6.3-without-hive spark
</span><span class='line'>
</span><span class='line'>把压缩包传到hdfs，这样每次启动任务就少传几百M的数据。后面spark.yarn.jar配置会用到
</span><span class='line'>[hadoop@hadoop-master2 ~]$ cd spark/lib/
</span><span class='line'>[hadoop@hadoop-master2 lib]$ hadoop fs -put spark-assembly-1.3.1-hadoop2.6.3.jar /spark/
</span></code></pre></td></tr></table></div></figure>


<p>做好软链接后效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ ll | grep -E "hive|spark"
</span><span class='line'>drwxrwxr-x   9 hadoop hadoop 4096 1月  14 08:08 apache-hive-1.2.1-bin
</span><span class='line'>lrwxrwxrwx   1 hadoop hadoop   21 1月  14 08:07 hive -&gt; apache-hive-1.2.1-bin
</span><span class='line'>lrwxrwxrwx   1 hadoop hadoop   40 3月  28 16:38 spark -&gt; spark-1.3.1-bin-hadoop2.6.3-without-hive
</span><span class='line'>drwxrwxr-x  10 hadoop hadoop 4096 3月  28 16:31 spark-1.3.1-bin-hadoop2.6.3-without-hive
</span><span class='line'>drwxrwxr-x  12 hadoop hadoop 4096 3月  25 16:18 spark-1.6.0-bin-2.6.3
</span><span class='line'>drwxrwxr-x  11 hadoop hadoop 4096 3月  28 11:15 spark-1.6.0-bin-hadoop2-without-hive</span></code></pre></td></tr></table></div></figure>


<p>这里的spark-1.6.0是教训啊！记住最好最好用hive/pom.xml中spark的版本！！！</p>

<h2>修改hive配置</h2>

<p>由于spark会加载很多的class，需要把permsize调大。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ less ~/hive/conf/hive-env.sh
</span><span class='line'>export HADOOP_OPTS="$HADOOP_OPTS -XX:MaxPermSize=256m -Dhive.home=${HIVE_HOME} "</span></code></pre></td></tr></table></div></figure>


<p>在conf目录下增加spark-defaults.conf文件，指定spark的配置。动态资源分配查看：<a href="http://spark.apache.org/docs/1.3.1/job-scheduling.html#dynamic-resource-allocation">dynamic-resource-allocation</a>：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 conf]$ cat spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.3.1-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.executorIdleTimeout    600
</span><span class='line'>spark.dynamicAllocation.minExecutors    160 
</span><span class='line'>spark.dynamicAllocation.maxExecutors    1800
</span><span class='line'>spark.dynamicAllocation.schedulerBacklogTimeout   5
</span><span class='line'>
</span><span class='line'>spark.driver.memory    10g
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address hadoop-master2:18080
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span><span class='line'>spark.kryoserializer.buffer.max    512m</span></code></pre></td></tr></table></div></figure>


<ul>
<li>minExecutors <strong>最好应该是和datanode机器数量差不多，每台一个executor才能本地计算嘛！</strong></li>
<li>dynamicAllocation需要yarn的配合，具体查看前一篇文章，或者直接看官网的资料。</li>
<li>eventlog查看历史记录需要，配置好后每个任务的信息会存储到eventlog.dir的路径。通过18080端口可以看到历史记录。</li>
</ul>


<h2>跑起来</h2>

<p><code>spark.master</code> 默认是 <strong>yarn-cluster</strong>， 这里先本地(local)跑一下看下效果。然后再改成yarn-cluster/yarn-client就可以了(推荐使用yarn-client，如果yarn-cluster模式AppMaster同时也是Driver，内存比较难控制，日志看起来也麻烦)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hive]$ hive --hiveconf hive.execution.engine=spark 
</span><span class='line'>
</span><span class='line'>hive&gt; set spark.master=local;
</span><span class='line'>hive&gt; select count(*) from t_house_info ;
</span><span class='line'>Query ID = hadoop_20160328163952_93dafddc-c8b1-4bc9-b851-5e51f6d26fa8
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 0
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-28 16:40:02,077 Stage-0_0: 0(+1)/1      Stage-1_0: 0/1
</span><span class='line'>2016-03-28 16:40:03,078 Stage-0_0: 1/1 Finished Stage-1_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 2.01 seconds
</span><span class='line'>OK
</span><span class='line'>1
</span><span class='line'>Time taken: 10.169 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; 
</span></code></pre></td></tr></table></div></figure>


<p>再回过头看其实挺简单，和官方文档中的差不多。</p>

<p>注意：hive的日志级别可以通过 <strong>hive-log4j.properties</strong> 来配置。</p>

<p>有一个问题，不管yarn-cluser还是yarn-client（hive1.2.1-on-spark1.3.1），application强制kill掉以后，再查询会失败，应该是application杀了但是session还在！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ yarn application -kill application_1460379750886_0012
</span><span class='line'>16/04/13 08:47:17 INFO client.RMProxy: Connecting to ResourceManager at file1/192.168.102.6:8032
</span><span class='line'>Killing application application_1460379750886_0012
</span><span class='line'>16/04/13 08:47:18 INFO impl.YarnClientImpl: Killed application application_1460379750886_0012
</span><span class='line'>
</span><span class='line'>    &gt; select count(*) from t_info where edate=20160413;
</span><span class='line'>Query ID = hadoop_20160413084736_ac8f88bb-5ee1-4941-9745-f4a8a504f2f3
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = eb7e038a-2db0-45d7-9b0d-1e55d354e5e9
</span><span class='line'>Status: Failed
</span><span class='line'>FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask</span></code></pre></td></tr></table></div></figure>


<h2>坑坑坑</h2>

<p>刚开始弄的时刻，没管spark的版本的。直接上spark-1.6.0，然后完全跑不通，看hive.log的日志，啥都看不出来。最后查看<a href="http://markmail.org/message/reingwn556e7e37y">http://markmail.org/message/reingwn556e7e37y</a>Hive on Spark的老大邮件列表的回复，把 <strong>spark.master=local</strong> 设置成本地跑才看到一点点有用的错误信息。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2 where day=20160327;
</span><span class='line'>Query ID = hadoop_20160328083028_a9fb9860-38dc-4288-8415-b5b2b88f920a
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Failed to execute spark task, with exception 'org.apache.hadoop.hive.ql.metadata.HiveException(Failed to create spark client.)'
</span><span class='line'>FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.spark.SparkTask
</span></code></pre></td></tr></table></div></figure>


<p>日志里面&#8217;毛&#8217;有用信息都没有！</p>

<p>把日志级别调成debug（hive-log4j.properties），并把 <code>set spark.master=local;</code> 设置成本地。再跑日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-03-28 15:13:52,549 DEBUG internal.PlatformDependent (Slf4JLogger.java:debug(71)) - Javassist: unavailable
</span><span class='line'>2016-03-28 15:13:52,549 DEBUG internal.PlatformDependent (Slf4JLogger.java:debug(71)) - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
</span><span class='line'>
</span><span class='line'>2016-03-28 15:14:56,594 DEBUG storage.BlockManager (Logging.scala:logDebug(62)) - Putting block broadcast_0_piece0 without replication took  8 ms
</span><span class='line'>2016-03-28 15:14:56,597 ERROR util.Utils (Logging.scala:logError(95)) - uncaught error in thread SparkListenerBus, stopping SparkContext
</span><span class='line'>java.lang.AbstractMethodError
</span><span class='line'>        at org.apache.spark.scheduler.SparkListenerBus$class.onPostEvent(SparkListenerBus.scala:62)
</span><span class='line'>        at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:31)
</span><span class='line'>        at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:31)
</span><span class='line'>        at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:55)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus.postToAll(AsynchronousListenerBus.scala:37)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(AsynchronousListenerBus.scala:80)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(AsynchronousListenerBus.scala:65)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(AsynchronousListenerBus.scala:65)
</span><span class='line'>        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1.apply$mcV$sp(AsynchronousListenerBus.scala:64)
</span><span class='line'>        at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1180)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1.run(AsynchronousListenerBus.scala:63)</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><strong>调用抽象方法</strong>的错误。然后查看了hive-1.2.1中 SparkListener实现类JobMetricsListener 确实没有(spark-1.6.0)62行错误的onBlockUpdated方法实现。然后把spark换成1.3.1一切就好了，其他就是文章前面写的。</p>

<p><strong>心得</strong>: 刚刚开始用一个新东西的时刻，还是安装官网指定的版本来用省心。等到自己熟悉后，在玩其他的。</p>

<h2><strong>hive on spark</strong> VS <strong>SparkSQL</strong> VS <strong>hive on tez</strong></h2>

<p>前一篇已经弄好了SparkSQL，SparkSQL也有thriftserver服务，这里说说为啥还选择搞hive-on-spark：</p>

<ul>
<li>SparkSQL-Thriftserver所有结果全部内存，快是快，但是不能满足查询大量数据的需求。如果查询几千万的数据，SparkSQL是搞不定的。而hive-on-spark除了计算用spark其他逻辑都是hive的，返回的结果会先写hdfs，再慢慢返回给客户端。</li>
<li>SparkSQL-Thriftserver代码的是全部用scala重写的，和已有hive业务不一定兼容！！</li>
<li>SparkSQL-Thriftserver有一个最大的优势就是整个server相当于hive-on-spark的一个session，网页监控漂亮清晰。而hive-on-spark不同的session那就相当于不同的application！！（2016-4-13 20:57:23）用了动态分配，没感觉SparkSQLThriftserver快很多。</li>
<li>SparkSQL由于基于内存，再一些调度方面做了优化。如[limit]: hive是死算，sparksql递增数据量的一次次的试。sparksql可以这么做的，毕竟算好的数据在内存里面放着。</li>
</ul>


<p>hive和sparksql的理念不同，hive的存储是HDFS，而sparksql只是把HDFS作为持久化工具，它的数据基本都放内存。</p>

<p>查看hive的日志，可以看到返回结果后有写HDFS的动作体现，会有类似日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-03-28 19:39:25,687 INFO  exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1882))
</span><span class='line'> - Moving tmp dir: hdfs://zfcluster/hive/scratchdir/hadoop/de2b263e-9601-4df7-bc38-ba932ae83f42/hive_2016-03-28_19-38-08_834_7914607982986605890-1/-mr-10000/.hive-staging_hive_2016-03-28_19-38-08_834_7914607982986605890-1/_tmp.-ext-10001 
</span><span class='line'> to: hdfs://zfcluster/hive/scratchdir/hadoop/de2b263e-9601-4df7-bc38-ba932ae83f42/hive_2016-03-28_19-38-08_834_7914607982986605890-1/-mr-10000/.hive-staging_hive_2016-03-28_19-38-08_834_7914607982986605890-1/-ext-10001
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>tez的优势spark都有，并且tez其实缓冲优势并不大。而spark的缓冲效果更明显，而且可以快速返回。例如：你查3万条数据，tez是要全部查询然后再返回的，而sparksql取到3万条其他就不算了（效果看起来是这样子，具体没看源码实现；md hive-on-spark还是会全部跑）。</li>
<li>tez任务缓冲不能共享，spark更加细化，可以有process级别缓冲（就是用上次计算过的结果，加载过的缓冲）！例如，你查数据记录同时又要返回count，这时有些操作是prcess_local级别的，这个tez是不能比的！</li>
<li>spark的日志UI看起来更便捷，呵呵</li>
</ul>


<p>单就从用的角度，spark全面取胜啊。</p>

<h2>参考</h2>

<ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started">https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started</a></li>
<li><a href="http://spark.apache.org/docs/1.3.1/configuration.html">http://spark.apache.org/docs/1.3.1/configuration.html</a></li>
<li><a href="http://spark.apache.org/docs/1.3.1/job-scheduling.html#dynamic-resource-allocation">http://spark.apache.org/docs/1.3.1/job-scheduling.html#dynamic-resource-allocation</a></li>
<li>cloudera-hos优化: <a href="http://www.cloudera.com/documentation/enterprise/latest/topics/admin_hos_tuning.html">http://www.cloudera.com/documentation/enterprise/latest/topics/admin_hos_tuning.html</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SparkSQL-on-YARN的Executors池(动态)配置]]></title>
    <link href="http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn/"/>
    <updated>2016-03-25T15:14:53+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn</id>
    <content type="html"><![CDATA[<h2>官网配置资料</h2>

<ul>
<li><a href="http://spark.apache.org/docs/latest/running-on-yarn.html">http://spark.apache.org/docs/latest/running-on-yarn.html</a></li>
<li><a href="http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup">http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup</a></li>
<li><a href="http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation">http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation</a></li>
</ul>


<h2>实战</h2>

<h4>修改YARN配置，添加spark-yarn-shuffle.jar，同步配置和jar到nodemanager节点并重启。</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ vi etc/hadoop/yarn-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>&lt;value&gt;mapreduce_shuffle,spark_shuffle&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ cp ~/spark-1.6.0-bin-2.6.3/lib/spark-1.6.0-yarn-shuffle.jar share/hadoop/yarn/
</span><span class='line'>
</span><span class='line'>for h in `cat etc/hadoop/slaves` ; do rsync -az share $h:~/hadoop-2.6.3/ ; done 
</span><span class='line'>for h in `cat etc/hadoop/slaves` ; do rsync -az etc $h:~/hadoop-2.6.3/ ; done 
</span><span class='line'>
</span><span class='line'>rsync -vaz etc hadoop-master2:~/hadoop-2.6.3/
</span><span class='line'>rsync -vaz share hadoop-master2:~/hadoop-2.6.3/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-yarn.sh 
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-yarn.sh </span></code></pre></td></tr></table></div></figure>


<h4>原来已经部署了Hive-1.2.1（和spark-1.6.0的hive是匹配的），直接把hive-site.xml做一个软链到spark/conf下面：</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ cd conf/
</span><span class='line'>[hadoop@hadoop-master1 conf]$ ln -s ~/hive/conf/hive-site.xml 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ ll conf/hive-site.xml 
</span><span class='line'>lrwxrwxrwx. 1 hadoop hadoop 36 3月  25 11:30 conf/hive-site.xml -&gt; /home/hadoop/hive/conf/hive-site.xml</span></code></pre></td></tr></table></div></figure>


<p>注意：如果原来配置了tez，把hive-site.xml的 <strong>hive.execution.engine</strong> 配置注释掉。或者启动的时刻换引擎： <code>bin/spark-sql --master yarn-client --hiveconf hive.execution.engine=mr</code></p>

<h4>修改spark配置</h4>

<p>spark-defaults.conf</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 conf]$ cat spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.executorIdleTimeout    600s
</span><span class='line'>spark.dynamicAllocation.minExecutors    160
</span><span class='line'>spark.dynamicAllocation.maxExecutors    1800
</span><span class='line'>spark.dynamicAllocation.schedulerBacklogTimeout   5s
</span><span class='line'>
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address hadoop-master2:18080
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>spark.yarn.jar 配置后，spark启动后直接使用该文件作为executor的main-jar，不需要每次都上传一次spark.jar（每次都搞一下180M也不少资源了）</li>
<li>enabled 启用动态两个都配置必须设置为true</li>
<li>executorIdleTimeout 关闭不用executors需要等待的时间</li>
<li>schedulerBacklogTimeout 增加积压的任务时间来判断是否增加executors</li>
<li>minExecutors 至少存活的executors个数</li>
</ul>


<p>spark-env.sh环境变量</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 conf]$ cat spark-env.sh 
</span><span class='line'>SPARK_CLASSPATH=/home/hadoop/hive/lib/mysql-connector-java-5.1.21-bin.jar:$SPARK_CLASSPATH
</span><span class='line'>HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop
</span><span class='line'>SPARK_DRIVER_MEMORY=30g
</span><span class='line'>SPARK_PID_DIR=/home/hadoop/tmp/pids</span></code></pre></td></tr></table></div></figure>


<h4>启动</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ sbin/start-thriftserver.sh --master yarn-client
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 spark-1.6.0-bin-2.6.3]$ sbin/start-history-server.sh hdfs:///spark-eventlogs</span></code></pre></td></tr></table></div></figure>


<p>收工。</p>

<p>整个过程就是：添加spark-shuffle到yarn，然后配置spark参数，最后就是重启任务（yarn/hiveserver）。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop内存环境变量和参数]]></title>
    <link href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/"/>
    <updated>2016-03-17T14:09:26+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args</id>
    <content type="html"><![CDATA[<h2>问题：</h2>

<p><a href="https://www.zhihu.com/question/25498407">https://www.zhihu.com/question/25498407</a></p>

<p>问题是hadoop内存的配置，涉及两个方面：</p>

<ul>
<li>namenode/datanode/resourcemanager/nodemanager的HEAPSIZE环境变量</li>
<li>在配置文件/Configuration中影响MR运行的变量</li>
</ul>


<p>尽管搞hadoop有好一阵子了，对这些变量有个大概的了解，但没有真正的去弄懂他们的区别。乘着这个机会好好的整整（其实就是下载源码然后全文查找<sup>V</sup>^）。</p>

<h2>HEAPSIZE环境变量</h2>

<p>hadoop-env.sh配置文件hdfs和yarn脚本都会加载。hdfs是一脉相承使用 <strong>HADOOP_HEAPSIZE</strong> ，而yarn使用新的环境变量 <strong>YARN_HEAPSIZE</strong> 。</p>

<p>hadoop/hdfs/yarn命令最终会把HEAPSIZE的参数转换了 <strong>JAVA_HEAP_MAX</strong>，把它作为启动参数传递给Java。</p>

<ul>
<li>hadoop</li>
</ul>


<p>hadoop命令是把 <code>HADOOP_HEAPSIZE</code> 转换为 <code>JAVA_HEAP_MAX</code> ，调用路径：</p>

<p><code>hadoop -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>JAVA_HEAP_MAX=-Xmx1000m 
</span><span class='line'>
</span><span class='line'># check envvars which might override default args
</span><span class='line'>if [ "$HADOOP_HEAPSIZE" != "" ]; then
</span><span class='line'>  #echo "run with heapsize $HADOOP_HEAPSIZE"
</span><span class='line'>  JAVA_HEAP_MAX="-Xmx""$HADOOP_HEAPSIZE""m"
</span><span class='line'>  #echo $JAVA_HEAP_MAX
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<ul>
<li>hdfs</li>
</ul>


<p>hdfs其实就是从hadoop脚本里面分离出来的。调用路径：</p>

<p><code>hdfs -&gt; hdfs-config.sh -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<ul>
<li>yarn</li>
</ul>


<p>yarn也调用了hadoop-env.sh，但是设置内存的参数变成了 <strong>YARN_HEAPSIZE</strong> 。调用路径：</p>

<p><code>yarn -&gt; yarn-config.sh -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>JAVA_HEAP_MAX=-Xmx1000m 
</span><span class='line'>
</span><span class='line'># For setting YARN specific HEAP sizes please use this
</span><span class='line'># Parameter and set appropriately
</span><span class='line'># YARN_HEAPSIZE=1000
</span><span class='line'>
</span><span class='line'># check envvars which might override default args
</span><span class='line'>if [ "$YARN_HEAPSIZE" != "" ]; then
</span><span class='line'>  JAVA_HEAP_MAX="-Xmx""$YARN_HEAPSIZE""m"
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<ul>
<li>实例：</li>
</ul>


<p>配置hadoop参数的时刻，一般都是配置 <strong>hadoop-env.sh</strong> 如：<code>export HADOOP_HEAPSIZE=16000</code> 。查看相关进程命令有：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_resourcemanager -Xmx1000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_timelineserver -Xmx1000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_nodemanager -Xmx1000m 
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_journalnode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_namenode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_journalnode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_datanode -Xmx16000m</span></code></pre></td></tr></table></div></figure>


<p>与hdfs有关的内存都修改成功了。而与yarn的还是默认的1g(堆)内存。</p>

<h2>MR配置文件参数</h2>

<p>分成两组，一种是直接设置数字(mb结束的属性)，一种是配置java虚拟机变量的-Xmx。</p>

<pre><code>* yarn.app.mapreduce.am.resource.mb、mapreduce.map.memory.mb、mapreduce.reduce.memory.mb
    用于调度计算内存，是不是还能分配任务（计算额度）
* yarn.app.mapreduce.am.command-opts、mapreduce.map.java.opts、mapreduce.reduce.java.opts
    程序实际启动使用的参数
</code></pre>

<p>一个是控制中枢，一个是实实在在的限制。</p>

<ul>
<li>官网文档的介绍：</li>
</ul>


<blockquote><ul>
<li>mapreduce.map.memory.mb 1024    The amount of memory to request from the scheduler for each map task.</li>
<li>mapreduce.reduce.memory.mb  1024    The amount of memory to request from the scheduler for each reduce task.</li>
<li>mapred.child.java.opts  -Xmx200m    Java opts for the task processes.</li>
</ul>
</blockquote>

<ul>
<li><p>下面用实践来验证效果：</p>

<ul>
<li>先搞一个很大大只有一个block的文件，把程序运行时间拖长一点</li>
<li>修改opts参数，查看效果</li>
<li>修改mb参数，查看效果</li>
</ul>
</li>
<li><p>实践一</p></li>
</ul>


<p>mapreduce.map.memory.mb设置为1000，而mapreduce.map.java.opts设置为1200m。程序照样跑的很欢！！</p>

<p>同时从map的 YarnChild 进程看出起实际作用的是 mapreduce.map.java.opts 参数。memory.mb用来计算节点是否有足够的内存来跑任务，以及用来计算整个集群的可用内存等。而java.opts则是用来限制真正任务的堆内存用量。</p>

<p><strong>注意</strong> ： 这里仅仅是用来测试，正式环境java.opts的内存应该小于memory.mb！！具体配置参考：<a href="http://blog.javachen.com/2015/06/05/yarn-memory-and-cpu-configuration.html">yarn-memory-and-cpu-configuration</a></p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-opts-mb.jpg" alt="" /></p>

<ul>
<li>实践二</li>
</ul>


<p>map.memory.mb设置太大，导致调度失败！</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-mb-1.jpg" alt="" /></p>

<ul>
<li>实践三</li>
</ul>


<p>尽管实际才用不大于1.2G的内存，但是由于mapreduce.map.memory.mb设置为8G，整个集群显示已用内存18G（2 * 8g + 1 * 2g）。登录实际运行任务的机器，实际内存其实不多。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-mb-2.jpg" alt="" />
<img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-mb-3.jpg" alt="" /></p>

<p>reduce和am（appmaster）的参数类似。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-appmaster-mb-1.jpg" alt="" />
<img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-appmaster-mb-2.jpg" alt="" /></p>

<h2>mapred.child.java.opts参数</h2>

<p>这是一个过时的属性，当然你设置也能起效果(没有设置mapreduce.map.java.opts/mapreduce.reduce.java.opts)。相当于把MR的java.opts都设置了。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/mapred-opts.jpg" alt="" /></p>

<p>获取map/reduce的opts中间会取 <strong>mapred.child.java.opts</strong> 的值。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/mapred-opts-2.jpg" alt="" /></p>

<h2>admin-opts</h2>

<p>查找源码后，其实opts被分成两部分：admin和user。admin的写在前面，user在后面。user设置的opts可以覆盖admin设置的。应该是方便用于设置默认值吧。</p>

<h2>实例</h2>

<p>同时在一台很牛掰的机器上跑程序（分了yarn.nodemanager.resource.memory-mb 26G内存），但是总是只能一次跑一个任务，但还剩很多内存(20G)没有用啊！！初步怀疑是调度算法的问题。</p>

<p>查看了调度的日志，初始化的时刻会输出 <strong>scheduler.capacity.LeafQueue</strong> 的日志，打印了集群控制的一些参数。然后 同时找到一篇<a href="http://stackoverflow.com/questions/33465300/why-does-yarn-job-not-transition-to-running-state">http://stackoverflow.com/questions/33465300/why-does-yarn-job-not-transition-to-running-state</a> 说是调整 <strong>yarn.scheduler.capacity.maximum-am-resource-percent</strong> ，是用于控制appmaster最多可用的资源。</p>

<p>appmaster的默认内存是： <strong>yarn.app.mapreduce.am.resource.mb  1536</strong>（client设置有效）， <strong>yarn.scheduler.capacity.maximum-am-resource-percent 0.1</strong>。</p>

<p>跑第二job的时刻，第二个appmaster调度的时刻没有足够的内存（26G * 0.1 - 1.536 > 1.536），所以就跑不了两个job。</p>

<h2>CLIENT_OPTS</h2>

<p>一般 HADOOP 集群都会配套 HIVE，hive直接用 sql 来查询数据比mapreduce简单很多。启动hive是直接用 hadoop jar 来启动的。相对于一个客户端程序。控制hive内存的就是 HADOOP_CLIENT_OPTS 环境变量中的 -Xmx 。</p>

<p>所以要调整 hive 内存的使用，可以通过调整 HADOOP_CLIENT_OPTS 来控制。（当然理解这些环境变量，你就可以随心随欲的改）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hive]$ sh -x bin/hiveserver2 
</span><span class='line'>...
</span><span class='line'>++ exec /home/hadoop/hadoop/bin/hadoop jar /home/hadoop/hive/lib/hive-service-1.2.1.jar org.apache.hive.service.server.HiveServer2
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ grep -3  "HADOOP_CLIENT_OPTS" ~/hadoop/etc/hadoop/hadoop-env.sh
</span><span class='line'>export HADOOP_PORTMAP_OPTS="-Xmx512m $HADOOP_PORTMAP_OPTS"
</span><span class='line'>
</span><span class='line'># The following applies to multiple commands (fs, dfs, fsck, distcp etc)
</span><span class='line'>export HADOOP_CLIENT_OPTS="-Xmx128m $HADOOP_CLIENT_OPTS"
</span><span class='line'>#HADOOP_JAVA_PLATFORM_OPTS="-XX:-UsePerfData $HADOOP_JAVA_PLATFORM_OPTS"
</span><span class='line'>
</span><span class='line'># On secure datanodes, user to run the datanode as after dropping privileges.
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ jinfo 10249
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>VM Flags:
</span><span class='line'>
</span><span class='line'>-Xmx256m -Djava.net.preferIPv4Stack=true -Dhadoop.log.dir=/home/hadoop/hadoop-2.6.3/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.6.3 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Djava.library.path=/home/hadoop/hadoop-2.6.3/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx128m -Dhadoop.security.logger=INFO,NullAppender
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ jmap -heap 10249
</span><span class='line'>...
</span><span class='line'>Heap Configuration:
</span><span class='line'>   MinHeapFreeRatio = 40
</span><span class='line'>   MaxHeapFreeRatio = 70
</span><span class='line'>   MaxHeapSize      = 134217728 (128.0MB)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装配置OpenVPN]]></title>
    <link href="http://winseliu.com/blog/2016/03/11/install-and-config-openvpn/"/>
    <updated>2016-03-11T09:46:49+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/11/install-and-config-openvpn</id>
    <content type="html"><![CDATA[<p>由于测试环境搭建不在同一个网络，平时查看hadoop集群状态、提交任务都可以通过hadoop-master的外网来操作。但是要读写kafka，需要直接连通所有的节点，全部映射端口太麻烦。一开始想到了VLAN(虚拟局域网），远远超出能力范围。最后通过搭架VPN来实现与测试环境的透明访问。</p>

<h2>使用集成版本</h2>

<p>参考 <a href="https://linux.cn/article-4733-1.html">https://linux.cn/article-4733-1.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># download https://openvpn.net/index.php/access-server/download-openvpn-as-sw.html
</span><span class='line'>
</span><span class='line'># 安装
</span><span class='line'>[root@cu2 ~]# rpm -ivh openvpn-as-2.0.25-CentOS6.x86_64.rpm 
</span><span class='line'>Preparing...                ########################################### [100%]
</span><span class='line'>   1:openvpn-as             ########################################### [100%]
</span><span class='line'>The Access Server has been successfully installed in /usr/local/openvpn_as
</span><span class='line'>Configuration log file has been written to /usr/local/openvpn_as/init.log
</span><span class='line'>Please enter "passwd openvpn" to set the initial
</span><span class='line'>administrative password, then login as "openvpn" to continue
</span><span class='line'>configuration here: https://192.168.0.214:943/admin
</span><span class='line'>To reconfigure manually, use the /usr/local/openvpn_as/bin/ovpn-init tool.
</span><span class='line'>
</span><span class='line'>Access Server web UIs are available here:
</span><span class='line'>Admin  UI: https://192.168.0.214:943/admin
</span><span class='line'>Client UI: https://192.168.0.214:943/
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# passwd openvpn
</span><span class='line'>
</span><span class='line'>然后通过web admin进行配置。如主机的信息、hostname以及监听绑定的IP</span></code></pre></td></tr></table></div></figure>


<p>配置好以后，本地通过网页下载client程序安装。连接配置后：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>C:\Users\winse&gt;tracert  cu3
</span><span class='line'>
</span><span class='line'>通过最多 30 个跃点跟踪
</span><span class='line'>到 cu3 [192.168.0.148] 的路由:
</span><span class='line'>
</span><span class='line'>  1     2 ms     2 ms     2 ms  172.27.232.1
</span><span class='line'>  2     2 ms     2 ms     2 ms  cu3 [192.168.0.148]
</span><span class='line'>
</span><span class='line'>跟踪完成。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>C:\Users\winse&gt;route print
</span><span class='line'>===========================================================================
</span><span class='line'>IPv4 路由表
</span><span class='line'>===========================================================================
</span><span class='line'>活动路由:
</span><span class='line'>网络目标        网络掩码          网关       接口   跃点数
</span><span class='line'>          0.0.0.0          0.0.0.0      192.168.1.1    192.168.1.102     20
</span><span class='line'>          0.0.0.0        128.0.0.0     172.27.232.1     172.27.232.2     20
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p><a href="http://designmylife.blog.163.com/blog/static/2067142542013527101659960/">http://designmylife.blog.163.com/blog/static/2067142542013527101659960/</a></p>

<p>路由匹配按最大(最亲)方式匹配。上面路由会先匹配mask为 <code>128.0.0.0</code> 的路由。最终把所有的流量经由VPN出去。</p>

<p>通过 <strong>Access Server</strong> 安装简单，配置通过网页来弄，和网上资料的都匹配不上，还有用户数量的限制，囧。</p>

<h2>编译源码安装</h2>

<ul>
<li>服务端安装配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 openvpn-2.3.10]# yum install libpam*
</span><span class='line'>[root@cu2 openvpn-2.3.10]# yum install pam-devel.x86_64
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring lzo-2.06.tar.gz...
</span><span class='line'>  100%     569 KB     569 KB/sec    00:00:01       0 Errors  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# tar zxvf lzo-2.06.tar.gz 
</span><span class='line'>[root@cu2 ~]# cd lzo-2.06
</span><span class='line'>[root@cu2 lzo-2.06]# ./configure 
</span><span class='line'>[root@cu2 lzo-2.06]# make &&  make install
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# ./configure --prefix=/usr/local/openvpn 
</span><span class='line'>[root@cu2 openvpn-2.3.10]# make && make install
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# /usr/local/openvpn/sbin/openvpn --version
</span><span class='line'>OpenVPN 2.3.10 x86_64-unknown-linux-gnu [SSL (OpenSSL)] [EPOLL] [MH] [IPv6] built on Mar  9 2016
</span><span class='line'>
</span><span class='line'>https://github.com/OpenVPN/easy-rsa/releases
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa  help
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa init-pki
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]#  ./easyrsa build-ca
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa gen-req openvpn nopass
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa sign client openvpn
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa gen-req eshore-cu nopass
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa sign server eshore-cu
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# tree pki/
</span><span class='line'>pki/
</span><span class='line'>├── ca.crt
</span><span class='line'>├── certs_by_serial
</span><span class='line'>│   ├── 01.pem
</span><span class='line'>│   └── 02.pem
</span><span class='line'>├── index.txt
</span><span class='line'>├── index.txt.attr
</span><span class='line'>├── index.txt.attr.old
</span><span class='line'>├── index.txt.old
</span><span class='line'>├── issued
</span><span class='line'>│   ├── eshore-cu.crt
</span><span class='line'>│   └── openvpn.crt
</span><span class='line'>├── private
</span><span class='line'>│   ├── ca.key
</span><span class='line'>│   ├── eshore-cu.key
</span><span class='line'>│   └── openvpn.key
</span><span class='line'>├── reqs
</span><span class='line'>│   ├── eshore-cu.req
</span><span class='line'>│   └── openvpn.req
</span><span class='line'>├── serial
</span><span class='line'>└── serial.old
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]#  ./easyrsa gen-dh
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# cd pki
</span><span class='line'>[root@cu2 pki]# cp ca.crt dh.pem issued/eshore-cu.crt private/eshore-cu.key /etc/openvpn/ 
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# cp sample/sample-config-files/server.conf /etc/openvpn/
</span><span class='line'>
</span><span class='line'>  proto tcp
</span><span class='line'>  cert eshore-cu.crt
</span><span class='line'>  key eshore-cu.key 
</span><span class='line'>  dh dh.pem
</span><span class='line'>  # 在客户端额外添加这条路由到VPN
</span><span class='line'>  push "route 192.168.0.0 255.255.255.0"
</span><span class='line'>  # 和AS一样，会添加0.0.0.0到VPN的路由。默认走VPN
</span><span class='line'>  ;push "redirect-gateway def1 bypass-dhcp"
</span><span class='line'>  user nobody
</span><span class='line'>  group nobody
</span><span class='line'>
</span><span class='line'>[root@cu2 pki]# cd /etc/openvpn/
</span><span class='line'>[root@cu2 openvpn]# /usr/local/openvpn/sbin/openvpn --config /etc/openvpn/server.conf 
</span><span class='line'>[root@cu2 openvpn]# /usr/local/openvpn/sbin/openvpn --daemon --config server.conf </span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装客户端：</li>
</ul>


<p><a href="https://openvpn.net/index.php/open-source/downloads.html">https://openvpn.net/index.php/open-source/downloads.html</a> 下载安装对应的版本。</p>

<p>拷贝sample-config/client.ovpn和服务端的ca.crt、openvpn.crt、openvpn.key到config目录下面。</p>

<p>修改client.ovpn:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proto tcp
</span><span class='line'>remote webcu2 1194
</span><span class='line'>cert openvpn.crt
</span><span class='line'>key openvpn.key</span></code></pre></td></tr></table></div></figure>


<p>然后启动 <strong>OpenVPN GUI</strong> ，右键connect就行了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ route print
</span><span class='line'>...
</span><span class='line'>IPv4 路由表
</span><span class='line'>===========================================================================
</span><span class='line'>活动路由:
</span><span class='line'>网络目标        网络掩码          网关       接口   跃点数
</span><span class='line'>          0.0.0.0          0.0.0.0      192.168.1.1    192.168.1.102     20
</span><span class='line'>         10.8.0.1  255.255.255.255         10.8.0.5         10.8.0.6     20
</span><span class='line'>         10.8.0.4  255.255.255.252            在链路上          10.8.0.6    276
</span><span class='line'>         10.8.0.6  255.255.255.255            在链路上          10.8.0.6    276
</span><span class='line'>         10.8.0.7  255.255.255.255            在链路上          10.8.0.6    276
</span><span class='line'>      192.168.0.0    255.255.255.0         10.8.0.5         10.8.0.6     20
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h2>问题</h2>

<ul>
<li>连接到VPN服务端的机器是没有问题，但是不能访问该机器的应用（端口不同）</li>
</ul>


<p>被防火墙限制了，在服务端把10.8.0.0/24加入到防火墙允许。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -A INPUT -s 10.8.0.0/24 -j ACCEPT </span></code></pre></td></tr></table></div></figure>


<ul>
<li>不能访问服务端其他机器</li>
</ul>


<p>在iptables上增加转发</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE</span></code></pre></td></tr></table></div></figure>


<p>查看iptables规则：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -nL -t nat</span></code></pre></td></tr></table></div></figure>


<p>测试下:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ping cu3
</span><span class='line'>
</span><span class='line'>正在 Ping cu3 [192.168.0.148] 具有 32 字节的数据:
</span><span class='line'>来自 192.168.0.148 的回复: 字节=32 时间=5ms TTL=63
</span><span class='line'>来自 192.168.0.148 的回复: 字节=32 时间=5ms TTL=63</span></code></pre></td></tr></table></div></figure>


<p>其他（参数，未实践，记录下来）</p>

<blockquote><p>必须在服务器端的内网网关上将到10.8.0.0/24网段的路由指向到openvpn服务器，不然从服务器端内网其他机器根本找不到去往10.8.0.0/24网段的路由。这里又分两种情况，一种是服务端有内网网关设备的（按如上说法即可）；一种是服务端内网没有网关设备，即服务器通过交换机相连，相互通讯靠广播的情况。我的就是这种情况。需要在想访问的server上增加到10.8.0.0/24的路由，如下</p>

<p>route add -net 10.8.0.0/24 gw 192.168.1.211    #1.211为openvpn服务器的内网IP</p>

<p>Make sure that you&rsquo;ve enabled IP and TUN/TAP forwarding on the OpenVPN server machine.
确定开启了转发功能，然后在openvpn服务器Iptables添加如下两条规则</p>

<p>iptables -A FORWARD -i tun0 -s 10.8.0.0/24 -j ACCEPT    #简单说，允许数据从客户端到后端server
iptables -A FORWARD -i em2 -d 10.8.0.0/24 -j ACCEPT    #允许数据从后端server到客户端</p></blockquote>

<h2>参考</h2>

<ul>
<li><a href="https://openvpn.net/index.php/open-source/documentation/howto.html">https://openvpn.net/index.php/open-source/documentation/howto.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html">http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html</a></li>
<li><a href="http://www.linuxquestions.org/questions/linux-networking-3/openvpn-conencts-but-can%27t-ping-servers-on-the-other-network-660610/">http://www.linuxquestions.org/questions/linux-networking-3/openvpn-conencts-but-can%27t-ping-servers-on-the-other-network-660610/</a></li>
<li><a href="http://www.ilanni.com/?p=9877">http://www.ilanni.com/?p=9877</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html">http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html</a></li>
<li><a href="http://kaifly.blog.51cto.com/3209616/1367591">http://kaifly.blog.51cto.com/3209616/1367591</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
