<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-04-12T21:20:57+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Spark-on-yarn内存分配]]></title>
    <link href="http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate/"/>
    <updated>2016-04-11T19:44:51+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate</id>
    <content type="html"><![CDATA[<p>上次写了一篇关于配置参数是如何影响mapreduce的实际调度的<a href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/">参考</a>：</p>

<ul>
<li>opts（yarn.app.mapreduce.am.command-opts、mapreduce.map.java.opts、mapreduce.reduce.java.opts）是实际运行程序是内存参数。</li>
<li>memory（yarn.app.mapreduce.am.resource.mb、mapreduce.map.memory.mb、mapreduce.reduce.memory.mb）是用于ResourceManager计算集群资源使用和调度。</li>
</ul>


<p>了解参数区别，就没有再深究task内存的问题了。</p>

<h2>新问题-内存分配</h2>

<p>这次又遇到内存问题：spark使用yarn-client的方式运行时，spark有memoryOverhead的设置，但是加了额外的内存后，再经过集群调度内存浪费严重，对于本来就小内存的集群来说完全无法接受。</p>

<ul>
<li>am默认是512加上384 overhead，也就是896m。但是调度后am分配内存资源为1024。</li>
<li>executor默认是1024加上384，等于1408M。单调度后executor分配内存资源为2048。</li>
</ul>


<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-0.png" alt="" /></p>

<p>从appmaster的日志可以看出来请求的内存大小是1408：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-1.png" alt="" /></p>

<p><strong>一个executor就浪费了500M，本来可以跑4个executor的但现在只能执行3个！</strong></p>

<p>关于内存参数的具体含义查看官网： <a href="http://spark.apache.org/docs/latest/running-on-yarn.html">spark-on-yarn</a> 和 <a href="http://hadoop.apache.org/docs/r2.6.4/hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a></p>

<table>
<thead>
<tr>
<th></th>
<th style="text-align:center;"> <em>参数</em>                                  </th>
<th></th>
<th style="text-align:left;"> <em>值</em></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.am.memory                    </td>
<td></td>
<td style="text-align:left;"> 512m</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.driver.memory                     </td>
<td></td>
<td style="text-align:left;"> 1g</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.executor.memoryOverhead      </td>
<td></td>
<td style="text-align:left;"> executorMemory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.driver.memoryOverhead        </td>
<td></td>
<td style="text-align:left;"> driverMemory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> spark.yarn.am.memoryOverhead            </td>
<td></td>
<td style="text-align:left;"> AM memory * 0.10, with minimum of 384</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.nodemanager.resource.memory-mb     </td>
<td></td>
<td style="text-align:left;"> 8192</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.scheduler.minimum-allocation-mb    </td>
<td></td>
<td style="text-align:left;"> 1024</td>
</tr>
<tr>
<td></td>
<td style="text-align:center;"> yarn.scheduler.maximum-allocation-mb    </td>
<td></td>
<td style="text-align:left;"> 8192</td>
</tr>
</tbody>
</table>


<p>分配的内存看着像是 <strong>最小分配内存</strong> 的整数倍。把 <code>yarn.scheduler.minimum-allocation-mb</code> 修改为512，重启yarn再运行，executor的分配的内存果真减少到1536(<strong>512*3</strong>)。</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-3.png" alt="" /></p>

<p>同时 <a href="http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html">http://blog.javachen.com/2015/06/09/memory-in-spark-on-yarn.html</a> 这篇文章也讲 <strong>在YARN中，Container申请的内存大小必须为yarn.scheduler.minimum-allocation-mb的整数倍</strong> 。我们不去猜，调试下调度代码，看看究竟是什么情况。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ sbin/yarn-daemon.sh stop resourcemanager 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ grep "minimum-allocation-mb" -1 yarn-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;&lt;value&gt;512&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ export YARN_RESOURCEMANAGER_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000"
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ sbin/yarn-daemon.sh start resourcemanager </span></code></pre></td></tr></table></div></figure>


<p>本地eclipse在 <code>CapacityScheduler#allocate</code> 打断点，然后跑任务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2 where month=201512;</span></code></pre></td></tr></table></div></figure>


<p>AppMaster内存分配：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-appmaster.png" alt="" /></p>

<p>Executor内存分配：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-memory/hive-on-spark-memory-allocate-executor.png" alt="" /></p>

<p>request进到allocate后，最终调用 <code>DefaultResourceCalculator.normalize</code> 重新计算了一遍请求需要的资源，把内存调整了。默认的DefaultResourceCalculator可以通过 capacity-scheduler.xml 的 <code>yarn.scheduler.capacity.resource-calculator</code> 来修改。</p>

<p>具体代码调度过程如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public Allocation allocate(ApplicationAttemptId applicationAttemptId,
</span><span class='line'>      List&lt;ResourceRequest&gt; ask, List&lt;ContainerId&gt; release, 
</span><span class='line'>      List&lt;String&gt; blacklistAdditions, List&lt;String&gt; blacklistRemovals) {
</span><span class='line'>    ...
</span><span class='line'>    // Sanity check
</span><span class='line'>    SchedulerUtils.normalizeRequests(
</span><span class='line'>        ask, getResourceCalculator(), getClusterResource(),
</span><span class='line'>        getMinimumResourceCapability(), maximumAllocation);
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static void normalizeRequest(
</span><span class='line'>      ResourceRequest ask, 
</span><span class='line'>      ResourceCalculator resourceCalculator, 
</span><span class='line'>      Resource clusterResource,
</span><span class='line'>      Resource minimumResource,
</span><span class='line'>      Resource maximumResource,
</span><span class='line'>      Resource incrementResource) {
</span><span class='line'>    Resource normalized = 
</span><span class='line'>        Resources.normalize(
</span><span class='line'>            resourceCalculator, ask.getCapability(), minimumResource,
</span><span class='line'>            maximumResource, incrementResource);
</span><span class='line'>    ask.setCapability(normalized);
</span><span class='line'>  }   
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static Resource normalize(
</span><span class='line'>      ResourceCalculator calculator, Resource lhs, Resource min,
</span><span class='line'>      Resource max, Resource increment) {
</span><span class='line'>    return calculator.normalize(lhs, min, max, increment);
</span><span class='line'>  }
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public Resource normalize(Resource r, Resource minimumResource,
</span><span class='line'>      Resource maximumResource, Resource stepFactor) {
</span><span class='line'>    int normalizedMemory = Math.min(
</span><span class='line'>        roundUp(
</span><span class='line'>            Math.max(r.getMemory(), minimumResource.getMemory()),
</span><span class='line'>            stepFactor.getMemory()),
</span><span class='line'>            maximumResource.getMemory());
</span><span class='line'>    return Resources.createResource(normalizedMemory);
</span><span class='line'>  }
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>  public static int roundUp(int a, int b) {
</span><span class='line'>    return divideAndCeil(a, b) * b;
</span><span class='line'>  }
</span><span class='line'>  </span></code></pre></td></tr></table></div></figure>


<p></p>

<h2>小结</h2>

<p>今天又重新认识一个yarn参数 <code>yarn.scheduler.minimum-allocation-mb</code> ，不仅仅是最小分配的内存，同时分配的资源也是minimum-allocation-mb的整数倍，还告诉我们 <code>yarn.nodemanager.resource.memory-mb</code> 也最好是minimum-allocation-mb的整数倍。</p>

<p>间接的学习了新的参数，可以通过 <code>yarn.scheduler.capacity.resource-calculator</code> 参数 来修改 CapacityScheduler 调度器的资源计算类。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive-on-spark Snappy on Centos5]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/"/>
    <updated>2016-04-08T22:27:06+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark</id>
    <content type="html"><![CDATA[<p>hive的assembly包就是一个坑货！既然是一个单独的可运行的jar放到lib包下面干嘛呢！！纯属记录工作过程总的经历，想找干货的飘过吧！！</p>

<p><br/></p>

<p>上周支撑部门其他项目的hadoop项目，由于 <strong>hive mr</strong> 比较慢，想用spark试一试看能不能优化。但是系统使用Centos5，我们项目使用的是Centos6。按部就班的编译呗，hive-on-saprk启用SNAPPY的必要条件：</p>

<ul>
<li>hadoop使用snappy需要native的支持，首先当然是Centos5上编译hadoop。(现在看来可以不必要，但每次hdfs命令都提示我native的错误就很不爽)</li>
<li>hive增加spark。</li>
</ul>


<p>各程序版本信息：</p>

<ul>
<li>hadoop-2.6.3</li>
<li>hive-1.2.1</li>
<li>spark-1.3.1</li>
<li>centos5.4</li>
</ul>


<h2>编译hadoop-snappy</h2>

<ul>
<li>centos5手动</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost snappy-1.1.3]# ./autogen.sh 
</span><span class='line'>Remember to add `AC_PROG_LIBTOOL' to `configure.ac'.
</span><span class='line'>You should update your `aclocal.m4' by running aclocal.
</span><span class='line'>libtoolize: `config.guess' exists: use `--force' to overwrite
</span><span class='line'>libtoolize: `config.sub' exists: use `--force' to overwrite
</span><span class='line'>libtoolize: `ltmain.sh' exists: use `--force' to overwrite
</span><span class='line'>Makefile.am:4: Libtool library used but `LIBTOOL' is undefined
</span><span class='line'>Makefile.am:4: 
</span><span class='line'>Makefile.am:4: The usual way to define `LIBTOOL' is to add `AC_PROG_LIBTOOL'
</span><span class='line'>Makefile.am:4: to `configure.ac' and run `aclocal' and `autoconf' again.
</span><span class='line'>Makefile.am:20: `dist_doc_DATA' is used but `docdir' is undefined</span></code></pre></td></tr></table></div></figure>


<p>在centos5上面手动编译搞不定，不是专业写C的，这些问题就是天书啊(查了很多资料，试了很多方法都没通)！！ <strong>Snappy可以在centos6上面编译，编译好以后再centos5上面也能用，编译hadoop-snappy也是ok的</strong> 。</p>

<ul>
<li>centos5-rpm</li>
</ul>


<p>这里直接用rpm安装snappy。觉得创建虚拟机麻烦的话，也可以用docker。docker不同版本的centos下载： <a href="https://github.com/CentOS/sig-cloud-instance-images/">https://github.com/CentOS/sig-cloud-instance-images/</a> 。然后docker共享host主机的文件： <code>docker run -ti -v /home/hadoop:/home/hadoop -v /opt:/opt -v /data:/data centos:centos5 /bin/bash</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@8fb11f6b3ced ~]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 5.11 (Final)
</span><span class='line'>
</span><span class='line'>https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy
</span><span class='line'>https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy-devel
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ivh snappy-1.0.5-1.el5.x86_64.rpm 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ivh snappy-devel-1.0.5-1.el5.x86_64.rpm                                                                                  
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# rpm -ql snappy-devel snappy
</span><span class='line'>/usr/include/snappy-c.h
</span><span class='line'>/usr/include/snappy-sinksource.h
</span><span class='line'>/usr/include/snappy-stubs-public.h
</span><span class='line'>/usr/include/snappy.h
</span><span class='line'>/usr/lib64/libsnappy.so
</span><span class='line'>/usr/share/doc/snappy-devel-1.0.5
</span><span class='line'>/usr/share/doc/snappy-devel-1.0.5/format_description.txt
</span><span class='line'>/usr/lib64/libsnappy.so.1
</span><span class='line'>/usr/lib64/libsnappy.so.1.1.3
</span><span class='line'>/usr/share/doc/snappy-1.0.5
</span><span class='line'>/usr/share/doc/snappy-1.0.5/AUTHORS
</span><span class='line'>/usr/share/doc/snappy-1.0.5/COPYING
</span><span class='line'>/usr/share/doc/snappy-1.0.5/ChangeLog
</span><span class='line'>/usr/share/doc/snappy-1.0.5/NEWS
</span><span class='line'>/usr/share/doc/snappy-1.0.5/README
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export JAVA_HOME=/opt/jdk1.7.0_17
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export MAVEN_HOME=/opt/apache-maven-3.3.9
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]#  
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# yum install which gcc gcc-c++ zlib-devel make -y
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd protobuf-2.5.0
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# ./configure 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# make && make install
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# which protoc
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# 
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# yum install cmake openssl openssl-devel -y
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-2.6.3-src/
</span><span class='line'># bundle.snappy和snappy.lib一起使用，可以把系统的snappy.so文件拷贝到lib/native下面（方便拷贝）
</span><span class='line'># &lt;http://grepcode.com/file/repo1.maven.org/maven2/org.apache.hadoop/hadoop-project-dist/2.6.0/META-INF/maven/org.apache.hadoop/hadoop-project-dist/pom.xml&gt;
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# mvn clean package -Dmaven.javadoc.skip=true -DskipTests -Drequire.snappy=true -Dbundle.snappy=true -Dsnappy.lib=/usr/lib64 -Pdist,native
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# ll hadoop-dist/target/hadoop-2.6.3/lib/native/
</span><span class='line'>total 3808
</span><span class='line'>-rw-r--r-- 1 root root 1036552 Apr 12 09:35 libhadoop.a
</span><span class='line'>-rw-r--r-- 1 root root 1212600 Apr 12 09:36 libhadooppipes.a
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libhadoop.so -&gt; libhadoop.so.1.0.0
</span><span class='line'>-rwxr-xr-x 1 root root  613267 Apr 12 09:35 libhadoop.so.1.0.0
</span><span class='line'>-rw-r--r-- 1 root root  401836 Apr 12 09:36 libhadooputils.a
</span><span class='line'>-rw-r--r-- 1 root root  364026 Apr 12 09:35 libhdfs.a
</span><span class='line'>lrwxrwxrwx 1 root root      16 Apr 12 09:35 libhdfs.so -&gt; libhdfs.so.0.0.0
</span><span class='line'>-rwxr-xr-x 1 root root  229672 Apr 12 09:35 libhdfs.so.0.0.0
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libsnappy.so -&gt; libsnappy.so.1.1.3
</span><span class='line'>lrwxrwxrwx 1 root root      18 Apr 12 09:35 libsnappy.so.1 -&gt; libsnappy.so.1.1.3
</span><span class='line'>-rwxr-xr-x 1 root root   21568 Apr 12 09:35 libsnappy.so.1.1.3
</span><span class='line'>
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-dist/target/hadoop-2.6.3/
</span><span class='line'>[root@8fb11f6b3ced hadoop-2.6.3]# bin/hadoop checknative -a
</span><span class='line'>16/04/12 09:38:29 WARN bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version
</span><span class='line'>16/04/12 09:38:29 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
</span><span class='line'>Native library checking:
</span><span class='line'>hadoop:  true /data/bigdata/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3/lib/native/libhadoop.so.1.0.0
</span><span class='line'>zlib:    true /lib64/libz.so.1
</span><span class='line'>snappy:  true /data/bigdata/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3/lib/native/libsnappy.so.1
</span><span class='line'>lz4:     true revision:99
</span><span class='line'>bzip2:   false 
</span><span class='line'>openssl: false org.apache.hadoop.crypto.OpensslCipher.initIDs()V
</span><span class='line'>16/04/12 09:38:29 INFO util.ExitUtil: Exiting with status 1</span></code></pre></td></tr></table></div></figure>


<p>把native下面的打tar包，然后替换生成的。一切都是正常的。接下来坑爹的是spark-snappy，具体的说应该是hive-assmably坑！！</p>

<h2>hive-on-spark snappy</h2>

<p>spark官网也没讲使用snappy需要做什么额外的配置（默认spark.io.compression.codec默认为snappy）。部署后设置 <code>hive.execution.engine=spark</code> 执行spark查询，立马就报错了 <strong> Caused by: java.lang.UnsatisfiedLinkError: /tmp/snappy-1.0.5-libsn
appyjava.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9&#8217; not found (required by /tmp/snappy-1.0.5-libsnappyjava.so)</strong> 从错误堆栈看与hadoop-native-snappy没关系，而是一个snappy-java的包。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX
</span><span class='line'>GLIBCXX_3.4
</span><span class='line'>GLIBCXX_3.4.1
</span><span class='line'>GLIBCXX_3.4.2
</span><span class='line'>GLIBCXX_3.4.3
</span><span class='line'>GLIBCXX_3.4.4
</span><span class='line'>GLIBCXX_3.4.5
</span><span class='line'>GLIBCXX_3.4.6
</span><span class='line'>GLIBCXX_3.4.7
</span><span class='line'>GLIBCXX_3.4.8
</span><span class='line'>GLIBCXX_FORCE_NEW</span></code></pre></td></tr></table></div></figure>


<p>确实缺少GLIBCXX_3.4.9，最新版本的centos5.11也是一样输出的。</p>

<p>spark的配置为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.3.1-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'>spark.master  yarn-client
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.minExecutors    2 
</span><span class='line'>spark.dynamicAllocation.maxExecutors    18
</span><span class='line'>
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>spark.master=yarn-client
</span><span class='line'>spark.driver.memory=5g
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address file1:18080
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span><span class='line'>spark.kryoserializer.buffer.max    512m</span></code></pre></td></tr></table></div></figure>


<p>报错的具体信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>- 16/04/12 20:20:08 INFO storage.BlockManagerMaster: Registered BlockManager
</span><span class='line'>- java.lang.reflect.InvocationTargetException
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>-        at java.lang.reflect.Method.invoke(Method.java:606)
</span><span class='line'>-        at org.xerial.snappy.SnappyLoader.loadNativeLibrary(SnappyLoader.java:322)
</span><span class='line'>-        at org.xerial.snappy.SnappyLoader.load(SnappyLoader.java:229)
</span><span class='line'>-        at org.xerial.snappy.Snappy.&lt;clinit&gt;(Snappy.java:48)
</span><span class='line'>-        at org.apache.spark.io.SnappyCompressionCodec.&lt;init&gt;(CompressionCodec.scala:150)
</span><span class='line'>-        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
</span><span class='line'>-        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
</span><span class='line'>-        at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:68)
</span><span class='line'>-        at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:60)
</span><span class='line'>-        at org.apache.spark.scheduler.EventLoggingListener.&lt;init&gt;(EventLoggingListener.scala:67)
</span><span class='line'>-        at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:400)
</span><span class='line'>-        at org.apache.spark.api.java.JavaSparkContext.&lt;init&gt;(JavaSparkContext.scala:61)
</span><span class='line'>-        at org.apache.hive.spark.client.RemoteDriver.&lt;init&gt;(RemoteDriver.java:169)
</span><span class='line'>-        at org.apache.hive.spark.client.RemoteDriver.main(RemoteDriver.java:556)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>-        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>-        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>-        at java.lang.reflect.Method.invoke(Method.java:606)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
</span><span class='line'>-        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
</span><span class='line'>- Caused by: java.lang.UnsatisfiedLinkError: /tmp/snappy-1.0.5-libsnappyjava.so: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9' not found (required by /tmp/snappy-1.0.5-libs
</span><span class='line'>-        at java.lang.ClassLoader$NativeLibrary.load(Native Method)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary1(ClassLoader.java:1965)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1890)
</span><span class='line'>-        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1851)
</span><span class='line'>-        at java.lang.Runtime.load0(Runtime.java:795)
</span><span class='line'>-        at java.lang.System.load(System.java:1062)
</span><span class='line'>-        at org.xerial.snappy.SnappyNativeLoader.load(SnappyNativeLoader.java:39)
</span><span class='line'>-        ... 28 more</span></code></pre></td></tr></table></div></figure>


<p>spark用到了snappy-java来处理snappy的解压缩。用jinfo查看SparkSubmit进程的classpath，用这个classpath跑helloworld确实是报错的，但是单独用hadoop-common下面的 snappy-java-1.0.4.1.jar 是没问题的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 snappy-java-test]$ cat Hello.java 
</span><span class='line'>import org.xerial.snappy.Snappy;
</span><span class='line'>
</span><span class='line'>public class Hello { 
</span><span class='line'>public static void main(String[] args) throws Exception {
</span><span class='line'>String input = "Hello snappy-java!";
</span><span class='line'>
</span><span class='line'>byte[] compressed = Snappy.compress(input.getBytes("utf-8"));
</span><span class='line'>byte[] uncompressed = Snappy.uncompress(compressed);
</span><span class='line'>
</span><span class='line'>String result = new String(uncompressed, "utf-8");
</span><span class='line'>System.out.println(result);
</span><span class='line'>}
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[hadoop@file1 snappy-java-test]$ java -cp .:/home/hadoop/tools/hadoop-2.6.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar Hello
</span><span class='line'>Hello snappy-java!</span></code></pre></td></tr></table></div></figure>


<p>而而而，classpath中就只有hadoop-common和hadoop-mapreduce下面有snappy-java包，并且都是1.0.4.1，那TMD的使用SparkSubmit-classpath加载Snappy是哪个jar里面的呢？</p>

<p>调整后的helloworld为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 snappy-java-test]$ cat Hello.java 
</span><span class='line'>import org.xerial.snappy.Snappy;
</span><span class='line'>
</span><span class='line'>public class Hello { 
</span><span class='line'>public static void main(String[] args) throws Exception {
</span><span class='line'>String input = "Hello snappy-java!";
</span><span class='line'>
</span><span class='line'>System.out.println(Snappy.class.getProtectionDomain());
</span><span class='line'>byte[] compressed = Snappy.compress(input.getBytes("utf-8"));
</span><span class='line'>byte[] uncompressed = Snappy.uncompress(compressed);
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>String result = new String(uncompressed, "utf-8");
</span><span class='line'>System.out.println(result);
</span><span class='line'>}
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>添加getProtectionDomain查看加载类的jar。再编译跑一次，这次终于找到真凶了！！hive-assembly，assembly包还放在lib下面就tmd的是一个坑货！！hive-exec的guava已经坑了很多人了，这次换hive-jdbc了！！</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-centos5-snappy-hive-jdbc.png" alt="" /></p>

<p>如果指定使用hadoop编译依赖的snappy.so.1.1.3动态链接库会出现版本不兼容的问题。还是干掉hive-jdbc-standalone吧。。。囧</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 查看源码SnappyLoader#loadSnappySystemProperties，可以通过配置指定使用系统动态链接库
</span><span class='line'>[hadoop@file1 snappy-java-test]$ cat org-xerial-snappy.properties 
</span><span class='line'>org.xerial.snappy.use.systemlib=true
</span><span class='line'>[hadoop@file1 snappy-java-test]$ ln -s /home/hadoop/tools/hadoop-2.6.3/lib/native/libsnappy.so libsnappyjava.so
</span><span class='line'>[hadoop@file1 snappy-java-test]$ ll
</span><span class='line'>总计 1240
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop     854 04-08 10:11 Hello.class
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop     408 04-08 10:11 Hello.java
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop      55 04-12 19:37 libsnappyjava.so -&gt; /home/hadoop/tools/hadoop-2.6.3/lib/native/libsnappy.so
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop      37 04-12 19:15 org-xerial-snappy.properties
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 1251514 2014-04-29 snappy-java-1.0.5.jar
</span><span class='line'>[hadoop@file1 snappy-java-test]$ java -cp .:snappy-java-1.0.5.jar -Djava.library.path=. Hello
</span><span class='line'>ProtectionDomain  (file:/home/hadoop/snappy-java-test/snappy-java-1.0.5.jar &lt;no signer certificates&gt;)
</span><span class='line'> sun.misc.Launcher$AppClassLoader@333cb1eb
</span><span class='line'> &lt;no principals&gt;
</span><span class='line'> java.security.Permissions@7377711 (
</span><span class='line'> ("java.io.FilePermission" "/home/hadoop/snappy-java-test/snappy-java-1.0.5.jar" "read")
</span><span class='line'> ("java.lang.RuntimePermission" "exitVM")
</span><span class='line'>)
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Exception in thread "main" java.lang.UnsatisfiedLinkError: org.xerial.snappy.SnappyNative.maxCompressedLength(I)I
</span><span class='line'>        at org.xerial.snappy.SnappyNative.maxCompressedLength(Native Method)
</span><span class='line'>        at org.xerial.snappy.Snappy.maxCompressedLength(Snappy.java:320)
</span><span class='line'>        at org.xerial.snappy.Snappy.rawCompress(Snappy.java:333)
</span><span class='line'>        at org.xerial.snappy.Snappy.compress(Snappy.java:92)
</span><span class='line'>        at Hello.main(Hello.java:8)
</span><span class='line'>      </span></code></pre></td></tr></table></div></figure>


<p>删掉jdbc-standalone后，hive-on-spark就ok了。如果你无法下手删除 hive-jdbc-1.2.1-standalone.jar ，那就把 <code>spark.io.compression.codec</code> 改成 <code>lz4</code> 等压缩也是可以的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@file1 ~]$ hive
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/home/hadoop/tools/apache-hive-1.2.1-bin/conf/hive-log4j.properties
</span><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_info where edate=20160411;
</span><span class='line'>Query ID = hadoop_20160412205338_2c95c5fd-af50-42ba-8681-e154e4b74cb1
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 69afc030-fa1f-4fdf-81ef-12bdca411a4f
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-04-12 20:54:11,367 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:14,421 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:17,457 Stage-0_0: 0(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:19,486 Stage-0_0: 2(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:20,497 Stage-0_0: 3(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:21,509 Stage-0_0: 5(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:22,520 Stage-0_0: 6(+2)/234    Stage-1_0: 0/1
</span><span class='line'>2016-04-12 20:54:23,532 Stage-0_0: 7(+2)/234    Stage-1_0: 0/1</span></code></pre></td></tr></table></div></figure>


<h2>小结</h2>

<p>第一，hive的assembly的包太tmd的坑了。第二，以后找java具体加载那个类，可以通过 class.getProtectionDomain 来获取了。第三，又多尝试一个环境部署hadoop。呵呵</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[puppet4.4.1入门安装]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/puppet-install/"/>
    <updated>2016-04-08T19:49:32+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/puppet-install</id>
    <content type="html"><![CDATA[<p>网上资料比较多比较老，基本操作可以借鉴。安装Puppet最简单的方式就是用yum来安装(操作系统centos6），由于天朝的特殊环境最好建立本地仓库。本文记录我自己安装过程的过程，先介绍本地仓库创建，然后介绍Puppet环境的搭建。</p>

<p>操作系统：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.5 (Final)</span></code></pre></td></tr></table></div></figure>


<h2>本地仓库搭建</h2>

<p>Puppet4所有依赖都进行统一打包，其实通过rpm就能直接安装。为了体现下高大山、并且Puppet内部的项目之间是有依赖的。这里先使用createrepo创建本地库。</p>

<p>createrepo其实就是用来创建目录下rpm文件的索引数据(repodata)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# yum install createrepo
</span><span class='line'>
</span><span class='line'># 下载系统对应的puppet-pc1的包: https://yum.puppetlabs.com/el/6/PC1/x86_64/ 全部最新版本
</span><span class='line'>[root@hadoop-master2 repo]# ls -1
</span><span class='line'>puppet-agent-1.4.1-1.el6.x86_64.rpm
</span><span class='line'>puppet-dashboard-1.2.23-0.1rc3.el6.noarch.rpm
</span><span class='line'>puppetdb-4.0.0-1.el6.noarch.rpm
</span><span class='line'>puppetdb-termini-3.2.4-1.el6.noarch.rpm
</span><span class='line'>puppetdb-terminus-3-1.el6.noarch.rpm
</span><span class='line'>puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# createrepo .
</span><span class='line'>Spawning worker 0 with 6 pkgs
</span><span class='line'>Workers Finished
</span><span class='line'>Gathering worker results
</span><span class='line'>
</span><span class='line'>Saving Primary metadata
</span><span class='line'>Saving file lists metadata
</span><span class='line'>Saving other metadata
</span><span class='line'>Generating sqlite DBs
</span><span class='line'>Sqlite DBs complete
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=file:///opt/puppetlabs/repo
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span></code></pre></td></tr></table></div></figure>


<p>查看local下的rpm包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 repo]# yum clean all
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Cleaning repos: base epel extras pgdg94 puppet-local updates
</span><span class='line'>Cleaning up Everything
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum list all | grep "puppet-local"
</span><span class='line'>puppet-agent.x86_64                         1.4.1-1.el6                  @puppet-local
</span><span class='line'>puppet-dashboard.noarch                     1.2.23-0.1rc3.el6            @puppet-local
</span><span class='line'>puppetdb.noarch                             4.0.0-1.el6                  @puppet-local
</span><span class='line'>puppetdb-termini.noarch                     3.2.4-1.el6                  @puppet-local
</span><span class='line'>puppetserver.noarch                         2.3.1-1.el6                  @puppet-local
</span><span class='line'>puppetdb-terminus.noarch                    3-1.el6                      puppet-local
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum search puppet</span></code></pre></td></tr></table></div></figure>


<p>网上资料还有安装 <code>yum-priorities</code> 来设置repo优先级的。我这里没有包冲突问题所以并没有安装这个。</p>

<h2>单机安装</h2>

<p>安装前翻一翻官网的文档： <a href="https://docs.puppet.com/puppetserver/latest/install_from_packages.html">https://docs.puppet.com/puppetserver/latest/install_from_packages.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先看看 puppet-agent 和 puppetserver 的依赖
</span><span class='line'>[root@hadoop-master2 repo]# yum deplist puppet-agent
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.aliyun.com
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'> * extras: mirrors.aliyun.com
</span><span class='line'> * updates: mirrors.aliyun.com
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: tar
</span><span class='line'>   provider: tar.x86_64 2:1.23-13.el6
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: readline
</span><span class='line'>   provider: readline.i686 6.0-4.el6
</span><span class='line'>   provider: readline.x86_64 6.0-4.el6
</span><span class='line'>  dependency: util-linux
</span><span class='line'>   provider: util-linux-ng.i686 2.17.2-12.18.el6
</span><span class='line'>   provider: util-linux-ng.x86_64 2.17.2-12.18.el6
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 repo]# yum deplist puppetserver
</span><span class='line'>Loaded plugins: fastestmirror, security
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.aliyun.com
</span><span class='line'> * epel: ftp.cuhk.edu.hk
</span><span class='line'> * extras: mirrors.aliyun.com
</span><span class='line'> * updates: mirrors.aliyun.com
</span><span class='line'>Finding dependencies: 
</span><span class='line'>package: puppetserver.noarch 2.3.1-1.el6
</span><span class='line'>  dependency: /bin/bash
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: java-1.8.0-openjdk-headless
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.45-35.b13.el6
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-0.b16.el6_6
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-1.b16.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.51-3.b16.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.65-0.b17.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.71-1.b15.el6_7
</span><span class='line'>   provider: java-1.8.0-openjdk-headless.x86_64 1:1.8.0.77-0.b03.el6_7
</span><span class='line'>  dependency: puppet-agent &gt;= 1.4.0
</span><span class='line'>   provider: puppet-agent.x86_64 1.4.1-1.el6
</span><span class='line'>  dependency: net-tools
</span><span class='line'>   provider: net-tools.x86_64 1.60-110.el6_2
</span><span class='line'>  dependency: /usr/bin/env
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6
</span><span class='line'>   provider: coreutils.x86_64 8.4-37.el6_7.3
</span><span class='line'>  dependency: /bin/sh
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6
</span><span class='line'>   provider: bash.x86_64 4.1.2-33.el6_7.1
</span><span class='line'>  dependency: chkconfig
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6
</span><span class='line'>   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
</span><span class='line'>
</span><span class='line'># 安装
</span><span class='line'>[root@hadoop-master2 repo]# yum install puppetserver
</span><span class='line'>
</span><span class='line'># 安装好后，查看各版本软件版本信息
</span><span class='line'>[root@hadoop-master2 repo]# puppet -V
</span><span class='line'>4.4.1
</span><span class='line'>[root@hadoop-master2 repo]# facter -v
</span><span class='line'>3.1.5 (commit b5c2cf9b2ac290cb17fcadea19b467a39e17c1fd)
</span><span class='line'>[root@hadoop-master2 repo]# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1</span></code></pre></td></tr></table></div></figure>


<p>puppetserver依赖puppet-agent，而puppet-agent是一个all-in-one的assembly的包。所以服务端安装puppetserver就行了。客户端仅安装puppet-agent即可。</p>

<p>Puppet4的目录进行比较大的调整，程序路径为 <code>/opt/puppetlabs</code> ，配置路径为 <code>/etc/puppetlabs</code> 。如果你看的是puppet3资料，对照查看官网 <a href="https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html">Where Did Everything Go in Puppet 4.x?</a> 了解各程序的目录位置。</p>

<h2>单机版HelloWorld</h2>

<p>单机模式不需要认证，当做学习调试环境挺好的：方便简单。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 manifests]# vi helloworld.pp
</span><span class='line'>notify { 'greeting':
</span><span class='line'>  message =&gt; 'Hello, world!'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 manifests]# puppet apply helloworld.pp 
</span><span class='line'>Notice: Compiled catalog for hadoop-master2.localdomain in environment production in 0.03 seconds
</span><span class='line'>Notice: Hello, world!
</span><span class='line'>Notice: /Stage[main]/Main/Notify[greeting]/message: defined 'message' as 'Hello, world!'
</span><span class='line'>Notice: Applied catalog in 0.04 seconds
</span><span class='line'>
</span><span class='line'># 可以用resource根据当前环境生成配置
</span><span class='line'>[root@hadoop-master2 manifests]# puppet resource user hadoop
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  gid              =&gt; '500',
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; 'XXXXXX',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  uid              =&gt; '500',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># 状态变更
</span><span class='line'>[root@hadoop-master2 puppetlabs]# bin/puppet resource service puppet ensure=running enable=false
</span><span class='line'>Notice: /Service[puppet]/enable: enable changed 'true' to 'false'
</span><span class='line'>service { 'puppet':
</span><span class='line'>  ensure =&gt; 'running',
</span><span class='line'>  enable =&gt; 'false',
</span><span class='line'>}
</span><span class='line'>[root@hadoop-master2 puppetlabs]# chkconfig --list | grep puppet
</span><span class='line'>puppet          0:off   1:off   2:off   3:off   4:off   5:off   6:off
</span><span class='line'>puppetserver    0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span></code></pre></td></tr></table></div></figure>


<h2>CS模式配置</h2>

<p>这里完全模拟生产环境情况(内网)，首先搭建两个本地仓库：centos，puppet。puppet依赖RPM根据具体情况下载即可，我这里用的是centos6.5。</p>

<p>搭建私有仓库：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>增加 java-1.8.0-openjdk-headless 和 tzdata-java-2014g(iso带的2013g不适配)
</span><span class='line'>[root@hadoop-master2 repo]# ll
</span><span class='line'>total 142344
</span><span class='line'>-rw-r--r-- 1 root root 33135156 Apr  9 21:47 java-1.8.0-openjdk-headless-1.8.0.51-3.b16.el6_7.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root 26740012 Apr  9 11:29 puppet-agent-1.4.1-1.el6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  4509000 Apr  9 11:29 puppet-dashboard-1.2.23-0.1rc3.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 21866876 Apr  9 11:29 puppetdb-4.0.0-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root    25516 Apr  9 11:29 puppetdb-termini-3.2.4-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root     3676 Apr  9 11:29 puppetdb-terminus-3-1.el6.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 33412844 Apr  9 11:29 puppetserver-2.3.1-1.el6.noarch.rpm
</span><span class='line'>drwxr-xr-x 2 root root     4096 Apr  9 22:56 repodata
</span><span class='line'>-rw-r--r-- 1 root root   181196 Sep 17  2014 tzdata-java-2014g-1.el6.noarch.rpm
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 ~]# mount -t iso9660 -o loop CentOS-6.5-x86_64-bin-DVD1.iso /mnt/cdrom
</span><span class='line'># httpd 我的系统已经安装了
</span><span class='line'>[root@hadoop-master2 ~]# cd /var/www/html/
</span><span class='line'>[root@hadoop-master2 html]# ll
</span><span class='line'>total 820
</span><span class='line'>lrwxrwxrwx  1 root root     10 Apr  9 21:54 centos6_5 -&gt; /mnt/cdrom
</span><span class='line'>lrwxrwxrwx  1 root root     20 Mar 30 17:11 puppet -&gt; /opt/puppetlabs/repo</span></code></pre></td></tr></table></div></figure>


<p>启动docker实例，参考 <a href="http://www.winseliu.com/blog/2014/09/30/docker-ssh-on-centos/">docker的安装</a>。由于centos和puppet中有包冲突，需要安装 <code>yum-priorities</code> 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 repo]# docker run -i -t centos:centos6 /bin/bash
</span><span class='line'>bash-4.1# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.5 (Final)
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install yum-plugin-priorities-1.1.30-30.el6.noarch.rpm 
</span><span class='line'>
</span><span class='line'># 把默认的repo清理掉，添加puppet和centos
</span><span class='line'>bash-4.1# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=http://172.17.42.1/puppet
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>priority=1
</span><span class='line'>bash-4.1# cat /etc/yum.repos.d/centos-local.repo 
</span><span class='line'>[centos-local]
</span><span class='line'>name=Centos Local
</span><span class='line'>baseurl=http://172.17.42.1/centos6_5
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>priority=2
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install puppetserver
</span><span class='line'>
</span><span class='line'># 加载环境变量
</span><span class='line'>bash-4.1# source /etc/profile.d/puppet-agent.sh
</span><span class='line'># 查看puppet各程序版本
</span><span class='line'>bash-4.1# puppet -V
</span><span class='line'>4.4.1
</span><span class='line'>bash-4.1# puppetserver -v
</span><span class='line'>puppetserver version: 2.3.1
</span><span class='line'>bash-4.1# facter -v
</span><span class='line'>3.1.5 (commit b5c2cf9b2ac290cb17fcadea19b467a39e17c1fd)</span></code></pre></td></tr></table></div></figure>


<p>Agent安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# cat /etc/yum.repos.d/puppet-local.repo 
</span><span class='line'>[puppet-local]
</span><span class='line'>name=Puppet Local
</span><span class='line'>baseurl=http://172.17.42.1/puppet
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>[centos-local]
</span><span class='line'>name=Centos Local
</span><span class='line'>baseurl=http://172.17.42.1/centos6_5
</span><span class='line'>failovermethod=priority
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>bash-4.1# yum install puppet-agent -y</span></code></pre></td></tr></table></div></figure>


<p>配置：</p>

<ul>
<li>添加hosts</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# cat /etc/hosts
</span><span class='line'>172.17.0.4 puppet
</span><span class='line'>172.17.0.5 agent1
</span><span class='line'>172.17.0.6 agent2</span></code></pre></td></tr></table></div></figure>


<ul>
<li>master自测</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 3e4b2ba27563.localdomain
</span><span class='line'>Info: Applying configuration version '1460222292'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.01 seconds</span></code></pre></td></tr></table></div></figure>


<ul>
<li>agent连接服务器</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Creating a new SSL key for 5a56be361905.localdomain
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Info: csr_attributes file loading from /etc/puppetlabs/puppet/csr_attributes.yaml
</span><span class='line'>Info: Creating a new SSL certificate request for 5a56be361905.localdomain
</span><span class='line'>Info: Certificate Request fingerprint (SHA256): 58:1A:2E:28:D3:D7:C5:7B:E3:1A:C2:0F:70:D0:46:C0:34:39:7F:EC:98:65:B1:09:96:D3:4B:A7:4B:32:A6:C6
</span><span class='line'>Info: Caching certificate for ca
</span><span class='line'>Exiting; no certificate found and waitforcert is disabled
</span><span class='line'>
</span><span class='line'># master查看/认证
</span><span class='line'>bash-4.1# puppet cert list
</span><span class='line'>  "5a56be361905.localdomain" (SHA256) 58:1A:2E:28:D3:D7:C5:7B:E3:1A:C2:0F:70:D0:46:C0:34:39:7F:EC:98:65:B1:09:96:D3:4B:A7:4B:32:A6:C6
</span><span class='line'>  "6516b8d0538b.localdomain" (SHA256) F7:49:CC:93:EA:5D:D9:A2:90:33:01:A9:74:86:97:0C:20:0C:EB:24:3A:13:85:64:5C:32:A8:D7:36:91:3C:77
</span><span class='line'>bash-4.1# puppet cert sign --all 
</span><span class='line'>Notice: Signed certificate request for 6516b8d0538b.localdomain
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest 6516b8d0538b.localdomain at '/etc/puppetlabs/puppet/ssl/ca/requests/6516b8d0538b.localdomain.pem'
</span><span class='line'>Notice: Signed certificate request for 5a56be361905.localdomain
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest 5a56be361905.localdomain at '/etc/puppetlabs/puppet/ssl/ca/requests/5a56be361905.localdomain.pem'
</span><span class='line'>
</span><span class='line'># agent再连
</span><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Caching certificate for 5a56be361905.localdomain
</span><span class='line'>Info: Caching certificate_revocation_list for ca
</span><span class='line'>Info: Caching certificate for 5a56be361905.localdomain
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 5a56be361905.localdomain
</span><span class='line'>Info: Applying configuration version '1460222614'
</span><span class='line'>Info: Creating state file /opt/puppetlabs/puppet/cache/state/state.yaml
</span><span class='line'>Notice: Applied catalog in 0.02 seconds</span></code></pre></td></tr></table></div></figure>


<p>相比puppet那么多配置项，安装还是相对简单的。安装写到这些也差不多了，接下来要研究下监控和puppet的配置。</p>

<p>安装过程中也遇到一些问题，主要都是DNS导致。一开始 <strong>直接用hosts</strong> 来配置是最简便的，把server的ip指定为puppet域名。</p>

<p>再来个Hello：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master
</span><span class='line'>bash-4.1# cd /etc/puppetlabs/code/environments/production/
</span><span class='line'>bash-4.1# ls
</span><span class='line'>environment.conf  hieradata  manifests  modules
</span><span class='line'>bash-4.1# cd manifests/
</span><span class='line'>bash-4.1# cat helloworld.pp 
</span><span class='line'>notify { 'Hello World' : 
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># agent
</span><span class='line'>bash-4.1# puppet agent -t
</span><span class='line'>Info: Using configured environment 'production'
</span><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Info: Caching catalog for 5a56be361905.localdomain
</span><span class='line'>Info: Applying configuration version '1460223248'
</span><span class='line'>Notice: Hello World
</span><span class='line'>Notice: /Stage[main]/Main/Notify[Hello World]/message: defined 'message' as 'Hello World'
</span><span class='line'>Notice: Applied catalog in 0.02 seconds
</span><span class='line'>bash-4.1# </span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/">https://docs.puppet.com/puppet/4.4/reference/</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/install_pre.html">https://docs.puppetlabs.com/puppet/latest/reference/install_pre.html</a></li>
<li><a href="https://docs.puppet.com/puppetserver/latest/install_from_packages.html">https://docs.puppet.com/puppetserver/latest/install_from_packages.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html">https://docs.puppet.com/puppet/4.4/reference/whered_it_go.html</a></li>
<li><a href="https://github.com/puppetlabs/puppet-specifications/blob/master/file_paths.md">https://github.com/puppetlabs/puppet-specifications/blob/master/file_paths.md</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/reference/install_linux.html#installing-release-packages-on-yum-based-systems">https://docs.puppet.com/puppet/4.4/reference/install_linux.html#installing-release-packages-on-yum-based-systems</a></li>
<li><a href="https://yum.puppetlabs.com/el/6/PC1/x86_64/">https://yum.puppetlabs.com/el/6/PC1/x86_64/</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/type.html#file">https://docs.puppetlabs.com/puppet/latest/reference/type.html#file</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html">https://docs.puppetlabs.com/puppet/latest/reference/config_important_settings.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppetdb/4.0/install_from_packages.html">https://docs.puppetlabs.com/puppetdb/4.0/install_from_packages.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/4.4/reference/config_file_auth.html">https://docs.puppetlabs.com/puppet/4.4/reference/config_file_auth.html</a></li>
<li><p><a href="https://docs.puppetlabs.com/puppet/4.4/reference/config_file_autosign.html">https://docs.puppetlabs.com/puppet/4.4/reference/config_file_autosign.html</a></p></li>
<li><p>yum配置与各种使用 <a href="http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html">http://www.cnblogs.com/mchina/archive/2013/01/04/2842275.html</a></p></li>
<li><a href="http://kisspuppet.com/2014/01/26/puppet_create_repo/">http://kisspuppet.com/2014/01/26/puppet_create_repo/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DBCP参数在Hive JDBC上的实践]]></title>
    <link href="http://winseliu.com/blog/2016/04/08/dbcp-parameters/"/>
    <updated>2016-04-08T19:48:01+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/08/dbcp-parameters</id>
    <content type="html"><![CDATA[<p>查询程序一开始只是简单使用dbcp来做连接的限制。在实践的过程中遇到各种问题，本文记录DBCP的参数优化提高程序健壮性的两次过程。</p>

<p>最开始的DBCP的配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>  destroy-method="close" 
</span><span class='line'>  p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>  p:url="${hiveUrl}" 
</span><span class='line'>  p:username="${hiveUsername}" 
</span><span class='line'>  p:password="${hivePassword}"
</span><span class='line'>  p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>  p:maxWait="${hiveMaxWait}" 
</span><span class='line'>  p:maxActive="${hiveMaxActive}" /&gt;
</span><span class='line'>
</span><span class='line'>&lt;bean id="hiveTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt;
</span><span class='line'>  &lt;property name="dataSource"&gt;
</span><span class='line'>      &lt;ref bean="hiveDataSource" /&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>&lt;/bean&gt;</span></code></pre></td></tr></table></div></figure>


<p>第一个遇到的问题，就是每次hiveserver2重启后，这个查询程序也得重启。在实际使用过程中非常的麻烦！！</p>

<h4>重启问题（连接断开后不能重连）</h4>

<p>首先给出学习的链接 <a href="http://elf8848.iteye.com/blog/1931778">http://elf8848.iteye.com/blog/1931778</a> 巨详细，同时问题的场景都一模一样啊！！</p>

<p>添加三个参数：</p>

<ul>
<li>testOnBorrow = &ldquo;true&rdquo;       借出连接时不要测试，否则很影响性能</li>
<li>testWhileIdle = &ldquo;true&rdquo;       指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除.</li>
<li>validationQuery = &ldquo;show databases&rdquo; 验证连接是否可用，使用的SQL语句</li>
</ul>


<p>解释：</p>

<p>testWhileIdle = &ldquo;true&rdquo; 表示每 {timeBetweenEvictionRunsMillis} (默认-1，不执行)秒，取出 {numTestsPerEvictionRun} (默认值3)条连接，使用 {validationQuery} 进行测试 ，测试不成功就销毁连接。销毁连接后，连接数量就少了，如果小于minIdle数量，就新建连接。</p>

<p>testOnBorrow = &ldquo;true&rdquo; 它的默认值是true，如果测试失败会drop掉然后再borrow。false表示每次从连接池中取出连接时，不需要执行 {validationQuery} 中的SQL进行测试。若配置为true,对性能有非常大的影响，性能会下降7-10倍。所在一定要配置为false.</p>

<p>调整参数后hiveserver2重启，查询再连会先报错然后再连。在每次取连接的时刻使用 <code>show databases</code> 测试，如果失败则从pool中删掉这个连接，重新再取，实现了重连的效果。这里不用 <code>select 1</code> hive里面执行很慢， 同时testWhileIdle并没有生效，因为没有配置timeBetweenEvictionRunsMillis参数。</p>

<p>调整后的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>destroy-method="close" 
</span><span class='line'>p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>p:url="${hiveUrl}" 
</span><span class='line'>p:username="${hiveUsername}" 
</span><span class='line'>p:password="${hivePassword}"
</span><span class='line'>p:testOnBorrow="${hiveTestOnBorrow}"
</span><span class='line'>p:testWhileIdle="${hiveTestWhileIdle}" 
</span><span class='line'>p:validationQuery="${hiveValidationQuery}"
</span><span class='line'>p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>p:maxWait="${hiveMaxWait}" 
</span><span class='line'>p:maxActive="${hiveMaxActive}" 
</span><span class='line'>/&gt;</span></code></pre></td></tr></table></div></figure>


<p>问题又来了，由于测试切换tez和spark才配置了上面的重连。但是切换到spark后，启动的spark会一直保持(连接创建的session不会主动关闭)，直到hiveserver2 session超时(默认6h检查一次，7h idle就关闭)。</p>

<p>注意：有个隐忧，hive-on-spark每个连接都创建一个SESSION，这就退化到MR操作了。不能完全利用SPARK的优势！！例如业务中，即查询count、又获取一页数据，这里就是两个单独的spark程序！！N个session就N个 <strong>hive on spark</strong> 啊！！</p>

<h4>第二个问题，服务端session强制关闭</h4>

<p>问题其实和参考中的: <strong>MySQL8小时问题，Mysql服务器默认连接的“wait_timeout”是8小时，也就是说一个connection空闲超过8个小时，Mysql将自动断开该 connection</strong> 一模一样的。在增加 <strong>minEvictableIdleTimeMillis</strong> 和 <strong>timeBetweenEvictionRunsMillis</strong> 设置检查和回收的时间。</p>

<ul>
<li>timeBetweenEvictionRunsMillis = &ldquo;1800000&rdquo;  每30分钟运行一次空闲连接回收器，没必要那么频繁。</li>
<li>minEvictableIdleTimeMillis = &ldquo;3600000&rdquo;  池中的连接空闲1个小时后被回收，如果1个半小时没有操作，这个session就会被客户端关闭。可以通过yarn-8088的scheduler页面查看。</li>
</ul>


<p>设置后的最终效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;bean id="hiveDataSource" class="org.apache.commons.dbcp.BasicDataSource"
</span><span class='line'>destroy-method="close" 
</span><span class='line'>p:driverClassName="${hiveDriverClassName}"
</span><span class='line'>p:url="${hiveUrl}" 
</span><span class='line'>p:username="${hiveUsername}" 
</span><span class='line'>p:password="${hivePassword}"
</span><span class='line'>p:testOnBorrow="${hiveTestOnBorrow}"
</span><span class='line'>p:validationQuery="${hiveValidationQuery}"
</span><span class='line'>p:maxWait="${hiveMaxWait}" 
</span><span class='line'>p:maxIdle="${hiveMaxIdle}" 
</span><span class='line'>p:maxActive="${hiveMaxActive}" 
</span><span class='line'>p:testWhileIdle="${hiveTestWhileIdle}" 
</span><span class='line'>p:timeBetweenEvictionRunsMillis="${hiveTimeBetweenEvictionRunsMillis}" 
</span><span class='line'>p:minEvictableIdleTimeMillis="${hiveMinEvictableIdleTimeMillis}" 
</span><span class='line'>p:removeAbandoned="true"
</span><span class='line'>p:logAbandoned="true"
</span><span class='line'>/&gt;</span></code></pre></td></tr></table></div></figure>


<p>很多程序都有很多参数，大部分能通过文档明白，但是一些参数不到实践真的很难真正体会它的含义。参考的文章两次改进我查看了，但是第一次看的时刻根本没去加其他参数，因为对我来说没用，解决当前问题用不到嘛。</p>

<p>hadoop的参数更多，core/hdfs/mapred/yarn需要多用才能发现参数的功能和妙用。<strong>纸上得来终觉浅，绝知此事要躬行</strong> 。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RPM打包]]></title>
    <link href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/"/>
    <updated>2016-04-04T16:07:21+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/04/rpm-build-your-package</id>
    <content type="html"><![CDATA[<h2>资料</h2>

<ul>
<li><a href="http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html">http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/index.html">用 RPM 打包软件-打包教程</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part3/index.html">用 RPM 打包软件-高级部分：安装前后控制</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-rpm/index.html">RPM 打包技术与典型 SPEC 文件分析-各变量含义</a></li>
<li><a href="http://hlee.iteye.com/blog/343499">http://hlee.iteye.com/blog/343499</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/indent-2.spec">案例</a></li>
<li><p><a href="https://github.com/apache/zookeeper/tree/release-3.4.8/src/packages">zookeeper打包案例</a></p></li>
<li><p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html">http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html</a></p></li>
</ul>


<h2>实践</h2>

<ul>
<li>系统配置准备</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 新建一个docker实例，来测试、学习
</span><span class='line'>[root@cu1 ~]# docker run -ti centos:centos6 /bin/bash
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.6 (Final)
</span><span class='line'>
</span><span class='line'># 安装编译环境所需的软件
</span><span class='line'>yum install which tree lrzsz tar gcc rpm-build
</span><span class='line'># wget编译的依赖
</span><span class='line'>yum install -y gnutls gnutls-devel</span></code></pre></td></tr></table></div></figure>


<ul>
<li>步骤</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bdc25400cc63 home]# mkdir mywget 
</span><span class='line'>[root@bdc25400cc63 home]# cd mywget/
</span><span class='line'>[root@bdc25400cc63 mywget]# mkdir BUILD RPMS SOURCES SPECS SRPMS
</span><span class='line'>[root@bdc25400cc63 mywget]# cd SOURCES/
</span><span class='line'>[root@bdc25400cc63 SOURCES]# mv /home/wget-1.17.tar.gz .
</span><span class='line'>[root@bdc25400cc63 SOURCES]# ls
</span><span class='line'>wget-1.17.tar.gz
</span><span class='line'>[root@bdc25400cc63 SOURCES]# cd ..
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# rpmbuild --showrc
</span><span class='line'>[test@bdc25400cc63 mywget]$ rpm --eval "%{_topdir}"
</span><span class='line'>
</span><span class='line'>[test@bdc25400cc63 mywget]$ grep -i _topdir /usr/lib/rpm/rpmrc /usr/lib/rpm/redhat/rpmrc /usr/lib/rpm/macros /usr/lib/rpm/redhat/macros  | less
</span><span class='line'>/usr/lib/rpm/macros:%_builddir          %{_topdir}/BUILD
</span><span class='line'>/usr/lib/rpm/macros:%_rpmdir            %{_topdir}/RPMS
</span><span class='line'>/usr/lib/rpm/macros:%_sourcedir         %{_topdir}/SOURCES
</span><span class='line'>/usr/lib/rpm/macros:%_specdir           %{_topdir}/SPECS
</span><span class='line'>/usr/lib/rpm/macros:%_srcrpmdir         %{_topdir}/SRPMS
</span><span class='line'>/usr/lib/rpm/macros:%_buildrootdir              %{_topdir}/BUILDROOT
</span><span class='line'>/usr/lib/rpm/macros:%_topdir            %{getenv:HOME}/rpmbuild
</span><span class='line'>
</span><span class='line'>[test@bdc25400cc63 mywget]$ cat ~/.rpmmacros 
</span><span class='line'>%_topdir /home/mywget/rpm
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# vi SPECS/wget.spec
</span><span class='line'>  # this is a sample spec file for wget
</span><span class='line'>  
</span><span class='line'>  %define _topdir /home/mywget
</span><span class='line'>  %define name    wget
</span><span class='line'>  %define release 2
</span><span class='line'>  %define version 1.17
</span><span class='line'>  # 定义 _buildrootdir 不起作用，不知道为啥??? 在 .rpmmacros 定义了 %_topdir，root转到 /home/mywget/rpm/BUILDROOT 了。
</span><span class='line'>  
</span><span class='line'>  %define _unpackaged_files_terminate_build 0
</span><span class='line'>  
</span><span class='line'>  Summary:   GNU wget
</span><span class='line'>  License:   GPL
</span><span class='line'>  Name:      %{name}
</span><span class='line'>  Version:   %{version}
</span><span class='line'>  Release:   %{release}
</span><span class='line'>  Source:    %{name}-%{version}.tar.gz
</span><span class='line'>  Prefix:    /usr/local/wget
</span><span class='line'>  Group:     Development/Tools
</span><span class='line'>  
</span><span class='line'>  %description
</span><span class='line'>  The GNU wget program downloads files from the Internet using the command-line.
</span><span class='line'>  
</span><span class='line'>  %prep
</span><span class='line'>  %setup -q
</span><span class='line'>  
</span><span class='line'>  %build
</span><span class='line'>  ./configure
</span><span class='line'>  make
</span><span class='line'>  
</span><span class='line'>  %install
</span><span class='line'>  make install prefix=$RPM_BUILD_ROOT/usr/local/wget # or use DESTDIR=$RPM_BUILD_ROOT
</span><span class='line'>  
</span><span class='line'>  %post
</span><span class='line'>  echo "hello world"
</span><span class='line'>  
</span><span class='line'>  %preun
</span><span class='line'>  echo "bye"
</span><span class='line'>  
</span><span class='line'>  %clean
</span><span class='line'>  rm -rf $RPM_BUILD_ROOT
</span><span class='line'>  
</span><span class='line'>  %files
</span><span class='line'>  %defattr(-, root, root)
</span><span class='line'>  /usr/local/wget/bin/wget
</span><span class='line'>  
</span><span class='line'>[root@bdc25400cc63 mywget]# rpmbuild -vv -bb --clean SPECS/wget.spec 
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# tree .
</span><span class='line'>.
</span><span class='line'>├── BUILD
</span><span class='line'>├── RPMS
</span><span class='line'>│   └── x86_64
</span><span class='line'>│       ├── wget-1.17-2.x86_64.rpm
</span><span class='line'>│       └── wget-debuginfo-1.17-2.x86_64.rpm
</span><span class='line'>├── SOURCES
</span><span class='line'>│   └── wget-1.17.tar.gz
</span><span class='line'>├── SPECS
</span><span class='line'>│   └── wget.spec
</span><span class='line'>└── SRPMS
</span><span class='line'>
</span><span class='line'>6 directories, 4 files
</span><span class='line'>
</span><span class='line'>[root@bdc25400cc63 mywget]# rpm -qpl RPMS/x86_64/wget-1.17-2.x86_64.rpm  
</span><span class='line'>/usr/local/wget/bin/wget
</span></code></pre></td></tr></table></div></figure>


<p>接下来就可以直接拿到这个包到其他机器上安装了，如果自己建立了本地库，使用createrepo更新下，就可以使用yum安装最新打的包了。</p>

<p>注： <code>%pre</code> , <code>%post</code> 和 <code>%preun</code> , <code>%postun</code> 可以在安装前后执行一些脚本。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parquet学习]]></title>
    <link href="http://winseliu.com/blog/2016/03/29/parquet-simple-view/"/>
    <updated>2016-03-29T19:13:53+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/29/parquet-simple-view</id>
    <content type="html"><![CDATA[<h2>经典文章</h2>

<ul>
<li><a href="http://parquet.apache.org/documentation/latest/">http://parquet.apache.org/documentation/latest/</a></li>
<li><a href="https://blog.twitter.com/2013/dremel-made-simple-with-parquet">https://blog.twitter.com/2013/dremel-made-simple-with-parquet</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a></li>
</ul>


<h2>概念</h2>

<ul>
<li>Row Group

<ul>
<li>Column Chunk

<ul>
<li>Page

<ul>
<li>Definition Levels: To support nested records we need to store the level for which the field is null. This is what the definition level is for: from 0 at the root of the schema up to the maximum level for this column. When a field is defined then all its parents are defined too, but <strong>when it is null we need to record the level at which it started being null to be able to reconstruct the record</strong>.</li>
<li>Repetition Levels: To support repeated fields we need to store when new lists are starting in a column of values. This is what repetition level is for: it is the level at which we have to create a new list for the current value. <strong>In other words, the repetition level can be seen as a marker of when to start a new list and at which level</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>FileMetaData</li>
</ul>


<p>The definition and repetition levels are optional, based on the schema definition. If the column is not nested (i.e. the path to the column has length 1), we do not encode the repetition levels (it would always have the value 1). For data that is required, the definition levels are skipped (if encoded, it will always have the value of the max definition level).</p>

<p>For example, in the case where the column is non-nested and required, the data in the page is only the encoded values.</p>

<p><strong>An optimized read setup would be: 1GB row groups, 1GB HDFS block size, 1 HDFS block per HDFS file.</strong></p>

<h2>texfile转parquet</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ cd apache-hive-1.2.1-bin/
</span><span class='line'>[hadoop@hadoop-master2 apache-hive-1.2.1-bin]$ bin/hive
</span><span class='line'>hive&gt; CREATE TABLE `t_ods_access_log2_parquet`(   `houseid` string,    `sourceip` string,    `destinationip` string,    `sourceport` string,    `destinationport` string,    `domain` string,    `url` string,    `accesstime` string,    `logid` string,    `sourceipnum` bigint,    `timedetected` string,    `protocol` string,    `duration` string) ROW FORMAT DELIMITED    FIELDS TERMINATED BY '|'  STORED AS PARQUET LOCATION   '/user/hive/t_ods_access_log2_parquet'</span></code></pre></td></tr></table></div></figure>


<p>关键 <strong>STORED AS PARQUET</strong>。</p>

<p>关于压缩，可以通过mapreduce参数设置（ <code>mapreduce.output.fileoutputformat.compress</code> 和 <code>mapreduce.output.fileoutputformat.compress.codec</code> ），但是推荐使用 <code>parquet.compression</code> 属性来指定。</p>

<p>reader/writer都会从 <code>CodecConfig.getCodec()</code> 获取压缩编码。代码中会从parquet属性和mapreduce获取压缩参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>alter table t_ods_access_log2_parquet SET TBLPROPERTIES ('parquet.compression' = 'SNAPPY' );
</span><span class='line'>
</span><span class='line'>create table t_ods_access_log2_parquet_none like t_ods_access_log2_parquet TBLPROPERTIES ('parquet.compression' = 'UNCOMPRESSED' );
</span><span class='line'>create table t_ods_access_log2_parquet_gzip like t_ods_access_log2_parquet TBLPROPERTIES ('parquet.compression' = 'GZIP' );</span></code></pre></td></tr></table></div></figure>


<p>直接使用hive的insert into语句就可以把原来的textfile的文件转成parquet格式。同时也转成gzip和uncompress比较了一下：</p>

<table>
<thead>
<tr>
<th style="text-align:left;">文件格式     </th>
<th style="text-align:left;"> 压缩       </th>
<th style="text-align:left;"> 大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">textfile     </td>
<td style="text-align:left;"> snappy     </td>
<td style="text-align:left;"> 4.1G</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> snappy     </td>
<td style="text-align:left;"> 3.6G</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> uncompress </td>
<td style="text-align:left;"> 7.2G</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> gzip       </td>
<td style="text-align:left;"> 2.2G</td>
</tr>
</tbody>
</table>


<p>直接count整个数据表，使用parquet的输入1M不到数据，太环保了！！（文件都是几十M的，一个文件都在一台机器上）。</p>

<table>
<thead>
<tr>
<th style="text-align:left;">文件格式     </th>
<th style="text-align:left;"> 运行引擎       </th>
<th style="text-align:left;"> 大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">textfile     </td>
<td style="text-align:left;"> tez            </td>
<td style="text-align:left;"> HDFS_BYTES_READ    4,454,071,542</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> tez            </td>
<td style="text-align:left;"> HDFS_BYTES_READ    415,870</td>
</tr>
<tr>
<td style="text-align:left;">textfile     </td>
<td style="text-align:left;"> sparksql       </td>
<td style="text-align:left;"> Input  4.1 GB</td>
</tr>
<tr>
<td style="text-align:left;">parquet      </td>
<td style="text-align:left;"> sparksql       </td>
<td style="text-align:left;"> Input  384.9 KB</td>
</tr>
</tbody>
</table>


<p>用sparksql跑textfile尽让更快。果然内存大暴力也很牛啊！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; insert into t_ods_access_log2_back select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 ;
</span><span class='line'>Query ID = hadoop_20160329200414_96f1de35-48c5-4b38-977f-05de8554f388
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3955)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    152        152        0        0       1       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 01/01  [==========================&gt;&gt;] 100%  ELAPSED TIME: 341.56 s   
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Loading data to table default.t_ods_access_log2_back
</span><span class='line'>Table default.t_ods_access_log2_back stats: [numFiles=152, numRows=57688987, totalSize=4454071542, rawDataSize=11018516544]
</span><span class='line'>OK
</span><span class='line'>Time taken: 347.997 seconds
</span><span class='line'>hive&gt; insert into t_ods_access_log2_parquet select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 ;
</span><span class='line'>Query ID = hadoop_20160329212157_57b66595-5dfc-4fc9-9ad1-398e2b8ade6b
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>Tez session was closed. Reopening...
</span><span class='line'>Session re-established.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3992)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    152        152        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 01/01  [==========================&gt;&gt;] 100%  ELAPSED TIME: 237.28 s   
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Loading data to table default.t_ods_access_log2_parquet
</span><span class='line'>Table default.t_ods_access_log2_parquet stats: [numFiles=0, numRows=1305035789, totalSize=0, rawDataSize=16965465257]
</span><span class='line'>OK
</span><span class='line'>Time taken: 260.515 seconds
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>Query ID = hadoop_20160329212644_da8e7997-5bcc-41ab-8b63-f1a5919c5a2f
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3992)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    107        107        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 59.01 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 59.768 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>Query ID = hadoop_20160329212813_2fb8dafa-5c9a-40e8-a904-13e7cf865ec6
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1458893800770_3992)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED    106        106        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 45.82 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 47.275 seconds, Fetched: 1 row(s)
</span><span class='line'>
</span><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; set spark.master=yarn-client;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>Query ID = hadoop_20160329214550_a58d1056-9c91-4bbe-be7d-122ec3efdd8d
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 3a03d432-83a4-4d5a-a878-c9e52aa94bed
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:46:26,523 Stage-0_0: 0(+114)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:27,535 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:30,563 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:33,582 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:36,606 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:39,624 Stage-0_0: 0(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:41,637 Stage-0_0: 0(+118)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:42,644 Stage-0_0: 4(+115)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:43,651 Stage-0_0: 110(+41)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:44,658 Stage-0_0: 124(+28)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:45,665 Stage-0_0: 128(+24)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:46,671 Stage-0_0: 138(+14)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:47,677 Stage-0_0: 142(+10)/152 Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:48,684 Stage-0_0: 144(+8)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:49,691 Stage-0_0: 147(+5)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:50,698 Stage-0_0: 148(+4)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:51,705 Stage-0_0: 149(+3)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:52,712 Stage-0_0: 150(+2)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:55,731 Stage-0_0: 151(+1)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:46:58,750 Stage-0_0: 151(+1)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:47:01,769 Stage-0_0: 151(+1)/152  Stage-1_0: 0/1
</span><span class='line'>2016-03-29 21:47:02,776 Stage-0_0: 152/152 Finished     Stage-1_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:05,793 Stage-0_0: 152/152 Finished     Stage-1_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 70.33 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 75.211 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>Query ID = hadoop_20160329214723_9663eaf7-7014-46b1-b2ca-811ba64fc55c
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = f2dbcd55-b23c-4eb3-9439-8f1c825fbac3
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[1] stages:
</span><span class='line'>2
</span><span class='line'>3
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[1])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:47:24,449 Stage-2_0: 0(+122)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:25,455 Stage-2_0: 96(+56)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:26,462 Stage-2_0: 123(+29)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:27,469 Stage-2_0: 128(+24)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:28,476 Stage-2_0: 132(+20)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:29,483 Stage-2_0: 137(+15)/152 Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:30,489 Stage-2_0: 145(+7)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:31,495 Stage-2_0: 146(+6)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:32,500 Stage-2_0: 150(+2)/152  Stage-3_0: 0/1
</span><span class='line'>2016-03-29 21:47:33,506 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:36,524 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:39,540 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:42,557 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:45,573 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:48,589 Stage-2_0: 152/152 Finished     Stage-3_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:47:49,594 Stage-2_0: 152/152 Finished     Stage-3_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 26.15 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 26.392 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>Query ID = hadoop_20160329214758_25084e25-fdaf-4ef8-9c1a-2573515caca6
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 4360be5c-4188-49c4-a2a7-e5bb80164646
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[2] stages:
</span><span class='line'>5
</span><span class='line'>4
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[2])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:47:59,472 Stage-4_0: 0(+63)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:00,478 Stage-4_0: 1(+62)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:01,486 Stage-4_0: 49(+14)/65   Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:02,492 Stage-4_0: 51(+14)/65   Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:03,498 Stage-4_0: 57(+8)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:04,505 Stage-4_0: 62(+3)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:05,511 Stage-4_0: 63(+2)/65    Stage-5_0: 0/1
</span><span class='line'>2016-03-29 21:48:06,518 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:09,537 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:12,556 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:15,574 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:18,592 Stage-4_0: 65/65 Finished       Stage-5_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:21,608 Stage-4_0: 65/65 Finished       Stage-5_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 23.14 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 23.376 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>Query ID = hadoop_20160329214826_173311b1-0083-4e11-9a29-fe13f48bb649
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = c452b02b-c68f-4c68-bc28-cb9748d7dcb2
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[3] stages:
</span><span class='line'>6
</span><span class='line'>7
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[3])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 21:48:27,332 Stage-6_0: 3(+60)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:28,338 Stage-6_0: 53(+10)/65   Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:29,343 Stage-6_0: 60(+3)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:30,349 Stage-6_0: 61(+4)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:31,354 Stage-6_0: 63(+2)/65    Stage-7_0: 0/1
</span><span class='line'>2016-03-29 21:48:32,360 Stage-6_0: 65/65 Finished       Stage-7_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:35,377 Stage-6_0: 65/65 Finished       Stage-7_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:38,393 Stage-6_0: 65/65 Finished       Stage-7_0: 0(+1)/1
</span><span class='line'>2016-03-29 21:48:40,404 Stage-6_0: 65/65 Finished       Stage-7_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 14.08 seconds
</span><span class='line'>OK
</span><span class='line'>57688987
</span><span class='line'>Time taken: 14.306 seconds, Fetched: 1 row(s)
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 spark-1.6.0-bin-2.6.3]$ bin/spark-sql --master yarn-client --hiveconf hive.execution.engine=mr 
</span><span class='line'>         &gt; select count(*) from t_ods_access_log2_parquet;
</span><span class='line'>57688987
</span><span class='line'>16/03/29 22:19:51 INFO CliDriver: Time taken: 21.82 seconds, Fetched 1 row(s)
</span><span class='line'>
</span><span class='line'>         &gt; select count(*) from t_ods_access_log2_back;
</span><span class='line'>57688987
</span><span class='line'>16/03/29 22:20:44 INFO CliDriver: Time taken: 6.634 seconds, Fetched 1 row(s)
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Limit on Sparksql and Hive]]></title>
    <link href="http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive/"/>
    <updated>2016-03-29T15:27:03+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive</id>
    <content type="html"><![CDATA[<p>前一篇提到sparksql查询limit的时刻会提前返回，不需要查询所有的数据。hive是死算，sparksql递增数据量的一次次的试。sparksql可以这么做的，毕竟算好的数据在内存里面放着。</p>

<p>把日志记录下面：</p>

<h2>hive1.2.1-on-spark1.3.1</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 and sourceip='118.112.188.17' limit 10;
</span><span class='line'>Query ID = hadoop_20160329151420_25fe9497-e223-4f48-980e-e7fe859848ce
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 9036c8d7-62b6-4b9a-b6d3-2d8b5eed6bf9
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[2] stages:
</span><span class='line'>3
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[2])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-29 15:14:22,053 Stage-3_0: 0(+160)/942
</span><span class='line'>2016-03-29 15:14:23,059 Stage-3_0: 47(+160)/942
</span><span class='line'>2016-03-29 15:14:24,064 Stage-3_0: 131(+160)/942
</span><span class='line'>2016-03-29 15:14:25,069 Stage-3_0: 266(+160)/942
</span><span class='line'>2016-03-29 15:14:26,075 Stage-3_0: 382(+160)/942
</span><span class='line'>2016-03-29 15:14:27,080 Stage-3_0: 497(+152)/942
</span><span class='line'>2016-03-29 15:14:28,085 Stage-3_0: 607(+142)/942
</span><span class='line'>2016-03-29 15:14:29,090 Stage-3_0: 714(+125)/942
</span><span class='line'>2016-03-29 15:14:30,094 Stage-3_0: 794(+91)/942
</span><span class='line'>2016-03-29 15:14:31,099 Stage-3_0: 846(+61)/942
</span><span class='line'>2016-03-29 15:14:32,103 Stage-3_0: 868(+47)/942
</span><span class='line'>2016-03-29 15:14:33,107 Stage-3_0: 886(+35)/942
</span><span class='line'>2016-03-29 15:14:34,112 Stage-3_0: 895(+26)/942
</span><span class='line'>2016-03-29 15:14:35,116 Stage-3_0: 902(+21)/942
</span><span class='line'>2016-03-29 15:14:36,120 Stage-3_0: 904(+19)/942
</span><span class='line'>2016-03-29 15:14:37,124 Stage-3_0: 906(+17)/942
</span><span class='line'>2016-03-29 15:14:38,128 Stage-3_0: 910(+15)/942
</span><span class='line'>2016-03-29 15:14:39,132 Stage-3_0: 914(+13)/942
</span><span class='line'>2016-03-29 15:14:40,137 Stage-3_0: 920(+9)/942
</span><span class='line'>2016-03-29 15:14:41,141 Stage-3_0: 921(+8)/942
</span><span class='line'>2016-03-29 15:14:44,155 Stage-3_0: 928(+14)/942
</span><span class='line'>2016-03-29 15:14:45,159 Stage-3_0: 934(+8)/942
</span><span class='line'>2016-03-29 15:14:46,164 Stage-3_0: 936(+6)/942
</span><span class='line'>2016-03-29 15:14:47,169 Stage-3_0: 937(+5)/942
</span><span class='line'>2016-03-29 15:14:50,180 Stage-3_0: 938(+4)/942
</span><span class='line'>2016-03-29 15:14:52,188 Stage-3_0: 939(+3)/942
</span><span class='line'>2016-03-29 15:14:54,196 Stage-3_0: 941(+1)/942
</span><span class='line'>2016-03-29 15:14:57,206 Stage-3_0: 941(+1)/942
</span><span class='line'>2016-03-29 15:15:00,215 Stage-3_0: 942/942 Finished
</span><span class='line'>Status: Finished successfully in 39.17 seconds</span></code></pre></td></tr></table></div></figure>


<h2>sparksql1.6.0</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark-sql&gt; select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 and sourceip='118.112.188.17' limit 10;
</span><span class='line'>16/03/29 15:15:16 INFO parse.ParseDriver: Parsing command: select houseid,  sourceip,  destinationip,  sourceport,  destinationport,  domain,  url,  accesstime,  logid,  sourceipnum,  timedetected,  protocol,  duration from t_ods_access_log2 where hour=2016032804 and sourceip='118.112.188.17' limit 10
</span><span class='line'>16/03/29 15:15:16 INFO parse.ParseDriver: Parse Completed
</span><span class='line'>16/03/29 15:15:16 INFO metastore.HiveMetaStore: 0: get_table : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:16 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_table : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:17 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 543.3 KB, free 9.7 MB)
</span><span class='line'>16/03/29 15:15:17 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 44.1 KB, free 9.8 MB)
</span><span class='line'>16/03/29 15:15:17 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.32.12:51590 (size: 44.1 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:17 INFO spark.SparkContext: Created broadcast 6 from processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:17 INFO metastore.HiveMetaStore: 0: get_partitions : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:17 INFO HiveMetaStore.audit: ugi=hadoop  ip=unknown-ip-addr      cmd=get_partitions : db=default tbl=t_ods_access_log2
</span><span class='line'>16/03/29 15:15:18 INFO mapred.FileInputFormat: Total input paths to process : 942
</span><span class='line'>16/03/29 15:15:18 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Got job 4 (processCmd at CliDriver.java:376) with 1 output partitions
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:18 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.9 MB, free 13.7 MB)
</span><span class='line'>16/03/29 15:15:18 INFO storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 318.8 KB, free 14.0 MB)
</span><span class='line'>16/03/29 15:15:18 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:18 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:18 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks
</span><span class='line'>16/03/29 15:15:18 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 1260, hadoop-slaver135, partition 0,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:19 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on hadoop-slaver135:59376 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:20 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver135:59376 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 1260) in 3273 ms on hadoop-slaver135 (1/1)
</span><span class='line'>16/03/29 15:15:21 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: ResultStage 5 (processCmd at CliDriver.java:376) finished in 3.276 s
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Job 4 finished: processCmd at CliDriver.java:376, took 3.475462 s
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@57e08525
</span><span class='line'>16/03/29 15:15:21 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: task runtime:(count: 1, mean: 3273.000000, stdev: 0.000000, max: 3273.000000, min: 3273.000000)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s   3.3 s
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Got job 5 (processCmd at CliDriver.java:376) with 2 output partitions
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: task result size:(count: 1, mean: 3763.000000, stdev: 0.000000, max: 3763.000000, min: 3763.000000)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB  3.7 KB
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: executor (non-fetch) time pct: (count: 1, mean: 51.879010, stdev: 0.000000, max: 51.879010, min: 51.879010)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   52 %    52 %    52 %    52 %    52 %    52 %    52 %    52 %    52 %
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener: other time pct: (count: 1, mean: 48.120990, stdev: 0.000000, max: 48.120990, min: 48.120990)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.StatsReportListener:   48 %    48 %    48 %    48 %    48 %    48 %    48 %    48 %    48 %
</span><span class='line'>16/03/29 15:15:21 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.9 MB, free 17.9 MB)
</span><span class='line'>16/03/29 15:15:21 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 318.8 KB, free 18.2 MB)
</span><span class='line'>16/03/29 15:15:21 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:21 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:21 INFO cluster.YarnScheduler: Adding task set 6.0 with 2 tasks
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 1261, hadoop-slaver67, partition 1,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:21 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 1262, hadoop-slaver121, partition 2,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:21 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on hadoop-slaver67:49600 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver67:49600 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on hadoop-slaver121:57614 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver121:57614 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:22 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 1261) in 930 ms on hadoop-slaver67 (1/2)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 1262) in 1207 ms on hadoop-slaver121 (2/2)
</span><span class='line'>16/03/29 15:15:23 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: ResultStage 6 (processCmd at CliDriver.java:376) finished in 1.210 s
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Job 5 finished: processCmd at CliDriver.java:376, took 1.378783 s
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@573e5329
</span><span class='line'>16/03/29 15:15:23 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: task runtime:(count: 2, mean: 1068.500000, stdev: 138.500000, max: 1207.000000, min: 930.000000)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   930.0 ms        930.0 ms        930.0 ms        930.0 ms        1.2 s   1.2 s   1.2 s   1.2 s   1.2 s
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Got job 6 (processCmd at CliDriver.java:376) with 7 output partitions
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: task result size:(count: 2, mean: 2267.500000, stdev: 0.500000, max: 2268.000000, min: 2267.000000)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: executor (non-fetch) time pct: (count: 2, mean: 73.649411, stdev: 11.511880, max: 85.161290, min: 62.137531)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   62 %    62 %    62 %    62 %    85 %    85 %    85 %    85 %    85 %
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener: other time pct: (count: 2, mean: 26.350589, stdev: 11.511880, max: 37.862469, min: 14.838710)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.StatsReportListener:   15 %    15 %    15 %    15 %    38 %    38 %    38 %    38 %    38 %
</span><span class='line'>16/03/29 15:15:23 INFO storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.9 MB, free 22.1 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 318.8 KB, free 22.4 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:23 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.DAGScheduler: Submitting 7 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:23 INFO cluster.YarnScheduler: Adding task set 7.0 with 7 tasks
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 7.0 (TID 1263, hadoop-slaver158, partition 9,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 1264, hadoop-slaver82, partition 3,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 7.0 (TID 1265, hadoop-slaver68, partition 8,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 1266, hadoop-slaver120, partition 4,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 7.0 (TID 1267, hadoop-slaver14, partition 5,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 7.0 (TID 1268, hadoop-slaver137, partition 7,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 7.0 (TID 1269, hadoop-slaver70, partition 6,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver68:45281 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver70:34080 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver137:45760 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver82:36935 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver158:39852 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver14:40126 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on hadoop-slaver120:46667 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver68:45281 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver120:46667 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver70:34080 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver82:36935 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver14:40126 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver137:45760 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:23 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver158:39852 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 1266) in 780 ms on hadoop-slaver120 (1/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 1264) in 943 ms on hadoop-slaver82 (2/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 7.0 (TID 1265) in 999 ms on hadoop-slaver68 (3/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 7.0 (TID 1269) in 1047 ms on hadoop-slaver70 (4/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 7.0 (TID 1268) in 1123 ms on hadoop-slaver137 (5/7)
</span><span class='line'>16/03/29 15:15:24 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 7.0 (TID 1267) in 1413 ms on hadoop-slaver14 (6/7)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 7.0 (TID 1263) in 2229 ms on hadoop-slaver158 (7/7)
</span><span class='line'>16/03/29 15:15:25 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: ResultStage 7 (processCmd at CliDriver.java:376) finished in 2.231 s
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Job 6 finished: processCmd at CliDriver.java:376, took 2.399044 s
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@5210a024
</span><span class='line'>16/03/29 15:15:25 INFO spark.SparkContext: Starting job: processCmd at CliDriver.java:376
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: task runtime:(count: 7, mean: 1219.142857, stdev: 449.417537, max: 2229.000000, min: 780.000000)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   780.0 ms        780.0 ms        780.0 ms        943.0 ms        1.0 s   1.4 s   2.2 s   2.2 s   2.2 s
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: task result size:(count: 7, mean: 2267.428571, stdev: 0.494872, max: 2268.000000, min: 2267.000000)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Got job 7 (processCmd at CliDriver.java:376) with 25 output partitions
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: executor (non-fetch) time pct: (count: 7, mean: 83.082955, stdev: 4.773503, max: 92.418125, min: 77.114871)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   77 %    77 %    77 %    78 %    83 %    86 %    92 %    92 %    92 %
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Missing parents: List()
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener: other time pct: (count: 7, mean: 16.917045, stdev: 4.773503, max: 22.885129, min: 7.581875)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376), which has no missing parents
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.StatsReportListener:    8 %     8 %     8 %    14 %    17 %    22 %    23 %    23 %    23 %
</span><span class='line'>16/03/29 15:15:25 INFO storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.9 MB, free 26.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 318.8 KB, free 26.6 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.32.12:51590 (size: 318.8 KB, free: 21.3 GB)
</span><span class='line'>16/03/29 15:15:25 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.DAGScheduler: Submitting 25 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at processCmd at CliDriver.java:376)
</span><span class='line'>16/03/29 15:15:25 INFO cluster.YarnScheduler: Adding task set 8.0 with 25 tasks
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 19.0 in stage 8.0 (TID 1270, hadoop-slaver61, partition 29,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 8.0 (TID 1271, hadoop-slaver100, partition 12,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 8.0 (TID 1272, hadoop-slaver34, partition 19,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 8.0 (TID 1273, hadoop-slaver76, partition 20,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 8.0 (TID 1274, hadoop-slaver84, partition 24,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 8.0 (TID 1275, hadoop-slaver96, partition 27,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 8.0 (TID 1276, hadoop-slaver38, partition 14,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 8.0 (TID 1277, hadoop-slaver11, partition 23,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 8.0 (TID 1278, hadoop-slaver98, partition 25,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 1279, hadoop-slaver136, partition 11,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 8.0 (TID 1280, hadoop-slaver44, partition 17,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 20.0 in stage 8.0 (TID 1281, hadoop-slaver120, partition 30,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 8.0 (TID 1282, hadoop-slaver141, partition 21,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 23.0 in stage 8.0 (TID 1283, hadoop-slaver82, partition 33,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 24.0 in stage 8.0 (TID 1284, hadoop-slaver159, partition 34,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 18.0 in stage 8.0 (TID 1285, hadoop-slaver15, partition 28,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 8.0 (TID 1286, hadoop-slaver1, partition 16,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 8.0 (TID 1287, hadoop-slaver145, partition 18,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 22.0 in stage 8.0 (TID 1288, hadoop-slaver142, partition 32,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 8.0 (TID 1289, hadoop-slaver31, partition 26,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 8.0 (TID 1290, hadoop-slaver75, partition 15,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 8.0 (TID 1291, hadoop-slaver97, partition 22,NODE_LOCAL, 2354 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 21.0 in stage 8.0 (TID 1292, hadoop-slaver149, partition 31,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 1293, hadoop-slaver163, partition 10,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 8.0 (TID 1294, hadoop-slaver91, partition 13,NODE_LOCAL, 2355 bytes)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver34:54432 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver120:46667 (size: 318.8 KB, free: 510.0 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver15:58396 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver82:36935 (size: 318.8 KB, free: 510.0 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver31:37685 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver1:38813 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver100:56851 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver61:37705 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver98:60144 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver38:57228 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver76:40021 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver44:37682 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver149:59628 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver159:40160 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver11:44070 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver91:47206 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver75:50788 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver97:54552 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver34:54432 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver75:50788 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver38:57228 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver100:56851 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver98:60144 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver149:59628 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver44:37682 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver97:54552 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver1:38813 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver91:47206 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver76:40021 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver31:37685 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver159:40160 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver15:58396 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver145:37716 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver61:37705 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver141:60941 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver136:33234 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:25 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver96:53017 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver96:53017 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver141:60941 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver163:50662 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver145:37716 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver84:34548 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 20.0 in stage 8.0 (TID 1281) in 762 ms on hadoop-slaver120 (1/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 8.0 (TID 1278) in 873 ms on hadoop-slaver98 (2/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 8.0 (TID 1271) in 892 ms on hadoop-slaver100 (3/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 8.0 (TID 1291) in 911 ms on hadoop-slaver97 (4/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 8.0 (TID 1290) in 914 ms on hadoop-slaver75 (5/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 8.0 (TID 1276) in 938 ms on hadoop-slaver38 (6/25)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver163:50662 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 8.0 (TID 1280) in 955 ms on hadoop-slaver44 (7/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 8.0 (TID 1273) in 963 ms on hadoop-slaver76 (8/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 8.0 (TID 1286) in 974 ms on hadoop-slaver1 (9/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 8.0 (TID 1272) in 1019 ms on hadoop-slaver34 (10/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 8.0 (TID 1282) in 1186 ms on hadoop-slaver141 (11/25)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 23.0 in stage 8.0 (TID 1283) in 1187 ms on hadoop-slaver82 (12/25)
</span><span class='line'>16/03/29 15:15:26 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver11:44070 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:26 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 8.0 (TID 1287) in 1260 ms on hadoop-slaver145 (13/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 21.0 in stage 8.0 (TID 1292) in 1349 ms on hadoop-slaver149 (14/25)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver136:33234 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on hadoop-slaver142:59911 (size: 318.8 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 19.0 in stage 8.0 (TID 1270) in 1569 ms on hadoop-slaver61 (15/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 1293) in 1598 ms on hadoop-slaver163 (16/25)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver84:34548 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on hadoop-slaver142:59911 (size: 44.1 KB, free: 510.3 MB)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 8.0 (TID 1277) in 1958 ms on hadoop-slaver11 (17/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 8.0 (TID 1294) in 2018 ms on hadoop-slaver91 (18/25)
</span><span class='line'>16/03/29 15:15:27 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 8.0 (TID 1274) in 2267 ms on hadoop-slaver84 (19/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 8.0 (TID 1275) in 2717 ms on hadoop-slaver96 (20/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 8.0 (TID 1289) in 2733 ms on hadoop-slaver31 (21/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 18.0 in stage 8.0 (TID 1285) in 2864 ms on hadoop-slaver15 (22/25)
</span><span class='line'>16/03/29 15:15:28 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 1279) in 3129 ms on hadoop-slaver136 (23/25)
</span><span class='line'>16/03/29 15:15:29 INFO scheduler.TaskSetManager: Finished task 22.0 in stage 8.0 (TID 1288) in 3308 ms on hadoop-slaver142 (24/25)
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 8.0 (TID 1284) in 5445 ms on hadoop-slaver159 (25/25)
</span><span class='line'>16/03/29 15:15:31 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.DAGScheduler: ResultStage 8 (processCmd at CliDriver.java:376) finished in 5.448 s
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.DAGScheduler: Job 7 finished: processCmd at CliDriver.java:376, took 5.621305 s
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener: Finished stage: org.apache.spark.scheduler.StageInfo@1251c1a
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener: task runtime:(count: 25, mean: 1751.560000, stdev: 1086.831729, max: 5445.000000, min: 762.000000)
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   762.0 ms        873.0 ms        892.0 ms        955.0 ms        1.3 s   2.3 s   3.1 s   3.3 s   5.4 s
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener: task result size:(count: 25, mean: 2501.840000, stdev: 410.074401, max: 3304.000000, min: 2266.000000)
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   0%      5%      10%     25%     50%     75%     90%     95%     100%
</span><span class='line'>16/03/29 15:15:31 INFO scheduler.StatsReportListener:   2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.2 KB  2.6 KB  3.2 KB  3.2 KB  3.2 KB</span></code></pre></td></tr></table></div></figure>


<p>一共弄了4次: <code>1 -&gt; 2 -&gt; 7 -&gt; 25</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive on Spark]]></title>
    <link href="http://winseliu.com/blog/2016/03/28/hive-on-spark/"/>
    <updated>2016-03-28T18:20:46+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/28/hive-on-spark</id>
    <content type="html"><![CDATA[<p>先看官网的资源<a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started">Hive on Spark: Getting Started</a> 。文档是值得信任和有保证的，但是有前提：<strong>Spark版本</strong>得是hive/pom.xml中指定的。</p>

<h2>重新编译spark(assembly包中去掉hive、hadoop)</h2>

<p>这里hive-1.2.1用的是spark-1.3.1 !!!</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 spark-1.3.1]$ ./make-distribution.sh --name "hadoop2.6.3-without-hive" --tgz --mvn "$(which mvn)" -Pyarn,hadoop-provided,hadoop-2.6,parquet-provided -Dhadoop.version=2.6.3 -Dmaven.test.skip=true -Dmaven.javadoc.skip=true -DskipTests
</span></code></pre></td></tr></table></div></figure>


<p>拷贝打包好的 spark-1.3.1-bin-hadoop2.6.3-without-hive.tgz 到服务器。解压并做一个软链接到spark(或者指定 <strong>SPARK_HOME</strong> 环境变量 )，Hive不遗余力啊，把所有想的jar通过各种办法拿到 ( <code>sparkHome=$(readlink -f $bin/../../spark)</code> )。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ ln -s spark-1.3.1-bin-hadoop2.6.3-without-hive spark
</span><span class='line'>
</span><span class='line'>把压缩包传到hdfs，这样每次启动任务就少传几百M的数据。后面spark.yarn.jar配置会用到
</span><span class='line'>[hadoop@hadoop-master2 ~]$ cd spark/lib/
</span><span class='line'>[hadoop@hadoop-master2 lib]$ hadoop fs -put spark-assembly-1.3.1-hadoop2.6.3.jar /spark/
</span></code></pre></td></tr></table></div></figure>


<p>做好软链接后效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ ll | grep -E "hive|spark"
</span><span class='line'>drwxrwxr-x   9 hadoop hadoop 4096 1月  14 08:08 apache-hive-1.2.1-bin
</span><span class='line'>lrwxrwxrwx   1 hadoop hadoop   21 1月  14 08:07 hive -&gt; apache-hive-1.2.1-bin
</span><span class='line'>lrwxrwxrwx   1 hadoop hadoop   40 3月  28 16:38 spark -&gt; spark-1.3.1-bin-hadoop2.6.3-without-hive
</span><span class='line'>drwxrwxr-x  10 hadoop hadoop 4096 3月  28 16:31 spark-1.3.1-bin-hadoop2.6.3-without-hive
</span><span class='line'>drwxrwxr-x  12 hadoop hadoop 4096 3月  25 16:18 spark-1.6.0-bin-2.6.3
</span><span class='line'>drwxrwxr-x  11 hadoop hadoop 4096 3月  28 11:15 spark-1.6.0-bin-hadoop2-without-hive</span></code></pre></td></tr></table></div></figure>


<p>这里的spark-1.6.0是教训啊！记住最好最好用hive/pom.xml中spark的版本！！！</p>

<h2>修改hive配置</h2>

<p>由于spark会加载很多的class，需要把permsize调大。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ less ~/hive/conf/hive-env.sh
</span><span class='line'>export HADOOP_OPTS="$HADOOP_OPTS -XX:PermSize=256m -Dhive.home=${HIVE_HOME} "</span></code></pre></td></tr></table></div></figure>


<p>在conf目录下增加spark-defaults.conf文件，指定spark的配置。动态资源分配查看：<a href="http://spark.apache.org/docs/1.3.1/job-scheduling.html#dynamic-resource-allocation">dynamic-resource-allocation</a>：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 conf]$ cat spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.3.1-hadoop2.6.3.jar
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.executorIdleTimeout    600
</span><span class='line'>spark.dynamicAllocation.minExecutors    160 
</span><span class='line'>spark.dynamicAllocation.maxExecutors    1800
</span><span class='line'>spark.dynamicAllocation.schedulerBacklogTimeout   5
</span><span class='line'>
</span><span class='line'>spark.driver.memory    10g
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address hadoop-master2:18080
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span><span class='line'>spark.kryoserializer.buffer.max    512m</span></code></pre></td></tr></table></div></figure>


<ul>
<li>minExecutors <strong>最好应该是和datanode机器差不多，每台一个executor才能本地计算嘛！</strong></li>
<li>dynamicAllocation需要yarn的配合，具体查看前一篇文章，或者直接看官网的资料。</li>
<li>eventlog查看历史记录需要，配置好后每个任务的信息会存储到eventlog.dir的路径。通过18080端口可以看到历史记录。</li>
</ul>


<h2>跑起来</h2>

<p><code>spark.master</code> 默认是 <strong>yarn-cluster</strong>， 这里先本地跑一下看下效果。然后再改成yarn-cluster/yarn-client就可以了(推荐使用yarn-client，如果yarn-cluster模式AppMaster同时也是Driver，内存比较难控制，日志看起来也麻烦)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hive]$ hive --hiveconf hive.execution.engine=spark 
</span><span class='line'>
</span><span class='line'>hive&gt; set spark.master=local;
</span><span class='line'>hive&gt; select count(*) from t_house_info ;
</span><span class='line'>Query ID = hadoop_20160328163952_93dafddc-c8b1-4bc9-b851-5e51f6d26fa8
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 0
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>1
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2016-03-28 16:40:02,077 Stage-0_0: 0(+1)/1      Stage-1_0: 0/1
</span><span class='line'>2016-03-28 16:40:03,078 Stage-0_0: 1/1 Finished Stage-1_0: 1/1 Finished
</span><span class='line'>Status: Finished successfully in 2.01 seconds
</span><span class='line'>OK
</span><span class='line'>1
</span><span class='line'>Time taken: 10.169 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; 
</span></code></pre></td></tr></table></div></figure>


<p>再回过头看其实挺简单，和官方文档中的差不多。</p>

<p>hive的日志级别可以通过 <strong>hive-log4j.properties</strong> 来配置。</p>

<h2>坑坑坑</h2>

<p>刚开始弄的时刻，没管spark的版本的。直接上spark-1.6.0，然后完全跑不通，看hive.log的日志，啥都看不出来。最后查看<a href="http://markmail.org/message/reingwn556e7e37y">http://markmail.org/message/reingwn556e7e37y</a>Hive on Spark的老大邮件列表的回复，把 <strong>spark.master=local</strong> 设置成本地跑才看到一点点有用的错误信息。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; set hive.execution.engine=spark;
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2 where day=20160327;
</span><span class='line'>Query ID = hadoop_20160328083028_a9fb9860-38dc-4288-8415-b5b2b88f920a
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Failed to execute spark task, with exception 'org.apache.hadoop.hive.ql.metadata.HiveException(Failed to create spark client.)'
</span><span class='line'>FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.spark.SparkTask
</span></code></pre></td></tr></table></div></figure>


<p>日志里面&#8217;毛&#8217;有用信息都没有！</p>

<p>把日志级别调成debug（hive-log4j.properties），并把 <code>set spark.master=local;</code> 设置成本地。再跑日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-03-28 15:13:52,549 DEBUG internal.PlatformDependent (Slf4JLogger.java:debug(71)) - Javassist: unavailable
</span><span class='line'>2016-03-28 15:13:52,549 DEBUG internal.PlatformDependent (Slf4JLogger.java:debug(71)) - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
</span><span class='line'>
</span><span class='line'>2016-03-28 15:14:56,594 DEBUG storage.BlockManager (Logging.scala:logDebug(62)) - Putting block broadcast_0_piece0 without replication took  8 ms
</span><span class='line'>2016-03-28 15:14:56,597 ERROR util.Utils (Logging.scala:logError(95)) - uncaught error in thread SparkListenerBus, stopping SparkContext
</span><span class='line'>java.lang.AbstractMethodError
</span><span class='line'>        at org.apache.spark.scheduler.SparkListenerBus$class.onPostEvent(SparkListenerBus.scala:62)
</span><span class='line'>        at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:31)
</span><span class='line'>        at org.apache.spark.scheduler.LiveListenerBus.onPostEvent(LiveListenerBus.scala:31)
</span><span class='line'>        at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:55)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus.postToAll(AsynchronousListenerBus.scala:37)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(AsynchronousListenerBus.scala:80)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(AsynchronousListenerBus.scala:65)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(AsynchronousListenerBus.scala:65)
</span><span class='line'>        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1$$anonfun$run$1.apply$mcV$sp(AsynchronousListenerBus.scala:64)
</span><span class='line'>        at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1180)
</span><span class='line'>        at org.apache.spark.util.AsynchronousListenerBus$$anon$1.run(AsynchronousListenerBus.scala:63)</span></code></pre></td></tr></table></div></figure>


<p></p>

<p><strong>调用抽象方法</strong>的错误。然后查看了hive-1.2.1中 SparkListener实现类JobMetricsListener 确实没有(spark-1.6.0)62行错误的onBlockUpdated方法实现。然后把spark换成1.3.1一切就好了，其他就是文章前面写的。</p>

<p><strong>心得</strong>: 刚刚开始用一个新东西的时刻，还是安装官网指定的版本来用省心。等到自己熟悉后，在玩其他的。</p>

<h2><strong>hive on spark</strong> VS <strong>SparkSQL</strong> VS <strong>hive on tez</strong></h2>

<p>前一篇已经弄好了SparkSQL，SparkSQL也有thriftserver服务，这里说说为啥还选择搞hive-on-spark：</p>

<ul>
<li>SparkSQL-Thriftserver所有结果全部内存，快是快，但是不能满足查询大量数据的需求。如果查询几千万的数据，SparkSQL是搞不定的。而hive-on-spark除了计算用spark其他逻辑都是hive的，返回的结果会先写hdfs，再慢慢返回给客户端。</li>
<li>SparkSQL-Thriftserver的是全新重写的，和已有hive业务不一定兼容！！</li>
<li>SparkSQL由于基于内存，再一些调度方面做了优化。如limit: hive是死算，sparksql递增数据量的一次次的试。sparksql可以这么做的，毕竟算好的数据在内存里面放着。</li>
</ul>


<p>hive和sparksql的理念不同，hive的存储是HDFS，而sparksql只是把HDFS作为持久化工具，它的数据基本都放内存。</p>

<p>查看hive的日志，可以看到返回结果后有写HDFS的动作体现，会有类似日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-03-28 19:39:25,687 INFO  exec.FileSinkOperator (Utilities.java:mvFileToFinalPath(1882))
</span><span class='line'> - Moving tmp dir: hdfs://zfcluster/hive/scratchdir/hadoop/de2b263e-9601-4df7-bc38-ba932ae83f42/hive_2016-03-28_19-38-08_834_7914607982986605890-1/-mr-10000/.hive-staging_hive_2016-03-28_19-38-08_834_7914607982986605890-1/_tmp.-ext-10001 
</span><span class='line'> to: hdfs://zfcluster/hive/scratchdir/hadoop/de2b263e-9601-4df7-bc38-ba932ae83f42/hive_2016-03-28_19-38-08_834_7914607982986605890-1/-mr-10000/.hive-staging_hive_2016-03-28_19-38-08_834_7914607982986605890-1/-ext-10001
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>tez的优势spark都有，并且tez其实缓冲优势并不大。而spark的缓冲效果更明显，而且可以快速返回。例如：你查3万条数据，tez是要全部查询然后再返回的，而sparksql取到3万条其他就不算了（效果看起来是这样子，具体没看源码实现；md hive-on-spark还是会全部跑）。</li>
<li>tez还是进程级别的，spark更加细化，可以有process级别！例如，你查数据记录同时又要返回count，这时有些操作是prcess_local级别的，这个tez是不能比的！</li>
<li>spark的日志UI看起来更便捷，呵呵</li>
</ul>


<p>单就从用的角度，spark全面取胜啊。</p>

<h2>参考</h2>

<ul>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started">https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started</a></li>
<li><a href="http://spark.apache.org/docs/1.3.1/configuration.html">http://spark.apache.org/docs/1.3.1/configuration.html</a></li>
<li><a href="http://spark.apache.org/docs/1.3.1/job-scheduling.html#dynamic-resource-allocation">http://spark.apache.org/docs/1.3.1/job-scheduling.html#dynamic-resource-allocation</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SparkSQL-on-YARN的Executors池(动态)配置]]></title>
    <link href="http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn/"/>
    <updated>2016-03-25T15:14:53+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn</id>
    <content type="html"><![CDATA[<h2>官网配置资料</h2>

<ul>
<li><a href="http://spark.apache.org/docs/latest/running-on-yarn.html">http://spark.apache.org/docs/latest/running-on-yarn.html</a></li>
<li><a href="http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup">http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup</a></li>
<li><a href="http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation">http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation</a></li>
</ul>


<h2>实战</h2>

<h4>修改YARN配置，添加spark-yarn-shuffle.jar，同步配置和jar到nodemanager节点并重启。</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ vi etc/hadoop/yarn-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>&lt;value&gt;mapreduce_shuffle,spark_shuffle&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ cp ~/spark-1.6.0-bin-2.6.3/lib/spark-1.6.0-yarn-shuffle.jar share/hadoop/yarn/
</span><span class='line'>
</span><span class='line'>for h in `cat etc/hadoop/slaves` ; do rsync -az share $h:~/hadoop-2.6.3/ ; done 
</span><span class='line'>for h in `cat etc/hadoop/slaves` ; do rsync -az etc $h:~/hadoop-2.6.3/ ; done 
</span><span class='line'>
</span><span class='line'>rsync -vaz etc hadoop-master2:~/hadoop-2.6.3/
</span><span class='line'>rsync -vaz share hadoop-master2:~/hadoop-2.6.3/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-yarn.sh 
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-yarn.sh </span></code></pre></td></tr></table></div></figure>


<h4>原来已经部署了Hive-1.2.1（和spark-1.6.0的hive是匹配的），直接把hive-site.xml做一个软链到spark/conf下面：</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ cd conf/
</span><span class='line'>[hadoop@hadoop-master1 conf]$ ln -s ~/hive/conf/hive-site.xml 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ ll conf/hive-site.xml 
</span><span class='line'>lrwxrwxrwx. 1 hadoop hadoop 36 3月  25 11:30 conf/hive-site.xml -&gt; /home/hadoop/hive/conf/hive-site.xml</span></code></pre></td></tr></table></div></figure>


<p>注意：如果原来配置了tez，把hive-site.xml的 <strong>hive.execution.engine</strong> 配置注释掉。或者启动的时刻换引擎： <code>bin/spark-sql --master yarn-client --hiveconf hive.execution.engine=mr</code></p>

<h4>修改spark配置</h4>

<p>spark-defaults.conf</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 conf]$ cat spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.executorIdleTimeout    600s
</span><span class='line'>spark.dynamicAllocation.minExecutors    160
</span><span class='line'>spark.dynamicAllocation.maxExecutors    1800
</span><span class='line'>spark.dynamicAllocation.schedulerBacklogTimeout   5s
</span><span class='line'>
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address hadoop-master2:18080
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>spark.yarn.jar 配置后，spark启动后直接使用该文件作为executor的main-jar，不需要每次都上传一次spark.jar（每次都搞一下180M也不少资源了）</li>
<li>enabled 启用动态两个都配置必须设置为true</li>
<li>executorIdleTimeout 关闭不用executors需要等待的时间</li>
<li>schedulerBacklogTimeout 增加积压的任务时间来判断是否增加executors</li>
<li>minExecutors 至少存活的executors个数</li>
</ul>


<p>spark-env.sh环境变量</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 conf]$ cat spark-env.sh 
</span><span class='line'>SPARK_CLASSPATH=/home/hadoop/hive/lib/mysql-connector-java-5.1.21-bin.jar:$SPARK_CLASSPATH
</span><span class='line'>HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop
</span><span class='line'>SPARK_DRIVER_MEMORY=30g
</span><span class='line'>SPARK_PID_DIR=/home/hadoop/tmp/pids</span></code></pre></td></tr></table></div></figure>


<h4>启动</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ sbin/start-thriftserver.sh --master yarn-client
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 spark-1.6.0-bin-2.6.3]$ sbin/start-history-server.sh hdfs:///spark-eventlogs</span></code></pre></td></tr></table></div></figure>


<p>收工。</p>

<p>整个过程就是：添加spark-shuffle到yarn，然后配置spark参数，最后就是重启任务（yarn/hiveserver）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop内存环境变量和参数]]></title>
    <link href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/"/>
    <updated>2016-03-17T14:09:26+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args</id>
    <content type="html"><![CDATA[<h2>问题：</h2>

<p><a href="https://www.zhihu.com/question/25498407">https://www.zhihu.com/question/25498407</a></p>

<p>问题是hadoop内存的配置，涉及两个方面：</p>

<ul>
<li>namenode/datanode/resourcemanager/nodemanager的HEAPSIZE环境变量</li>
<li>在配置文件/Configuration中影响MR运行的变量</li>
</ul>


<p>尽管搞hadoop有好一阵子了，对这些变量有个大概的了解，但没有真正的去弄懂他们的区别。乘着这个机会好好的整整（其实就是下载源码然后全文查找<sup>V</sup>^）。</p>

<h2>HEAPSIZE环境变量</h2>

<p>hadoop-env.sh配置文件hdfs和yarn脚本都会加载。hdfs是一脉相承使用 <strong>HADOOP_HEAPSIZE</strong> ，而yarn使用新的环境变量 <strong>YARN_HEAPSIZE</strong> 。</p>

<p>hadoop/hdfs/yarn命令最终会把HEAPSIZE的参数转换了 <strong>JAVA_HEAP_MAX</strong>，把它作为启动参数传递给Java。</p>

<ul>
<li>hadoop</li>
</ul>


<p>hadoop命令是把 <code>HADOOP_HEAPSIZE</code> 转换为 <code>JAVA_HEAP_MAX</code> ，调用路径：</p>

<p><code>hadoop -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>JAVA_HEAP_MAX=-Xmx1000m 
</span><span class='line'>
</span><span class='line'># check envvars which might override default args
</span><span class='line'>if [ "$HADOOP_HEAPSIZE" != "" ]; then
</span><span class='line'>  #echo "run with heapsize $HADOOP_HEAPSIZE"
</span><span class='line'>  JAVA_HEAP_MAX="-Xmx""$HADOOP_HEAPSIZE""m"
</span><span class='line'>  #echo $JAVA_HEAP_MAX
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<ul>
<li>hdfs</li>
</ul>


<p>hdfs其实就是从hadoop脚本里面分离出来的。调用路径：</p>

<p><code>hdfs -&gt; hdfs-config.sh -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<ul>
<li>yarn</li>
</ul>


<p>yarn也调用了hadoop-env.sh，但是设置内存的参数变成了 <strong>YARN_HEAPSIZE</strong> 。调用路径：</p>

<p><code>yarn -&gt; yarn-config.sh -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>JAVA_HEAP_MAX=-Xmx1000m 
</span><span class='line'>
</span><span class='line'># For setting YARN specific HEAP sizes please use this
</span><span class='line'># Parameter and set appropriately
</span><span class='line'># YARN_HEAPSIZE=1000
</span><span class='line'>
</span><span class='line'># check envvars which might override default args
</span><span class='line'>if [ "$YARN_HEAPSIZE" != "" ]; then
</span><span class='line'>  JAVA_HEAP_MAX="-Xmx""$YARN_HEAPSIZE""m"
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<ul>
<li>实例：</li>
</ul>


<p>配置hadoop参数的时刻，一般都是配置 <strong>hadoop-env.sh</strong> 如：<code>export HADOOP_HEAPSIZE=16000</code> 。查看相关进程命令有：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_resourcemanager -Xmx1000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_timelineserver -Xmx1000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_nodemanager -Xmx1000m 
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_journalnode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_namenode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_journalnode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_datanode -Xmx16000m</span></code></pre></td></tr></table></div></figure>


<p>与hdfs有关的内存都修改成功了。而与yarn的还是默认的1g(堆)内存。</p>

<h2>MR配置文件参数</h2>

<p>分成两组，一种是直接设置数字(mb结束的属性)，一种是配置java虚拟机变量的-Xmx。</p>

<pre><code>* yarn.app.mapreduce.am.resource.mb、mapreduce.map.memory.mb、mapreduce.reduce.memory.mb
    用于调度计算内存，是不是还能分配任务（计算额度）
* yarn.app.mapreduce.am.command-opts、mapreduce.map.java.opts、mapreduce.reduce.java.opts
    程序实际启动使用的参数
</code></pre>

<p>一个是控制中枢，一个是实实在在的限制。</p>

<ul>
<li>官网文档的介绍：</li>
</ul>


<blockquote><ul>
<li>mapreduce.map.memory.mb 1024    The amount of memory to request from the scheduler for each map task.</li>
<li>mapreduce.reduce.memory.mb  1024    The amount of memory to request from the scheduler for each reduce task.</li>
<li>mapred.child.java.opts  -Xmx200m    Java opts for the task processes.</li>
</ul>
</blockquote>

<ul>
<li><p>下面用实践来验证效果：</p>

<ul>
<li>先搞一个很大大只有一个block的文件，把程序运行时间拖长一点</li>
<li>修改opts参数，查看效果</li>
<li>修改mb参数，查看效果</li>
</ul>
</li>
<li><p>实践一</p></li>
</ul>


<p>mapreduce.map.memory.mb设置为1000，而mapreduce.map.java.opts设置为1200m。程序照样跑的很欢！！</p>

<p>同时从map的 YarnChild 进程看出起实际作用的是 mapreduce.map.java.opts 参数。memory.mb用来计算节点是否有足够的内存来跑任务，以及用来计算整个集群的可用内存等。而java.opts则是用来限制真正任务的堆内存用量。</p>

<p><strong>注意</strong> ： 这里仅仅是用来测试，正式环境java.opts的内存应该小于memory.mb！！具体配置参考：<a href="http://blog.javachen.com/2015/06/05/yarn-memory-and-cpu-configuration.html">yarn-memory-and-cpu-configuration</a></p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-opts-mb.jpg" alt="" /></p>

<ul>
<li>实践二</li>
</ul>


<p>map.memory.mb设置太大，导致调度失败！</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-mb-1.jpg" alt="" /></p>

<ul>
<li>实践三</li>
</ul>


<p>尽管实际才用不大于1.2G的内存，但是由于mapreduce.map.memory.mb设置为8G，整个集群显示已用内存18G（2 * 8g + 1 * 2g）。登录实际运行任务的机器，实际内存其实不多。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-mb-2.jpg" alt="" />
<img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-mb-3.jpg" alt="" /></p>

<p>reduce和am（appmaster）的参数类似。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-appmaster-mb-1.jpg" alt="" />
<img src="http://winseliu.com/images/blogs/hadoop-opts/yarn-appmaster-mb-2.jpg" alt="" /></p>

<h2>mapred.child.java.opts参数</h2>

<p>这是一个过时的属性，当然你设置也能起效果(没有设置mapreduce.map.java.opts/mapreduce.reduce.java.opts)。相当于把MR的java.opts都设置了。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/mapred-opts.jpg" alt="" /></p>

<p>获取map/reduce的opts中间会取 <strong>mapred.child.java.opts</strong> 的值。</p>

<p><img src="http://winseliu.com/images/blogs/hadoop-opts/mapred-opts-2.jpg" alt="" /></p>

<h2>admin-opts</h2>

<p>查找源码后，其实opts被分成两部分：admin和user。admin的写在前面，user在后面。user设置的opts可以覆盖admin设置的。应该是方便用于设置默认值吧。</p>

<h2>实例</h2>

<p>同时在一台很牛掰的机器上跑程序（分了yarn.nodemanager.resource.memory-mb 26G内存），但是总是只能一次跑一个任务，但还剩很多内存(20G)没有用啊！！初步怀疑是调度算法的问题。</p>

<p>查看了调度的日志，初始化的时刻会输出 <strong>scheduler.capacity.LeafQueue</strong> 的日志，打印了集群控制的一些参数。然后 同时找到一篇<a href="http://stackoverflow.com/questions/33465300/why-does-yarn-job-not-transition-to-running-state">http://stackoverflow.com/questions/33465300/why-does-yarn-job-not-transition-to-running-state</a> 说是调整 <strong>yarn.scheduler.capacity.maximum-am-resource-percent</strong> ，是用于控制appmaster最多可用的资源。</p>

<p>appmaster的默认内存是： <strong>yarn.app.mapreduce.am.resource.mb  1536</strong>（client设置有效）， <strong>yarn.scheduler.capacity.maximum-am-resource-percent 0.1</strong>。</p>

<p>跑第二job的时刻，第二个appmaster调度的时刻没有足够的内存（26G * 0.1 - 1.536 > 1.536），所以就跑不了两个job。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装配置OpenVPN]]></title>
    <link href="http://winseliu.com/blog/2016/03/11/install-and-config-openvpn/"/>
    <updated>2016-03-11T09:46:49+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/11/install-and-config-openvpn</id>
    <content type="html"><![CDATA[<p>由于测试环境搭建不在同一个网络，平时查看hadoop集群状态、提交任务都可以通过hadoop-master的外网来操作。但是要读写kafka，需要直接连通所有的节点，全部映射端口太麻烦。一开始想到了VLAN(虚拟局域网），远远超出能力范围。最后通过搭架VPN来实现与测试环境的透明访问。</p>

<h2>使用集成版本</h2>

<p>参考 <a href="https://linux.cn/article-4733-1.html">https://linux.cn/article-4733-1.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># download https://openvpn.net/index.php/access-server/download-openvpn-as-sw.html
</span><span class='line'>
</span><span class='line'># 安装
</span><span class='line'>[root@cu2 ~]# rpm -ivh openvpn-as-2.0.25-CentOS6.x86_64.rpm 
</span><span class='line'>Preparing...                ########################################### [100%]
</span><span class='line'>   1:openvpn-as             ########################################### [100%]
</span><span class='line'>The Access Server has been successfully installed in /usr/local/openvpn_as
</span><span class='line'>Configuration log file has been written to /usr/local/openvpn_as/init.log
</span><span class='line'>Please enter "passwd openvpn" to set the initial
</span><span class='line'>administrative password, then login as "openvpn" to continue
</span><span class='line'>configuration here: https://192.168.0.214:943/admin
</span><span class='line'>To reconfigure manually, use the /usr/local/openvpn_as/bin/ovpn-init tool.
</span><span class='line'>
</span><span class='line'>Access Server web UIs are available here:
</span><span class='line'>Admin  UI: https://192.168.0.214:943/admin
</span><span class='line'>Client UI: https://192.168.0.214:943/
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# passwd openvpn
</span><span class='line'>
</span><span class='line'>然后通过web admin进行配置。如主机的信息、hostname以及监听绑定的IP</span></code></pre></td></tr></table></div></figure>


<p>配置好以后，本地通过网页下载client程序安装。连接配置后：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>C:\Users\winse&gt;tracert  cu3
</span><span class='line'>
</span><span class='line'>通过最多 30 个跃点跟踪
</span><span class='line'>到 cu3 [192.168.0.148] 的路由:
</span><span class='line'>
</span><span class='line'>  1     2 ms     2 ms     2 ms  172.27.232.1
</span><span class='line'>  2     2 ms     2 ms     2 ms  cu3 [192.168.0.148]
</span><span class='line'>
</span><span class='line'>跟踪完成。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>C:\Users\winse&gt;route print
</span><span class='line'>===========================================================================
</span><span class='line'>IPv4 路由表
</span><span class='line'>===========================================================================
</span><span class='line'>活动路由:
</span><span class='line'>网络目标        网络掩码          网关       接口   跃点数
</span><span class='line'>          0.0.0.0          0.0.0.0      192.168.1.1    192.168.1.102     20
</span><span class='line'>          0.0.0.0        128.0.0.0     172.27.232.1     172.27.232.2     20
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p><a href="http://designmylife.blog.163.com/blog/static/2067142542013527101659960/">http://designmylife.blog.163.com/blog/static/2067142542013527101659960/</a></p>

<p>路由匹配按最大(最亲)方式匹配。上面路由会先匹配mask为 <code>128.0.0.0</code> 的路由。最终把所有的流量经由VPN出去。</p>

<p>通过 <strong>Access Server</strong> 安装简单，配置通过网页来弄，和网上资料的都匹配不上，还有用户数量的限制，囧。</p>

<h2>编译源码安装</h2>

<ul>
<li>服务端安装配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 openvpn-2.3.10]# yum install libpam*
</span><span class='line'>[root@cu2 openvpn-2.3.10]# yum install pam-devel.x86_64
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring lzo-2.06.tar.gz...
</span><span class='line'>  100%     569 KB     569 KB/sec    00:00:01       0 Errors  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# tar zxvf lzo-2.06.tar.gz 
</span><span class='line'>[root@cu2 ~]# cd lzo-2.06
</span><span class='line'>[root@cu2 lzo-2.06]# ./configure 
</span><span class='line'>[root@cu2 lzo-2.06]# make &&  make install
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# ./configure --prefix=/usr/local/openvpn 
</span><span class='line'>[root@cu2 openvpn-2.3.10]# make && make install
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# /usr/local/openvpn/sbin/openvpn --version
</span><span class='line'>OpenVPN 2.3.10 x86_64-unknown-linux-gnu [SSL (OpenSSL)] [EPOLL] [MH] [IPv6] built on Mar  9 2016
</span><span class='line'>
</span><span class='line'>https://github.com/OpenVPN/easy-rsa/releases
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa  help
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa init-pki
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]#  ./easyrsa build-ca
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa gen-req openvpn nopass
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa sign client openvpn
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa gen-req eshore-cu nopass
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa sign server eshore-cu
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# tree pki/
</span><span class='line'>pki/
</span><span class='line'>├── ca.crt
</span><span class='line'>├── certs_by_serial
</span><span class='line'>│   ├── 01.pem
</span><span class='line'>│   └── 02.pem
</span><span class='line'>├── index.txt
</span><span class='line'>├── index.txt.attr
</span><span class='line'>├── index.txt.attr.old
</span><span class='line'>├── index.txt.old
</span><span class='line'>├── issued
</span><span class='line'>│   ├── eshore-cu.crt
</span><span class='line'>│   └── openvpn.crt
</span><span class='line'>├── private
</span><span class='line'>│   ├── ca.key
</span><span class='line'>│   ├── eshore-cu.key
</span><span class='line'>│   └── openvpn.key
</span><span class='line'>├── reqs
</span><span class='line'>│   ├── eshore-cu.req
</span><span class='line'>│   └── openvpn.req
</span><span class='line'>├── serial
</span><span class='line'>└── serial.old
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]#  ./easyrsa gen-dh
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# cd pki
</span><span class='line'>[root@cu2 pki]# cp ca.crt dh.pem issued/eshore-cu.crt private/eshore-cu.key /etc/openvpn/ 
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# cp sample/sample-config-files/server.conf /etc/openvpn/
</span><span class='line'>
</span><span class='line'>  proto tcp
</span><span class='line'>  cert eshore-cu.crt
</span><span class='line'>  key eshore-cu.key 
</span><span class='line'>  dh dh.pem
</span><span class='line'>  # 在客户端额外添加这条路由到VPN
</span><span class='line'>  push "route 192.168.0.0 255.255.255.0"
</span><span class='line'>  # 和AS一样，会添加0.0.0.0到VPN的路由。默认走VPN
</span><span class='line'>  ;push "redirect-gateway def1 bypass-dhcp"
</span><span class='line'>  user nobody
</span><span class='line'>  group nobody
</span><span class='line'>
</span><span class='line'>[root@cu2 pki]# cd /etc/openvpn/
</span><span class='line'>[root@cu2 openvpn]# /usr/local/openvpn/sbin/openvpn --config /etc/openvpn/server.conf 
</span><span class='line'>[root@cu2 openvpn]# /usr/local/openvpn/sbin/openvpn --daemon --config server.conf </span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装客户端：</li>
</ul>


<p><a href="https://openvpn.net/index.php/open-source/downloads.html">https://openvpn.net/index.php/open-source/downloads.html</a> 下载安装对应的版本。</p>

<p>拷贝sample-config/client.ovpn和服务端的ca.crt、openvpn.crt、openvpn.key到config目录下面。</p>

<p>修改client.ovpn:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proto tcp
</span><span class='line'>remote webcu2 1194
</span><span class='line'>cert openvpn.crt
</span><span class='line'>key openvpn.key</span></code></pre></td></tr></table></div></figure>


<p>然后启动 <strong>OpenVPN GUI</strong> ，右键connect就行了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ route print
</span><span class='line'>...
</span><span class='line'>IPv4 路由表
</span><span class='line'>===========================================================================
</span><span class='line'>活动路由:
</span><span class='line'>网络目标        网络掩码          网关       接口   跃点数
</span><span class='line'>          0.0.0.0          0.0.0.0      192.168.1.1    192.168.1.102     20
</span><span class='line'>         10.8.0.1  255.255.255.255         10.8.0.5         10.8.0.6     20
</span><span class='line'>         10.8.0.4  255.255.255.252            在链路上          10.8.0.6    276
</span><span class='line'>         10.8.0.6  255.255.255.255            在链路上          10.8.0.6    276
</span><span class='line'>         10.8.0.7  255.255.255.255            在链路上          10.8.0.6    276
</span><span class='line'>      192.168.0.0    255.255.255.0         10.8.0.5         10.8.0.6     20
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h2>问题</h2>

<ul>
<li>连接到VPN服务端的机器是没有问题，但是不能访问该机器的应用（端口不同）</li>
</ul>


<p>被防火墙限制了，在服务端把10.8.0.0/24加入到防火墙允许。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -A INPUT -s 10.8.0.0/24 -j ACCEPT </span></code></pre></td></tr></table></div></figure>


<ul>
<li>不能访问服务端其他机器</li>
</ul>


<p>在iptables上增加转发</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE</span></code></pre></td></tr></table></div></figure>


<p>查看iptables规则：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -nL -t nat</span></code></pre></td></tr></table></div></figure>


<p>测试下:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ping cu3
</span><span class='line'>
</span><span class='line'>正在 Ping cu3 [192.168.0.148] 具有 32 字节的数据:
</span><span class='line'>来自 192.168.0.148 的回复: 字节=32 时间=5ms TTL=63
</span><span class='line'>来自 192.168.0.148 的回复: 字节=32 时间=5ms TTL=63</span></code></pre></td></tr></table></div></figure>


<p>其他（参数，未实践，记录下来）</p>

<blockquote><p>必须在服务器端的内网网关上将到10.8.0.0/24网段的路由指向到openvpn服务器，不然从服务器端内网其他机器根本找不到去往10.8.0.0/24网段的路由。这里又分两种情况，一种是服务端有内网网关设备的（按如上说法即可）；一种是服务端内网没有网关设备，即服务器通过交换机相连，相互通讯靠广播的情况。我的就是这种情况。需要在想访问的server上增加到10.8.0.0/24的路由，如下</p>

<p>route add -net 10.8.0.0/24 gw 192.168.1.211    #1.211为openvpn服务器的内网IP</p>

<p>Make sure that you&rsquo;ve enabled IP and TUN/TAP forwarding on the OpenVPN server machine.
确定开启了转发功能，然后在openvpn服务器Iptables添加如下两条规则</p>

<p>iptables -A FORWARD -i tun0 -s 10.8.0.0/24 -j ACCEPT    #简单说，允许数据从客户端到后端server
iptables -A FORWARD -i em2 -d 10.8.0.0/24 -j ACCEPT    #允许数据从后端server到客户端</p></blockquote>

<h2>参考</h2>

<ul>
<li><a href="https://openvpn.net/index.php/open-source/documentation/howto.html">https://openvpn.net/index.php/open-source/documentation/howto.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html">http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html</a></li>
<li><a href="http://www.linuxquestions.org/questions/linux-networking-3/openvpn-conencts-but-can%27t-ping-servers-on-the-other-network-660610/">http://www.linuxquestions.org/questions/linux-networking-3/openvpn-conencts-but-can%27t-ping-servers-on-the-other-network-660610/</a></li>
<li><a href="http://www.ilanni.com/?p=9877">http://www.ilanni.com/?p=9877</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html">http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html</a></li>
<li><a href="http://kaifly.blog.51cto.com/3209616/1367591">http://kaifly.blog.51cto.com/3209616/1367591</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rsync与scp优势]]></title>
    <link href="http://winseliu.com/blog/2016/03/07/rsync-vs-scp/"/>
    <updated>2016-03-07T17:05:45+08:00</updated>
    <id>http://winseliu.com/blog/2016/03/07/rsync-vs-scp</id>
    <content type="html"><![CDATA[<p>今天在做flume写kafka数据时，数据从其他目录cp拷贝过来，flume采集程序报错 <strong>程序采集的时刻文件发生了改变</strong>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>07 Mar 2016 16:46:05,535 ERROR [pool-3-thread-1] (org.apache.flume.source.SpoolDirectorySource$SpoolDirectoryRunnable.run:256)  - FATAL: Spool Directory source s1: { spoolDir: /home/hadoop/flume/data/ }: Uncaught exception in SpoolDirectorySource thread. Restart or reconfigure Flume to continue processing.
</span><span class='line'>java.lang.IllegalStateException: File has changed size since being read: /home/hadoop/flume/data/hbase-hadoop-master-cu2.log
</span><span class='line'>        at org.apache.flume.client.avro.ReliableSpoolingFileEventReader.retireCurrentFile(ReliableSpoolingFileEventReader.java:326)
</span><span class='line'>        at org.apache.flume.client.avro.ReliableSpoolingFileEventReader.readEvents(ReliableSpoolingFileEventReader.java:259)</span></code></pre></td></tr></table></div></figure>


<p>联想到scp和rsync，好像rsync是有重命名这样的步骤的。网上也有很多对比这个两个工具的资料。</p>

<ul>
<li><a href="http://stackoverflow.com/questions/20244585/how-does-scp-differ-from-rsync">http://stackoverflow.com/questions/20244585/how-does-scp-differ-from-rsync</a></li>
<li><p><a href="http://superuser.com/questions/193952/why-is-rsync-avz-faster-than-scp-r">http://superuser.com/questions/193952/why-is-rsync-avz-faster-than-scp-r</a></p></li>
<li><p>rsync可以增量复制，并且只复制内容不同的部分</p></li>
<li>rsync可以压缩，通过有断点续传 <code>-P</code></li>
<li>rsync有各种参数： exclude等</li>
<li>SCP也可以增加压缩参数： <code>scp -C -o 'CompressionLevel 9' -o 'IPQoS throughput'  -c arcfour machine:file .</code></li>
<li>rsync会先写临时文件，复制完成后再重命名！</li>
</ul>


<p>这里只关注最后一点，对于按照名称来采集的程序非常关键！下面使用inotify监控目录的操作，在进行scp和rsync时发生的操作：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 test]$ scp -r source target/
</span><span class='line'>[hadoop@cu2 test]$ rm target/source/1234
</span><span class='line'>[hadoop@cu2 test]$ rsync -vaz source target/
</span><span class='line'>sending incremental file list
</span><span class='line'>source/
</span><span class='line'>source/1234
</span><span class='line'>
</span><span class='line'>sent 141 bytes  received 35 bytes  352.00 bytes/sec
</span><span class='line'>total size is 34  speedup is 0.19</span></code></pre></td></tr></table></div></figure>


<p>对应的inotify的输出为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 test]$ inotifywait -m target/source/
</span><span class='line'>Setting up watches.
</span><span class='line'>Watches established.
</span><span class='line'>target/source/ CREATE 1234
</span><span class='line'>target/source/ OPEN 1234
</span><span class='line'>target/source/ MODIFY 1234
</span><span class='line'>target/source/ CLOSE_WRITE,CLOSE 1234
</span><span class='line'>
</span><span class='line'>target/source/ DELETE 1234
</span><span class='line'>
</span><span class='line'>target/source/ ATTRIB,ISDIR 
</span><span class='line'>target/source/ CREATE .1234.ARUg56
</span><span class='line'>target/source/ OPEN .1234.ARUg56
</span><span class='line'>target/source/ ATTRIB .1234.ARUg56
</span><span class='line'>target/source/ MODIFY .1234.ARUg56
</span><span class='line'>target/source/ CLOSE_WRITE,CLOSE .1234.ARUg56
</span><span class='line'>target/source/ ATTRIB .1234.ARUg56
</span><span class='line'>target/source/ MOVED_FROM .1234.ARUg56
</span><span class='line'>target/source/ MOVED_TO 1234
</span></code></pre></td></tr></table></div></figure>


<p>rsync会先写把内容复制到一个临时文件，复制完成后，再重命名为正式的名称。</p>

<p><strong>在生产环境尽量使用rsync来进行文件(夹)的复制/同步操作，即快键有安全。</strong></p>

<p>当然还有奇葩的快速删除海量文件夹的方式也用的是rsync：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rsync --delete-before -d /data/blank/ /var/spool/clientmqueue/ 
</span><span class='line'>
</span><span class='line'>rsync --delete-before -a -H -v --progress --stats /tmp/test/ log/</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://logo32.iteye.com/blog/1564727">http://logo32.iteye.com/blog/1564727</a></li>
<li><a href="http://www.ha97.com/4107.html">http://www.ha97.com/4107.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ganglia页自定义视图]]></title>
    <link href="http://winseliu.com/blog/2016/02/25/ganglia-web-ui-views/"/>
    <updated>2016-02-25T20:29:11+08:00</updated>
    <id>http://winseliu.com/blog/2016/02/25/ganglia-web-ui-views</id>
    <content type="html"><![CDATA[<p>官网自带的页面指标太拥挤，同一个组各指标的顺序不能指定(默认好像是按名称排序的)不便于观察。通过页面的Views页签可以查看自定的图标。</p>

<p>在conf文件夹(由conf_default.php中views_dir指定)下面建立文件名以 <strong>view</strong> 开头的json文件。通过Views还可以聚合多个指标，在一个图中查看整体的变化趋势。配置聚合视图前可以先在 <strong>Aggregate Graphs</strong> 弄出来先瞧一瞧。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /var/www/html/ganglia/
</span><span class='line'># 查看view放置的位置
</span><span class='line'>[root@cu2 ganglia]# grep views_dir conf_default.php 
</span><span class='line'>$conf['views_dir'] = $conf['gweb_confdir'] . '/conf';
</span><span class='line'>
</span><span class='line'># view配置目录
</span><span class='line'>[root@cu2 conf]$ ll
</span><span class='line'>......
</span><span class='line'>-rw-rw-r-- 1 apache apache    58 Oct  2 04:38 view_default.json
</span><span class='line'>-rw-r--r-- 1 root   root    2344 Feb 25 20:12 view_qbevery.json
</span><span class='line'>-rw-r--r-- 1 root   root     241 Feb 25 18:59 view_qb.json
</span><span class='line'>
</span><span class='line'>[root@cu2 conf]# cat view_qb.json 
</span><span class='line'>{
</span><span class='line'>"default_size" : "xlarge",
</span><span class='line'>"view_name": "qb",
</span><span class='line'>"items": [
</span><span class='line'>{
</span><span class='line'>"aggregate_graph": "true",
</span><span class='line'>"graph_type": "stack", 
</span><span class='line'>"host_regex":  [ { "regex" : "cu2" } ], 
</span><span class='line'>"metric_regex": [ { "regex":  "qb_.*" } ],
</span><span class='line'>"title": "qb"
</span><span class='line'>}
</span><span class='line'>],
</span><span class='line'>"view_type": "standard"
</span><span class='line'>}
</span><span class='line'>[root@cu2 conf]# cat view_qbevery.json 
</span><span class='line'>{
</span><span class='line'>"default_size" : "medium",
</span><span class='line'>"view_name": "qbevery",
</span><span class='line'>"items": [
</span><span class='line'>{ "hostname":"cu2","metric":"qb_520k_53d_9.82_120807"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_500k_98d_7.81_116763"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_400k_91d_7.67_116762"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_350k_42d_9.08_120802"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_350k_83d_7.40_116761"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_300k_78d_7.12_116760"}
</span><span class='line'>],
</span><span class='line'>"view_type": "standard"
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="https://github.com/ganglia/ganglia-web/wiki#Views">https://github.com/ganglia/ganglia-web/wiki#Views</a></li>
<li><a href="https://gist.github.com/mnikhil-git/4708591">https://gist.github.com/mnikhil-git/4708591</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ganglia扩展-Python]]></title>
    <link href="http://winseliu.com/blog/2016/02/01/ganglia-python-extension/"/>
    <updated>2016-02-01T18:23:43+08:00</updated>
    <id>http://winseliu.com/blog/2016/02/01/ganglia-python-extension</id>
    <content type="html"><![CDATA[<p>最简单的添加metric的方式使用 <code>gmetric</code> ：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/usr/local/ganglia/bin/gmetric -n "TITLE" -v VALUE -t int16 -g GROUP</span></code></pre></td></tr></table></div></figure>


<p>有时指标计算复杂，通过简单的shell不能满足功能需要。我们可以使用python模块来定制。</p>

<h2>安装</h2>

<p>默认安装会检查Python环境，符合条件会自动的安装Python模块。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia-3.7.2]# yum install -y python-devel
</span><span class='line'>[root@cu2 ganglia-3.7.2]# ./configure --with-gmetad --enable-gexec --enable-status --prefix=/usr/local/ganglia
</span><span class='line'>...
</span><span class='line'>Checking for python
</span><span class='line'>checking for python... /usr/bin/python
</span><span class='line'>checking Python version... 2.6
</span><span class='line'>checking Python support... yes
</span><span class='line'>checking Perl support... no
</span><span class='line'>checking for pkg-config... /usr/bin/pkg-config
</span><span class='line'>checking pkg-config is at least version 0.9.0... yes
</span><span class='line'>...
</span><span class='line'>[root@cu2 ganglia-3.7.2]# make && make install</span></code></pre></td></tr></table></div></figure>


<h2>安装成功</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia]# pwd
</span><span class='line'>/usr/local/ganglia
</span><span class='line'>[root@cu2 ganglia]# ll lib64/ganglia/
</span><span class='line'>total 704
</span><span class='line'>-rwxr-xr-x 1 root root 87344 Feb  1 16:52 modcpu.so
</span><span class='line'>-rwxr-xr-x 1 root root 84566 Feb  1 16:52 moddisk.so
</span><span class='line'>-rwxr-xr-x 1 root root 17896 Feb  1 16:52 modgstatus.so
</span><span class='line'>-rwxr-xr-x 1 root root 84526 Feb  1 16:52 modload.so
</span><span class='line'>-rwxr-xr-x 1 root root 86280 Feb  1 16:52 modmem.so
</span><span class='line'>-rwxr-xr-x 1 root root 31695 Feb  1 16:52 modmulticpu.so
</span><span class='line'>-rwxr-xr-x 1 root root 84928 Feb  1 16:52 modnet.so
</span><span class='line'>-rwxr-xr-x 1 root root 84246 Feb  1 16:52 modproc.so
</span><span class='line'>-rwxr-xr-x 1 root root 53994 Feb  1 16:52 modpython.so
</span><span class='line'>-rwxr-xr-x 1 root root 85584 Feb  1 16:52 modsys.so
</span><span class='line'>[root@cu2 ganglia]# ll etc/conf.d/
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 408 Feb  1 16:52 modpython.conf
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia]# vi etc/gmetad.conf
</span><span class='line'> rrdtool_dir
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia]# cat etc/conf.d/modpython.conf 
</span><span class='line'>/*
</span><span class='line'>  params - path to the directory where mod_python
</span><span class='line'>           should look for python metric modules
</span><span class='line'>
</span><span class='line'>  the "pyconf" files in the include directory below
</span><span class='line'>  will be scanned for configurations for those modules
</span><span class='line'>*/
</span><span class='line'>modules {
</span><span class='line'>  module {
</span><span class='line'>    name = "python_module"
</span><span class='line'>    path = "modpython.so"
</span><span class='line'>    params = "/usr/local/ganglia/lib64/ganglia/python_modules"
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>include ("/usr/local/ganglia/etc/conf.d/*.pyconf")
</span></code></pre></td></tr></table></div></figure>


<h2>Hello World</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia]# cd lib64/ganglia/
</span><span class='line'>[root@cu2 ganglia]# mkdir python_modules
</span><span class='line'>[root@cu2 ganglia]# cd python_modules/
</span><span class='line'>
</span><span class='line'>[root@cu2 python_modules]# cp ~/ganglia-3.7.2/gmond/python_modules/example/example.py ./
</span><span class='line'>[root@cu2 python_modules]# 
</span><span class='line'>
</span><span class='line'>[root@cu2 python_modules]# cd /usr/local/ganglia/etc/conf.d/
</span><span class='line'>[root@cu2 conf.d]# vi example.pyconf
</span><span class='line'>modules {
</span><span class='line'>  module {
</span><span class='line'>    name = "example"
</span><span class='line'>    language = "python"
</span><span class='line'>    param RandomMax {
</span><span class='line'>      value = 600
</span><span class='line'>    }
</span><span class='line'>    param ConstantValue {
</span><span class='line'>      value = 112
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>collection_group {
</span><span class='line'>  collect_every = 10
</span><span class='line'>  time_threshold = 50
</span><span class='line'>  metric {
</span><span class='line'>    name = "PyRandom_Numbers"
</span><span class='line'>    title = "Random"
</span><span class='line'>    value_threshold = 70
</span><span class='line'>  }
</span><span class='line'>  metric {
</span><span class='line'>    name = "PyConstant_Number"
</span><span class='line'>    title = "Constant"
</span><span class='line'>    value_threshold = 70
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@cu2 conf.d]# service gmond restart
</span></code></pre></td></tr></table></div></figure>


<p><strong>example.py</strong> 初始化函数 <code>metric_init</code> 从 <strong>example.pyconf</strong> 文件获取配置、返回可用指标对象（ <code>call_back</code> 关联执行的handler; <code>groups</code> 数据的分组）。</p>

<p>模块中必须包含的三个方法是：</p>

<ul>
<li>def metric_init(params):</li>
<li>def metric_cleanup():</li>
<li>def metric_handler(name):</li>
</ul>


<p>前面两个方法的名字必须是一定的，而最后一个 metric_handler与 <code>metric_init</code> 返回对象的callback对应。<code>__main__</code> 函数用于debug，可以单独调试该模块，以检测是否有错。
更详细的内容看官网的文档<a href="https://github.com/ganglia/monitor-core/wiki/Ganglia-GMond-Python-Modules">Ganglia-GMond-Python-Modules</a></p>

<h2>参考</h2>

<ul>
<li><a href="https://github.com/ganglia/monitor-core/wiki/Ganglia-GMond-Python-Modules">https://github.com/ganglia/monitor-core/wiki/Ganglia-GMond-Python-Modules</a></li>
<li><a href="http://www.cnblogs.com/marysam/archive/2012/01/03/2311187.html">http://www.cnblogs.com/marysam/archive/2012/01/03/2311187.html</a></li>
<li><a href="http://blog.csdn.net/cloudeep/article/details/5669295">http://blog.csdn.net/cloudeep/article/details/5669295</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pdsh]]></title>
    <link href="http://winseliu.com/blog/2016/01/25/pdsh-simple-usage/"/>
    <updated>2016-01-25T19:50:35+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/25/pdsh-simple-usage</id>
    <content type="html"><![CDATA[<p>弄hadoop总是需要折腾不少机器，单单执行 <code>rsync</code> 就挺折腾人的，有时还要排除部分机器来查看一堆机器使用内存情况，等等。以前都使用 <code>expect</code> 结合 <code>for in</code> 来实现，总归简单用着也觉得还行。</p>

<p>但是最近，升级hadoop、tez、安装ganglia被折腾的不行。复制 <code>for</code> 语句到累，原来看过 <code>pdsh</code> 的介绍，不过原来就部署4-5台机器，最近查找Ganglia安装问题的博文里面再次 <code>pdsh</code> ，觉得非常亲切和简洁。再次安装使用也就有了本文。</p>

<h2>安装</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bigdatamgr1 pdsh-2.29]# umask 0022
</span><span class='line'>[root@bigdatamgr1 pdsh-2.29]# ./configure -h
</span><span class='line'>[root@bigdatamgr1 pdsh-2.29]# ./configure --with-dshgroups  --with-exec --with-ssh 
</span><span class='line'>[root@bigdatamgr1 pdsh-2.29]# make && make install
</span></code></pre></td></tr></table></div></figure>


<p>挺多选项的，用 <code>disgroups</code> 加上 <code>ssh</code> 差不多够用了，以后不够用的时刻再慢慢研究这些选项。</p>

<h2>简单使用</h2>

<p>使用pdsh管理机器的前提是已经建立了到目标机器的SSH无密钥登录，而建立这N台机器的无秘钥登录还是少不了 <code>expect</code> (当然你愿意一个个输入yes和密码也是OK的)！</p>

<ul>
<li>加载的模块</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 查看，安装的ssh/exec
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -L
</span><span class='line'>
</span><span class='line'># 设置默认使用的模块
</span><span class='line'>[eshore@bigdatamgr1 ~]$ export PDSH_RCMD_TYPE=exec
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2] ssh %h hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>
</span><span class='line'># 命令行指定模块
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -R ssh -w bigdata1,bigdata2 hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>
</span><span class='line'># 一个个的指定
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ssh:bigdata1,ssh:bigdata2 hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ssh:bigdata[1,2] hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>主机加载</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2,5,6-8] -X nodes hostname
</span><span class='line'>bigdata5: bigdata5
</span><span class='line'>bigdata6: bigdata6
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata8: bigdata8
</span><span class='line'>bigdata7: bigdata7
</span></code></pre></td></tr></table></div></figure>


<p>pdsh除了使用 <code>-w</code> 来指定主机列表，还可以通过文件来指定，如编译时的 <code>--with-machines</code> ，同时可以通过读取默认的位置的文件来获取。在编译pdsh时可以通过 <code>--with-dshgroups</code> 参数来激活此选项，默认可以将一组主机列表写入一个文件中并放到本地主机的 <code>~/.dsh/group</code> 或 <code>/etc/dsh/group</code> 目录下，这样就可以通过 <code>-g</code> 参数调用了。同时 <code>-X groupname</code> 可以用来排除主机列表中属于groupname组的主机（下面会提到group分组）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ export PDSH_RCMD_TYPE=ssh
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ mkdir -p .dsh/group
</span><span class='line'>[eshore@bigdatamgr1 ~]$ cd .dsh/group/
</span><span class='line'>[eshore@bigdatamgr1 group]$ vi nodes
</span><span class='line'>bigdata1
</span><span class='line'>bigdata3
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -g nodes hostname
</span><span class='line'>bigdata3: bigdata3
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-8] -X nodes hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata8: bigdata8
</span><span class='line'>bigdata5: bigdata5
</span><span class='line'>bigdata6: bigdata6
</span><span class='line'>bigdata4: bigdata4
</span><span class='line'>bigdata7: bigdata7</span></code></pre></td></tr></table></div></figure>


<p><code>-w</code> 参数也可以用来读取特定文件中的主机列表，同时结合其他规则和进行过滤（具体查看man帮助）。<code>-x</code> 在主机列表基础上进行过滤（提供多一种的方式来实现过滤）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ cat slaves | head -2
</span><span class='line'>bigdata1
</span><span class='line'>bigdata2
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves hostname | head -5
</span><span class='line'>bigdata8: bigdata8
</span><span class='line'>bigdata6: bigdata6
</span><span class='line'>bigdata5: bigdata5
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata3: bigdata3
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves,-bigdata[2-8]
</span><span class='line'>pdsh&gt; hostname
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>pdsh&gt; 
</span><span class='line'>pdsh&gt; exit
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves,-/bigdata.?/
</span><span class='line'>pdsh@bigdatamgr1: no remote hosts specified
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves -x bigdata[1-7] hostname
</span><span class='line'>bigdata8: bigdata8
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>输出格式化</li>
</ul>


<p>当一台主机的输出多余一行时，pdsh输出的内容看起来并不和谐。使用dshbak格式化</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2] free -m  | dshbak -c
</span><span class='line'>----------------
</span><span class='line'>bigdata1
</span><span class='line'>----------------
</span><span class='line'>             total       used       free     shared    buffers     cached
</span><span class='line'>Mem:         64405      59207       5198          0        429      31356
</span><span class='line'>-/+ buffers/cache:      27420      36985
</span><span class='line'>Swap:        65535         57      65478
</span><span class='line'>----------------
</span><span class='line'>bigdata2
</span><span class='line'>----------------
</span><span class='line'>             total       used       free     shared    buffers     cached
</span><span class='line'>Mem:         64405      58192       6213          0        505      29847
</span><span class='line'>-/+ buffers/cache:      27838      36566
</span><span class='line'>Swap:        65535         58      65477
</span></code></pre></td></tr></table></div></figure>


<h2>批量SSH无密钥登录</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master4 ~]$ cat ssh-copy-id.expect 
</span><span class='line'>#!/usr/bin/expect  
</span><span class='line'>
</span><span class='line'>## Usage $0 [user@]host password
</span><span class='line'>
</span><span class='line'>set host [lrange $argv 0 0];
</span><span class='line'>set password [lrange $argv 1 1] ;
</span><span class='line'>
</span><span class='line'>set timeout 30;
</span><span class='line'>
</span><span class='line'>spawn ssh-copy-id $host ;
</span><span class='line'>
</span><span class='line'>expect {
</span><span class='line'>  "(yes/no)?" { send yes\n; exp_continue; }
</span><span class='line'>  "password:" { send $password\n; exp_continue; }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>exec sleep 1;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master4 ~]$ pdsh -w ^slaves ./ssh-copy-id.expect %h 'PASSWD'
</span><span class='line'>
</span><span class='line'># 验证是否全部成功
</span><span class='line'>[hadoop@hadoop-master4 ~]# pdsh -w ^slaves -x hadoop-slaver[1-16] -R ssh hostname
</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pdsh -w ssh:user00[1-10] "date"
</span><span class='line'>此命令用于在user001到user0010上执行date命令。
</span><span class='line'>pdsh -w ssh:user0[10-31],/1$/ "uptime"
</span><span class='line'>此命令在选择远程主机时使用了正则表达式，表示在user010到user031中选择以1结尾的主机名，即在user011、user021、user031上执行uptime命令
</span><span class='line'>
</span><span class='line'>-l    指定在远程主机上使用的用户名称。例如：
</span><span class='line'>pdsh -R ssh -l opsuser -w user00[1-9] "date"
</span><span class='line'>
</span><span class='line'>-f    设置同时连接到远程主机的个数
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://ixdba.blog.51cto.com/2895551/1550184">并行分布式运维工具pdsh</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Some quick tips on how to get started using pdsh:
</span><span class='line'>Set up your environment:
</span><span class='line'>export PDSH_SSH_ARGS_APPEND=”-o ConnectTimeout=5 -o CheckHostIP=no -o StrictHostKeyChecking=no” (Add this to your .bashrc to save time.)</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://radfest.wordpress.com/2012/05/24/parallel-remote-shelling-via-pdsh/">Parallel remote &ldquo;shelling&rdquo; via pdsh</a></li>
<li><a href="http://kumu-linux.github.io/blog/2013/06/19/pdsh/">Pdsh使用方法</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装配置Ganglia(2)]]></title>
    <link href="http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/"/>
    <updated>2016-01-23T17:47:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2</id>
    <content type="html"><![CDATA[<p>前一篇介绍了全部手工安装Ganglia的文章，当时安装测试的环境比较简单。按照网上的步骤安装好，看到图了以为就懂了。Ganglia的基本多播/单播的概念都没弄懂。</p>

<p>这次有机会把Ganglia安装到正式环境，由于网络复杂一些，遇到新的问题。也更进一步的了解了Ganglia。</p>

<p>后端Gmetad(ganglia meta daemon)和Gmond(ganglia monitoring daemon)是Ganglia的两个组件。</p>

<p>Gmetad负责收集各个cluster的数据，并更新到rrd数据库中；Gmond把本机的数据UDP广播（或者单播给某台机），同时收集集群节点的数据供Gmetad读取。Gmetad并不用于监控数据的汇总，是对已经采集好的全部数据处理并存储到rrdtool数据库。</p>

<h2>搭建yum环境</h2>

<p>由于正式环境没有提供外网环境，所以需要把安装光盘拷贝到机器，作为yum的本地源。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mount -t iso9660 -o loop rhel-server-6.4-x86_64-dvd\[ED2000.COM\].iso iso/
</span><span class='line'>ln -s iso rhel6.4
</span><span class='line'>
</span><span class='line'>vi /etc/yum.repos.d/rhel.repo 
</span><span class='line'>[os]
</span><span class='line'>name = Linux OS Packages
</span><span class='line'>baseurl = file:///opt/rhel6.4
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck = 0
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>再极端点，yum程序都没有安装。到 Packages 目录用 rpm 安装 <code>yum*</code> 。</p>

<p>安装httpd后，把 rhel6.4 源建一个软链接到 <code>/var/www/html/rhel6.4</code> ，其他机器就可以使用该源来进行安装软件了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat /etc/yum.repos.d/rhel.repo
</span><span class='line'>[http]
</span><span class='line'>name=LOCAL YUM server
</span><span class='line'>baseurl = http://cu-omc1/rhel6.4
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0</span></code></pre></td></tr></table></div></figure>


<h2>使用yum安装依赖</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install -y gcc gd httpd php php-devel php-mysql php-pear php-common php-gd php-mbstring php-cli 
</span><span class='line'>
</span><span class='line'>yum install -y rrdtool 
</span><span class='line'>
</span><span class='line'>yum install -y apr*
</span><span class='line'>
</span><span class='line'># 编译Ganglia时加 --with-libpcre=no 可以不安装pcre
</span><span class='line'>yum install -y pcre*
</span><span class='line'>
</span><span class='line'># yum install -y zlib-devel
</span></code></pre></td></tr></table></div></figure>


<h2>(仅)编译安装Ganglia</h2>

<p>下载下面的软件(yum没有这些软件)：</p>

<ul>
<li><a href="http://rpm.pbone.net/index.php3/stat/4/idpl/15992683/dir/scientific_linux_6/com/rrdtool-devel-1.3.8-6.el6.x86_64.rpm.html">rrdtool-devel-1.3.8-6.el6.x86_64.rpm</a></li>
<li><a href="http://download.savannah.gnu.org/releases/confuse/">confuse-2.7.tar.gz</a></li>
<li><a href="http://sourceforge.net/projects/ganglia/files/ganglia%20monitoring%20core/">ganglia</a></li>
<li><a href="http://sourceforge.net/projects/ganglia/files/ganglia-web/">ganglia-web</a></li>
</ul>


<p>安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>umask 0022 # 临时修改下，不然后面会遇到权限问题
</span><span class='line'>
</span><span class='line'>rpm -ivh rrdtool-devel-1.3.8-6.el6.x86_64.rpm 
</span><span class='line'>
</span><span class='line'># yum install -y libconfuse*
</span><span class='line'>tar zxf confuse-2.7.tar.gz
</span><span class='line'>cd confuse-2.7
</span><span class='line'>./configure CFLAGS=-fPIC --disable-nls
</span><span class='line'>make && make install
</span><span class='line'>
</span><span class='line'>tar zxf ganglia-3.7.2.tar.gz 
</span><span class='line'>cd ganglia-3.7.2
</span><span class='line'>./configure --with-gmetad --enable-gexec --enable-status --prefix=/usr/local/ganglia
</span><span class='line'># 可选项，用于指定默认配置位置 `-sysconfdir=/etc/ganglia`
</span><span class='line'>make && make install
</span><span class='line'>
</span><span class='line'>cp gmetad/gmetad.init /etc/init.d/gmetad
</span><span class='line'>chkconfig gmetad on
</span><span class='line'>chkconfig --list | grep gm
</span><span class='line'>
</span><span class='line'>df -h # 把rrds目录放到最大的分区，再做个链接到data目录下
</span><span class='line'>mkdir -p /data/ganglia/rrds
</span><span class='line'>chown nobody:nobody /data/ganglia/rrds
</span><span class='line'>ln -s /usr/local/ganglia/sbin/gmetad /usr/sbin/gmetad
</span><span class='line'>
</span><span class='line'>gmetad -h # 查看默认的config位置。下面两个步骤二选一根据是否配置 sysconfdir 选项
</span><span class='line'># cp gmetad/gmetad.conf /etc/ganglia/
</span><span class='line'>vi /etc/init.d/gmetad 
</span><span class='line'>  /usr/local/ganglia/etc/gmetad.conf #修改原来的默认配置路径
</span><span class='line'> 
</span><span class='line'>cd ganglia-3.7.2/gmond/
</span><span class='line'>ln -s /usr/local/ganglia/sbin/gmond /usr/sbin/gmond
</span><span class='line'>cp gmond.init /etc/init.d/gmond
</span><span class='line'>chkconfig gmond on
</span><span class='line'>chkconfig --list gmond
</span><span class='line'>  
</span><span class='line'>gmond -h # 查看默认的config位置。
</span><span class='line'>./gmond -t &gt;/usr/local/ganglia/etc/gmond.conf
</span><span class='line'>vi /etc/init.d/gmond 
</span><span class='line'>  /usr/local/ganglia/etc/gmond.conf #修改原来的默认配置路径
</span></code></pre></td></tr></table></div></figure>


<h2>配置</h2>

<ul>
<li>Ganglia配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi /usr/local/ganglia/etc/gmetad.conf
</span><span class='line'>  datasource "HADOOP" hadoop-master1
</span><span class='line'>  datasource "CU" cu-ud1
</span><span class='line'>  rrd_rootdir "/data/ganglia/rrds"
</span><span class='line'>  gridname "bigdata"
</span><span class='line'>
</span><span class='line'>vi /usr/local/ganglia/etc/gmond.conf
</span><span class='line'>  cluster {
</span><span class='line'>   name = "CU"
</span><span class='line'>
</span><span class='line'>  udp_send_channel {
</span><span class='line'>   bind_hostname = yes
</span></code></pre></td></tr></table></div></figure>


<p><a href="http://ixdba.blog.51cto.com/2895551/1149003">http://ixdba.blog.51cto.com/2895551/1149003</a></p>

<p>Ganglia的收集数据工作可以工作在单播（unicast)或多播(multicast)模式下，默认为多播模式。</p>

<ul>
<li>单播：发送自己 <strong>收集</strong> 到的监控数据到特定的一台或几台机器上，可以跨网段</li>
<li>多播：发送自己收集到的监控数据到同一网段内所有的机器上，同时收集同一网段内的所有机器发送过来的监控数据。因为是以广播包的形式发送，因此需要同一网段内。但同一网段内，又可以定义不同的发送通道。</li>
</ul>


<p>主机多网卡(多IP)情况下需要绑定到特定的IP，设置bind_hostname来设置要绑定的IP地址。单IP情况下可以不需要考虑。</p>

<p>多播情况下只能在单一网段进行，如果集群存在多个网段，可以分拆成多个子集群（data_source)，或者使用单播来进行配置。期望配置简单点的话，配置多个 data_source 。</p>

<ul>
<li><code>data_source "cluster-db" node1 node2</code>  定义集群名称，以及获取集群监控数据的节点。由于采用multicast模式，每台gmond节点都有本集群内节点服务器的所有监控数据，因此不必把所有节点都列出来。node1 node2是or的关系，如果node1无法下载，则才会尝试去node2下载，所以它们应该都是同一个集群的节点，保存着同样的数据。</li>
<li><code>cluster.name</code> 本节点属于哪个cluster，需要与data_source对应。</li>
<li><code>host.location</code> 类似于hostname的作用。</li>
<li><code>udp_send_channel.mcast_join/host</code> 多播地址，工作在239.2.11.71通道下。如果使用单播模式，则要写host=node1，单播模式下可以配置多个upd_send_channel</li>
<li><code>udp_recv_channel.mcast_join</code></li>
</ul>


<p><strong>参考思路</strong> (未具体实践)：多网段情况可以用单播解决，要是单网段要配置多个data_source(集群)那就换个多播的端口吧！</p>

<h2>启动以及测试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service httpd restart
</span><span class='line'>service gmetad start
</span><span class='line'>service gmond start
</span><span class='line'>
</span><span class='line'>service gmond status
</span><span class='line'>
</span><span class='line'>netstat -anp | grep -E "gmond|gmetad"
</span><span class='line'>
</span><span class='line'># 启动如果有问题，使用调试模式启动查找问题
</span><span class='line'>/usr/sbin/gmetad -d 10
</span><span class='line'>
</span><span class='line'>/usr/local/ganglia/bin/gstat -a
</span><span class='line'>/usr/local/ganglia/bin/gstat -a -i hadoop-master1
</span><span class='line'>
</span><span class='line'>telnet localhost 8649
</span><span class='line'>telnet localhost 8651</span></code></pre></td></tr></table></div></figure>


<p>问题：多播地址绑定失败</p>

<blockquote><p><a href="http://llydmissile.blog.51cto.com/7784666/1411239">http://llydmissile.blog.51cto.com/7784666/1411239</a>
<a href="http://www.cnblogs.com/Cherise/p/4350581.html">http://www.cnblogs.com/Cherise/p/4350581.html</a></p>

<p>测试过程中可能会出现以下错误：Error creating multicast server mcast_join=239.2.11.71 port=8649 mcast_if=NULL family=&lsquo;inet4&rsquo;. Will try again&hellip;，系统不支持多播，需要将多播ip地址加入路由表，使用route add -host 239.2.11.71 dev eth0命令即可，将该命令加入/etc/rc.d/rc.local文件中，一劳永逸</p></blockquote>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master4 ~]# gmond -d 10
</span><span class='line'>loaded module: core_metrics
</span><span class='line'>loaded module: cpu_module
</span><span class='line'>loaded module: disk_module
</span><span class='line'>loaded module: load_module
</span><span class='line'>loaded module: mem_module
</span><span class='line'>loaded module: net_module
</span><span class='line'>loaded module: proc_module
</span><span class='line'>loaded module: sys_module
</span><span class='line'>udp_recv_channel mcast_join=239.2.11.71 mcast_if=NULL port=8649 bind=239.2.11.71 buffer=0
</span><span class='line'>Error creating multicast server mcast_join=239.2.11.71 port=8649 mcast_if=NULL family='inet4'.  Will try again...</span></code></pre></td></tr></table></div></figure>


<p>环境的default route被清理掉了(或者是由于网关和本机不在同一网段)。需要手动添加一条到网卡的route。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master4 ~]# route
</span><span class='line'>Kernel IP routing table
</span><span class='line'>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span><span class='line'>192.168.32.0    *               255.255.255.0   U     0      0        0 bond0
</span><span class='line'>192.168.31.0    192.168.32.254  255.255.255.0   UG    0      0        0 bond0
</span><span class='line'>link-local      *               255.255.0.0     U     1006   0        0 bond0
</span><span class='line'>[root@hadoop-master4 ~]# route add -host 239.2.11.71 dev bond0
</span><span class='line'>[root@hadoop-master4 ~]# route
</span><span class='line'>Kernel IP routing table
</span><span class='line'>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span><span class='line'>239.2.11.71     *               255.255.255.255 UH    0      0        0 bond0
</span><span class='line'>192.168.32.0    *               255.255.255.0   U     0      0        0 bond0
</span><span class='line'>192.168.31.0    192.168.32.254  255.255.255.0   UG    0      0        0 bond0
</span><span class='line'>link-local      *               255.255.0.0     U     1006   0        0 bond0</span></code></pre></td></tr></table></div></figure>


<h2>安装GWeb</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd ~/ganglia-web-3.7.1
</span><span class='line'>vi Makefile # 一次性配置好，不再需要去修改conf_default.php
</span><span class='line'>  GDESTDIR = /var/www/html/ganglia
</span><span class='line'>  GCONFDIR = /usr/local/ganglia/etc/
</span><span class='line'>  GWEB_STATEDIR = /var/www/html/ganglia
</span><span class='line'>  # Gmetad rootdir (parent location of rrd folder)
</span><span class='line'>  GMETAD_ROOTDIR = /data/ganglia
</span><span class='line'>  APACHE_USER = apache
</span><span class='line'>make install
</span><span class='line'>
</span><span class='line'># 注意：内网还是需要改下 conf_default.php 一堆jquery的js。
</span><span class='line'># 如果Web不能访问，查看下防火墙以及SELinux
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>httpd登录密码配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>htpasswd -c /var/www/html/ganglia/etc/htpasswd.users gangliaadmin 
</span><span class='line'>
</span><span class='line'>vi /etc/httpd/conf/httpd.conf 
</span><span class='line'>
</span><span class='line'>  &lt;Directory "/var/www/html/ganglia"&gt;
</span><span class='line'>  #  SSLRequireSSL
</span><span class='line'>     Options None
</span><span class='line'>     AllowOverride None
</span><span class='line'>     &lt;IfVersion &gt;= 2.3&gt;
</span><span class='line'>        &lt;RequireAll&gt;
</span><span class='line'>           Require all granted
</span><span class='line'>  #        Require host 127.0.0.1
</span><span class='line'>
</span><span class='line'>           AuthName "Ganglia Access"
</span><span class='line'>           AuthType Basic
</span><span class='line'>           AuthUserFile /var/www/html/ganglia/etc/htpasswd.users
</span><span class='line'>           Require valid-user
</span><span class='line'>        &lt;/RequireAll&gt;
</span><span class='line'>     &lt;/IfVersion&gt;
</span><span class='line'>     &lt;IfVersion &lt; 2.3&gt;
</span><span class='line'>        Order allow,deny
</span><span class='line'>        Allow from all
</span><span class='line'>  #     Order deny,allow
</span><span class='line'>  #     Deny from all
</span><span class='line'>  #     Allow from 127.0.0.1
</span><span class='line'>
</span><span class='line'>        AuthName "Ganglia Access"
</span><span class='line'>        AuthType Basic
</span><span class='line'>        AuthUserFile /var/www/html/ganglia/etc/htpasswd.users
</span><span class='line'>        Require valid-user
</span><span class='line'>     &lt;/IfVersion&gt;
</span><span class='line'>  &lt;/Directory&gt;
</span><span class='line'>
</span><span class='line'>service httpd restart
</span></code></pre></td></tr></table></div></figure>


<p>如果在nginx做权限控制，一样很简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>location /ganglia {
</span><span class='line'>      proxy_pass http://localhost/ganglia;
</span><span class='line'>      auth_basic "Ganglia Access";
</span><span class='line'>      auth_basic_user_file "/var/www/html/ganglia/etc/htpasswd.users";
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>集群配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /usr/local 
</span><span class='line'>for h in cu-ud1 cu-ud2 hadoop-master1 hadoop-master2 ; do 
</span><span class='line'>  cd /usr/local;
</span><span class='line'>  rsync -vaz  ganglia $h:/usr/local/ ;
</span><span class='line'>  ssh $h ln -s /usr/local/ganglia/sbin/gmond /usr/sbin/gmond ;
</span><span class='line'>  scp /etc/init.d/gmond $h:/etc/init.d/ ;
</span><span class='line'>  ssh $h "chkconfig gmond on" ;
</span><span class='line'>  ssh $h "yum install apr* -y" ; 
</span><span class='line'>  ssh $h "service gmond start" ; 
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'># 不同的集群，gmond.conf的cluster.name需要修改
</span><span class='line'>
</span><span class='line'>telnet hadoop-master1 8649
</span><span class='line'>netstat -anp | grep gm
</span></code></pre></td></tr></table></div></figure>


<p>要是集群有变动，添加还好，删除的话，会存在原来的旧数据，页面会提示机器down掉了。可以删除rrds目录下对应集群中节点的数据，然后重庆gmetad/httpd即可。</p>

<h2>参考</h2>

<h3>内容</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>防火墙规则设置
</span><span class='line'>iptables -I INPUT 3 -p tcp -m tcp --dport 80 -j ACCEPT
</span><span class='line'>iptables -I INPUT 3 -p udp -m udp --dport 8649 -j ACCEPT
</span><span class='line'>
</span><span class='line'>service iptables save
</span><span class='line'>service iptables restart
</span><span class='line'>
</span><span class='line'>关闭selinux
</span><span class='line'>vi /etc/selinux/config
</span><span class='line'>SELINUX=disabled
</span><span class='line'>setenforce 0
</span></code></pre></td></tr></table></div></figure>


<p>实际应用中，需要监控的机器往往在不同的网段内，这个时候，就不能用gmond默认的多播方式（用于同一个网段内）来传送数据，必须使用单播的方法。</p>

<p>gmond可以配置成为一个cluster，这些gmond节点之间相互发送各自的监控数据。所以每个gmond节点上实际上都会有 cluster内的所有节点的监控数据。gmetad只需要去某一个节点获取数据就可以了。</p>

<p>web front-end 一个基于web的监控界面，通常和Gmetad安装在同一个节点上(还需确认是否可以不在一个节点上，因为php的配置文件中ms可配置gmetad的地址及端口)，它从Gmetad取数据，并且读取rrd数据库，生成图片，显示出来。</p>

<p>gmetad周期性的去gmond节点或者gmetad节点poll数据。一个gmetad可以设置多个datasource，每个datasource可以有多个备份，一个失败还可以去其他host取数据。Gmetad只有tcp通道，一方面他向datasource发送请求，另一方面会使用一个tcp端口，发 布自身收集的xml文件，默认使用8651端口。所以gmetad即可以从gmond也可以从其他的gmetad得到xml数据。</p>

<p>对于IO来说，Gmetad默认15秒向gmond取一次xml数据，如果gmond和gmetad都是在同一个节点，这样就相当于本地io请求。同时gmetad请求完xml文件后，还需要对其解析，也就是说按默认设置每15秒需要解析一个10m级别的xml文件，这样cpu的压力就会很大。同时它还有写入RRD数据库，还要处理来自web客户端的解析请求，也会读RRD数据库。这样本身的IO CPU 网络压力就很大，因此这个节点至少应该是个空闲的而且能力比较强的节点。</p>

<ul>
<li>多播模式配置
这个是默认的方式，基本上不需要修改配置文件，且所有节点的配置是一样的。这种模式的好处是所有的节点上的 gmond 都有完备的数据，gmetad 连接其中任意一个就可以获取整个集群的所有监控数据，很方便。
其中可能要修改的是 mcast_if 这个参数，用于指定多播的网络接口。如果有多个网卡，要填写对应的内网接口。</li>
<li>单播模式配置
监控机上的接收 Channel 配置。我们使用 UDP 单播模式，非常简单。我们的集群有部分机器在另一个机房，所以监听了 0.0.0.0，如果整个集群都在一个内网中，建议只 bind 内网地址。如果有防火墙，要打开相关的端口。</li>
<li>最重要的配置项是 data_source: <code>data_source "my-cluster" localhost:8648</code> 如果使用的是默认的 8649 端口，则端口部分可以省略。如果有多个集群，则可以指定多个 data_source，每行一个。</li>
<li>最后是 gridname 配置，用于给整个 Grid 命名</li>
<li><a href="https://github.com/ganglia/gmond_python_modules">https://github.com/ganglia/gmond_python_modules</a></li>
</ul>


<h3>网址</h3>

<ul>
<li><a href="http://yhz.me/blog/Install-Ganglia-On-CentOS.html">在 CentOS 6.5 上安装 Ganglia 3.6.0</a></li>
<li>*<a href="http://ixdba.blog.51cto.com/2895551/1149003">分布式监控系统ganglia配置文档</a></li>
<li><p>*<a href="http://www.3mu.me/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%80%E6%BA%90%E7%9B%91%E6%8E%A7%E8%BD%AF%E4%BB%B6ganglia-%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/">企业级开源监控软件Ganglia 安装与配置</a></p></li>
<li><p>*<a href="http://jerrypeng.me/2014/07/04/server-side-java-monitoring-ganglia/">Java 服务端监控方案（二. Ganglia 篇）</a></p></li>
<li><a href="http://jerrypeng.me/2014/07/22/server-side-java-monitoring-nagios/">Java 服务端监控方案（三. Nagios 篇）</a></li>
<li><p><a href="https://github.com/ganglia/ganglia-web/wiki/Nagios-Integration">https://github.com/ganglia/ganglia-web/wiki/Nagios-Integration</a></p></li>
<li><p><a href="https://ganglia.wikimedia.org/latest/">维基百科Ganglia</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[坑]]></title>
    <link href="http://winseliu.com/blog/2016/01/19/hole/"/>
    <updated>2016-01-19T16:53:29+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/19/hole</id>
    <content type="html"><![CDATA[<h2>Set</h2>

<p><img src="http://winseliu.com/images/blogs/hole-set-add-diff.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Set&lt;BlockedInfo&gt; diffs = new HashSet&lt;&gt;();
</span><span class='line'>diffs.addAll(oldBlockedList);
</span><span class='line'>diffs.addAll(newBlockedList);
</span><span class='line'>Iterator&lt;BlockedInfo&gt; iterator = diffs.iterator();
</span><span class='line'>while (iterator.hasNext()) {
</span><span class='line'>  BlockedInfo i = iterator.next();
</span><span class='line'>  if (oldBlockedList.contains(i) && newBlockedList.contains(i)) {
</span><span class='line'>      iterator.remove();
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>第二段代码希望找出前后两个list的差别，即XOR的效果。但是。。。为什么呢？想一想。</p>

<p>用guava库一行代码搞定：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Sets.difference(Sets.union(oldBlockedList, newBlockedList), Sets.intersection(oldBlockedList, newBlockedList))</span></code></pre></td></tr></table></div></figure>


<h2>hive建表</h2>

<p>由于fs.defaultFS和hive.metastore.warehouse.dir对不上，建表后不能删除。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;hdfs://zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;hdfs://zfcluster:8020/hive/warehousedir&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<p>删除表报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; drop table es_t_house_monitor2;
</span><span class='line'>FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.lang.IllegalArgumentException: Wrong FS: hdfs://zfcluster:8020/hive/warehousedir/es_t_house_monitor2, expected: hdfs://zfcluster)</span></code></pre></td></tr></table></div></figure>


<p>建错了，只能先改！然后把hive.metastore.warehouse.dir和fs.defaultFS调成一致。</p>

<p>修改hive持久化（数据库）的表sds，找到location是该路径的改掉。然后就可以drop表了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[配置TEZ-UI]]></title>
    <link href="http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run/"/>
    <updated>2016-01-12T20:28:35+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run</id>
    <content type="html"><![CDATA[<p>tez-ui很早就出来了，荒废了很多时间。今天才把它配置出来，效果挺不错的，和spark-web差不多。</p>

<p>记录了在hive-1.2.1上配置tez-0.7.0过程，配置运行hadoop2.6.3-timeline以及为tez添加tez-ui特性的步骤。</p>

<h2>编译tez-0.7.0</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ mvn package -Dhadoop.version=2.6.3 -DskipTests
</span><span class='line'>
</span><span class='line'>[INFO] Reactor Summary:
</span><span class='line'>[INFO] 
</span><span class='line'>[INFO] tez ................................................ SUCCESS [  0.831 s]
</span><span class='line'>[INFO] tez-api ............................................ SUCCESS [  6.580 s]
</span><span class='line'>[INFO] tez-common ......................................... SUCCESS [  0.124 s]
</span><span class='line'>[INFO] tez-runtime-internals .............................. SUCCESS [  0.676 s]
</span><span class='line'>[INFO] tez-runtime-library ................................ SUCCESS [  1.378 s]
</span><span class='line'>[INFO] tez-mapreduce ...................................... SUCCESS [  0.989 s]
</span><span class='line'>[INFO] tez-examples ....................................... SUCCESS [  0.105 s]
</span><span class='line'>[INFO] tez-dag ............................................ SUCCESS [  2.391 s]
</span><span class='line'>[INFO] tez-tests .......................................... SUCCESS [  0.187 s]
</span><span class='line'>[INFO] tez-ui ............................................. SUCCESS [02:23 min]
</span><span class='line'>[INFO] tez-plugins ........................................ SUCCESS [  0.017 s]
</span><span class='line'>[INFO] tez-yarn-timeline-history .......................... SUCCESS [  0.595 s]
</span><span class='line'>[INFO] tez-yarn-timeline-history-with-acls ................ SUCCESS [  0.316 s]
</span><span class='line'>[INFO] tez-mbeans-resource-calculator ..................... SUCCESS [  0.189 s]
</span><span class='line'>[INFO] tez-tools .......................................... SUCCESS [  0.017 s]
</span><span class='line'>[INFO] tez-dist ........................................... SUCCESS [ 16.554 s]
</span><span class='line'>[INFO] Tez ................................................ SUCCESS [  0.015 s]
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] BUILD SUCCESS
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] Total time: 02:55 min
</span><span class='line'>[INFO] Finished at: 2016-01-12T19:08:50+08:00
</span><span class='line'>[INFO] Final Memory: 63M/756M
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span></code></pre></td></tr></table></div></figure>


<h2>tez嵌入到hive</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 上传tez程序到hdfs
</span><span class='line'>[hadoop@cu2 ~]$ cd sources/apache-tez-0.7.0-src/tez-dist/target/
</span><span class='line'>[hadoop@cu2 target]$ hadoop fs -mkdir -p /apps/tez-0.7.0
</span><span class='line'>[hadoop@cu2 target]$ hadoop fs -put tez-0.7.0.tar.gz /apps/tez-0.7.0/
</span><span class='line'>
</span><span class='line'>// TEZ_CONF_DIR = HADOOP_CONF_DIR
</span><span class='line'>[hadoop@cu2 ~]$ cd hadoop-2.6.3/etc/hadoop/
</span><span class='line'>[hadoop@cu2 hadoop]$ vi tez-site.xml
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>&lt;value&gt;${fs.defaultFS}/apps/tez-0.7.0/tez-0.7.0.tar.gz&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>// 本地tez jars加入HADOOP_CLASSPATH
</span><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ cd tez-dist/target/
</span><span class='line'>archive-tmp/              maven-archiver/           tez-0.7.0/                tez-0.7.0-minimal.tar.gz  tez-0.7.0.tar.gz          tez-dist-0.7.0-tests.jar  
</span><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ cd tez-dist/target/
</span><span class='line'>[hadoop@cu2 target]$ mv tez-0.7.0 ~/
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ vi apache-hive-1.2.1-bin/conf/hive-env.sh
</span><span class='line'>
</span><span class='line'>// 多个jline版本 http://stackoverflow.com/questions/28997441/hive-startup-error-terminal-initialization-failed-falling-back-to-unsupporte
</span><span class='line'>export HADOOP_USER_CLASSPATH_FIRST=true
</span><span class='line'>export TEZ_HOME=/home/hadoop/tez-0.7.0
</span><span class='line'>export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/*:$TEZ_HOME/lib/*
</span><span class='line'>
</span><span class='line'>// http://stackoverflow.com/questions/26988388/hive-0-14-0-not-starting [/tmp/hive on HDFS should be writable. Current permissions are: rwxrwxr-x]
</span><span class='line'>// hive.metastore.warehouse.dir  hive.exec.scratchdir
</span><span class='line'>[hadoop@cu2 hive]$ rm -rf /tmp/hive
</span><span class='line'>[hadoop@cu2 hive]$ hadoop fs -rmr /tmp/hive
</span><span class='line'>// 或者修改权限 hadoop fs -chmod 777 /tmp/hive</span></code></pre></td></tr></table></div></figure>


<h2>启用/使用tez</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop]$ cat ~/hive/conf/hive-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hive.execution.engine&lt;/name&gt;
</span><span class='line'>&lt;value&gt;tez&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ bin/hive
</span><span class='line'>...
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2;
</span><span class='line'>Query ID = hadoop_20160112200359_f8be3d1c-9adc-42c0-abb9-2643dfef2cc7
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1452600034599_0001)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 20.83 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>67
</span><span class='line'>Time taken: 27.823 seconds, Fetched: 1 row(s)
</span></code></pre></td></tr></table></div></figure>


<h2>部署/启动hadoop-timeline</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop]$ vi etc/hadoop/yarn-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.hostname&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;hadoop-master2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.http-cross-origin.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.resourcemanager.system-metrics-publisher.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ for h in hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/yarn-daemon.sh start timelineserver
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/stop-all.sh
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/start-all.sh
</span></code></pre></td></tr></table></div></figure>


<h2>部署tez-ui</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 放置tez-ui
</span><span class='line'>[hadoop@cu2 target]$ cd ../../tez-ui/
</span><span class='line'>[hadoop@cu2 tez-ui]$ cd target/
</span><span class='line'>[hadoop@cu2 target]$ ll
</span><span class='line'>total 1476
</span><span class='line'>drwxrwxr-x 3 hadoop hadoop    4096 Jan 12 19:08 classes
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop    4096 Jan 12 19:08 maven-archiver
</span><span class='line'>drwxrwxr-x 8 hadoop hadoop    4096 Jan 12 19:08 tez-ui-0.7.0
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop    3058 Jan 12 19:08 tez-ui-0.7.0-tests.jar
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop 1491321 Jan 12 19:08 tez-ui-0.7.0.war
</span><span class='line'>[hadoop@cu2 target]$ mv tez-ui-0.7.0 ~/
</span><span class='line'>
</span><span class='line'>// 部署tez-ui
</span><span class='line'>[hadoop@cu2 ~]$ cd apache-tomcat-7.0.67/conf/
</span><span class='line'>修改端口为9999
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ vi conf/server.xml 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ cd conf/Catalina/localhost/
</span><span class='line'>[hadoop@cu2 localhost]$ vi tez-ui.xml
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ bin/startup.sh 
</span><span class='line'>
</span><span class='line'>// tez添加tez-ui功能
</span><span class='line'>[hadoop@cu2 hive]$ vi ~/hadoop-2.6.3/etc/hadoop/tez-site.xml 
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>&lt;value&gt;${fs.defaultFS}/apps/tez-0.7.0/tez-0.7.0.tar.gz&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.history.logging.service.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.tez-ui.history-url.base&lt;/name&gt;
</span><span class='line'>&lt;value&gt;http://hadoop-master2:9999/tez-ui/&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span></code></pre></td></tr></table></div></figure>


<p>再运行一遍hive，查询一两个SQL。</p>

<p>最终效果：</p>

<p><img src="http://winseliu.com/images/blogs/tez-ui.png" alt="" /></p>

<h2>参考</h2>

<ul>
<li><a href="http://tez.apache.org/install.html">http://tez.apache.org/install.html</a></li>
<li><a href="http://tez.apache.org/tez-ui.html">http://tez.apache.org/tez-ui.html</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html">http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(4)HA升级]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/"/>
    <updated>2016-01-07T23:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade</id>
    <content type="html"><![CDATA[<p>官网的文档[HDFSHighAvailabilityWithQJM.html]和[HdfsRollingUpgrade.html]（Note that rolling upgrade is supported only from Hadoop-2.4.0 onwards.）很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<ol>
<li>关闭所有的namenode，部署新版本的hadoop</li>
<li>启动所有的journalnode，是所有！！升级namenode的同时，也会升级所有journalnode！！</li>
<li>使用-upgrade选项启动一台namenode。启动的这台namenode会直接进入active状态，升级本地的元数据，同时会升级shared edit log（也就是journalnode的数据）</li>
<li>使用-bootstrapStandby启动其他namenode，同步更新。不能使用-upgrade选项！（我也没试，不知道试了是啥效果）</li>
</ol>


<h2>关闭集群，部署新版本的hadoop</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/08 09:10:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/08 09:10:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping zkfc
</span><span class='line'>hadoop-master2: stopping zkfc
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ~/hadoop-2.6.3
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ ll
</span><span class='line'>total 52
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 bin
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop    32 Jan  8 06:05 etc -&gt; /home/hadoop/hadoop-2.2.0/ha-etc
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 include
</span><span class='line'>drwxr-xr-x 3 hadoop hadoop  4096 Dec 18 01:52 lib
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 libexec
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 15429 Dec 18 01:52 LICENSE.txt
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop  4096 Jan  8 03:37 logs
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   101 Dec 18 01:52 NOTICE.txt
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  1366 Dec 18 01:52 README.txt
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 sbin
</span><span class='line'>drwxr-xr-x 3 hadoop hadoop  4096 Jan  7 08:00 share
</span><span class='line'>
</span><span class='line'>#// 同步
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs ~/hadoop-2.6.3 $h:~/ ; done</span></code></pre></td></tr></table></div></figure>


<h2>启动所有Journalnode</h2>

<p>2.6和2.2用的是一份配置！etc通过软链接到2.2的ha-etc配置。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/hadoop-daemons.sh --hostnames "hadoop-master1" --script /home/hadoop/hadoop-2.2.0/bin/hdfs start journalnode
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
</span><span class='line'>31047 JournalNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>31097 Jps</span></code></pre></td></tr></table></div></figure>


<h2>升级一台namenode</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ bin/hdfs namenode -upgrade
</span><span class='line'>...
</span><span class='line'>16/01/08 09:13:54 INFO namenode.NameNode: createNameNode [-upgrade]
</span><span class='line'>...
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSImage: Starting upgrade of local storage directories.
</span><span class='line'>   old LV = -47; old CTime = 0.
</span><span class='line'>   new LV = -60; new CTime = 1452244437060
</span><span class='line'>16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>官网文档上说，除了升级了namenode的本地元数据外，sharededitlog也被升级了的。</p>

<p>查看journalnode的日志，确实journalnode也升级了：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-journalnode-hadoop-master1.log 
</span><span class='line'>...
</span><span class='line'>2016-01-08 09:13:57,070 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Starting upgrade of edits directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,072 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Starting upgrade of edits directory: .
</span><span class='line'>   old LV = -47; old CTime = 0.
</span><span class='line'>   new LV = -60; new CTime = 1452244437060
</span><span class='line'>2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,222 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastWriterEpoch from 2 to 3 for client /172.17.0.1
</span><span class='line'>2016-01-08 09:16:57,731 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 3 to 4 for client /172.17.0.1
</span><span class='line'>2016-01-08 09:16:57,735 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/data/journal/zfcluster)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>升级的namenode是前台运行的，不要关闭这个进程。接下来把另一台namenode同步一下。</p>

<h2>同步另一台namenode</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>...
</span><span class='line'>=====================================================
</span><span class='line'>About to bootstrap Standby ID nn2 from:
</span><span class='line'>           Nameservice ID: zfcluster
</span><span class='line'>        Other Namenode ID: nn1
</span><span class='line'>  Other NN's HTTP address: http://hadoop-master1:50070
</span><span class='line'>  Other NN's IPC  address: hadoop-master1/172.17.0.1:8020
</span><span class='line'>             Namespace ID: 639021326
</span><span class='line'>            Block pool ID: BP-1695500896-172.17.0.1-1452152050513
</span><span class='line'>               Cluster ID: CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
</span><span class='line'>           Layout version: -60
</span><span class='line'>       isUpgradeFinalized: false
</span><span class='line'>=====================================================
</span><span class='line'>16/01/08 09:15:19 INFO ha.BootstrapStandby: The active NameNode is in Upgrade. Prepare the upgrade for the standby NameNode as well.
</span><span class='line'>16/01/08 09:15:19 INFO common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 5008@hadoop-master2
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Opening connection to http://hadoop-master1:50070/imagetransfer?getimage=1&txid=1126&storageInfo=-60:639021326:1452244437060:CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001126 size 977 bytes.
</span><span class='line'>16/01/08 09:15:21 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h2>重新启动集群</h2>

<p>ctrl+c关闭hadoop-master1 upgrade的namenode。启动整个集群。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</span><span class='line'>16/01/08 09:16:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: journalnode running as process 31047. Stop it first.
</span><span class='line'>16/01/08 09:16:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
</span><span class='line'>31047 JournalNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>31596 DFSZKFailoverController
</span><span class='line'>31655 Jps
</span><span class='line'>31294 NameNode
</span></code></pre></td></tr></table></div></figure>


<h2>后记：Journalnode重置</h2>

<p>在HA和non-HA环境来回的切换，最后启动HA时master起不来，执行bootstrapStandby也不行。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-01-08 06:15:36,746 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [172.17.0.1:8485]. Skipping.
</span><span class='line'>org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 1/1. 1 exceptions thrown:
</span><span class='line'>172.17.0.1:8485: Asked for firstTxId 1022 which is in the middle of file /data/journal/zfcluster/current/edits_0000000000000001021-0000000000000001022
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FileJournalManager.getRemoteEditLogs(FileJournalManager.java:198)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:640)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:181)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:203)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:17453)
</span><span class='line'>        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>关闭集群，启动journalnode，跳转到没有问题的namenode机器，执行initializeSharedEdits命令。然后在有问题的namenode上重新初始化！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh</span></code></pre></td></tr></table></div></figure>


<p>后话（谨慎，没有试验过，猜想而已）： 其实上面HA升级的步骤，如果upgrade时没用启动journalnode，导致了问题的话，把journalnode重置应该也是可以的。</p>

<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(3)HA配置]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/"/>
    <updated>2016-01-07T23:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha</id>
    <content type="html"><![CDATA[<p>官网的文档[HDFSHighAvailabilityWithQJM.html]很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<h2>配置</h2>

<p>hadoop-master1和hadoop-master2之间无密钥登录（failover要用到）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-keygen
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master2
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master1</span></code></pre></td></tr></table></div></figure>


<p>配置文件修改：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/core-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hdfs://zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/tmp&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/hdfs-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span><span class='line'>&lt;value&gt; &lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.nameservices&lt;/name&gt;
</span><span class='line'>&lt;value&gt;zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.namenodes.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;nn1,nn2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;qjournal://hadoop-master1:8485/zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.client.failover.proxy.provider.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/journal&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
</span><span class='line'>&lt;value&gt;sshfence&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
</span><span class='line'>&lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>启动</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ..
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.2.0 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>#// 此时可以启动datanode，通过50070端口看namenode的状态
</span><span class='line'>
</span><span class='line'>#// Automatic failover，zkfc和namenode没有启动顺序的问题！
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs zkfc -formatZK
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs haadmin -failover nn1 nn2
</span><span class='line'>
</span><span class='line'>#// 测试failover，把一个active的namenode直接kill掉，看看另一个是否变成active！
</span><span class='line'>
</span><span class='line'># 重启
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/07 10:57:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/07 10:58:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: no zkfc to stop
</span><span class='line'>hadoop-master1: no zkfc to stop
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>16/01/07 10:59:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>16/01/07 10:59:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ jps
</span><span class='line'>15241 DFSZKFailoverController
</span><span class='line'>14882 NameNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>18715 Jps
</span><span class='line'>15076 JournalNode</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html</a></li>
<li><a href="http://www.xlgps.com/article/40993.html">http://www.xlgps.com/article/40993.html</a></li>
<li><a href="http://hbase.apache.org/book.html#basic.prerequisites">http://hbase.apache.org/book.html#basic.prerequisites</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
