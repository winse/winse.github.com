<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-09-28T19:57:27+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[批量下载163-open的视频]]></title>
    <link href="http://winseliu.com/blog/2016/09/19/163-open-movies-download/"/>
    <updated>2016-09-19T23:19:31+08:00</updated>
    <id>http://winseliu.com/blog/2016/09/19/163-open-movies-download</id>
    <content type="html"><![CDATA[<p>163的视频资源还是挺丰富的，默认情况下必须用客户端下载。感觉挺麻烦的，对于网络慢的情况可能要下很久，如果能用下载工具批量下载就好了。</p>

<p>首先从视频播放页面获取下载的地址(查看下载按钮的js):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>appsrc : 'http://mov.bn.netease.com/open-movie/nos/mp4/2015/01/19/SAFDACJPD_sd.m3u8',</span></code></pre></td></tr></table></div></figure>


<ul>
<li>然后从列表页获取列表所有视频的详情URL，</li>
<li>然后从详情URL获取appsrc的地址，</li>
<li>最后把后缀m3u8改成mp4。当然还可以把视频的名称优化下。</li>
</ul>


<p>下面结合【chrome调试工具】、【notepad++】、【shell】来获取视频的下载地址：</p>

<ol>
<li>F12使用js获取列表详情URL</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$("#list2").find("tr &gt;td.u-ctitle a").each(function(i,node){console.log($(node).attr("href"));})</span></code></pre></td></tr></table></div></figure>


<p>使用notepad++的<strong>列处理</strong>功能 处理chrome输出的信息只留下URL保存到url.txt，如 <code>http://open.163.com/movie/2008/1/1/H/M6SGF6VB4_M6SGL3P1H.html</code> 。</p>

<p>这里用同样的步骤也把视频列表的名称获取到，用于后面的视频重命名：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$("#list2").find("tr &gt;td.u-ctitle a").each(function(i,node){console.log($(node).text());})</span></code></pre></td></tr></table></div></figure>


<ol>
<li>使用SHELL获取详情页面的URL</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cat url.txt | while read line ; do if [ "$line" != '' ] ; then curl -s $line | grep -a appsrc ; fi ; done</span></code></pre></td></tr></table></div></figure>


<p>获取到的数据同样包含一些不需要的信息，使用notepad++进行裁剪。提取 <code>http://mov.bn.netease.com/open-movie/nos/mp4/2015/01/19/SAFDCDGNA_sd.m3u8</code>  的视频地址，使用replace把m3u8替换成mp4，然后把URL复制到<strong>迅雷下载的下载框</strong>即可批量下载了。</p>

<ol>
<li>重命名</li>
</ol>


<p>给获取到的视频的名称加上顺序标识，然后弄成重命名的命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mv SAFD8B131_sd.mp4  01机器学习的动机与应用.mp4
</span><span class='line'>mv SAFD8D355_sd.mp4  02监督学习应用.梯度下降.mp4
</span><span class='line'>mv SAFD8O947_sd.mp4  03欠拟合与过拟合的概念.mp4
</span><span class='line'>mv SAFD8PQO8_sd.mp4  04牛顿方法.mp4
</span><span class='line'>mv SAFD94US8_sd.mp4  05生成学习算法.mp4
</span><span class='line'>mv SAFD97CGO_sd.mp4  06朴素贝叶斯算法.mp4
</span><span class='line'>mv SAFD9I82D_sd.mp4  07最优间隔分类器问题.mp4
</span><span class='line'>mv SAFD9L3B9_sd.mp4  08顺序最小优化算法.mp4
</span><span class='line'>mv SAFD9VGEO_sd.mp4  09经验风险最小化.mp4
</span><span class='line'>mv SAFDA37TS_sd.mp4  10特征选择.mp4
</span><span class='line'>mv SAFDACJPD_sd.mp4  11贝叶斯统计正则化.mp4
</span><span class='line'>mv SAFDAHG1C_sd.mp4  12K-means算法.mp4
</span><span class='line'>mv SAFDAQ19J_sd.mp4  13高斯混合模型.mp4
</span><span class='line'>mv SAFDB0UUS_sd.mp4  14主成分分析法.mp4
</span><span class='line'>mv SAFDB7QLL_sd.mp4  15奇异值分解.mp4
</span><span class='line'>mv SAFDBF188_sd.mp4  16马尔可夫决策过程.mp4
</span><span class='line'>mv SAFDBM41T_sd.mp4  17离散与维数灾难.mp4
</span><span class='line'>mv SAFDBTL6V_sd.mp4  18线性二次型调节控制.mp4
</span><span class='line'>mv SAFDC4B84_sd.mp4  19微分动态规划.mp4
</span><span class='line'>mv SAFDCDGNA_sd.mp4  20策略搜索.mp4</span></code></pre></td></tr></table></div></figure>


<p>以上几个步骤就能完美的实现视频的下载。步骤比较多，但是还是很有成就感啊，程序员的逗逼方法。</p>

<h2>附</h2>

<p>几年前下载TED视频的脚本(全部用脚本来实现，其实拆分步骤或许是更好的选择简单些)：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget -qO- http://open.163.com/ted/ | iconv -f gbk -t utf-8 | awk '{if($0 ~ /&lt;a href="http:\/\/v\.163\.com\/movie/ ){print}}' \  
</span><span class='line'> | sed -n 's/.*&lt;a href="\([^"]*\)".*/\1/p' \  
</span><span class='line'> | while read url  
</span><span class='line'>do   
</span><span class='line'>        echo $url;  
</span><span class='line'>        wget -qO- "$url" | iconv -f gbk -t utf-8 | awk '/appsrc: \047http:\/\//{if(match($0,/http:[^\047]*/))print substr($0,RSTART,RLENGTH);}' \  
</span><span class='line'> | sed -e s/-list\.m3u8/.mp4/ -e s/movie/movieMP4/  
</span><span class='line'>done  </span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zookeeper节点切换]]></title>
    <link href="http://winseliu.com/blog/2016/09/12/zookeeper-switch-node/"/>
    <updated>2016-09-12T16:51:39+08:00</updated>
    <id>http://winseliu.com/blog/2016/09/12/zookeeper-switch-node</id>
    <content type="html"><![CDATA[<p>收告警邮件实在是收到烦了，zookeeper实例的机器挂掉了，机器一直没人处理。最后最终还是改了告警的脚本（呵呵，等到快出问题的时刻才告警）。</p>

<p>过程中也尝试了添加删除节点，下面是对本次体验的一些记载。</p>

<h2>告警的检查脚本帖出来：</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>msg=`$HADOOP_HOME/bin/hdfs getconf -confKey ha.zookeeper.quorum 2&gt;/dev/null`
</span><span class='line'>
</span><span class='line'>zks_total=`echo "$msg" | awk 'BEGIN{RS=","; } {print}' | grep -v '^$' `
</span><span class='line'>total_count=`echo "$zks_total" | wc -l `
</span><span class='line'>
</span><span class='line'>lost_zks=`echo "$zks_total" |  while read zk  ; do if ! echo mntr | nc ${zk//:/ } | grep zk_server_state &gt;/dev/null ; then echo "$zk " ; fi ; done  `
</span><span class='line'>lost_count=`echo "$lost_zks" | grep -v "^$" | wc -l ` 
</span><span class='line'>lost_zks=`echo $lost_zks `
</span><span class='line'>
</span><span class='line'>message="Zookeepers total: $total_count, dead: $lost_count"
</span><span class='line'>if  [[ "$lost_count" != 0 ]]
</span><span class='line'>then
</span><span class='line'>  message="$message;  Dead: $lost_zks"
</span><span class='line'>fi 
</span><span class='line'>
</span><span class='line'>if (( $lost_count*2 &gt; $total_count )) ; then
</span><span class='line'>        echo "CRITICAL - $message"
</span><span class='line'>        exit 2
</span><span class='line'>elif (( $total_count/2 == $lost_count )) ; then
</span><span class='line'>        echo "WARNING - $message"
</span><span class='line'>        exit 1
</span><span class='line'>else 
</span><span class='line'>        echo "OK - $message"
</span><span class='line'>        exit 0
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<h2>zookeeper3.5</h2>

<p>zookeeper3.5的版本已经有动态增删节点的功能。</p>

<ul>
<li><a href="https://zookeeper.apache.org/doc/trunk/zookeeperReconfig.html">ZooKeeper Dynamic Reconfiguration</a></li>
<li><a href="https://www.usenix.org/sites/default/files/conference/protected-files/shraer_atc12_slides.pdf">Dynamic Reconfiguration of Primary/Backup Clusters</a></li>
</ul>


<h2>手动割接问题节点</h2>

<p>生产的是3.4的，不支持reconfig的命令。只能手动切换，在测试环境通过不同的端口来模拟3台机器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu3 zktest]$ mv zoo_sample.cfg zoo1.cfg
</span><span class='line'>[hadoop@cu3 zktest]$ sed -e 's/12181/22181/' -e 's/data1/data2/' zoo1.cfg &gt;zoo2.cfg
</span><span class='line'>[hadoop@cu3 zktest]$ sed -e 's/12181/32181/' -e 's/data1/data3/' zoo1.cfg &gt;zoo3.cfg
</span><span class='line'>[hadoop@cu3 zktest]$ cat zoo3.cfg 
</span><span class='line'>tickTime=2000
</span><span class='line'>initLimit=10
</span><span class='line'>syncLimit=5
</span><span class='line'>#maxClientCnxns=60
</span><span class='line'>
</span><span class='line'>dataDir=/home/hadoop/zktest/data3
</span><span class='line'>clientPort=32181
</span><span class='line'>
</span><span class='line'>server.1=localhost:13888:13999
</span><span class='line'>server.2=localhost:23888:23999
</span><span class='line'>server.3=localhost:33888:33999
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 zktest]$ for i in {1..3} ; do echo $i &gt;data$i/myid ; done 
</span><span class='line'>
</span><span class='line'># 添加两个便利的函数
</span><span class='line'>[hadoop@cu3 zktest]$ function zkstat { 
</span><span class='line'>&gt; for i in {1..4} ; do ( echo "${i}2181 =&gt; `cat data$i/zookeeper_server.pid` : `echo mntr | nc localhost ${i}2181 | grep zk_server_state | awk '{print $2}' ` " ) ; done
</span><span class='line'>&gt; }
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 zktest]$ function zkstart { 
</span><span class='line'>&gt; for i in "$@" ; do (cd data$i ; ~/zookeeper-3.4.6/bin/zkServer.sh start /home/hadoop/zktest/zoo$i.cfg ) ; done
</span><span class='line'>&gt; }
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 zktest]$ zkstart {1..3}
</span></code></pre></td></tr></table></div></figure>


<h4>切换时，Leader一直不变</h4>

<p>模拟server.1进程down掉，用一个新的server.4代替: 切换的过程中不能停leader！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置server.4
</span><span class='line'>[hadoop@cu3 zktest]$ sed -e 's/12181/42181/' -e 's/data1/data4/' zoo1.cfg &gt;zoo4.cfg
</span><span class='line'>[hadoop@cu3 zktest]$ mkdir data4
</span><span class='line'>[hadoop@cu3 zktest]$ echo 4 &gt; data4/myid
</span><span class='line'>
</span><span class='line'># 去掉server.1，添加server.4
</span><span class='line'>[hadoop@cu3 zktest]$ vi zoo4.cfg 
</span><span class='line'>...
</span><span class='line'>server.4=localhost:43888:43999
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 20750 : follower 
</span><span class='line'>22181 =&gt; 21037 : leader 
</span><span class='line'>32181 =&gt; 21075 : follower 
</span><span class='line'>42181 =&gt; 19757 :  
</span><span class='line'>
</span><span class='line'># 停server.1
</span><span class='line'>[hadoop@cu3 zktest]$ kill 20750
</span><span class='line'>
</span><span class='line'># 启动server.4
</span><span class='line'>[hadoop@cu3 zktest]$ zkstart {2..4}
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat 
</span><span class='line'>12181 =&gt; 20750 :  
</span><span class='line'>22181 =&gt; 21037 : leader 
</span><span class='line'>32181 =&gt; 21075 : follower 
</span><span class='line'>42181 =&gt; 21246 : follower 
</span><span class='line'>
</span><span class='line'>此时server.4是新的配置，server.2和server.3是旧的配置。
</span><span class='line'>
</span><span class='line'># 停server.3，注意这里不能停leader！！
</span><span class='line'>[hadoop@cu3 zktest]$ kill 21075
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 20750 :  
</span><span class='line'>22181 =&gt; 21037 : leader 
</span><span class='line'>32181 =&gt; 21075 :  
</span><span class='line'>42181 =&gt; 21246 : follower 
</span><span class='line'>
</span><span class='line'># server.3的配置：server.1换成server.4
</span><span class='line'>[hadoop@cu3 zktest]$ vi zoo3.cfg 
</span><span class='line'>[hadoop@cu3 zktest]$ zkstart 3
</span><span class='line'>JMX enabled by default
</span><span class='line'>Using config: /home/hadoop/zktest/zoo3.cfg
</span><span class='line'>Starting zookeeper ... STARTED
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 20750 :  
</span><span class='line'>22181 =&gt; 21037 : leader 
</span><span class='line'>32181 =&gt; 21791 : follower 
</span><span class='line'>42181 =&gt; 21246 : follower 
</span><span class='line'>
</span><span class='line'>3个server有两个已经是新的配置，现在停掉leader后重新选举也是ok的。
</span><span class='line'>
</span><span class='line'># 最后停leader，修改zoo2.cfg。集群down节点成功切换！！
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 20750 :  
</span><span class='line'>22181 =&gt; 22044 : follower 
</span><span class='line'>32181 =&gt; 21791 : follower 
</span><span class='line'>42181 =&gt; 21246 : leader </span></code></pre></td></tr></table></div></figure>


<h4>中间停Leader，重新选领导失败</h4>

<p>现在再测试下中间过程停leader会是什么效果呢？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先zoo4挂掉了，用zoo1来补充。
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 20750 :  
</span><span class='line'>22181 =&gt; 22044 : leader 
</span><span class='line'>32181 =&gt; 21791 : follower 
</span><span class='line'>42181 =&gt; 21246 : 
</span><span class='line'>
</span><span class='line'>配置 zoo1: 
</span><span class='line'>
</span><span class='line'># 修改zoo1的配置 和 myid，不能用原来的旧id: Have smaller server identifier, so dropping the connection: (3, 1)
</span><span class='line'>server.5=localhost:13888:13999
</span><span class='line'>server.2=localhost:23888:23999
</span><span class='line'>server.3=localhost:33888:33999
</span><span class='line'>
</span><span class='line'># 此时zoo2，zoo3的配置为：
</span><span class='line'>server.2=localhost:23888:23999
</span><span class='line'>server.3=localhost:33888:33999
</span><span class='line'>server.4=localhost:43888:43999
</span><span class='line'>
</span><span class='line'># 启动zoo1
</span><span class='line'>[hadoop@cu3 zktest]$ zkstart 1
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 22439 : follower 
</span><span class='line'>22181 =&gt; 22044 : leader 
</span><span class='line'>32181 =&gt; 21791 : follower 
</span><span class='line'>42181 =&gt; 21246 :  
</span><span class='line'>
</span><span class='line'>如果这里停的leader，zoo1收不到大于1/2的投票？
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 zktest]$ kill 22044
</span><span class='line'>[hadoop@cu3 zktest]$ zkstat
</span><span class='line'>12181 =&gt; 22439 :  
</span><span class='line'>22181 =&gt; 22044 :  
</span><span class='line'>32181 =&gt; 21791 :  
</span><span class='line'>42181 =&gt; 21246 :  
</span><span class='line'>[hadoop@cu3 zktest]$ jps -m | grep zktest
</span><span class='line'>21791 QuorumPeerMain /home/hadoop/zktest/zoo3.cfg
</span><span class='line'>22439 QuorumPeerMain /home/hadoop/zktest/zoo1.cfg
</span><span class='line'>
</span><span class='line'>服务挂了！！
</span></code></pre></td></tr></table></div></figure>


<p>正常切换后，应用不需要修改。只要zkserver中的一台zk服务器能连接就可以了。但可能监控的需要进行修改，因为原来是监控所有服务的，配置可能需要进行相应的修改。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet批量修改用户密码]]></title>
    <link href="http://winseliu.com/blog/2016/09/06/puppet-modify-password/"/>
    <updated>2016-09-06T11:00:57+08:00</updated>
    <id>http://winseliu.com/blog/2016/09/06/puppet-modify-password</id>
    <content type="html"><![CDATA[<ol>
<li>先在一台机器修改成想要修改的密码，然后获取该用户的信息。</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 ~]# puppet resource user root
</span><span class='line'>user { 'root':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  comment          =&gt; 'root',
</span><span class='line'>  gid              =&gt; '0',
</span><span class='line'>  home             =&gt; '/root',
</span><span class='line'>  password         =&gt; '$6$C6EXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  uid              =&gt; '0',
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ol>
<li><p>保存到文件 user.pp ，使用 <code>puppet apply user.pp</code> 测试看看文件是否有问题。毕竟是生产，出了问题就要进机房的啊，谨慎点好。</p></li>
<li><p>把用户的资源信息写入的site.pp(不知道是啥的话，去看看puppet的文档先)。先搞几台机器测试下 <code>puppet agent -t</code></p></li>
<li><p>然后使用 <code>mco puppet runall 10</code> 全部同步进行密码修改。或者 <code>mco shell run -- /opt/puppetlabs/bin/puppet agent -t</code></p></li>
</ol>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maven压缩js/css功能实践]]></title>
    <link href="http://winseliu.com/blog/2016/08/19/j2ee-maven-resources-compress/"/>
    <updated>2016-08-19T16:34:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/08/19/j2ee-maven-resources-compress</id>
    <content type="html"><![CDATA[<p>为了节约网络带宽，一般在发布项目时对资源(js/css)文件进行压缩（去掉空行、精简代码等）。但是要做到兼容开发与生产还是的下一番功夫才行。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ls -l src/main/webapp/static/assets/js/ | head
</span><span class='line'>total 3120
</span><span class='line'>-rwxrwxr--+ 1 winse None  24804 Aug 10 17:40 bootbox.js
</span><span class='line'>-rwxrwxr--+ 1 winse None  71315 Aug 10 17:40 bootstrap.js
</span><span class='line'>-rwxrwxr--+ 1 winse None  13905 Aug 10 17:40 bootstrap-colorpicker.js
</span><span class='line'>-rwxrwxr--+ 1 winse None  49319 Aug 10 17:40 bootstrap-multiselect.js
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>$ ls -l target/dist/js/ | head
</span><span class='line'>total 1368
</span><span class='line'>-rwxrwx---+ 1 winse None   8943 Aug 19 16:53 bootbox-min.js
</span><span class='line'>-rwxrwx---+ 1 winse None   8057 Aug 19 16:53 bootstrap-colorpicker-min.js
</span><span class='line'>-rwxrwx---+ 1 winse None  38061 Aug 19 16:53 bootstrap-min.js
</span><span class='line'>-rwxrwx---+ 1 winse None  18232 Aug 19 16:53 bootstrap-multiselect-min.js
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>项目中原本使用dist(压缩)、assets目录放置js/css等资源，在部署的时刻替换dist为assets，有点麻烦。首先想到的<strong>用nginx进行url重写</strong>，但是需要增加一个服务有点麻烦，能不能直接用spring来实现呢？</p>

<ul>
<li>自定义一个handler类</li>
</ul>


<p>查看Spring的 <code>mvc:resources</code> 实现，相当于注册了一个 <code>location -&gt; ResourceHttpRequestHandler</code> 的映射。
第一种尝试自动化的方式就是自定义handler类来进行资源的定位。增加 StaticRequestHandler 的处理类，增加配置 location 和 compressLocation 的配置：首先去查找压缩文件([NAME]-min.js)，找不到然后再找源文件([NAME].js)位置。</p>

<p>主要修改 getResource 方法，具体完整代码如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## java
</span><span class='line'>public class StaticRequestHandler extends ResourceHttpRequestHandler {
</span><span class='line'>
</span><span class='line'>  private final static Log logger = LogFactory.getLog(ResourceHttpRequestHandler.class);
</span><span class='line'>
</span><span class='line'>  private String location;
</span><span class='line'>  private String compressLocation;
</span><span class='line'>
</span><span class='line'>  private Resource locationResource;
</span><span class='line'>  private Resource compressLocationResource;
</span><span class='line'>
</span><span class='line'>  public void setLocation(String location) {
</span><span class='line'>      this.location = location;
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  public void setCompressLocation(String compressLocation) {
</span><span class='line'>      this.compressLocation = compressLocation;
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  @Override
</span><span class='line'>  public void afterPropertiesSet() throws Exception {
</span><span class='line'>      super.afterPropertiesSet();
</span><span class='line'>
</span><span class='line'>      this.locationResource = getWebApplicationContext().getResource(location);
</span><span class='line'>      super.setLocations(Collections.singletonList(this.locationResource));
</span><span class='line'>
</span><span class='line'>      this.compressLocationResource = getWebApplicationContext().getResource(compressLocation);
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  @Override
</span><span class='line'>  protected Resource getResource(HttpServletRequest request) {
</span><span class='line'>      String path = (String) request.getAttribute(HandlerMapping.PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE);
</span><span class='line'>      if (path == null) {
</span><span class='line'>          throw new IllegalStateException("Required request attribute '"
</span><span class='line'>                  + HandlerMapping.PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE + "' is not set");
</span><span class='line'>      }
</span><span class='line'>
</span><span class='line'>      if (!StringUtils.hasText(path) || isInvalidPath(path)) {
</span><span class='line'>          if (logger.isDebugEnabled()) {
</span><span class='line'>              logger.debug("Ignoring invalid resource path [" + path + "]");
</span><span class='line'>          }
</span><span class='line'>          return null;
</span><span class='line'>      }
</span><span class='line'>
</span><span class='line'>      Resource res = null;
</span><span class='line'>      if (path.endsWith(".css")) {
</span><span class='line'>          res = findResource(compressLocationResource, path.substring(0, path.length() - 4) + ".min.css");
</span><span class='line'>      } else if (path.endsWith(".js")) {
</span><span class='line'>          res = findResource(compressLocationResource, path.substring(0, path.length() - 3) + ".min.js");
</span><span class='line'>      }
</span><span class='line'>
</span><span class='line'>      if (res == null) {
</span><span class='line'>          res = findResource(locationResource, path);
</span><span class='line'>      }
</span><span class='line'>
</span><span class='line'>      return res;
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  private Resource findResource(Resource location, String path) {
</span><span class='line'>      try {
</span><span class='line'>          if (logger.isDebugEnabled()) {
</span><span class='line'>              logger.debug("Trying relative path [" + path + "] against base location: " + location);
</span><span class='line'>          }
</span><span class='line'>          Resource resource = location.createRelative(path);
</span><span class='line'>          if (resource.exists() && resource.isReadable()) {
</span><span class='line'>              if (logger.isDebugEnabled()) {
</span><span class='line'>                  logger.debug("Found matching resource: " + resource);
</span><span class='line'>              }
</span><span class='line'>              return resource;
</span><span class='line'>          } else if (logger.isTraceEnabled()) {
</span><span class='line'>              logger.trace("Relative resource doesn't exist or isn't readable: " + resource);
</span><span class='line'>          }
</span><span class='line'>      } catch (IOException ex) {
</span><span class='line'>          logger.debug("Failed to create relative resource - trying next resource location", ex);
</span><span class='line'>      }
</span><span class='line'>
</span><span class='line'>      return null;
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>## spring config
</span><span class='line'>  &lt;!-- 静态资源 --&gt;
</span><span class='line'>  &lt;!-- &lt;mvc:resources mapping="/static/**" location="/static/" /&gt; --&gt;
</span><span class='line'>
</span><span class='line'>  &lt;bean class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt;
</span><span class='line'>      &lt;property name="mappings"&gt;
</span><span class='line'>          &lt;value&gt;
</span><span class='line'>              /static/assets/**=staticRequestHandler
</span><span class='line'>          &lt;/value&gt;
</span><span class='line'>      &lt;/property&gt;
</span><span class='line'>  &lt;/bean&gt;
</span><span class='line'>  &lt;bean id="staticRequestHandler" class="com.hotel.servlet.resource.StaticRequestHandler"&gt;
</span><span class='line'>      &lt;property name="location" value="/static/assets/" /&gt;
</span><span class='line'>      &lt;property name="compressLocation" value="/static/dist/" /&gt;
</span><span class='line'>  &lt;/bean&gt;</span></code></pre></td></tr></table></div></figure>


<p>这种方式实现了自动定位压缩资源 <code>min.js</code> 的功能，但是压缩还是不能自动化而且不能实时的更新（min要单独压缩产生），并且调试和生产环境还是需要手动的修改配置来切换。</p>

<p>有没有更好的自动化的实现开发环境和生产环境分开呢？</p>

<ul>
<li>Maven打包时压缩然后替换源文件</li>
</ul>


<p>使用 <strong>yuicompressor-maven-plugin</strong> 插件压缩资源，然后把压缩资源<strong>先</strong>打包放置到assets目录下。</p>

<p>注意： yuicomressor 插件的 nosuffix 配置为 true ! 这样压缩后的文件名和源文件名称才一样。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## spring config
</span><span class='line'>  &lt;!-- 静态资源 --&gt;
</span><span class='line'>  &lt;mvc:resources mapping="/static/**" location="/static/" /&gt;
</span><span class='line'>
</span><span class='line'>## maven pom.xml
</span><span class='line'>      &lt;profile&gt;
</span><span class='line'>          &lt;id&gt;release&lt;/id&gt;
</span><span class='line'>
</span><span class='line'>          &lt;build&gt;
</span><span class='line'>              &lt;plugins&gt;
</span><span class='line'>                  &lt;!-- http://alchim.sourceforge.net/yuicompressor-maven-plugin/compress-mojo.html --&gt;
</span><span class='line'>                  &lt;plugin&gt;
</span><span class='line'>                      &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;
</span><span class='line'>                      &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt;
</span><span class='line'>                      &lt;version&gt;1.3.2&lt;/version&gt;
</span><span class='line'>                      &lt;executions&gt;
</span><span class='line'>                          &lt;execution&gt;
</span><span class='line'>                              &lt;id&gt;compress_js_css&lt;/id&gt;
</span><span class='line'>                              &lt;phase&gt;process-resources&lt;/phase&gt;
</span><span class='line'>                              &lt;goals&gt;
</span><span class='line'>                                  &lt;goal&gt;compress&lt;/goal&gt;
</span><span class='line'>                              &lt;/goals&gt;
</span><span class='line'>                          &lt;/execution&gt;
</span><span class='line'>                      &lt;/executions&gt;
</span><span class='line'>                      &lt;configuration&gt;
</span><span class='line'>                          &lt;encoding&gt;UTF-8&lt;/encoding&gt;
</span><span class='line'>                          &lt;nosuffix&gt;true&lt;/nosuffix&gt;
</span><span class='line'>                          &lt;skip&gt;false&lt;/skip&gt;
</span><span class='line'>
</span><span class='line'>                          &lt;jswarn&gt;false&lt;/jswarn&gt;
</span><span class='line'>                          &lt;nomunge&gt;false&lt;/nomunge&gt;
</span><span class='line'>                          &lt;preserveAllSemiColons&gt;false&lt;/preserveAllSemiColons&gt;
</span><span class='line'>
</span><span class='line'>                          &lt;sourceDirectory&gt;src/main/webapp/static/assets&lt;/sourceDirectory&gt;
</span><span class='line'>                          &lt;outputDirectory&gt;${project.build.directory}/dist&lt;/outputDirectory&gt;
</span><span class='line'>                      &lt;/configuration&gt;
</span><span class='line'>                  &lt;/plugin&gt;
</span><span class='line'>
</span><span class='line'>                  &lt;plugin&gt;
</span><span class='line'>                      &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
</span><span class='line'>                      &lt;version&gt;2.6&lt;/version&gt;
</span><span class='line'>                      &lt;configuration&gt;
</span><span class='line'>                          &lt;webResources&gt;
</span><span class='line'>                              &lt;resource&gt;
</span><span class='line'>                                  &lt;directory&gt;${project.build.directory}/dist&lt;/directory&gt;
</span><span class='line'>                                  &lt;targetPath&gt;static/assets&lt;/targetPath&gt;
</span><span class='line'>                                  &lt;filtering&gt;false&lt;/filtering&gt;
</span><span class='line'>                              &lt;/resource&gt;
</span><span class='line'>                          &lt;/webResources&gt;
</span><span class='line'>                      &lt;/configuration&gt;
</span><span class='line'>                  &lt;/plugin&gt;
</span><span class='line'>                  
</span><span class='line'>              &lt;/plugins&gt;
</span><span class='line'>          &lt;/build&gt;
</span><span class='line'>      &lt;/profile&gt;</span></code></pre></td></tr></table></div></figure>


<p>war插件添加了自定义webResources资源，首先把压缩的文件拷贝到对应目录，maven发现文件已经存在就不会再拷贝同名的文件。这样源文件就相当于被替换成压缩的资源了。</p>

<h2>总结</h2>

<p>使用maven插件压缩打包，完美的解决js/css压缩导致的开发和生产不兼容问题。</p>

<h2>后记</h2>

<p>jsp使用了tag的地方总是会产生很多的空行，看着挺烦的。其实可以通过在jsp开头添加 trimDirectiveWhitespaces 属性来去掉空行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;%@ page language="java" trimDirectiveWhitespaces="true" contentType="text/html; charset=utf-8" pageEncoding="utf-8"%&gt;</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis批量操作]]></title>
    <link href="http://winseliu.com/blog/2016/08/17/redis-batch-operate/"/>
    <updated>2016-08-17T15:33:47+08:00</updated>
    <id>http://winseliu.com/blog/2016/08/17/redis-batch-operate</id>
    <content type="html"><![CDATA[<p>紧接上一篇优化的文章，在生产进行shard分库/分片操作后，部分大量zsort键值对拆散到多个redis实例。原来统计总量的命令现在需要汇总后才行。</p>

<p>今天就来说说Redis里面的批量操作，批量操作其实就是循环，把大部分的工作让机器做了。逻辑比较复杂的用比较实现，功能简单的用脚本即可。</p>

<ul>
<li>单机用lua脚本</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># redis-cli
</span><span class='line'>
</span><span class='line'>eval "local aks=redis.call('keys', '*'); local res=0; for i,r in ipairs(aks) do res=res+redis.call('hlen', r) end; return res" 0</span></code></pre></td></tr></table></div></figure>


<p>通过keys获取所有的键（都是hash类型），然后计算出匹配的hash包括的键值对总数。</p>

<p>在<strong>同一个实例</strong>的小数据量的统计，lua脚本优势还是比较明显的：redis自带的还能编程。</p>

<ul>
<li>shell脚本</li>
</ul>


<p>看官网的文档：<a href="http://redis.io/topics/rediscli">the Redis command line interface</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## shell
</span><span class='line'>
</span><span class='line'>cat commands | redis-cli --raw
</span><span class='line'>
</span><span class='line'>## redis-cli
</span><span class='line'>
</span><span class='line'>127.0.0.1:6379&gt; CONFIG RESETSTAT
</span><span class='line'>OK
</span><span class='line'>...
</span><span class='line'>127.0.0.1:6379&gt; info stats
</span><span class='line'># Stats
</span><span class='line'>total_connections_received:2
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>注意：不要用循环然后调用<code>redis-cli COMMAND</code>，这种方式会产生很多的TCP连接，如果要执行的命令太多，可能导致TCP端口不够用。</p>

<p>还有 <code>redis-cli --stat</code>，<code>redis-cli --scan</code>，<code>redis-cli monitor</code> 这些命令挺有意思的。</p>

<ul>
<li>直接tcp连接管道操作</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## shell
</span><span class='line'>
</span><span class='line'>sed 's/$/^M/' commands &gt; test.redis.cmd
</span><span class='line'>cat test.redis.cmd | nc localhost 6379
</span><span class='line'>
</span><span class='line'>## redis-cli
</span><span class='line'>
</span><span class='line'>127.0.0.1:6379&gt; info stats
</span><span class='line'># Stats
</span><span class='line'>total_connections_received:1
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>通过tcp连接操作，一批次的操作就一个连接。但是，操作的时刻需要主要，linux的换行符是 <code>\n</code>，而redis需要的是 <code>\r\n</code>；还有通过tcp连接返回的结果是redis协议原始数据，没有经过处理，需要稍微看看协议规范<a href="http://redis.io/topics/protocol">Redis Protocol specification</a></p>

<ul>
<li>pipelining</li>
</ul>


<p>redis自带的管道功能，性能提升相当明显（<a href="http://redis.io/topics/pipelining#some-benchmark">官网数据</a>）。</p>

<p>原来看到过觉得高大上，准备试试。但是返回结果却只有一个成功数而已！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo 119.84.100.68 | xargs -I{} echo "1:ips:2016-08-16:{}" | while read cmd ; do echo -e "*2\r\n\$5\r\nzcard\r\n\$${#cmd}\r\n$cmd\r\n" ; done  | redis-cli -p 26379 --pipe
</span><span class='line'>All data transferred. Waiting for the last reply...
</span><span class='line'>Last reply received from server.
</span><span class='line'>errors: 0, replies: 1</span></code></pre></td></tr></table></div></figure>


<p>注意：redis-cli带的pipe就比较坑：最后只返回操作成功失败的统计数量，只适合用来做更新操作<a href="http://redis.io/topics/mass-insert">Redis Mass Insertion</a>！！</p>

<p>要用pipeline来实现查询的话，用java/scala等语言来弄吧。</p>

<p>最后帖一下用shell脚本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>day=${day:-`date "+%Y-%m-%d"`}
</span><span class='line'>key="1:ips:$day"
</span><span class='line'>
</span><span class='line'>for h in hadoop-master{1..4} ; do 
</span><span class='line'>  exists=$(redis-cli -h $h -p 6372 exists $key)
</span><span class='line'>  if [ $exists -gt 0 ] ; then
</span><span class='line'>    redis-cli -h $h -p 6372 zrange $key 0 -1 &gt; activeresourceip$day.data
</span><span class='line'>    for h in hadoop-master{1..4} ; do
</span><span class='line'>      cat activeresourceip$day.data | while read ip ; do echo -e "zcard $key:$ip\r" ; done | redis-cli -h $h -p 6372
</span><span class='line'>    done
</span><span class='line'>  fi
</span><span class='line'>done | awk '{s+=$1} END {print s}' </span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis使用优化]]></title>
    <link href="http://winseliu.com/blog/2016/07/28/redis-optimise/"/>
    <updated>2016-07-28T08:22:26+08:00</updated>
    <id>http://winseliu.com/blog/2016/07/28/redis-optimise</id>
    <content type="html"><![CDATA[<p>最近对生产的Redis做了两个优化：Redis扩展、以及对简单键值对的存储优化（string改成hash形式）</p>

<h2>Redis扩展</h2>

<p>上一篇介绍的Codis安装。但是使用Pipeline操作时间比较长、连接数比较多的情况下，经常出现连接重置的情况。感觉不踏实，go也不懂感觉短时间处理不了这种问题。</p>

<p>寻求它法。前期是把不同业务数据写入不同的redis实例，根据业务来分。对于同一个业务来说，得根据key的hash来写入不同的实例，但是自己写的话得包装一堆东西。</p>

<p>jedis工具包括Shared的功能，根据写入key的hash映射到不同的redis实例。截取了部分Shared的主要代码:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public class Sharded&lt;R, S extends ShardInfo&lt;R&gt;&gt; {
</span><span class='line'>...
</span><span class='line'>    private void initialize(List&lt;S&gt; shards) {
</span><span class='line'>  nodes = new TreeMap&lt;Long, S&gt;();
</span><span class='line'>
</span><span class='line'>  for (int i = 0; i != shards.size(); ++i) {
</span><span class='line'>      final S shardInfo = shards.get(i);
</span><span class='line'>      if (shardInfo.getName() == null)
</span><span class='line'>      for (int n = 0; n &lt; 160 * shardInfo.getWeight(); n++) {
</span><span class='line'>          nodes.put(this.algo.hash("SHARD-" + i + "-NODE-" + n),
</span><span class='line'>              shardInfo);
</span><span class='line'>      }
</span><span class='line'>      else
</span><span class='line'>      for (int n = 0; n &lt; 160 * shardInfo.getWeight(); n++) {
</span><span class='line'>          nodes.put(
</span><span class='line'>              this.algo.hash(shardInfo.getName() + "*"
</span><span class='line'>                  + shardInfo.getWeight() + n), shardInfo);
</span><span class='line'>      }
</span><span class='line'>      resources.put(shardInfo, shardInfo.createResource());
</span><span class='line'>  }
</span><span class='line'>    }
</span><span class='line'>...   
</span><span class='line'>    public S getShardInfo(byte[] key) {
</span><span class='line'>  SortedMap&lt;Long, S&gt; tail = nodes.tailMap(algo.hash(key));
</span><span class='line'>  if (tail.isEmpty()) {
</span><span class='line'>      return nodes.get(nodes.firstKey());
</span><span class='line'>  }
</span><span class='line'>  return tail.get(tail.firstKey());
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    public S getShardInfo(String key) {
</span><span class='line'>  return getShardInfo(SafeEncoder.encode(getKeyTag(key)));
</span><span class='line'>    }
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>使用的时刻很简单，通过ShardedJedis来进读写，大部分的操作与Jedis类似。只是有部分整个集群的操作不能用：keys/scan等。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public List&lt;JedisShardInfo&gt; getShards(String sValue) {
</span><span class='line'>    String[] servers = sValue.split(",");
</span><span class='line'>
</span><span class='line'>    List&lt;JedisShardInfo&gt; shards = new ArrayList&lt;&gt;();
</span><span class='line'>    for (String server : servers) {
</span><span class='line'>      Pair&lt;String, Integer&gt; hp = parseServer(server);
</span><span class='line'>      shards.add(new JedisShardInfo(hp.getLeft(), hp.getRight(), Integer.MAX_VALUE));
</span><span class='line'>    }
</span><span class='line'>    return shards;
</span><span class='line'>  }
</span><span class='line'>  private ShardedJedisPool createRedisPool(String server) {
</span><span class='line'>    return new ShardedJedisPool(new GenericObjectPoolConfig(), getShards(server));
</span><span class='line'>  }</span></code></pre></td></tr></table></div></figure>


<p>如果使用过程中要使用keys，可以通过getAllShards得到所有Jedis实例的键再进行处理：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public Double zscore(String key, String member) {
</span><span class='line'>    try (ShardedJedis redis = getRedis()) {
</span><span class='line'>      return redis.zscore(key, member);
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  public void expires(List&lt;String&gt; patterns, int seconds) {
</span><span class='line'>    try (ShardedJedis shardedJedis = getRedis()) {
</span><span class='line'>      Set&lt;String&gt; keys = new HashSet&lt;&gt;();
</span><span class='line'>
</span><span class='line'>      for (Jedis redis : shardedJedis.getAllShards()) {
</span><span class='line'>        for (String p : patterns) {
</span><span class='line'>          keys.addAll(redis.keys(p)); // 调用单独实例的keys命令获取匹配的键
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>
</span><span class='line'>      ShardedJedisPipeline pipeline = shardedJedis.pipelined();
</span><span class='line'>      for (String key : keys) {
</span><span class='line'>        pipeline.expire(key, seconds);
</span><span class='line'>      }
</span><span class='line'>      pipeline.sync();
</span><span class='line'>    }
</span><span class='line'>  }</span></code></pre></td></tr></table></div></figure>


<p>进行多实例(集群)切分后，效果还是挺明显的。写入高峰期分流效果显著，负载均摊，可使用的内存也翻翻，键也基本平均分布（ <code>--maxmemory-policy volatile-lru</code> ）。生产实际效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 redis]$ sh stat_cluster.sh 
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 4 / 4
</span><span class='line'>
</span><span class='line'>hadoop-master1:
</span><span class='line'># Memory
</span><span class='line'>used_memory:44287785776
</span><span class='line'>used_memory_human:41.25G
</span><span class='line'>used_memory_rss:67458658304
</span><span class='line'>used_memory_peak:67981990576
</span><span class='line'>used_memory_peak_human:63.31G
</span><span class='line'>used_memory_lua:33792
</span><span class='line'>mem_fragmentation_ratio:1.52
</span><span class='line'>mem_allocator:jemalloc-3.6.0
</span><span class='line'># Keyspace
</span><span class='line'>db0:keys=72729777,expires=11967,avg_ttl=63510023
</span><span class='line'>
</span><span class='line'>hadoop-master2:
</span><span class='line'># Memory
</span><span class='line'>used_memory:50667945344
</span><span class='line'>used_memory_human:47.19G
</span><span class='line'>used_memory_rss:66036752384
</span><span class='line'>used_memory_peak:64424543672
</span><span class='line'>used_memory_peak_human:60.00G
</span><span class='line'>used_memory_lua:33792
</span><span class='line'>mem_fragmentation_ratio:1.30
</span><span class='line'>mem_allocator:jemalloc-3.6.0
</span><span class='line'># Keyspace
</span><span class='line'>db0:keys=100697581,expires=13426,avg_ttl=63509903
</span><span class='line'>
</span><span class='line'>hadoop-master3:
</span><span class='line'># Memory
</span><span class='line'>used_memory:56763389184
</span><span class='line'>used_memory_human:52.87G
</span><span class='line'>used_memory_rss:66324045824
</span><span class='line'>used_memory_peak:64424546136
</span><span class='line'>used_memory_peak_human:60.00G
</span><span class='line'>used_memory_lua:33792
</span><span class='line'>mem_fragmentation_ratio:1.17
</span><span class='line'>mem_allocator:jemalloc-3.6.0
</span><span class='line'># Keyspace
</span><span class='line'>db0:keys=94363547,expires=13544,avg_ttl=63505693
</span><span class='line'>
</span><span class='line'>hadoop-master4:
</span><span class='line'># Memory
</span><span class='line'>used_memory:54513952832
</span><span class='line'>used_memory_human:50.77G
</span><span class='line'>used_memory_rss:67257393152
</span><span class='line'>used_memory_peak:64820124928
</span><span class='line'>used_memory_peak_human:60.37G
</span><span class='line'>used_memory_lua:33792
</span><span class='line'>mem_fragmentation_ratio:1.23
</span><span class='line'>mem_allocator:jemalloc-3.6.0
</span><span class='line'># Keyspace
</span><span class='line'>db0:keys=83297543,expires=12418,avg_ttl=63507046
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 4 / 4 hosts in 298.89 ms</span></code></pre></td></tr></table></div></figure>


<h2>存储优化</h2>

<p>实际环境中存在会大量的用到简单string键值对，挺耗内存的。其实使用hash（内部存储ziplist）能更有效的利用内存。</p>

<p>注意是ziplist形式的hash才能省内存！！如果是skiplist的hash会浪费内存。</p>

<ul>
<li><a href="http://webcache.googleusercontent.com/search?q=cache:yr96Qf3F0e4J:heylinux.com/archives/1920.html+&amp;cd=1&amp;hl=zh-CN&amp;ct=clnk&amp;gl=jp">内存优化之Redis数据结构的设计优化实践</a> heylinux.com/archives/1920.html 这篇文章可能访问不了，可以通过google/baidu的快照来查看</li>
<li><a href="http://redis4you.com/articles.php?id=008&amp;name=Understanding+hash-max-zipmap-entries+and+">Understanding hash-max-zipmap-entries and &ldquo;hash of hashes&rdquo; optimization</a></li>
<li><a href="http://redis.io/topics/memory-optimization">http://redis.io/topics/memory-optimization</a></li>
<li><a href="http://redis.io/topics/lru-cache">http://redis.io/topics/lru-cache</a></li>
<li><a href="https://segmentfault.com/a/1190000004708270">Redis内存优化</a></li>
</ul>


<p>下面引用官网对简单键值对和Hash的一个比较（Redis中key的相关特性不关注）: 对于小数据量的hash进行了优化</p>

<blockquote><p> a few keys use a lot more memory than a single key containing a hash with a few fields.</p>

<p> We use a trick.</p>

<p> But many times hashes contain just a few fields. When hashes are small we can instead just encode them in an O(N) data structure, like a linear array with length-prefixed key value pairs. Since we do this only when N is small</p>

<p> This does not work well just from the point of view of time complexity, but also from the point of view of constant times, since a linear array of key value pairs happens to play very well with the CPU cache (it has a better cache locality than a hash table).</p></blockquote>

<p>优化主要涉及到ziplist的两个参数，是一个cpu/memory之间的均衡关系。entries直接用默认的就好了，value最好不要大于254（ziplist节点entry大于254需要增加4个到5字节，来存储前一个entry的长度）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hash-max-zipmap-entries 512 (hash-max-ziplist-entries for Redis &gt;= 2.6)
</span><span class='line'>hash-max-zipmap-value 64  (hash-max-ziplist-value for Redis &gt;= 2.6)</span></code></pre></td></tr></table></div></figure>


<p>简单列几条数据：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>3:0dc46077dfaa4970a1ec9f38cfc29277fa9e1012.ime.galileo.baidu.com  -&gt;  1469584847
</span><span class='line'>3:co4hk52ia0b1.5buzd.com                                          -&gt;  1468859527
</span><span class='line'>1:119.84.110.82_39502                                             -&gt;  1469666877</span></code></pre></td></tr></table></div></figure>


<p>原始key内容可以不需要，鉴于包括域名的key太长，直接对数据key取md5。以1亿键值对来进行估算，取md5的前五位作为key，后27位作为hash键值对的key。</p>

<p>扫描原始redis实例，然后把键值对转换后存储到新的实例。转换Scala代码如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import java.util.{List =&gt; JList}
</span><span class='line'>import org.apache.commons.codec.digest.DigestUtils
</span><span class='line'>import redis.clients.jedis._
</span><span class='line'>import scala.collection.JavaConversions._
</span><span class='line'>
</span><span class='line'>trait RedisUtils {
</span><span class='line'>
</span><span class='line'>  def md5(data: String): String = {
</span><span class='line'>    DigestUtils.md5Hex(data)
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  def Type(redis: Jedis, key: String) = redis.`type`(key)
</span><span class='line'>
</span><span class='line'>  def scan(redis: Jedis)(action: JList[String] =&gt; Unit): Unit = {
</span><span class='line'>    import scala.util.control.Breaks._
</span><span class='line'>
</span><span class='line'>    var cursor = "0"
</span><span class='line'>    breakable {
</span><span class='line'>      while (true) {
</span><span class='line'>        val res = redis.scan(cursor)
</span><span class='line'>
</span><span class='line'>        action(res.getResult())
</span><span class='line'>
</span><span class='line'>        cursor = res.getStringCursor
</span><span class='line'>        if (cursor.equals("0")) {
</span><span class='line'>          break
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  def printInfo(redis: Jedis): Unit = {
</span><span class='line'>    println(redis.info())
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  // 验证：
</span><span class='line'>  //  打印 **总共** 的键值对数量
</span><span class='line'>  //  eval "local aks=redis.call('keys', '*'); local res=0; for i,r in ipairs(aks) do res=res+redis.call('hlen', r) end; return res" 0
</span><span class='line'>  //  打印 **每个** hash包括的键值对个数
</span><span class='line'>  //  eval "local aks=redis.call('keys', '*'); local res={}; for i,r in ipairs(aks) do res[i]=redis.call('hlen', r) end; return res" 0
</span><span class='line'>  //
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>Object RedisTransfer extends RedisUtils {
</span><span class='line'>
</span><span class='line'>  def handle(key: String, value: String, tp: Pipeline): Unit = {
</span><span class='line'>    val m5 = md5(key)
</span><span class='line'>    tp.hset(m5.substring(0, 5), m5.substring(5), value)
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  def main(args: Array[String]) {
</span><span class='line'>    val Array(sHost, sPort, tHost, tPort) = args
</span><span class='line'>
</span><span class='line'>    val timeout = 60 * 1000
</span><span class='line'>    val source = new Jedis(sHost, sPort.toInt, timeout)
</span><span class='line'>    val sp = source.pipelined()
</span><span class='line'>    val target = new Jedis(tHost, tPort.toInt, timeout)
</span><span class='line'>    val tp = target.pipelined()
</span><span class='line'>
</span><span class='line'>    scan(source) { keys =&gt;
</span><span class='line'>      // 仅处理 string类型 的记录
</span><span class='line'>      val requests = for (key &lt;- keys) yield Some((key, sp.get(key)))
</span><span class='line'>      sp.sync()
</span><span class='line'>
</span><span class='line'>      for (
</span><span class='line'>        request &lt;- requests;
</span><span class='line'>        (key, resp) &lt;- request
</span><span class='line'>      ) {
</span><span class='line'>        try {
</span><span class='line'>          handle(key, resp.get(), tp)
</span><span class='line'>        } catch {
</span><span class='line'>          case e: Exception =&gt; println(s"fetch $key with exception, ${e.getMessage}")
</span><span class='line'>        }
</span><span class='line'>      }
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    tp.sync()
</span><span class='line'>
</span><span class='line'>    printInfo(target)
</span><span class='line'>
</span><span class='line'>    target.close()
</span><span class='line'>    source.close()
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>由于对数据进行了处理，对比不是很清晰，不能直接说省了多少空间。但是添加上面的处理后，原来30G（大概3亿多）的实例变成了15G。</p>

<h2>另一个案例</h2>

<p>另外对域名的实例做了下测试，6.4百万的键值对：707.29M内存：</p>

<p>md5前4个字符作为key，总共产生65536个键值对。每个hash大概包括100个kv。</p>

<ul>
<li>hash的key使用原来的键

<ul>
<li>不调ziplist_value的值，实际的转换成hash(skiplist)：939.6M，</li>
<li>ziplist_value修改成1024，转换成hash(ziplist)：513.78M</li>
</ul>
</li>
<li>md5的作为hash的新key：344.7M</li>
<li>md5的后28位作为hash的新key： 259.09M</li>
</ul>


<p>如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MD5:
</span><span class='line'>  3:0dc46077dfaa4970a1ec9f38cfc29277fa9e1012.ime.galileo.baidu.com
</span><span class='line'>  1356de078028ddf266c962533760b27c
</span><span class='line'>
</span><span class='line'>1356 -&gt; hash( 3:0dc46077dfaa4970a1ec9f38cfc29277fa9e1012.ime.galileo.baidu.com -&gt; 1469584847 )
</span><span class='line'>1356 -&gt; hash( 1356de078028ddf266c962533760b27c -&gt; 1469584847 )
</span><span class='line'>1356 -&gt; hash( de078028ddf266c962533760b27c -&gt; 1469584847 )</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Naxsi 处理 XSS]]></title>
    <link href="http://winseliu.com/blog/2016/07/19/xss-blocked-by-naxsi/"/>
    <updated>2016-07-19T19:43:13+08:00</updated>
    <id>http://winseliu.com/blog/2016/07/19/xss-blocked-by-naxsi</id>
    <content type="html"><![CDATA[<p>前台安全检查时出现了【检测到目标URL存在跨站漏洞】，就是可以通过url带js来截取用户的信息。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>js/jquery/jquery-1.8.2.min.js/&lt;ScRipt&gt;jovoys(6258);&lt;/ScRipt&gt;</span></code></pre></td></tr></table></div></figure>


<p>XSS的一些简单介绍：</p>

<ul>
<li><a href="http://anti-hacker.blogspot.com/2008/01/xsscross-site-script.html">淺析XSS(Cross Site Script)漏洞原理</a></li>
<li><a href="http://www.freebuf.com/articles/web/42727.html">XSS的原理分析与解剖（第二篇）</a></li>
</ul>


<p>搜索到使用 <strong>naxsi</strong> 配合 <strong>nginx</strong> 有现成的解决方案，网上的资料很乱，直接看 <a href="https://github.com/nbs-system/naxsi/wiki">官方文档</a> 清晰一些。</p>

<ol>
<li>编译</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 sources]$ ll
</span><span class='line'>drwxrwxr-x  6 hadoop hadoop      4096 Sep 10  2015 naxsi-0.54
</span><span class='line'>-rw-r--r--  1 hadoop hadoop    192843 Jul 19 18:42 naxsi-0.54.zip
</span><span class='line'>drwxr-xr-x  9 hadoop hadoop      4096 Nov 11  2015 nginx-1.7.10
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 sources]$ ll nginx-1.7.10/
</span><span class='line'>total 3180
</span><span class='line'>drwxr-xr-x  6 hadoop hadoop    4096 Nov 11  2015 auto
</span><span class='line'>-rw-r--r--  1 hadoop hadoop  246649 Feb 10  2015 CHANGES
</span><span class='line'>-rw-r--r--  1 hadoop hadoop  375103 Feb 10  2015 CHANGES.ru
</span><span class='line'>drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 conf
</span><span class='line'>-rwxr-xr-x  1 hadoop hadoop    2463 Feb 10  2015 configure
</span><span class='line'>drwxr-xr-x  4 hadoop hadoop    4096 Nov 11  2015 contrib
</span><span class='line'>drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 html
</span><span class='line'>-rw-r--r--  1 hadoop hadoop    1397 Feb 10  2015 LICENSE
</span><span class='line'>-rw-rw-r--  1 hadoop hadoop     342 Jul 19 18:44 Makefile
</span><span class='line'>drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 man
</span><span class='line'>drwxrwxr-x  4 hadoop hadoop    4096 Jul 19 18:45 objs
</span><span class='line'>-rw-r--r--  1 hadoop hadoop 2009464 Nov 11  2015 pcre-8.36.tar.gz
</span><span class='line'>-rw-r--r--  1 hadoop hadoop      49 Feb 10  2015 README
</span><span class='line'>drwxr-xr-x 10 hadoop hadoop    4096 Nov 11  2015 src
</span><span class='line'>-rw-r--r--  1 hadoop hadoop  571091 Nov 11  2015 zlib-1.2.8.tar.gz
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 nginx-1.7.10]$ ./configure --add-module=../naxsi-x.xx/naxsi_src/ --prefix=/opt/nginx
</span><span class='line'>[hadoop@cu2 nginx-1.7.10]$ make && make install
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>配置</li>
</ol>


<p>需要在 nginx.conf 的http中引入 <strong>naxsi_core.rules</strong> ，在location中加入规则。</p>

<p>先把 naxsi_core.rules 拷贝到 nginx/conf 目录下。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>http {
</span><span class='line'>    include       mime.types;
</span><span class='line'>    include       naxsi_core.rules;
</span><span class='line'>  ...
</span><span class='line'>    server {
</span><span class='line'>  ...
</span><span class='line'>        location /omc {
</span><span class='line'>
</span><span class='line'>#Enable naxsi
</span><span class='line'>SecRulesEnabled;
</span><span class='line'>
</span><span class='line'>#Enable learning mide
</span><span class='line'>#LearningMode;
</span><span class='line'>
</span><span class='line'>#Define where blocked requests go
</span><span class='line'>DeniedUrl "/omc/error.jsp";
</span><span class='line'>
</span><span class='line'>#CheckRules, determining when naxsi needs to take action
</span><span class='line'>CheckRule "$SQL &gt;= 8" BLOCK;
</span><span class='line'>CheckRule "$RFI &gt;= 8" BLOCK;
</span><span class='line'>CheckRule "$TRAVERSAL &gt;= 4" BLOCK;
</span><span class='line'>CheckRule "$EVADE &gt;= 4" BLOCK;
</span><span class='line'>CheckRule "$XSS &gt;= 8" BLOCK;
</span><span class='line'>
</span><span class='line'>#naxsi logs goes there
</span><span class='line'>error_log logs/foo.log;
</span><span class='line'>
</span><span class='line'>                proxy_set_header        X-Real-IP $remote_addr;
</span><span class='line'>                proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
</span><span class='line'>                proxy_set_header        Host $http_host;
</span><span class='line'>
</span><span class='line'>                proxy_pass http://localhost:8888/omc;
</span><span class='line'>        }
</span><span class='line'>      ...
</span><span class='line'>      </span></code></pre></td></tr></table></div></figure>


<ol>
<li>启动生效</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sbin/nginx -p $PWD</span></code></pre></td></tr></table></div></figure>


<p><a href="https://github.com/nbs-system/naxsi/wiki/naxsi-setup">https://github.com/nbs-system/naxsi/wiki/naxsi-setup</a>
<a href="https://github.com/nbs-system/naxsi/wiki/checkrules-bnf">https://github.com/nbs-system/naxsi/wiki/checkrules-bnf</a></p>

<p>检查会比较严格，添加后应用可能会报错，需要对 foo.log 中的情况进行确认，对规则进行一些修改。如不需要监控 cookie 里面的内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[omc@cu-omc1 nginx]$ vi conf/naxsi_core.rules 
</span><span class='line'>:%s/|$HEADERS_VAR:Cookie//</span></code></pre></td></tr></table></div></figure>


<p>还有一些 <code>%[2|3]</code> 的可能也需要改改。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>uri=/omc/Frame/Time.do&learning=0&vers=0.54&total_processed=404&total_blocked=10&block=1&zone0=BODY&id0=16&var_name0=</span></code></pre></td></tr></table></div></figure>


<p>根据请求的 id 去规则配置里面找具体的描述，然后 uri 和 var_name 查看具体的请求对症下药：去掉规则或者改请求。</p>

<p>如上面请求的 <strong>id0=16</strong> 对应 <strong>#@MainRule &ldquo;msg:empty POST&rdquo; id:16;</strong> 把请求修改成get即可。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Codis简单使用]]></title>
    <link href="http://winseliu.com/blog/2016/07/14/codis-guide/"/>
    <updated>2016-07-14T19:35:23+08:00</updated>
    <id>http://winseliu.com/blog/2016/07/14/codis-guide</id>
    <content type="html"><![CDATA[<p>总有单机搞不定的时刻，并且手动切分很麻烦的时刻。不得不开始redis集群，官网的redis3不支持pipeline首先就排除了。</p>

<p>安装codis，需要先安装go。(官网入门文档](<a href="https://github.com/CodisLabs/codis/blob/master/doc/tutorial_zh.md">https://github.com/CodisLabs/codis/blob/master/doc/tutorial_zh.md</a>)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 local]# tar zxvf go1.6.2.linux-amd64.tar.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ vi .bash_profile
</span><span class='line'>...
</span><span class='line'>export GOROOT=/usr/local/go
</span><span class='line'>export GOPATH=$HOME/codis
</span><span class='line'>
</span><span class='line'>PATH=$GOPATH/bin:$GOROOT/bin:$HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$PATH
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 codis]$ source ~/.bash_profile </span></code></pre></td></tr></table></div></figure>


<p>git,make 这些要提前安装好。测试环境都编译过hadoop、spark肯定齐全的。</p>

<p>通过go在线安装（如果生产不能上网，可以先在测试环境安装好后，然后打包复制过去）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
<span class='line-number'>296</span>
<span class='line-number'>297</span>
<span class='line-number'>298</span>
<span class='line-number'>299</span>
<span class='line-number'>300</span>
<span class='line-number'>301</span>
<span class='line-number'>302</span>
<span class='line-number'>303</span>
<span class='line-number'>304</span>
<span class='line-number'>305</span>
<span class='line-number'>306</span>
<span class='line-number'>307</span>
<span class='line-number'>308</span>
<span class='line-number'>309</span>
<span class='line-number'>310</span>
<span class='line-number'>311</span>
<span class='line-number'>312</span>
<span class='line-number'>313</span>
<span class='line-number'>314</span>
<span class='line-number'>315</span>
<span class='line-number'>316</span>
<span class='line-number'>317</span>
<span class='line-number'>318</span>
<span class='line-number'>319</span>
<span class='line-number'>320</span>
<span class='line-number'>321</span>
<span class='line-number'>322</span>
<span class='line-number'>323</span>
<span class='line-number'>324</span>
<span class='line-number'>325</span>
<span class='line-number'>326</span>
<span class='line-number'>327</span>
<span class='line-number'>328</span>
<span class='line-number'>329</span>
<span class='line-number'>330</span>
<span class='line-number'>331</span>
<span class='line-number'>332</span>
<span class='line-number'>333</span>
<span class='line-number'>334</span>
<span class='line-number'>335</span>
<span class='line-number'>336</span>
<span class='line-number'>337</span>
<span class='line-number'>338</span>
<span class='line-number'>339</span>
<span class='line-number'>340</span>
<span class='line-number'>341</span>
<span class='line-number'>342</span>
<span class='line-number'>343</span>
<span class='line-number'>344</span>
<span class='line-number'>345</span>
<span class='line-number'>346</span>
<span class='line-number'>347</span>
<span class='line-number'>348</span>
<span class='line-number'>349</span>
<span class='line-number'>350</span>
<span class='line-number'>351</span>
<span class='line-number'>352</span>
<span class='line-number'>353</span>
<span class='line-number'>354</span>
<span class='line-number'>355</span>
<span class='line-number'>356</span>
<span class='line-number'>357</span>
<span class='line-number'>358</span>
<span class='line-number'>359</span>
<span class='line-number'>360</span>
<span class='line-number'>361</span>
<span class='line-number'>362</span>
<span class='line-number'>363</span>
<span class='line-number'>364</span>
<span class='line-number'>365</span>
<span class='line-number'>366</span>
<span class='line-number'>367</span>
<span class='line-number'>368</span>
<span class='line-number'>369</span>
<span class='line-number'>370</span>
<span class='line-number'>371</span>
<span class='line-number'>372</span>
<span class='line-number'>373</span>
<span class='line-number'>374</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 codis]$ go get -u -d github.com/CodisLabs/codis
</span><span class='line'>package github.com/CodisLabs/codis: no buildable Go source files in /home/hadoop/codis/src/github.com/CodisLabs/codis
</span><span class='line'>[hadoop@cu2 codis]$ 
</span><span class='line'>
</span><span class='line'>&lt;&lt;安装依赖的工具
</span><span class='line'>[hadoop@cu2 codis]$ go get github.com/tools/godep
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 codis]$ make
</span><span class='line'>GO15VENDOREXPERIMENT=0 GOPATH=`godep path` godep restore
</span><span class='line'>godep: [WARNING]: godep should only be used inside a valid go package directory and
</span><span class='line'>godep: [WARNING]: may not function correctly. You are probably outside of your $GOPATH.
</span><span class='line'>godep: [WARNING]:       Current Directory: /home/hadoop/codis/src/github.com/CodisLabs/codis
</span><span class='line'>godep: [WARNING]:       $GOPATH: /home/hadoop/codis/src/github.com/CodisLabs/codis/Godeps/_workspace
</span><span class='line'>       
</span><span class='line'>&lt;&lt;这里要等一段时间
</span><span class='line'>
</span><span class='line'>GOPATH=`godep path`:$GOPATH go build -o bin/codis-proxy ./cmd/proxy
</span><span class='line'>godep: WARNING: Godep workspaces (./Godeps/_workspace) are deprecated and support for them will be removed when go1.8 is released.
</span><span class='line'>godep: WARNING: Go version (go1.6) & $GO15VENDOREXPERIMENT= wants to enable the vendor experiment, but disabling because a Godep workspace (Godeps/_workspace) exists
</span><span class='line'>GOPATH=`godep path`:$GOPATH go build -o bin/codis-config ./cmd/cconfig
</span><span class='line'>godep: WARNING: Godep workspaces (./Godeps/_workspace) are deprecated and support for them will be removed when go1.8 is released.
</span><span class='line'>godep: WARNING: Go version (go1.6) & $GO15VENDOREXPERIMENT= wants to enable the vendor experiment, but disabling because a Godep workspace (Godeps/_workspace) exists
</span><span class='line'>make -j4 -C extern/redis-2.8.21/
</span><span class='line'>make[1]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21'
</span><span class='line'>cd src && make all
</span><span class='line'>make[2]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/src'
</span><span class='line'>rm -rf redis-server redis-sentinel redis-cli redis-benchmark redis-check-dump redis-check-aof *.o *.gcda *.gcno *.gcov redis.info lcov-html
</span><span class='line'>(cd ../deps && make distclean)
</span><span class='line'>make[3]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps'
</span><span class='line'>(cd hiredis && make clean) &gt; /dev/null || true
</span><span class='line'>(cd linenoise && make clean) &gt; /dev/null || true
</span><span class='line'>(cd lua && make clean) &gt; /dev/null || true
</span><span class='line'>(cd jemalloc && [ -f Makefile ] && make distclean) &gt; /dev/null || true
</span><span class='line'>(rm -f .make-*)
</span><span class='line'>make[3]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps'
</span><span class='line'>(rm -f .make-*)
</span><span class='line'>echo STD=-std=c99 -pedantic &gt;&gt; .make-settings
</span><span class='line'>echo WARN=-Wall -W &gt;&gt; .make-settings
</span><span class='line'>echo OPT=-O2 &gt;&gt; .make-settings
</span><span class='line'>echo MALLOC=jemalloc &gt;&gt; .make-settings
</span><span class='line'>echo CFLAGS= &gt;&gt; .make-settings
</span><span class='line'>echo LDFLAGS= &gt;&gt; .make-settings
</span><span class='line'>echo REDIS_CFLAGS= &gt;&gt; .make-settings
</span><span class='line'>echo REDIS_LDFLAGS= &gt;&gt; .make-settings
</span><span class='line'>echo PREV_FINAL_CFLAGS=-std=c99 -pedantic -Wall -W -O2 -g -ggdb   -I../deps/hiredis -I../deps/linenoise -I../deps/lua/src -DUSE_JEMALLOC -I../deps/jemalloc/include &gt;&gt; .make-settings
</span><span class='line'>echo PREV_FINAL_LDFLAGS=  -g -ggdb -rdynamic &gt;&gt; .make-settings
</span><span class='line'>(cd ../deps && make hiredis linenoise lua jemalloc)
</span><span class='line'>make[3]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps'
</span><span class='line'>(cd hiredis && make clean) &gt; /dev/null || true
</span><span class='line'>(cd linenoise && make clean) &gt; /dev/null || true
</span><span class='line'>(cd lua && make clean) &gt; /dev/null || true
</span><span class='line'>(cd jemalloc && [ -f Makefile ] && make distclean) &gt; /dev/null || true
</span><span class='line'>(rm -f .make-*)
</span><span class='line'>(echo "" &gt; .make-ldflags)
</span><span class='line'>(echo "" &gt; .make-cflags)
</span><span class='line'>MAKE hiredis
</span><span class='line'>cd hiredis && make static
</span><span class='line'>MAKE linenoise
</span><span class='line'>cd linenoise && make
</span><span class='line'>MAKE lua
</span><span class='line'>cd lua/src && make all CFLAGS="-O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL " MYLDFLAGS="" AR="ar rcu"
</span><span class='line'>MAKE jemalloc
</span><span class='line'>cd jemalloc && ./configure --with-jemalloc-prefix=je_ --enable-cc-silence CFLAGS="-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops " LDFLAGS=""
</span><span class='line'>make[4]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/linenoise'
</span><span class='line'>cc  -Wall -Os -g  -c linenoise.c
</span><span class='line'>make[4]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/lua/src'
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lapi.o lapi.c
</span><span class='line'>make[4]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/hiredis'
</span><span class='line'>cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  net.c
</span><span class='line'>checking for xsltproc... /usr/bin/xsltproc
</span><span class='line'>checking for gcc... gcc
</span><span class='line'>checking whether the C compiler works... yes
</span><span class='line'>checking for C compiler default output file name... a.out
</span><span class='line'>checking for suffix of executables... 
</span><span class='line'>checking whether we are cross compiling... no
</span><span class='line'>checking for suffix of object files... o
</span><span class='line'>checking whether we are using the GNU C compiler... cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  hiredis.c
</span><span class='line'>yes
</span><span class='line'>checking whether gcc accepts -g... yes
</span><span class='line'>checking for gcc option to accept ISO C89... none needed
</span><span class='line'>checking how to run the C preprocessor... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lcode.o lcode.c
</span><span class='line'>make[4]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/linenoise'
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ldebug.o ldebug.c
</span><span class='line'>gcc -E
</span><span class='line'>checking for grep that handles long lines and -e... /bin/grep
</span><span class='line'>checking for egrep... /bin/grep -E
</span><span class='line'>checking for ANSI C header files... yes
</span><span class='line'>checking for sys/types.h... yes
</span><span class='line'>checking for sys/stat.h... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ldo.o ldo.c
</span><span class='line'>yes
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ldump.o ldump.c
</span><span class='line'>checking for stdlib.h... ldo.c: In function ‘f_parser’:
</span><span class='line'>ldo.c:496: warning: unused variable ‘c’
</span><span class='line'>yes
</span><span class='line'>checking for string.h... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lfunc.o lfunc.c
</span><span class='line'>yes
</span><span class='line'>checking for memory.h... yes
</span><span class='line'>checking for strings.h... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lgc.o lgc.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o llex.o llex.c
</span><span class='line'>yes
</span><span class='line'>cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  sds.c
</span><span class='line'>checking for inttypes.h... yes
</span><span class='line'>checking for stdint.h... yes
</span><span class='line'>checking for unistd.h... yes
</span><span class='line'>checking whether byte ordering is bigendian... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lmem.o lmem.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lobject.o lobject.c
</span><span class='line'>no
</span><span class='line'>checking size of void *... cc -std=c99 -pedantic -c -O3 -fPIC  -Wall -W -Wstrict-prototypes -Wwrite-strings -g -ggdb  async.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lopcodes.o lopcodes.c
</span><span class='line'>8
</span><span class='line'>checking size of int... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lparser.o lparser.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lstate.o lstate.c
</span><span class='line'>4
</span><span class='line'>checking size of long... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lstring.o lstring.c
</span><span class='line'>8
</span><span class='line'>checking size of intmax_t... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ltable.o ltable.c
</span><span class='line'>8
</span><span class='line'>checking build system type... ar rcs libhiredis.a net.o hiredis.o sds.o async.o
</span><span class='line'>x86_64-unknown-linux-gnu
</span><span class='line'>checking host system type... x86_64-unknown-linux-gnu
</span><span class='line'>checking whether pause instruction is compilable... make[4]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/hiredis'
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ltm.o ltm.c
</span><span class='line'>yes
</span><span class='line'>checking whether SSE2 intrinsics is compilable... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lundump.o lundump.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lvm.o lvm.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lzio.o lzio.c
</span><span class='line'>yes
</span><span class='line'>checking for ar... ar
</span><span class='line'>checking whether __attribute__ syntax is compilable... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o strbuf.o strbuf.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o fpconv.o fpconv.c
</span><span class='line'>yes
</span><span class='line'>checking whether compiler supports -fvisibility=hidden... yes
</span><span class='line'>checking whether compiler supports -Werror... yes
</span><span class='line'>checking whether tls_model attribute is compilable... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lauxlib.o lauxlib.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lbaselib.o lbaselib.c
</span><span class='line'>yes
</span><span class='line'>checking for a BSD-compatible install... /usr/bin/install -c
</span><span class='line'>checking for ranlib... ranlib
</span><span class='line'>checking for ld... /usr/bin/ld
</span><span class='line'>checking for autoconf... /usr/bin/autoconf
</span><span class='line'>checking for memalign... yes
</span><span class='line'>checking for valloc... yes
</span><span class='line'>checking configured backtracing method... N/A
</span><span class='line'>checking for sbrk... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ldblib.o ldblib.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o liolib.o liolib.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lmathlib.o lmathlib.c
</span><span class='line'>yes
</span><span class='line'>checking whether utrace(2) is compilable... no
</span><span class='line'>checking whether valgrind is compilable... no
</span><span class='line'>checking STATIC_PAGE_SHIFT... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o loslib.o loslib.c
</span><span class='line'>12
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o ltablib.o ltablib.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lstrlib.o lstrlib.c
</span><span class='line'>checking pthread.h usability... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o loadlib.o loadlib.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o linit.o linit.c
</span><span class='line'>yes
</span><span class='line'>checking pthread.h presence... yes
</span><span class='line'>checking for pthread.h... yes
</span><span class='line'>checking for pthread_create in -lpthread... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lua_cjson.o lua_cjson.c
</span><span class='line'>yes
</span><span class='line'>checking for _malloc_thread_cleanup... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lua_struct.o lua_struct.c
</span><span class='line'>no
</span><span class='line'>checking for _pthread_mutex_init_calloc_cb... no
</span><span class='line'>checking for TLS... yes
</span><span class='line'>checking whether a program using ffsl is compilable... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lua_cmsgpack.o lua_cmsgpack.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lua_bit.o lua_bit.c
</span><span class='line'>yes
</span><span class='line'>checking whether atomic(9) is compilable... no
</span><span class='line'>checking whether Darwin OSAtomic*() is compilable... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o lua.o lua.c
</span><span class='line'>cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o luac.o luac.c
</span><span class='line'>no
</span><span class='line'>checking whether to force 32-bit __sync_{add,sub}_and_fetch()... no
</span><span class='line'>checking whether to force 64-bit __sync_{add,sub}_and_fetch()... no
</span><span class='line'>checking whether Darwin OSSpin*() is compilable... no
</span><span class='line'>checking for stdbool.h that conforms to C99... cc -O2 -Wall -DLUA_ANSI -DENABLE_CJSON_GLOBAL    -c -o print.o print.c
</span><span class='line'>yes
</span><span class='line'>checking for _Bool... ar rcu liblua.a lapi.o lcode.o ldebug.o ldo.o ldump.o lfunc.o lgc.o llex.o lmem.o lobject.o lopcodes.o lparser.o lstate.o lstring.o ltable.o ltm.o lundump.o lvm.o lzio.o strbuf.o fpconv.o lauxlib.o lbaselib.o ldblib.o liolib.o lmathlib.o loslib.o ltablib.o lstrlib.o loadlib.o linit.o lua_cjson.o lua_struct.o lua_cmsgpack.o lua_bit.o        # DLL needs all object files
</span><span class='line'>ranlib liblua.a
</span><span class='line'>cc -o lua  lua.o liblua.a -lm 
</span><span class='line'>liblua.a(loslib.o): In function `os_tmpname':
</span><span class='line'>loslib.c:(.text+0x35): warning: the use of `tmpnam' is dangerous, better use `mkstemp'
</span><span class='line'>cc -o luac  luac.o print.o liblua.a -lm 
</span><span class='line'>yes
</span><span class='line'>make[4]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/lua/src'
</span><span class='line'>configure: creating ./config.status
</span><span class='line'>config.status: creating Makefile
</span><span class='line'>config.status: creating doc/html.xsl
</span><span class='line'>config.status: creating doc/manpages.xsl
</span><span class='line'>config.status: creating doc/jemalloc.xml
</span><span class='line'>config.status: creating include/jemalloc/jemalloc_macros.h
</span><span class='line'>config.status: creating include/jemalloc/jemalloc_protos.h
</span><span class='line'>config.status: creating include/jemalloc/internal/jemalloc_internal.h
</span><span class='line'>config.status: creating test/test.sh
</span><span class='line'>config.status: creating test/include/test/jemalloc_test.h
</span><span class='line'>config.status: creating config.stamp
</span><span class='line'>config.status: creating bin/jemalloc.sh
</span><span class='line'>config.status: creating include/jemalloc/jemalloc_defs.h
</span><span class='line'>config.status: creating include/jemalloc/internal/jemalloc_internal_defs.h
</span><span class='line'>config.status: creating test/include/test/jemalloc_test_defs.h
</span><span class='line'>config.status: executing include/jemalloc/internal/private_namespace.h commands
</span><span class='line'>config.status: executing include/jemalloc/internal/private_unnamespace.h commands
</span><span class='line'>config.status: executing include/jemalloc/internal/public_symbols.txt commands
</span><span class='line'>config.status: executing include/jemalloc/internal/public_namespace.h commands
</span><span class='line'>config.status: executing include/jemalloc/internal/public_unnamespace.h commands
</span><span class='line'>config.status: executing include/jemalloc/internal/size_classes.h commands
</span><span class='line'>config.status: executing include/jemalloc/jemalloc_protos_jet.h commands
</span><span class='line'>config.status: executing include/jemalloc/jemalloc_rename.h commands
</span><span class='line'>config.status: executing include/jemalloc/jemalloc_mangle.h commands
</span><span class='line'>config.status: executing include/jemalloc/jemalloc_mangle_jet.h commands
</span><span class='line'>config.status: executing include/jemalloc/jemalloc.h commands
</span><span class='line'>===============================================================================
</span><span class='line'>jemalloc version   : 3.6.0-0-g46c0af68bd248b04df75e4f92d5fb804c3d75340
</span><span class='line'>library revision   : 1
</span><span class='line'>
</span><span class='line'>CC                 : gcc
</span><span class='line'>CPPFLAGS           :  -D_GNU_SOURCE -D_REENTRANT
</span><span class='line'>CFLAGS             : -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden
</span><span class='line'>LDFLAGS            : 
</span><span class='line'>EXTRA_LDFLAGS      : 
</span><span class='line'>LIBS               :  -lpthread
</span><span class='line'>RPATH_EXTRA        : 
</span><span class='line'>
</span><span class='line'>XSLTPROC           : /usr/bin/xsltproc
</span><span class='line'>XSLROOT            : 
</span><span class='line'>
</span><span class='line'>PREFIX             : /usr/local
</span><span class='line'>BINDIR             : /usr/local/bin
</span><span class='line'>INCLUDEDIR         : /usr/local/include
</span><span class='line'>LIBDIR             : /usr/local/lib
</span><span class='line'>DATADIR            : /usr/local/share
</span><span class='line'>MANDIR             : /usr/local/share/man
</span><span class='line'>
</span><span class='line'>srcroot            : 
</span><span class='line'>abs_srcroot        : /home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/jemalloc/
</span><span class='line'>objroot            : 
</span><span class='line'>abs_objroot        : /home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/jemalloc/
</span><span class='line'>
</span><span class='line'>JEMALLOC_PREFIX    : je_
</span><span class='line'>JEMALLOC_PRIVATE_NAMESPACE
</span><span class='line'>                   : je_
</span><span class='line'>install_suffix     : 
</span><span class='line'>autogen            : 0
</span><span class='line'>experimental       : 1
</span><span class='line'>cc-silence         : 1
</span><span class='line'>debug              : 0
</span><span class='line'>code-coverage      : 0
</span><span class='line'>stats              : 1
</span><span class='line'>prof               : 0
</span><span class='line'>prof-libunwind     : 0
</span><span class='line'>prof-libgcc        : 0
</span><span class='line'>prof-gcc           : 0
</span><span class='line'>tcache             : 1
</span><span class='line'>fill               : 1
</span><span class='line'>utrace             : 0
</span><span class='line'>valgrind           : 0
</span><span class='line'>xmalloc            : 0
</span><span class='line'>mremap             : 0
</span><span class='line'>munmap             : 0
</span><span class='line'>dss                : 0
</span><span class='line'>lazy_lock          : 0
</span><span class='line'>tls                : 1
</span><span class='line'>===============================================================================
</span><span class='line'>cd jemalloc && make CFLAGS="-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops " LDFLAGS="" lib/libjemalloc.a
</span><span class='line'>make[4]: Entering directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/jemalloc'
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/jemalloc.o src/jemalloc.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/arena.o src/arena.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/atomic.o src/atomic.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/base.o src/base.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/bitmap.o src/bitmap.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/chunk.o src/chunk.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/chunk_dss.o src/chunk_dss.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/chunk_mmap.o src/chunk_mmap.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ckh.o src/ckh.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/ctl.o src/ctl.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/extent.o src/extent.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/hash.o src/hash.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/huge.o src/huge.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/mb.o src/mb.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/mutex.o src/mutex.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/prof.o src/prof.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/quarantine.o src/quarantine.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/rtree.o src/rtree.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/stats.o src/stats.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/tcache.o src/tcache.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/util.o src/util.c
</span><span class='line'>gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -c -D_GNU_SOURCE -D_REENTRANT -Iinclude -Iinclude -o src/tsd.o src/tsd.c
</span><span class='line'>ar crus lib/libjemalloc.a src/jemalloc.o src/arena.o src/atomic.o src/base.o src/bitmap.o src/chunk.o src/chunk_dss.o src/chunk_mmap.o src/ckh.o src/ctl.o src/extent.o src/hash.o src/huge.o src/mb.o src/mutex.o src/prof.o src/quarantine.o src/rtree.o src/stats.o src/tcache.o src/util.o src/tsd.o
</span><span class='line'>make[4]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps/jemalloc'
</span><span class='line'>make[3]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/deps'
</span><span class='line'>    CC adlist.o
</span><span class='line'>    CC ae.o
</span><span class='line'>    CC anet.o
</span><span class='line'>    CC dict.o
</span><span class='line'>anet.c: In function ‘anetSockName’:
</span><span class='line'>anet.c:565: warning: dereferencing pointer ‘s’ does break strict-aliasing rules
</span><span class='line'>anet.c:563: note: initialized from here
</span><span class='line'>anet.c:569: warning: dereferencing pointer ‘s’ does break strict-aliasing rules
</span><span class='line'>anet.c:567: note: initialized from here
</span><span class='line'>anet.c: In function ‘anetPeerToString’:
</span><span class='line'>anet.c:543: warning: dereferencing pointer ‘s’ does break strict-aliasing rules
</span><span class='line'>anet.c:541: note: initialized from here
</span><span class='line'>anet.c:547: warning: dereferencing pointer ‘s’ does break strict-aliasing rules
</span><span class='line'>anet.c:545: note: initialized from here
</span><span class='line'>anet.c: In function ‘anetTcpAccept’:
</span><span class='line'>anet.c:511: warning: dereferencing pointer ‘s’ does break strict-aliasing rules
</span><span class='line'>anet.c:509: note: initialized from here
</span><span class='line'>anet.c:515: warning: dereferencing pointer ‘s’ does break strict-aliasing rules
</span><span class='line'>anet.c:513: note: initialized from here
</span><span class='line'>    CC redis.o
</span><span class='line'>    CC sds.o
</span><span class='line'>    CC zmalloc.o
</span><span class='line'>    CC lzf_c.o
</span><span class='line'>    CC lzf_d.o
</span><span class='line'>    CC pqsort.o
</span><span class='line'>    CC zipmap.o
</span><span class='line'>    CC ziplist.o
</span><span class='line'>    CC sha1.o
</span><span class='line'>    CC release.o
</span><span class='line'>    CC networking.o
</span><span class='line'>    CC util.o
</span><span class='line'>    CC object.o
</span><span class='line'>    CC db.o
</span><span class='line'>    CC replication.o
</span><span class='line'>    CC rdb.o
</span><span class='line'>db.c: In function ‘scanGenericCommand’:
</span><span class='line'>db.c:454: warning: ‘pat’ may be used uninitialized in this function
</span><span class='line'>db.c:455: warning: ‘patlen’ may be used uninitialized in this function
</span><span class='line'>    CC t_string.o
</span><span class='line'>    CC t_list.o
</span><span class='line'>    CC t_set.o
</span><span class='line'>    CC t_zset.o
</span><span class='line'>    CC t_hash.o
</span><span class='line'>    CC config.o
</span><span class='line'>    CC aof.o
</span><span class='line'>    CC pubsub.o
</span><span class='line'>    CC multi.o
</span><span class='line'>    CC debug.o
</span><span class='line'>    CC sort.o
</span><span class='line'>    CC intset.o
</span><span class='line'>    CC syncio.o
</span><span class='line'>    CC migrate.o
</span><span class='line'>    CC endianconv.o
</span><span class='line'>    CC slowlog.o
</span><span class='line'>    CC scripting.o
</span><span class='line'>    CC bio.o
</span><span class='line'>    CC rio.o
</span><span class='line'>    CC rand.o
</span><span class='line'>    CC memtest.o
</span><span class='line'>    CC crc64.o
</span><span class='line'>    CC crc32.o
</span><span class='line'>    CC bitops.o
</span><span class='line'>    CC sentinel.o
</span><span class='line'>    CC notify.o
</span><span class='line'>    CC setproctitle.o
</span><span class='line'>    CC hyperloglog.o
</span><span class='line'>    CC latency.o
</span><span class='line'>    CC sparkline.o
</span><span class='line'>    CC slots.o
</span><span class='line'>    CC redis-cli.o
</span><span class='line'>    CC redis-benchmark.o
</span><span class='line'>    CC redis-check-dump.o
</span><span class='line'>    CC redis-check-aof.o
</span><span class='line'>    LINK redis-benchmark
</span><span class='line'>    LINK redis-check-dump
</span><span class='line'>    LINK redis-check-aof
</span><span class='line'>    LINK redis-server
</span><span class='line'>    INSTALL redis-sentinel
</span><span class='line'>    LINK redis-cli
</span><span class='line'>
</span><span class='line'>Hint: It's a good idea to run 'make test' ;)
</span><span class='line'>
</span><span class='line'>make[2]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21/src'
</span><span class='line'>make[1]: Leaving directory `/home/hadoop/codis/src/github.com/CodisLabs/codis/extern/redis-2.8.21'
</span><span class='line'>[hadoop@cu2 codis]$ </span></code></pre></td></tr></table></div></figure>


<p>简单使用：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 codis]$ pwd
</span><span class='line'>/home/hadoop/codis/src/github.com/CodisLabs/codis
</span><span class='line'>[hadoop@cu2 codis]$ ll bin
</span><span class='line'>total 39856
</span><span class='line'>drwxrwxr-x 4 hadoop hadoop     4096 Jul 14 15:49 assets
</span><span class='line'>-rwxrwxr-x 1 hadoop hadoop 17329904 Jul 14 15:49 codis-config
</span><span class='line'>-rwxrwxr-x 1 hadoop hadoop 17151864 Jul 14 15:49 codis-proxy
</span><span class='line'>-rwxrwxr-x 1 hadoop hadoop  6313083 Jul 14 15:49 codis-server
</span><span class='line'>
</span><span class='line'>&lt;&lt;配置
</span><span class='line'>[hadoop@cu2 codis]$ vi config.ini 
</span><span class='line'>zk=cu3:2181
</span><span class='line'>dashboard_addr=cu2:18087
</span><span class='line'>session_max_timeout=0
</span><span class='line'>session_max_bufsize=1310720
</span><span class='line'>session_max_pipeline=10240000
</span><span class='line'>
</span><span class='line'>&lt;&lt;启动dashboard（大部分命令其实都可以通过网页来完成）
</span><span class='line'>[hadoop@cu2 codis]$ nohup bin/codis-config dashboard &gt;log/dashboard.log 2&gt;&1 &
</span><span class='line'>
</span><span class='line'>&lt;&lt;初始化1024 slot
</span><span class='line'>[hadoop@cu2 codis]$ bin/codis-config slot init
</span><span class='line'>{
</span><span class='line'>  "msg": "OK",
</span><span class='line'>  "ret": 0
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>&lt;&lt;启动redis server
</span><span class='line'>[hadoop@cu2 codis]$ bin/codis-server --port 16379 --daemonize yes
</span><span class='line'>
</span><span class='line'>&lt;&lt;在网页上分配好slot，或者：
</span><span class='line'>
</span><span class='line'>$ bin/codis-config slot range-set 0 511 1 online
</span><span class='line'>$ bin/codis-config slot range-set 512 1023 2 online
</span><span class='line'>
</span><span class='line'>&lt;&lt;然后启动proxy
</span><span class='line'>[hadoop@hadoop-master1 codis]$ nohup bin/codis-proxy -c config.ini -L proxy.log  --cpu=64 --addr=0.0.0.0:6372 --http-addr=0.0.0.0:11000 &gt;&gt;proxy.log 2&gt;&1 &
</span><span class='line'>
</span><span class='line'>&lt;&lt;客户端连接proxy
</span><span class='line'>[hadoop@cu2 codis]$ ~/redis/bin/redis-cli -p 19000
</span><span class='line'>&lt;&lt;不支持的命令
</span><span class='line'>127.0.0.1:19000&gt; keys *
</span><span class='line'>Error: Server closed the connection
</span><span class='line'>127.0.0.1:19000&gt; scan 0
</span><span class='line'>Error: Server closed the connection
</span><span class='line'>
</span><span class='line'>127.0.0.1:19000&gt; get a
</span><span class='line'>"b"
</span><span class='line'>
</span><span class='line'>127.0.0.1:19000&gt; select 2
</span><span class='line'>(error) ERR invalid DB index, only accept DB 0
</span><span class='line'>
</span><span class='line'>&lt;&lt;也可以单独连接到redis server，进行操作
</span><span class='line'>[hadoop@cu2 codis]$ ~/redis/bin/redis-cli -p 16378
</span><span class='line'># Keyspace
</span><span class='line'>db0:keys=6,expires=0,avg_ttl=0
</span><span class='line'>127.0.0.1:16378&gt; keys *
</span><span class='line'>1) "7"
</span><span class='line'>2) "1"
</span><span class='line'>3) "2"
</span><span class='line'>4) "4"
</span><span class='line'>5) "5"
</span><span class='line'>6) "a"</span></code></pre></td></tr></table></div></figure>


<p><a href="https://github.com/CodisLabs/codis/blob/master/doc/unsupported_cmds.md">codis不支持的命令</a>，基本上都是全局操作的命令。不影响使用，如果一定要使用，可以通过客户端单独连server执行。</p>

<p>有个疑问，怎么查看proxy写的数据放在那个slot？要学学go才行。</p>

<h2>安装参考</h2>

<ul>
<li><a href="https://lvs071103.gitbooks.io/codis/content/install.html">https://lvs071103.gitbooks.io/codis/content/install.html</a></li>
<li><a href="http://jicki.blog.51cto.com/1323993/1748549">http://jicki.blog.51cto.com/1323993/1748549</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Flume+kafka+elasticsearch 处理数据]]></title>
    <link href="http://winseliu.com/blog/2016/06/28/flume-kafka-elasticsearch-for-analyse/"/>
    <updated>2016-06-28T09:50:05+08:00</updated>
    <id>http://winseliu.com/blog/2016/06/28/flume-kafka-elasticsearch-for-analyse</id>
    <content type="html"><![CDATA[<p>flume-1.6依赖的kafka、elasticsearch的版本与我这使用程序的版本不一致，部分jar依赖需要替换，flume-elasticsearch-sink源码需要进行一些修改来适配elasticsearch-2.2。</p>

<ul>
<li>flume-1.6.0</li>
<li>kafka_2.11-0.9.0.1(可以与0.8.2客户端通信, flume-kafka-channel-1.6.0不改)</li>
<li>elasticsearch-2.2.0</li>
</ul>


<p>由于版本的差异，需要替换/添加以下jar到 <code>flume/lib</code> 下：</p>

<p>使用 <code>mvn dependecy:copy-dependencies</code> 导出所需依赖的包</p>

<p>jackson一堆，hppc-0.7.1.jar，t-digest-3.0.jar，jsr166e-1.1.0.jar，guava-18.0.jar，lucene一堆，elasticsearch-2.2.0.jar。</p>

<p>远程调试配置：</p>

<p>source由于项目上的一些特殊规则，需要自己编写。通过远程DEBUG来打断点来排查BUG。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 flume]$ vi conf/flume-env.sh
</span><span class='line'>export JAVA_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8092"</span></code></pre></td></tr></table></div></figure>


<h2>实战1</h2>

<p>KafkaChannel：考虑到其他功能也需要用到这些数据。</p>

<p>先写一个配置把flume自带功能跑通，这里用 netcat 作为输入运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 flumebin]$ cat dta.flume 
</span><span class='line'>dta.sources=s1
</span><span class='line'>dta.channels=c1
</span><span class='line'>dta.sinks=k1
</span><span class='line'>
</span><span class='line'>dta.channels.c1.type=org.apache.flume.channel.kafka.KafkaChannel
</span><span class='line'>dta.channels.c1.capacity=10000
</span><span class='line'>dta.channels.c1.transactionCapacity=1000
</span><span class='line'>dta.channels.c1.brokerList=cu5:9093
</span><span class='line'>dta.channels.c1.topic=flume_cmdid_1234
</span><span class='line'>dta.channels.c1.groupId=flume_dta
</span><span class='line'>dta.channels.c1.zookeeperConnect=cu3:2181/kafka_0_9
</span><span class='line'>dta.channels.c1.parseAsFlumeEvent=false
</span><span class='line'>
</span><span class='line'>dta.sources.s1.channels=c1
</span><span class='line'>dta.sources.s1.type=netcat
</span><span class='line'>dta.sources.s1.bind=0.0.0.0
</span><span class='line'>dta.sources.s1.port=6666
</span><span class='line'>dta.sources.s1.max-line-length=88888888
</span><span class='line'>
</span><span class='line'>dta.sinks.k1.channel=c1
</span><span class='line'>dta.sinks.k1.type=elasticsearch
</span><span class='line'>dta.sinks.k1.hostNames=cu2:9300
</span><span class='line'>dta.sinks.k1.indexName=foo_index
</span><span class='line'>dta.sinks.k1.indexType=idcisp
</span><span class='line'>dta.sinks.k1.clusterName=eshore-cu
</span><span class='line'>dta.sinks.k1.batchSize=500
</span><span class='line'>dta.sinks.k1.ttl=5d
</span><span class='line'>dta.sinks.k1.serializer=com.eshore.zhfx.collector.InfoSecurityLogIndexRequestBuilderFactory
</span><span class='line'>dta.sinks.k1.serializer.idcispUrlBase64=true
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 flumebin]$ bin/flume-ng agent --classpath flume-dta-source-2.1.jar  -n dta -c conf -f dta.flume
</span><span class='line'>
</span><span class='line'># 新开一个窗口
</span><span class='line'>[hadoop@cu2 ~]$ nc localhost 6666
</span></code></pre></td></tr></table></div></figure>


<p>kafka的主题、ES的索引可以不要手动建，当然为了更好的控制ES索引创建可以添加一个索引名的template。</p>

<p>InfoSecurityLogIndexRequestBuilderFactory 实现 ElasticSearchIndexRequestBuilderFactory 把原始记录转换成 ES 的JSON对象。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  private Counter allRecordMetric = MetricManager.getInstance().counter("all_infosecurity");
</span><span class='line'>  private Counter errorRecordMetric = MetricManager.getInstance().counter("error_infosecurity");
</span><span class='line'>  
</span><span class='line'>  public IndexRequestBuilder createIndexRequest(Client client, String indexPrefix, String indexType, Event event)
</span><span class='line'>      throws IOException {
</span><span class='line'>    allRecordMetric.inc();
</span><span class='line'>
</span><span class='line'>    String record = new String(event.getBody(), outputCharset);
</span><span class='line'>
</span><span class='line'>    context.put(ElasticSearchSinkConstants.INDEX_NAME, indexPrefix);
</span><span class='line'>    indexNameBuilder.configure(context);
</span><span class='line'>    IndexRequestBuilder indexRequestBuilder = client.prepareIndex(indexNameBuilder.getIndexName(event), indexType);
</span><span class='line'>
</span><span class='line'>    try {
</span><span class='line'>      Gson gson = new Gson();
</span><span class='line'>      IdcIspLog log = parseRecord(record);
</span><span class='line'>      BytesArray data = new BytesArray(gson.toJson(log));
</span><span class='line'>
</span><span class='line'>      indexRequestBuilder.setSource(data);
</span><span class='line'>      indexRequestBuilder.setRouting(log.commandld);
</span><span class='line'>    } catch (Exception e) {
</span><span class='line'>      LOG.error(e.getMessage(), e);
</span><span class='line'>      errorRecordMetric.inc();
</span><span class='line'>
</span><span class='line'>      indexRequestBuilder.setSource(record.getBytes(outputCharset));
</span><span class='line'>      // 保留错误的数据
</span><span class='line'>      indexRequestBuilder.setRouting("error");
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    return indexRequestBuilder;
</span><span class='line'>  }</span></code></pre></td></tr></table></div></figure>


<h2>实战2</h2>

<p>测试自定义的Source：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dta.sources=s1
</span><span class='line'>dta.channels=c1
</span><span class='line'>dta.sinks=k1
</span><span class='line'>
</span><span class='line'>dta.channels.c1.type=memory
</span><span class='line'>dta.channels.c1.capacity=1000000
</span><span class='line'>dta.channels.c1.transactionCapacity=1000000
</span><span class='line'>dta.channels.c1.byteCapacity=7000000000
</span><span class='line'>
</span><span class='line'>dta.sources.s1.channels=c1
</span><span class='line'>dta.sources.s1.type=com.eshore.zhfx.collector.CollectSource
</span><span class='line'>dta.sources.s1.spoolDir=/home/hadoop/flume/data/
</span><span class='line'>dta.sources.s1.trackerDir=/tmp/dtaspool
</span><span class='line'>
</span><span class='line'>dta.sinks.k1.channel=c1
</span><span class='line'>dta.sinks.k1.type=logger</span></code></pre></td></tr></table></div></figure>


<p>CollectSource 实现PollableSource 继承AbstractSource类。参考Flume开发文档: <a href="http://flume.apache.org/FlumeDeveloperGuide.html#source">http://flume.apache.org/FlumeDeveloperGuide.html#source</a>  <code>org.apache.flume.source.SequenceGeneratorSource</code> 类。</p>

<p>方法process主逻辑代码如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public Status process() throws EventDeliveryException {
</span><span class='line'>    Status status = Status.READY;
</span><span class='line'>
</span><span class='line'>    try {
</span><span class='line'>      List&lt;Event&gt; events = readEvent(batchSize);
</span><span class='line'>      if (!events.isEmpty()) {
</span><span class='line'>        sourceCounter.addToEventReceivedCount(events.size());
</span><span class='line'>        sourceCounter.incrementAppendBatchReceivedCount();
</span><span class='line'>
</span><span class='line'>        getChannelProcessor().processEventBatch(events);
</span><span class='line'>        // 记录文件已经处理的位置
</span><span class='line'>        commit();
</span><span class='line'>
</span><span class='line'>        sourceCounter.addToEventAcceptedCount(events.size());
</span><span class='line'>        sourceCounter.incrementAppendBatchAcceptedCount();
</span><span class='line'>      }
</span><span class='line'>    } catch (ChannelException | IOException e) {
</span><span class='line'>      status = Status.BACKOFF;
</span><span class='line'>      Throwables.propagate(e);
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    return status;
</span><span class='line'>  }</span></code></pre></td></tr></table></div></figure>


<h2>实例：Flume+Kafka+ES</h2>

<p>把两个实例整合起来，把实例1的Source替换下即可。</p>

<h2>附-kafka基本操作</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-server-start.sh config/server1.properties 
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 kafka_2.11-0.9.0.1]$ cat config/server1.properties 
</span><span class='line'>listeners=PLAINTEXT://:9093
</span><span class='line'>log.dirs=/tmp/kafka-logs1
</span><span class='line'>num.partitions=1
</span><span class='line'>zookeeper.connect=cu3,cu4,cu5/kafka_0_9
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-topics.sh --create --zookeeper cu3:2181/kafka_0_9 --replication 1 --partitions 1 --topic flume
</span><span class='line'>Created topic "flume".
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-topics.sh --list --zookeeper cu3:2181/kafka_0_9
</span><span class='line'>flume
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-console-producer.sh --broker-list cu5:9093 --topic flume
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-console-consumer.sh --zookeeper cu3:2181/kafka_0_9 --topic flume --from-beginning
</span></code></pre></td></tr></table></div></figure>


<h2>附-Flume操作</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>https://flume.apache.org/FlumeUserGuide.html#fan-out-flow
</span><span class='line'>
</span><span class='line'>export FLUME_JAVA_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8092"
</span><span class='line'>bin/flume-ng agent --classpath "flume-dta-libs/*" -Dflume.root.logger=DEBUG,console  -n dta -c conf -f accesslog.flume
</span><span class='line'>
</span><span class='line'># with ganglia
</span><span class='line'>[ud@cu-ud1 apache-flume-1.6.0-bin]$ bin/flume-ng agent --classpath "/home/ud/collector/common-lib/*"  -Dflume.root.logger=Debug,console -Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=239.2.11.71:8649 -n dta -c conf -f accesslog.flume 
</span><span class='line'>
</span><span class='line'># windows
</span><span class='line'>bin\flume-ng.cmd agent -n agent -c conf -f helloworld.flume -property "flume.root.logger=INFO,console"</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Puppet安装配置Ganglia]]></title>
    <link href="http://winseliu.com/blog/2016/06/17/ganglia-install-on-centos-with-puppet/"/>
    <updated>2016-06-17T09:30:50+08:00</updated>
    <id>http://winseliu.com/blog/2016/06/17/ganglia-install-on-centos-with-puppet</id>
    <content type="html"><![CDATA[<p>前面写过完全纯手工和用yum安装依赖来安装ganglia的文章，最近生产安装了puppet，既然已经手上已有牛刀，杀鸡就不用再取菜刀了。今天记录下前几天使用puppet安装ganglia的经历。</p>

<h2>前提（自己操作过熟悉怎么用）</h2>

<ul>
<li>配置过私有仓库 (createrepo)</li>
<li>安装好puppet</li>
<li>编译过自己的rpm (rpmbuild)</li>
</ul>


<h2>编译gmetad，gmond，gweb</h2>

<p>点击链接下载SPEC：</p>

<ul>
<li><a href="http://winseliu.com/files/ganglia-puppet/gmetad.spec">gmetad.spec</a></li>
<li><a href="http://winseliu.com/files/ganglia-puppet/gmond.spec">gmond.spec</a></li>
<li><a href="http://winseliu.com/files/ganglia-puppet/gweb.spec">gweb.spec</a></li>
</ul>


<p>然后编译打包：</p>

<p>先手动编译安装 ganglia ，把依赖的问题处理好。编译安装没问题，然后再使用 rpmbuild 编译生成 rpm 包！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 1&gt; 建立目录结构
</span><span class='line'>mkdir ganglia-build
</span><span class='line'>cd ganglia-build
</span><span class='line'>mkdir BUILD RPMS SOURCES SPECS SRPMS
</span><span class='line'>
</span><span class='line'># 2&gt; 修改配置
</span><span class='line'># ganglia-web-3.7.1.tar.gz的makefile、conf_default.php.in修改下，根据等下要配置gmetad的参数进行修改
</span><span class='line'>
</span><span class='line'>less ganglia-web-3.7.1/Makefile 
</span><span class='line'>  # Location where gweb should be installed to (excluding conf, dwoo dirs).
</span><span class='line'>  GDESTDIR = /var/www/html/ganglia
</span><span class='line'>
</span><span class='line'>  # Location where default apache configuration should be installed to.
</span><span class='line'>  GCONFDIR = /usr/local/ganglia/etc/
</span><span class='line'>
</span><span class='line'>  # Gweb statedir (where conf dir and Dwoo templates dir are stored)
</span><span class='line'>  GWEB_STATEDIR = /var/www/html/ganglia
</span><span class='line'>
</span><span class='line'>  # Gmetad rootdir (parent location of rrd folder)
</span><span class='line'>  GMETAD_ROOTDIR = /data/ganglia
</span><span class='line'>
</span><span class='line'>  APACHE_USER = apache
</span><span class='line'>
</span><span class='line'># 连外网太慢，下载放到本地
</span><span class='line'>less ganglia-web-3.7.1/conf_default.php.in 
</span><span class='line'>  #$conf['cubism_js_path'] = "js/cubism.v1.min.js";
</span><span class='line'>  $conf['jquery_js_path'] = "js/jquery.min.js";
</span><span class='line'>  $conf['jquerymobile_js_path'] = "js/jquery.mobile.min.js";
</span><span class='line'>  $conf['jqueryui_js_path'] = "js/jquery-ui.min.js";
</span><span class='line'>  $conf['rickshaw_js_path'] = "js/rickshaw.min.js";
</span><span class='line'>  $conf['cubism_js_path'] = "js/cubism.v1.min.js";
</span><span class='line'>  $conf['d3_js_path'] = "js/d3.min.js";
</span><span class='line'>  $conf['protovis_js_path'] = "js/protovis.min.js";
</span><span class='line'>
</span><span class='line'># 3&gt; 源文件
</span><span class='line'># 把文件放到SOURCES目录下，
</span><span class='line'>ls SOURCES/
</span><span class='line'>  ganglia-3.7.2.tar.gz  ganglia-web-3.7.1.tar.gz
</span><span class='line'>
</span><span class='line'># 4&gt; 编译生成RPM
</span><span class='line'>rpmbuild -v -ba SPECS/gmetad.spec 
</span><span class='line'>rpmbuild -v -ba SPECS/gmond.spec 
</span><span class='line'>rpmbuild -v -ba SPECS/gweb.spec 
</span><span class='line'>
</span><span class='line'># 5&gt; 查看内容
</span><span class='line'>rpm -qpl RPMS/x86_64/ganglia-3.7.2-1.el6.x86_64.rpm </span></code></pre></td></tr></table></div></figure>


<h2>本地仓库</h2>

<p>这里假设已经把系统光盘做成了本地仓库。</p>

<p><strong>先安装httpd、php、createrepo</strong>，然后按照下面的步骤创建本地仓库：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 系统带的可以从光盘拷贝，直接映射到httpd的目录下即可
</span><span class='line'>[hadoop@hadoop-master1 rhel6.3]$ ls 
</span><span class='line'>Packages  repodata
</span><span class='line'>[hadoop@hadoop-master1 html]$ pwd
</span><span class='line'>/var/www/html
</span><span class='line'>[hadoop@hadoop-master1 html]$ ll
</span><span class='line'>lrwxrwxrwx.  1 root root   20 2月  15 2014 rhel6.3 -&gt; /opt/rhel6.3
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mkdir -p /opt/dta/repo
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd /opt/dta/repo
</span><span class='line'>[hadoop@hadoop-master1 repo]$ ls *.rpm
</span><span class='line'>gmetad-3.7.2-1.el6.x86_64.rpm  gmond-3.7.2-1.el6.x86_64.rpm  gweb-3.7.1-1.el6.x86_64.rpm  libconfuse-2.7-4.el6.x86_64.rpm
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 repo]$ sudo createrepo .
</span><span class='line'>3/3 - libconfuse-2.7-4.el6.x86_64.rpm                                           
</span><span class='line'>Saving Primary metadata
</span><span class='line'>Saving file lists metadata
</span><span class='line'>Saving other metadata
</span><span class='line'>
</span><span class='line'># 映射到httpd目录下
</span><span class='line'>[hadoop@hadoop-master1 yum.repos.d]$ cd /var/www/html/
</span><span class='line'>[hadoop@hadoop-master1 html]$ sudo ln -s /opt/dta/repo dta
</span><span class='line'>
</span><span class='line'># 加入本地仓库源
</span><span class='line'>[hadoop@hadoop-master1 yum.repos.d]$ sudo cp puppet.repo dta.repo
</span><span class='line'>[hadoop@hadoop-master1 yum.repos.d]$ sudo vi dta.repo 
</span><span class='line'>[dta]
</span><span class='line'>name=DTA Local
</span><span class='line'>baseurl=http://hadoop-master1:801/dta
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span></code></pre></td></tr></table></div></figure>


<p>注意： 在安装的时刻找不到gmond，可以先清理yum的缓冲： <code>yum clean all</code></p>

<h2>puppet模块</h2>

<p>添加了三个模块，用于主机添加repo配置和sudo配置，以及安装配置gmond。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 modules]# tree $PWD
</span><span class='line'>/etc/puppetlabs/code/environments/production/modules
</span><span class='line'>├── dtarepo
</span><span class='line'>│   ├── manifests
</span><span class='line'>│   │   └── init.pp
</span><span class='line'>│   └── templates
</span><span class='line'>│       └── dta.repo
</span><span class='line'>├── gmond
</span><span class='line'>│   ├── manifests
</span><span class='line'>│   │   └── init.pp
</span><span class='line'>│   └── templates
</span><span class='line'>│       └── gmond.conf
</span><span class='line'>└── sudo
</span><span class='line'>    ├── manifests
</span><span class='line'>    │   └── init.pp
</span><span class='line'>    └── templates
</span><span class='line'>        └── sudo.erb</span></code></pre></td></tr></table></div></figure>


<p>都比较简单，通过init.pp来进行配置，然后加载模板，写入到同步主机本地文件中。</p>

<ul>
<li>dtarepo</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./dtarepo/manifests/init.pp
</span><span class='line'>class dtarepo {
</span><span class='line'>
</span><span class='line'>file{'/etc/yum.repos.d/dta.repo':
</span><span class='line'>  ensure =&gt; file,
</span><span class='line'>  content =&gt; template('dtarepo/dta.repo'),
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>./dtarepo/templates/dta.repo
</span><span class='line'>[dta]
</span><span class='line'>name=DTA Local
</span><span class='line'>baseurl=http://hadoop-master1:801/dta
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0</span></code></pre></td></tr></table></div></figure>


<ul>
<li>sudo</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./sudo/manifests/init.pp
</span><span class='line'>class sudo {
</span><span class='line'>
</span><span class='line'>if ( $::hostname =~ /(^cu-omc)/ ) {
</span><span class='line'>  $user = 'omc'
</span><span class='line'>} elsif ( $::hostname =~ /(^cu-uc)/ ) {
</span><span class='line'>  $user = 'uc'
</span><span class='line'>} elsif ( $::hostname =~ /(^cu-ud)/ ) {
</span><span class='line'>  $user = 'ud'
</span><span class='line'>} elsif ( $::hostname =~ /(^cu-db)/ ) {
</span><span class='line'>  $user = 'mysql'
</span><span class='line'>} else {
</span><span class='line'>  $user = 'hadoop'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>file { "/etc/sudoers.d/10_$user":
</span><span class='line'>  ensure =&gt; file,
</span><span class='line'>  mode =&gt; '0440', 
</span><span class='line'>  content =&gt; template('sudo/sudo.erb'),
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>./sudo/templates/sudo.erb
</span><span class='line'>&lt;%= scope.lookupvar('sudo::user') %&gt; ALL=(ALL) NOPASSWD: ALL</span></code></pre></td></tr></table></div></figure>


<ul>
<li>gmond</li>
</ul>


<p>在默认的gmond.conf基础上修改一下两个配置: globals.deaf, cluster.name</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./gmond/manifests/init.pp
</span><span class='line'>class gmond {
</span><span class='line'>
</span><span class='line'>$deaf = $::hostname ? {
</span><span class='line'>  'hadoop-master1' =&gt; 'no',
</span><span class='line'>  'cu-omc1' =&gt; 'no',
</span><span class='line'>  default =&gt; 'yes',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>if ( $::hostname =~ /(^cu-)/ ) {
</span><span class='line'>  $cluster_name = 'CU'
</span><span class='line'>} else {
</span><span class='line'>  $cluster_name = 'HADOOP'
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>package { 'gmond':
</span><span class='line'>  ensure =&gt; present,
</span><span class='line'>  before =&gt; File['/usr/local/ganglia/etc/gmond.conf'],
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>file { '/usr/local/ganglia/etc/gmond.conf':
</span><span class='line'>  ensure =&gt; file,
</span><span class='line'>  content =&gt; template('gmond/gmond.conf'),
</span><span class='line'>  notify =&gt; Service['gmond'],
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>service { 'gmond':
</span><span class='line'>  ensure    =&gt; running,
</span><span class='line'>  enable    =&gt; true,
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>./gmond/templates/gmond.conf
</span><span class='line'>/* This configuration is as close to 2.5.x default behavior as possible
</span><span class='line'>   The values closely match ./gmond/metric.h definitions in 2.5.x */
</span><span class='line'>globals {
</span><span class='line'>...
</span><span class='line'>  mute = no
</span><span class='line'>  deaf = &lt;%= scope.lookupvar('gmond::deaf') %&gt;
</span><span class='line'>  allow_extra_data = yes
</span><span class='line'>...
</span><span class='line'>cluster {
</span><span class='line'>  name = "&lt;%= scope.lookupvar('gmond::cluster_name') %&gt;"</span></code></pre></td></tr></table></div></figure>


<p>参考下逻辑即可（也可以通过hiera配置）。</p>

<p>最后在 site.pp 引用加载编写的Module：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 modules]# cd ../manifests/
</span><span class='line'>[root@hadoop-master1 manifests]# cat site.pp 
</span><span class='line'>file{'/etc/puppetlabs/mcollective/facts.yaml':
</span><span class='line'>  owner    =&gt; root,
</span><span class='line'>  group    =&gt; root,
</span><span class='line'>  mode     =&gt; '400',
</span><span class='line'>  loglevel =&gt; debug, # reduce noise in Puppet reports
</span><span class='line'>  content  =&gt; inline_template("&lt;%= scope.to_hash.reject { |k,v| k.to_s =~ /(uptime_seconds|timestamp|free)/ }.to_yaml %&gt;"), # exclude rapidly changing facts
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>include dtarepo
</span><span class='line'>include gmond
</span><span class='line'>
</span><span class='line'># include sudo
</span></code></pre></td></tr></table></div></figure>


<h2>一键安装</h2>

<p>安装gmetad：</p>

<p>首先在主机上安装gmetad，由于只需要在一台机器安装，配置没有整成模板，这里直接手动弄。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 dtarepo]# mco rpc package install package=gmetad -I cu-omc1
</span><span class='line'>
</span><span class='line'># 注意：主机多网卡时可能需要添加route
</span><span class='line'>[root@cu-omc1 ~]# route add -host 239.2.11.71 dev bond0
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 ~]# /etc/ganglia/gmetad.conf 注意!! 这里的rrd_rootdir配置与上面gweb/makefile是对应的！！
</span><span class='line'>data_source "HADOOP" hadoop-master1
</span><span class='line'>data_source "CU" cu-omc1
</span><span class='line'>gridname "CQCU"
</span><span class='line'>rrd_rootdir "/data/ganglia/rrds"
</span></code></pre></td></tr></table></div></figure>


<p>安装gmond：</p>

<p>在cu-omc2上安装gmond（正则表达式，想怎么匹配就怎么写）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 production]# mco shell -I /^cu-omc2/ run -- "/opt/puppetlabs/bin/puppet agent -t"</span></code></pre></td></tr></table></div></figure>


<p>puppet同步好后，就安装好puppet，以及启动gmond服务。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch Startguide]]></title>
    <link href="http://winseliu.com/blog/2016/06/15/elasticsearch-startguide/"/>
    <updated>2016-06-15T08:40:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/06/15/elasticsearch-startguide</id>
    <content type="html"><![CDATA[<p>如果有Lucene的使用经历，elasticsearch的入门还是比较简单的。直接解压启动命令就安装好了，然后就是添加一些plugins就OK了。</p>

<h2>安装</h2>

<p>从官网下载 <a href="https://www.elastic.co/downloads/elasticsearch">TAR包</a> ，解压后，运行 elasticsearch 脚本启动服务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># -d 表示 daemonize 后台运行
</span><span class='line'>[hadoop@cu2 elasticsearch-2.2.0]$ bin/elasticsearch -d</span></code></pre></td></tr></table></div></figure>


<h2>插件</h2>

<p>大部分插件都是ajax方式的静态页面，可以通过plugin脚本安装，或者直接解压文件到plugins目录下面。</p>

<p>安装已经下载到本地的插件需要加file协议，不然程序会从官网下载。或者直接解压到plugins目录下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 elasticsearch-2.2.0]$ bin/plugin install file:///home/hadoop/elasticsearch-head-master.zip 
</span><span class='line'>-&gt; Installing from file:/home/hadoop/elasticsearch-head-master.zip...
</span><span class='line'>Trying file:/home/hadoop/elasticsearch-head-master.zip ...
</span><span class='line'>Downloading .........DONE
</span><span class='line'>Verifying file:/home/hadoop/elasticsearch-head-master.zip checksums if available ...
</span><span class='line'>NOTE: Unable to verify checksum for downloaded plugin (unable to find .sha1 or .md5 file to verify)
</span><span class='line'>Installed head into /home/hadoop/elasticsearch-2.2.0/plugins/head
</span></code></pre></td></tr></table></div></figure>


<p>windows</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\elasticsearch-2.3.3\bin&gt;plugin.bat install file:///D:/SOFTWARE/elasticsearch/elasticsearch-plugin/elasticsearch-head-master.zip</span></code></pre></td></tr></table></div></figure>


<p>安装好plugin后，打开浏览器查看索引情况： <a href="http://localhost:9200/_plugin/head/">http://localhost:9200/_plugin/head/</a></p>

<h2>插件高阶</h2>

<p>有些插件版本比较旧需要改一改，需要了解新版本的 elasticsearch-plugin 的规范：</p>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/plugins/2.3/installation.html">https://www.elastic.co/guide/en/elasticsearch/plugins/2.3/installation.html</a></p>

<p>新版本插件主要是需要增加一个描述文件：</p>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.3/breaking_20_plugin_and_packaging_changes.html#_plugins_require_descriptor_file">Plugins require descriptor file</a></p>

<p>遇到想安装的旧版本的plugin，描述文件写法可以参考 <a href="https://github.com/mobz/elasticsearch-head">elasticsearch-head</a> 。</p>

<p>可选插件：</p>

<ul>
<li>paramedic <a href="https://github.com/karmi/elasticsearch-paramedic">https://github.com/karmi/elasticsearch-paramedic</a></li>
<li>head <a href="https://github.com/mobz/elasticsearch-head">https://github.com/mobz/elasticsearch-head</a></li>
<li>kopf <a href="https://github.com/lmenezes/elasticsearch-kopf">https://github.com/lmenezes/elasticsearch-kopf</a></li>
</ul>


<h2>常用URL请求</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html
</span><span class='line'># 创建
</span><span class='line'>$ curl -XPUT 'http://localhost:9200/t_ods_idc_isp_log2/' -d '{
</span><span class='line'>    "settings" : {
</span><span class='line'>        "index" : {
</span><span class='line'>            "number_of_shards" : 3,
</span><span class='line'>            "number_of_replicas" : 0
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>}'
</span><span class='line'>{"acknowledged":true}
</span><span class='line'>
</span><span class='line'># https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-put-mapping.html
</span><span class='line'># 更新
</span><span class='line'># mapping.json
</span><span class='line'>{
</span><span class='line'>  "properties": {
</span><span class='line'>      "author": {
</span><span class='line'>          "type": "string"
</span><span class='line'>      },
</span><span class='line'>...
</span><span class='line'>      "year": {
</span><span class='line'>          "type": "long",
</span><span class='line'>          "ignore_malformed": false,
</span><span class='line'>          "index": "analyzed"
</span><span class='line'>      },
</span><span class='line'>      "avaiable": {
</span><span class='line'>          "type": "boolean"
</span><span class='line'>      }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>$ curl -XPUT 'localhost:9200/t_ods_idc_isp_log2/_mapping/default' -d @mapping.json
</span><span class='line'>
</span><span class='line'>$ curl -XPUT 'localhost:9200/t_ods_idc_isp_log2/_mapping/default' -d '
</span><span class='line'>{
</span><span class='line'>  "properties": {
</span><span class='line'>    "fDIID": {
</span><span class='line'>      "type": "string"
</span><span class='line'>    },
</span><span class='line'>...
</span><span class='line'>    "gatherTime": {
</span><span class='line'>      "type": "long"
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>'
</span><span class='line'>
</span><span class='line'># https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html
</span><span class='line'># 索引
</span><span class='line'># documents.json
</span><span class='line'>{ "index": {      "_index": "library",        "_type": "book",        "_id": "1"  } }
</span><span class='line'>{     "title": "All Quiet on the Western Front",  "otitle": "Im Westen nichts Neues",     "author": "Erich Maria Remarque",   "year": 1929,   "characters": ["Paul Baumer",   "Albert Kropp",     "Haie Westhus",     "Fredrich Muller",  "Stanislaus Katczinsky",    "Tjaden"],  "tags": ["novel"],  "copies": 1,    "available": true,  "section": 3 }
</span><span class='line'>{     "index": {      "_index": "library",        "_type": "book",        "_id": "2"  } }
</span><span class='line'>{     "title": "Catch-22",    "author": "Joseph Heller",  "year": 1961,   "characters": ["John Yossarian",    "Captain Aardvark",     "Chaplain Tappman",     "Colonel Cathcart",     "Doctor Daneeka"],  "tags": ["novel"],  "copies": 6,    "available": false,     "section": 1 }
</span><span class='line'>
</span><span class='line'>$ curl -s -XPOST localhost:9200/_bulk --data-binary @documents.json
</span><span class='line'>
</span><span class='line'># 删除
</span><span class='line'>$ curl -XDELETE 'http://localhost:9200/t_ods_idc_isp_log2/'
</span><span class='line'>{"acknowledged":true}
</span><span class='line'>
</span><span class='line'># https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-get-mapping.html
</span><span class='line'># https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-get-field-mapping.html
</span><span class='line'># 状态查看
</span><span class='line'>http://localhost:9200/_cat/health?v
</span><span class='line'>http://localhost:9200/_cat/nodes?v
</span><span class='line'>http://localhost:9200/_cat/indices?v
</span><span class='line'>
</span><span class='line'>curl -XGET 'http://localhost:9200/_all/_mapping/book/field/author'
</span><span class='line'>curl -XHEAD -i 'http://localhost:9200/twitter/tweet'
</span><span class='line'>curl localhost:9200/_stats
</span><span class='line'>curl -XGET 'http://localhost:9200/_all/_mapping/[type]'
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[读读书]Apache Spark源码剖析-Shell]]></title>
    <link href="http://winseliu.com/blog/2016/05/08/rrc-apache-spark-source-inside-shell/"/>
    <updated>2016-05-08T21:41:01+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/08/rrc-apache-spark-source-inside-shell</id>
    <content type="html"><![CDATA[<p>本来第二篇应该是与 [第1章 初识Spark] 有关，但我们运行helloworld、以及提交任务都是通过脚本 <code>bin/spark-shell</code> ，完全不知道那些脚本是干啥的？而且，在开发环境运行shell来启动应用总觉得怪怪的，这篇先来简单了解脚本的功能、以及Launcher模块。</p>

<p><strong> 其实每个大数据的框架，shell脚本都是通用入口，也是研读源码的第一个突破口 </strong>。掌握脚本功能相当于熟悉了基本的API功能，把 spark/bin 目录下面的脚本理清楚，然后再去写搭建开发环境、编写调试helloworld就事半功倍了。</p>

<p>官网 <strong> Quick Start </strong> 提供的简短例子都是通过 bin/spark-shell 来运行的。Submit页面提供了 bin/spark-submit 提交jar发布任务的方式。 spark-shell，spark-submit 就是两个非常重要的脚本，这里就来看下这两个脚本。</p>

<h2>spark-shell - 对应[3.1 spark-shell]章节</h2>

<p>spark-shell 脚本的内容相对多一些，主要代码如下（其他代码都是为了兼容cygwin弄的，我们这里不关注）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SPARK_SUBMIT_OPTS="$SPARK_SUBMIT_OPTS -Dscala.usejavacp=true"
</span><span class='line'>trap onExit INT     # 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl + C)时触发
</span><span class='line'>
</span><span class='line'>export SPARK_SUBMIT_OPTS
</span><span class='line'>"${SPARK_HOME}"/bin/spark-submit --class org.apache.spark.repl.Main --name "Spark shell" "$@"</span></code></pre></td></tr></table></div></figure>


<p>最终调用 bin/spark-submit 脚本。其实和我们自己提交 helloworld.jar 命令一样：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ bin/spark-submit \
</span><span class='line'>  --class "HelloWorld" \
</span><span class='line'>  --master local[2] \
</span><span class='line'>  target/scala-2.10/helloworld_2.10-1.0.jar</span></code></pre></td></tr></table></div></figure>


<p>不过通过 bin/spark-shell 提交运行的类是spark自带，没有附加（不需要）额外的jar。这个后面再讲，我们也可以通过这种方式类运行公共位置的jar，可以减少一些不必要的网络带宽。</p>

<h2>spark-submit</h2>

<p>submit脚本更简单。就是把 <strong>org.apache.spark.deploy.SparkSubmit</strong> 和 <strong>输入参数</strong> 全部传递给脚本 bin/spark-class 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>exec "${SPARK_HOME}"/bin/spark-class org.apache.spark.deploy.SparkSubmit "$@"</span></code></pre></td></tr></table></div></figure>


<h2>spark-class</h2>

<p>主要的功能都集中在 bin/spark-class。bin/spark-class脚本最终启动java、调用 <strong>Launcher模块(org.apache.spark.launcher.Main)</strong> 。而 <strong>Launcher模块</strong> 解析输入参数并输出 <strong>最终执行的命令</strong>，然后shell再通过 <strong>exec</strong> 来运行Driver程序。</p>

<p>要讲清楚 bin/spark-class 相对复杂点：通过脚本传递参数，调用java处理参数，又输出脚本，最后运行脚本才真正运行了Driver。所以这里通过 <strong>脚本</strong> 和 <strong>程序</strong> 来进行说明。</p>

<h4>脚本</h4>

<ul>
<li>先加载环境变量配置文件</li>
<li>再获取 assembly.jar 位置</li>
<li>然后调用 <code>org.apache.spark.launcher.Main</code> ， Main类根据环境变量和传入参数算出真正执行的命令(具体在【程序】部分讲)。</li>
</ul>


<p>下面是核心脚本的内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>. "${SPARK_HOME}"/bin/load-spark-env.sh 
</span><span class='line'>  # 把load-spark-env.sh展开
</span><span class='line'>  . "${user_conf_dir}/spark-env.sh"
</span><span class='line'>  
</span><span class='line'>  ASSEMBLY_DIR1="${SPARK_HOME}/assembly/target/scala-2.10"  # 通过ASSEMBLY路径来判断SPARK_SCALA_VERSION，编译打包成tar的不需要这个变量
</span><span class='line'>  export SPARK_SCALA_VERSION="2.10"
</span><span class='line'>
</span><span class='line'>RUNNER="${JAVA_HOME}/bin/java"
</span><span class='line'>
</span><span class='line'>SPARK_ASSEMBLY_JAR=
</span><span class='line'>if [ -f "${SPARK_HOME}/RELEASE" ]; then
</span><span class='line'>  ASSEMBLY_DIR="${SPARK_HOME}/lib"
</span><span class='line'>else
</span><span class='line'>  ASSEMBLY_DIR="${SPARK_HOME}/assembly/target/scala-$SPARK_SCALA_VERSION"
</span><span class='line'>fi
</span><span class='line'>ASSEMBLY_JARS="$(ls -1 "$ASSEMBLY_DIR" | grep "^spark-assembly.*hadoop.*\.jar$" || true)"
</span><span class='line'>SPARK_ASSEMBLY_JAR="${ASSEMBLY_DIR}/${ASSEMBLY_JARS}"
</span><span class='line'>LAUNCH_CLASSPATH="$SPARK_ASSEMBLY_JAR"
</span><span class='line'>
</span><span class='line'>export _SPARK_ASSEMBLY="$SPARK_ASSEMBLY_JAR"
</span><span class='line'>
</span><span class='line'>CMD=()
</span><span class='line'>while IFS= read -d '' -r ARG; do
</span><span class='line'>  CMD+=("$ARG")
</span><span class='line'>done &lt; &lt;("$RUNNER" -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@")
</span><span class='line'>exec "${CMD[@]}"</span></code></pre></td></tr></table></div></figure>


<p>大部分内容都是准备环境，就最后几行代码比较复杂。这里设置DEBUG在脚本 <code>while</code> 循环打印每个输出的值看下输出的是什么。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 修改后的效果
</span><span class='line'>CMD=()
</span><span class='line'>while IFS= read -d '' -r ARG; do
</span><span class='line'>  echo "[DEBUG] $ARG"
</span><span class='line'>  CMD+=("$ARG")
</span><span class='line'>done &lt; &lt;(set -x; "$RUNNER" -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@")
</span><span class='line'>echo "${CMD[@]}"
</span><span class='line'>exec "${CMD[@]}"</span></code></pre></td></tr></table></div></figure>


<p>启动 bin/spark-shell（最终会调用 bin/spark-class，上面已经讲过脚本之间的关系），查看输出的调试信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 spark-1.6.0-bin-2.6.3]$ bin/spark-shell 
</span><span class='line'>++ /opt/jdk1.8.0/bin/java -cp /home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar org.apache.spark.launcher.Main org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name 'Spark shell'
</span><span class='line'>[DEBUG] /opt/jdk1.8.0/bin/java
</span><span class='line'>[DEBUG] -cp
</span><span class='line'>[DEBUG] /home/hadoop/spark/lib/mysql-connector-java-5.1.34.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/conf/:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-rdbms-3.2.9.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-core-3.2.10.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/hadoop/etc/hadoop/
</span><span class='line'>[DEBUG] -Dscala.usejavacp=true
</span><span class='line'>[DEBUG] -Xms512m
</span><span class='line'>[DEBUG] -Xmx512m
</span><span class='line'>[DEBUG] org.apache.spark.deploy.SparkSubmit
</span><span class='line'>[DEBUG] --class
</span><span class='line'>[DEBUG] org.apache.spark.repl.Main
</span><span class='line'>[DEBUG] --name
</span><span class='line'>[DEBUG] Spark shell
</span><span class='line'>[DEBUG] spark-shell
</span><span class='line'>/opt/jdk1.8.0/bin/java -cp /home/hadoop/spark/lib/mysql-connector-java-5.1.34.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/conf/:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-rdbms-3.2.9.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-core-3.2.10.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/hadoop/etc/hadoop/ -Dscala.usejavacp=true -Xms512m -Xmx512m org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name 'Spark shell' spark-shell
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>从上面的调试信息可以看出：</p>

<ul>
<li><code>org.apache.spark.launcher.Main</code> 把传入参数整理后重新输出</li>
<li>脚本把java输出内容保存到 <code>CMD[@]</code> 数组中</li>
<li>最后使用exec来执行。</li>
</ul>


<p>根据上面 bin/spark-class 产生的启动命令可以直接在idea里面运行，效果与直接运行 bin/spark-shell 一样：</p>

<p><img src="http://winseliu.com/images/blogs/rcc-spark/idea-spark-shell.png" alt="" /></p>

<h4>Launcher模块</h4>

<p>如果shell和launcher的代码你都看了的话，会发现 shell 和 java代码 功能逻辑非常类似。比如说获取java程序路径的代码：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>List&lt;String&gt; buildJavaCommand(String extraClassPath) throws IOException {
</span><span class='line'>  ...
</span><span class='line'>  if (javaHome != null) {
</span><span class='line'>      cmd.add(join(File.separator, javaHome, "bin", "java"));
</span><span class='line'>  } else if ((envJavaHome = System.getenv("JAVA_HOME")) != null) {
</span><span class='line'>      cmd.add(join(File.separator, envJavaHome, "bin", "java"));
</span><span class='line'>  } else {
</span><span class='line'>      cmd.add(join(File.separator, System.getProperty("java.home"), "bin", "java"));
</span><span class='line'>  }
</span><span class='line'>  ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>在shell脚本里面的处理是：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Find the java binary
</span><span class='line'>if [ -n "${JAVA_HOME}" ]; then
</span><span class='line'>  RUNNER="${JAVA_HOME}/bin/java"
</span><span class='line'>else
</span><span class='line'>  if [ `command -v java` ]; then
</span><span class='line'>  RUNNER="java"
</span><span class='line'>  else
</span><span class='line'>  echo "JAVA_HOME is not set" &gt;&2
</span><span class='line'>  exit 1
</span><span class='line'>  fi
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<p>对比两者，其实是用脚本更加直观。但是使用java编写一个模块更便于管理和扩展，稍微调整下就能复用代码。比如说要添加windows的cmd脚本、又或者为了兼容多个操作系统/多语言(python，r 等)。所以提取一个公共的 <strong>Launcher模块</strong> 出来其实是个挺不错的选择。同时对于不是很熟悉shell的程序员来说也更方便了解系统运作。</p>

<p><strong>Launcher模块</strong> 按功能可以分为 CommandBuilder 和 SparkLauncher 两个部分。</p>

<ol>
<li><p>CommandBuilder</p></li>
<li><p>SparkSubmitCommandBuilder: 解析用户输入的参数并输出命令给脚本使用</p></li>
<li>SparkClassCommandBuilder: 主要为后台进程产生启动命令（sbin目录下面的脚本）。</li>
</ol>


<p>1.1 公共类</p>

<ul>
<li>Main ： 统一入口</li>
<li>AbstractCommandBuilder : 提供构造命令的公共基类

<ul>
<li>buildJavaCommand

<ul>
<li>buildClassPath

<ul>
<li>SPARK_CLASSPATH</li>
<li>extraClassPath</li>
<li>getConfDir : 等于环境变量 $SPARK_CONF_DIR 或者 $SPARK_HOME/conf 的值</li>
<li>classes

<ul>
<li>SPARK_PREPEND_CLASSES</li>
<li>SPARK_TESTING</li>
</ul>
</li>
<li>findAssembly : 获取 spark-assembly-1.6.0-hadoop2.6.3.jar 的路径，lib 或者 assembly/target/scala-$SPARK_SCALA_VERSION 路径下

<ul>
<li>_SPARK_ASSEMBLY</li>
</ul>
</li>
<li>datanucleus-* : 从 lib / lib_managed/jars 目录下获取</li>
<li>HADOOP_CONF_DIR</li>
<li>YARN_CONF_DIR</li>
<li>SPARK_DIST_CLASSPATH</li>
</ul>
</li>
</ul>
</li>
<li>getEffectiveConfig : 获取 spark-defaults.conf 的内容</li>
</ul>
</li>
</ul>


<p>1.2 SparkSubmitCommandBuilder</p>

<p>主要的类以及参数：</p>

<ul>
<li>SparkSubmitCommandBuilder

<ul>
<li>构造函数调用OptionParser解析参数，解析handle有处理specialClasses！</li>
<li>buildSparkSubmitCommand

<ul>
<li>getEffectiveConfig</li>
<li>extraClassPath : spark.driver.extraClassPath</li>
<li>SPARK_SUBMIT_OPTS</li>
<li>SPARK_JAVA_OPTS</li>
<li>client模式下加载配置

<ul>
<li>spark.driver.memory / SPARK_DRIVER_MEMORY / SPARK_MEM / DEFAULT_MEM(1g)</li>
<li>DRIVER_EXTRA_JAVA_OPTIONS</li>
<li>DRIVER_EXTRA_LIBRARY_PATH</li>
</ul>
</li>
<li>buildSparkSubmitArgs</li>
</ul>
</li>
</ul>
</li>
<li>SparkSubmitOptionParser(子类需要实现handle方法)</li>
<li>SparkSubmitCommandBuilder$OptionParser 命令参数

<ul>
<li><code>bin/spark-submit -h</code> 查看可以<strong>设置的参数</strong></li>
<li>直接查看<a href="http://spark.apache.org/docs/latest/submitting-applications.html">官网文档</a></li>
</ul>
</li>
</ul>


<p>1.3 SparkClassCommandBuilder</p>

<p>主要CommandBuilder的功能上面已经都覆盖了，SparkClassCommandBuilder主要关注命令行可以设置哪些环境变量：</p>

<ul>
<li>org.apache.spark.deploy.master.Master

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_MASTER_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.worker.Worker

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_WORKER_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.history.HistoryServer

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_HISTORY_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.executor.CoarseGrainedExecutorBackend

<ul>
<li>SPARK_JAVA_OPTS</li>
<li>SPARK_EXECUTOR_OPTS</li>
<li>SPARK_EXECUTOR_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.executor.MesosExecutorBackend

<ul>
<li>SPARK_EXECUTOR_OPTS</li>
<li>SPARK_EXECUTOR_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.ExternalShuffleService / org.apache.spark.deploy.mesos.MesosExternalShuffleService

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_SHUFFLE_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.tools.

<ul>
<li>extraClassPath : spark-tools_.*.jar</li>
<li>SPARK_JAVA_OPTS</li>
<li>DEFAULT_MEM(1g)</li>
</ul>
</li>
<li>other

<ul>
<li>SPARK_JAVA_OPTS</li>
<li>SPARK_DRIVER_MEMORY</li>
</ul>
</li>
</ul>


<h4>SparkLauncher</h4>

<p>SparkLauncher提供了在程序中提交任务的方式。通过Driver端的支持获取程序执行动态（通过socket与Driver交互），为实现后端管理应用提供一种可行的方式。</p>

<p>SparkLauncher提交任务其中一部分还是使用spark-submit脚本，绕一圈又回到上面的参数解析生成命令然后exec执行。另外SparkLauncher通过启动 SocketServer(LauncherServer)接收来自Driver(LauncherBackend)任务执行情况的最新状态。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-launcher.jpg" alt="" /></p>

<p>代码包括：</p>

<ul>
<li>SparkLauncher 主要是startApplication。其他都是解析设置参数，相当于把shell的工作用java重写了一遍</li>
<li>LauncherServer 服务SocketServer类</li>
<li>LauncherServer$ServerConnection 状态处理类</li>
<li>LauncherConnection 通信基类：接收、发送消息</li>
<li>LauncherProtocol 通信协议</li>
<li>ChildProcAppHandle : SparkAppHandle 接收到Driver的状态后，请求分发类</li>
</ul>


<p>具体功能的流转请下载代码 <a href="https://github.com/winse/spark-examples/blob/master/src/main/scala/com/github/winse/spark/HelloWorldLauncher.scala">HelloWorldLauncher.scala</a> ，然后本地调试一步步的追踪学习。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[读读书]Apache Spark源码剖析-序]]></title>
    <link href="http://winseliu.com/blog/2016/05/07/rrc-apache-spark-source-inside-preface/"/>
    <updated>2016-05-07T23:58:57+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/07/rrc-apache-spark-source-inside-preface</id>
    <content type="html"><![CDATA[<p><a href="http://dongxicheng.org/mapreduce-nextgen/how-to-read-hadoop-code-effectively/">如何高效的阅读hadoop源代码？</a> 先看看这篇。</p>

<p>今天去广州图书馆办了证，借了几本关于大数据的书。老实说，国家提供的便民基础设施应该发挥她的价值，国家建那么多公共设施，还有很多人在后台让这些服务运作起来。借书是一种最高性价比学习的方式，第一：不能乱写乱画必须做笔记或者背下来，把最有价值的东西汇集；第二：有时间限制，好书逼着我们持续的去读；第三：自然是读到烂书也不用花钱，有价值的书必然也是最多人看的，看到翻的很旧的新书你就借了吧。</p>

<p>其中一个《Apache Spark源码剖析-徐鹏》，大致翻了一下，老实说作者很牛逼啊，从那么多的代码里面挑出和主题相关的，不比鸡蛋里面挑石头容易，跟着作者的思路去读应该不错。打算每天读点代码，同时把看书和看代码也记录下来，每天一小结，同时希望对别人有些参考作用。</p>

<p>Spark更新的很快，书本介绍的是 spark-1.0 ，不过书中介绍的主要是思路，我们这里选择比较新的版本 1.6.0 来读（生产用的是1.6）。</p>

<p><strong> 说到思路，如果你对Redis也感兴趣，强烈推荐读读 《Redis设计与实现-黄建宏》 </strong></p>

<h2>使用环境说明</h2>

<p>和作者不同，我选择直接在windows来读/调试代码，为了读个代码还得整一套linux的开发环境挺累的（原来也试过整linux开发环境后来放弃了），Windows 积累的经验已经可以让我自由调试和看代码了。</p>

<p>吐槽下sbt，很讨厌这玩意又慢还用ivy，我X，大数据不都用 maven 嘛，难道我还得为 spark 整一套完全一样的jar本地缓冲？不过还好 spark-1.6 已经是用 maven 来管理了。</p>

<ul>
<li>win10 + cygwin</li>
<li>jdk8_x64（内存可以调到大于1G）</li>
<li>maven3</li>
<li>scala_2.10</li>
<li>spark_1.6.0</li>
<li>hive_1.2.1</li>
<li>hadoop_2.6.3</li>
<li>JetBrains idea 看代码确实不错</li>
</ul>


<h2>Spark开发环境搭建 - 对应书本的[附录A Spark源码调试]部分</h2>

<h4>配置 idea-scala</h4>

<h6>优化idea启动参数</h6>

<p>安装 <strong>最新版idea</strong> (当前最新版本是15.0.5)。在程序安装的 bin 目录下，有x64配置文件 idea64.exe.vmoptions ，在配置文件开头添加jdk8内存配置：</p>

<pre><code>-server
-Xms1g
-Xmx2g
-XX:MetaspaceSize=256m
-XX:MaxMetaspaceSize=256m
</code></pre>

<p>由于机器 eclipse 原来使用的 jdk_x86，为了兼容，单独编写 idea64.exe 的启动脚本 <strong> idea.bat </strong>：</p>

<pre><code>set JAVA_HOME=D:\Java\jdk1.8.0_40
D:
cd "D:\Program Files\JetBrains\IntelliJ IDEA Community Edition 15.0.5\bin"
start idea64.exe"

exit
</code></pre>

<p><strong> [IDEA的快键配置]：IDEA 适配 Eclipse 的快键集，通过 <code>Settings -&gt; Keymap -&gt; Keymaps</code> 配置。 </strong></p>

<h6>安装scala插件</h6>

<ol>
<li>第一种方式：当然最好就是通过plugins的搜索框就能安装，但在中国这得看运气。</li>
<li><p>第二种方式：首先下载好插件，然后选择从硬盘安装插件。</p></li>
<li><p>从网络安装</p></li>
</ol>


<p>打开 plugins 管理页面：（也可以通过 File -> Settings&hellip; -> Plugins 打开）</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-start-configure.png" alt="" /></p>

<p>弹出的 Plugins 对话框显示了当前已经安装的插件：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-plugins-list.png" alt="" /></p>

<p>在 Plugins 对话框页面选择 [<strong>Browse repositories&hellip;</strong>] 按钮，再在弹出的对话框中查找 <strong>Scala</strong> 的插件：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-browse-plugins.png" alt="" /></p>

<p>选择安装 Scala ，当然你也可以同时安装上 SBT 。</p>

<ul>
<li>从硬盘安装</li>
</ul>


<p>运气好就算可以直接从网络安装，但是下载过程其实也挺慢的。</p>

<p>我们还可以先自己下载好插件再安装（或者从其他同学获取、迅雷分分钟下完）。首先需要查看自己 idea 的版本，再在 <a href="https://plugins.jetbrains.com/?idea_ce">https://plugins.jetbrains.com/?idea_ce</a> 查找下载符合自己版本的 <a href="https://plugins.jetbrains.com/plugin/1347?pr=idea_ce">scala 插件</a>，最后通过 [<strong>Install plugin from disk&hellip;</strong>] 安装，然后重启IDEA即可。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-version.png" alt="" />
<img src="http://winseliu.com/images/blogs/rrc-spark/download-scala-plugin.png" alt="" />
<img src="http://winseliu.com/images/blogs/rrc-spark/idea-scala-from-disk.png" alt="" /></p>

<h4>下载 spark 源码，并导入idea</h4>

<ol>
<li><p>下载源码，检出 1.6.0 版本</p>

<p> $ git clone <a href="https://github.com/apache/spark.git">https://github.com/apache/spark.git</a>
 $ git checkout v1.6.0</p></li>
</ol>


<p>如果你只想看 1.6.0 的内容，可以直接在clone命令添加参数指定版本：</p>

<pre><code>$ git clone https://github.com/apache/spark.git -b v1.6.0
</code></pre>

<ol>
<li>导入idea</li>
</ol>


<p>导入之前先要生成arvo的java类(这里直接package编译一下)：</p>

<pre><code>E:\git\spark\external\flume-sink&gt;mvn package -DskipTests
</code></pre>

<p>由于我使用 hadoop-2.6.3 ，并且导入过程中不能修改环境变量，直接修改 pom.xml 里面 hadoop.version 属性的值。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-hadoop-version.png" alt="" /></p>

<p>启动IDEA，使用 [<strong>Import Project</strong>] 导入源代码; 然后选择 <code>E:/git/spark</code>（刚刚下载的源码位置）; 然后选择导入maven项目; 在 profile 页把必要的都选上（当然也可以后期通过 <code>Maven Projects</code> 面板来修改）:</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-import-profile.png" alt="" /></p>

<p>导入完成后，依赖关系maven已经处理好了，直接就能用了。也可以 Make Projects 再编译一次，并把运行application的make去掉，免得浪费编译时间）。</p>

<p><strong> 注意：mvn idea:idea 其实不咋的，生成的配置不兼容。最好不要用！！ </strong></p>

<ol>
<li>调试/测试</li>
</ol>


<p>在调试运行之前，先了解下并解决 idea maven-provided 的问题：</p>

<p>在idea里面直接运行 src/main/java 下面的类会被当做在生产环境运行，所以idea不会把这些 provided的依赖 加入到运行的classpath。</p>

<ul>
<li><a href="https://youtrack.jetbrains.com/issue/IDEA-54595">https://youtrack.jetbrains.com/issue/IDEA-54595</a></li>
<li><a href="http://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij">http://stackoverflow.com/questions/30453269/maven-provided-dependency-will-cause-noclassdeffounderror-in-intellij</a></li>
</ul>


<p><img src="http://winseliu.com/images/blogs/rrc-spark/idea-maven-provided.png" alt="" /></p>

<p>IDEA运行时是从 <code>examples/spark-examples_2.10.iml</code> 文件中读取classpath的配置，所以我们直接把 <code>spark-examples_2.10.iml</code> 的 <code>scope="PROVIDED"</code> 全部删掉即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 一次全部删掉！
</span><span class='line'>winse@Lenovo-PC ~/git/spark
</span><span class='line'>$ find . -name "*.iml"  | xargs -I{} sed -i 's/scope="PROVIDED"//' {}</span></code></pre></td></tr></table></div></figure>


<p>首先右键 [<strong>Run LogQuery</strong>] 运行（由于缺少master的配置会报错的），主要用于生成启动的 <code>LogQuery Configuration</code>：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-logquery-firststart.png" alt="" /></p>

<p>然后选择上图中下拉选项的 [<strong>Edit Configurations&hellip;</strong>] ，在弹出配置对话框为中为 <code>LogQuery</code> 添加 <strong>VM options</strong> 配置: <code>-Dspark.master=local</code> ，接下来我们就可以打断点，Debug调试了。</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-logquery-config.png" alt="" /></p>

<p>运行结果如下：</p>

<p><img src="http://winseliu.com/images/blogs/rrc-spark/spark-logquery-result.png" alt="" /></p>

<p>遇到IDEA导入maven依赖有问题的，可以参考下 <a href="http://stackoverflow.com/questions/11454822/import-maven-dependencies-in-intellij-idea">Import Maven dependencies in IntelliJ IDEA</a> 。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flamegraphs Java Cpu]]></title>
    <link href="http://winseliu.com/blog/2016/05/06/flamegraphs-java-cpu/"/>
    <updated>2016-05-06T21:35:03+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/06/flamegraphs-java-cpu</id>
    <content type="html"><![CDATA[<p>在MacTalk的公众号上读到了agentzh关于火焰图介绍(2016年5月6日07:57 动态追踪技术（中） - Dtrace、SystemTap、火焰图)，挺新奇的，并且应该对于查询热线程还是有作用的。</p>

<p>先了解perf和flamegraphs基础知识：</p>

<ul>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/">https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/</a></li>
<li><a href="http://www.brendangregg.com/perf.html#FlameGraphs">perf Examples</a></li>
<li><a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html">CPU Flame Graphs</a></li>
<li><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">Java in Flames</a></li>
<li><a href="http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html">Java CPU Flame Graphs</a></li>
<li>使用方法<a href="https://randomascii.wordpress.com/2013/03/26/summarizing-xperf-cpu-usage-with-flame-graphs/">xperf - windows perf</a></li>
<li>工具<a href="https://github.com/google/UIforETW/blob/master/bin/xperf_to_collapsedstacks.py">UIforETW</a></li>
</ul>


<p>perf好像有点类似java的btrace，不过perf是操作系统层面的。把操作系统当做服务，客户端通过perf来获取/查询系统的信息。</p>

<h2>安装</h2>

<p>perf包括在linux 2.6.31代码里面，redhat可以通过yum来安装/更新：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# yum install perf
</span><span class='line'>...
</span><span class='line'>Installed:
</span><span class='line'>  perf.x86_64 0:2.6.32-573.26.1.el6  
</span><span class='line'>  
</span><span class='line'>[root@hadoop-master2 ~]# perf stat ls /dev/shm
</span><span class='line'>
</span><span class='line'> Performance counter stats for 'ls /dev/shm':
</span><span class='line'>
</span><span class='line'>          0.697115 task-clock                #    0.613 CPUs utilized          
</span><span class='line'>                 0 context-switches          #    0.000 K/sec                  
</span><span class='line'>                 0 cpu-migrations            #    0.000 K/sec                  
</span><span class='line'>               236 page-faults               #    0.339 M/sec                  
</span><span class='line'>   &lt;not supported&gt; cycles                  
</span><span class='line'>   &lt;not supported&gt; stalled-cycles-frontend 
</span><span class='line'>   &lt;not supported&gt; stalled-cycles-backend  
</span><span class='line'>   &lt;not supported&gt; instructions            
</span><span class='line'>   &lt;not supported&gt; branches                
</span><span class='line'>   &lt;not supported&gt; branch-misses           
</span><span class='line'>
</span><span class='line'>       0.001137015 seconds time elapsed
</span></code></pre></td></tr></table></div></figure>


<p>虚拟机可能有一些event不能用，到真正的实体机上面应该是没问题的（网上有同学验证过）。可以通过 <code>perf list</code> 查看支持的event。</p>

<p>补充，实体机效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@dacs ~]# perf stat ls /dev/shm
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'> Performance counter stats for 'ls /dev/shm':
</span><span class='line'>
</span><span class='line'>          1.793297      task-clock (msec)         #    0.677 CPUs utilized          
</span><span class='line'>                 1      context-switches          #    0.558 K/sec                  
</span><span class='line'>                 0      cpu-migrations            #    0.000 K/sec                  
</span><span class='line'>               255      page-faults               #    0.142 M/sec                  
</span><span class='line'>           2765454      cycles                    #    1.542 GHz                     [44.66%]
</span><span class='line'>           1544155      stalled-cycles-frontend   #   55.84% frontend cycles idle    [64.12%]
</span><span class='line'>           1013635      stalled-cycles-backend    #   36.65% backend  cycles idle   
</span><span class='line'>           2692743      instructions              #    0.97  insns per cycle        
</span><span class='line'>                                                  #    0.57  stalled cycles per insn
</span><span class='line'>            603340      branches                  #  336.442 M/sec                  
</span><span class='line'>             12499      branch-misses             #    2.07% of all branches         [98.00%]
</span><span class='line'>
</span><span class='line'>       0.002650313 seconds time elapsed
</span></code></pre></td></tr></table></div></figure>


<p>windows的话直接下载 UIforETW ，运行 UIforETW.exe 就可以用来采样了。把采样产生的etl文件传给xperf_to_collapsedstacks.py，最后用flamegraph.pl画图。</p>

<p>perf的常用命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://www.brendangregg.com/perf.html
</span><span class='line'>perf list
</span><span class='line'>
</span><span class='line'>perf stat ./t1 
</span><span class='line'>perf stat -a -A ls
</span><span class='line'>
</span><span class='line'>perf top
</span><span class='line'> 
</span><span class='line'>perf record – e cpu-clock ./t1 
</span><span class='line'>perf report</span></code></pre></td></tr></table></div></figure>


<h2>画图</h2>

<ul>
<li><a href="http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html">http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html</a></li>
<li><a href="https://github.com/coderplay/perfj/releases">https://github.com/coderplay/perfj/releases</a></li>
<li><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">http://techblog.netflix.com/2015/07/java-in-flames.html</a></li>
</ul>


<h4>系统火焰图</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html
</span><span class='line'># https://github.com/brendangregg/FlameGraph
</span><span class='line'># 真实的机器效果还是挺不错的
</span><span class='line'>perf record -F 99 -a -g -- sleep 60
</span><span class='line'>perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
</span><span class='line'>~/FlameGraph/flamegraph.pl out.perf-folded &gt;perf.svg
</span><span class='line'>sz perf.svg
</span><span class='line'>
</span><span class='line'># --
</span><span class='line'># perf script | ./stackcollapse-perf.pl &gt; out.perf-folded
</span><span class='line'># grep -v cpu_idle out.perf-folded | ./flamegraph.pl &gt; nonidle.svg
</span><span class='line'># grep ext4 out.perf-folded | ./flamegraph.pl &gt; ext4internals.svg
</span><span class='line'># egrep 'system_call.*sys_(read|write)' out.perf-folded | ./flamegraph.pl &gt; rw.svg
</span></code></pre></td></tr></table></div></figure>


<p>安装的虚拟机中操作没采集到有用的。虚拟机和真实机器两个图：</p>

<p><img src="http://winseliu.com/images/blogs/flames/flames-real.png" alt="" /></p>

<p><img src="http://winseliu.com/images/blogs/flames/flames-vm.png" alt="" /></p>

<h4>java</h4>

<p>首先需要jdk8_u60+，直接下载最新的jdk就好了。应用启动带上参数 -XX:+PreserveFramePointer ：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# java -version
</span><span class='line'>java version "1.8.0_92"
</span><span class='line'>Java(TM) SE Runtime Environment (build 1.8.0_92-b14)
</span><span class='line'>Java HotSpot(TM) 64-Bit Server VM (build 25.92-b14, mixed mode)
</span><span class='line'>[root@hadoop-master2 ~]# cd /home/hadoop/spark-1.6.0-bin-2.6.3/
</span><span class='line'>[root@hadoop-master2 spark-1.6.0-bin-2.6.3]# export SPARK_SUBMIT_OPTS=-XX:+PreserveFramePointer     
</span><span class='line'>[root@hadoop-master2 spark-1.6.0-bin-2.6.3]# bin/spark-shell --master local   </span></code></pre></td></tr></table></div></figure>


<p>这里java进程使用root启动的，如果是普通用户如hadoop，为了采样需要把hadoop用户加入sudoer，在采样时使用 <code>sudo -u hadoop CMD</code>。</p>

<p><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">http://techblog.netflix.com/2015/07/java-in-flames.html</a></p>

<ul>
<li>A 使用perfj采样</li>
</ul>


<p><a href="http://greenteajug.cn/2015/07/02/greenteajug%E6%B4%BB%E5%8A%A8-%E7%AC%AC16%E6%9C%9F-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%88%A9%E5%99%A8-perfj/">性能调优利器——PerfJ</a></p>

<p>直接下载release-1.0的版本，解压后给 bin/perfj 加上执行权限。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 测试的时刻可以把-F 99设置大一点
</span><span class='line'># java和perfj的用户得一致！！
</span><span class='line'># https://github.com/coderplay/perfj/wiki/CPU-Flame-Graph
</span><span class='line'>
</span><span class='line'>[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
</span><span class='line'>[root@dacs ~]# wget http://blog.minzhou.info/perfj/leveldb-benchmark.jar
</span><span class='line'>[root@dacs ~]# $JAVA_HOME/bin/java -cp leveldb-benchmark.jar -XX:+PreserveFramePointer org.iq80.leveldb.benchmark.DbBenchmark --benchmarks=fillrandom --num=100000000
</span><span class='line'>
</span><span class='line'>[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
</span><span class='line'>[root@dacs ~]# perfj-1.0/bin/perfj record -F 999 -g -p `pgrep -f DbBenchmark` 
</span><span class='line'>perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
</span><span class='line'>~/FlameGraph/flamegraph.pl out.perf-folded  --color=java &gt;perf.svg
</span><span class='line'>sz perf.svg
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/flames/flames-java-leveldb.png" alt="" /></p>

<p>还是挺有意思的。</p>

<p><img src="http://winseliu.com/images/blogs/flames/flames-java-leveldb-vm.png" alt="" /></p>

<p>虚拟机的少了好多信息！一模一样的命令，得出来的东西差好远！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://github.com/coderplay/perfj/wiki/Context-Switch-Analysis
</span><span class='line'># 在vmware虚拟机里面运行啥都看不到！实体机也看不到作者的那些栈信息
</span><span class='line'>[root@dacs ~]# wget http://blog.minzhou.info/perfj/leveldb-benchmark.jar
</span><span class='line'>[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
</span><span class='line'>[root@dacs ~]# $JAVA_HOME/bin/javac ContextSwitchTest.java 
</span><span class='line'>[root@dacs ~]# $JAVA_HOME/bin/java -XX:+PreserveFramePointer ContextSwitchTest
</span><span class='line'>
</span><span class='line'>[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
</span><span class='line'>[root@dacs ~]# perfj-1.0/bin/perfj record  -e sched:sched_switch -F 999 -g -p `pgrep -f ContextSwitchTest` 
</span><span class='line'>[root@dacs ~]# perfj-1.0/bin/perfj report --stdio
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>B 使用perf-map-agent</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jrudolph/perf-map-agent.git
</span><span class='line'>cd perf-map-agent/
</span><span class='line'>export JAVA_HOME=/opt/jdk1.8.0_92
</span><span class='line'>cmake .
</span><span class='line'>make
</span><span class='line'>
</span><span class='line'>perf record -F 99 -g -p 7661 -- sleep 120
</span><span class='line'>bin/create-java-perf-map.sh 7661
</span><span class='line'>
</span><span class='line'>sudo perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
</span><span class='line'>cat out.perf-folded | ~/FlameGraph/flamegraph.pl --color=java &gt;perf.svg
</span><span class='line'>sz perf.svg</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hdfs异构存储实操]]></title>
    <link href="http://winseliu.com/blog/2016/05/05/hdfs-heterogeneous-storage/"/>
    <updated>2016-05-05T21:41:39+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/05/hdfs-heterogeneous-storage</id>
    <content type="html"><![CDATA[<p>[注意] 查看官方文档一定要和自己使用的环境对应！操作 storagepolicies 不同版本对应的命令不同（2.6.3<->2.7.2）！</p>

<p>我这里测试环境使用的是 2.6.3 <a href="https://hadoop.apache.org/docs/r2.6.3/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html">Heterogeneous Storage: Archival Storage, SSD &amp; Memory</a></p>

<h2>配置</h2>

<p>直接把内存盘放到 /dev/shm 下，单独挂载一个 tmpfs 的效果也差不多。<a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/MemoryStorage.html">r2.7.2 Memory Storage Support in HDFS</a> 2.6.3没有这个文档 概念都适应的。</p>

<p>1 调节系统参数</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi /etc/security/limits.conf
</span><span class='line'>
</span><span class='line'>  hadoop           -       nofile          65535
</span><span class='line'>  hadoop           -       nproc           65535
</span><span class='line'>  hadoop           -       memlock         268435456
</span></code></pre></td></tr></table></div></figure>


<p>需要调节memlock的大小，否则启动datanode报错。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-05-05 19:22:22,674 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
</span><span class='line'>java.lang.RuntimeException: Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) of 134217728 bytes is more than the datanode's available RLIMIT_MEMLOCK ulimit of 65536 bytes.
</span><span class='line'>        at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1067)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.datanode.DataNode.&lt;init&gt;(DataNode.java:417)
</span></code></pre></td></tr></table></div></figure>


<p>2 添加RAM_DISK</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi hdfs-site.xml
</span><span class='line'>
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;/data/bigdata/hadoop/dfs/data,[RAM_DISK]/dev/shm/dfs/data&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>  &lt;name&gt;dfs.datanode.max.locked.memory&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;134217728&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>  </span></code></pre></td></tr></table></div></figure>


<p>注意内存盘的写法，<code>[RAM_DISK]</code> 必须这些写，不然datanode不知道指定路径的storage的类型(默认是 DISK )。<a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html#Storage_Types_and_Storage_Policies">Storage_Types_and_Storage_Policies</a></p>

<blockquote><p>The default storage type of a datanode storage location will be DISK if it does not have a storage type tagged explicitly.</p></blockquote>

<p>3 同步配置并重启dfs</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# scp /etc/security/limits.conf cu3:/etc/security/
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ rsync -vaz etc cu3:~/hadoop-2.6.3/ 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3] sbin/stop-dfs.sh
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3] sbin/start-dfs.sh</span></code></pre></td></tr></table></div></figure>


<p>可以去到datanode查看日志，可以看到 /dev/shm/dfs/data 路径 <strong>StorageType</strong> 为 <strong>RAM_DISK</strong> ：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-05-05 19:33:39,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /data/bigdata/hadoop/dfs/data/current
</span><span class='line'>2016-05-05 19:33:39,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /data/bigdata/hadoop/dfs/data/current, StorageType: DISK
</span><span class='line'>2016-05-05 19:33:39,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: /dev/shm/dfs/data/current
</span><span class='line'>2016-05-05 19:33:39,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /dev/shm/dfs/data/current, StorageType: RAM_DISK</span></code></pre></td></tr></table></div></figure>


<p>同时查看 内存盘 的路径内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ ssh cu3 tree /dev/shm/dfs
</span><span class='line'>/dev/shm/dfs
</span><span class='line'>└── data
</span><span class='line'>    ├── current
</span><span class='line'>    │   ├── BP-1108852639-192.168.0.148-1452322889531
</span><span class='line'>    │   │   ├── current
</span><span class='line'>    │   │   │   ├── finalized
</span><span class='line'>    │   │   │   ├── rbw
</span><span class='line'>    │   │   │   └── VERSION
</span><span class='line'>    │   │   └── tmp
</span><span class='line'>    │   └── VERSION
</span><span class='line'>    └── in_use.lock
</span><span class='line'>
</span><span class='line'>7 directories, 3 files</span></code></pre></td></tr></table></div></figure>


<h2>测试使用</h2>

<p>通过三个例子对比，简单描述下使用。首先，使用默认的方式(主要用于对比)，第二个例子写文件是添加参数，第三个设置目录的存储类型（目录/文件会继承父目录的存储类型）</p>

<p>1 测试1</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -put README.txt /tmp/
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs fsck /tmp/README.txt -files -blocks -locations
</span><span class='line'>...
</span><span class='line'>/tmp/README.txt 1366 bytes, 1 block(s):  OK
</span><span class='line'>0. BP-1108852639-192.168.0.148-1452322889531:blk_1073752574_11776 len=1366 repl=1 [192.168.0.148:50010]
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 hadoop-2.6.3]$ find /data/bigdata/hadoop/dfs/data/ /dev/shm/dfs/data/ -name "*1073752574*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir41/blk_1073752574_11776.meta
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir41/blk_1073752574</span></code></pre></td></tr></table></div></figure>


<p>2 写文件时添加 lazy_persist 标识</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 添加 -l 参数，后台代码会加上 LAZY_PERSIST 标识。
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -help put 
</span><span class='line'>-put [-f] [-p] [-l] &lt;localsrc&gt; ... &lt;dst&gt; :
</span><span class='line'>  Copy files from the local file system into fs. Copying fails if the file already
</span><span class='line'>  exists, unless the -f flag is given.
</span><span class='line'>  Flags:
</span><span class='line'>                                                                       
</span><span class='line'>  -p  Preserves access and modification times, ownership and the mode. 
</span><span class='line'>  -f  Overwrites the destination if it already exists.                 
</span><span class='line'>  -l  Allow DataNode to lazily persist the file to disk. Forces        
</span><span class='line'>         replication factor of 1. This flag will result in reduced
</span><span class='line'>         durability. Use with care.
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/storage-lazy.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># -l 参数会把 replication 强制设置成数字1 ！
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -put -l README.txt /tmp/readme.txt2
</span><span class='line'>
</span><span class='line'># 查看namenode的日志，可以看到文件写入到 RAM_DISK 类型的存储
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ less logs/hadoop-hadoop-namenode-cu2.log 
</span><span class='line'>
</span><span class='line'>  2016-05-05 20:38:36,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/readme.txt2._COPYING_. BP-1108852639-192.168.0.148-1452322889531 blk_1073752578_11780{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-dcb2673f-3297-4bd7-af1c-ac0ee3eebaf9:NORMAL:192.168.0.30:50010|RBW]]}
</span><span class='line'>  2016-05-05 20:38:36,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.0.30:50010 is added to blk_1073752578_11780{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[RAM_DISK]DS-bf1ab64f-7eb3-41e0-8466-43287de9893d:NORMAL:192.168.0.30:50010|FINALIZED]]} size 0
</span><span class='line'>  2016-05-05 20:38:36,594 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/readme.txt2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1388277364_1
</span><span class='line'>
</span><span class='line'># 具体的内容所在位置
</span><span class='line'>[hadoop@cu4 ~]$ tree /dev/shm/dfs/data/
</span><span class='line'>/dev/shm/dfs/data/
</span><span class='line'>├── current
</span><span class='line'>│   ├── BP-1108852639-192.168.0.148-1452322889531
</span><span class='line'>│   │   ├── current
</span><span class='line'>│   │   │   ├── finalized
</span><span class='line'>│   │   │   │   └── subdir0
</span><span class='line'>│   │   │   │       └── subdir42
</span><span class='line'>│   │   │   │           ├── blk_1073752578
</span><span class='line'>│   │   │   │           └── blk_1073752578_11780.meta
</span><span class='line'>│   │   │   ├── rbw
</span><span class='line'>│   │   │   └── VERSION
</span><span class='line'>│   │   └── tmp
</span><span class='line'>│   └── VERSION
</span><span class='line'>└── in_use.lock
</span></code></pre></td></tr></table></div></figure>


<p>3 设置目录的存储类型</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -mkdir /ramdisk
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -setStoragePolicy /ramdisk LAZY_PERSIST 
</span><span class='line'>Set storage policy LAZY_PERSIST on /ramdisk
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -put README.txt /ramdisk
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk
</span><span class='line'>The storage policy of /ramdisk:
</span><span class='line'>BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}
</span><span class='line'>
</span><span class='line'># 不支持通配符
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk/*
</span><span class='line'>getStoragePolicy: File/Directory does not exist: /ramdisk/*
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk/README.txt
</span><span class='line'>The storage policy of /ramdisk/README.txt:
</span><span class='line'>BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 添加replication参数，再测试多个备份只有一个写ram_disk
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfs -Ddfs.replication=3 -put README.txt /ramdisk/readme.txt2
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs dfsadmin -getStoragePolicy /ramdisk/readme.txt2
</span><span class='line'>The storage policy of /ramdisk/readme.txt2:
</span><span class='line'>BlockStoragePolicy{LAZY_PERSIST:15, storageTypes=[RAM_DISK, DISK], creationFallbacks=[DISK], replicationFallbacks=[DISK]}
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ hdfs fsck /ramdisk/readme.txt2 -files -blocks -locations
</span><span class='line'>
</span><span class='line'>  /ramdisk/readme.txt2 1366 bytes, 1 block(s):  OK
</span><span class='line'>  0. BP-1108852639-192.168.0.148-1452322889531:blk_1073752580_11782 len=1366 repl=3 [192.168.0.30:50010, 192.168.0.174:50010, 192.168.0.148:50010]
</span><span class='line'>
</span><span class='line'>[hadoop@cu3 ~]$ find /data/bigdata/hadoop/dfs/data /dev/shm/dfs/data -name "*1073752580*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>
</span><span class='line'># 已经把ram_disk的内容持久化到磁盘了("Lazy_Persist")
</span><span class='line'>[hadoop@cu4 ~]$ find /data/bigdata/hadoop/dfs/data /dev/shm/dfs/data -name "*1073752580*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/lazypersist/subdir0/subdir42/blk_1073752580
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/lazypersist/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>/dev/shm/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580
</span><span class='line'>/dev/shm/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>
</span><span class='line'>[hadoop@cu5 ~]$ find /data/bigdata/hadoop/dfs/data /dev/shm/dfs/data -name "*1073752580*"
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580_11782.meta
</span><span class='line'>/data/bigdata/hadoop/dfs/data/current/BP-1108852639-192.168.0.148-1452322889531/current/finalized/subdir0/subdir42/blk_1073752580
</span></code></pre></td></tr></table></div></figure>


<p>[设想] 对于那些处理完就删除的临时文件，可以把持久化的时间设置的久一点 <code>dfs.datanode.lazywriter.interval.sec</code>。这样就不需要写磁盘了。</p>

<p>不要妄想了，反正都会持久化！就是缓冲的效果，其他没有了！！一次性存储并且不需要持久化的还是用alluxio吧。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.LazyWriter#saveNextReplica
</span><span class='line'>  org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.RamDiskAsyncLazyPersistService#submitLazyPersistTask</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li>挺详细的<a href="http://blog.csdn.net/androidlushangderen/article/details/51105876">HDFS异构存储</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetboard Install]]></title>
    <link href="http://winseliu.com/blog/2016/05/05/puppetboard-install/"/>
    <updated>2016-05-05T10:54:26+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/05/puppetboard-install</id>
    <content type="html"><![CDATA[<p>对于我这样的python小白来说，有网络来安装 puppetboard 还是比较容易的（离线安装依赖处理可能比较麻烦）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://fedoraproject.org/wiki/EPEL/zh-cn
</span><span class='line'>[root@cu2 ~]# yum search epel
</span><span class='line'>[root@cu2 ~]# yum install epel-release
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# yum repolist
</span><span class='line'>Loaded plugins: fastestmirror, priorities
</span><span class='line'>Loading mirror speeds from cached hostfile
</span><span class='line'> * base: mirrors.skyshe.cn
</span><span class='line'> * centosplus: mirrors.pubyun.com
</span><span class='line'> * epel: mirror01.idc.hinet.net
</span><span class='line'> * extras: mirrors.skyshe.cn
</span><span class='line'> * updates: mirrors.skyshe.cn
</span><span class='line'>193 packages excluded due to repository priority protections
</span><span class='line'>repo id                                   repo name                                                                   status
</span><span class='line'>base                                      CentOS-6 - Base                                                                  6,575
</span><span class='line'>centosplus                                CentOS-6 - Centosplus                                                             0+76
</span><span class='line'>epel                                      Extra Packages for Enterprise Linux 6 - x86_64                              12,127+117
</span><span class='line'>extras                                    CentOS-6 - Extras                                                                   62
</span><span class='line'>puppet-local                              Puppet Local                                                                         5
</span><span class='line'>updates                                   CentOS-6 - Updates                                                               1,607
</span><span class='line'>repolist: 20,376
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# yum install python-pip -y
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# pip install puppetboard
</span><span class='line'>/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
</span><span class='line'>  InsecurePlatformWarning
</span><span class='line'>You are using pip version 7.1.0, however version 8.1.1 is available.
</span><span class='line'>You should consider upgrading via the 'pip install --upgrade pip' command.
</span><span class='line'>Collecting puppetboard
</span><span class='line'>/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
</span><span class='line'>  InsecurePlatformWarning
</span><span class='line'>  Downloading puppetboard-0.1.3.tar.gz (598kB)
</span><span class='line'>    100% |████████████████████████████████| 602kB 726kB/s 
</span><span class='line'>Collecting Flask&gt;=0.10.1 (from puppetboard)
</span><span class='line'>  Downloading Flask-0.10.1.tar.gz (544kB)
</span><span class='line'>    100% |████████████████████████████████| 544kB 734kB/s 
</span><span class='line'>Collecting Flask-WTF&lt;=0.9.5,&gt;=0.9.4 (from puppetboard)
</span><span class='line'>  Downloading Flask-WTF-0.9.5.tar.gz (245kB)
</span><span class='line'>    100% |████████████████████████████████| 249kB 320kB/s 
</span><span class='line'>Collecting WTForms&lt;2.0 (from puppetboard)
</span><span class='line'>  Downloading WTForms-1.0.5.zip (355kB)
</span><span class='line'>    100% |████████████████████████████████| 356kB 1.3MB/s 
</span><span class='line'>Collecting pypuppetdb&lt;0.3.0,&gt;=0.2.1 (from puppetboard)
</span><span class='line'>  Downloading pypuppetdb-0.2.1.tar.gz
</span><span class='line'>Collecting Werkzeug&gt;=0.7 (from Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading Werkzeug-0.11.9-py2.py3-none-any.whl (306kB)
</span><span class='line'>    100% |████████████████████████████████| 307kB 1.5MB/s 
</span><span class='line'>Collecting Jinja2&gt;=2.4 (from Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading Jinja2-2.8-py2.py3-none-any.whl (263kB)
</span><span class='line'>    100% |████████████████████████████████| 266kB 2.3MB/s 
</span><span class='line'>Collecting itsdangerous&gt;=0.21 (from Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading itsdangerous-0.24.tar.gz (46kB)
</span><span class='line'>    100% |████████████████████████████████| 49kB 7.2MB/s 
</span><span class='line'>Collecting requests&gt;=1.2.3 (from pypuppetdb&lt;0.3.0,&gt;=0.2.1-&gt;puppetboard)
</span><span class='line'>  Downloading requests-2.10.0-py2.py3-none-any.whl (506kB)
</span><span class='line'>    100% |████████████████████████████████| 507kB 920kB/s 
</span><span class='line'>Collecting MarkupSafe (from Jinja2&gt;=2.4-&gt;Flask&gt;=0.10.1-&gt;puppetboard)
</span><span class='line'>  Downloading MarkupSafe-0.23.tar.gz
</span><span class='line'>Installing collected packages: Werkzeug, MarkupSafe, Jinja2, itsdangerous, Flask, WTForms, Flask-WTF, requests, pypuppetdb, puppetboard
</span><span class='line'>  Running setup.py install for MarkupSafe
</span><span class='line'>  Running setup.py install for itsdangerous
</span><span class='line'>  Running setup.py install for Flask
</span><span class='line'>  Running setup.py install for WTForms
</span><span class='line'>  Running setup.py install for Flask-WTF
</span><span class='line'>  Running setup.py install for pypuppetdb
</span><span class='line'>  Running setup.py install for puppetboard
</span><span class='line'>Successfully installed Flask-0.10.1 Flask-WTF-0.9.5 Jinja2-2.8 MarkupSafe-0.23 WTForms-1.0.5 Werkzeug-0.11.9 itsdangerous-0.24 puppetboard-0.1.3 pypuppetdb-0.2.1 requests-2.10.0
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# pip show puppetboard
</span><span class='line'>You are using pip version 7.1.0, however version 8.1.1 is available.
</span><span class='line'>You should consider upgrading via the 'pip install --upgrade pip' command.
</span><span class='line'>---
</span><span class='line'>Metadata-Version: 1.0
</span><span class='line'>Name: puppetboard
</span><span class='line'>Version: 0.1.3
</span><span class='line'>Summary: Web frontend for PuppetDB
</span><span class='line'>Home-page: https://github.com/puppet-community/puppetboard
</span><span class='line'>Author: Daniele Sluijters
</span><span class='line'>Author-email: daniele.sluijters+pypi@gmail.com
</span><span class='line'>License: Apache License 2.0
</span><span class='line'>Location: /usr/lib/python2.6/site-packages
</span><span class='line'>Requires: Flask, Flask-WTF, WTForms, pypuppetdb
</span><span class='line'>[root@cu2 ~]# ll /usr/lib/python2.6/site-packages/puppetboard
</span><span class='line'>total 100
</span><span class='line'>-rw-r--r-- 1 root root 31629 May  5 09:12 app.py
</span><span class='line'>-rw-r--r-- 1 root root 30481 May  5 09:12 app.pyc
</span><span class='line'>-rw-r--r-- 1 root root  1206 May  5 09:12 default_settings.py
</span><span class='line'>-rw-r--r-- 1 root root  1477 May  5 09:12 default_settings.pyc
</span><span class='line'>-rw-r--r-- 1 root root  1025 May  5 09:12 forms.py
</span><span class='line'>-rw-r--r-- 1 root root  1982 May  5 09:12 forms.pyc
</span><span class='line'>-rw-r--r-- 1 root root     0 May  5 09:12 __init__.py
</span><span class='line'>-rw-r--r-- 1 root root   143 May  5 09:12 __init__.pyc
</span><span class='line'>drwxr-xr-x 9 root root  4096 May  5 09:12 static
</span><span class='line'>drwxr-xr-x 2 root root  4096 May  5 09:12 templates
</span><span class='line'>-rw-r--r-- 1 root root  2155 May  5 09:12 utils.py
</span><span class='line'>-rw-r--r-- 1 root root  3433 May  5 09:12 utils.pyc
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# pip install uwsgi
</span><span class='line'>You are using pip version 7.1.0, however version 8.1.1 is available.
</span><span class='line'>You should consider upgrading via the 'pip install --upgrade pip' command.
</span><span class='line'>Collecting uwsgi
</span><span class='line'>/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
</span><span class='line'>  InsecurePlatformWarning
</span><span class='line'>  Downloading uwsgi-2.0.12.tar.gz (784kB)
</span><span class='line'>    100% |████████████████████████████████| 786kB 143kB/s 
</span><span class='line'>Installing collected packages: uwsgi
</span><span class='line'>  Running setup.py install for uwsgi
</span><span class='line'>Successfully installed uwsgi-2.0.12
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# mkdir -p /var/www/puppetboard
</span><span class='line'>[root@cu2 ~]# cd /var/www/puppetboard/
</span><span class='line'>[root@cu2 puppetboard]# cp /usr/lib/python2.6/site-packages/puppetboard/default_settings.py ./settings.py
</span><span class='line'># 修改配置 
</span><span class='line'># https://github.com/voxpupuli/puppetboard#settings
</span><span class='line'>PUPPETDB_HOST = 'cu3'
</span><span class='line'>PUPPETDB_PORT = 8080
</span><span class='line'>REPORTS_COUNT = 21
</span><span class='line'>ENABLE_CATALOG = True
</span><span class='line'>
</span><span class='line'>[root@cu2 puppetboard]# vi wsgi.py 
</span><span class='line'>from __future__ import absolute_import
</span><span class='line'>import os
</span><span class='line'>
</span><span class='line'>os.environ['PUPPETDOARD_SETTINGS'] = '/var/www/puppetboard/settings.py'
</span><span class='line'>from puppetboard.app import app as application
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># A 直接用uwsgi-http
</span><span class='line'># http://yongqing.is-programmer.com/posts/43688.html
</span><span class='line'>[root@cu2 puppetboard]# uwsgi --http :9091 --wsgi-file /var/www/puppetboard/wsgi.py 
</span><span class='line'>
</span><span class='line'># 使用 supervisord 管理
</span><span class='line'>[root@cu2 supervisord.d]# cat uwsgi.ini 
</span><span class='line'>[program:puppetboard]
</span><span class='line'>command=uwsgi --http :9091 --wsgi-file /var/www/puppetboard/wsgi.py 
</span><span class='line'>[root@cu2 supervisord.d]# supervisorctl update
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># B nginx + uwsgi-socket
</span><span class='line'># 需要对应到 / ，新增一个9091的server
</span><span class='line'>[root@cu2 puppetboard]# vi /home/hadoop/nginx/conf/nginx.conf
</span><span class='line'>server {
</span><span class='line'>  listen 9091;
</span><span class='line'>
</span><span class='line'>  location /static {
</span><span class='line'>    alias /usr/lib/python2.6/site-packages/puppetboard/static;
</span><span class='line'>  }
</span><span class='line'>  location / {
</span><span class='line'>    include uwsgi_params;
</span><span class='line'>    uwsgi_pass 127.0.0.1:9090;
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@cu2 puppetboard]# uwsgi --socket :9090 --wsgi-file /var/www/puppetboard/wsgi.py 
</span><span class='line'>
</span><span class='line'>[root@cu2 puppetboard]# /home/hadoop/nginx/sbin/nginx -s reload
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/puppetboard-install.png" alt="" /></p>

<p>配置SSL访问需要把ssl_verify设置为false。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 2.7.9+网上说好像就没问题
</span><span class='line'># http://stackoverflow.com/questions/29099404/ssl-insecureplatform-error-when-using-requests-package
</span><span class='line'># https://github.com/pypa/pip/issues/2681
</span><span class='line'>[root@cu2 ~]# yum install -y  libffi-devel libffi 
</span><span class='line'>[root@cu2 ~]# pip install 'requests[security]'
</span><span class='line'>
</span><span class='line'># [重要] 两个链接内容一样的：
</span><span class='line'># * https://groups.google.com/forum/#!msg/puppet-users/m7Sakf4bQ7Q/y6uAa0AUsZIJ
</span><span class='line'># * http://grokbase.com/t/gg/puppet-users/1428vjkncr/puppetboard-and-ssl
</span><span class='line'># You have two choices now, set SSL_VERIFY to False and trust that you're
</span><span class='line'># always talking to your actual PuppetDB or copy from the Puppet CA
</span><span class='line'># $vardir/ssl/ca_crt.pem to /etc/puppetboard and set SSL_VERIFY to the path
</span><span class='line'># of ca_crt.pem. In that case the file SSL_VERIFY points to will be used to
</span><span class='line'># verify PuppetDB's server certificate instead of the OS truststore.
</span><span class='line'>[root@cu2 puppetboard]# vi settings.py 
</span><span class='line'>PUPPETDB_HOST = 'cu3.eshore.cn'
</span><span class='line'>PUPPETDB_PORT = 8081
</span><span class='line'>PUPPETDB_SSL_VERIFY = False  # 这里设置为false
</span><span class='line'>PUPPETDB_KEY = '/etc/puppetlabs/puppet/ssl/private_keys/cu2.eshore.cn.pem'
</span><span class='line'>PUPPETDB_CERT = '/etc/puppetlabs/puppet/ssl/ca/signed/cu2.eshore.cn.pem'
</span><span class='line'>
</span><span class='line'># 重启uwsgi-http服务
</span><span class='line'>[root@cu2 ~]# supervisorctl restart puppetboard
</span></code></pre></td></tr></table></div></figure>


<p>如果 puppetboard 和 puppetdb 安装在同一机器，可以使用 puppetdb/ssl 路径下的ssl文件（puppetdb/ssl也是从puppet/ssl拷贝过来的）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# puppetdb ssl-setup -f
</span><span class='line'>PEM files in /etc/puppetlabs/puppetdb/ssl are missing, we will move them into place for you
</span><span class='line'>Copying files: /etc/puppetlabs/puppet/ssl/certs/ca.pem, /etc/puppetlabs/puppet/ssl/private_keys/cu3.eshore.cn.pem and /etc/puppetlabs/puppet/ssl/certs/cu3.eshore.cn.pem to /etc/puppetlabs/puppetdb/ssl
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# tree /etc/puppetlabs/puppetdb/ssl/
</span><span class='line'>/etc/puppetlabs/puppetdb/ssl/
</span><span class='line'>├── ca.pem
</span><span class='line'>├── private.pem
</span><span class='line'>└── public.pem
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hiera and Facts]]></title>
    <link href="http://winseliu.com/blog/2016/05/03/hiera-and-facts/"/>
    <updated>2016-05-03T18:30:41+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/03/hiera-and-facts</id>
    <content type="html"><![CDATA[<p>为什么用hiera： <a href="https://docs.puppet.com/hiera/3.1/#why-hiera">https://docs.puppet.com/hiera/3.1/#why-hiera</a></p>

<ul>
<li>hierarchy层级体系。可以设置公共属性，也可以覆写！</li>
<li>&ldquo;注入&#8221;设置 class 中的属性值。</li>
<li>hiera_include 通过配置来完成site.pp同样的功能，并且比 <code>node</code> 更加强大灵活（数组值可以合并）。</li>
</ul>


<p>基本概念：</p>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/configuring.html">hiera.yaml</a> 默认配置文件放在 $codedir/hiera.yaml 。 结合puppet使用时可以通过修改 puppet.conf 的 hiera_config 自定义配置的文件。</li>
<li><a href="https://docs.puppet.com/hiera/3.1/hierarchy.html">hierarchy</a> hierarchy定义好可以简化很多工作量。如需要根据操作系统 %{::osfamily} 进行适配。</li>
<li><a href="https://docs.puppet.com/hiera/3.1/data_sources.html#yaml">datasource</a> yaml格式介绍。</li>
</ul>


<h2>windows cygwin命令行环境配置</h2>

<pre><code>winse@Lenovo-PC ~
$ cat bin/hiera
#!/bin/sh

# default puppetlabs config in c:\Users\winse\Puppetlabs
export HOME=/cygdrive/c/Users/winse

name=`basename $0`

# execute
"C:/Progra~1/Puppet~1/Puppet/bin"/$name.bat "$@"


winse@Lenovo-PC ~
$ cat .bash_profile
...
function hiera_look(){
  code_dir=`puppet config print codedir | sed 's/\r//' `
  ~/bin/hiera -c "$code_dir/hiera.yaml" --debug "$@" ::environment=production
}
</code></pre>

<h2>HelloWorld</h2>

<pre><code>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat /cygdrive/c/Users/winse/.puppetlabs/etc/puppet/puppet.conf
[main]
codedir = D:/eshore-shells/puppet/dta/code
hiera_config = $codedir/hiera.yaml

certname = winse

winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat hiera.yaml
---
:backends:
  - yaml
:hierarchy:
  - "nodes/%{::trusted.certname}"
  - common

:yaml:
  :datadir: "D:/eshore-shells/puppet/dta/code/environments/%{::environment}/hieradata"


winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
$ cat environments/production/hieradata/common.yaml
whoami: winse


winse@Lenovo-PC ~
$ hiera_look whoami
DEBUG: 2016-05-03 11:27:41 +0100: Hiera YAML backend starting
DEBUG: 2016-05-03 11:27:41 +0100: Looking up whoami in YAML backend
DEBUG: 2016-05-03 11:27:41 +0100: Looking for data source common
DEBUG: 2016-05-03 11:27:41 +0100: Found whoami in common
winse
</code></pre>

<h2><strong>与Puppet结合使用</strong></h2>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/puppet.html">https://docs.puppet.com/hiera/3.1/puppet.html</a></li>
<li><a href="https://docs.puppet.com/hiera/3.1/puppet.html#assigning-classes-to-nodes-with-hiera-hierainclude">https://docs.puppet.com/hiera/3.1/puppet.html#assigning-classes-to-nodes-with-hiera-hierainclude</a></li>
<li>单值属性重复优先级：就近原则 <a href="https://docs.puppet.com/hiera/3.1/hierarchy.html#example">https://docs.puppet.com/hiera/3.1/hierarchy.html#example</a></li>
</ul>


<h4>参考案例</h4>

<ul>
<li><a href="https://docs.puppet.com/hiera/3.1/complete_example.html">https://docs.puppet.com/hiera/3.1/complete_example.html</a></li>
<li><a href="https://kisspuppet.gitbooks.io/puppet/content/puppet_learning_ext1.html">https://kisspuppet.gitbooks.io/puppet/content/puppet_learning_ext1.html</a></li>
</ul>


<h4>主要功能</h4>

<ul>
<li>hiera获取puppet-facts的属性</li>
<li>puppet读取hiera中的属性</li>
<li>hiera注入设置puppet-module的属性：
  获取到第一个就返回了(类似于hiera)，对于strings, arrays, hashes类型 cannot merge values from multiple hierarchy levels; 需要使用来 hiera_array or hiera_hash 代替。</li>
<li>hiera_include</li>
</ul>


<h4>动手实践</h4>

<pre><code>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code/environments/production
$ tree .
.
├── hieradata
│   ├── common.yaml
│   └── nodes
│       └── winse.yaml
├── manifests
│   └── site.pp
└── modules
    └── helloworld
        └── manifests
            └── init.pp

$ cat hieradata/common.yaml
whoami: "%{calling_module} - %{calling_class} - %{calling_class_path} - %{::domain}"

$ cat hieradata/nodes/winse.yaml  | iconv -f gbk -t utf8
---
classes:
  - helloworld::hello
  - helloworld::world

# 文件编码需要与环境匹配，windows要GBK的
helloworld::hello::hello: 你好

$ cat modules/helloworld/manifests/init.pp

class helloworld::hello ($hello = "hello"){

  notify {$hello :
  }

}

class helloworld::world {

  notify {hiera('whoami') : # 不推荐在module中使用hiera方法，这里仅为了演示获取calling_module等
  }

}

$ cat manifests/site.pp

hiera_include('classes')

$ puppet apply environments/production/manifests/site.pp
Notice: Compiled catalog for winse in environment production in 0.28 seconds
Notice: 你好
Notice: /Stage[main]/Helloworld::Hello/Notify[你好]/message: defined 'message' as '你好'
Notice: helloworld - helloworld::world - helloworld/world - DHCP HOST
Notice: /Stage[main]/Helloworld::World/Notify[helloworld - helloworld::world - helloworld/world - DHCP HOST]/message: defined 'message' as 'helloworld - helloworld::world - helloworld/world - DHCP HOST'
Notice: Applied catalog in 0.02 seconds

# 测试获取hiera变量
$ puppet apply -e "notice(hiera('whoami'))"
Notice: Scope(Class[main]):  -  -  - DHCP HOST
Notice: Compiled catalog for winse in environment production in 0.05 seconds
Notice: Applied catalog in 0.03 seconds

$ puppet apply -e "notice(hiera('classes'))"
Notice: Scope(Class[main]): [helloworld::hello, helloworld::world]
Notice: Compiled catalog for winse in environment production in 0.05 seconds
Notice: Applied catalog in 0.02 seconds
</code></pre>

<h2>facts</h2>

<ul>
<li><a href="https://docs.puppet.com/facter/3.1/">https://docs.puppet.com/facter/3.1/</a></li>
<li>系统自带指标 <a href="https://docs.puppet.com/facter/3.1/core_facts.html">https://docs.puppet.com/facter/3.1/core_facts.html</a></li>
</ul>


<h4>自定义指标</h4>

<ul>
<li><a href="https://docs.puppet.com/facter/3.1/custom_facts.html">https://docs.puppet.com/facter/3.1/custom_facts.html</a></li>
<li>Example <a href="https://docs.puppet.com/facter/3.1/fact_overview.html">https://docs.puppet.com/facter/3.1/fact_overview.html</a></li>
<li>《Learning Puppet4》</li>
</ul>


<p>三种方式：</p>

<ul>
<li>文件: yaml/json/txt。推荐放置到 modules/[name]/facts.d 目录下</li>
<li>可执行脚本输出键值对。推荐放置到 modules/[name]/facts.d 目录下，可执行脚本！</li>
<li>ruby。放置到 modules/[name]/lib/facter 。<a href="https://docs.puppet.com/guides/plugins_in_modules.html">custom facts should go in lib/facter/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cat environments/production/modules/helloworld/facts.d/simple_facts.yaml
</span><span class='line'>---
</span><span class='line'>my_fact: my_value
</span><span class='line'>
</span><span class='line'>$ puppet facts find --debug | grep -iE "my_fact|helloworld"
</span><span class='line'>Debug: Loading external facts from D:/eshore-shells/puppet/dta/code/environments/production/modules/helloworld/facts.d
</span><span class='line'>Debug: Facter: searching "D:/eshore-shells\puppet\dta\code\environments\production\modules\helloworld\facts.d" for external facts.
</span><span class='line'>Debug: Facter: resolving facts from YAML file "D:/eshore-shells\puppet\dta\code\environments\production\modules\helloworld\facts.d\simple_facts.yaml".
</span><span class='line'>Debug: Facter: fact "my_fact" has resolved to "my_value".
</span><span class='line'>Debug: Facter: completed resolving facts from YAML file "D:/eshore-shells\puppet\dta\code\environments\production\modules\helloworld\facts.d\simple_facts.yaml".
</span><span class='line'>    "my_fact": "my_value",
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC /cygdrive/d/eshore-shells/puppet/dta/code
</span><span class='line'>$ cat environments/production/modules/helloworld/lib/facter/users.rb
</span><span class='line'>Facter.add('users') do
</span><span class='line'>  setcode do
</span><span class='line'>    ["winse", "winseliu"]
</span><span class='line'>  end
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>$ puppet facts | grep -3 users
</span><span class='line'>    "uptime_days": 0,
</span><span class='line'>    "uptime_hours": 1,
</span><span class='line'>    "uptime_seconds": 6980,
</span><span class='line'>    "users": [
</span><span class='line'>      "winse",
</span><span class='line'>      "winseliu"
</span><span class='line'>    ],
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MCollective Plugins]]></title>
    <link href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/"/>
    <updated>2016-04-28T21:37:51+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/28/mcollective-plugins</id>
    <content type="html"><![CDATA[<p>上一篇介绍了mcollective的安装。乘着这股热情把 mco 命令行和插件的安装弄通，记录下来。</p>

<h2>基本命令使用</h2>

<ul>
<li><a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html">https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 ~]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  rpc             Generic RPC agent client application
</span></code></pre></td></tr></table></div></figure>


<p>自带的插件只能用来查看环境情况(下面列出来的命令<a href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/#cli-simple-usage">上一篇:MCollective安装配置</a>都已记录过)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mco ping
</span><span class='line'>mco inventory [server_host]
</span><span class='line'>mco facts [fact]</span></code></pre></td></tr></table></div></figure>


<p>mcollective 的 filter（适配节点）功能很强大，具体查看文档：<a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html#selecting-request-targets-using-filters">Selecting Request Targets Using Filters</a></p>

<p><strong> 使用filter功能需要结合facts，需要先把节点的信息写入到mcollective/facts.yaml文件 </strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco ping -I /^hadoop/
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco puppet runall 8 -I /^hadoop/
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco service iptables status -I "/cu-ud.*/"
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 manifests]# mco ping -S "hostname=hadoop-master2"
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco ping -S 'hostname=/hadoop.*/'
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco facts hostname</span></code></pre></td></tr></table></div></figure>


<h2>插件安装</h2>

<ul>
<li><a href="https://docs.puppet.com/mcollective/deploy/standard.html#install-agent-plugins">https://docs.puppet.com/mcollective/deploy/standard.html#install-agent-plugins</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/plugins.html">Installing Plugins</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/plugins.html#example">https://docs.puppet.com/mcollective/deploy/plugins.html#example</a></li>
</ul>


<p>文档中描述了 <code>Use packages</code> 和 <code>Put files directly into the libdir</code> 两种安装插件的方式。但是 Packages 都是放在 <a href="http://yum.puppetlabs.com/el/6/products/x86_64/">旧的repo</a> 里面，我们这里使用第二种方式把github下载源码放到libdir来安装。</p>

<h4>安装mcollective-puppet-agent</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 使用文档 https://github.com/puppetlabs/mcollective-puppet-agent#readme
</span><span class='line'># 直接下载release版本 
</span><span class='line'>[root@hadoop-master2 ~]# cd /usr/libexec/mcollective/
</span><span class='line'>[root@hadoop-master2 mcollective]# ll
</span><span class='line'>total 44
</span><span class='line'>-rw-r--r-- 1 root root 44759 Apr 29 11:53 mcollective-puppet-agent-1.10.0.tar.gz
</span><span class='line'>[root@hadoop-master2 mcollective]# tar zxf mcollective-puppet-agent-1.10.0.tar.gz  
</span><span class='line'>[root@hadoop-master2 mcollective]# ll mcollective-puppet-agent-1.10.0
</span><span class='line'>total 60
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 agent
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 aggregate
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 application
</span><span class='line'>-rw-rw-r-- 1 root root  3456 Apr 13  2015 CHANGELOG.md
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 data
</span><span class='line'>drwxrwxr-x 4 root root  4096 Apr 13  2015 ext
</span><span class='line'>-rw-rw-r-- 1 root root   349 Apr 13  2015 Gemfile
</span><span class='line'>-rw-rw-r-- 1 root root  3036 Apr 13  2015 Rakefile
</span><span class='line'>-rw-rw-r-- 1 root root 14739 Apr 13  2015 README.md
</span><span class='line'>drwxrwxr-x 9 root root  4096 Apr 13  2015 spec
</span><span class='line'>drwxrwxr-x 3 root root  4096 Apr 13  2015 util
</span><span class='line'>drwxrwxr-x 2 root root  4096 Apr 13  2015 validator
</span><span class='line'># 官网提供example有区分服务端和客户端文件。反正多了没问题，直接全部放就行咯。。。
</span><span class='line'>[root@hadoop-master2 mcollective]# mv mcollective-puppet-agent-1.10.0 mcollective
</span><span class='line'>
</span><span class='line'># 验证
</span><span class='line'># 多了puppet的命令！
</span><span class='line'>[root@hadoop-master2 mcollective]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  puppet          Schedule runs, enable, disable and interrogate the Puppet Agent
</span><span class='line'>  rpc             Generic RPC agent client application
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 同步到mcollective-servers （172.17.0.2对应hadoop-slaver1）
</span><span class='line'>[root@hadoop-master2 mcollective]# rsync -az /usr/libexec/mcollective 172.17.0.2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># mcollective-server添加插件后，重启mcollective服务
</span><span class='line'># 也可以使用 reload-agents 来重新加载agents： service mcollective reload-agents
</span><span class='line'>[root@hadoop-slaver1 libexec]# service mcollective restart
</span><span class='line'>Shutting down mcollective:                                 [  OK  ]
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 验证server，已经可以看到新添加的puppet命令了
</span><span class='line'>[root@hadoop-master2 mcollective]# mco inventory hadoop-slaver1
</span><span class='line'>Inventory for hadoop-slaver1:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-04-29 12:01:40 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 123
</span><span class='line'>               Total Messages: 1
</span><span class='line'>      Messages Passed Filters: 1
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 0
</span><span class='line'>         Total Processor Time: 0.67 seconds
</span><span class='line'>                  System Time: 0.8 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       puppet          rpcutil        
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat           puppet          resource       
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco help puppet
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco puppet status    
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-slaver1: Currently stopped; last completed run 10 hours 57 minutes 20 seconds ago
</span><span class='line'>   hadoop-master1: Currently stopped; last completed run 11 hours 1 minutes 05 seconds ago
</span><span class='line'>   hadoop-slaver2: Currently stopped; last completed run 10 hours 57 minutes 16 seconds ago
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 配置server.conf
</span><span class='line'># 注意：真正要执行puppet命令，为了适配puppet4需要添加/修改配置
</span><span class='line'>-bash-4.1# cat /etc/puppetlabs/mcollective/server.cfg 
</span><span class='line'>...
</span><span class='line'>plugin.puppet.command = /opt/puppetlabs/bin/puppet agent
</span><span class='line'>plugin.puppet.config = /etc/puppetlabs/puppet/puppet.conf
</span><span class='line'>
</span><span class='line'># 重启所有mcollective（重新加载agent也可以不重启，使用 mco shell run service mcollective reload-agents 来重新加载）
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco puppet runall 1
</span><span class='line'>2016-04-29 16:52:46: Running all nodes with a concurrency of 1
</span><span class='line'>2016-04-29 16:52:46: Discovering enabled Puppet nodes to manage
</span><span class='line'>2016-04-29 16:52:49: Found 3 enabled nodes
</span><span class='line'>2016-04-29 16:52:50: hadoop-slaver1 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:55: hadoop-slaver2 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:59: hadoop-master1 schedule status: Started a Puppet run using the '/opt/puppetlabs/bin/puppet agent --onetime --no-daemonize --color=false --show_diff --verbose --no-splay' command
</span><span class='line'>2016-04-29 16:52:59: Iteration complete. Initiated a Puppet run on 3 nodes.
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 puppetlabs]# mco puppet status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-master1: Currently stopped; last completed run 10 seconds ago
</span><span class='line'>   hadoop-slaver1: Currently stopped; last completed run 15 seconds ago
</span><span class='line'>   hadoop-slaver2: Currently stopped; last completed run 04 seconds ago
</span><span class='line'>...
</span><span class='line'># 或者通过 puppetexplorer 查看节点最后的更新时间
</span></code></pre></td></tr></table></div></figure>


<h4>安装 package / service 插件</h4>

<p>为了更好的管理，再添加 package 和 service 两个插件</p>

<ul>
<li><a href="https://github.com/puppetlabs/mcollective-package-agent#readme">https://github.com/puppetlabs/mcollective-package-agent#readme</a></li>
<li><a href="https://github.com/puppetlabs/mcollective-service-agent#readme">https://github.com/puppetlabs/mcollective-service-agent#readme</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://stackoverflow.com/questions/8488253/how-to-force-cp-to-overwrite-without-confirmation
</span><span class='line'>[root@hadoop-master2 mcollective]# unalias cp
</span><span class='line'>[root@hadoop-master2 mcollective]# cp -rf mcollective-service-agent-3.1.3/* mcollective/   
</span><span class='line'>[root@hadoop-master2 mcollective]# cp -rf mcollective-package-agent-4.4.0/* mcollective/
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# rsync -az /usr/libexec/mcollective 172.17.0.2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># 重启mcollective服务（或者 mco shell run service mcollective reload-agents 重新加载）
</span><span class='line'>
</span><span class='line'># updated 2016-5-11 17:15:08
</span><span class='line'># 还是重启比较好，reload-agents Data Plugins 没有重新加载
</span><span class='line'>[root@hadoop-master1 puppet]# mco inventory hadoop-master2
</span><span class='line'>Inventory for hadoop-master2:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-05-11 17:12:45 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 39878
</span><span class='line'>               Total Messages: 1
</span><span class='line'>      Messages Passed Filters: 1
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 0
</span><span class='line'>         Total Processor Time: 1.17 seconds
</span><span class='line'>                  System Time: 0.1 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       package         puppet         
</span><span class='line'>      rpcutil         service         shell          
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat           puppet          resource       
</span><span class='line'>      service                                        
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>[root@hadoop-master1 puppet]# mco inventory hadoop-slaver2
</span><span class='line'>Inventory for hadoop-slaver2:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-05-11 16:56:09 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 14062
</span><span class='line'>               Total Messages: 9
</span><span class='line'>      Messages Passed Filters: 7
</span><span class='line'>            Messages Filtered: 2
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 6
</span><span class='line'>         Total Processor Time: 1.31 seconds
</span><span class='line'>                  System Time: 0.23 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       package         puppet         
</span><span class='line'>      rpcutil         service         shell          
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat                                          
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>验证下package的实力：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 mcollective]# mco package lrzsz status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-slaver1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-master1: -purged.
</span><span class='line'>   hadoop-slaver2: -purged.
</span><span class='line'>
</span><span class='line'>Summary of Arch:
</span><span class='line'>
</span><span class='line'>   x86_64 = 1
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>             purged = 2
</span><span class='line'>   0.12.20-27.1.el6 = 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 1488.41 ms
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco rpc package install package=lrzsz
</span><span class='line'>Discovering hosts using the mc method for 2 second(s) .... 3
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>hadoop-slaver1                           Unknown Request Status
</span><span class='line'>   Package is already installed
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>   0.12.20-27.1.el6 = 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 14525.03 ms
</span><span class='line'>[root@hadoop-master2 mcollective]# mco package lrzsz status
</span><span class='line'>
</span><span class='line'> * [ ============================================================&gt; ] 3 / 3
</span><span class='line'>
</span><span class='line'>   hadoop-master1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-slaver2: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>   hadoop-slaver1: lrzsz-0.12.20-27.1.el6.x86_64
</span><span class='line'>
</span><span class='line'>Summary of Arch:
</span><span class='line'>
</span><span class='line'>   x86_64 = 3
</span><span class='line'>
</span><span class='line'>Summary of Ensure:
</span><span class='line'>
</span><span class='line'>   0.12.20-27.1.el6 = 3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 572.13 ms
</span></code></pre></td></tr></table></div></figure>


<p>还有很多的插件：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/plugin_directory/index.html">https://docs.puppet.com/mcollective/plugin_directory/index.html</a></li>
<li>shell插件也不错，安装的时刻注意一下目录结构！<a href="https://github.com/puppetlabs/mcollective-shell-agent">https://github.com/puppetlabs/mcollective-shell-agent</a></li>
</ul>


<p>添加了 service，package，shell，puppet 插件后，用 mco 来执行管理集群太爽了！！</p>

<h4>后期统一安装</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 mcollective]# ll
</span><span class='line'>total 100
</span><span class='line'>-rw-r--r-- 1 root root 17101 Apr 29 12:15 mcollective-package-agent-4.4.0.tar.gz
</span><span class='line'>-rw-r--r-- 1 root root 44759 Apr 29 11:53 mcollective-puppet-agent-1.10.0.tar.gz
</span><span class='line'>-rw-r--r-- 1 root root 12483 Apr 29 12:15 mcollective-service-agent-3.1.3.tar.gz
</span><span class='line'>-rw-r--r-- 1 root root 17984 Apr 29 19:24 mcollective-shell-agent-0.0.2.tar.gz
</span><span class='line'>[root@hadoop-master1 mcollective]# ls | xargs -I{} tar zxf {}
</span><span class='line'>
</span><span class='line'># TODO 可以考虑打包成rpm
</span><span class='line'>[root@hadoop-master1 mcollective]# mkdir mcollective
</span><span class='line'>[root@hadoop-master1 mcollective]# unalias cp
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-package-agent-4.4.0/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-puppet-agent-1.10.0/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-service-agent-3.1.3/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# cp -rf mcollective-shell-agent-0.0.2/lib/mcollective/* mcollective/
</span><span class='line'>[root@hadoop-master1 mcollective]# rm -rf mcollective-*
</span><span class='line'>
</span><span class='line'># 验证
</span><span class='line'>[root@hadoop-master1 mcollective]# mco help
</span><span class='line'>The Marionette Collective version 2.8.8
</span><span class='line'>
</span><span class='line'>  completion      Helper for shell completion systems
</span><span class='line'>  describe_filter Display human readable interpretation of filters
</span><span class='line'>  facts           Reports on usage for a specific fact
</span><span class='line'>  find            Find hosts using the discovery system matching filter criteria
</span><span class='line'>  help            Application list and help
</span><span class='line'>  inventory       General reporting tool for nodes, collectives and subcollectives
</span><span class='line'>  package         Install, uninstall, update, purge and perform other actions to packages
</span><span class='line'>  ping            Ping all nodes
</span><span class='line'>  plugin          MCollective Plugin Application
</span><span class='line'>  puppet          Schedule runs, enable, disable and interrogate the Puppet Agent
</span><span class='line'>  rpc             Generic RPC agent client application
</span><span class='line'>  service         Manages system services
</span><span class='line'>  shell           Run shell commands
</span><span class='line'>
</span><span class='line'># 同步
</span><span class='line'>[root@hadoop-master1 mcollective]# cd ..
</span><span class='line'>[root@hadoop-master1 libexec]# rsync -az mcollective hadoop-master2:/usr/libexec/
</span><span class='line'>
</span><span class='line'># filter
</span><span class='line'>[root@hadoop-master1 manifests]# mco shell run hostname -S "hostname=hadoop-master2"
</span><span class='line'>[root@hadoop-master1 manifests]# mco ping -S "not hostname=hadoop-master1"
</span><span class='line'>[root@hadoop-master1 manifests]# mco ping -S "! hostname=hadoop-master1"
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ sudo mco shell --sort -I /cu-ud[1234]{1}$/ run -- ' ls /home/ud/ftpxdr | wc -l  '
</span><span class='line'>
</span><span class='line'># 少配置了
</span><span class='line'>[root@hadoop-master1 manifests]# mco shell run "echo -e '\n\nplugin.puppet.command = /opt/puppetlabs/bin/puppet agent\nplugin.puppet.config = /etc/puppetlabs/puppet/puppet.conf' &gt;&gt; /etc/puppetlabs/mcollective/server.cfg" 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 重启 mcollective 服务
</span><span class='line'>[root@hadoop-master1 manifests]# mco shell run "echo service mcollective restart &gt;/tmp/mcollective_restart.sh ; nohup sh /tmp/mcollective_restart.sh "
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># ---
</span><span class='line'>[root@hadoop-master1 dtarepo]# mco rpc package install package=lrzsz -I cu-omc1
</span><span class='line'>[root@hadoop-master1 dtarepo]# mco rpc package install package=gmetad -I cu-omc1
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 gmond]# mco shell -I cu-ud2 run -- "/opt/puppetlabs/bin/puppet agent -t"
</span><span class='line'>[root@hadoop-master1 production]# mco shell -I /^cu-omc2/ run -- "/opt/puppetlabs/bin/puppet agent -t"
</span><span class='line'>
</span><span class='line'># gmond 多网卡情况确认
</span><span class='line'>[root@hadoop-master1 production]# route add -host 239.2.11.71 dev bond0
</span><span class='line'>
</span><span class='line'># puppet 基本语法
</span><span class='line'># https://docs.puppet.com/puppet/latest/reference/lang_conditional.html#if-statements
</span><span class='line'># https://docs.puppet.com/puppet/latest/reference/lang_relationships.html
</span><span class='line'>
</span><span class='line'># puppet使用tag可以更灵活的使用
</span><span class='line'># https://docs.puppet.com/puppet/latest/reference/lang_tags.html
</span><span class='line'>apache::vhost {'docs.puppetlabs.com':
</span><span class='line'>  port =&gt; 80,
</span><span class='line'>  tag  =&gt; ['us_mirror1', 'us_mirror2'],
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>$ sudo puppet agent --test --tags apache,us_mirror1
</span></code></pre></td></tr></table></div></figure>


<p>再次强调Filter ： <a href="https://docs.puppet.com/mcollective/reference/basic/basic_cli_usage.html#selecting-request-targets-using-filters">Selecting Request Targets Using Filters</a></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MCollective安装配置]]></title>
    <link href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/"/>
    <updated>2016-04-28T08:39:23+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/28/mcollective-quick-start</id>
    <content type="html"><![CDATA[<p>puppet agent 通过定时拉取的方式来更新本地系统，但无法满足实时更新的需求。 mcollective 通过 <strong>消息中间件</strong> 的方式，mclient/mservers通过消息的推送/订阅，实现mservers实时执行mclient提交的请求。（添加 m 说明是mcollective的组件！）</p>

<p>最新版的安装除了官网，没有其他可以直接学习的资料（只能参考）。先看官网的资料：</p>

<ul>
<li>组件功能(必须看看) <a href="https://docs.puppet.com/mcollective/overview_components.html">https://docs.puppet.com/mcollective/overview_components.html</a></li>
<li>部署 <a href="https://docs.puppet.com/mcollective/deploy/install.html">https://docs.puppet.com/mcollective/deploy/install.html</a></li>
<li>部署规范/准则 <a href="https://docs.puppet.com/mcollective/deploy/standard.html">https://docs.puppet.com/mcollective/deploy/standard.html</a></li>
</ul>


<p>摘录官网安装描述：[Installing MCollective requires the following steps]</p>

<ul>
<li>Make sure your middleware is up and running and your firewalls are in order.</li>
<li>Install the mcollective package on servers, then make sure the mcollective service is running.</li>
<li>Install the mcollective-client package on admin workstations.</li>
<li>Most Debian-like and Red Hat-like systems can use the official Puppet Labs packages. Enable the Puppet Labs repos, or import the packages into your own repos.

<ul>
<li>If you’re on Debian/Ubuntu, mind the missing package dependency.</li>
</ul>
</li>
<li>If your systems can’t use the official packages, check the system requirements and either build your own or run from source.</li>
</ul>


<p>mcollective对于puppet来说是一个锦上添花的组件，没有puppet一样正常运转。部署主要由两个部分组成：</p>

<ul>
<li>部署消息中间件</li>
<li>配置mcollective(puppet4.4 agent已经安装该功能，redhat也自带装了Stomp包：<code>/opt/puppetlabs/puppet/lib/ruby/gems/2.1.0/gems/</code> 目录下面)

<ul>
<li>配置mclient/mserver</li>
<li>配置Stomp with TLS</li>
<li>配置security</li>
</ul>
</li>
</ul>


<p>本文先简单实现连接远程主机，然后配置安全功能，最后用puppet来重新实现 mcollective 的安装和配置。</p>

<h1>环境说明</h1>

<ul>
<li>hadoop-master2:

<ul>
<li>172.17.42.1</li>
<li>puppetserver, activemq-server, mcollective-client</li>
</ul>
</li>
<li>hadoop-master1/hadoop-slaver1/hadoop-slaver2:

<ul>
<li>172.17.0.2/&frac34;</li>
<li>puppet-agent, mcollective-server</li>
</ul>
</li>
</ul>


<h1>ActiveMQ部署</h1>

<p>activemq的服务端是一个spring-jetty项目，直接解压运行启动脚本即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># http://activemq.apache.org/download-archives.html
</span><span class='line'># 直接下载最新的 tar.gz
</span><span class='line'>
</span><span class='line'># 解压，启动
</span><span class='line'>On Unix:
</span><span class='line'>From a command shell, change to the installation directory and run ActiveMQ as a foregroud process:
</span><span class='line'>cd [activemq_install_dir]/bin
</span><span class='line'>./activemq console
</span><span class='line'>From a command shell, change to the installation directory and run ActiveMQ as a daemon process:
</span><span class='line'>cd [activemq_install_dir]/bin
</span><span class='line'>./activemq start
</span><span class='line'>
</span><span class='line'># 确认
</span><span class='line'>URL: http://127.0.0.1:8161/admin/
</span><span class='line'>Login: admin
</span><span class='line'>Passwort: admin
</span><span class='line'># 起了好多端口，随便试一个
</span><span class='line'>netstat -nl|grep 61616
</span><span class='line'>netstat -anp|grep PID
</span><span class='line'>
</span><span class='line'># 数据/日志目录
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# ll data/
</span><span class='line'>total 16
</span><span class='line'>-rw-r--r-- 1 root users 4276 Apr 27 21:36 activemq.log
</span><span class='line'>-rw-r--r-- 1 root root     5 Apr 27 21:36 activemq.pid
</span><span class='line'>-rw-r--r-- 1 root root     0 Apr 27 21:36 audit.log
</span><span class='line'>drwxr-xr-x 2 root root  4096 Apr 27 21:36 kahadb</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/mcollective-activemq.png" alt="" /></p>

<p>查看连接密码：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 conf]# cat credentials.properties
</span><span class='line'>...
</span><span class='line'>activemq.username=system
</span><span class='line'>activemq.password=manager
</span><span class='line'>guest.password=password[root@hadoop-master2 conf]# 
</span></code></pre></td></tr></table></div></figure>


<h1>简单配置(unencrypted Stomp) <a name="cli-simple-usage"></a></h1>

<p>安装puppet4.4后，mcollective已经安装好了！直接修改配置连接到activemq即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 puppetlabs]# chkconfig --list | grep mco
</span><span class='line'>mcollective     0:off   1:off   2:off   3:off   4:off   5:off   6:off
</span><span class='line'>
</span><span class='line'># puppetserver作为mcollective-client
</span><span class='line'>[root@hadoop-master2 mcollective]# cat client.cfg                    
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61613
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>No responses received
</span><span class='line'>
</span><span class='line'># puppet agent作为mcollective-server
</span><span class='line'>-bash-4.1# cat server.cfg 
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61613
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>-bash-4.1# service mcollective start
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>-bash-4.1# service mcollective status
</span><span class='line'>mcollectived (pid  202) is running...
</span><span class='line'>
</span><span class='line'># 其他两台agent机器一样的配置操作
</span><span class='line'>
</span><span class='line'># 1. mcollective-client(puppetserver) 测试
</span><span class='line'>[root@hadoop-master2 ~]# mco find
</span><span class='line'>hadoop-master1
</span><span class='line'>hadoop-slaver2
</span><span class='line'>hadoop-slaver1
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping
</span><span class='line'>hadoop-master1                           time=148.29 ms
</span><span class='line'>hadoop-slaver2                           time=187.99 ms
</span><span class='line'>hadoop-slaver1                           time=190.21 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 190.21 min: 148.29 avg: 175.50 
</span><span class='line'>
</span><span class='line'># 2. 先查看/扫描节点状态。（如果配置了facts后，会输出一长串的Facts！）
</span><span class='line'>[root@hadoop-master2 ssl]# mco inventory hadoop-master1
</span><span class='line'>Inventory for hadoop-master1:
</span><span class='line'>
</span><span class='line'>   Server Statistics:
</span><span class='line'>                      Version: 2.8.8
</span><span class='line'>                   Start Time: 2016-04-29 00:21:31 +0800
</span><span class='line'>                  Config File: /etc/puppetlabs/mcollective/server.cfg
</span><span class='line'>                  Collectives: mcollective
</span><span class='line'>              Main Collective: mcollective
</span><span class='line'>                   Process ID: 155
</span><span class='line'>               Total Messages: 13
</span><span class='line'>      Messages Passed Filters: 3
</span><span class='line'>            Messages Filtered: 0
</span><span class='line'>             Expired Messages: 0
</span><span class='line'>                 Replies Sent: 2
</span><span class='line'>         Total Processor Time: 2.32 seconds
</span><span class='line'>                  System Time: 0.3 seconds
</span><span class='line'>
</span><span class='line'>   Agents:
</span><span class='line'>      discovery       rpcutil                        
</span><span class='line'>
</span><span class='line'>   Data Plugins:
</span><span class='line'>      agent           collective      fact           
</span><span class='line'>      fstat                                          
</span><span class='line'>
</span><span class='line'>   Configuration Management Classes:
</span><span class='line'>      No classes applied
</span><span class='line'>
</span><span class='line'>   Facts:
</span><span class='line'>      mcollective =&gt; 1
</span><span class='line'>
</span><span class='line'># 3. 获取节点facts，需要配合puppet一起来使用
</span><span class='line'># puppetserver节点 配置更新agent facts.yaml信息
</span><span class='line'>[root@hadoop-master2 manifests]# cat site.pp 
</span><span class='line'>file{'/etc/puppetlabs/mcollective/facts.yaml':
</span><span class='line'>  owner    =&gt; root,
</span><span class='line'>  group    =&gt; root,
</span><span class='line'>  mode     =&gt; '400',
</span><span class='line'>  loglevel =&gt; debug, # reduce noise in Puppet reports
</span><span class='line'>  content  =&gt; inline_template("&lt;%= scope.to_hash.reject { |k,v| k.to_s =~ /(uptime_seconds|timestamp|free)/ }.to_yaml %&gt;"), # exclude rapidly changing facts
</span><span class='line'>}
</span><span class='line'># 读取facts
</span><span class='line'>[root@hadoop-master2 manifests]# mco facts hostname
</span><span class='line'>Report for fact: hostname
</span><span class='line'>
</span><span class='line'>        hadoop-master1                           found 1 times
</span><span class='line'>        hadoop-slaver1                           found 1 times
</span><span class='line'>        hadoop-slaver2                           found 1 times
</span><span class='line'>
</span><span class='line'>Finished processing 3 / 3 hosts in 579.93 ms
</span></code></pre></td></tr></table></div></figure>


<p>自带的插件功能比较少，要真正把 mcollective 用起来需要安装插件：puppet, service, package等等。这篇主要记录安装过程，<a href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/">插件安装以及使用</a>后面具体实践了再写。</p>

<p>我觉得内网生产环境安装，到这一步已经差不多了！下面的安全配置就当深入学习吧。</p>

<h1>Stomp with TLS 配置</h1>

<ul>
<li><a href="https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html">https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html">https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html</a></li>
</ul>


<p><strong>Anonymous TLS</strong> 步骤简单一点，这里就不列出来了，自己去看官网的文档: <a href="https://docs.puppet.com/mcollective/reference/integration/activemq_ssl.html#anonymous-tls">Anonymous TLS</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># CA-Verified TLS
</span><span class='line'>
</span><span class='line'># 1 手动配置activemq
</span><span class='line'>
</span><span class='line'># 1.1 可以直接用puppet的cert/private-keys，我这里新生成一个activemq的证书
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet master --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'># 一个不冲突的名称即可，不需要是hostname/FQDN
</span><span class='line'>[root@hadoop-master2 puppetlabs]# puppet cert generate activemq
</span><span class='line'>Notice: activemq has a waiting certificate request
</span><span class='line'>Notice: Signed certificate request for activemq
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest activemq at '/etc/puppetlabs/puppet/ssl/ca/requests/activemq.pem'
</span><span class='line'>Notice: Removing file Puppet::SSL::CertificateRequest activemq at '/etc/puppetlabs/puppet/ssl/certificate_requests/activemq.pem'
</span><span class='line'>[root@hadoop-master2 puppetlabs]# tree /etc/puppetlabs/puppet/ssl/
</span><span class='line'>/etc/puppetlabs/puppet/ssl/
</span><span class='line'>...
</span><span class='line'>├── certificate_requests
</span><span class='line'>├── certs
</span><span class='line'>│   ├── activemq.pem
</span><span class='line'>│   ├── ca.pem
</span><span class='line'>│   └── hadoop-master2.example.com.pem
</span><span class='line'>├── crl.pem
</span><span class='line'>├── private
</span><span class='line'>├── private_keys
</span><span class='line'>│   ├── activemq.pem
</span><span class='line'>│   └── hadoop-master2.example.com.pem
</span><span class='line'>└── public_keys
</span><span class='line'>    ├── activemq.pem
</span><span class='line'>    └── hadoop-master2.example.com.pem
</span><span class='line'>
</span><span class='line'>9 directories, 22 files
</span><span class='line'>
</span><span class='line'># certs/activemq.pem, certs/ca.pem, private_keys/activemq.pem 就是我们需要的。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.2 创建Truststore
</span><span class='line'>[root@hadoop-master2 puppetlabs]# which keytool
</span><span class='line'>/opt/jdk1.7.0_60/bin/keytool
</span><span class='line'>[root@hadoop-master2 puppetlabs]# cd /etc/puppetlabs/puppet/ssl            
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -import -alias "CU CA" -file certs/ca.pem -keystore truststore.jks
</span><span class='line'>Enter keystore password:  
</span><span class='line'>Re-enter new password: 
</span><span class='line'>Owner: CN=Puppet CA: hadoop-master2.example.com
</span><span class='line'>Issuer: CN=Puppet CA: hadoop-master2.example.com
</span><span class='line'>...
</span><span class='line'>Trust this certificate? [no]:  y
</span><span class='line'>Certificate was added to keystore
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 32
</span><span class='line'>drwxr-xr-x 5 puppet puppet 4096 Apr 23 00:01 ca
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 certificate_requests
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 certs
</span><span class='line'>-rw-r--r-- 1 puppet puppet  979 Apr 28 10:33 crl.pem
</span><span class='line'>drwxr-x--- 2 puppet puppet 4096 Apr 22 23:51 private
</span><span class='line'>drwxr-x--- 2 puppet puppet 4096 Apr 28 19:53 private_keys
</span><span class='line'>drwxr-xr-x 2 puppet puppet 4096 Apr 28 19:53 public_keys
</span><span class='line'>-rw-r--r-- 1 root   root   1496 Apr 28 20:01 truststore.jks
</span><span class='line'># 验证下指纹fingerprints
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -list -keystore truststore.jks 
</span><span class='line'>Enter keystore password:  
</span><span class='line'>
</span><span class='line'>Keystore type: JKS
</span><span class='line'>Keystore provider: SUN
</span><span class='line'>
</span><span class='line'>Your keystore contains 1 entry
</span><span class='line'>
</span><span class='line'>cu ca, Apr 28, 2016, trustedCertEntry, 
</span><span class='line'>Certificate fingerprint (SHA1): 40:2C:45:37:6B:C7:9C:92:E7:4D:1E:4F:2B:C4:17:F4:A3:5F:EB:56
</span><span class='line'>[root@hadoop-master2 ssl]# openssl x509 -in certs/ca.pem -fingerprint -sha1
</span><span class='line'>SHA1 Fingerprint=40:2C:45:37:6B:C7:9C:92:E7:4D:1E:4F:2B:C4:17:F4:A3:5F:EB:56
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.3 创建Keystore
</span><span class='line'>[root@hadoop-master2 ssl]# cat private_keys/activemq.pem certs/activemq.pem &gt;activemq.pem
</span><span class='line'># 所有密码都需一致！！ All of these passwords must be the same.
</span><span class='line'>[root@hadoop-master2 ssl]# openssl pkcs12 -export -in activemq.pem -out activemq.p12 -name activemq      
</span><span class='line'>Enter Export Password:
</span><span class='line'>Verifying - Enter Export Password:
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -importkeystore -destkeystore keystore.jks -srckeystore activemq.p12 \
</span><span class='line'>&gt; -srcstoretype PKCS12 -alias activemq
</span><span class='line'>Enter destination keystore password:  XXX
</span><span class='line'>Re-enter new password: XXX
</span><span class='line'>Enter source keystore password:  XXX
</span><span class='line'>[root@hadoop-master2 ssl]# ll -t
</span><span class='line'>total 52
</span><span class='line'>-rw-r--r-- 1 root   root   3918 Apr 28 20:12 keystore.jks
</span><span class='line'>-rw-r--r-- 1 root   root   4230 Apr 28 20:08 activemq.p12
</span><span class='line'>-rw-r--r-- 1 root   root   5203 Apr 28 20:07 activemq.pem
</span><span class='line'>-rw-r--r-- 1 root   root   1496 Apr 28 20:01 truststore.jks
</span><span class='line'>...
</span><span class='line'># 验证指纹
</span><span class='line'>[root@hadoop-master2 ssl]# keytool -list -keystore keystore.jks 
</span><span class='line'>Enter keystore password:  
</span><span class='line'>
</span><span class='line'>Keystore type: JKS
</span><span class='line'>Keystore provider: SUN
</span><span class='line'>
</span><span class='line'>Your keystore contains 1 entry
</span><span class='line'>
</span><span class='line'>activemq, Apr 28, 2016, PrivateKeyEntry, 
</span><span class='line'>Certificate fingerprint (SHA1): 4F:DF:DE:64:13:36:0E:74:8B:7F:D3:61:78:29:C4:AA:4F:A4:ED:D8
</span><span class='line'>[root@hadoop-master2 ssl]# openssl x509 -in certs/activemq.pem -fingerprint -sha1
</span><span class='line'>SHA1 Fingerprint=4F:DF:DE:64:13:36:0E:74:8B:7F:D3:61:78:29:C4:AA:4F:A4:ED:D8
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 1.4 配置activemq
</span><span class='line'># http://activemq.apache.org/how-do-i-use-ssl.html
</span><span class='line'># https://docs.puppet.com/mcollective/deploy/middleware/activemq.html#tls-credentials
</span><span class='line'># https://docs.puppet.com/mcollective/deploy/middleware/activemq.html#stomp
</span><span class='line'>[root@hadoop-master2 ssl]# mv keystore.jks truststore.jks /opt/puppetlabs/apache-activemq-5.13.2/conf
</span><span class='line'>[root@hadoop-master2 ssl]# cd /opt/puppetlabs/apache-activemq-5.13.2/conf/
</span><span class='line'># 填上面步骤设置的密码
</span><span class='line'>[root@hadoop-master2 conf]# vi activemq.xml 
</span><span class='line'>...
</span><span class='line'>&lt;sslContext&gt;
</span><span class='line'>  &lt;sslContext keyStore="keystore.jks" keyStorePassword="XXXX"
</span><span class='line'>              trustStrore="truststore.jks" trustStorePassword="XXXX" /&gt;
</span><span class='line'>&lt;/sslContext&gt;
</span><span class='line'>
</span><span class='line'>&lt;transportConnectors&gt;
</span><span class='line'>  &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt;
</span><span class='line'>  &lt;transportConnector name="stomp+nio+ssl" uri="stomp+nio+ssl://0.0.0.0:61614?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600&amp;needClientAuth=true&amp;transport.enabledProtocols=TLSv1,TLSv1.1,TLSv1.2"/&gt;
</span><span class='line'>&lt;/transportConnectors&gt;
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# chmod 600 conf/activemq.xml 
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# bin/activemq stop
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# bin/activemq start
</span><span class='line'># 日志查看
</span><span class='line'>[root@hadoop-master2 apache-activemq-5.13.2]# less data/activemq.log 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 2 puppetserver(mcollective client)
</span><span class='line'># https://docs.puppet.com/mcollective/configure/client.html
</span><span class='line'>[root@hadoop-master2 ~]# cd /etc/puppetlabs/mcollective/
</span><span class='line'>[root@hadoop-master2 mcollective]# cat client.cfg
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61614
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>plugin.activemq.pool.1.ssl = true
</span><span class='line'>plugin.activemq.pool.1.ssl.ca = /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.key = /etc/puppetlabs/puppet/ssl/private_keys/hadoop-master2.example.com.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.cert = /etc/puppetlabs/puppet/ssl/certs/hadoop-master2.example.com.pem
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping -v
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>No responses received
</span><span class='line'>
</span><span class='line'># 3 puppet agents(mcollective servers)
</span><span class='line'># https://docs.puppet.com/mcollective/configure/server.html
</span><span class='line'>-bash-4.1# puppet agent --configprint confdir
</span><span class='line'>/etc/puppetlabs/puppet
</span><span class='line'>-bash-4.1# puppet agent --configprint ssldir
</span><span class='line'>/etc/puppetlabs/puppet/ssl
</span><span class='line'>-bash-4.1# puppet agent --configprint hostprivkey
</span><span class='line'>/etc/puppetlabs/puppet/ssl/private_keys/hadoop-master1.example.com.pem
</span><span class='line'>-bash-4.1# puppet agent --configprint hostcert
</span><span class='line'>/etc/puppetlabs/puppet/ssl/certs/hadoop-master1.example.com.pem
</span><span class='line'>-bash-4.1# puppet agent --configprint localcacert
</span><span class='line'>/etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>
</span><span class='line'>-bash-4.1# cd /etc/puppetlabs/mcollective/
</span><span class='line'>-bash-4.1# cat server.cfg 
</span><span class='line'>...
</span><span class='line'>connector = activemq
</span><span class='line'>plugin.activemq.pool.size = 1
</span><span class='line'>plugin.activemq.pool.1.host = hadoop-master2.example.com
</span><span class='line'>plugin.activemq.pool.1.port = 61614
</span><span class='line'>plugin.activemq.pool.1.user = system
</span><span class='line'>plugin.activemq.pool.1.password = manager
</span><span class='line'>plugin.activemq.pool.1.ssl = true
</span><span class='line'>plugin.activemq.pool.1.ssl.ca = /etc/puppetlabs/puppet/ssl/certs/ca.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.key = /etc/puppetlabs/puppet/ssl/private_keys/hadoop-master1.example.com.pem
</span><span class='line'>plugin.activemq.pool.1.ssl.cert = /etc/puppetlabs/puppet/ssl/certs/hadoop-master1.example.com.pem
</span><span class='line'>...
</span><span class='line'>-bash-4.1# service mcollective restart
</span><span class='line'>Shutting down mcollective: 
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'>
</span><span class='line'># 其他两台机器一样的操作
</span><span class='line'>
</span><span class='line'># 测试
</span><span class='line'>[root@hadoop-master2 mcollective]# mco ping -v
</span><span class='line'>hadoop-master1                           time=41.99 ms
</span><span class='line'>hadoop-slaver2                           time=84.87 ms
</span><span class='line'>hadoop-slaver1                           time=85.46 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 85.46 min: 41.99 avg: 70.77 
</span></code></pre></td></tr></table></div></figure>


<p>更多activemq的设置查看官方文档： <a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq.html">ActiveMQ Config Reference for MCollective Users</a> <a href="https://raw.github.com/puppetlabs/marionette-collective/master/ext/activemq/examples/single-broker/activemq.xml">example activemq.xml</a></p>

<h1>SSL Security plugin</h1>

<p>Stomp with TLS (安全传输层协议)用于加密数据。而 security plugin 主要功能有：</p>

<ul>
<li>mcollective server要授权才会执行 client 发送的请求。</li>
<li>create a token that uniquely identify the client - based on the filename of the public key。</li>
<li>在请求中添加创建时间和TTL保证数据的完整性(不被拦截、篡改以及重复)。</li>
</ul>


<p>参考：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/configure/client.html#security-plugin-settings">https://docs.puppet.com/mcollective/configure/client.html#security-plugin-settings</a></li>
<li><a href="https://docs.puppet.com/mcollective/security.html">https://docs.puppet.com/mcollective/security.html</a></li>
<li><a href="https://docs.puppet.com/mcollective/reference/plugins/security_ssl.html">https://docs.puppet.com/mcollective/reference/plugins/security_ssl.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 1 生成server秘钥(公钥、私钥)
</span><span class='line'>[root@hadoop-master2 mcollective-security]# openssl genrsa -out server-private.pem 1024
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 mcollective-security]# openssl rsa -in server-private.pem -out server-public.pem -outform PEM -pubout  
</span><span class='line'>writing RSA key
</span><span class='line'>[root@hadoop-master2 mcollective-security]# ll
</span><span class='line'>total 12
</span><span class='line'>-rw-r--r-- 1 root root 7915 Apr 29 00:06 server-private.pem
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:07 server-public.pem
</span><span class='line'>
</span><span class='line'># 把 private/public 复制到所有的mcollective-servers节点
</span><span class='line'># 把 public 复制到mcollective-clients节点
</span><span class='line'>[root@hadoop-master2 mcollective-security]# ssh 172.17.0.2 mkdir -p /etc/puppetlabs/mcollective/ssl/clients
</span><span class='line'>[root@hadoop-master2 mcollective-security]# scp * 172.17.0.2:/etc/puppetlabs/mcollective/ssl/
</span><span class='line'>server-private.pem   100% 7915     7.7KB/s   00:00    
</span><span class='line'>server-public.pem    100% 1836     1.8KB/s   00:00    
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 mcollective-security]# mkdir -p /etc/puppetlabs/mcollective/ssl
</span><span class='line'>[root@hadoop-master2 mcollective-security]# cp server-public.pem /etc/puppetlabs/mcollective/ssl/
</span><span class='line'>
</span><span class='line'># 2 配置mcollective-servers。节点间配置不能同步，TLS配置的证书名称是不一样的！！
</span><span class='line'>-bash-4.1# vi /etc/puppetlabs/mcollective/server.cfg 
</span><span class='line'>...
</span><span class='line'># Plugins
</span><span class='line'>#securityprovider = psk
</span><span class='line'>#plugin.psk = unset
</span><span class='line'>
</span><span class='line'>securityprovider = ssl
</span><span class='line'>plugin.ssl_server_private = /etc/puppetlabs/mcollective/ssl/server-private.pem
</span><span class='line'>plugin.ssl_server_public = /etc/puppetlabs/mcollective/ssl/server-public.pem
</span><span class='line'>plugin.ssl_client_cert_dir = /etc/puppetlabs/mcollective/ssl/clients/
</span><span class='line'>plugin.ssl.enfore_ttl = 0
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>-bash-4.1# service mcollective restart
</span><span class='line'>Shutting down mcollective:                                 [  OK  ]
</span><span class='line'>Starting mcollective:                                      [  OK  ]
</span><span class='line'># 可以通过 /var/log/puppetlabs/mcollective.log 查看详细日志
</span><span class='line'>
</span><span class='line'># 配置一个节点后，mco ping已经不再显示hadoop-master1了！！
</span><span class='line'>
</span><span class='line'># 3 生成client秘钥
</span><span class='line'>[root@hadoop-master2 mcollective-security]# cd /etc/puppetlabs/mcollective/ssl
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x 2 root root 4096 Apr 29 00:15 clients
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:15 server-public.pem
</span><span class='line'>[root@hadoop-master2 ssl]# openssl genrsa -out winse-private.pem 1024    
</span><span class='line'>...
</span><span class='line'>[root@hadoop-master2 ssl]# openssl rsa -in winse-private.pem -out winse-public.pem -outform PEM -pubout
</span><span class='line'>writing RSA key
</span><span class='line'>[root@hadoop-master2 ssl]# ll
</span><span class='line'>total 16
</span><span class='line'>drwxr-xr-x 2 root root 4096 Apr 29 00:15 clients
</span><span class='line'>-rw-r--r-- 1 root root 1836 Apr 29 00:15 server-public.pem
</span><span class='line'>-rw-r--r-- 1 root root  887 Apr 29 00:26 winse-private.pem
</span><span class='line'>-rw-r--r-- 1 root root  272 Apr 29 00:26 winse-public.pem
</span><span class='line'>
</span><span class='line'># 把client用户的公钥拷贝到所有mcollective-servers的ssl/clients目录下
</span><span class='line'>[root@hadoop-master2 ssl]# scp winse-public.pem 172.17.0.2:/etc/puppetlabs/mcollective/ssl/clients
</span><span class='line'>winse-public.pem 100%  272     0.3KB/s   00:00    
</span><span class='line'>
</span><span class='line'># 4 配置clients
</span><span class='line'>[root@hadoop-master2 ~]# vi /etc/puppetlabs/mcollective/client.cfg 
</span><span class='line'>...
</span><span class='line'># Plugins
</span><span class='line'>#securityprovider = psk
</span><span class='line'>#plugin.psk = unset
</span><span class='line'>securityprovider = ssl
</span><span class='line'>plugin.ssl_server_public = /etc/puppetlabs/mcollective/ssl/server-public.pem
</span><span class='line'>plugin.ssl_client_private = /etc/puppetlabs/mcollective/ssl/winse-private.pem
</span><span class='line'>plugin.ssl_client_public = /etc/puppetlabs/mcollective/ssl/winse-public.pem
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'># mcollective-server不需要重启！客户端连接测试
</span><span class='line'>[root@hadoop-master2 ssl]# mco ping -v
</span><span class='line'>hadoop-master1                           time=561.29 ms
</span><span class='line'>hadoop-slaver2                           time=601.91 ms
</span><span class='line'>hadoop-slaver1                           time=608.31 ms
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>---- ping statistics ----
</span><span class='line'>3 replies max: 608.31 min: 561.29 avg: 590.50 
</span></code></pre></td></tr></table></div></figure>


<p>理解了功能后，再按条理配置其实感觉就不是那么难了。遇到问题先查看日志！！</p>

<h1>最佳实践</h1>

<p>官网推荐使用 站点管理工具 统一来安装管理，如puppet。下面使用puppet来配置mcollective：</p>

<ul>
<li><a href="https://docs.puppet.com/mcollective/deploy/install.html#example">https://docs.puppet.com/mcollective/deploy/install.html#example</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html#creating-keystores-with-puppet">https://docs.puppet.com/mcollective/deploy/middleware/activemq_keystores.html#creating-keystores-with-puppet</a></li>
<li><a href="https://docs.puppet.com/mcollective/deploy/standard.html#write-the-server-config-file">https://docs.puppet.com/mcollective/deploy/standard.html#write-the-server-config-file</a></li>
</ul>


<p>TODO</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[整理] Hadoop入门]]></title>
    <link href="http://winseliu.com/blog/2016/04/23/hadoop-guide-catalog/"/>
    <updated>2016-04-23T15:45:34+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/23/hadoop-guide-catalog</id>
    <content type="html"><![CDATA[<h2>1. 环境准备</h2>

<p>工欲善事其必先利其器。不要吝啬硬件上投入，找一个适合自己的环境！</p>

<ul>
<li>Windows

<ul>
<li><a href="http://winseliu.com/blog/2014/02/23/quickly-open-program-in-windows/">快速打开程序</a></li>
<li>Cygwin：Windows本地编译需要，执行命令比 cmd 更方便</li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2011/02/28/win7-install-fedora-linux/">Windows + Linux双系统</a></li>
<li>Linux

<ul>
<li><a href="http://winseliu.com/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a></li>
<li><a href="http://winseliu.com/blog/2015/09/13/review-linux-101-hacks/">【linux 101 Hacks】读后感</a>

<ul>
<li><a href="http://winseliu.com/images/blogs/linux-101-hacks-review-securecrt-config.png">Socket5代理</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/03/11/install-and-config-openvpn/">OpenVPN</a></li>
<li>docker

<ul>
<li><a href="http://winseliu.com/blog/2014/09/27/docker-start-guide-on-centos/">Docker入门</a></li>
<li><a href="http://winseliu.com/blog/2014/09/30/docker-ssh-on-centos/">配置ssh</a></li>
<li><a href="http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster/">Dnsmasq</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>2. 安装部署hadoop/spark</h2>

<h4>编译安装</h4>

<ul>
<li>Hadoop安装与升级:

<ul>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/">Docker中安装</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/">2.2升级到2.6</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/">HA配置</a></li>
<li><a href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/">HA升级</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6/">Centos6 Build hadoop2.6</a></li>
<li><a href="http://winseliu.com/blog/2015/03/09/windows-build-hadoop-2-dot-6/">Windows Build hadoop2.6</a></li>
<li><a href="http://winseliu.com/blog/2014/10/16/spark-build-and-configuration/">各版本Spark编译/搭建环境</a></li>
</ul>


<h4>功能优化</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/01/hadoop2-mapreduce-compress/">Hadoop2 Mapreduce输入输出压缩</a></li>
<li><a href="http://winseliu.com/blog/2014/07/29/hadoop2-use-shortcircuit-local-reading/">Hadoop2 ShortCircuit Local Reading</a></li>
<li><a href="http://winseliu.com/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>

<ul>
<li><a href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/05/05/hdfs-heterogeneous-storage.markdown">HDFS RamDisk内存缓冲</a></li>
</ul>


<h4>维护</h4>

<ul>
<li><a href="http://winseliu.com/blog/2013/02/22/hadoop-cluster-increases-nodes/">Hadoop集群增加节点</a></li>
<li><a href="http://winseliu.com/blog/2014/07/29/safely-remove-datanode/">安全的关闭datanode</a></li>
<li><a href="http://winseliu.com/blog/2015/03/25/deploy-separated-yarn-on-exists-hdfs-cluster/">已有HDFS上部署yarn</a></li>
<li><a href="http://winseliu.com/blog/2015/06/10/hadoop-deploy-spark-diff-version-yarn-and-hdfs/">Hadoop不同版本yarn和hdfs混搭，spark-yarn环境配置</a></li>
</ul>


<h4>旧版本安装</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a></li>
<li><a href="http://winseliu.com/blog/2013/03/24/pseudo-distributed-hadoop-in-windows/"><del>Windows配置hadoop伪分布式环境(续)</del></a> 不再推荐cygwin下部署Hadoop。</li>
<li><a href="http://winseliu.com/blog/2013/03/02/quickly-build-a-second-hadoop-cluster/">快速搭建第二个hadoop分布式集群环境</a></li>
<li><a href="http://winseliu.com/blog/2013/03/27/run-on-hadoop-on-ant/"><del>Ant实现hadoop插件Run-on-Hadoop</del></a></li>
</ul>


<h2>3. 进阶</h2>

<h4>配置深入理解</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/08/02/hadoop-datanode-config-should-equals/">Hadoop的datanode数据节点机器配置</a></li>
<li><a href="http://winseliu.com/blog/2016/03/17/hadoop-memory-opts-and-args/">Hadoop内存环境变量和参数</a></li>
<li><a href="http://winseliu.com/blog/2016/04/11/spark-on-yarn-memory-allocate/">Spark-on-yarn内存分配</a></li>
<li><a href="http://winseliu.com/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn/">SparkSQL-on-YARN的Executors池(动态)配置</a></li>
</ul>


<h4>问题定位</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/17/windows-hadoop2-test-your-mapreduce-feature/">在windows开发测试mapreduce几种方式</a></li>
<li><a href="http://winseliu.com/blog/2014/04/22/remote-debug-hadoop2/">远程调试hadoop2以及错误处理方法</a></li>
<li><a href="http://winseliu.com/blog/2014/08/25/step-by-step-found-java-oom-error/">逐步定位Java程序OOM的异常</a></li>
</ul>


<h4>读码</h4>

<ul>
<li>Hadoop2 Balancer磁盘空间平衡

<ul>
<li><a href="http://winseliu.com/blog/2014/08/06/read-hadoop-balancer-source-part1/">上</a></li>
<li><a href="http://winseliu.com/blog/2014/09/05/read-hadoop-balancer-source-part2/">中</a></li>
<li><a href="http://winseliu.com/blog/2014/09/05/read-hadoop-balancer-source-part3/">下</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2015/03/13/hadoop-distcp/">Hadoop Distcp</a></li>
</ul>


<h4>其他</h4>

<ul>
<li><a href="http://winseliu.com/blog/2014/09/12/scala-wordcount-on-hadoop/">Scala Wordcount on Hadoop2</a></li>
<li><a href="http://winseliu.com/blog/2014/12/07/hadoop-mr-rest-api/">MR Rest接口</a></li>
</ul>


<h2>4. Hadoop平台</h2>

<ul>
<li>zookeeper</li>
<li>hive

<ul>
<li><a href="http://winseliu.com/blog/2014/06/21/upgrade-hive/">Upgrade Hive: 0.12.0 to 0.13.1</a></li>
<li>tez:

<ul>
<li><a href="http://winseliu.com/blog/2014/06/18/hadoop-tez-firststep/">Tez编译及使用</a></li>
<li><a href="http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run/">配置TEZ-UI</a></li>
</ul>
</li>
<li>hive on spark

<ul>
<li><a href="http://winseliu.com/blog/2016/03/28/hive-on-spark/">Hive on Spark</a></li>
<li><a href="http://winseliu.com/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a></li>
<li><a href="http://winseliu.com/blog/2016/03/29/limit-on-sparksql-and-hive/">Limit on Sparksql and Hive</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/04/08/dbcp-parameters/">DBCP参数在Hive JDBC上的实践</a></li>
<li><a href="http://winseliu.com/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0/">Hiveserver2 Ui and Upgrade hive2.0.0</a></li>
</ul>
</li>
<li>kafka

<ul>
<li><a href="http://winseliu.com/blog/2015/01/08/kafka-guide/">Kafka快速入门</a></li>
</ul>
</li>
<li>alluxio(tachyon)

<ul>
<li><a href="http://winseliu.com/blog/2015/04/15/tachyon-quickstart/">Tachyon入门指南</a></li>
<li><a href="http://winseliu.com/blog/2015/04/18/tachyon-deep-source/">Tachyon剖析</a></li>
<li><a href="http://winseliu.com/blog/2016/04/15/alluxio-quickstart2/">Alluxio入门大全2</a></li>
</ul>
</li>
</ul>


<h2>5. 监控与自动化部署</h2>

<h4>监控</h4>

<ul>
<li><a href="http://winseliu.com/blog/2013/02/26/linux-top-command-mannual/">top</a></li>
<li>nagios

<ul>
<li><a href="http://winseliu.com/blog/2015/09/25/nagios-start-guide/">Nagios监控主机</a></li>
</ul>
</li>
<li><del>cacti</del>    Ganglia更简单

<ul>
<li><a href="http://winseliu.com/blog/2015/09/22/cacti-start-guide/">Cacti监控主机</a></li>
<li><a href="http://winseliu.com/blog/2015/10/13/cacti-batch-adding-configurations/">Cacti批量添加配置</a></li>
</ul>
</li>
<li>ganglia

<ul>
<li><a href="http://winseliu.com/blog/2014/07/18/install-ganglia-on-redhat/"><del>Install Ganglia on Redhat5+</del></a> 手动安装依赖太麻烦了！</li>
<li><a href="http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a></li>
<li><a href="http://winseliu.com/blog/2016/02/01/ganglia-python-extension/">Ganglia扩展-Python</a></li>
<li><a href="http://winseliu.com/blog/2016/02/25/ganglia-web-ui-views/">Ganglia页自定义视图</a></li>
</ul>
</li>
</ul>


<h4>自动化</h4>

<ul>
<li>git:

<ul>
<li><a href="http://winseliu.com/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a></li>
<li><a href="http://winseliu.com/blog/2014/02/19/maven-package-dependent-git-projects/">打包依赖的git项目</a></li>
<li><a href="http://winseliu.com/blog/2013/05/27/handle-git-conflict/">处理git冲突</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2014/09/07/expect-automate-and-batch-config-ssh/">expect-批量实现SSH无密钥登录</a></li>
<li>puppet

<ul>
<li><a href="http://winseliu.com/blog/2016/04/08/puppet-install/">puppet4.4.1入门安装</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppet-domain-fdqn/">puppet入门之域名证书</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppetdb-install-and-config/">puppetdb安装配置</a>

<ul>
<li><a href="http://winseliu.com/blog/2015/12/13/postgresql-start-guide/">postgresql入门</a></li>
</ul>
</li>
<li>puppet-ui

<ul>
<li><a href="http://winseliu.com/blog/2016/05/05/puppetboard-install/">puppetboard安装</a></li>
<li><a href="http://winseliu.com/blog/2016/04/21/puppetexplorer-setting/">puppetexplorer设置</a></li>
<li>foreman</li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/">RPM打包</a></li>
<li>puppet基本使用以及配置集群</li>
<li>mcollective

<ul>
<li><a href="http://winseliu.com/blog/2016/04/28/mcollective-quick-start/">安装配置</a></li>
<li><a href="http://winseliu.com/blog/2016/04/28/mcollective-plugins/">插件安装</a></li>
</ul>
</li>
<li><a href="http://winseliu.com/blog/2016/05/03/hiera-and-facts/">Hiera</a></li>
</ul>
</li>
</ul>


<p>&hellip;</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
