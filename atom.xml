<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2017-10-08T10:55:57+00:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Docker多主机网络配置 - Macvlan]]></title>
    <link href="http://winseliu.com/blog/2017/10/08/docker-network-via-macvlan/"/>
    <updated>2017-10-08T02:27:54+00:00</updated>
    <id>http://winseliu.com/blog/2017/10/08/docker-network-via-macvlan</id>
    <content type="html"><![CDATA[<h2>参考</h2>

<ul>
<li><a href="https://docs.docker.com/engine/userguide/networking/get-started-macvlan/#macvlan-bridge-mode-example-usage">Get started with Macvlan network driver</a></li>
<li><a href="https://github.com/alfredhuang211/study-docker-doc/blob/master/docker%E8%B7%A8%E4%B8%BB%E6%9C%BAmacvlan%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE.md">docker跨主机macvlan网络配置</a></li>
<li><a href="https://blog.jessfraz.com/post/ips-for-all-the-things/">ip static</a></li>
<li><a href="https://stackoverflow.com/questions/35742807/docker-1-10-containers-ip-in-lan/39285950#39285950">Docker 1.12+ container&rsquo;s IP in LAN</a></li>
<li><a href="http://hustcat.github.io/docker-macvlan/">Docker自定义网络——MacVLAN</a> 这篇内容有点类似pipework。</li>
</ul>


<blockquote><p>Note: In Macvlan you are not able to ping or communicate with the default namespace IP address. For example, if you create a container and try to ping the Docker host’s eth0 it will not work. That traffic is explicitly filtered by the kernel modules themselves to offer additional provider isolation and security.</p></blockquote>

<h2>主机</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-master140 ~]# ip addr show ens33
</span><span class='line'>2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000
</span><span class='line'>    link/ether 00:0c:29:40:2d:15 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 192.168.191.140/24 brd 192.168.191.255 scope global dynamic ens33
</span><span class='line'>       valid_lft 1765sec preferred_lft 1765sec
</span><span class='line'>    inet6 fe80::1186:2fe5:9ee5:8790/64 scope link 
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>
</span><span class='line'>[root@kube-worker141 ~]# ip addr show ens33
</span><span class='line'>2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000
</span><span class='line'>    link/ether 00:0c:29:2e:67:4d brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 192.168.191.141/24 brd 192.168.191.255 scope global dynamic ens33
</span><span class='line'>       valid_lft 1779sec preferred_lft 1779sec
</span><span class='line'>    inet6 fe80::dd23:1df6:b37:efae/64 scope link 
</span><span class='line'>       valid_lft forever preferred_lft forever</span></code></pre></td></tr></table></div></figure>


<h2>创建网络</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-worker141 ~]# docker network create \
</span><span class='line'>-d macvlan \
</span><span class='line'>--subnet=192.168.191.0/24 \
</span><span class='line'>--gateway=192.168.191.2 \
</span><span class='line'>-o parent=ens33 pub_net
</span><span class='line'>4370998ed03024bc0057a894f1280d5b0fcdba526fd9e8da612a3abb0dbc884b
</span><span class='line'>
</span><span class='line'>[root@kube-worker141 ~]# docker network list 
</span><span class='line'>NETWORK ID          NAME                DRIVER              SCOPE
</span><span class='line'>eee9236a36ba        bridge              bridge              local               
</span><span class='line'>ddc7f59215c1        host                host                local               
</span><span class='line'>d8dc7fbc40a6        none                null                local               
</span><span class='line'>4370998ed030        pub_net             macvlan             local               
</span><span class='line'>
</span><span class='line'>[root@kube-worker141 ~]# docker network inspect pub_net
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h2>使用</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker rm -f $( docker ps -a | grep -v IMAGE | awk '{print $1}' ) 
</span><span class='line'>
</span><span class='line'>[root@kube-worker141 ~]# docker run --net=pub_net --ip=192.168.191.200 --name c200 -tid busybox /bin/sh
</span><span class='line'>2e0a2ede40e80a2f1739330bb3a6c45b91ea08d78d26d165ad13945bedbea40f
</span><span class='line'>
</span><span class='line'>[root@kube-worker141 ~]# docker ps 
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</span><span class='line'>2e0a2ede40e8        busybox             "/bin/sh"           13 seconds ago      Up 11 seconds                           c200
</span><span class='line'>[root@kube-worker141 ~]# docker exec c200 ifconfig 
</span><span class='line'>eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:BF:C8  
</span><span class='line'>          inet addr:192.168.191.200  Bcast:0.0.0.0  Mask:255.255.255.0
</span><span class='line'>          inet6 addr: fe80::42:c0ff:fea8:bfc8/64 Scope:Link
</span><span class='line'>          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
</span><span class='line'>          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>          collisions:0 txqueuelen:0 
</span><span class='line'>          RX bytes:0 (0.0 B)  TX bytes:648 (648.0 B)
</span><span class='line'>
</span><span class='line'>lo        Link encap:Local Loopback  
</span><span class='line'>          inet addr:127.0.0.1  Mask:255.0.0.0
</span><span class='line'>          inet6 addr: ::1/128 Scope:Host
</span><span class='line'>          UP LOOPBACK RUNNING  MTU:65536  Metric:1
</span><span class='line'>          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>          collisions:0 txqueuelen:1 
</span><span class='line'>          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</span><span class='line'>
</span><span class='line'>[root@kube-worker141 ~]# docker exec c200 route -n
</span><span class='line'>Kernel IP routing table
</span><span class='line'>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span><span class='line'>0.0.0.0         192.168.191.2   0.0.0.0         UG    0      0        0 eth0
</span><span class='line'>192.168.191.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0
</span><span class='line'>[root@kube-worker141 ~]# docker exec c200 ping baidu.com 
</span><span class='line'>PING baidu.com (111.13.101.208): 56 data bytes
</span><span class='line'>64 bytes from 111.13.101.208: seq=0 ttl=128 time=45.029 ms
</span><span class='line'>64 bytes from 111.13.101.208: seq=1 ttl=128 time=44.616 ms
</span><span class='line'>
</span><span class='line'>#201
</span><span class='line'>[root@kube-worker141 ~]# docker run --net=pub_net --ip=192.168.191.201 -tid busybox /bin/sh 
</span><span class='line'>c8cfd3443f2b7b3973a06470cb95442eadface8d89c8cb1749ad73ebbd7e9e39
</span><span class='line'>
</span><span class='line'>##本地容器互通: 
</span><span class='line'>#: HOST141-200 ping HOST141-201
</span><span class='line'>[root@kube-worker141 ~]# docker exec c200 ping -W 10 192.168.191.201
</span><span class='line'>PING 192.168.191.201 (192.168.191.201): 56 data bytes
</span><span class='line'>64 bytes from 192.168.191.201: seq=0 ttl=64 time=0.523 ms
</span><span class='line'>
</span><span class='line'>#210 
</span><span class='line'>[root@kube-master ~]# docker run --net=pub_net --ip=192.168.191.210 -tid busybox /bin/sh 
</span><span class='line'>7929c136c3dbc646b68b3b7302e8525a25fe2f583db2246fea0da85a448b7b78
</span><span class='line'>
</span><span class='line'>##B访问A主机的容器: 
</span><span class='line'>#: HOST140 ping HOST141-201 
</span><span class='line'>[root@kube-master140 ~]# ping 192.168.191.201 
</span><span class='line'>PING 192.168.191.201 (192.168.191.201) 56(84) bytes of data.
</span><span class='line'>64 bytes from 192.168.191.201: icmp_seq=1 ttl=64 time=1.44 ms
</span><span class='line'>
</span><span class='line'>##A主机容器访问B主机容器: 
</span><span class='line'>#: HOST141-200 ping HOST140-210
</span><span class='line'>[root@kube-worker141 ~]# docker exec c200 ping -W 10 192.168.191.210
</span><span class='line'>PING 192.168.191.210 (192.168.191.210): 56 data bytes
</span><span class='line'>64 bytes from 192.168.191.210: seq=0 ttl=64 time=2.049 ms
</span><span class='line'>64 bytes from 192.168.191.210: seq=1 ttl=64 time=0.993 ms
</span><span class='line'>
</span><span class='line'>#主机与所在容器互相不能访问 (--!): 
</span><span class='line'>#: HOST141 ping HOST141-200
</span><span class='line'>[root@kube-worker141 ~]# ping 192.168.191.200
</span><span class='line'>PING 192.168.191.200 (192.168.191.200) 56(84) bytes of data.
</span><span class='line'>From 192.168.191.141 icmp_seq=1 Destination Host Unreachable
</span><span class='line'>From 192.168.191.141 icmp_seq=2 Destination Host Unreachable
</span><span class='line'>#: HOST141-200 ping HOST141
</span><span class='line'>[root@kube-worker1 ~]# docker exec c200 ping 192.168.191.141
</span></code></pre></td></tr></table></div></figure>


<p>针对主机与本机容器不能互通的问题，可以增加一张默认的网卡：<a href="https://success.docker.com/KBase/Multiple_Docker_Networks">Multiple Docker Networks</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#先通过默认网络创建
</span><span class='line'>[root@kube-worker1 ~]# docker run --name c200 -tid busybox /bin/sh                                   
</span><span class='line'>47b7c1813b95cbec471b1a6de6a870e5537cfa70d54120873a5edb4e444b373b
</span><span class='line'>#然后连接pub_net！
</span><span class='line'>[root@kube-worker1 ~]# docker network connect --ip=192.168.191.200 pub_net c200        
</span><span class='line'>[root@kube-worker1 ~]# docker exec c200 ip a
</span><span class='line'>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1
</span><span class='line'>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span><span class='line'>    inet 127.0.0.1/8 scope host lo
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>    inet6 ::1/128 scope host 
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>14: eth0@if15: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue 
</span><span class='line'>    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 172.18.0.2/16 scope global eth0
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>    inet6 fe80::42:acff:fe12:2/64 scope link 
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>16: eth1@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue 
</span><span class='line'>    link/ether 02:42:c0:a8:bf:c8 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 192.168.191.200/24 scope global eth1
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>    inet6 fe80::42:c0ff:fea8:bfc8/64 scope link 
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>       </span></code></pre></td></tr></table></div></figure>


<p>方式1：</p>

<p>与主机的通信，通过 172.18.0.0/24 的网络。其他的通过 192.168.191.0/24 。还是感觉有点鸡肋！！</p>

<p>方式2：</p>

<p>增加route：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#route add -host $container_ip gw $lan_router_ip $if_device_nic2
</span><span class='line'>
</span><span class='line'>[root@kube-worker1 ~]# route add -net 192.168.191.200 gw 172.18.0.1 netmask 255.255.255.255 dev docker0
</span><span class='line'>[root@kube-worker1 ~]# route -n
</span><span class='line'>Kernel IP routing table
</span><span class='line'>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span><span class='line'>0.0.0.0         192.168.191.2   0.0.0.0         UG    100    0        0 ens33
</span><span class='line'>172.17.3.0      192.168.191.140 255.255.255.0   UG    100    0        0 ens33
</span><span class='line'>172.17.4.0      0.0.0.0         255.255.255.0   U     425    0        0 kbr0
</span><span class='line'>172.18.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
</span><span class='line'>192.168.191.0   0.0.0.0         255.255.255.0   U     100    0        0 ens33
</span><span class='line'>192.168.191.200 172.18.0.1      255.255.255.255 UGH   0      0        0 docker0
</span><span class='line'>[root@kube-worker1 ~]# ping 192.168.191.200
</span><span class='line'>PING 192.168.191.200 (192.168.191.200) 56(84) bytes of data.
</span><span class='line'>64 bytes from 192.168.191.200: icmp_seq=1 ttl=64 time=0.239 ms
</span><span class='line'>64 bytes from 192.168.191.200: icmp_seq=2 ttl=64 time=0.106 ms
</span><span class='line'>^C
</span><span class='line'>--- 192.168.191.200 ping statistics ---
</span><span class='line'>2 packets transmitted, 2 received, 0% packet loss, time 1000ms
</span><span class='line'>rtt min/avg/max/mdev = 0.106/0.172/0.239/0.067 ms
</span></code></pre></td></tr></table></div></figure>


<p>通过操作与pipework比较，互有优劣：</p>

<ul>
<li>pipework会创建网卡，然后所有的ip都是互通的，但是绑定、还得把主机的ip配置到br0上。</li>
<li>而docker-network的方式与主机互通需要做额外的配置。</li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker多主机网络配置 - Pipework]]></title>
    <link href="http://winseliu.com/blog/2017/10/07/docker-network-via-pipework/"/>
    <updated>2017-10-07T15:24:23+00:00</updated>
    <id>http://winseliu.com/blog/2017/10/07/docker-network-via-pipework</id>
    <content type="html"><![CDATA[<p>前面使用nat+route的方式手动连通两台机器上的docker容器。pipework是通过脚本的方式（手动）设置网络以及修改路由来进行配置的。</p>

<p>参考：</p>

<ul>
<li><a href="http://www.infoq.com/cn/articles/docker-network-and-pipework-open-source-explanation-practice">Docker网络详解及pipework源码解读与实践</a></li>
<li><a href="http://hongge.blog.51cto.com/2083180/1843169">docker技术剖析&ndash;docker网络（二）docker宿主机之间容器互通 for centos7.2</a> 步骤更详细一点</li>
</ul>


<p>原理就是建立一条连接link，一端 <strong> 在主机 </strong> 一端 <strong> 在容器 </strong> ；然后手动配置容器ip和路由；最后把主机Ethernet和新建的Bridge桥接连接到物理网络。</p>

<p>容器的ip地址和主机的ip地址在一个网段内，所以在同一交换机下的所有主机、里面的容器都互通。</p>

<h2>查看原网络的信息：</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-worker1 ~]# nmcli d show ens33 
</span><span class='line'>GENERAL.DEVICE:                         ens33
</span><span class='line'>GENERAL.TYPE:                           ethernet
</span><span class='line'>GENERAL.HWADDR:                         00:0C:29:2E:67:4D
</span><span class='line'>GENERAL.MTU:                            1500
</span><span class='line'>GENERAL.STATE:                          100 (connected)
</span><span class='line'>GENERAL.CONNECTION:                     ens33
</span><span class='line'>GENERAL.CON-PATH:                       /org/freedesktop/NetworkManager/ActiveConnection/0
</span><span class='line'>WIRED-PROPERTIES.CARRIER:               on
</span><span class='line'>IP4.ADDRESS[1]:                         192.168.191.141/24
</span><span class='line'>IP4.GATEWAY:                            192.168.191.2
</span><span class='line'>IP4.ROUTE[1]:                           dst = 172.17.3.0/24, nh = 192.168.191.140, mt = 100
</span><span class='line'>IP4.DNS[1]:                             192.168.191.2
</span><span class='line'>IP4.DOMAIN[1]:                          localdomain
</span><span class='line'>IP6.ADDRESS[1]:                         fe80::3995:4490:e2e7:1d0f/64
</span><span class='line'>IP6.GATEWAY:                            </span></code></pre></td></tr></table></div></figure>


<h2>安装pipework</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jpetazzo/pipework
</span><span class='line'>cp ~/pipework/pipework /usr/local/bin/</span></code></pre></td></tr></table></div></figure>


<h2>运行docker</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#设置ip转发
</span><span class='line'>echo 1 &gt; /proc/sys/net/ipv4/ip_forward
</span><span class='line'>
</span><span class='line'>vi /etc/sysctl.conf
</span><span class='line'>net.ipv4.ip_forward = 1  
</span><span class='line'>
</span><span class='line'>NAME=test1
</span><span class='line'>
</span><span class='line'>#如不需要安装软件，可以加 --net none
</span><span class='line'>docker run -itd --name $NAME centos /bin/bash
</span><span class='line'>
</span><span class='line'>#docker ps -a -f name=$NAME | grep $NAME && docker start $NAME 
</span><span class='line'>#docker exec test1 yum install -y iproute net-tools </span></code></pre></td></tr></table></div></figure>


<h2>配置网络</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>function docker_container_ip () {
</span><span class='line'>  local name=$1
</span><span class='line'>  local ip=$2
</span><span class='line'>  local gateway=${3:-$GATEWAY}
</span><span class='line'>  
</span><span class='line'>  pipework br0 $name $ip@$gateway
</span><span class='line'>  #docker exec $name ifconfig 
</span><span class='line'>  #docker exec $name route -n 
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>function docker_hosted_bridge_network_reset () {
</span><span class='line'>  local ip=$1
</span><span class='line'>  local gateway=$2
</span><span class='line'>  local iface=$3
</span><span class='line'>  
</span><span class='line'>  if nmcli d show $iface | grep -i ethernet ; then
</span><span class='line'>    #把地址给网桥，然后把ethernet和bridge连起来：(SSH连接操作的话，需要一条命令搞定！修改br0地址后route会变)
</span><span class='line'>    ip addr add $ip dev br0 ; \
</span><span class='line'>    ip addr del $ip dev $iface ; \
</span><span class='line'>    brctl addif br0 $iface ; \
</span><span class='line'>    #ip route del default ; \
</span><span class='line'>    ip route add default via $gateway 
</span><span class='line'>  fi 
</span><span class='line'>  
</span><span class='line'>  brctl show br0
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>GATEWAY=$( route -n | grep '^0.0.0.0' | awk '{print $2}' )
</span><span class='line'>IFACE=$( route -n | grep '^0.0.0.0' | awk '{print $8}' )
</span><span class='line'>HOSTED_IPADDR=$( ip addr show $IFACE | grep "inet " | awk '{print $2}' )
</span></code></pre></td></tr></table></div></figure>


<p>设置容器的IP：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>NAME=test1
</span><span class='line'>IP=192.168.191.210/24
</span><span class='line'>
</span><span class='line'>docker_container_ip $NAME $IP $GATEWAY
</span><span class='line'>docker_hosted_bridge_network_reset $HOSTED_IPADDR $GATEWAY $IFACE</span></code></pre></td></tr></table></div></figure>


<p>上面的方式配置方式<strong>重启就失效</strong>的，可以通过写配置文件的方式来永久生效。如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-worker1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33 
</span><span class='line'>TYPE=Ethernet
</span><span class='line'>DEVICE=ens33
</span><span class='line'>BRIDGE=br0
</span><span class='line'>[root@kube-worker1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 
</span><span class='line'>DEVICE=br0
</span><span class='line'>TYPE=Bridge
</span><span class='line'>ONBOOT=yes
</span><span class='line'>BOOTPROTO=static
</span><span class='line'>IPADDR=192.168.191.141
</span><span class='line'>NETMASK=255.255.255.0
</span><span class='line'>GATEWAY=192.168.191.2
</span><span class='line'>DNS1=192.168.191.2
</span><span class='line'>
</span><span class='line'>USERCTL=no</span></code></pre></td></tr></table></div></figure>


<h2>测试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-worker1 ~]# screen
</span><span class='line'>
</span><span class='line'>  GATEWAY=$( route -n | grep '^0.0.0.0' | awk '{print $2}' )
</span><span class='line'>  IFACE=$( route -n | grep '^0.0.0.0' | awk '{print $8}' )
</span><span class='line'>  HOSTED_IPADDR=$( ip addr show $IFACE | grep "inet " | awk '{print $2}' )
</span><span class='line'>
</span><span class='line'>  docker run -itd --name test21 centos /bin/bash
</span><span class='line'>  docker run -itd --name test22 centos /bin/bash
</span><span class='line'>
</span><span class='line'>  docker_container_ip test21 192.168.191.231/24 $GATEWAY
</span><span class='line'>  docker_container_ip test22 192.168.191.232/24 $GATEWAY
</span><span class='line'>
</span><span class='line'>  docker exec test21 ping  192.168.191.140
</span><span class='line'>  docker exec test21 ping  192.168.191.141
</span><span class='line'>
</span><span class='line'>[root@kube-master ~]# screen #会话"不断"
</span><span class='line'>
</span><span class='line'>  docker_container_ip test11 192.168.191.221/24 $GATEWAY 
</span><span class='line'>  docker_container_ip test12 192.168.191.222/24 $GATEWAY
</span><span class='line'>
</span><span class='line'>  docker_hosted_bridge_network_reset $HOSTED_IPADDR $GATEWAY $IFACE
</span><span class='line'>
</span><span class='line'>  docker exec test11 ping 192.168.191.233</span></code></pre></td></tr></table></div></figure>


<p>注意：容器重启后，这些配置的网卡/路由都没有了，要重新配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-worker1 ~]# docker stop test21
</span><span class='line'>test21
</span><span class='line'>[root@kube-worker1 ~]# docker start test21
</span><span class='line'>test21
</span><span class='line'>[root@kube-worker1 ~]# pipework route test21 show 
</span><span class='line'>default via 172.18.0.1 dev eth0 
</span><span class='line'>172.18.0.0/16 dev eth0  proto kernel  scope link  src 172.18.0.2 
</span><span class='line'>
</span><span class='line'>[root@kube-worker1 ~]# docker_container_ip test21 192.168.191.231/24 $GATEWAY
</span><span class='line'>[root@kube-worker1 ~]# pipework route test21 show                            
</span><span class='line'>default via 192.168.191.2 dev eth1 
</span><span class='line'>172.18.0.0/16 dev eth0  proto kernel  scope link  src 172.18.0.2 
</span><span class='line'>192.168.191.0/24 dev eth1  proto kernel  scope link  src 192.168.191.231 
</span><span class='line'>
</span><span class='line'>[root@kube-worker1 ~]# docker exec test21 ping 192.168.191.140</span></code></pre></td></tr></table></div></figure>


<p>了解原理后，操作起来还是比较容易的。就是每次重启都要重新配置比较烦。可以写成脚本，启动docker容器的时刻就执行下网络配置。</p>

<p>pipework还可以用来配置vlan，暂时没这个需求，并且基本的操作都类似就没有实际操作了。</p>

<p>话说，<strong> pipework还可以用来创建多网卡的容器。用docker network connect其实更简单。 </strong></p>

<h2>后记</h2>

<p>除了通过pipework来实现共享物理网络外，docker network也可以实现这个功能：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/35742807/docker-1-10-containers-ip-in-lan/35799206#35799206">Docker 1.10 container&rsquo;s IP in LAN</a></li>
<li><p><a href="https://gist.github.com/dreamcat4/bc202ae175b367bcbe693da7a52851af">using bridge driver and brctrl.md</a> 感觉原理也类似pipework，就是那一堆的netns让 docker network + docker run &ndash;net 实现了而已。</p></li>
<li><p>建立并配置Bridge：</p></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#中间会导致网络断掉，一条命令搞定才行
</span><span class='line'>docker network create --gateway=192.168.191.141 --subnet 192.168.191.0/24 --aux-address "DefaultGatewayIPv4=192.168.191.2" -o com.docker.network.bridge.name=br-home-net homenet ; \
</span><span class='line'>ip addr del 192.168.191.141/24 dev ens33 ; \
</span><span class='line'>brctl addif br-home-net ens33 
</span><span class='line'>
</span><span class='line'>#主机不上外网可以不加
</span><span class='line'>ip route add default via 192.168.191.2 ; 
</span><span class='line'>echo "nameserver 114.114.114.114" &gt;&gt;/etc/resolv.conf ; </span></code></pre></td></tr></table></div></figure>


<ul>
<li>测试 docker-net + bridge：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@kube-worker1 ~]# ip a
</span><span class='line'>...
</span><span class='line'>2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br-home-net state UP qlen 1000
</span><span class='line'>    link/ether 00:0c:29:2e:67:4d brd ff:ff:ff:ff:ff:ff
</span><span class='line'>4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN 
</span><span class='line'>    link/ether 02:42:44:ef:32:28 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 172.18.0.1/16 scope global docker0
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>11: br-home-net: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP 
</span><span class='line'>    link/ether 02:42:84:97:c2:25 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 192.168.191.141/24 scope global br-home-net
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>    inet6 fe80::42:84ff:fe97:c225/64 scope link 
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>       
</span><span class='line'>[root@kube-worker1 ~]# docker run -tid --name c200 --net homenet --ip 192.168.191.200 busybox /bin/sh 
</span><span class='line'>2579c2ddd18d23322eb1e145ad630205933dbc527b8981169ec6b125da8d8f1e
</span><span class='line'>
</span><span class='line'>[root@kube-worker1 ~]# docker exec -ti c200 sh 
</span><span class='line'>/ # ip a
</span><span class='line'>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1
</span><span class='line'>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span><span class='line'>    inet 127.0.0.1/8 scope host lo
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>12: eth0@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue 
</span><span class='line'>    link/ether 02:42:c0:a8:bf:c8 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 192.168.191.200/24 scope global eth0
</span><span class='line'>       valid_lft forever preferred_lft forever
</span><span class='line'>/ # route -n
</span><span class='line'>Kernel IP routing table
</span><span class='line'>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span><span class='line'>0.0.0.0         192.168.191.2   0.0.0.0         UG    0      0        0 eth0
</span><span class='line'>192.168.191.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0
</span><span class='line'>/ # ping baidu.com 
</span><span class='line'>PING baidu.com (111.13.101.208): 56 data bytes
</span><span class='line'>64 bytes from 111.13.101.208: seq=0 ttl=128 time=48.225 ms
</span><span class='line'>^C
</span><span class='line'>--- baidu.com ping statistics ---
</span><span class='line'>1 packets transmitted, 1 packets received, 0% packet loss
</span><span class='line'>round-trip min/avg/max = 48.225/48.225/48.225 ms
</span><span class='line'>/ # ping 192.169.191.140
</span><span class='line'>PING 192.169.191.140 (192.169.191.140): 56 data bytes
</span><span class='line'>^C
</span><span class='line'>--- 192.169.191.140 ping statistics ---
</span><span class='line'>4 packets transmitted, 0 packets received, 100% packet loss
</span><span class='line'>/ # ping 192.168.191.140
</span><span class='line'>PING 192.168.191.140 (192.168.191.140): 56 data bytes
</span><span class='line'>64 bytes from 192.168.191.140: seq=0 ttl=64 time=2.572 ms
</span><span class='line'>64 bytes from 192.168.191.140: seq=1 ttl=64 time=1.076 ms
</span><span class='line'>^C
</span><span class='line'>--- 192.168.191.140 ping statistics ---
</span><span class='line'>2 packets transmitted, 2 packets received, 0% packet loss
</span><span class='line'>round-trip min/avg/max = 1.076/1.824/2.572 ms
</span><span class='line'>/ # ping 192.168.191.141
</span><span class='line'>PING 192.168.191.141 (192.168.191.141): 56 data bytes
</span><span class='line'>64 bytes from 192.168.191.141: seq=0 ttl=64 time=0.474 ms
</span><span class='line'>64 bytes from 192.168.191.141: seq=1 ttl=64 time=0.138 ms
</span><span class='line'>^C
</span><span class='line'>--- 192.168.191.141 ping statistics ---
</span><span class='line'>2 packets transmitted, 2 packets received, 0% packet loss
</span><span class='line'>round-trip min/avg/max = 0.138/0.306/0.474 ms
</span><span class='line'>/ # ping 192.168.191.1
</span><span class='line'>PING 192.168.191.1 (192.168.191.1): 56 data bytes
</span><span class='line'>64 bytes from 192.168.191.1: seq=0 ttl=128 time=1.068 ms
</span><span class='line'>64 bytes from 192.168.191.1: seq=1 ttl=128 time=0.603 ms
</span><span class='line'>^C
</span><span class='line'>--- 192.168.191.1 ping statistics ---
</span><span class='line'>2 packets transmitted, 2 packets received, 0% packet loss
</span><span class='line'>round-trip min/avg/max = 0.603/0.835/1.068 ms
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[STAF Start Guide]]></title>
    <link href="http://winseliu.com/blog/2017/10/06/staf-start-guide/"/>
    <updated>2017-10-06T00:07:49+00:00</updated>
    <id>http://winseliu.com/blog/2017/10/06/staf-start-guide</id>
    <content type="html"><![CDATA[<p>STAF(Software Testing Automation Framework) 是用来构建自动化测试的框架，用来部署测试环境。包括跨平台自动化部署的各种组件：config、process、handle、fs、log、monitor、queue、var、security等各种服务，还可以轻松的扩展。机器通过STAFProc启动的端口来进行通讯（set、query等）。</p>

<blockquote><p>STAF的作用实际上就是提供了机器之间的通信通道并提供基于这个通道的基础服务。</p></blockquote>

<h2>安装</h2>

<ul>
<li><a href="http://staf.sourceforge.net/current/STAFInstall.pdf">http://staf.sourceforge.net/current/STAFInstall.pdf</a></li>
<li><a href="http://blog.csdn.net/lsj6730960/article/details/6186861">STAF的原理及使用</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-test-stafstax/index.html">使用 STAF/STAX 实现测试自动化和持续集成</a></li>
</ul>


<p>直接用 <a href="http://staf.sourceforge.net/getcurrent.php">InstallAnywhere（IA）</a> 的方式安装。文档介绍了整个安装过程中做的所有事情，非常非常的详细。下面针对Linux的安装配置步骤：</p>

<ul>
<li>安装配置项（选项），三种方式选一种：
  交互方式
  文件方式
  默认值</li>
<li>环境变量：使用InstallAnywhere的方式会把环境变量配置好，文档中介绍了使用的环境变量。</li>
<li>启动：shell脚本、开机启动（centos7的服务配置可以参考文档的[Fedora 15 and later]部分）</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#安装（默认值）
</span><span class='line'>./STAF3426-setup-linux-amd64-NoJVM.bin -i silent -DACCEPT_LICENSE=1
</span><span class='line'>
</span><span class='line'>#启动
</span><span class='line'>su -
</span><span class='line'>/usr/local/staf/bin/STAFProc
</span><span class='line'>或者
</span><span class='line'>./startSTAFProc.sh 
</span><span class='line'>
</span><span class='line'>#测试
</span><span class='line'>[root@cdb1 staf]# staf local ping ping
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>PONG
</span><span class='line'>[root@cdb1 staf]# staf local process start command ifconfig
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>5
</span><span class='line'>#程序运行产生的输出是在运行的机器上的！
</span><span class='line'>[root@cdb1 staf]# less nohup.out 
</span><span class='line'>
</span><span class='line'>Machine          : cdb1
</span><span class='line'>Machine nickname : cdb1
</span><span class='line'>Startup time     : 20171006-08:50:55
</span><span class='line'>
</span><span class='line'>STAFProc version 3.4.26 initialized
</span><span class='line'>ens192: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
</span><span class='line'>        inet 192.168.193.101  netmask 255.255.192.0  broadcast 192.168.255.255
</span><span class='line'>        inet6 fe80::932a:7b98:cc20:f791  prefixlen 64  scopeid 0x20&lt;link&gt;
</span><span class='line'>        inet6 fe80::9ba3:ce9e:cc9c:477d  prefixlen 64  scopeid 0x20&lt;link&gt;
</span><span class='line'>        inet6 fe80::7d8c:b318:d441:70b2  prefixlen 64  scopeid 0x20&lt;link&gt;
</span><span class='line'>        ether 00:50:56:92:26:93  txqueuelen 1000  (Ethernet)
</span><span class='line'>        RX packets 11020400  bytes 3439058707 (3.2 GiB)
</span><span class='line'>        RX errors 0  dropped 717  overruns 0  frame 0
</span><span class='line'>        TX packets 9067587  bytes 3110097659 (2.8 GiB)
</span><span class='line'>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span><span class='line'>
</span><span class='line'>lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
</span><span class='line'>        inet 127.0.0.1  netmask 255.0.0.0
</span><span class='line'>        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;
</span><span class='line'>        loop  txqueuelen 1  (Local Loopback)
</span><span class='line'>        RX packets 70483  bytes 10164575 (9.6 MiB)
</span><span class='line'>        RX errors 0  dropped 0  overruns 0  frame 0
</span><span class='line'>        TX packets 70483  bytes 10164575 (9.6 MiB)
</span><span class='line'>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#多机测试
</span><span class='line'>[root@cdb2 staf]# vi bin/STAF.cfg
</span><span class='line'>trust machine 192.168.193.101 level 5
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf cdb2 ping ping 
</span><span class='line'>[root@cdb1 staf]# staf cdb2 process start command ifconfig 
</span><span class='line'>[root@cdb2 staf]# less nohup.out 
</span><span class='line'>
</span><span class='line'>#安全退出
</span><span class='line'>STAF local SHUTDOWN SHUTDOWN
</span><span class='line'>C:\STAF\bin\STAF.exe local SHUTDOWN SHUTDOWN
</span></code></pre></td></tr></table></div></figure>


<h2>Getting Started</h2>

<p><a href="http://staf.sourceforge.net/current/STAFGS.pdf">http://staf.sourceforge.net/current/STAFGS.pdf</a></p>

<p>STAFGS 对所有的知识点都做了简单的介绍和归纳。更详细的需要看 User Guide 文档。</p>

<p>STAF is an Open Source automation framework designed around the idea of reusable components. It is intended to make it
easier to create automated testcases and workloads. STAF can help you increase the efficiency, productivity, and quality of
your testing by improving your level of automation and reuse in your individual testcases as well as your overall test
environment.</p>

<p>STAF operates in a peer-to-peer environment; in other words, there is no client-server hierarchy among machines
running STAF.</p>

<h4>Basic STAF Concepts</h4>

<p>STAF Instances
Since multiple instances of STAF can be run at the same time on the same system, a STAF Instance name is used to
specify a name for each STAF instance. You specify the instance name to be used by setting the environment variable
STAF_INSTANCE_NAME. The default instance name is &ldquo;STAF&rdquo;.</p>

<p>A basic description of each level follows</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Level 0 - No access
</span><span class='line'>Level 1 - Restricted access. Only PING and helps available.
</span><span class='line'>Level 2 - Limited access. Only query/view facilities available.
</span><span class='line'>Level 3 - Standard access. Non-destructive updates allowed, e.g., logging.
</span><span class='line'>Level 4 - Advanced access. Update abilities, e.g., copying files, deleting log files.
</span><span class='line'>Level 5 - All access, e.g., SHUTDOWN, Process invocation, Trust definition manipulation</span></code></pre></td></tr></table></div></figure>


<p>STAF requests submitted from the command line are generally used to query information from STAF services.</p>

<h4>STAF Commands</h4>

<p>You can also start STAFProc by simply typing STAFProc at a command prompt
window. ( /usr/local/staf/bin is in your PATH )</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>STAF  &lt;Endpoint&gt;/[&lt;Interface&gt;://]&lt;System Identifier&gt;[@&lt;Port&gt;]  &lt;Service&gt; &lt;Request&gt;
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local ping ping 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>PONG
</span><span class='line'>#没运行
</span><span class='line'>[root@cdb1 staf]# staf cdb2 ping ping 
</span><span class='line'>Error submitting request, RC: 16
</span><span class='line'>Additional info
</span><span class='line'>---------------
</span><span class='line'>STAFConnectionProviderConnect: Error performing test read on connected endpoint: recv() RC=111: 22, Endpoint: ssl://cdb2
</span><span class='line'>[root@cdb1 staf]# staf cdb2 ping ping 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>PONG
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local service help 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>*** SERVICE Service Help ***
</span><span class='line'>
</span><span class='line'>LIST    [ SERVICES | SERVICELOADERS | AUTHENTICATORS |
</span><span class='line'>          REQUESTS &lt;[PENDING] [COMPLETE] [LONG]&gt; | [SUMMARY] ]
</span><span class='line'>QUERY   SERVICE &lt;Service Name&gt; | SERVICELOADER &lt;ServiceLoader Name&gt; |
</span><span class='line'>        AUTHENTICATOR &lt;Authenticator Name&gt; | REQUEST &lt;Request Number&gt;
</span><span class='line'>ADD     SERVICE &lt;Service Name&gt; LIBRARY &lt;Library Name&gt;
</span><span class='line'>        [EXECUTE &lt;Executable&gt;] [OPTION &lt;Name[=Value]&gt;]...
</span><span class='line'>        [PARMS &lt;Parameters&gt;]
</span><span class='line'>REMOVE  SERVICE &lt;Service Name&gt;
</span><span class='line'>FREE    REQUEST &lt;Request Number&gt; [FORCE]
</span><span class='line'>HELP
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local shutdown help 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>*** SHUTDOWN Service Help ***
</span><span class='line'>
</span><span class='line'>SHUTDOWN
</span><span class='line'>
</span><span class='line'>NOTIFY REGISTER   [MACHINE &lt;Machine&gt;] [HANDLE &lt;Handle&gt; | NAME &lt;Name&gt;]
</span><span class='line'>                  [PRIORITY &lt;Priority&gt;]
</span><span class='line'>NOTIFY UNREGISTER [MACHINE &lt;Machine&gt;] [HANDLE &lt;Handle&gt; | NAME &lt;Name&gt;]
</span><span class='line'>                  [PRIORITY &lt;Priority&gt;]
</span><span class='line'>NOTIFY LIST
</span><span class='line'>
</span><span class='line'>HELP
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt;&gt; The information returned by Help show us the options we can place after "STAF local shutdown ....." 
</span><span class='line'>in command requests
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local service list 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Name      Library    Executable
</span><span class='line'>--------- ---------- ----------
</span><span class='line'>CONFIG    &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>DELAY     &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>DIAG      &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>ECHO      &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>FS        &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>HANDLE    &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>HELP      &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>LIFECYCLE &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>MISC      &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>PING      &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>PROCESS   &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>QUEUE     &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>SEM       &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>SERVICE   &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>SHUTDOWN  &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>TRACE     &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>TRUST     &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>VAR       &lt;Internal&gt; &lt;None&gt;    
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local var list 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>STAF/Config/BootDrive             : /
</span><span class='line'>STAF/Config/CodePage              : UTF-8
</span><span class='line'>STAF/Config/ConfigFile            : /usr/local/staf/bin/STAF.cfg
</span><span class='line'>STAF/Config/DefaultAuthenticator  : none
</span><span class='line'>STAF/Config/DefaultInterface      : ssl
</span><span class='line'>STAF/Config/InstanceName          : STAF
</span><span class='line'>STAF/Config/Machine               : cdb1
</span><span class='line'>STAF/Config/MachineNickname       : cdb1
</span><span class='line'>STAF/Config/Mem/Physical/Bytes    : 3974971392
</span><span class='line'>STAF/Config/Mem/Physical/KB       : 3881808
</span><span class='line'>STAF/Config/Mem/Physical/MB       : 3790
</span><span class='line'>STAF/Config/OS/MajorVersion       : 3.10.0-693.el7.x86_64
</span><span class='line'>STAF/Config/OS/MinorVersion       : #1 SMP Tue Aug 22 21:09:27 UTC 2017
</span><span class='line'>STAF/Config/OS/Name               : Linux
</span><span class='line'>STAF/Config/OS/Revision           : x86_64
</span><span class='line'>STAF/Config/Processor/NumAvail    : 4
</span><span class='line'>STAF/Config/Sep/Command           : ;
</span><span class='line'>STAF/Config/Sep/File              : /
</span><span class='line'>STAF/Config/Sep/Line              : 
</span><span class='line'>
</span><span class='line'>STAF/Config/Sep/Path              : :
</span><span class='line'>STAF/Config/STAFRoot              : /usr/local/staf
</span><span class='line'>STAF/Config/StartupTime           : 20171006-10:33:42
</span><span class='line'>STAF/DataDir                      : /usr/local/staf/data/STAF
</span><span class='line'>STAF/Env/_                        : /usr/bin/nohup
</span><span class='line'>STAF/Env/CLASSPATH                : /usr/local/staf/lib/JSTAF.jar:/usr/local/staf/samples/demo/STAFDemo.jar:/usr/local/staf/samples/demo/STAFDemo.jar:/usr/local/staf/lib/JSTAF.jar:
</span><span class='line'>STAF/Env/HISTCONTROL              : ignoredups
</span><span class='line'>STAF/Env/HISTSIZE                 : 1000
</span><span class='line'>STAF/Env/HOME                     : /root
</span><span class='line'>STAF/Env/HOSTNAME                 : cdb1
</span><span class='line'>STAF/Env/JAVA_HOME                : /usr/local/jdk
</span><span class='line'>STAF/Env/LANG                     : en_US.UTF-8
</span><span class='line'>STAF/Env/LD_LIBRARY_PATH          : /usr/local/staf/lib:/usr/local/staf/lib:
</span><span class='line'>STAF/Env/LESSOPEN                 : ||/usr/bin/lesspipe.sh %s
</span><span class='line'>STAF/Env/LOGNAME                  : root
</span><span class='line'>STAF/Env/LS_COLORS                : rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
</span><span class='line'>STAF/Env/MAIL                     : /var/spool/mail/root
</span><span class='line'>STAF/Env/PATH                     : /usr/local/staf/bin:/usr/local/staf/bin:/usr/local/jdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
</span><span class='line'>STAF/Env/PWD                      : /usr/local/staf
</span><span class='line'>STAF/Env/SELINUX_LEVEL_REQUESTED  : 
</span><span class='line'>STAF/Env/SELINUX_ROLE_REQUESTED   : 
</span><span class='line'>STAF/Env/SELINUX_USE_CURRENT_RANGE: 
</span><span class='line'>STAF/Env/SHELL                    : /bin/bash
</span><span class='line'>STAF/Env/SHLVL                    : 2
</span><span class='line'>STAF/Env/SSH_AUTH_SOCK            : /tmp/ssh-yEmD907zdB/agent.28259
</span><span class='line'>STAF/Env/SSH_CLIENT               : 192.168.193.10 34774 22
</span><span class='line'>STAF/Env/SSH_CONNECTION           : 192.168.193.10 34774 192.168.193.101 22
</span><span class='line'>STAF/Env/SSH_TTY                  : /dev/pts/2
</span><span class='line'>STAF/Env/STAF_INSTANCE_NAME       : STAF
</span><span class='line'>STAF/Env/STAFCONVDIR              : /usr/local/staf/codepage
</span><span class='line'>STAF/Env/TERM                     : vt100
</span><span class='line'>STAF/Env/USER                     : root
</span><span class='line'>STAF/Env/XDG_DATA_DIRS            : /root/.local/share/flatpak/exports/share/:/var/lib/flatpak/exports/share/:/usr/local/share/:/usr/share/
</span><span class='line'>STAF/Env/XDG_RUNTIME_DIR          : /run/user/0
</span><span class='line'>STAF/Env/XDG_SESSION_ID           : 2080
</span><span class='line'>STAF/Version                      : 3.4.26
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt;&gt; STAF predefines many useful variables, including information about the machine's Operating System 
</span><span class='line'>and File/Line/Path separators. 
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local var resolve system string {STAF/Config/Sep/File}
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>/
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local handle list handles
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Handle Handle Name                     State      Last Used Date-Time
</span><span class='line'>------ ------------------------------- ---------- -------------------
</span><span class='line'>1      STAF_Process                    InProcess  20171006-10:33:42  
</span><span class='line'>2      STAF/Service/STAFServiceLoader1 InProcess  20171006-10:33:42  
</span><span class='line'>11     STAF/Client                     Registered 20171006-10:41:39  
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt;&gt; handle 1 is assigned to STAFProc. Each of the STAF/Client requests represent each 
</span><span class='line'>of the three "STAF local handle list handles" commands you submitted. Note that each request is assigned a new handle
</span><span class='line'>number, and that the previous handles have been deleted 
</span></code></pre></td></tr></table></div></figure>


<h4>Configuring STAF</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cdb1 staf]# staf local log log  machine logname log1 level info message test-message
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local log list machines
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>cdb1
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local log query machine cdb1 logname log1 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Date-Time         Level Message     
</span><span class='line'>----------------- ----- ------------
</span><span class='line'>20171006-10:54:33 Info  test-message
</span><span class='line'>
</span><span class='line'>#配置
</span><span class='line'>[root@cdb1 staf]# echo "MACHINENICKNAME cdb1.dev" &gt;&gt;bin/STAF.cfg 
</span><span class='line'>[root@cdb1 staf]# staf local shutdown shutdown 
</span><span class='line'>[root@cdb1 staf]# ./startSTAFProc.sh 
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local log log  machine logname log3 level info message test-message
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local log list machines
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>cdb1
</span><span class='line'>cdb1.dev
</span><span class='line'>[root@cdb1 staf]# staf local log query machine cdb1.dev logname log3
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Date-Time         Level Message     
</span><span class='line'>----------------- ----- ------------
</span><span class='line'>20171006-10:57:59 Info  test-message
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt;&gt; This primarily effects the data stored by
</span><span class='line'>services such as the Log and Monitor services, which store data based on the machine from which it came by using the
</span><span class='line'>STAF/Config/MachineNickname system variable as part of the directory path when creating logs and monitor data. By
</span><span class='line'>allowing the STAF/Config/MachineNickname system variable to be overridden, it allows you to better manage your
</span><span class='line'>data.
</span><span class='line'>Note that the machine nickname is not used to communicate with other systems and does not have any effect on trust. 
</span><span class='line'>
</span><span class='line'>#配置
</span><span class='line'>echo "SET DATADIR /data" &gt;&gt;bin/STAF.cfg
</span><span class='line'>...
</span><span class='line'>SET SYSTEM VAR Test/TestABC=websphere
</span><span class='line'>SET SYSTEM VAR Test/TestXYZ=150
</span><span class='line'>
</span><span class='line'>restart STAFProc and from a command prompt, try the STAF local var list command
</span><span class='line'>
</span><span class='line'>TRUST LEVEL 2 DEFAULT
</span><span class='line'>TRUST LEVEL 5 MACHINE 192.168.193.*
</span><span class='line'>TRUST LEVEL 4 MACHINE tcp://9.3.41.*
</span><span class='line'>TRUST LEVEL 5 MACHINE tcP://9.41.53.147
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local trust list 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Type    Entry             Trust Level
</span><span class='line'>------- ----------------- -----------
</span><span class='line'>Default &lt;None&gt;            2          
</span><span class='line'>Machine *://192.168.193.* 5          
</span><span class='line'>Machine local://local     5          
</span><span class='line'>Machine tcp://9.3.41.*    4          
</span><span class='line'>Machine tcP://9.41.53.147 5          
</span></code></pre></td></tr></table></div></figure>


<h4>Using the Help Service</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cdb1 staf]# staf local help help 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>*** HELP Service Help ***
</span><span class='line'>
</span><span class='line'>REGISTER   SERVICE &lt;Name&gt; ERROR &lt;Number&gt; INFO &lt;String&gt; DESCRIPTION &lt;String&gt;
</span><span class='line'>
</span><span class='line'>UNREGISTER SERVICE &lt;Name&gt; ERROR &lt;Number&gt;
</span><span class='line'>
</span><span class='line'>[SERVICE &lt;Name&gt;] ERROR &lt;Number&gt;
</span><span class='line'>
</span><span class='line'>LIST SERVICES | [SERVICE &lt;Name&gt;] ERRORS
</span><span class='line'>
</span><span class='line'>HELP
</span><span class='line'>
</span><span class='line'>#错误码详情
</span><span class='line'>[root@cdb1 staf]# staf local error list 
</span><span class='line'>Error submitting request, RC: 2
</span><span class='line'>Additional info
</span><span class='line'>---------------
</span><span class='line'>error
</span><span class='line'>[root@cdb1 staf]# staf local help error 2
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Description: Unknown service
</span><span class='line'>Details    : You have tried to submit a request to a service that is unknown to STAFProc.  Verify that you have correctly registered the service.
</span></code></pre></td></tr></table></div></figure>


<h4>Registering STAF Services</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>http://staf.sourceforge.net/getservices.php 下载EventV315.tar
</span><span class='line'>[root@cdb1 staf]# tar xf EventV315.tar 
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# vi bin/STAF.cfg 
</span><span class='line'>...
</span><span class='line'>service Event library JSTAF execute /usr/local/staf/event/STAFEvent.jar
</span><span class='line'>
</span><span class='line'>[root@cdb1 staf]# staf local shutdown shutdown 
</span><span class='line'>[root@cdb1 staf]# ./startSTAFProc.sh 
</span><span class='line'>[root@cdb1 staf]# staf local service list 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>Name      Library    Executable                         
</span><span class='line'>--------- ---------- -----------------------------------
</span><span class='line'>...
</span><span class='line'>EVENT     JSTAF      /usr/local/staf/event/STAFEvent.jar
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>#帮助文档： http://staf.sourceforge.net/current/event.htm
</span></code></pre></td></tr></table></div></figure>


<h4>STAF Demo（<strong> 前提得安装上面的EVENT，并且STAFProc也得在图形界面Terminal启动！！ </strong>）</h4>

<ol>
<li>each machine must give the other machine a TRUST level of 5</li>
<li>samples\demo\STAFDemo.jar在CLASSPATH里面.</li>
<li>java STAFDemoController是图形界面程序！！</li>
<li>弹出的窗口【An Arbitrary Process:Handle X】的标题（界面没看到的话，可能是被遮住了）。</li>
</ol>


<p><strong> However, the STAFProcess window should be displayed on your remote machine。</strong></p>

<p>具体的代码解析查阅【8.2. STAF Demo Code - Leveraging STAF】这个章节。</p>

<h2>User&rsquo;s Guide</h2>

<ul>
<li><a href="http://staf.sourceforge.net/current/STAFUG.htm">http://staf.sourceforge.net/current/STAFUG.htm</a></li>
<li><a href="http://staf.sourceforge.net/current/STAFUG.htm#HDRJVMCFG">4.4.2 JSTAF service proxy library</a></li>
</ul>


<h2>STAX Getting Started</h2>

<p><a href="http://staf.sourceforge.net/current/staxgs.pdf">http://staf.sourceforge.net/current/staxgs.pdf</a></p>

<p>Verify that the CLASSPATH environment variable contains the JSTAF.jar file. JSTAF.jar contains the STAF Java APIs
to communicate with STAF from Java programs and is required to register STAF services written in Java.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cdb1 staf]# tar xf ~/STAXV3517.tar 
</span><span class='line'>[root@cdb1 staf]# vi bin/STAF.cfg 
</span><span class='line'>...
</span><span class='line'>SERVICE STAX LIBRARY JSTAF EXECUTE {STAF/Config/STAFRoot}/stax/STAX.jar OPTION J2=-Xmx2048m
</span><span class='line'>SERVICE EVENT LIBRARY JSTAF EXECUTE {STAF/Config/STAFRoot}/stax/STAFEvent.jar
</span><span class='line'>SET MAXQUEUESIZE 10000
</span></code></pre></td></tr></table></div></figure>


<p>If you do not want to include the JVM bin directory in your PATH, then you can use the
&ldquo;OPTION JVM=xxx&rdquo; to specify which Java executable to use for the services.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cdb1 staf]# staf local stax version 
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>3.5.17
</span><span class='line'>[root@cdb1 staf]# staf local stax version jython
</span><span class='line'>Response
</span><span class='line'>--------
</span><span class='line'>2.5.2-staf-v1
</span><span class='line'>[root@cdb1 staf]# 
</span></code></pre></td></tr></table></div></figure>


<p>Errors that occur when running the STAX service will be stored in its JVM log. This log is data/STAF/lang/java/jvm/STAFJVM1/JVMLog.1 in
your root STAF directory</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>source /etc/profile
</span><span class='line'>cd stax
</span><span class='line'>java -jar STAXMon.jar
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt;&gt; You use script elements within your STAX jobs to define Python variables and execute Python code. However, also note that in most cases, all of
</span><span class='line'>the element content and element attributes in your STAX jobs will also be evaluated as Python code. 
</span><span class='line'>
</span><span class='line'>&lt;script&gt;testName = 'CoolTest1'&lt;/script&gt;
</span><span class='line'>&lt;testcase name="testName"&gt;
</span><span class='line'>&lt;testcase name="'%s Part A' % testName"&gt;
</span><span class='line'>&lt;testcase name="'%s Part A on machine %s' % (testName, machineName)"&gt;
</span><span class='line'>
</span><span class='line'>#DoesNothing.xml 
</span><span class='line'>&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
</span><span class='line'>&lt;!DOCTYPE stax SYSTEM "stax.dtd"&gt;
</span><span class='line'>
</span><span class='line'>&lt;stax&gt;
</span><span class='line'>
</span><span class='line'>  &lt;defaultcall function="main"/&gt;
</span><span class='line'>
</span><span class='line'>  &lt;function name="main"&gt;
</span><span class='line'>    &lt;nop/&gt;
</span><span class='line'>  &lt;/function&gt;
</span><span class='line'>
</span><span class='line'>&lt;/stax&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#generate dtd for xml editor
</span><span class='line'>set STAF_QUIET_MODE=1 (or if on Unix: export STAF_QUIET_MODE=1)
</span><span class='line'>STAF local STAX GET DTD &gt; stax.dtd
</span><span class='line'>set STAF_QUIET_MODE= (or if on Unix: unset STAF_QUIET_MODE)
</span><span class='line'>
</span><span class='line'>#RunNotepadProcess.xml
</span><span class='line'>&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;
</span><span class='line'>&lt;!DOCTYPE stax SYSTEM "stax.dtd"&gt;
</span><span class='line'>
</span><span class='line'>&lt;stax&gt;
</span><span class='line'>
</span><span class='line'>  &lt;defaultcall function="main"/&gt;
</span><span class='line'>
</span><span class='line'>  &lt;function name="main"&gt;
</span><span class='line'>
</span><span class='line'>    &lt;process&gt;
</span><span class='line'>      &lt;location&gt;'local'&lt;/location&gt;
</span><span class='line'>      &lt;command&gt;'notepad'&lt;/command&gt;
</span><span class='line'>    &lt;/process&gt;
</span><span class='line'>
</span><span class='line'>  &lt;/function&gt;
</span><span class='line'>
</span><span class='line'>&lt;/stax&gt;</span></code></pre></td></tr></table></div></figure>


<p>结束任务，打开的程序也会被kill掉！！！</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[连接树莓派]]></title>
    <link href="http://winseliu.com/blog/2017/10/05/respberrypi-connected-via/"/>
    <updated>2017-10-05T09:04:24+00:00</updated>
    <id>http://winseliu.com/blog/2017/10/05/respberrypi-connected-via</id>
    <content type="html"><![CDATA[<p>启动树莓派后，总得连上去操作才能告诉它做事情。最常用的就是通过SSH远程控制，前提是能连上网络、知道树莓派获取到的地址。下来把了解到的，以及自实践的连接方式做下小结。</p>

<h4>通过路由器</h4>

<p>网线、无线连接后，通过 <strong> 显示器 </strong> 、<strong> 路由管理界面 </strong> 获取树莓派的地址（在管理web界面有明确的respberrypi的字样）。</p>

<h4>通过USB</h4>

<ol>
<li>USB转COM</li>
</ol>


<p>USB连接电脑，连树莓派的GPIO对应的针。然后通过COM口协议与树莓派通信</p>

<ol>
<li>USB共享网络</li>
</ol>


<p>使用手机的USB共享网络。</p>

<p>USB连树莓派，Micro口连手机。手机上打开USB网络共享，树莓派中会建立一个usb0的网卡。这样就能通过这个网卡进行上网了（网上也有说同时打开wifi热点，没啥用啊，usb和wlan是两个不同的网段）。</p>

<p>手机上安装一个ssh的工具（juicessh等），先连上本地的shell，然后执行 <code>cat /proc/net/arp</code> 或者 <code>busybox arp -a</code> 查看与 rndis0 同一个网段的ip（一般就是连接到树莓派的地址了）。</p>

<p>在手机上安装一个IP扫描软件应该也行，但 <strong> 通过ARP是最简单最高效的方式了。</strong></p>

<p><img src="http://winseliu.com/images/blogs/raspberrypi-phone-usb-network.png" alt="" /></p>

<p>注意：busybox感觉像一个工具集，包含了很多linux的命令，并且有些命令参数比系统提供的更全，如 <code>tar -j</code> 。可以用 <code>busybox --help</code> 查看帮助。</p>

<h4>网线互联</h4>

<p>一跟网线直接连电脑和树莓派。</p>

<p>互传数据应该有用。当前感觉，这种方式没啥优势，有点鸡肋。上网比较麻烦：手动设置IP、域名解析、还要在电脑上面搞网卡绑定。</p>

<p>下面自动获取的方法（没试，应该是可以的吧）：</p>

<blockquote><p>网线直接把树莓派与电脑连接起来，电脑需要连wifi（如果不连接无法使用网络共享让树莓派获取到ip地址），在 设置->网络->wlan->网络与共享中心->wlan->属性->共享->允许​其它用户通过它来连接->确定。</p>

<p>稍等片刻树莓派应该就获取到一个ip地址了，此时打开命令提示符（我用的Xshell），运行arp -a命令，应该就可以看到​一个局域网段，如192.168.xx.1，通常以192.168开头，最后一位是1的那个接口，下面多出来的一条动态记录就是树莓派的。</p></blockquote>

<h2>参考：</h2>

<ul>
<li><a href="https://jingyan.baidu.com/article/676629977483b154d51b848e.html">使用Android手机作为树莓派的屏幕</a></li>
<li><a href="http://www.jianshu.com/p/f2e0a02c01d9">http://www.jianshu.com/p/f2e0a02c01d9</a></li>
<li><a href="http://blog.163.com/elliot_alderson/blog/static/26832905920161122104246919/">http://blog.163.com/elliot_alderson/blog/static/26832905920161122104246919/</a> 添加过ifcfg-usb0，但需要重启网卡才是设置IP地址，麻烦。</li>
<li><a href="http://blog.163.com/elliot_alderson/blog/static/268329059201611925543687/">树莓派安装kali linux （系统安装和初步配置）</a> 安装、gparted扩容</li>
</ul>


<h2>键盘输入、手机显示</h2>

<p>前提：安装screen。</p>

<ul>
<li>连接USB键盘，启动树莓派。</li>
<li>键盘盲打登录（输入：root回车centos回车screen -S pi）。</li>
<li>然后手机上ssh连接，进入pi的会话（screen -x pi）</li>
</ul>


<p>这样就能用键盘敲、手机看了！觉得挺好玩的。</p>

<h2>重新折腾树莓派</h2>

<ul>
<li>安装centos7: 密码root/centos</li>
</ul>


<p><a href="http://www.21ic.com/evm/trick/201605/675705.htm">http://www.21ic.com/evm/trick/201605/675705.htm</a></p>

<ul>
<li>扩大容量：</li>
</ul>


<p><a href="http://blog.csdn.net/qq_20480611/article/details/48657827">http://blog.csdn.net/qq_20480611/article/details/48657827</a></p>

<p>fdisk删掉分区然后重新加，重启后执行resize2fs</p>

<ul>
<li>安装wiringpi</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone git://git.drogon.net/wiringPi
</span><span class='line'>cd wiringPi
</span><span class='line'>./build
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>epel</li>
</ul>


<p><a href="https://hobo.house/2016/03/03/installing-centos-on-the-raspberry-pi-2/">https://hobo.house/2016/03/03/installing-centos-on-the-raspberry-pi-2/</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat &gt; /etc/yum.repos.d/epel-unsigned.repo &lt;&lt; EOF
</span><span class='line'>[epel]
</span><span class='line'>name=Epel rebuild for armhfp
</span><span class='line'>baseurl=https://armv7.dev.centos.org/repodir/epel-pass-1/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>
</span><span class='line'>EOF
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[两台主机的docker通过route互联互通]]></title>
    <link href="http://winseliu.com/blog/2017/09/20/docker-manual-make-connect-each-other/"/>
    <updated>2017-09-20T10:34:52+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/20/docker-manual-make-connect-each-other</id>
    <content type="html"><![CDATA[<p>前面一直用k8s的flannel来建立主机间docker容器的互联，但是当仅有两台机器用来做测试的时刻，安装一个flannel也是挺纠结的：麻烦、还有未知的问题，起一个服务在那里总会有那么些担忧。</p>

<p>其实可以直接通过建立路由来实现两台机器间容器的互联互通：<a href="http://www.pangxie.space/docker/139">Docker多台宿主机间的容器互联-centos7（直接路由）</a></p>

<p>两台主机（centos7/docker-1.12.6）：</p>

<ul>
<li>192.168.191.140 kube-master</li>
<li>192.168.191.141 kube-worker1</li>
</ul>


<h2>安装/配置docker</h2>

<p>这里不多讲了，参考 <a href="http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/">Kubeadm部署kubernetes</a> 进行docker的安装。</p>

<h2>建立新网卡，修改docker配置使用新网卡</h2>

<ul>
<li>安装/更新依赖</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install net-tools bridge-utils -y</span></code></pre></td></tr></table></div></figure>


<ul>
<li>关防火墙、关selinux</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>setenforce 0
</span><span class='line'>
</span><span class='line'>vi /etc/selinux/config
</span><span class='line'>SELINUX=disabled
</span><span class='line'>
</span><span class='line'>systemctl stop firewalld
</span><span class='line'>systemctl disable firewalld</span></code></pre></td></tr></table></div></figure>


<ul>
<li>设置ip转发</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo 1 &gt; /proc/sys/net/ipv4/ip_forward
</span><span class='line'>
</span><span class='line'>vi /etc/sysctl.conf
</span><span class='line'>net.ipv4.ip_forward = 1  </span></code></pre></td></tr></table></div></figure>


<ul>
<li>删docker0，建kbr0</li>
</ul>


<p>先停docker！先停docker！先停docker！（好像docker会缓冲bridge的ip）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service docker stop
</span><span class='line'>brctl addbr kbr0
</span><span class='line'>ip link set dev docker0 down
</span><span class='line'>ip link del dev docker0</span></code></pre></td></tr></table></div></figure>


<p>下面的配置，两台机不同，如下：</p>

<table>
<thead>
<tr>
<th style="text-align:left;"> 192.168.191.140 kube-master                   </th>
<th style="text-align:left;"> 192.168.191.141 kube-worker1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> vi /etc/sysconfig/network-scripts/ifcfg-kbr0</td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> DEVICE=kbr0                                   </td>
<td style="text-align:left;"> DEVICE=kbr0</td>
</tr>
<tr>
<td style="text-align:left;"> ONBOOT=yes                                    </td>
<td style="text-align:left;"> ONBOOT=yes</td>
</tr>
<tr>
<td style="text-align:left;"> BOOTPROTO=static                              </td>
<td style="text-align:left;"> BOOTPROTO=static</td>
</tr>
<tr>
<td style="text-align:left;"> IPADDR=172.17.3.1                             </td>
<td style="text-align:left;"> IPADDR=172.17.4.1</td>
</tr>
<tr>
<td style="text-align:left;"> NETMASK=255.255.255.0                         </td>
<td style="text-align:left;"> NETMASK=255.255.255.0</td>
</tr>
<tr>
<td style="text-align:left;"> GATEWAY=172.17.3.0                            </td>
<td style="text-align:left;"> GATEWAY=172.17.4.0</td>
</tr>
<tr>
<td style="text-align:left;"> USERCTL=no                                    </td>
<td style="text-align:left;"> USERCTL=no</td>
</tr>
<tr>
<td style="text-align:left;"> TYPE=Bridge                                   </td>
<td style="text-align:left;"> TYPE=Bridge</td>
</tr>
<tr>
<td style="text-align:left;"> IPV6INIT=no                                   </td>
<td style="text-align:left;"> IPV6INIT=no</td>
</tr>
<tr>
<td style="text-align:left;">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</td>
<td style="text-align:left;">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</td>
</tr>
<tr>
<td style="text-align:left;"> vi /etc/sysconfig/network-scripts/route-ens33 （ip对应的网卡名称）</td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> 172.17.4.0/24 via 192.168.191.141 dev ens33   </td>
<td style="text-align:left;"> 172.17.3.0/24 via 192.168.191.140 dev ens33</td>
</tr>
<tr>
<td style="text-align:left;">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</td>
<td style="text-align:left;">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</td>
</tr>
</tbody>
</table>


<p>参考： <a href="https://www.centos.org/docs/5/html/5.2/Deployment_Guide/s1-networkscripts-static-routes.html">Configuring Static Routes</a></p>

<ul>
<li>修改docker配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi /usr/lib/systemd/system/docker.service     
</span><span class='line'>ExecStart=/usr/bin/dockerd --bridge=kbr0 
</span><span class='line'>
</span><span class='line'>systemctl daemon-reload </span></code></pre></td></tr></table></div></figure>


<ul>
<li>重新启动</li>
</ul>


<p>先起网卡！先起网卡！先起网卡！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service network restart
</span><span class='line'>
</span><span class='line'>systemctl start docker</span></code></pre></td></tr></table></div></figure>


<h2>最终效果</h2>

<table>
<thead>
<tr>
<th style="text-align:left;"> 192.168.191.140 kube-master                                                   </th>
<th style="text-align:left;"> 192.168.191.141 kube-worker1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;"> [root@kube-master ~]# ifconfig                                                </td>
<td style="text-align:left;"> [root@kube-worker1 ~]# ifconfig</td>
</tr>
<tr>
<td style="text-align:left;"> ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500                   </td>
<td style="text-align:left;"> ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500</td>
</tr>
<tr>
<td style="text-align:left;">         inet 192.168.191.140  netmask 255.255.255.0  broadcast 192.168.191.255</td>
<td style="text-align:left;">         inet 192.168.191.141  netmask 255.255.255.0  broadcast 192.168.191.255</td>
</tr>
<tr>
<td style="text-align:left;">         inet6 fe80::1186:2fe5:9ee5:8790  prefixlen 64  scopeid 0x20<link>     </td>
<td style="text-align:left;">         inet6 fe80::3995:4490:e2e7:1d0f  prefixlen 64  scopeid 0x20<link></td>
</tr>
<tr>
<td style="text-align:left;">         ether 00:0c:29:40:2d:15  txqueuelen 1000  (Ethernet)                  </td>
<td style="text-align:left;">         ether 00:0c:29:2e:67:4d  txqueuelen 1000  (Ethernet)</td>
</tr>
<tr>
<td style="text-align:left;">         RX packets 18010  bytes 10754845 (10.2 MiB)                           </td>
<td style="text-align:left;">         RX packets 19871  bytes 12247126 (11.6 MiB)</td>
</tr>
<tr>
<td style="text-align:left;">         RX errors 0  dropped 0  overruns 0  frame 0                           </td>
<td style="text-align:left;">         RX errors 0  dropped 0  overruns 0  frame 0</td>
</tr>
<tr>
<td style="text-align:left;">         TX packets 4797  bytes 475332 (464.1 KiB)                             </td>
<td style="text-align:left;">         TX packets 5647  bytes 561624 (548.4 KiB)</td>
</tr>
<tr>
<td style="text-align:left;">         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0            </td>
<td style="text-align:left;">         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</td>
</tr>
<tr>
<td style="text-align:left;">                                                                               </td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> kbr1: flags=4099&lt;UP,BROADCAST,MULTICAST>  mtu 1500                            </td>
<td style="text-align:left;"> kbr0: flags=4099&lt;UP,BROADCAST,MULTICAST>  mtu 1500</td>
</tr>
<tr>
<td style="text-align:left;">         inet 172.17.3.1  netmask 255.255.255.0  broadcast 172.17.3.255        </td>
<td style="text-align:left;">         inet 172.17.4.1  netmask 255.255.255.0  broadcast 172.17.4.255</td>
</tr>
<tr>
<td style="text-align:left;">         ether 00:00:00:00:00:00  txqueuelen 1000  (Ethernet)                  </td>
<td style="text-align:left;">         ether 00:00:00:00:00:00  txqueuelen 1000  (Ethernet)</td>
</tr>
<tr>
<td style="text-align:left;">         RX packets 179  bytes 13932 (13.6 KiB)                                </td>
<td style="text-align:left;">         RX packets 139  bytes 10492 (10.2 KiB)</td>
</tr>
<tr>
<td style="text-align:left;">         RX errors 0  dropped 0  overruns 0  frame 0                           </td>
<td style="text-align:left;">         RX errors 0  dropped 0  overruns 0  frame 0</td>
</tr>
<tr>
<td style="text-align:left;">         TX packets 43  bytes 3894 (3.8 KiB)                                   </td>
<td style="text-align:left;">         TX packets 36  bytes 3004 (2.9 KiB)</td>
</tr>
<tr>
<td style="text-align:left;">         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0            </td>
<td style="text-align:left;">         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</td>
</tr>
<tr>
<td style="text-align:left;">                                                                               </td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> lo: flags=73&lt;UP,LOOPBACK,RUNNING>  mtu 65536                                  </td>
<td style="text-align:left;"> lo: flags=73&lt;UP,LOOPBACK,RUNNING>  mtu 65536</td>
</tr>
<tr>
<td style="text-align:left;">         inet 127.0.0.1  netmask 255.0.0.0                                     </td>
<td style="text-align:left;">         inet 127.0.0.1  netmask 255.0.0.0</td>
</tr>
<tr>
<td style="text-align:left;">         inet6 ::1  prefixlen 128  scopeid 0x10<host>                          </td>
<td style="text-align:left;">         inet6 ::1  prefixlen 128  scopeid 0x10<host></td>
</tr>
<tr>
<td style="text-align:left;">         loop  txqueuelen 1  (Local Loopback)                                  </td>
<td style="text-align:left;">         loop  txqueuelen 1  (Local Loopback)</td>
</tr>
<tr>
<td style="text-align:left;">         RX packets 140  bytes 11644 (11.3 KiB)                                </td>
<td style="text-align:left;">         RX packets 215  bytes 18260 (17.8 KiB)</td>
</tr>
<tr>
<td style="text-align:left;">         RX errors 0  dropped 0  overruns 0  frame 0                           </td>
<td style="text-align:left;">         RX errors 0  dropped 0  overruns 0  frame 0</td>
</tr>
<tr>
<td style="text-align:left;">         TX packets 140  bytes 11644 (11.3 KiB)                                </td>
<td style="text-align:left;">         TX packets 215  bytes 18260 (17.8 KiB)</td>
</tr>
<tr>
<td style="text-align:left;">         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0            </td>
<td style="text-align:left;">         TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</td>
</tr>
<tr>
<td style="text-align:left;">                                                                               </td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> [root@kube-master ~]# route -n                                                </td>
<td style="text-align:left;"> [root@kube-worker1 ~]# route -n</td>
</tr>
<tr>
<td style="text-align:left;"> Kernel IP routing table                                                       </td>
<td style="text-align:left;"> Kernel IP routing table</td>
</tr>
<tr>
<td style="text-align:left;"> Destination     Gateway         Genmask         Flags Metric Ref    Use Iface </td>
<td style="text-align:left;"> Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</td>
</tr>
<tr>
<td style="text-align:left;"> 0.0.0.0         192.168.191.2   0.0.0.0         UG    100    0        0 ens33 </td>
<td style="text-align:left;"> 0.0.0.0         192.168.191.2   0.0.0.0         UG    100    0        0 ens33</td>
</tr>
<tr>
<td style="text-align:left;"> 172.17.3.0      0.0.0.0         255.255.255.0   U     427    0        0 kbr1  </td>
<td style="text-align:left;"> 172.17.3.0      192.168.191.140 255.255.255.0   UG    100    0        0 ens33</td>
</tr>
<tr>
<td style="text-align:left;"> 172.17.4.0      192.168.191.141 255.255.255.0   UG    100    0        0 ens33 </td>
<td style="text-align:left;"> 172.17.4.0      0.0.0.0         255.255.255.0   U     425    0        0 kbr0</td>
</tr>
<tr>
<td style="text-align:left;"> 192.168.191.0   0.0.0.0         255.255.255.0   U     100    0        0 ens33 </td>
<td style="text-align:left;"> 192.168.191.0   0.0.0.0         255.255.255.0   U     100    0        0 ens33</td>
</tr>
<tr>
<td style="text-align:left;"> [root@kube-master ~]#                                                         </td>
<td style="text-align:left;"> [root@kube-worker1 ~]#</td>
</tr>
<tr>
<td style="text-align:left;"> [root@kube-master ~]# docker run -ti &ndash;rm busybox sh                          </td>
<td style="text-align:left;"> [root@kube-worker1 ~]# docker run -ti &ndash;rm busybox sh</td>
</tr>
<tr>
<td style="text-align:left;"> / # ifconfig                                                                  </td>
<td style="text-align:left;"> / # ifconfig</td>
</tr>
<tr>
<td style="text-align:left;"> eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:03:02                       </td>
<td style="text-align:left;"> eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:04:02</td>
</tr>
<tr>
<td style="text-align:left;">           inet addr:172.17.3.2  Bcast:0.0.0.0  Mask:255.255.255.0             </td>
<td style="text-align:left;">           inet addr:172.17.4.2  Bcast:0.0.0.0  Mask:255.255.255.0</td>
</tr>
<tr>
<td style="text-align:left;">           inet6 addr: fe80::42:acff:fe11:302/64 Scope:Link                    </td>
<td style="text-align:left;">           inet6 addr: fe80::42:acff:fe11:402/64 Scope:Link</td>
</tr>
<tr>
<td style="text-align:left;">           UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1                  </td>
<td style="text-align:left;">           UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</td>
</tr>
<tr>
<td style="text-align:left;">           RX packets:23 errors:0 dropped:0 overruns:0 frame:0                 </td>
<td style="text-align:left;">           RX packets:16 errors:0 dropped:0 overruns:0 frame:0</td>
</tr>
<tr>
<td style="text-align:left;">           TX packets:15 errors:0 dropped:0 overruns:0 carrier:0               </td>
<td style="text-align:left;">           TX packets:8 errors:0 dropped:0 overruns:0 carrier:0</td>
</tr>
<tr>
<td style="text-align:left;">           collisions:0 txqueuelen:0                                           </td>
<td style="text-align:left;">           collisions:0 txqueuelen:0</td>
</tr>
<tr>
<td style="text-align:left;">           RX bytes:1870 (1.8 KiB)  TX bytes:1222 (1.1 KiB)                    </td>
<td style="text-align:left;">           RX bytes:1296 (1.2 KiB)  TX bytes:648 (648.0 B)</td>
</tr>
<tr>
<td style="text-align:left;">                                                                               </td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> lo        Link encap:Local Loopback                                           </td>
<td style="text-align:left;"> lo        Link encap:Local Loopback</td>
</tr>
<tr>
<td style="text-align:left;">           inet addr:127.0.0.1  Mask:255.0.0.0                                 </td>
<td style="text-align:left;">           inet addr:127.0.0.1  Mask:255.0.0.0</td>
</tr>
<tr>
<td style="text-align:left;">           inet6 addr: ::1/128 Scope:Host                                      </td>
<td style="text-align:left;">           inet6 addr: ::1/128 Scope:Host</td>
</tr>
<tr>
<td style="text-align:left;">           UP LOOPBACK RUNNING  MTU:65536  Metric:1                            </td>
<td style="text-align:left;">           UP LOOPBACK RUNNING  MTU:65536  Metric:1</td>
</tr>
<tr>
<td style="text-align:left;">           RX packets:0 errors:0 dropped:0 overruns:0 frame:0                  </td>
<td style="text-align:left;">           RX packets:0 errors:0 dropped:0 overruns:0 frame:0</td>
</tr>
<tr>
<td style="text-align:left;">           TX packets:0 errors:0 dropped:0 overruns:0 carrier:0                </td>
<td style="text-align:left;">           TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</td>
</tr>
<tr>
<td style="text-align:left;">           collisions:0 txqueuelen:1                                           </td>
<td style="text-align:left;">           collisions:0 txqueuelen:1</td>
</tr>
<tr>
<td style="text-align:left;">           RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)                              </td>
<td style="text-align:left;">           RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</td>
</tr>
<tr>
<td style="text-align:left;"> / # ping 172.17.4.2                                                           </td>
<td></td>
</tr>
<tr>
<td style="text-align:left;"> PING 172.17.4.2 (172.17.4.2): 56 data bytes                                   </td>
<td style="text-align:left;"> / # ping 172.17.3.2</td>
</tr>
<tr>
<td style="text-align:left;"> 64 bytes from 172.17.4.2: seq=0 ttl=62 time=2.598 ms                          </td>
<td style="text-align:left;"> PING 172.17.3.2 (172.17.3.2): 56 data bytes</td>
</tr>
<tr>
<td style="text-align:left;"> 64 bytes from 172.17.4.2: seq=1 ttl=62 time=1.569 ms                          </td>
<td style="text-align:left;"> 64 bytes from 172.17.3.2: seq=0 ttl=62 time=1.421 ms</td>
</tr>
<tr>
<td style="text-align:left;"> 64 bytes from 172.17.4.2: seq=2 ttl=62 time=1.194 ms                          </td>
<td style="text-align:left;"> 64 bytes from 172.17.3.2: seq=1 ttl=62 time=1.446 ms</td>
</tr>
<tr>
<td style="text-align:left;"> ^C                                                                            </td>
<td style="text-align:left;"> ^C</td>
</tr>
<tr>
<td style="text-align:left;"> &mdash; 172.17.4.2 ping statistics &mdash;                                            </td>
<td style="text-align:left;"> &mdash; 172.17.3.2 ping statistics &mdash;</td>
</tr>
<tr>
<td style="text-align:left;"> 3 packets transmitted, 3 packets received, 0% packet loss                     </td>
<td style="text-align:left;"> 2 packets transmitted, 2 packets received, 0% packet loss</td>
</tr>
<tr>
<td style="text-align:left;"> round-trip min/avg/max = 1.194/1.787/2.598 ms                                 </td>
<td style="text-align:left;"> round-trip min/avg/max = 1.421/1.433/1.446 ms</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:left;">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-</td>
<td style="text-align:left;">&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</td>
</tr>
</tbody>
</table>


<p>效果还不错，什么都没有安装配置下route两台机器的docker就互联互通了。二三台机器使用这种方式最省事的，并且理论上效率也是最高的。</p>

<h2>其他参考</h2>

<ul>
<li><a href="http://www.infoq.com/cn/articles/docker-network-and-pipework-open-source-explanation-practice">Docker网络详解及pipework源码解读与实践</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用U盘安装Centos7]]></title>
    <link href="http://winseliu.com/blog/2017/09/19/os-install-via-usb/"/>
    <updated>2017-09-19T14:26:30+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/19/os-install-via-usb</id>
    <content type="html"><![CDATA[<p>使用U盘安装操作系统，原来一直用 unetbootin-windows 但这次不好使，U盘重新格式化也不行。遇到的几个问题：</p>

<ol>
<li>有光驱最好啊，没光驱才用U盘安装啊！</li>
<li>U盘是否能被识别？安装系统嘛，你的屈就电脑，它不识别你就只能换另一个咯。旧的服务器识别USB3.0有问题。</li>
<li>进BIOS看启动项是否有你的U盘？把U盘的顺序调整到HDD的前面。与第二项是一起的检测的。</li>
<li>做的系统是否正确？下载<a href="http://isoredirect.centos.org/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1708.iso">Minimal.iso</a>，用<a href="https://wiki.centos.org/zh/HowTos/InstallFromUSBkey">采用 Windows iso2usb</a> 把iso载入到U盘。</li>
</ol>


<p>注意1： 看到 ntldr is missing 这样的提示，就可以去再重写一遍U盘了！</p>

<p>注意2： U盘必须是FAT32的！！</p>

<p>安装系统的时刻，问题又来了：</p>

<ul>
<li>dracut_initqueue[599]: Warning: Could not boot</li>
</ul>


<p>找不到镜像。</p>

<p>处理： <strong> 等一段时间后会进行入到 Dracut shell </strong>, 查看下 /dev 下面有哪些磁盘设备。<strong> 最大/后的那个磁盘设备 </strong> 一般就是你的U盘。如我的是 /dev/sdc1 。</p>

<p>CTRL+ALT+DELETE 重新启动，进入CENTOS安装界面启动选项时，按TAB，替换为如下内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vmlinux initrd=initrd.img
</span><span class='line'>inst.stage2=hd:/dev/sdc1 quit</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://m.blog.csdn.net/w_z_z_1991/article/details/41909851">http://m.blog.csdn.net/w_z_z_1991/article/details/41909851</a></li>
<li><a href="http://www.jianshu.com/p/e3cd90c540c3">http://www.jianshu.com/p/e3cd90c540c3</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redmine部署以及插件安装]]></title>
    <link href="http://winseliu.com/blog/2017/09/18/redmine-deploy-and-install-plugins/"/>
    <updated>2017-09-18T15:46:24+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/18/redmine-deploy-and-install-plugins</id>
    <content type="html"><![CDATA[<p>Redmine是类似JIRA的一个项目/BUG管理工具，使用ruby语言编写的。安装相对就麻烦一点，不熟嘛，一堆的东西要安装。有两种简单/傻瓜式的安装方式：</p>

<ul>
<li>bitnami-redmine，相当于一键安装；</li>
<li>docker + redmine，使用docker把所有的依赖都安装好，只需要配置remine即可。</li>
</ul>


<p>这里选择使用docker-compose来安装 <a href="https://github.com/sameersbn/docker-redmine">sameersbn/redmine:3.4.2</a></p>

<h2>部署</h2>

<p>先跑起来，然后再根据需求修改配置。搞得不好的话，重新安装也超级简单，是吧！</p>

<ul>
<li><a href="https://github.com/sameersbn/docker-redmine#quick-start">https://github.com/sameersbn/docker-redmine#quick-start</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir -p /srv/docker/redmine/{redmine,postgresql}
</span><span class='line'>
</span><span class='line'>wget https://raw.githubusercontent.com/sameersbn/docker-redmine/master/docker-compose.yml
</span><span class='line'>docker-compose up
</span></code></pre></td></tr></table></div></figure>


<p>启动后，浏览器访问 <a href="http://HOSTED_IP:10083">http://HOSTED_IP:10083</a> ，使用 admin/admin 登录。</p>

<ul>
<li>重新弄，初始化：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker-compose rm -f 或者 docker-compose down
</span><span class='line'>
</span><span class='line'>rm -rf /srv/docker/redmine/redmine/tmp/*
</span><span class='line'>rm -rf /srv/docker/redmine/postgresql/* 
</span><span class='line'>
</span><span class='line'>docker-compose up --build
</span></code></pre></td></tr></table></div></figure>


<h2>Theme主题</h2>

<ul>
<li><a href="https://github.com/sameersbn/docker-redmine#themes">https://github.com/sameersbn/docker-redmine#themes</a></li>
<li><a href="http://www.redmine.org/projects/redmine/wiki/Themes">http://www.redmine.org/projects/redmine/wiki/Themes</a></li>
<li><a href="https://www.redmineup.com/pages/themes/a1">https://www.redmineup.com/pages/themes/a1</a></li>
</ul>


<p>改头换面，下载主题后放到 /srv/docker/redmine/redmine/themes/ 目录下。然后 <strong> 重启容器 </strong>，再重新登录，修改 <strong> 管理 - 配置 - 显示 - 主题 - A1 </strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s redmine]# ll /srv/docker/redmine/redmine/themes/
</span><span class='line'>total 0
</span><span class='line'>drwxr-xr-x. 6 es es 69 Sep 18 23:38 a1
</span></code></pre></td></tr></table></div></figure>


<h2>Plugins</h2>

<p>有些插件不兼容3.4，注意版本的选择！一下是在3.4下面安装使用的插件：</p>

<ul>
<li><a href="http://www.redmine.org/projects/redmine/wiki/Plugins">http://www.redmine.org/projects/redmine/wiki/Plugins</a></li>
<li><a href="http://www.redmine.org/plugins/clipboard_image_paste">http://www.redmine.org/plugins/clipboard_image_paste</a></li>
<li><a href="https://github.com/peclik/clipboard_image_paste">https://github.com/peclik/clipboard_image_paste</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_checklists">http://www.redmine.org/plugins/redmine_checklists</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_agile">http://www.redmine.org/plugins/redmine_agile</a></li>
<li><a href="https://github.com/paginagmbh/redmine_lightbox2.git">https://github.com/paginagmbh/redmine_lightbox2.git</a></li>
<li><a href="https://github.com/paginagmbh/redmine_lightbox2">https://github.com/paginagmbh/redmine_lightbox2</a></li>
<li><a href="http://www.redmine.org/plugins/mega_calendar">http://www.redmine.org/plugins/mega_calendar</a></li>
<li><a href="https://github.com/berti92/mega_calendar/wiki/Installation">https://github.com/berti92/mega_calendar/wiki/Installation</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_work_time">http://www.redmine.org/plugins/redmine_work_time</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_issue_templates">http://www.redmine.org/plugins/redmine_issue_templates</a></li>
<li>Kanban</li>
<li><a href="http://www.redmine.org/plugins/redhopper">http://www.redmine.org/plugins/redhopper</a></li>
<li><a href="http://www.redmine.org/plugins/redhopper">http://www.redmine.org/plugins/redhopper</a></li>
<li><a href="http://www.redmine.org/plugins/deployer">http://www.redmine.org/plugins/deployer</a></li>
<li><a href="https://github.com/zapic0/deployer">https://github.com/zapic0/deployer</a></li>
<li><a href="http://www.redmine.org/plugins/redmine-ckeditor">http://www.redmine.org/plugins/redmine-ckeditor</a></li>
<li><a href="https://github.com/a-ono/redmine_ckeditor">https://github.com/a-ono/redmine_ckeditor</a></li>
<li><a href="http://www.redmine.org/plugins/apijs">http://www.redmine.org/plugins/apijs</a> 有一些依赖要安装，没用到的可以不安装。</li>
<li><a href="https://www.luigifab.info/redmine/en/apijs.php">https://www.luigifab.info/redmine/en/apijs.php</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s plugins]# sed -i '/haml/s/^/#/' redhopper/Gemfile           
</span><span class='line'>[root@k8s plugins]# mv apijs redmine_apijs
</span><span class='line'>
</span><span class='line'>[root@k8s redmine]# ll /srv/docker/redmine/redmine/plugins/
</span><span class='line'>total 0
</span><span class='line'>drwxr-xr-x.  8 es es 118 Sep 18 14:05 clipboard_image_paste
</span><span class='line'>drwxr-xr-x. 10 es es 212 Sep 18 19:18 deployer
</span><span class='line'>drwxr-xr-x.  7 es es 160 Sep 18 12:00 issuefy
</span><span class='line'>drwxr-xr-x.  4 es es  60 Sep 18 11:59 line_numbers
</span><span class='line'>drwxr-xr-x.  8 es es 182 Sep 17 18:05 mega_calendar
</span><span class='line'>drwxr-xr-x.  6 es es 158 Sep 18 12:00 open_flash_chart
</span><span class='line'>drwxrwxr-x.  8 es es 225 Sep 18 22:15 redhopper
</span><span class='line'>drwxr-xr-x.  9 es es 156 Sep  6 19:02 redmine_agile
</span><span class='line'>drwxr-xr-x.  7 es es 133 Sep 18 22:00 redmine_apijs
</span><span class='line'>drwxr-xr-x. 10 es es 119 Aug 30 21:46 redmine_checklists
</span><span class='line'>drwxr-xr-x.  9 es es 158 Sep 18 19:19 redmine_ckeditor
</span><span class='line'>drwxr-xr-x.  8 es es 221 Sep 18 12:01 redmine_code_review
</span><span class='line'>drwxr-xr-x.  8 es es 252 Sep 18 12:01 redmine_dashboard
</span><span class='line'>drwxr-xr-x.  3 es es  70 Sep 18 12:00 redmine_embedded_video
</span><span class='line'>drwxr-xr-x.  2 es es  78 Sep 18 12:00 redmine_gist
</span><span class='line'>drwxrwxr-x.  8 es es 129 Aug  5 10:52 redmine_issue_templates
</span><span class='line'>drwxr-xr-x.  8 es es 170 Sep 18 17:46 redmine_lightbox2
</span><span class='line'>drwxr-xr-x.  8 es es 160 Mar  5  2017 redmine_work_time</span></code></pre></td></tr></table></div></figure>


<p>不重启容器的话，可以登录到容器把 ~/data/plugins 拷贝到 ~/redmine/plugins 下面，然后执行下面的命令进行更新：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@f0481f5f8cda:/home/redmine/redmine# 
</span><span class='line'>bundle install --without development test
</span><span class='line'>bundle exec rake redmine:plugins:migrate RAILS_ENV=production
</span><span class='line'>
</span><span class='line'>supervisorctl restart unicorn
</span></code></pre></td></tr></table></div></figure>


<h2>其他的一些插件</h2>

<ul>
<li><a href="http://www.redmine.org/plugins/dmsf">http://www.redmine.org/plugins/dmsf</a></li>
<li><a href="https://github.com/danmunn/redmine_dmsf">https://github.com/danmunn/redmine_dmsf</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_git_hosting">http://www.redmine.org/plugins/redmine_git_hosting</a> X</li>
<li><a href="http://www.redmine.org/plugins/redmine_upwork_plugin">http://www.redmine.org/plugins/redmine_upwork_plugin</a></li>
<li><a href="https://github.com/alexbevi/redmine_knowledgebase">https://github.com/alexbevi/redmine_knowledgebase</a></li>
<li><a href="https://github.com/danmunn/redmine_dmsf">https://github.com/danmunn/redmine_dmsf</a></li>
<li><a href="https://github.com/jbox-web/redmine_jenkins">https://github.com/jbox-web/redmine_jenkins</a></li>
<li><a href="https://github.com/masweetman/issue_charts">https://github.com/masweetman/issue_charts</a></li>
<li>3.3.x</li>
<li><a href="http://www.redmine.org/plugins/redmine_pivot_table">http://www.redmine.org/plugins/redmine_pivot_table</a></li>
<li><a href="https://www.redmine.org/plugins/advanced_roadmap_v2">https://www.redmine.org/plugins/advanced_roadmap_v2</a></li>
<li><a href="https://github.com/Coren/redmine_advanced_roadmap_v2">https://github.com/Coren/redmine_advanced_roadmap_v2</a></li>
<li><a href="https://github.com/Loriowar/redmine_issues_tree">https://github.com/Loriowar/redmine_issues_tree</a></li>
<li><a href="https://github.com/speedy32129/projects_show">https://github.com/speedy32129/projects_show</a></li>
</ul>


<h2>参考</h2>

<ul>
<li><a href="https://github.com/bitnami/bitnami-docker-redmine">https://github.com/bitnami/bitnami-docker-redmine</a></li>
<li><a href="http://11398377.blog.51cto.com/11388377/1875686">http://11398377.blog.51cto.com/11388377/1875686</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker Compose入门]]></title>
    <link href="http://winseliu.com/blog/2017/09/17/docker-compose-hello/"/>
    <updated>2017-09-17T00:48:25+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/17/docker-compose-hello</id>
    <content type="html"><![CDATA[<p>使用Docker也一段时间了，一开始直接使用命令行 docker run 来启动的，后面使用 k8s 来管理，对于多机环境来说还是挺方便的。但是如果仅仅是单机上面跑docker容器，安装一套 k8s 的话也挺尴尬的。</p>

<p>docker提供了compose编排的功能，通过配置文件的方式来启动、管理（多）容器的运行。有点启动脚本的意思，当然也包含一些管理的元素，对容器LifeCycle的管理。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s composetest]# docker version
</span><span class='line'>Client:
</span><span class='line'> Version:      1.12.6
</span><span class='line'> API version:  1.24
</span><span class='line'> Go version:   go1.6.4
</span><span class='line'> Git commit:   78d1802
</span><span class='line'> Built:        Tue Jan 10 20:20:01 2017
</span><span class='line'> OS/Arch:      linux/amd64
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Version:      1.12.6
</span><span class='line'> API version:  1.24
</span><span class='line'> Go version:   go1.6.4
</span><span class='line'> Git commit:   78d1802
</span><span class='line'> Built:        Tue Jan 10 20:20:01 2017
</span><span class='line'> OS/Arch:      linux/amd64
</span><span class='line'> 
</span><span class='line'>[root@k8s composetest]# docker-compose version
</span><span class='line'>docker-compose version 1.16.1, build 6d1ac21
</span><span class='line'>docker-py version: 2.5.1
</span><span class='line'>CPython version: 2.7.13
</span><span class='line'>OpenSSL version: OpenSSL 1.0.1t  3 May 2016
</span></code></pre></td></tr></table></div></figure>


<p>docker的版本需要和compose配置的版本适配： <a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a> ，docker-1.12的话，compose version不能高于 2.1。<a href="https://docs.docker.com/compose/compose-file/compose-file-v2/#build">Compose file version 2</a> 。</p>

<p>先安装官网的helloworld来运行一个例子：</p>

<ul>
<li><a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a></li>
<li><a href="https://docs.docker.com/compose/gettingstarted/#prerequisites">https://docs.docker.com/compose/gettingstarted/#prerequisites</a></li>
</ul>


<h2>安装：</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 浏览器下载docker-compose
</span><span class='line'>https://github.com/docker/compose/releases/download/1.16.1/docker-compose-Linux-x86_64
</span><span class='line'>
</span><span class='line'>[root@k8s opt]# cd /usr/local/bin/
</span><span class='line'>[root@k8s bin]# rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring docker-compose-Linux-x86_64 (1)...
</span><span class='line'>  100%    8648 KB    4324 KB/sec    00:00:02       0 Errors  
</span><span class='line'>
</span><span class='line'>[root@k8s bin]# mv docker-compose-Linux-x86_64 docker-compose
</span><span class='line'>[root@k8s bin]# chmod +x docker-compose 
</span></code></pre></td></tr></table></div></figure>


<h2>Hello World:</h2>

<p>官网是一个访问量统计的例子，通过python网站结合redis来实现。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s composetest]# ll
</span><span class='line'>total 16
</span><span class='line'>-rw-r--r--. 1 root root 303 Sep 17 08:09 app.py
</span><span class='line'>-rw-r--r--. 1 root root 112 Sep 17 08:39 docker-compose.yml
</span><span class='line'>-rw-r--r--. 1 root root 114 Sep 17 08:42 Dockerfile
</span><span class='line'>-rw-r--r--. 1 root root  13 Sep 17 08:09 requirements.txt
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat app.py 
</span><span class='line'>from flask import Flask
</span><span class='line'>from redis import Redis
</span><span class='line'>
</span><span class='line'>app = Flask(__name__)
</span><span class='line'>redis = Redis(host='redis', port=6379)
</span><span class='line'>
</span><span class='line'>@app.route('/')
</span><span class='line'>def hello():
</span><span class='line'>  count = redis.incr('hits')
</span><span class='line'>  return 'Hello World! I have been seen {} times.\n'.format(count)
</span><span class='line'>
</span><span class='line'>if __name__ == "__main__":
</span><span class='line'>  app.run(host="0.0.0.0", debug=True)
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat requirements.txt 
</span><span class='line'>flask
</span><span class='line'>redis
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat Dockerfile 
</span><span class='line'>FROM python:3.4-alpine
</span><span class='line'>
</span><span class='line'>ADD . /code
</span><span class='line'>WORKDIR /code
</span><span class='line'>
</span><span class='line'>RUN pip install -r requirements.txt
</span><span class='line'>
</span><span class='line'>CMD ["python", "app.py"]
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat docker-compose.yml 
</span><span class='line'>version: '2.1'
</span><span class='line'>services:
</span><span class='line'>  web:
</span><span class='line'>    build: .
</span><span class='line'>    ports:
</span><span class='line'>      - "5000:5000"
</span><span class='line'>  redis:
</span><span class='line'>    image: "redis:alpine"
</span></code></pre></td></tr></table></div></figure>


<p>依赖的镜像可以提前下载好，可以不修改docker配置的情况下来下载，参考<a href="https://raw.githubusercontent.com/winse/shell-not-just-on-work/master/docker-download-mirror.sh">docker-download-mirror.sh</a></p>

<p>写好配置后，运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s composetest]# docker-compose up --build
</span><span class='line'>Building web
</span><span class='line'>Step 1 : FROM python:3.4-alpine
</span><span class='line'> ---&gt; 27a0e572c13a
</span><span class='line'>Step 2 : ADD . /code
</span><span class='line'> ---&gt; 84082044fb5e
</span><span class='line'>Removing intermediate container 7c4675b618da
</span><span class='line'>Step 3 : WORKDIR /code
</span><span class='line'> ---&gt; Running in a014af85b748
</span><span class='line'> ---&gt; 2ada42bd756c
</span><span class='line'>Removing intermediate container a014af85b748
</span><span class='line'>Step 4 : RUN pip install -r requirements.txt
</span><span class='line'> ---&gt; Running in 4be6f8f5c8b8
</span><span class='line'>Collecting flask (from -r requirements.txt (line 1))
</span><span class='line'>  Downloading Flask-0.12.2-py2.py3-none-any.whl (83kB)
</span><span class='line'>Collecting redis (from -r requirements.txt (line 2))
</span><span class='line'>  Downloading redis-2.10.6-py2.py3-none-any.whl (64kB)
</span><span class='line'>Collecting Jinja2&gt;=2.4 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading Jinja2-2.9.6-py2.py3-none-any.whl (340kB)
</span><span class='line'>Collecting click&gt;=2.0 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading click-6.7-py2.py3-none-any.whl (71kB)
</span><span class='line'>Collecting itsdangerous&gt;=0.21 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading itsdangerous-0.24.tar.gz (46kB)
</span><span class='line'>Collecting Werkzeug&gt;=0.7 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading Werkzeug-0.12.2-py2.py3-none-any.whl (312kB)
</span><span class='line'>Collecting MarkupSafe&gt;=0.23 (from Jinja2&gt;=2.4-&gt;flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading MarkupSafe-1.0.tar.gz
</span><span class='line'>Building wheels for collected packages: itsdangerous, MarkupSafe
</span><span class='line'>  Running setup.py bdist_wheel for itsdangerous: started
</span><span class='line'>  Running setup.py bdist_wheel for itsdangerous: finished with status 'done'
</span><span class='line'>  Stored in directory: /root/.cache/pip/wheels/fc/a8/66/24d655233c757e178d45dea2de22a04c6d92766abfb741129a
</span><span class='line'>  Running setup.py bdist_wheel for MarkupSafe: started
</span><span class='line'>  Running setup.py bdist_wheel for MarkupSafe: finished with status 'done'
</span><span class='line'>  Stored in directory: /root/.cache/pip/wheels/88/a7/30/e39a54a87bcbe25308fa3ca64e8ddc75d9b3e5afa21ee32d57
</span><span class='line'>Successfully built itsdangerous MarkupSafe
</span><span class='line'>Installing collected packages: MarkupSafe, Jinja2, click, itsdangerous, Werkzeug, flask, redis
</span><span class='line'>Successfully installed Jinja2-2.9.6 MarkupSafe-1.0 Werkzeug-0.12.2 click-6.7 flask-0.12.2 itsdangerous-0.24 redis-2.10.6
</span><span class='line'> ---&gt; ee3e476d4fad
</span><span class='line'>Removing intermediate container 4be6f8f5c8b8
</span><span class='line'>Step 5 : CMD python app.py
</span><span class='line'> ---&gt; Running in f2f9eefe782e
</span><span class='line'> ---&gt; 08e3065107b2
</span><span class='line'>Removing intermediate container f2f9eefe782e
</span><span class='line'>Successfully built 08e3065107b2
</span><span class='line'>Recreating composetest_web_1 ... 
</span><span class='line'>Recreating composetest_web_1
</span><span class='line'>Starting composetest_redis_1 ... 
</span><span class='line'>Recreating composetest_web_1 ... done
</span><span class='line'>Attaching to composetest_redis_1, composetest_web_1
</span><span class='line'>redis_1  | 1:C 17 Sep 00:43:45.012 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
</span><span class='line'>redis_1  | 1:C 17 Sep 00:43:45.013 # Redis version=4.0.1, bits=64, commit=00000000, modified=0, pid=1, just started
</span><span class='line'>redis_1  | 1:C 17 Sep 00:43:45.013 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 * Running mode=standalone, port=6379.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # Server initialized
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 * DB loaded from disk: 0.000 seconds
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 * Ready to accept connections
</span><span class='line'>web_1    |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
</span><span class='line'>web_1    |  * Restarting with stat
</span><span class='line'>web_1    |  * Debugger is active!
</span><span class='line'>web_1    |  * Debugger PIN: 175-303-648</span></code></pre></td></tr></table></div></figure>


<p>查看容器状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s opt]# curl http://0.0.0.0:5000/
</span><span class='line'>Hello World! I have been seen 1 times.
</span><span class='line'>[root@k8s opt]# curl http://0.0.0.0:5000/
</span><span class='line'>Hello World! I have been seen 2 times.
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# docker-compose ps 
</span><span class='line'>       Name                      Command               State           Ports         
</span><span class='line'>-------------------------------------------------------------------------------------
</span><span class='line'>composetest_redis_1   docker-entrypoint.sh redis ...   Up      6379/tcp              
</span><span class='line'>composetest_web_1     python app.py                    Up      0.0.0.0:5000-&gt;5000/tcp
</span><span class='line'>
</span><span class='line'>##
</span><span class='line'>docker-compose rm -f # Remove stopped containers
</span><span class='line'>docker-compose down  # Stop and remove containers, networks, images, and volumes
</span></code></pre></td></tr></table></div></figure>


<h2>其他</h2>

<p>后台运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-compose up -d
</span><span class='line'>$ docker-compose ps</span></code></pre></td></tr></table></div></figure>


<p>在指定容器内执行命令：有点类似 docker exec/kubectl exec</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-compose run web env</span></code></pre></td></tr></table></div></figure>


<p><a href="https://docs.docker.com/compose/production/#deploying-changes">单独编译运行</a> 仅更改过内容的容器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-compose build web
</span><span class='line'>$ docker-compose up --no-deps -d web</span></code></pre></td></tr></table></div></figure>


<p>配置<a href="https://docs.docker.com/compose/extends/#extending-services">复用/覆写</a>：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
</span><span class='line'>
</span><span class='line'># A
</span><span class='line'>webapp:
</span><span class='line'>  build: .
</span><span class='line'>  ports:
</span><span class='line'>    - "8000:8000"
</span><span class='line'>  volumes:
</span><span class='line'>    - "/data"
</span><span class='line'>   
</span><span class='line'># EA   
</span><span class='line'>web:
</span><span class='line'>  extends:
</span><span class='line'>    file: common-services.yml
</span><span class='line'>    service: webapp
</span><span class='line'>    </span></code></pre></td></tr></table></div></figure>


<h2>学习</h2>

<ul>
<li><a href="https://yeasy.gitbooks.io/docker_practice/content/compose/commands.html">Compose 命令</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zookeeper ACL]]></title>
    <link href="http://winseliu.com/blog/2017/09/02/zookeeper-acl/"/>
    <updated>2017-09-02T15:14:55+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/02/zookeeper-acl</id>
    <content type="html"><![CDATA[<p>集群又一次进行安检，SSH躲不过需要升级的，这次还加了hadoop security和zookeeper acl的bug。以前没太在意这些内容，既然安全检查出来了，还是需要处理的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ZooKeeper 未授权访问【原理扫描】
</span><span class='line'>详细描述  ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 
</span><span class='line'>ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 
</span><span class='line'>在通常情况下，zookeeper允许未经授权的访问。
</span><span class='line'>解决办法  为ZooKeeper配置相应的访问权限。 
</span><span class='line'>
</span><span class='line'>方式一： 
</span><span class='line'>1）增加一个认证用户 
</span><span class='line'>addauth digest 用户名:密码明文 
</span><span class='line'>eg. addauth digest user1:password1 
</span><span class='line'>2）设置权限 
</span><span class='line'>setAcl /path auth:用户名:密码明文:权限 
</span><span class='line'>eg. setAcl /test auth:user1:password1:cdrwa 
</span><span class='line'>3）查看Acl设置 
</span><span class='line'>getAcl /path 
</span><span class='line'>
</span><span class='line'>方式二： 
</span><span class='line'>setAcl /path digest:用户名:密码密文:权限
</span><span class='line'>
</span><span class='line'>威胁分值  5.0
</span><span class='line'>危险插件  否
</span><span class='line'>发现日期  2015-02-10
</span></code></pre></td></tr></table></div></figure>


<h2>Zookeeper权限基本知识点、操作</h2>

<ul>
<li><a href="https://zookeeper.apache.org/doc/r3.3.3/zookeeperProgrammers.html#sc_ZooKeeperAccessControl">https://zookeeper.apache.org/doc/r3.3.3/zookeeperProgrammers.html#sc_ZooKeeperAccessControl</a></li>
<li><a href="https://my.oschina.net/guol/blog/1358538">https://my.oschina.net/guol/blog/1358538</a></li>
<li><a href="http://blog.csdn.net/xyang81/article/details/53147894">http://blog.csdn.net/xyang81/article/details/53147894</a></li>
<li><a href="https://ihong5.wordpress.com/2014/07/24/apache-zookeeper-setting-acl-in-zookeeper-client/">https://ihong5.wordpress.com/2014/07/24/apache-zookeeper-setting-acl-in-zookeeper-client/</a></li>
<li><a href="https://zookeeper.apache.org/doc/r3.3.3/zookeeperStarted.html">https://zookeeper.apache.org/doc/r3.3.3/zookeeperStarted.html</a></li>
</ul>


<p>Note also that an ACL pertains only to a specific znode. In particular it does not apply to children. ACL在znode上无继承性，也就是说子znode不会继承父znode的ACL权限.</p>

<ul>
<li>world has a single id, anyone, that represents anyone.</li>
<li>auth doesn&rsquo;t use any id, represents any authenticated user.</li>
<li>digest uses a username:password string to generate MD5 hash which is then used as an ACL ID identity. Authentication is done by sending the username:password in clear text. When used in the ACL the expression will be the username:base64 encoded SHA1 password digest.</li>
<li>ip uses the client host IP as an ACL ID identity. The ACL expression is of the form addr/bits(3.5+) where the most significant bits of addr are matched against the most significant bits of the client host IP.</li>
</ul>


<p>zookeeper的ACL格式为 schema:id:permissions 。模式就是上面列的几种，再加一个super。创建的节点默认权限为 world:anyone:rwadc 表示所有人都对这个节点有rwadc的权限。</p>

<ul>
<li>Create：允许对子节点Create 操作</li>
<li>Read：允许对本节点GetChildren 和GetData 操作</li>
<li>Write ：允许对本节点SetData 操作</li>
<li>Delete ：允许对子节点Delete 操作</li>
<li>Admin ：允许对本节点setAcl 操作</li>
</ul>


<h2>Auth授权</h2>

<p>不需要id，当前 &ldquo;登录&rdquo; 的所有users都有权限（sasl、kerberos这些授权方式不懂，囧)。虽然不需要id，但是格式还得按照 scheme:id:perm 的写法。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 15] setAcl /c auth:rwadc  
</span><span class='line'>auth:rwadc does not have the form scheme:id:perm
</span><span class='line'>Acl is not valid : /c
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 13] addauth digest a:a
</span><span class='line'>[zk: k8s(CONNECTED) 14] addauth digest b:b
</span><span class='line'>[zk: k8s(CONNECTED) 15] addauth digest c:c
</span><span class='line'>[zk: k8s(CONNECTED) 16] create /e e
</span><span class='line'>Created /e
</span><span class='line'>[zk: k8s(CONNECTED) 17] setAcl /e auth::cdrwa
</span><span class='line'>...省略节点输出信息
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 18] getAcl /e
</span><span class='line'>'digest,'a:mDmPUap4qvYwm+PZOtJ/scGyHLY=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'b:+F8zPn3x1CLx3qpYHEaRwIheWcc=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'c:K7CO7OxIfBOQxczG+7FI9BdZ6/s=
</span><span class='line'>: cdrwa</span></code></pre></td></tr></table></div></figure>


<p>id随便写也可以，zookeeper都不记录的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 9] addauth digest hdfs:hdfs    
</span><span class='line'>[zk: localhost:2181(CONNECTED) 10] setAcl /c auth:x:x:rwadc
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 11] getAcl /c               
</span><span class='line'>'digest,'user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'hdfs:0wpra2yK6RCUB9sbo0BkElpzcl8=
</span><span class='line'>: cdrwa</span></code></pre></td></tr></table></div></figure>


<p>也可以对根 / 授权，这样客户端就不能随便在根下面新建节点了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 9] addauth digest user:password    
</span><span class='line'>[zk: localhost:2181(CONNECTED) 21] setAcl / auth::rawdc
</span><span class='line'>
</span><span class='line'>重新登录
</span><span class='line'>[zk: localhost:2181(CONNECTED) 0] ls /
</span><span class='line'>Authentication is not valid : /
</span><span class='line'>[zk: localhost:2181(CONNECTED) 1] getAcl /
</span><span class='line'>'digest,'user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>还原</p>

<p>使用有权限的用户/实例，如果都忘了那就只能放绝招：使用超级管理员登录，重新设置权限为world即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 26] setAcl / world:anyone:cdrwa</span></code></pre></td></tr></table></div></figure>


<h2>Digest</h2>

<p>直接用起来比 auth 简单，直接把密文交给zookeeper。首先得生成对应用户的密码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s zookeeper-3.4.10]# java -cp zookeeper-3.4.10.jar:lib/* org.apache.zookeeper.server.auth.DigestAuthenticationProvider user:password
</span><span class='line'>user:password-&gt;user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>
</span><span class='line'>[root@k8s zookeeper-3.4.10]# java -cp zookeeper-3.4.10.jar:lib/* org.apache.zookeeper.server.auth.DigestAuthenticationProvider es:es
</span><span class='line'>es:es-&gt;es:KiHfMOSWCTgPKpz78IL/6qO8AEE=</span></code></pre></td></tr></table></div></figure>


<p>scheme是digest的时候，id需要密文。通过Zookeeper的客户端编码方式添加认证（登录），digest对应的auth数据是明文。</p>

<p>ACL授权一样使用 setAcl ：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ A实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 17] setAcl /b digest:user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=:cdrwa
</span><span class='line'>和md5密码类似，数据库被盗了，如果是常用的密码会被猜出来
</span><span class='line'>[zk: localhost:2181(CONNECTED) 18] getAcl /b
</span><span class='line'>'digest,'user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'>$$ B实例
</span><span class='line'>重新登录：
</span><span class='line'>[zk: k8s:2181(CONNECTED) 2] ls /b
</span><span class='line'>Authentication is not valid : /b
</span><span class='line'>
</span><span class='line'>$$ A实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 20] create /b/bb ''
</span><span class='line'>Authentication is not valid : /b/bb
</span><span class='line'>[zk: localhost:2181(CONNECTED) 21] addauth digest user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>[zk: localhost:2181(CONNECTED) 22] create /b/bb ''                                 
</span><span class='line'>Authentication is not valid : /b/bb
</span><span class='line'>
</span><span class='line'># 需要使用明文登录
</span><span class='line'>[zk: localhost:2181(CONNECTED) 23] addauth digest user:password
</span><span class='line'>[zk: localhost:2181(CONNECTED) 24] create /b/bb '' 
</span><span class='line'>Created /b/bb 
</span><span class='line'>
</span><span class='line'># 权限没有继承性
</span><span class='line'>[zk: localhost:2181(CONNECTED) 25] getAcl /b/bb
</span><span class='line'>'world,'anyone
</span><span class='line'>: cdrwa</span></code></pre></td></tr></table></div></figure>


<h1>IP</h1>

<p>ip的权限配置更简单些。逻辑就是匹配客户端的IP地址，在权限IP地址段范围内的才能访问。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ A实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 18] setAcl /i ip:127.0.0.1:cdrwa
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 19] getAcl /i
</span><span class='line'>'ip,'127.0.0.1
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 24] get /i
</span><span class='line'>Authentication is not valid : /i
</span><span class='line'>
</span><span class='line'>咋回事呢，就是本地还没权限？有时可localhost不一定对应127.0.0.1的。。。
</span><span class='line'>
</span><span class='line'>$$ B实例
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkCli.sh -server 127.0.0.1
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 0] get /i
</span><span class='line'>i
</span><span class='line'>...
</span><span class='line'>改成另一个网卡的ip地址
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 1] setAcl /i ip:192.168.191.138:cdrwa
</span><span class='line'>...
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 2] getAcl /i
</span><span class='line'>'ip,'192.168.191.138
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 3] get /i
</span><span class='line'>Authentication is not valid : /i
</span><span class='line'>
</span><span class='line'>$$ C实例
</span><span class='line'>用主机名(191.138)登录的实例
</span><span class='line'>[zk: k8s(CONNECTED) 19] get /i
</span><span class='line'>i</span></code></pre></td></tr></table></div></figure>


<h2>超级管理员</h2>

<p>如果权限设置错了，咋办？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: k8s(CONNECTED) 21] setAcl /i ip:192.168.191.0/24:cdrwa                   
</span><span class='line'>Acl is not valid : /i
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 25] setAcl /i ip:192.168.191.0:cdrwa
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 26] getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: k8s(CONNECTED) 27] get /i
</span><span class='line'>Authentication is not valid : /i</span></code></pre></td></tr></table></div></figure>


<p>除非把客户端的ip地址换成 192.168.191.0 否则就访问不了了。</p>

<p>此时需要超级管理员才行，不然真没办法折腾了。（不知道为啥）是可以删掉（特指我当前的环境啊），但是这样数据就没有了啊！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 26] getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 27] delete /i
</span><span class='line'>[zk: localhost:2181(CONNECTED) 28] ls /
</span><span class='line'>[a, b, c, zookeeper, d, e]
</span><span class='line'>[zk: localhost:2181(CONNECTED) 29] ls /i
</span><span class='line'>Node does not exist: /i</span></code></pre></td></tr></table></div></figure>


<p>如果数据很重要，重启后用超级管理员的方式找回密码还是很划的来的。</p>

<ul>
<li><a href="https://community.hortonworks.com/articles/29900/zookeeper-using-superdigest-to-gain-full-access-to.html">https://community.hortonworks.com/articles/29900/zookeeper-using-superdigest-to-gain-full-access-to.html</a></li>
</ul>


<p>用 DigestAuthenticationProvider 加密就不操作了，直接用 es:es 对应的 es:es->es:KiHfMOSWCTgPKpz78IL/6qO8AEE= 作为管理员的账号密码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export SERVER_JVMFLAGS=-Dzookeeper.DigestAuthenticationProvider.superDigest=es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkServer.sh stop
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkServer.sh start
</span><span class='line'>ZooKeeper JMX enabled by default
</span><span class='line'>Using config: /opt/zookeeper-3.4.10/bin/../conf/zoo.cfg
</span><span class='line'>Starting zookeeper ... STARTED
</span><span class='line'>
</span><span class='line'>$$ A实例
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkCli.sh 
</span><span class='line'>[zk: localhost:2181(CONNECTED) 0] get /i
</span><span class='line'>Authentication is not valid : /i
</span><span class='line'>[zk: localhost:2181(CONNECTED) 1] getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 2] addauth digest es:es
</span><span class='line'>[zk: localhost:2181(CONNECTED) 3] get /i
</span><span class='line'>i
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 4] setAcl /i world:anyone:cdrwa
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>$$ B实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 0] get /i
</span><span class='line'>i
</span><span class='line'>[zk: localhost:2181(CONNECTED) 1] getAcl /i
</span><span class='line'>'world,'anyone
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<h2>实践&mdash;好玩</h2>

<p>权限可以直接在创建的时刻指定：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>create /mynode content digest:user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=:cdrwa</span></code></pre></td></tr></table></div></figure>


<p>也可以一次性设置N个权限：</p>

<p>注：以下操作都是超级管理员登录的窗口，所以不存在权限的问题。想怎么改就怎么改</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>setAcl /i ip:192.168.191.0:cdrwa,ip:127.0.0.1:cdrwa,ip:192.168.191.138:cdrwa
</span><span class='line'>
</span><span class='line'>getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>'ip,'127.0.0.1
</span><span class='line'>: cdrwa
</span><span class='line'>'ip,'192.168.191.138
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>但是，使用ip、digest、word重设权限后，会覆盖旧的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 7] setAcl /i ip:0.0.0.0:cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 8] getAcl /i
</span><span class='line'>'ip,'0.0.0.0
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'>[zk: localhost:2181(CONNECTED) 15] setAcl /i world:anyone:cdraw
</span><span class='line'>[zk: localhost:2181(CONNECTED) 16] getAcl /i
</span><span class='line'>'world,'anyone
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>3.4的版本不支持ip段（3.5应该是ok的）： <a href="https://github.com/apache/zookeeper/blob/release-3.4.10/src/java/main/org/apache/zookeeper/server/auth/IPAuthenticationProvider.java#L114">IPAuthenticationProvider</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public boolean isValid(String id) {
</span><span class='line'>    return addr2Bytes(id) != null;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>可以找对应版本的源码（远程）调试下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s zookeeper-3.4.10]# export SERVER_JVMFLAGS="-Dzookeeper.DigestAuthenticationProvider.superDigest=es:KiHfMOSWCTgPKpz78IL/6qO8AEE= -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005"
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkServer.sh start
</span></code></pre></td></tr></table></div></figure>


<p>auth的权限比较有意思：自家兄弟添加、排除异己；permission按最新的算</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 21] setAcl /i auth::cdrwa,ip:0.0.0.0:cd
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 22] getAcl /i
</span><span class='line'>'ip,'0.0.0.0
</span><span class='line'>: cd
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'># auth add
</span><span class='line'>[zk: localhost:2181(CONNECTED) 27] addauth digest m:m
</span><span class='line'>[zk: localhost:2181(CONNECTED) 28] addauth digest n:n
</span><span class='line'>[zk: localhost:2181(CONNECTED) 29] setAcl /i auth::cdrwa
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 30] getAcl /i
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'m:WZiIgWqJgd8EQVBh55Bslf/7JRc=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'n:TZ3f1UF7B75EF5g6qWR0VmEvb/s=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'># perm
</span><span class='line'>[zk: localhost:2181(CONNECTED) 31] addauth digest z:z
</span><span class='line'>[zk: localhost:2181(CONNECTED) 32] addauth digest l:l
</span><span class='line'>[zk: localhost:2181(CONNECTED) 33] setAcl /i auth:z:z:cd
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 34] getAcl /i
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cd
</span><span class='line'>'digest,'m:WZiIgWqJgd8EQVBh55Bslf/7JRc=
</span><span class='line'>: cd
</span><span class='line'>'digest,'n:TZ3f1UF7B75EF5g6qWR0VmEvb/s=
</span><span class='line'>: cd
</span><span class='line'>'digest,'z:cOgtYxFOAwKiTCMigcN2j2fFI3c=
</span><span class='line'>: cd
</span><span class='line'>'digest,'l:gdlgatwJdq7uG8kFfIjcIZj0tnQ=
</span><span class='line'>: cd
</span><span class='line'>
</span><span class='line'>可以看到全部变成cd了
</span><span class='line'>
</span><span class='line'>[zk: localhost:2181(CONNECTED) 35] setAcl /i auth:z:z:cdraw
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 36] getAcl /i               
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'m:WZiIgWqJgd8EQVBh55Bslf/7JRc=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'n:TZ3f1UF7B75EF5g6qWR0VmEvb/s=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'z:cOgtYxFOAwKiTCMigcN2j2fFI3c=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'l:gdlgatwJdq7uG8kFfIjcIZj0tnQ=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'>全部变成cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>我觉得用 auth 设置权限是最保险的，不会搞错了出现自己都访问不了的情况。</p>

<h2>后记</h2>

<p>ok，到此基本的知识点算大概了解了。还有自定义实现授权的provider，这有点高级了有兴趣的自己去看官方文档了。</p>

<p>但是因为权限没有继承关系，像一些开源项目用到zookeeper的话，怎么进行加密呢？所有子目录都一个个的加？或者自定义根路径（chroot）让别人猜不到？</p>

<p>还有像zookeeper自己的目录 /zookeeper ，怎么进行权限管理呢？</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[命令行调用Jenkins2.63打包]]></title>
    <link href="http://winseliu.com/blog/2017/08/30/jenkins-build-via-shell/"/>
    <updated>2017-08-30T17:26:40+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/30/jenkins-build-via-shell</id>
    <content type="html"><![CDATA[<p>Jenkins给集成打包带来了很多的便捷，让不懂开发的同事也能轻松的打包。但是对于开发和运维来说，可能还需要在打包之外做一些事情，以及批量的处理N个打包。</p>

<p>对于研发来说，重复是最难忍受的。Jenkins可以直接通过api来调用查看和处理各种请求。</p>

<p>网络上资料其实挺多的。也有直接一个脚本直接搞定部署的。知其然知其所以然，还是需要自己下功夫理解人家的脚本这样才能更好的用（先不说自己写了）。主要的就是三个步骤：</p>

<ol>
<li>怎么登陆: <a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-Remoteaccess">JenkinsScriptConsole-Remoteaccess</a> .|. <a href="https://wiki.jenkins.io/display/JENKINS/Remote+access+API#RemoteaccessAPI-CSRFProtection">RemoteaccessAPI-CSRFProtection</a></li>
<li>执行build：<a href="http://www.inanzzz.com/index.php/post/jnrg/running-jenkins-build-via-command-line">Running jenkins jobs via command line</a> .|. <a href="https://www.nczonline.net/blog/2015/10/triggering-jenkins-builds-by-url/">Triggering Jenkins builds by URL</a></li>
<li>检查结果：<a href="https://gist.githubusercontent.com/julianchurchill/8780920/raw/ae3ab0c120857b0fe69fe3718d720cb4ef94c4b8/checkJenkins.sh">checkJenkins.sh</a></li>
</ol>


<h2>crumb</h2>

<p>首先来看看crumb是啥</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@iZ9416vn227Z opt]# curl -X POST $JENKINS_PROJ_AUTH_URL/build
</span><span class='line'>&lt;html&gt;
</span><span class='line'>&lt;head&gt;
</span><span class='line'>&lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8"/&gt;
</span><span class='line'>&lt;title&gt;Error 403 No valid crumb was included in the request&lt;/title&gt;
</span><span class='line'>&lt;/head&gt;
</span><span class='line'>&lt;body&gt;&lt;h2&gt;HTTP ERROR 403&lt;/h2&gt;
</span><span class='line'>&lt;p&gt;Problem accessing /job/helloworld/build. Reason:
</span><span class='line'>&lt;pre&gt;    No valid crumb was included in the request&lt;/pre&gt;&lt;/p&gt;&lt;hr&gt;&lt;a href="http://eclipse.org/jetty"&gt;Powered by Jetty:// 9.4.z-SNAPSHOT&lt;/a&gt;&lt;hr/&gt;
</span><span class='line'>
</span><span class='line'>&lt;/body&gt;
</span><span class='line'>&lt;/html&gt;
</span></code></pre></td></tr></table></div></figure>


<p>这里<a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-RemoteaccesswithCSRFprotectionenabled">CSRF</a> 相当于jenkins做的一个权限控制，有两种方式处理：</p>

<p>方法一：取消控制</p>

<ul>
<li><a href="http://www.zhyea.com/2016/10/14/resolve-no-valid-crumb-was-included-in-the-request-error.html">no valid crumb was included in the request解决</a></li>
<li><a href="https://github.com/ghale/gradle-jenkins-plugin/issues/78#issuecomment-215783175">No valid crumb was included in the request</a></li>
</ul>


<p>在菜单 系统管理 –> Configure Global Security 中调整设置: 取消 防止跨站点请求伪造(Prevent Cross Site Request Forgery exploits) 的勾选。 如果还坚持要启用“防止跨站点请求伪造”，就需要先动态获取crumb。</p>

<p>方法二：获取token</p>

<ul>
<li><a href="https://stackoverflow.com/questions/16738441/how-to-request-for-crumb-issuer-for-jenkins">How to request for Crumb issuer for jenkins</a></li>
<li><a href="http://russellsimpkins.blogspot.jp/2014/10/calling-jenkins-job-with-bash-script.html">Calling a jenkins job with a bash script</a></li>
<li><a href="https://support.cloudbees.com/hc/en-us/articles/218889337-How-to-build-a-job-using-the-REST-API-and-cURL-">https://support.cloudbees.com/hc/en-us/articles/218889337-How-to-build-a-job-using-the-REST-API-and-cURL-</a></li>
</ul>


<p>通过URL: crumbIssuer/api/json 获取token的键值，然后把它附加到build请求的HEADER。</p>

<h2>命令行通过URL请求jenkins进行编译</h2>

<ul>
<li><a href="http://blog.csdn.net/xian312854159/article/details/41118245">使用shell脚本curl调用jenkins进行构建并判断是否构建成功 </a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Remote+access+API">Remote access API</a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Authenticating+scripted+clients">https://wiki.jenkins.io/display/JENKINS/Authenticating+scripted+clients</a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console">https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>JENKINS_ID="admin:PASSWORD"
</span><span class='line'>JENKINS_PROJ_AUTH_URL=http://$JENKINS_ID@localhost:18080/job/helloworld
</span><span class='line'>JENKINS_PROJ_URL=http://localhost:18080/job/helloworld
</span><span class='line'>
</span><span class='line'>curl $JENKINS_PROJ_AUTH_URL/lastBuild/api/json
</span><span class='line'>
</span><span class='line'>#Get the current configuration and save it locally
</span><span class='line'>curl -X GET $JENKINS_PROJ_URL/config.xml
</span><span class='line'>
</span><span class='line'>curl 'http://'$JENKINS_ID'@localhost:18080/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,":",//crumb)'
</span><span class='line'>Jenkins-Crumb:a4296173a91d900c11af07d932559fcd
</span><span class='line'>
</span><span class='line'>curl -X POST -H "Jenkins-Crumb:a4296173a91d900c11af07d932559fcd"  $JENKINS_PROJ_AUTH_URL/build
</span><span class='line'>
</span><span class='line'>curl -s $JENKINS_PROJ_AUTH_URL/lastBuild/api/json | jq .
</span><span class='line'>
</span><span class='line'># --- TODO ---
</span><span class='line'>
</span><span class='line'>progress（排队中）|pending（构建中），每三秒去重新获取结果进行判断  
</span><span class='line'>while grep -qE "In progress|pending" build.tmp2;  
</span><span class='line'>
</span><span class='line'>if grep -qE "Success" build.tmp2 ;then  
</span><span class='line'>elif grep -qE "Unstable" build.tmp2 ;then  
</span><span class='line'>elif grep -qE "Failed|Aborted" build.tmp2 ;then  
</span><span class='line'>echo "#Open Link: ${jobPage}${newbuild}/console see details"  
</span></code></pre></td></tr></table></div></figure>


<p>BuildName</p>

<ul>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Build+Name+Setter+Plugin">https://wiki.jenkins.io/display/JENKINS/Build+Name+Setter+Plugin</a></li>
<li><a href="https://stackoverflow.com/questions/42172320/how-to-set-the-jenkins-build-name-based-on-some-conditions">https://stackoverflow.com/questions/42172320/how-to-set-the-jenkins-build-name-based-on-some-conditions</a></li>
<li><a href="https://stackoverflow.com/questions/30111298/how-to-use-build-name-setter-plugin">https://stackoverflow.com/questions/30111298/how-to-use-build-name-setter-plugin</a></li>
</ul>


<p>jenkins的使用案例</p>

<ul>
<li><a href="http://debugtalk.com/post/iOS-Android-Packing-with-Jenkins-details/">http://debugtalk.com/post/iOS-Android-Packing-with-Jenkins-details/</a></li>
</ul>


<h2>参考</h2>

<p>API使用</p>

<ul>
<li><a href="https://gist.githubusercontent.com/julianchurchill/8780920/raw/ae3ab0c120857b0fe69fe3718d720cb4ef94c4b8/checkJenkins.sh">https://gist.githubusercontent.com/julianchurchill/8780920/raw/ae3ab0c120857b0fe69fe3718d720cb4ef94c4b8/checkJenkins.sh</a></li>
<li><a href="https://www.nczonline.net/blog/2015/10/triggering-jenkins-builds-by-url/">Triggering Jenkins builds by URL</a></li>
</ul>


<p>登录/权限问题</p>

<ul>
<li><a href="https://stackoverflow.com/questions/10698419/how-can-a-jenkins-user-authentication-details-be-passed-to-a-script-which-uses">https://stackoverflow.com/questions/10698419/how-can-a-jenkins-user-authentication-details-be-passed-to-a-script-which-uses</a></li>
<li><a href="http://www.scmgalaxy.com/tutorials/ways-to-login-jenkins-using-command-line">http://www.scmgalaxy.com/tutorials/ways-to-login-jenkins-using-command-line</a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-Remoteaccess">https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-Remoteaccess</a></li>
<li><a href="http://russellsimpkins.blogspot.jp/2014/10/calling-jenkins-job-with-bash-script.html">Calling a jenkins job with a bash script</a></li>
<li><a href="https://issues.jenkins-ci.org/browse/JENKINS-42200">No valid crumb was included in the request in kubernetes</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vagrant创建自定义的BOX]]></title>
    <link href="http://winseliu.com/blog/2017/08/22/vagrant-create-your-own-box/"/>
    <updated>2017-08-22T23:04:17+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/22/vagrant-create-your-own-box</id>
    <content type="html"><![CDATA[<p>在《奔跑吧Ansible》中接触了Vagrant+VirtualBox，但是感觉一般般，也没觉得很特别的：就自己安装虚拟机差不多嘛。</p>

<p>后面在网上了解了一些关于这两工具，很多人用来搭建开发环境，脑子瞬间被击中了&mdash;还可以这么玩。这样系统重装的时刻就不用那么纠结和犹豫了，很多软件都安装在VirtualBox里面，重装后，直接启动虚拟机，就一切的开发环境的软件就都回来了。还有集群的搭建也挺方便的：由于Vagrant是命令行的方式结合配置来启动了，非常方便。</p>

<p>官方网站 <a href="http://www.vagrantbox.es/">Vagrantbox.es</a> <a href="https://app.vagrantup.com/boxes/search">Discover Vagrant Boxes</a> 有提供一些镜像，如Centos6:</p>

<ul>
<li><a href="https://app.vagrantup.com/centos/boxes/6">https://app.vagrantup.com/centos/boxes/6</a></li>
<li><a href="https://app.vagrantup.com/matchy/boxes/centos6-i386">https://app.vagrantup.com/matchy/boxes/centos6-i386</a> 。</li>
</ul>


<p>但是网络提供的不总能满足需要。所以有时还得亲自下手从零开始创建自己的Box。制作Vagrant的Box需要遵循一些要求/规范，官网有提供文档和说明：</p>

<ul>
<li><a href="https://www.vagrantup.com/docs/boxes/base.html">https://www.vagrantup.com/docs/boxes/base.html</a></li>
<li><a href="https://www.vagrantup.com/docs/virtualbox/boxes.html">https://www.vagrantup.com/docs/virtualbox/boxes.html</a></li>
<li><a href="https://unifreak.github.io/tutorial/Making-my-first-vagrant-box">制作自己第一个 vagrant box</a></li>
<li><a href="http://xuclv.blog.51cto.com/5503169/1239351">如何制作一个vagrant的base box</a></li>
</ul>


<p>为啥用vagrant：<a href="https://www.oschina.net/translate/get-vagrant-up-and-running-in-no-time">https://www.oschina.net/translate/get-vagrant-up-and-running-in-no-time</a></p>

<blockquote><p>在本地开发爽。用Vagrant快，简单，并可帮助你同时管理多个开发环境。</p>

<p>想象一下，你正在和据说15人的团队开发一个应用程序。这个程序真是狂棒！它使用Laravel的PHP框架，Redis和Memcached，ImageMagick和GD的PHP模块，curl，MySQL和PostgreSQL， 甚至MongoDB。 另外，Laravel明确依赖PHP版本5.3.7或更高版本，以及mcrypt的PHP扩展。</p>

<p>理想情况下，你会希望团队所有的15人在开发这个应用程序时，都是相同的开发环境。 但是不是所有的开发团队，都有系统管理的专家或者培养一个系统管理。获得相同设置的开发环境可能是一个非常艰巨的任务。 最重要的是，有些人使用的是Mac，而其他人则使用Linux或Windows。在它之前，开发人员会纠结在无尽的配置中，用电脑扔墙而筋疲力尽。</p></blockquote>

<p>其实，步骤不多也不是很复杂，但是总会遇到一些特定环境的问题。下来是我制作的过程（Vagrant1.9+VirutalBox5.1+Centos6.9_i686）。</p>

<p>还有其他的优点：</p>

<ul>
<li>还有配置化后，就可以可以进行版本管理。</li>
<li>分享。</li>
</ul>


<h2>下载安装系统</h2>

<ul>
<li>下载安装 VirtualBox ：<a href="https://www.virtualbox.org/">https://www.virtualbox.org/</a></li>
<li>下载安装 Vagrant ：<a href="http://www.vagrantup.com/">http://www.vagrantup.com/</a></li>
<li>操作系统 <a href="http://mirrors.zju.edu.cn/centos/6.9/isos/i386/">bin-DVD1.iso</a></li>
</ul>


<p>不要安装LiveDVD的版本会把桌面也安装了，系统大几个G，其实用不到图形界面。用DVD的安装没有mininal的系统。</p>

<h2>系统网络</h2>

<p>安装VirutalBox5.1完后，Windows宿主机多了一个 VirtualBox Host-Only Ethernet Adapter 本地网卡，可以先在VirtualBox菜单 [管理-全局设定-网络] 里删除Host-Only Network网卡。</p>

<p>在安装之前需要先了解VirtualBox的网卡的配置，它的选项/含义和VmWare不太一致，需要单独学习了解下：</p>

<ul>
<li>未指定： 相当于虚拟机没有插上网线的情况，此时与宿主机也连不通。</li>
<li>网络地址转换(NAT)：通过NAT转换仅通过HOST主机访问网络，但是访问不到虚拟机（单向的）。需要通过端口转发功能HOST主机才能连接到虚拟机。单机上网最简单的方式。</li>
<li>NAT网络</li>
<li>桥接网卡：虚拟机桥接到宿主机的一块网卡，直接与外部交换数据包，像是不经过宿主机一样。虚拟机能够设置一个独立的IP，所有网络功能完全和在网络中的真实机器一样(通过路由器来自动分配IP地址)。</li>
<li>内部网络：只虚拟机互通的网络。可以相互访问，前提是在设置网络时，两台虚拟机设置同一网络名称。</li>
<li>仅主机(Host-Only)网络：内部网络和桥接模式的混合，需要一个虚拟的网卡来配合。此时虚拟机可以和宿主机及宿主机所在的局域网通信，无法与外网通信。看F1帮助文档里面的，感觉和内部网络差不多，由于HOST主机 多了个网卡可以和HOST通信（通过Host Only网卡的IP），但虚拟机需要上网的话还需要再多配置一个桥接网络。</li>
<li>通用驱动</li>
</ul>


<p>网上的一些资料：</p>

<ul>
<li><a href="http://www.live-in.org/archives/789.html">http://www.live-in.org/archives/789.html</a></li>
<li><a href="https://liuliqiang.info/post/29/">https://liuliqiang.info/post/29/</a> 非常详细</li>
<li><a href="https://www.douban.com/group/topic/15558388/">https://www.douban.com/group/topic/15558388/</a> 和上一篇一样不知道谁抄谁，都看过就列在这里了</li>
<li><a href="https://serverfault.com/questions/225155/virtualbox-how-to-set-up-networking-so-both-host-and-guest-can-access-internet">VirtualBox: How to set up networking so both host and guest can access internet and talk to each other</a> NAT / host only;   use a Bridge Adapter 桥接</li>
<li><a href="https://superuser.com/questions/521072/cant-ping-guest-os-in-virtualbox-but-guests-can-ping-host">Can&rsquo;t ping guest OS in VirtualBox, but guests can ping host</a></li>
</ul>


<h2>配置</h2>

<p>安装系统后默认eth0的网卡是没有启用的。修改网络配置然后重启网络。</p>

<p>如果网卡启动失败，用 ifconfig -a 看看设备是不是eth0。</p>

<p>接下来就是连接系统，然后配置Vagrant了。</p>

<ul>
<li><a href="https://unifreak.github.io/tutorial/Making-my-first-vagrant-box">制作自己第一个 vagrant box</a></li>
<li><a href="http://xuclv.blog.51cto.com/5503169/1239351">如何制作一个vagrant的base box</a></li>
</ul>


<p>为了后面的配置更加顺利，需要先把网络调通。在虚拟机的黑窗口操作是非常不方便的，添加端口转发然后本地用Putty/git-ssh等工具登录系统操作 <a href="https://stackoverflow.com/questions/9885108/ssh-to-vagrant-box-in-windows">SSH to Vagrant box in Windows?</a> 。</p>

<p>接下来按照官网的说明进行配置：</p>

<ul>
<li><a href="https://www.vagrantup.com/docs/boxes/base.html#quot-vagrant-quot-user">https://www.vagrantup.com/docs/boxes/base.html#quot-vagrant-quot-user</a></li>
<li><a href="https://www.vagrantup.com/docs/virtualbox/boxes.html#to-install-via-the-command-line-">https://www.vagrantup.com/docs/virtualbox/boxes.html#to-install-via-the-command-line-</a></li>
<li><a href="https://www.vagrantup.com/docs/virtualbox/boxes.html#virtual-machine">https://www.vagrantup.com/docs/virtualbox/boxes.html#virtual-machine</a></li>
<li><a href="https://www.vagrantup.com/docs/boxes/base.html#testing-the-box">https://www.vagrantup.com/docs/boxes/base.html#testing-the-box</a></li>
</ul>


<p>步骤如下：</p>

<ol>
<li>增加帐号密码均为 vagrant ，root密码也是 vagrant</li>
<li>配置sudo</li>
<li>配置无密钥登录使用密钥进行登录，同时把insecure的 <a href="https://github.com/mitchellh/vagrant/tree/master/keys">vagrant的公钥</a> 写入authorized_key</li>
<li>安装tools</li>
<li>清理yum缓冲，tmp目录下的内容，以及其他的一些临时文件</li>
<li>删掉、禁用虚拟机多余的设备</li>
<li>第一个网卡设置为NAT（用于vagrant的端口转发，并且这网卡要boot启动啊！） <a href="https://www.vagrantup.com/docs/virtualbox/boxes.html#virtual-machine">boxes.html#virtual-machine</a></li>
<li>打包，进入到虚拟机存储的目录(可以通过【设置-高级】的备份位置确定），然后执行 <code>vagrant package --base centos6_i386</code></li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost ~]# passwd
</span><span class='line'>
</span><span class='line'>[root@localhost ~]# useradd vagrant
</span><span class='line'>[root@localhost ~]# passwd vagrant
</span><span class='line'>
</span><span class='line'>[root@localhost ~]# echo 'vagrant ALL=(ALL) NOPASSWD: ALL' &gt;/etc/sudoers
</span><span class='line'>
</span><span class='line'>[root@localhost ~]# su - vagrant
</span><span class='line'>[vagrant@localhost ~]$ mkdir .ssh && chmod 700 .ssh && cd .ssh
</span><span class='line'>[vagrant@localhost .ssh]$ curl https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant.pub -o authorized_keys 
</span><span class='line'>[vagrant@localhost .ssh]$ chmod 600 authorized_keys 
</span></code></pre></td></tr></table></div></figure>


<p>这里单独把安装tools执行的命令抽取出来：</p>

<ul>
<li><a href="https://superuser.com/questions/412527/modprobe-vboxguest-failed">https://superuser.com/questions/412527/modprobe-vboxguest-failed</a> 关键</li>
<li><a href="https://www.if-not-true-then-false.com/2010/install-virtualbox-guest-additions-on-fedora-centos-red-hat-rhel/comment-page-5/#comment-121648">https://www.if-not-true-then-false.com/2010/install-virtualbox-guest-additions-on-fedora-centos-red-hat-rhel/comment-page-5/#comment-121648</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># wget http://download.virtualbox.org/virtualbox/5.1.26/VBoxGuestAdditions_5.1.26.iso
</span><span class='line'>curl -o VBoxGuestAdditions_5.1.26.iso http://download.virtualbox.org/virtualbox/5.1.26/VBoxGuestAdditions_5.1.26.iso
</span><span class='line'>mkdir /media/VBoxGuestAdditions
</span><span class='line'>mount -o loop,ro VBoxGuestAdditions_5.1.26.iso /media/VBoxGuestAdditions
</span></code></pre></td></tr></table></div></figure>


<p>事情总归不会一帆风顺的，依赖需要进行处理，如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost ~]# sh /media/VBoxGuestAdditions/VBoxLinuxAdditions.run 
</span><span class='line'>Verifying archive integrity... All good.
</span><span class='line'>Uncompressing VirtualBox 5.1.26 Guest Additions for Linux...........
</span><span class='line'>VirtualBox Guest Additions installer
</span><span class='line'>Copying additional installer modules ...
</span><span class='line'>Installing additional modules ...
</span><span class='line'>vboxadd.sh: Starting the VirtualBox Guest Additions.
</span><span class='line'>Failed to set up service vboxadd, please check the log file
</span><span class='line'>/var/log/VBoxGuestAdditions.log for details.
</span><span class='line'>[root@localhost ~]# cat /var/log/VBoxGuestAdditions.log
</span><span class='line'>
</span><span class='line'>vboxadd.sh: failed: Look at /var/log/vboxadd-install.log to find out what went wrong.
</span><span class='line'>vboxadd.sh: failed: Look at /var/log/vboxadd-install.log to find out what went wrong.
</span><span class='line'>vboxadd.sh: failed: modprobe vboxguest failed.
</span><span class='line'>[root@localhost ~]# cat /var/log/vboxadd-install.log
</span><span class='line'>/tmp/vbox.0/Makefile.include.header:112: *** Error: unable to find the sources of your current Linux kernel. Specify KERN_DIR=&lt;directory&gt; and run Make again.  Stop.
</span><span class='line'>Creating user for the Guest Additions.
</span><span class='line'>Creating udev rule for the Guest Additions kernel module.
</span><span class='line'>
</span><span class='line'># 处理
</span><span class='line'>[root@localhost ~]# yum install gcc make patch glibc-headers glibc-devel kernel-headers -y 
</span><span class='line'>[root@localhost ~]# yum install kernel-devel # / yum install kernel-devel-2.6.32-696.el6.i686  
</span><span class='line'>[root@localhost ~]# export KERN_DIR=/usr/src/kernels/2.6.32-696.6.3.el6.i686  &lt;- 根据情况改
</span><span class='line'>[root@localhost ~]# sh /media/VBoxGuestAdditions/VBoxLinuxAdditions.run 
</span><span class='line'>Verifying archive integrity... All good.
</span><span class='line'>Uncompressing VirtualBox 5.1.26 Guest Additions for Linux...........
</span><span class='line'>VirtualBox Guest Additions installer
</span><span class='line'>Removing installed version 5.1.26 of VirtualBox Guest Additions...
</span><span class='line'>vboxadd.sh: Stopping VirtualBox Additions.
</span><span class='line'>Copying additional installer modules ...
</span><span class='line'>Installing additional modules ...
</span><span class='line'>vboxadd.sh: Starting the VirtualBox Guest Additions.
</span><span class='line'>
</span><span class='line'>Could not find the X.Org or XFree86 Window System, skipping.
</span></code></pre></td></tr></table></div></figure>


<p>安装配置(jdk/tomcat/mysql/pgsql/redis/&hellip;)好后，打包前清理缓冲：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum clean all
</span><span class='line'>history -c
</span><span class='line'>rm -rf ~/.bash_history
</span><span class='line'>rm -rf /tmp/* /var/log/* /var/cache/*</span></code></pre></td></tr></table></div></figure>


<p>然后打开windows的命令行，进入到虚拟机磁盘文件目录打包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>C:\Users\XXXX\VirtualBox VMs\centos6_i386&gt;vagrant package --base centos6_i386
</span><span class='line'>2017/08/24 07:18:04 launcher: detected 32bit Windows installation
</span><span class='line'>==&gt; centos6_i386: Clearing any previously set forwarded ports...
</span><span class='line'>==&gt; centos6_i386: Exporting VM...
</span><span class='line'>==&gt; centos6_i386: Compressing package to: C:/Users/XXXX/VirtualBox VMs/centos6_i386/package.box
</span></code></pre></td></tr></table></div></figure>


<h2>搭建开发环境</h2>

<ul>
<li><a href="https://blog.smdcn.net/article/1308.html">使用Vagrant在Windows下部署开发环境</a> 非常好的一篇文章</li>
<li><a href="https://blog.codecentric.de/en/2012/02/automated-virtual-test-environments-with-vagrant-and-puppet/">Automated virtual test-environments with Vagrant and Puppet</a></li>
<li><a href="https://favoorr.github.io/2017/01/06/import-vagrant-box-manually/">手工下载和导入 vagrant 镜像</a> 现在下载很快啊，尽管如此也是能学习一种新的备用方法。</li>
</ul>


<h2>实际操作命令</h2>

<h2>重装系统后再绑定</h2>

<p>重新安装后，vagrant和virtualbox在C盘用户目录的文件没有保存。再次启动发现vagrant是去重新启动一个新的虚拟机。</p>

<p>虚拟机嘛，总还是台机器，不会和对待docker那样操作。很多的文件、配置等等还是存储在虚拟机里面的。现在vagrant和virtualbox脱钩了。我们要做的就是把他们再绑定起来:</p>

<ul>
<li>首先启动直接双击box，启动虚拟机。会在用户目录.VirtualBox下面产生/修改VirtualBox.xml，打开文件找到当前虚拟机MachineEntry对应的uuid。</li>
<li>打开原vagrant的目录下 .vagrant\machines\default\virtualbox 的id文件。内容替换为virtualbox的最新的id。</li>
<li>上面的步骤已经把两者关联起来了，但是无密钥登录不行了。需要重新把github上的内容写入到虚拟机用户vagrant的authorzied_key里面。</li>
</ul>


<p>至此，就可以用 vagrant up 启动虚拟机了。还原绑定成功。</p>

<h2>其他</h2>

<ul>
<li><a href="https://github.com/guigarage/vagrant-binding">java invoke vagrant</a></li>
</ul>


<p>vagrant + virtualbox + nginx cache</p>

<ul>
<li><a href="https://stackoverflow.com/questions/9479117/vagrant-virtualbox-apache2-strange-cache-behaviour">https://stackoverflow.com/questions/9479117/vagrant-virtualbox-apache2-strange-cache-behaviour</a></li>
<li><a href="https://github.com/mitchellh/vagrant/issues/351#issuecomment-1339640">https://github.com/mitchellh/vagrant/issues/351#issuecomment-1339640</a></li>
</ul>


<p>vagrant + java deveploe env</p>

<ul>
<li><a href="https://github.com/rob-murray/vagrant-javadev-box/blob/master/Vagrantfile">https://github.com/rob-murray/vagrant-javadev-box/blob/master/Vagrantfile</a> 案例</li>
<li><a href="https://github.com/rob-murray/vagrant-javadev-box/blob/master/puppet/manifests/base.pp">https://github.com/rob-murray/vagrant-javadev-box/blob/master/puppet/manifests/base.pp</a></li>
<li><a href="https://github.com/spanneberg/vagrant-puppet-demo/blob/master/files/my.cnf">https://github.com/spanneberg/vagrant-puppet-demo/blob/master/files/my.cnf</a></li>
<li><a href="https://blog.codecentric.de/en/2012/02/automated-virtual-test-environments-with-vagrant-and-puppet/">https://blog.codecentric.de/en/2012/02/automated-virtual-test-environments-with-vagrant-and-puppet/</a></li>
</ul>


<p>git</p>

<ul>
<li><a href="https://stackoverflow.com/questions/34252265/how-to-start-mingw-console-gitbash-from-command-line-on-windows">https://stackoverflow.com/questions/34252265/how-to-start-mingw-console-gitbash-from-command-line-on-windows</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kubeadm部署k8s(资源已有)]]></title>
    <link href="http://winseliu.com/blog/2017/08/13/kubeadm-install-k8s-on-centos7-with-resources/"/>
    <updated>2017-08-13T00:05:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/13/kubeadm-install-k8s-on-centos7-with-resources</id>
    <content type="html"><![CDATA[<p>上一篇安装的文章这种代理，这种问题显的有点乱。在本机虚拟机安装调通后，今天把测试环境也升级了一下。安装需要的rpm和docker images可以通过百度网盘下载：<a href="http://pan.baidu.com/s/1hrRs5MW">http://pan.baidu.com/s/1hrRs5MW</a> 。</p>

<p>时间同步，主机名，/etc/hosts，防火墙，selinux, 无密钥登录，安装docker-1.12.6 这些都已经配置好了的。</p>

<ul>
<li>机器：cu[1-5]</li>
<li>主节点： cu3</li>
<li>跳板机： cu2（有外网IP）</li>
</ul>


<h2>首先做YUM本地仓库，把镜像导入到node节点</h2>

<p>首先在一台主机上部署YUM本地仓库</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /var/www/html/kubernetes/
</span><span class='line'>[root@cu2 kubernetes]# createrepo .
</span><span class='line'>[root@cu2 kubernetes]# ll
</span><span class='line'>total 42500
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  8974214 Aug 10 15:22 1a6f5f73f43077a50d877df505481e5a3d765c979b89fda16b8b9622b9ebd9a4-kubeadm-1.7.2-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 17372710 Aug 10 15:22 1e508e26f2b02971a7ff5f034b48a6077d613e0b222e0ec973351117b4ff45ea-kubelet-1.7.2-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  9361006 Aug 10 15:22 dc8329515fc3245404fea51839241b58774e577d7736f99f21276e764c309db5-kubectl-1.7.2-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  7800562 Aug 10 15:22 e7a4403227dd24036f3b0615663a371c4e07a95be5fee53505e647fd8ae58aa6-kubernetes-cni-0.5.1-0.x86_64.rpm
</span><span class='line'>drwxr-xr-x 2 root   root       4096 Aug 10 15:58 repodata
</span></code></pre></td></tr></table></div></figure>


<p>（所有node）导入新镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>在cu2上操作，导入docker镜像
</span><span class='line'>
</span><span class='line'>docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>ssh cu1 docker load &lt;/home/hadoop/kubeadm.tar 
</span><span class='line'>ssh cu3 docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>ssh cu4 docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>ssh cu5 docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>
</span><span class='line'>Loaded image: gcr.io/google_containers/etcd-amd64:3.0.17
</span><span class='line'>Loaded image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-controller-manager-amd64:v1.7.2
</span><span class='line'>Loaded image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.4
</span><span class='line'>Loaded image: gcr.io/google_containers/heapster-amd64:v1.3.0
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-scheduler-amd64:v1.7.2
</span><span class='line'>Loaded image: gcr.io/google_containers/heapster-grafana-amd64:v4.4.1
</span><span class='line'>Loaded image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.4
</span><span class='line'>Loaded image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.4
</span><span class='line'>Loaded image: centos:centos6
</span><span class='line'>Loaded image: gcr.io/google_containers/heapster-influxdb-amd64:v1.1.1
</span><span class='line'>Loaded image: gcr.io/google_containers/pause-amd64:3.0
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-apiserver-amd64:v1.7.2
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-proxy-amd64:v1.7.2
</span><span class='line'>Loaded image: quay.io/coreos/flannel:v0.8.0-amd64
</span></code></pre></td></tr></table></div></figure>


<p>YUM仓库配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>在cu2上操作
</span><span class='line'>
</span><span class='line'>cat &gt; /etc/yum.repos.d/dta.repo  &lt;&lt;EOF
</span><span class='line'>[K8S]
</span><span class='line'>name=K8S Local
</span><span class='line'>baseurl=http://cu2:801/kubernetes
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>for h in cu{1,3:5} ; do scp /etc/yum.repos.d/dta.repo $h:/etc/yum.repos.d/ ; done
</span></code></pre></td></tr></table></div></figure>


<h2>安装kubeadm、kubelet</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pdsh -w cu[1-5] "yum clean all; yum install -y kubelet kubeadm; systemctl enable kubelet; systemctl start kubelet "
</span></code></pre></td></tr></table></div></figure>


<p>问题1</p>

<p>启动完以后，查看 /var/log/messages 日志有如下错误：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Aug 12 23:33:38 cu5 kubelet: error: failed to run Kubelet: invalid kubeconfig: stat /etc/kubernetes/kubelet.conf: no such file or directory</span></code></pre></td></tr></table></div></figure>


<p>不用理会啊，继续执行后面的配置（kubeadm才开始配置）。</p>

<h2>使用kubeadm部署集群</h2>

<h4>master节点</h4>

<p>初始化</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16 --kubernetes-version=v1.7.2 </span></code></pre></td></tr></table></div></figure>


<p>启动后会卡在了 <strong> Created API client, waiting for the control plane to become ready </strong> ， 不要关闭当前的窗口。新开一个窗口，查看并定位解决错误：</p>

<p>问题2</p>

<p>新打开一个窗口，查看 /var/log/messages 有如下错误：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Aug 12 23:40:10 cu3 kubelet: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgroupfs"</span></code></pre></td></tr></table></div></figure>


<p>docker和kubelet的cgroup driver不一样，修改kubelet的配置。把docker启动参数 masq 一起改了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# sed -i 's/KUBELET_CGROUP_ARGS=--cgroup-driver=systemd/KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs/' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 
</span><span class='line'>[root@cu3 ~]# sed -i 's#/usr/bin/dockerd.*#/usr/bin/dockerd --ip-masq=false#' /usr/lib/systemd/system/docker.service
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# systemctl daemon-reload; systemctl restart docker kubelet 
</span></code></pre></td></tr></table></div></figure>


<p>多开几个窗口来解决问题，不会影响kubeadm运行的。就是说，由于其他的问题导致kubeadm中间卡住，只要你解决了问题，kubeadm就会继续配置直到成功。</p>

<p>初始化完后，窗口完整日志如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16 --kubernetes-version=v1.7.2 
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[init] Using Kubernetes version: v1.7.2
</span><span class='line'>[init] Using Authorization modes: [Node RBAC]
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
</span><span class='line'>[certificates] Generated CA certificate and key.
</span><span class='line'>[certificates] Generated API server certificate and key.
</span><span class='line'>[certificates] API Server serving cert is signed for DNS names [cu3 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.0.148]
</span><span class='line'>[certificates] Generated API server kubelet client certificate and key.
</span><span class='line'>[certificates] Generated service account token signing key and public key.
</span><span class='line'>[certificates] Generated front-proxy CA certificate and key.
</span><span class='line'>[certificates] Generated front-proxy client certificate and key.
</span><span class='line'>[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>[apiclient] Created API client, waiting for the control plane to become ready
</span><span class='line'> [apiclient] All control plane components are healthy after 494.001036 seconds
</span><span class='line'>[token] Using token: ad430d.beff5be4b98dceec
</span><span class='line'>[apiconfig] Created RBAC rules
</span><span class='line'>[addons] Applied essential addon: kube-proxy
</span><span class='line'>[addons] Applied essential addon: kube-dns
</span><span class='line'>
</span><span class='line'>Your Kubernetes master has initialized successfully!
</span><span class='line'>
</span><span class='line'>To start using your cluster, you need to run (as a regular user):
</span><span class='line'>
</span><span class='line'>  mkdir -p $HOME/.kube
</span><span class='line'>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>You should now deploy a pod network to the cluster.
</span><span class='line'>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
</span><span class='line'>  http://kubernetes.io/docs/admin/addons/
</span><span class='line'>
</span><span class='line'>You can now join any number of machines by running the following on each node
</span><span class='line'>as root:
</span><span class='line'>
</span><span class='line'>  kubeadm join --token ad430d.beff5be4b98dceec 192.168.0.148:6443
</span></code></pre></td></tr></table></div></figure>


<p>然后按照上面的提示，把客户端kubectl要用的配置准备好：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]#   mkdir -p $HOME/.kube
</span><span class='line'>[root@cu3 ~]#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>[root@cu3 ~]#   sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span></code></pre></td></tr></table></div></figure>


<p>到这里K8S的基础服务controller，apiserver，scheduler是起来了，但是dns还是有问题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 kubeadm]# kubectl get pods --all-namespaces
</span><span class='line'>NAMESPACE     NAME                          READY     STATUS    RESTARTS   AGE
</span><span class='line'>kube-system   etcd-cu3                      1/1       Running   0          6m
</span><span class='line'>kube-system   kube-apiserver-cu3            1/1       Running   0          5m
</span><span class='line'>kube-system   kube-controller-manager-cu3   1/1       Running   0          6m
</span><span class='line'>kube-system   kube-dns-2425271678-wwnkp     0/3       Pending   0          6m
</span><span class='line'>kube-system   kube-proxy-ptnlx              1/1       Running   0          6m
</span><span class='line'>kube-system   kube-scheduler-cu3            1/1       Running   0          6m
</span></code></pre></td></tr></table></div></figure>


<p>dns的容器是使用bridge网络，需要配置网络才能跑起来。有如下错误日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Aug 12 23:54:04 cu3 kubelet: W0812 23:54:04.800316   12886 cni.go:189] Unable to update cni config: No networks found in /etc/cni/net.d
</span><span class='line'>Aug 12 23:54:04 cu3 kubelet: E0812 23:54:04.800472   12886 kubelet.go:2136] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span></code></pre></td></tr></table></div></figure>


<p>下载 <a href="https://github.com/winse/docker-hadoop/tree/master/kube-deploy/kubeadm">https://github.com/winse/docker-hadoop/tree/master/kube-deploy/kubeadm</a> 目录下的 flannel 配置：</p>

<p>在官网的基础上 cni-conf.json 增加了： <code>"ipMasq": false,</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置网络
</span><span class='line'>[root@cu3 kubeadm]# kubectl apply -f kube-flannel.yml 
</span><span class='line'>kubectl apply -f kube-flannel-rbac.yml 
</span><span class='line'>serviceaccount "flannel" created
</span><span class='line'>configmap "kube-flannel-cfg" created
</span><span class='line'>daemonset "kube-flannel-ds" created
</span><span class='line'>[root@cu3 kubeadm]# kubectl apply -f kube-flannel-rbac.yml 
</span><span class='line'>clusterrole "flannel" created
</span><span class='line'>clusterrolebinding "flannel" created
</span><span class='line'>
</span><span class='line'># 等待一段时间后，dns的pods也启动好了
</span><span class='line'>[root@cu3 kubeadm]# kubectl get pods --all-namespaces
</span><span class='line'>NAMESPACE     NAME                          READY     STATUS    RESTARTS   AGE
</span><span class='line'>kube-system   etcd-cu3                      1/1       Running   0          7m
</span><span class='line'>kube-system   kube-apiserver-cu3            1/1       Running   0          7m
</span><span class='line'>kube-system   kube-controller-manager-cu3   1/1       Running   0          7m
</span><span class='line'>kube-system   kube-dns-2425271678-wwnkp     3/3       Running   0          8m
</span><span class='line'>kube-system   kube-flannel-ds-dbvkj         2/2       Running   0          38s
</span><span class='line'>kube-system   kube-proxy-ptnlx              1/1       Running   0          8m
</span><span class='line'>kube-system   kube-scheduler-cu3            1/1       Running   0          7m</span></code></pre></td></tr></table></div></figure>


<h4>node节点部署</h4>

<p>配置kubelet、docker</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sed -i 's/KUBELET_CGROUP_ARGS=--cgroup-driver=systemd/KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs/' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 
</span><span class='line'>sed -i 's#/usr/bin/dockerd.*#/usr/bin/dockerd --ip-masq=false#' /usr/lib/systemd/system/docker.service 
</span><span class='line'>
</span><span class='line'>systemctl daemon-reload; systemctl restart docker kubelet </span></code></pre></td></tr></table></div></figure>


<p>注意：加了 ip-masq=false 后，docker0就不能上外网了。也就是单独起的docker容器不能上外网！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ExecStart=/usr/bin/dockerd --ip-masq=false</span></code></pre></td></tr></table></div></figure>


<p>加入集群</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubeadm join --token ad430d.beff5be4b98dceec 192.168.0.148:6443 --skip-preflight-checks
</span><span class='line'>
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[discovery] Trying to connect to API Server "192.168.0.148:6443"
</span><span class='line'>[discovery] Created cluster-info discovery client, requesting info from "https://192.168.0.148:6443"
</span><span class='line'>[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.0.148:6443"
</span><span class='line'>[discovery] Successfully established connection with API Server "192.168.0.148:6443"
</span><span class='line'>[bootstrap] Detected server version: v1.7.2
</span><span class='line'>[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
</span><span class='line'>[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
</span><span class='line'>[csr] Received signed certificate from the API server, generating KubeConfig...
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>
</span><span class='line'>Node join complete:
</span><span class='line'>* Certificate signing request sent to master and response
</span><span class='line'>  received.
</span><span class='line'>* Kubelet informed of new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the master to see this machine join.</span></code></pre></td></tr></table></div></figure>


<p>CU2是跳板机，把kubectl的config配置拷贝过来，然后就可以在CU2上面运行命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# kubectl get nodes
</span><span class='line'>NAME      STATUS     AGE         VERSION
</span><span class='line'>cu2       NotReady   &lt;invalid&gt;   v1.7.2
</span><span class='line'>cu3       Ready      25m         v1.7.2
</span><span class='line'>
</span><span class='line'>[root@cu2 kube-deploy]# kubectl proxy 
</span><span class='line'>Starting to serve on 127.0.0.1:8001</span></code></pre></td></tr></table></div></figure>


<p>我代理做在这台机器啊 <a href="http://localhost:8001/ui">http://localhost:8001/ui</a>。。。咔咔</p>

<p>5台机器都添加后：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# kubectl get nodes 
</span><span class='line'>NAME      STATUS    AGE       VERSION
</span><span class='line'>cu1       Ready     32s       v1.7.2
</span><span class='line'>cu2       Ready     3m        v1.7.2
</span><span class='line'>cu3       Ready     29m       v1.7.2
</span><span class='line'>cu4       Ready     26s       v1.7.2
</span><span class='line'>cu5       Ready     20s       v1.7.2</span></code></pre></td></tr></table></div></figure>


<p>节点防火墙(由于是云主机，增加防火墙)：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent 
</span><span class='line'>firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent 
</span><span class='line'>firewall-cmd --complete-reload</span></code></pre></td></tr></table></div></figure>


<h2>SOURCE IP测试</h2>

<p>Sourceip的问题应该不存在。。。看了iptables-save的信息，没有cni0/cbr0的相关的数据</p>

<p>还是再来测一遍：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl run centos --image=cu.eshore.cn/library/java:jdk8 --command -- vi 
</span><span class='line'>kubectl scale --replicas=4 deployment/centos
</span><span class='line'>
</span><span class='line'>[root@cu2 kube-deploy]# pods
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE         IP              NODE
</span><span class='line'>default       centos-3954723268-62tpc                 1/1       Running   0          &lt;invalid&gt;   10.244.2.2      cu1
</span><span class='line'>default       centos-3954723268-6cmf9                 1/1       Running   0          &lt;invalid&gt;   10.244.1.2      cu2
</span><span class='line'>default       centos-3954723268-blfc4                 1/1       Running   0          &lt;invalid&gt;   10.244.3.2      cu4
</span><span class='line'>default       centos-3954723268-tb1rn                 1/1       Running   0          &lt;invalid&gt;   10.244.4.2      cu5
</span><span class='line'>default       nexus-djr9c                             1/1       Running   0          2m          192.168.0.37    cu1
</span><span class='line'>
</span><span class='line'># ping互通没问题 TEST
</span><span class='line'>
</span><span class='line'>[root@cu2 hadoop]# ./pod_bash centos-3954723268-62tpc default
</span><span class='line'>[root@centos-3024873821-4490r /]# ping 10.244.4.2 -c 1
</span><span class='line'>
</span><span class='line'># 源IP没问题 TEST
</span><span class='line'>
</span><span class='line'>[root@centos-3954723268-62tpc opt]# yum install epel-release -y  
</span><span class='line'>[root@centos-3954723268-62tpc opt]# yum install -y nginx 
</span><span class='line'>[root@centos-3954723268-62tpc opt]# service nginx start
</span><span class='line'>
</span><span class='line'>[root@centos-3954723268-blfc4 opt]# curl 10.244.2.2
</span><span class='line'>[root@centos-3954723268-tb1rn opt]# curl 10.244.2.2
</span><span class='line'>
</span><span class='line'>[root@centos-3954723268-62tpc opt]# less /var/log/nginx/access.log 
</span></code></pre></td></tr></table></div></figure>


<h4>DNS</h4>

<p>奇了怪了，这次重新安装DNS是没问题的，heaspter安装一次通过。</p>

<p>在cu3起的pods上执行 <code>nslookup kubernetes.default</code> 也是通的！</p>

<h4>监控</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># heaspter
</span><span class='line'>[root@cu2 kubeadm]# kubectl apply -f heapster/influxdb/
</span><span class='line'>deployment "monitoring-grafana" created
</span><span class='line'>service "monitoring-grafana" created
</span><span class='line'>serviceaccount "heapster" created
</span><span class='line'>deployment "heapster" created
</span><span class='line'>service "heapster" created
</span><span class='line'>deployment "monitoring-influxdb" created
</span><span class='line'>service "monitoring-influxdb" created
</span><span class='line'>[root@cu2 kubeadm]# kubectl apply -f heapster/rbac/
</span><span class='line'>clusterrolebinding "heapster" created
</span><span class='line'>
</span><span class='line'># dashboard
</span><span class='line'>[root@cu2 kubeadm]# kubectl apply -f kubernetes-dashboard.yaml 
</span><span class='line'>serviceaccount "kubernetes-dashboard" created
</span><span class='line'>clusterrolebinding "kubernetes-dashboard" created
</span><span class='line'>deployment "kubernetes-dashboard" created
</span><span class='line'>service "kubernetes-dashboard" created
</span><span class='line'>
</span><span class='line'>[root@cu2 kubeadm]# kubectl get service --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1       &lt;none&gt;        443/TCP         18m
</span><span class='line'>kube-system   kube-dns               10.96.0.10      &lt;none&gt;        53/UDP,53/TCP   18m
</span><span class='line'>kube-system   kubernetes-dashboard   10.104.165.81   &lt;none&gt;        80/TCP          5m</span></code></pre></td></tr></table></div></figure>


<p>等一小段时间，查看所有的服务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubeadm]# kubectl get services --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1        &lt;none&gt;        443/TCP         2h
</span><span class='line'>kube-system   heapster               10.102.176.168   &lt;none&gt;        80/TCP          3m
</span><span class='line'>kube-system   kube-dns               10.96.0.10       &lt;none&gt;        53/UDP,53/TCP   2h
</span><span class='line'>kube-system   kubernetes-dashboard   10.110.2.118     &lt;none&gt;        80/TCP          2m
</span><span class='line'>kube-system   monitoring-grafana     10.106.251.155   &lt;none&gt;        80/TCP          3m
</span><span class='line'>kube-system   monitoring-influxdb    10.100.168.147   &lt;none&gt;        8086/TCP        3m</span></code></pre></td></tr></table></div></figure>


<p>直接访问 10.106.251.155 或者查看 monitoring的pod 日志，查看heaspter的状态。dashboard上面出图要等一小段时间才行。</p>

<p>如果通过 monitoring-grafana 的IP访问能看到CLUSTER和POD的监控图，但是dashboard上的图就是出不来，可以重新部署dashboard：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl delete -f kubernetes-dashboard.yaml 
</span><span class='line'>kubectl create -f kubernetes-dashboard.yaml </span></code></pre></td></tr></table></div></figure>


<p>到此整个K8S就在测试环境上重新运行起来了。harbor就不安装了，平时没怎么用，也就5台机器直接save然后load工作量也不多。</p>

<h2>参考</h2>

<ul>
<li><a href="https://github.com/kubernetes/kubernetes/issues/40969">https://github.com/kubernetes/kubernetes/issues/40969</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzI4MTQyMDAxMA==&amp;mid=2247483665&amp;idx=1&amp;sn=d8b61666fe0a0965336d15250e2648cb&amp;scene=0">http://mp.weixin.qq.com/s?__biz=MzI4MTQyMDAxMA==&amp;mid=2247483665&amp;idx=1&amp;sn=d8b61666fe0a0965336d15250e2648cb&amp;scene=0</a></li>
<li><a href="http://cizixs.com/2017/05/23/container-network-cni">http://cizixs.com/2017/05/23/container-network-cni</a></li>
<li><a href="https://github.com/containernetworking/cni/blob/master/SPEC.md#network-configuration">https://github.com/containernetworking/cni/blob/master/SPEC.md#network-configuration</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[保护/加密JAVA代码]]></title>
    <link href="http://winseliu.com/blog/2017/08/09/java-bytecode-security/"/>
    <updated>2017-08-09T18:10:39+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/09/java-bytecode-security</id>
    <content type="html"><![CDATA[<p>由于Java代码生成的是中间过程字节码，javap以及一些反编译的工具基本能看代码的大概，对于提供给客户的代码需要做一些处理：混淆或者加密。下面分几块把在实际操作过程中参考的内容罗列出来，希望对看到本文并感兴趣的你有所帮助。</p>

<h2>自定义ClassLoader</h2>

<p>混淆+ClassLoader</p>

<ul>
<li><a href="http://www.voidcn.com/blog/zmx729618/article/p-4375840.html">java源代码加密+使用proguard混淆java web项目代码+自定义Classloader</a> 思路不错</li>
</ul>


<p>自定义ClassLoader并用Java实现解密</p>

<ul>
<li><a href="http://www.aspphp.online/bianchen/java/gyjava/201701/112687.html">利用DES加密的算法保護Java源代碼</a> 为啥要加密，以及一般的保护措施（混淆、加密盘、自定义classloader）。实现有点low，用Java写的加密人家调试下就全部请求怎么弄的了。</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-secureclass/index.html">运用加密技术保护Java源代码</a> Java实现加解密通过自定义classloader。2001年的文章啊，牛逼</li>
<li><a href="http://blog.csdn.net/dianacody/article/details/38585209">Java代码加密与反编译（二）：用加密算法DES修改classLoader实现对.class文件加密</a> 有点实践了上一篇ibm文章的意思。</li>
</ul>


<p>自定义ClassLoader（jvmti）用C++实现解密</p>

<ul>
<li><a href="https://wenku.baidu.com/view/587af93767ec102de2bd892c.html">ClassLoader加密技术改进研究pdf</a> 理论派。classloader的实现用C++写（loadClass用JNI实现），但是还是需要对原有代码进行一定的修改</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-protectjava/index.html">如何有效的保护 JAVA 程序</a> 这种ClassLoader加密实现有点复杂了，还改java.c的loadClass？2002年的文章啊：解决了 ClassLoader 本身的安全性，其不失为一个比较好安全方案。</li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/]%20%E9%9D%9E%E5%B8%B8%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E4%B8%80%E7%AF%87%E3%80%82%E8%AE%B2%E4%BA%86%E8%87%AA%E5%AE%9A%E4%B9%89classloader%E5%92%8Cjvmti%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%8F%90%E4%BE%9B%E4%BA%86%E6%BA%90%E7%A0%81%E5%B7%A5%E7%A8%8B[JarEncrypt](https://github.com/AloneMonkey/JarEncrypt">jar包加密保护解决方案</a>，参考。</li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a> 用jvmti来实现加解密，牛逼的一篇文章啊！一步步按他的操作可以实现，还附有源码，参考。</li>
</ul>


<p>其他一些</p>

<ul>
<li><a href="http://cjnetwork.iteye.com/blog/851544#bc1819690">java源程序加密解决方案(基于Classloader解密)</a> 本身是一篇很棒的文章，多重加密保障ClassLoader安全。又有大神的回复：java的class加密都可以通过dumpclass来还原出来，囧</li>
<li><a href="http://rednaxelafx.iteye.com/blog/727938">如何dump出一个Java进程里的类对应的Class文件？</a> 大神的sun.jvm.hotspot.tools.jcore.ClassDump文章，只要知道类名就无敌了啊</li>
</ul>


<h2>JNI</h2>

<p>javah</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">Calling native functions from Java with JNI and Maven</a> maven搭建native的环境，整体的结构很值得学习</li>
<li><a href="http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html">http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html</a> maven native插件</li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a> 从生成.h到最后打包一条龙，值得学习。</li>
</ul>


<p>环境部署及入门</p>

<ul>
<li><a href="http://blog.csdn.net/ididcan/article/details/6828982">JNI简单实现Java调用C++/C的HelloWorld</a> 搭开发环境的时刻，可以按照步骤一步步来</li>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a> 直接VS建空项目，不错。思路清晰。中文入门不二之选！</li>
<li><a href="http://www.javamex.com/tutorials/jni/getting_started.shtml">Getting started with JNI</a> 需要小翻个墙啊，有介绍Additional Include Directories的方式配置java的头文件。</li>
<li><a href="https://www.ibm.com/developerworks/java/tutorials/j-jni/j-jni.html">Java programming with JNI</a> 了解JNI没有比这篇更好的文章了，即介绍了java调c++，又介绍了c++调用java。</li>
<li><a href="http://tinggo.iteye.com/blog/1185551">VS项目配置详解</a> VS预定义头：DEBUG，RELEASE的一些头可以定义在配置里面。有点像makefile里面决定打什么版本。</li>
</ul>


<p>配jni.h的 附加目录 的时刻，需要选择 配置 和 平台 的配置！！需要对应好！ jni的.h文件需要放到c++的项目下面去，引用外部的好像找不到，有问题。</p>

<p>java与c++类型之间的转换</p>

<ul>
<li><a href="https://stackoverflow.com/questions/8439233/how-to-convert-jbytearray-to-native-char-in-jni">How to convert jbyteArray to native char* in jni?</a></li>
<li><a href="https://stackoverflow.com/questions/12854333/jni-in-c-to-read-file-to-jbytearray">JNI in C++ to read file to jbyteArray</a></li>
</ul>


<p>JNI调用C++的加密算法</p>

<ul>
<li><a href="http://blog.csdn.net/wtbee/article/details/11658017">Java实现DES对称加密算法（附Android下3DES的JNI源码）</a> 有简单介绍DES的只是。中间换成过他的DES的实现，但是感觉怪怪的，有点不太靠谱。后面换成OPENSSL了。</li>
<li><a href="http://www.cnblogs.com/kolin/p/4256614.html">JNI调用c++实现AES加密解密</a> android的，用的应该也是OPENSSL。可以参考过程</li>
</ul>


<h2>OPENSSL</h2>

<ul>
<li><a href="http://www.qmailer.net/archives/183.html">OpenSSL编程-对称加密及DES/3DES简介</a> 简单的介绍</li>
<li><a href="http://blog.csdn.net/duanxingheng/article/details/11655037">OPENSSL库的使用-DES篇</a> 看看算法还可以。算法介绍，有对OPENSSL DES库的介绍和使用</li>
<li><a href="https://www.madboa.com/geek/openssl/">OpenSSL Command-Line</a></li>
<li><a href="http://www.cnblogs.com/gordon0918/p/5317701.html">openssl 对称加密算法enc命令详解</a> 命令行的使用</li>
<li><a href="https://www.slideshare.net/guanzhi/crypto-with-openssl">https://www.slideshare.net/guanzhi/crypto-with-openssl</a></li>
<li><a href="http://www.linuxjournal.com/article/4822">An Introduction to OpenSSL Programming</a> 2001年的太老了，留个纪念。</li>
</ul>


<p>WINDOWS安装/编译安装OPENSSL然后在VS里面应用：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio">https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio</a></li>
<li><a href="https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012">https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012</a></li>
<li><a href="https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64">https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64</a></li>
<li><a href="http://slproweb.com/products/Win32OpenSSL.html">http://slproweb.com/products/Win32OpenSSL.html</a></li>
</ul>


<p>NuGet安装OpenSSL on VS2015-1.0.2版本：（我用的这种方式）</p>

<ul>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a> VS2015 安装openssl v1.0.2 才有v140的include。 v1.0.2.1安装不了，参考。</li>
</ul>


<p>GCC</p>

<ul>
<li><a href="https://stackoverflow.com/questions/1894013/how-to-use-openssl-in-gcc">How to use OpenSSL in GCC?</a> 加依赖: -L/usr/lib -lssl -lcrypto -o server</li>
</ul>


<p>DES</p>

<ul>
<li><a href="https://my.oschina.net/mawx/blog/85424">https://my.oschina.net/mawx/blog/85424</a> Java DESede用C++ Openssl实现 参考下他的链接</li>
<li><a href="http://www.open-open.com/solution/view/1320502797546">http://www.open-open.com/solution/view/1320502797546</a> Java与C++通过DES、blowfish互相加解密</li>
<li><a href="http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs">http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs</a> OpenSSL DES APIs</li>
</ul>


<p>AES</p>

<ul>
<li><a href="https://www.lovelucy.info/openssl-aes-encryption.html">AES加密和解密——使用openssl编程</a> 参考他的makefile。AES用的是OPENSSL，写的中规中矩</li>
<li><a href="http://www.cnblogs.com/luop/p/4334160.html">密码算法详解——AES</a></li>
<li><a href="http://www.ssdfans.com/?p=238">AES加密算法图解</a> flash动画很赞</li>
<li><a href="http://yuanshuilee.blog.163.com/blog/static/21769727520140942826137/">openssl之aes加密（AES_cbc_encrypt 与 AES_encrypt 的编程案例）</a> 很棒的一篇，参考。</li>
<li><a href="https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/">https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/</a> 高级加密标准AES的工作模式（ECB、CBC、CFB、OFB），还有接口的介绍，非常好的一篇文章</li>
</ul>


<p>AES CBC 相互加解密 Java/PHP/C++ java和c++加解密，互通</p>

<ul>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a> 非常牛逼的一篇，参考。</li>
<li><a href="http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html">http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html</a> Java和C/C++进行DES/AES密文传输</li>
<li><a href="https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl">https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl</a></li>
<li><a href="https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent">https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent</a></li>
<li><a href="http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html">http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html</a> DES 算法的 C++ 与 JAVA 互相加解密</li>
<li><a href="http://juliusdavies.ca/commons-ssl/pbe.html">OpenSSL&rsquo;s &ldquo;enc&rdquo; in Java (PBE / Password Based Encryption)</a></li>
<li><a href="http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html">http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html</a></li>
<li><p><a href="https://ruby-china.org/topics/26490">https://ruby-china.org/topics/26490</a></p></li>
<li><p><a href="https://shanetully.com/2012/06/openssl-rsa-aes-and-c/">OpenSSL, RSA, AES and C++</a> 好鬼长复杂没怎么看，搜AES找到了。</p></li>
</ul>


<h4>OPENSSL MD5： VS + GCC + JAVA + 命令行</h4>

<ul>
<li><a href="http://www.askyb.com/cpp/openssl-md5-hashing-example-in-cpp/">OpenSSL MD5 Hashing Example in C++</a></li>
<li><a href="https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash">https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash</a> LINUX命令行</li>
<li><a href="https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal">https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal</a> md5sum</li>
<li><a href="https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files">https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files</a> 循环算一个目录下文件的MD5</li>
<li><a href="https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC">https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC</a> OPENSSL各种算法的使用</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># SHA256, used in chef cookbooks
</span><span class='line'>openssl dgst -sha256 path/to/myfile
</span><span class='line'># MD5
</span><span class='line'>openssl dgst -md5 path/to/myfile
</span><span class='line'>echo -n 'text to be encrypted' | md5sum -
</span><span class='line'>$ echo -n 123456 | md5sum | awk '{print $1}'
</span><span class='line'>$ echo -n Welcome | md5sum
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# gcc -Wall -lcrypto -lssl opensslmd5.cpp -o md5
</span><span class='line'>[root@cu2 ~]# ./md5
</span><span class='line'>md5 digest: 56ab24c15b72a457069c5ea42fcfc640
</span></code></pre></td></tr></table></div></figure>


<p>makefile</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CC=g++
</span><span class='line'>CFLAGS=-Wall -g -O2
</span><span class='line'>LIBS=-lcrypto
</span><span class='line'>
</span><span class='line'>all: aes
</span><span class='line'>
</span><span class='line'>aes: aes.cc
</span><span class='line'>    $(CC) $(CFLAGS) aes.cc -o $@ $(LIBS)
</span><span class='line'>
</span><span class='line'>clean:
</span><span class='line'>    @rm -f aes
</span></code></pre></td></tr></table></div></figure>


<h4>OPENSSL命令行</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>openssl des3 -nosalt -k abc123 -in file.txt -out file.des3 #不加盐，key为abc123来加密
</span><span class='line'>openssl des3 -d -nosalt -in file.des3 -out f.txt -k abc123#解密
</span><span class='line'>
</span><span class='line'>默认是-salt，加盐的，如果不加盐，则根据pass生成的key和iv不变，例：
</span><span class='line'>
</span><span class='line'>You can get openssl to base64-encode the message by using the -a
</span><span class='line'>stefano:~$ openssl aes-256-cbc -in attack-plan.txt -a
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -a -salt -k abcdefghijklmnop
</span><span class='line'>[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -k abcdefghijklmnop |  openssl aes-128-cbc -d -k abcdefghijklmnop
</span></code></pre></td></tr></table></div></figure>


<h2>其他</h2>

<p>SHELL二进制编码：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script">https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script</a> hexdump</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>el@defiant ~ $ printf '%x\n' 26
</span><span class='line'>el@defiant ~ $ echo $((0xAA))
</span><span class='line'>printf -v result1 "%x" "$decimal1"
</span><span class='line'>% xxd -l 16 -p /dev/random
</span><span class='line'>193f6c54814f0576bc27d51ab39081dc
</span><span class='line'>$ echo -n $'\x12\x34' | xxd -p
</span><span class='line'>
</span><span class='line'>$ echo -n $'\x12\x34' | hexdump -e '"%x"'
</span><span class='line'>
</span><span class='line'>od -vt x1|awk '{$1="";print}'
</span><span class='line'>echo "obase=16; 34" | bc
</span></code></pre></td></tr></table></div></figure>


<p>c++命令行不直接关闭。。。最后用断点的方式替代了，没找到好的方法！！</p>

<p>文件读写</p>

<ul>
<li><a href="http://blog.csdn.net/lightlater/article/details/6364931">C++读写二进制文件</a></li>
<li><a href="http://blog.csdn.net/guyue6670/article/details/6681037">fopen中w w+ wb区别</a> 人家代码写的是w+，加密class后多了0D。后面问了搞C的同事才知道二进制要用wb，C就是一堆坑啊！</li>
</ul>


<p>g++</p>

<ul>
<li><a href="https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope">https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope</a> snprintf</li>
</ul>


<p>git</p>

<ul>
<li><a href="https://git-scm.com/docs/git-archive">https://git-scm.com/docs/git-archive</a> GIT打包</li>
</ul>


<h2>重要的参考文章再列一遍</h2>

<ul>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a></li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/">jar包加密保护解决方案</a> 源码<a href="https://github.com/AloneMonkey/JarEncrypt">JarEncrypt</a></li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a></li>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a></li>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a></li>
</ul>


<p>TODO 编译打包</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">http://www.tricoder.net/blog/?p=197</a></li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NFS on Centos7]]></title>
    <link href="http://winseliu.com/blog/2017/08/05/nfs-on-centos7/"/>
    <updated>2017-08-05T08:38:56+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/05/nfs-on-centos7</id>
    <content type="html"><![CDATA[<h2>参考</h2>

<ul>
<li><a href="https://www.howtoforge.com/nfs-server-and-client-on-centos-7">https://www.howtoforge.com/nfs-server-and-client-on-centos-7</a></li>
<li><a href="http://blog.huatai.me/2014/10/14/CentOS-7-NFS-Server-and-Client-Setup/">http://blog.huatai.me/2014/10/14/CentOS-7-NFS-Server-and-Client-Setup/</a></li>
</ul>


<h2>指令</h2>

<p>安装</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 data]# yum install nfs-utils -y 
</span><span class='line'>[root@cu3 data]# chmod -R 777 /data/k8s-dta
</span><span class='line'>
</span><span class='line'>systemctl enable rpcbind
</span><span class='line'>systemctl enable nfs-server
</span><span class='line'>systemctl enable nfs-lock
</span><span class='line'>systemctl enable nfs-idmap
</span><span class='line'>
</span><span class='line'>systemctl start rpcbind
</span><span class='line'>systemctl start nfs-server
</span><span class='line'>systemctl start nfs-lock
</span><span class='line'>systemctl start nfs-idmap</span></code></pre></td></tr></table></div></figure>


<p>配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 data]# vi /etc/exports
</span><span class='line'>/data/k8s-dta 192.168.0.0/24(rw,sync,no_root_squash,no_all_squash)
</span></code></pre></td></tr></table></div></figure>


<p>说明：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/data/k8s-dta – 共享目录
</span><span class='line'>192.168.0.0/24 – 允许访问NFS的客户端IP地址段
</span><span class='line'>rw – 允许对共享目录进行读写
</span><span class='line'>sync – 实时同步共享目录
</span><span class='line'>no_root_squash – 允许root访问
</span><span class='line'>no_all_squash - 允许用户授权
</span><span class='line'>no_subtree_check - 如果卷的一部分被输出，从客户端发出请求文件的一个常规的调用子目录检查验证卷的相应部分。如果是整个卷输出，禁止这个检查可以加速传输。
</span><span class='line'>no_subtree_check - If only part of a volume is exported, a routine called subtree checking verifies that a file that is requested from the client is in the appropriate part of the volume. If the entire volume is exported, disabling this check will speed up transfers. Setting Up an NFS Server
</span></code></pre></td></tr></table></div></figure>


<p>然后重启服务，并开放防火墙（或者关闭）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>systemctl restart nfs-server
</span><span class='line'>
</span><span class='line'>firewall-cmd --permanent --zone=public --add-service=ssh
</span><span class='line'>firewall-cmd --permanent --zone=public --add-service=nfs
</span><span class='line'>firewall-cmd --reload</span></code></pre></td></tr></table></div></figure>


<h2>客户端配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 opt]# yum install -y nfs-utils
</span><span class='line'>
</span><span class='line'>[root@cu2 opt]# mount cu3:/data/k8s-dta dta
</span><span class='line'>[root@cu2 opt]# touch dta/abc
</span><span class='line'>[root@cu2 opt]# ll dta
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Aug  3  2017 abc
</span><span class='line'>
</span><span class='line'>[root@cu3 data]# ll k8s-dta/
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Aug  3 15:19 abc</span></code></pre></td></tr></table></div></figure>


<h2>后记</h2>

<p>建好NFS服务后，可以把它作为k8s容器的存储，这样就不怕丢数据了。</p>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#writing-to-stable-storage">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#writing-to-stable-storage</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs">https://kubernetes.io/docs/concepts/storage/volumes/#nfs</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/master/examples/volumes/nfs">https://github.com/kubernetes/kubernetes/tree/master/examples/volumes/nfs</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encfs加密文件系统]]></title>
    <link href="http://winseliu.com/blog/2017/08/05/encfs-secure-filesystem/"/>
    <updated>2017-08-05T02:55:57+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/05/encfs-secure-filesystem</id>
    <content type="html"><![CDATA[<p>为了数据安全，最近领导给了个链接让去了解了解 <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-ecryptfs/">eCryptfs</a> 。通过yum和自己手动编译安装后都运行失败，系统的<a href="http://centosfaq.org/centos/about-ecryptfs-utils/#comment-110110">Centos7内核不支持ecryptfs模块</a> 。</p>

<p>通过一个介绍ecryptfs的<a href="https://linux.cn/article-4470-1.html">关联的链接</a> 了解到 <a href="http://www.arg0.net/encfs">encfs</a> 也是做 ecryptfs 类似的事情。然后就去下载安装，最后发现windows下面也可以用（惊喜）。</p>

<p>epel下面已经发布了 encfs 的rpm包。现在只要是仓库有的包就不自己编译（进行过N次升级的洗礼，最终发现yum、rpm才是最终归宿啊）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install fuse 
</span><span class='line'>[root@k8s ~]# yum install encfs
</span><span class='line'>
</span><span class='line'>挂载、创建
</span><span class='line'>[root@k8s shm]# encfs /dev/shm/.test /dev/shm/test
</span><span class='line'>The directory "/dev/shm/.test/" does not exist. Should it be created? (y,n) y
</span><span class='line'>The directory "/dev/shm/test/" does not exist. Should it be created? (y,n) y
</span><span class='line'>Creating new encrypted volume.
</span><span class='line'>Please choose from one of the following options:
</span><span class='line'> enter "x" for expert configuration mode,
</span><span class='line'> enter "p" for pre-configured paranoia mode,
</span><span class='line'> anything else, or an empty line will select standard mode.
</span><span class='line'>?&gt;
</span><span class='line'>
</span><span class='line'>Standard configuration selected.
</span><span class='line'>
</span><span class='line'>Configuration finished.  The filesystem to be created has
</span><span class='line'>the following properties:
</span><span class='line'>Filesystem cipher: "ssl/aes", version 3:0:2
</span><span class='line'>Filename encoding: "nameio/block", version 4:0:2
</span><span class='line'>Key Size: 192 bits
</span><span class='line'>Block Size: 1024 bytes
</span><span class='line'>Each file contains 8 byte header with unique IV data.
</span><span class='line'>Filenames encoded using IV chaining mode.
</span><span class='line'>File holes passed through to ciphertext.
</span><span class='line'>
</span><span class='line'>Now you will need to enter a password for your filesystem.
</span><span class='line'>You will need to remember this password, as there is absolutely
</span><span class='line'>no recovery mechanism.  However, the password can be changed
</span><span class='line'>later using encfsctl.
</span><span class='line'>
</span><span class='line'>New Encfs Password: 123456
</span><span class='line'>Verify Encfs Password:
</span><span class='line'>
</span><span class='line'>[root@k8s shm]# echo $(hostname) &gt; test/hostname.txt
</span><span class='line'>[root@k8s shm]# ll -R -a
</span><span class='line'>.:
</span><span class='line'>total 0
</span><span class='line'>drwxrwxrwt.  4 root root   80 Aug  4 22:04 .
</span><span class='line'>drwxr-xr-x. 20 root root 3260 Aug  4 21:16 ..
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 test
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 .test
</span><span class='line'>
</span><span class='line'>./test:
</span><span class='line'>total 4
</span><span class='line'>drwx------. 2 root root 80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root 80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root  4 Aug  4 22:06 hostname.txt
</span><span class='line'>
</span><span class='line'>./.test:
</span><span class='line'>total 8
</span><span class='line'>drwx------. 2 root root   80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root   80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root 1263 Aug  4 22:04 .encfs6.xml
</span><span class='line'>-rw-r--r--. 1 root root   12 Aug  4 22:06 pAqhW671kQSK4kPLJM-TF6sp
</span><span class='line'>
</span><span class='line'>卸载
</span><span class='line'>[root@k8s shm]# fusermount -u test
</span><span class='line'>[root@k8s shm]# ll -R -a
</span><span class='line'>.:
</span><span class='line'>total 0
</span><span class='line'>drwxrwxrwt.  4 root root   80 Aug  4 22:04 .
</span><span class='line'>drwxr-xr-x. 20 root root 3260 Aug  4 21:16 ..
</span><span class='line'>drwx------.  2 root root   40 Aug  4 22:04 test
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 .test
</span><span class='line'>
</span><span class='line'>./test:
</span><span class='line'>total 0
</span><span class='line'>drwx------. 2 root root 40 Aug  4 22:04 .
</span><span class='line'>drwxrwxrwt. 4 root root 80 Aug  4 22:04 ..
</span><span class='line'>
</span><span class='line'>./.test:
</span><span class='line'>total 8
</span><span class='line'>drwx------. 2 root root   80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root   80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root 1263 Aug  4 22:04 .encfs6.xml
</span><span class='line'>-rw-r--r--. 1 root root   12 Aug  4 22:06 pAqhW671kQSK4kPLJM-TF6sp
</span></code></pre></td></tr></table></div></figure>


<p>注意: 最好将 .encfs6.xml 备份起來, 这个文件损坏或丢失将无法还原加密的文件。</p>

<p>把加密的文件备份到云盘，然后本地挂载就能看到原始内容了。安全的云盘就这么简单的实现了，咔咔。。。</p>

<p>在windows安装 <a href="https://encfsmp.sourceforge.io/download.html">EncFSMP</a> 就可以和在Linux上面一样操作encfs文件系统了。</p>

<blockquote><p>EncFS从原理不同TrueCrypt的容器 ，它存储在一个单一的大文件的加密文件。 相反，EncFS为您添加的每个文件创建单独的文件。 它更好地与云存储服务，每次更改时重新上传整个TrueCrypt容器。</p></blockquote>

<h2>参考链接</h2>

<ul>
<li><a href="http://www.arg0.net/encfs">http://www.arg0.net/encfs</a></li>
<li><a href="https://linux.cn/article-4470-1.html">https://linux.cn/article-4470-1.html</a> 通过这篇文章查看到了encfs</li>
<li><a href="https://github.com/vgough/encfs/blob/master/INSTALL.md">https://github.com/vgough/encfs/blob/master/INSTALL.md</a> 编译安装</li>
<li><a href="http://www.vonwei.com/post/introduceToEncFS.html">http://www.vonwei.com/post/introduceToEncFS.html</a> 中文简单介绍和入门。手动编译，命令的参数也有介绍，还有介绍加密目录的 .encfs6.xml</li>
<li><a href="https://github.com/vgough/encfs/blob/master/encfs/encfs.pod#examples">https://github.com/vgough/encfs/blob/master/encfs/encfs.pod#examples</a></li>
<li><a href="https://github.com/vgough/encfs/blob/master/encfs/encfsctl.pod">https://github.com/vgough/encfs/blob/master/encfs/encfsctl.pod</a></li>
<li><p><a href="https://www.howtoip.com/how-to-encrypt-cloud-storage-on-linux-and-windows-with-encfs/">https://www.howtoip.com/how-to-encrypt-cloud-storage-on-linux-and-windows-with-encfs/</a>  非常棒的教程，linux和windows都介绍了</p></li>
<li><p><a href="http://www.jianshu.com/p/073957902fa9">http://www.jianshu.com/p/073957902fa9</a> 手动编译，以后可能用得到。最后的启动自动加载磁盘可以借鉴。</p></li>
<li><a href="https://github.com/vgough/encfs/issues/66">https://github.com/vgough/encfs/issues/66</a>  encfs on cygwin</li>
<li><a href="https://superuser.com/questions/179150/reading-an-encfs-volume-from-windows">https://superuser.com/questions/179150/reading-an-encfs-volume-from-windows</a></li>
<li><a href="https://encfsmp.sourceforge.io/download.html">https://encfsmp.sourceforge.io/download.html</a> for windows</li>
<li><a href="https://github.com/dokan-dev/dokany">https://github.com/dokan-dev/dokany</a> fuse on windows</li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kubeadm部署kubernetes]]></title>
    <link href="http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/"/>
    <updated>2017-07-30T12:18:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7</id>
    <content type="html"><![CDATA[<p>官网文档差，删文档倒是不手软。使用脚本启动、安装的文档（docker-multinode）已经删掉了，现在都推荐使用kubeadm来进行安装。</p>

<p>本文使用代理在master上安装并缓冲rpm、以及下载docker镜像，然后做本地YUM仓库和拷贝镜像到其他worker节点的方式来部署集群。下一篇再介绍在拥有kubelet/kubeadm rpm、以及k8s docker镜像的情况下怎么去部署一个新的k8s集群。</p>

<p>这里使用两台虚拟机做测试：</p>

<ul>
<li>k8s kube-master : 192.168.191.138</li>
<li>woker1 : 192.168.191.139</li>
</ul>


<h2>修改主机名，改时间、时区，防火墙</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hostnamectl --static set-hostname k8s 
</span><span class='line'>hostname k8s 
</span><span class='line'>
</span><span class='line'>rm -rf /etc/localtime 
</span><span class='line'>ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 
</span><span class='line'>
</span><span class='line'>systemctl disable firewalld ; service firewalld stop
</span></code></pre></td></tr></table></div></figure>


<h2>安装docker</h2>

<ul>
<li><a href="https://docs.docker.com/v1.12/engine/installation/linux/rhel/">https://docs.docker.com/v1.12/engine/installation/linux/rhel/</a></li>
<li><a href="https://yum.dockerproject.org/repo/main/centos/7/Packages/">https://yum.dockerproject.org/repo/main/centos/7/Packages/</a> 打开看下1.12的具体版本</li>
<li><a href="https://docs.docker.com/v1.12/engine/admin/systemd/">https://docs.docker.com/v1.12/engine/admin/systemd/</a>  *</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'
</span><span class='line'>[dockerrepo]
</span><span class='line'>name=Docker Repository
</span><span class='line'>baseurl=https://yum.dockerproject.org/repo/main/centos/7/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=https://yum.dockerproject.org/gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>yum list docker-engine --showduplicates
</span><span class='line'>
</span><span class='line'>yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6 -y
</span><span class='line'>systemctl enable docker ; systemctl start docker
</span></code></pre></td></tr></table></div></figure>


<h2>翻墙安装配置</h2>

<p>具体操作参考 <a href="http://winseliu.com/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks">使用Privoxy把shadowsocks转换为Http代理</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install -y epel-release ; yum install -y python-pip 
</span><span class='line'>[root@k8s ~]# pip install shadowsocks
</span><span class='line'>[root@k8s ~]# vi /etc/shadowsocks.json 
</span><span class='line'>[root@k8s ~]# sslocal -c /etc/shadowsocks.json 
</span><span class='line'>[root@k8s ~]# curl --socks5-hostname 127.0.0.1:1080 www.google.com
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# yum install privoxy -y
</span><span class='line'>[root@k8s ~]# vi /etc/privoxy/config 
</span><span class='line'>...
</span><span class='line'>forward-socks5 / 127.0.0.1:1080 .
</span><span class='line'>listen-address 192.168.191.138:8118
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl enable privoxy
</span><span class='line'>[root@k8s ~]# systemctl start privoxy
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# curl -x 192.168.191.138:8118 www.google.com
</span><span class='line'>
</span><span class='line'>等k8s安装启动好后，把privoxy的服务disable掉
</span><span class='line'>[root@k8s ~]# systemctl disable privoxy.service</span></code></pre></td></tr></table></div></figure>


<h2>下载kubectl（怪了，这个竟然可以直接下载）</h2>

<p>变化好快，现在都1.7.2了！ <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>

<p>在master机器（常用的操作机器）安装即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
</span><span class='line'>chmod +x ./kubectl
</span><span class='line'>mv ./kubectl /usr/local/bin/kubectl
</span><span class='line'>
</span><span class='line'># 启用shell的提示/自动完成autocompletion
</span><span class='line'>echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl version 
</span><span class='line'>Client Version: version.Info{Major:"1", Minor:"7", GitVersion:"v1.7.2", GitCommit:"922a86cfcd65915a9b2f69f3f193b8907d741d9c", GitTreeState:"clean", BuildDate:"2017-07-21T08:23:22Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"linux/amd64"}
</span><span class='line'>The connection to the server localhost:8080 was refused - did you specify the right host or port?
</span></code></pre></td></tr></table></div></figure>


<h2>通过VPN安装kubelet和kubeadm</h2>

<p>参考 <a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm">https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm</a></p>

<p>You will install these packages on all of your machines:</p>

<ul>
<li>kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</li>
<li>kubeadm: the command to bootstrap the cluster.</li>
</ul>


<p>所有机器都要安装的，我们先在master节点上通过代理安装这两个软件，并把安装的所有rpm缓冲起来。</p>

<ul>
<li>配置kubernetes的仓库源：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span><span class='line'>[kubernetes]
</span><span class='line'>name=Kubernetes
</span><span class='line'>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>repo_gpgcheck=1
</span><span class='line'>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
</span><span class='line'>        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 
</span><span class='line'>setenforce 0
</span><span class='line'>
</span><span class='line'>yum-config-manager --enable kubernetes</span></code></pre></td></tr></table></div></figure>


<ul>
<li>YUM配置socks5代理： <a href="https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum">https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum</a></li>
</ul>


<p>修改yum的配置，增加代理，并缓冲（用于其他机器安装）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# vi /etc/yum.conf 
</span><span class='line'>keepcache=1
</span><span class='line'>...
</span><span class='line'>proxy=socks5://127.0.0.1:1080
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装并启动kubelet：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install -y kubelet kubeadm
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl enable kubelet && systemctl start kubelet
</span><span class='line'>Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<h2>通过VPN安装初始化集群（主要是配置代理下载docker容器）</h2>

<p>由于是直接docker去获取镜像的，首先需要修改docker的配置。</p>

<p>参考 <a href="https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy">https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy</a></p>

<ul>
<li>配置代理并重启docker、kubelet</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# systemctl enable docker
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# mkdir -p /etc/systemd/system/docker.service.d/
</span><span class='line'>[root@k8s ~]# vi /etc/systemd/system/docker.service.d/http-proxy.conf
</span><span class='line'>[Service]
</span><span class='line'>Environment="HTTP_PROXY=http://192.168.191.138:8118/" "HTTPS_PROXY=http://192.168.191.138:8118/" "NO_PROXY=localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
</span><span class='line'>                             
</span><span class='line'>[root@k8s ~]# systemctl daemon-reload
</span><span class='line'>[root@k8s ~]# systemctl restart docker</span></code></pre></td></tr></table></div></figure>


<p>docker和kubelet的cgroup驱动方式不同，需要修复配置：<a href="https://github.com/kubernetes/kubeadm/issues/103">https://github.com/kubernetes/kubeadm/issues/103</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>前面已经启动了kubelet，有如下的错误日志
</span><span class='line'>[root@k8s ~]# journalctl -xeu kubelet
</span><span class='line'>Jul 29 09:11:24 k8s kubelet[48557]: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgr
</span><span class='line'>
</span><span class='line'>修改配置
</span><span class='line'>[root@k8s ~]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span><span class='line'>Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs"
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl daemon-reload
</span><span class='line'>[root@k8s ~]# service kubelet restart
</span><span class='line'>Redirecting to /bin/systemctl restart  kubelet.service
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>使用kubeadm进行初始化</li>
</ul>


<p><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a> （可以使用 &ndash;kubernetes-version 来指定k8s的版本）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置代理，kubeadm有部分请求应该也是需要走代理的（前面用脚本安装过multinode on docker的经历猜测的）
</span><span class='line'>
</span><span class='line'>export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
</span><span class='line'>export https_proxy=http://192.168.191.138:8118/
</span><span class='line'>export http_proxy=http://192.168.191.138:8118/
</span><span class='line'>
</span><span class='line'># 使用reset重置，网络代理的配置修改了多次（kubeadm初始换过程失败过），还有前几次的初始化没有配置pod地址段
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm reset
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>[reset] Stopping the kubelet service
</span><span class='line'>[reset] Unmounting mounted directories in "/var/lib/kubelet"
</span><span class='line'>[reset] Removing kubernetes-managed containers
</span><span class='line'>[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/lib/etcd]
</span><span class='line'>[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
</span><span class='line'>[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
</span><span class='line'>
</span><span class='line'># 使用flannel需要指定pod的网卡地址段（文档要整体看一遍才能少踩坑，囧）
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[init] Using Kubernetes version: v1.7.2
</span><span class='line'>[init] Using Authorization modes: [Node RBAC]
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
</span><span class='line'>[certificates] Generated CA certificate and key.
</span><span class='line'>[certificates] Generated API server certificate and key.
</span><span class='line'>[certificates] API Server serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.191.138]
</span><span class='line'>[certificates] Generated API server kubelet client certificate and key.
</span><span class='line'>[certificates] Generated service account token signing key and public key.
</span><span class='line'>[certificates] Generated front-proxy CA certificate and key.
</span><span class='line'>[certificates] Generated front-proxy client certificate and key.
</span><span class='line'>[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
</span><span class='line'>[apiclient] Created API client, waiting for the control plane to become ready  
</span><span class='line'>&lt;-&gt; 这里会停的比较久，要去下载镜像，然后还得启动容器
</span><span class='line'>[apiclient] All control plane components are healthy after 293.004469 seconds
</span><span class='line'>[token] Using token: 2af779.b803df0b1effb3d9
</span><span class='line'>[apiconfig] Created RBAC rules
</span><span class='line'>[addons] Applied essential addon: kube-proxy
</span><span class='line'>[addons] Applied essential addon: kube-dns
</span><span class='line'>
</span><span class='line'>Your Kubernetes master has initialized successfully!
</span><span class='line'>
</span><span class='line'>To start using your cluster, you need to run (as a regular user):
</span><span class='line'>
</span><span class='line'>  mkdir -p $HOME/.kube
</span><span class='line'>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>You should now deploy a pod network to the cluster.
</span><span class='line'>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
</span><span class='line'>  http://kubernetes.io/docs/admin/addons/
</span><span class='line'>
</span><span class='line'>You can now join any number of machines by running the following on each node
</span><span class='line'>as root:
</span><span class='line'>
</span><span class='line'>  kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<p>监控安装情况命令有： <code>docker ps</code>, <code>docker images</code>, <code>journalctl -xeu kubelet</code> (/var/log/messages) 。</p>

<p>如果有镜像下载和容器新增，说明安装过程在进行中。否则得检查下你的代理是否正常工作了！</p>

<p>初始化完成后，配置kubectl的kubeconfig。一般都是主节点了，直接在节点执行下面命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# mkdir -p $HOME/.kube
</span><span class='line'>[root@k8s ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>[root@k8s ~]# chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>[root@k8s ~]# 
</span><span class='line'>[root@k8s ~]# ll ~/.kube/
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x. 3 root root   23 Jul 29 21:39 cache
</span><span class='line'>-rw-------. 1 root root 5451 Jul 29 22:57 config</span></code></pre></td></tr></table></div></figure>


<p><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">使用Kubeadm安装Kubernetes</a> 介绍了很多作者自己安装过程，以及遇到的问题，非常详细。安装的差不多才发现这篇文章，感觉好迟，如果早点找到，至少安装的时刻心安一点啊。</p>

<p>OK，服务启动了，但是 dns容器 还没有正常启动。由于我们的网络组建还没有安装好啊。其实官网也有说明，但是这安装的顺序也是醉了。</p>

<p> <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p>

<h2>安装flannel</h2>

<p>参考： <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span><span class='line'>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.yml</span></code></pre></td></tr></table></div></figure>


<p>flannel启动了后，再等一阵，dns才会启动好。</p>

<h2>安装dashboard</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>现在就一台机器，得让master也能跑pods。 
</span><span class='line'>https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#master-isolation
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
</span><span class='line'>node "k8s" untainted
</span><span class='line'>
</span><span class='line'># https://lukemarsden.github.io/docs/user-guide/ui/
</span><span class='line'># 部署dashboard
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods --all-namespaces 看看dashboard的情况
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get services --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1       &lt;none&gt;        443/TCP         1h
</span><span class='line'>kube-system   kube-dns               10.96.0.10      &lt;none&gt;        53/UDP,53/TCP   1h
</span><span class='line'>kube-system   kubernetes-dashboard   10.107.103.17   &lt;none&gt;        80/TCP          9m</span></code></pre></td></tr></table></div></figure>


<p>用 <a href="https://master:6443/ui">https://master:6443/ui</a> 访问不了，可以直接用k8s的service地址访问 <a href="http://10.107.103.17/#!/overview?namespace=kube-system">http://10.107.103.17/#!/overview?namespace=kube-system</a></p>

<p>或者通过 <strong> proxy </strong> 访问UI：<a href="https://github.com/kubernetes/kubernetes/issues/44275">https://github.com/kubernetes/kubernetes/issues/44275</a></p>

<p>先运行proxy，启动代理程序：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl proxy
</span><span class='line'>Starting to serve on 127.0.0.1:8001</span></code></pre></td></tr></table></div></figure>


<p>然后访问： <a href="http://localhost:8001/ui">http://localhost:8001/ui</a></p>

<h2>所有的pods、镜像、容器</h2>

<p>基本的东西都跑起来，还是挺激动啊！！第N次安装部署K8S了啊，每次都还是得像坐过山车一样啊！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl get pods --all-namespaces -o wide
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE       IP                NODE
</span><span class='line'>kube-system   etcd-k8s                                1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-apiserver-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-controller-manager-k8s             1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-dns-2425271678-qwx9f               3/3       Running   0          9h        10.244.0.2        k8s
</span><span class='line'>kube-system   kube-flannel-ds-s5f63                   2/2       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-proxy-4pjkg                        1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-scheduler-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kubernetes-dashboard-3313488171-xl25m   1/1       Running   0          8h        10.244.0.3        k8s
</span><span class='line'>[root@k8s ~]# docker images
</span><span class='line'>REPOSITORY                                               TAG                 IMAGE ID            CREATED             SIZE
</span><span class='line'>gcr.io/google_containers/kubernetes-dashboard-amd64      v1.6.3              691a82db1ecd        35 hours ago        139 MB
</span><span class='line'>gcr.io/google_containers/kube-apiserver-amd64            v1.7.2              4935105a20b1        8 days ago          186.1 MB
</span><span class='line'>gcr.io/google_containers/kube-proxy-amd64                v1.7.2              13a7af96c7e8        8 days ago          114.7 MB
</span><span class='line'>gcr.io/google_containers/kube-controller-manager-amd64   v1.7.2              2790e95830f6        8 days ago          138 MB
</span><span class='line'>gcr.io/google_containers/kube-scheduler-amd64            v1.7.2              5db1f9874ae0        8 days ago          77.18 MB
</span><span class='line'>quay.io/coreos/flannel                                   v0.8.0-amd64        9db3bab8c19e        2 weeks ago         50.73 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-sidecar-amd64           1.14.4              38bac66034a6        4 weeks ago         41.81 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-kube-dns-amd64          1.14.4              a8e00546bcf3        4 weeks ago         49.38 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64     1.14.4              f7f45b9cb733        4 weeks ago         41.41 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                      3.0.17              243830dae7dd        5 months ago        168.9 MB
</span><span class='line'>gcr.io/google_containers/pause-amd64                     3.0                 99e59f495ffa        15 months ago       746.9 kB
</span><span class='line'>[root@k8s ~]# docker ps 
</span><span class='line'>CONTAINER ID        IMAGE                                                                                                                            COMMAND                  CREATED             STATUS              PORTS               NAMES
</span><span class='line'>631dc2cab02e        gcr.io/google_containers/kubernetes-dashboard-amd64@sha256:2c4421ed80358a0ee97b44357b6cd6dc09be6ccc27dfe9d50c9bfc39a760e5fe      "/dashboard --insecur"   7 hours ago         Up 7 hours                              k8s_kubernetes-dashboard_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
</span><span class='line'>8f5e4d044a6e        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 8 hours ago         Up 8 hours                              k8s_POD_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
</span><span class='line'>65881f9dd2dd        gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:97074c951046e37d3cbb98b82ae85ed15704a290cce66a8314e7f846404edde9           "/sidecar --v=2 --log"   9 hours ago         Up 9 hours                              k8s_sidecar_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>994c2ec99663        gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64@sha256:aeeb994acbc505eabc7415187cd9edb38cbb5364dc1c2fc748154576464b3dc2     "/dnsmasq-nanny -v=2 "   9 hours ago         Up 9 hours                              k8s_dnsmasq_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>5b181a0ed809        gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344          "/kube-dns --domain=c"   9 hours ago         Up 9 hours                              k8s_kubedns_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>a0d3f166e992        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>9cc7d6faf0b0        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/bin/sh -c 'set -e -"   9 hours ago         Up 9 hours                              k8s_install-cni_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>2f41276df8e1        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/opt/bin/flanneld --"   9 hours ago         Up 9 hours                              k8s_kube-flannel_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>bc25b0c70264        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>dc3e5641c273        gcr.io/google_containers/kube-proxy-amd64@sha256:d455480e81d60e0eff3415675278fe3daec6f56c79cd5b33a9b76548d8ab4365                "/usr/local/bin/kube-"   9 hours ago         Up 9 hours                              k8s_kube-proxy_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>6b8b9515f562        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>72418ca8e94f        gcr.io/google_containers/kube-apiserver-amd64@sha256:a9ccc205760319696d2ef0641de4478ee90fb0b75fbe6c09b1d64058c8819f97            "kube-apiserver --ser"   9 hours ago         Up 9 hours                              k8s_kube-apiserver_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
</span><span class='line'>9c9a3f5d8919        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
</span><span class='line'>43a1751ff2bb        gcr.io/google_containers/etcd-amd64@sha256:d83d3545e06fb035db8512e33bd44afb55dea007a3abd7b17742d3ac6d235940                      "etcd --listen-client"   9 hours ago         Up 9 hours                              k8s_etcd_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
</span><span class='line'>b110fff29f66        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
</span><span class='line'>66ae85500128        gcr.io/google_containers/kube-scheduler-amd64@sha256:b2e897138449e7a00508dc589b1d4b71e56498a4d949ff30eb07b1e9d665e439            "kube-scheduler --add"   9 hours ago         Up 9 hours                              k8s_kube-scheduler_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
</span><span class='line'>d4343be2f2d0        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
</span><span class='line'>9934cd83f6b3        gcr.io/google_containers/kube-controller-manager-amd64@sha256:2b268ab9017fadb006ee994f48b7222375fe860dc7bd14bf501b98f0ddc2961b   "kube-controller-mana"   9 hours ago         Up 9 hours                              k8s_kube-controller-manager_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
</span><span class='line'>acc1d7d90180        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
</span><span class='line'>[root@k8s ~]# </span></code></pre></td></tr></table></div></figure>


<h2>Woker节点部署</h2>

<p>时间，主机名，/etc/hosts，防火墙，selinux, 无密钥登录，安装docker-1.12.6就不再赘述了。</p>

<p>直接用master的yum缓冲，还有docker镜像直接拷贝：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master机器已安装httpd服务
</span><span class='line'>
</span><span class='line'>[root@k8s html]# ln -s /var/cache/yum/x86_64/7/kubernetes/packages/ k8s 
</span><span class='line'>[root@k8s k8s]# createrepo .          
</span><span class='line'>
</span><span class='line'># 把镜像全部拷到worker节点
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker save $( echo $( docker images | grep -v REPOSITORY | awk '{print $1}' ) ) | ssh worker1 docker load 
</span><span class='line'>
</span><span class='line'># 配置私有仓库源
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# vi k8s.repo
</span><span class='line'>[k8s]
</span><span class='line'>name=Kubernetes
</span><span class='line'>baseurl=http://master/k8s
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>[root@worker1 yum.repos.d]# yum list | grep k8s 
</span><span class='line'>kubeadm.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubectl.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubelet.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubernetes-cni.x86_64                      0.5.1-0                     k8s      
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# yum install -y kubelet kubeadm                          
</span><span class='line'>
</span><span class='line'># 修改cgroup-driver
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf  
</span><span class='line'>[root@worker1 yum.repos.d]# 
</span><span class='line'>[root@worker1 yum.repos.d]# service docker restart
</span><span class='line'>Redirecting to /bin/systemctl restart  docker.service
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# systemctl daemon-reload
</span><span class='line'>[root@worker1 yum.repos.d]# systemctl enable kubelet.service
</span><span class='line'>[root@worker1 yum.repos.d]# service kubelet restart
</span><span class='line'>Redirecting to /bin/systemctl restart  kubelet.service
</span><span class='line'>
</span><span class='line'># worker节点加入集群（初始化）
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443 --skip-preflight-checks
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[discovery] Trying to connect to API Server "192.168.191.138:6443"
</span><span class='line'>[discovery] Created cluster-info discovery client, requesting info from "https://192.168.191.138:6443"
</span><span class='line'>[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.191.138:6443"
</span><span class='line'>[discovery] Successfully established connection with API Server "192.168.191.138:6443"
</span><span class='line'>[bootstrap] Detected server version: v1.7.2
</span><span class='line'>[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
</span><span class='line'>[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
</span><span class='line'>[csr] Received signed certificate from the API server, generating KubeConfig...
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>
</span><span class='line'>Node join complete:
</span><span class='line'>* Certificate signing request sent to master and response
</span><span class='line'>  received.
</span><span class='line'>* Kubelet informed of new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the master to see this machine join.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get nodes
</span><span class='line'>NAME      STATUS    AGE       VERSION
</span><span class='line'>k8s       Ready     10h       v1.7.2
</span><span class='line'>worker1   Ready     57s       v1.7.2</span></code></pre></td></tr></table></div></figure>


<p>主节点运行的flannel网络组件是个 daemonset 的pod，只要加入到集群就会在每个节点上启动。不需要额外的操作。</p>

<h2>关于重启：</h2>

<p>使用RPM安装的好处是：程序系统都帮你管理了：</p>

<ul>
<li>worker节点重启后，kubelet会把所有的服务都带起来。</li>
<li>master重启后，需要等一段时间，因为pods启动有顺序/依赖：dns需要等flannel，dashboard需要等dns。</li>
</ul>


<h2>POD间连通性测试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl run hello-nginx --image=nginx --port=80
</span><span class='line'>deployment "hello-nginx" created
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS              RESTARTS   AGE
</span><span class='line'>hello-nginx-1507731416-qh3fx   0/1       ContainerCreating   0          8s
</span><span class='line'>
</span><span class='line'># 脚本启动新的dockerd并配置加速器，下载好然后save导入都本地docker实例
</span><span class='line'># https://github.com/winse/docker-hadoop/blob/master/kube-deploy/hadoop/docker-download-mirror.sh
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# ./docker-download-mirror.sh nginx 
</span><span class='line'>Using default tag: latest
</span><span class='line'>latest: Pulling from library/nginx
</span><span class='line'>
</span><span class='line'>94ed0c431eb5: Pull complete 
</span><span class='line'>9406c100a1c3: Pull complete 
</span><span class='line'>aa74daafd50c: Pull complete 
</span><span class='line'>Digest: sha256:788fa27763db6d69ad3444e8ba72f947df9e7e163bad7c1f5614f8fd27a311c3
</span><span class='line'>Status: Downloaded newer image for nginx:latest
</span><span class='line'>eb78099fbf7f: Loading layer [==================================================&gt;] 58.42 MB/58.42 MB
</span><span class='line'>29f11c413898: Loading layer [==================================================&gt;] 52.74 MB/52.74 MB
</span><span class='line'>af5bd3938f60: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>
</span><span class='line'># 拷贝镜像到其他的worker节点，就几台机器搭建register服务感觉太重了
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker save nginx | ssh worker1 docker load
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>
</span><span class='line'># 查看效果
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE
</span><span class='line'>hello-nginx-1507731416-qh3fx   1/1       Running   0          1m
</span><span class='line'>
</span><span class='line'># 扩容
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl scale --replicas=4 deployment/hello-nginx  
</span><span class='line'>deployment "hello-nginx" scaled
</span><span class='line'>[root@k8s ~]# kubectl get pods -o wide
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE       IP           NODE
</span><span class='line'>hello-nginx-1507731416-h39f0   1/1       Running   0          34s       10.244.0.6   k8s
</span><span class='line'>hello-nginx-1507731416-mnj3m   1/1       Running   0          34s       10.244.1.3   worker1
</span><span class='line'>hello-nginx-1507731416-nsdr2   1/1       Running   0          34s       10.244.0.7   k8s
</span><span class='line'>hello-nginx-1507731416-qh3fx   1/1       Running   0          5m        10.244.1.2   worker1
</span><span class='line'>[root@k8s ~]# kubectl delete deployment hello-nginx
</span><span class='line'>
</span><span class='line'>这容器太简洁了，PING都没有啊！！搞个熟悉的linux版本，再跑一遍
</span><span class='line'>
</span><span class='line'>kubectl run centos --image=centos:centos6 --command -- vi 
</span><span class='line'>kubectl scale --replicas=4 deployment/centos
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods  -o wide 
</span><span class='line'>NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
</span><span class='line'>centos-3024873821-4490r   1/1       Running   0          49s       10.244.1.6    worker1
</span><span class='line'>centos-3024873821-k74gn   1/1       Running   0          11s       10.244.0.11   k8s
</span><span class='line'>centos-3024873821-l27xs   1/1       Running   0          11s       10.244.0.10   k8s
</span><span class='line'>centos-3024873821-pbg52   1/1       Running   0          11s       10.244.1.7    worker1
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl exec -ti centos-3024873821-4490r bash
</span><span class='line'>[root@centos-3024873821-4490r /]# yum install -y iputils
</span><span class='line'>[root@centos-3024873821-4490r /]# ping 10.244.0.11 -c 1
</span><span class='line'>
</span><span class='line'>以上IP都是互通的，从master节点PING这些IP也是通的。
</span><span class='line'>
</span><span class='line'># 查看pod状态的命令
</span><span class='line'>kubectl -n ${NAMESPACE} describe pod ${POD_NAME}
</span><span class='line'>kubectl -n ${NAMESPACE} logs ${POD_NAME} -c ${CONTAINER_NAME}</span></code></pre></td></tr></table></div></figure>


<h2>源IP问题</h2>

<p>原来部署hadoop的时刻，已经遇到过了。知道根源所在，但是这次使用的cni（直接改 <code>dockerd --ip-masq=false</code> 配置仅修改的是docker0）。</p>

<p>先来重现下源ip问题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./pod_bash centos-3024873821-t3k3r 
</span><span class='line'>
</span><span class='line'>yum install epel-release -y ; yum install nginx -y ;
</span><span class='line'>service nginx start
</span><span class='line'>
</span><span class='line'>ifconfig
</span><span class='line'>
</span><span class='line'># nginx安装后，访问查看access_log
</span><span class='line'>
</span><span class='line'>less /var/log/nginx/access.log 
</span></code></pre></td></tr></table></div></figure>


<p>在 kube-flannel.yml 中添加 cni-conf.json 网络配置为 <code>"ipMasq": false,</code>，没啥效果，在iptables上面还是有cni的cbr0的MASQUERADE（SNAT）。</p>

<p>注意：重启后，发现一切都正常了。可能是通过apply修改的，没有生效！在配置flannel之前就修改属性应该就ok了！！后面的可以不要看了，方法还比较挫。</p>

<p>用比较极端点的方式，删掉docker0，替换成cni0。 <a href="https://kubernetes.io/docs/getting-started-guides/scratch/#docker">https://kubernetes.io/docs/getting-started-guides/scratch/#docker</a></p>

<p>把docker的网卡设置成cni0(flannel会创建cni0的网卡) :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 清空原来的策略
</span><span class='line'>iptables -t nat -F
</span><span class='line'>ip link set docker0 down
</span><span class='line'>ip link delete docker0
</span><span class='line'>
</span><span class='line'>[root@worker1 ~]# cat /usr/lib/systemd/system/docker.service  | grep dockerd
</span><span class='line'>ExecStart=/usr/bin/dockerd --bridge=cni0 --ip-masq=false 
</span></code></pre></td></tr></table></div></figure>


<p>但是机器重启后cni0这个网卡设备就没有了，导致机器重启后docker启动失败！（cni-conf.json的&#8221;ipMasq&#8221;: false是有效果的，但是好像得是新建的网卡设备才行！）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; Aug 01 08:36:10 k8s dockerd[943]: time="2017-08-01T08:36:10.017266292+08:00" level=fatal msg="Error starting daemon: Error initializing network controller: Error creating default \"bridge\" network: bridge device with non default name cni0 must be created manually"
</span><span class='line'>
</span><span class='line'>ip link add name cni0 type bridge
</span><span class='line'>ip link set dev cni0 mtu 1460
</span><span class='line'># 让flannel来设置IP地址
</span><span class='line'># ip addr add $NODE_X_BRIDGE_ADDR dev cni0
</span><span class='line'>ip link set dev cni0 up
</span><span class='line'>
</span><span class='line'>systemctl restart docker kubelet
</span></code></pre></td></tr></table></div></figure>


<p>另一种网络部署方式 kubenet + hostroutes ： <a href="https://jishu.io/kubernetes/deploy-production-ready-kubernetes-cluster-on-aliyun/">https://jishu.io/kubernetes/deploy-production-ready-kubernetes-cluster-on-aliyun/</a></p>

<h2>DNS</h2>

<p><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># cat busybox.yaml
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  namespace: default
</span><span class='line'>spec:
</span><span class='line'>  containers:
</span><span class='line'>  - image: busybox
</span><span class='line'>    command:
</span><span class='line'>      - sleep
</span><span class='line'>      - "3600"
</span><span class='line'>    imagePullPolicy: IfNotPresent
</span><span class='line'>    name: busybox
</span><span class='line'>  restartPolicy: Always
</span><span class='line'>
</span><span class='line'>kubectl create -f busybox.yaml
</span><span class='line'>kubectl exec -ti busybox -- nslookup kubernetes.default
</span><span class='line'>kubectl exec busybox cat /etc/resolv.conf
</span></code></pre></td></tr></table></div></figure>


<h2>DNS问题</h2>

<p>在master节点上的POD容器内访问DNS（service）服务，但是返回数据却是域名服务内部POD的IP，而不是Service服务的IP地址。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl describe services kube-dns -n kube-system
</span><span class='line'>Name:                   kube-dns
</span><span class='line'>Namespace:              kube-system
</span><span class='line'>Labels:                 k8s-app=kube-dns
</span><span class='line'>                        kubernetes.io/cluster-service=true
</span><span class='line'>                        kubernetes.io/name=KubeDNS
</span><span class='line'>Annotations:            &lt;none&gt;
</span><span class='line'>Selector:               k8s-app=kube-dns
</span><span class='line'>Type:                   ClusterIP
</span><span class='line'>IP:                     10.96.0.10
</span><span class='line'>Port:                   dns     53/UDP
</span><span class='line'>Endpoints:              10.244.0.30:53
</span><span class='line'>Port:                   dns-tcp 53/TCP
</span><span class='line'>Endpoints:              10.244.0.30:53
</span><span class='line'>Session Affinity:       None
</span><span class='line'>Events:                 &lt;none&gt;
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl exec -ti centos-3024873821-b6d48 -- nslookup kubernetes.default
</span><span class='line'>;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</span><span class='line'>;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</span></code></pre></td></tr></table></div></figure>


<h4>相关问题的一些资源：</h4>

<ul>
<li>*<a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">kubernetes pods replying with unexpected source for DNS queries</a></li>
<li><a href="https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477">https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477</a></li>
<li><p><a href="https://github.com/coreos/coreos-kubernetes/issues/572">cni plugin + flannel on v1.3: pods can&rsquo;t route to service IPs</a></p></li>
<li><p><a href="https://www.slideshare.net/kubecon/container-network-interface-network-plugins-for-kubernetes-and-beyond">Container Network Interface: Network Plugins for Kubernetes and beyond</a></p></li>
<li><a href="http://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/">Understanding CNI (Container Networking Interface)</a></li>
<li><a href="https://feisky.gitbooks.io/kubernetes/network/flannel/">Kubernetes指南 - flannel</a></li>
<li>Pod to external traffic is not masqueraded <a href="https://github.com/kubernetes/kubernetes/issues/40761">https://github.com/kubernetes/kubernetes/issues/40761</a></li>
</ul>


<h4>解决方法：</h4>

<p><strong> kube-proxy加上 &ndash;masquerade-all 解决了。</strong></p>

<h4>处理方法：</h4>

<blockquote><p><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a>
kubeadm installs add-on components via the API server. Right now this is the internal DNS server and the kube-proxy DaemonSet.</p></blockquote>

<p>修改有技巧，正如官网文档所说：kube-proxy是内部容器启动的。没找到yaml配置，不能直接改配置文件，这里有如下两种方式修改：</p>

<ul>
<li>通过Dashboard页面的编辑对配置进行修改</li>
<li>通过edit命令对配置进行修改：<code>kubectl edit daemonset kube-proxy -n=kube-system</code> 命令添加 <code>- --masquerade-all</code></li>
</ul>


<h2>Heapster</h2>

<p>参考</p>

<ul>
<li><a href="https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md">https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md</a></li>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/">https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# git clone https://github.com/kubernetes/heapster.git
</span><span class='line'>Cloning into 'heapster'...
</span><span class='line'>remote: Counting objects: 26084, done.
</span><span class='line'>remote: Total 26084 (delta 0), reused 0 (delta 0), pack-reused 26084
</span><span class='line'>Receiving objects: 100% (26084/26084), 36.33 MiB | 2.66 MiB/s, done.
</span><span class='line'>Resolving deltas: 100% (13084/13084), done.
</span><span class='line'>Checking out files: 100% (2531/2531), done.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# cd heapster/
</span><span class='line'>[root@k8s heapster]# kubectl create -f deploy/kube-config/influxdb/
</span><span class='line'>deployment "monitoring-grafana" created
</span><span class='line'>service "monitoring-grafana" created
</span><span class='line'>serviceaccount "heapster" created
</span><span class='line'>deployment "heapster" created
</span><span class='line'>service "heapster" created
</span><span class='line'>deployment "monitoring-influxdb" created
</span><span class='line'>service "monitoring-influxdb" created
</span><span class='line'>[root@k8s heapster]# kubectl create -f deploy/kube-config/rbac/heapster-rbac.yaml 
</span><span class='line'>clusterrolebinding "heapster" created
</span></code></pre></td></tr></table></div></figure>


<p>其他资源：</p>

<ul>
<li><a href="http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/">http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/</a></li>
<li><a href="http://www.pangxie.space/docker/727">http://www.pangxie.space/docker/727</a></li>
<li><a href="http://jerrymin.blog.51cto.com/3002256/1904460">http://jerrymin.blog.51cto.com/3002256/1904460</a></li>
<li><a href="http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer</a></li>
</ul>


<p>DNS的问题耗了比较多的时间。弄好了DNS后，以及heapster的docker镜像的下载都OK的话，就万事俱备了。最后重新启动下dashboard就行了：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl delete -f kubernetes-dashboard.yaml 
</span><span class='line'>[root@k8s ~]# kubectl create -f kubernetes-dashboard.yaml 
</span></code></pre></td></tr></table></div></figure>


<p>然后就可以在dashboard上看到美美的曲线图了。</p>

<h2>harbor</h2>

<p>参考 <a href="https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md">https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md</a></p>

<p>日新月异啊，1.1.2版本了！！ 用迅雷直接下载 <a href="https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz">https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz</a>  这个地址。</p>

<p>操作方式还是和原来的版本一样。也就是说可以用原来简化的脚本来安装！</p>

<p>搭建好了后，会基本的使用就差不多了。测试环境资源有限，并且其实用save和load也能解决（咔咔）。</p>

<h2>livenessProbe - Nexus的无响应处理</h2>

<p>在 <a href="https://github.com/winse/docker-hadoop/blob/master/kube-deploy/nexus-rc.yaml">github仓库</a> 上有一份开发环境的NEXUS的启动脚本，从一开始的单pods，改成replicationcontroller。觉得万事大吉了。</p>

<p>但，现在又出现一个问题，就是容器还在，但是8081不提供服务了。这很尴尬，其他开发人员说nexus又不能访问了，我想不对，不是已经改成rc了么，容器应该不会挂才对啊。上环境一看，容器是在，但是服务是真没响应。</p>

<p>怎么办？</p>

<p>搞定时任务，觉得有点low。后面想如果判断一下服务不能访问了就重启，其实k8s已经想到了这一点了，提供了<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-a-liveness-http-request">存活探针livenessProbe</a> 。直接按照官网给的http的例子写就行了。等过几天看效果。</p>

<h2>参考</h2>

<p>官方的一些资源</p>

<ul>
<li><a href="https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy">https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></li>
<li><a href="https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/">https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection">https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#environment-variables">https://kubernetes.io/docs/admin/kubeadm/#environment-variables</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/</a> 怎么升级，以及如何制定特定的k8s版本</li>
</ul>


<p>使用kubeadm安装集群</p>

<ul>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/</a> 参考</li>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/</a>  weave net网络</li>
<li><a href="https://www.kubernetes.org.cn/1165.html">https://www.kubernetes.org.cn/1165.html</a> 就是上面第一篇，但是排版看起来跟舒服点</li>
<li><a href="http://hairtaildai.com/blog/11">http://hairtaildai.com/blog/11</a> 安装似乎太顺利了，都没有遇到啥问题？</li>
<li><a href="https://my.oschina.net/xdatk/blog/895645">https://my.oschina.net/xdatk/blog/895645</a> 这篇不推荐，太繁琐了。很多贴的是内容，不知道改过啥！</li>
</ul>


<p>DNS问题参考</p>

<ul>
<li><a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries</a></li>
<li><a href="https://kubernetes.io/docs/admin/kube-proxy/">https://kubernetes.io/docs/admin/kube-proxy/</a></li>
<li><p><a href="https://docs.docker.com/engine/admin/systemd/#httphttps-proxy">https://docs.docker.com/engine/admin/systemd/#httphttps-proxy</a></p></li>
<li><p><a href="https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html">https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html</a> 命令行编辑的方法在这里看到的</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/34101">https://github.com/kubernetes/kubernetes/issues/34101</a>
Ok, so it turns out that this flag is not enough, we still have an issue reaching kubernetes service IP. The simplest solution to this is to run kube-proxy with &ndash;proxy-mode=userspace. To enable this, you can use kubectl -n kube-system edit ds kube-proxy-amd64 &amp;&amp; kubectl -n kube-system delete pods -l name=kube-proxy-amd64.</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/36835">https://github.com/kubernetes/kubernetes/issues/36835</a> To enable off-cluster bridging when &ndash;proxy-mode=iptables, also set &ndash;cluster-cidr.</p></li>
<li><a href="https://github.com/kubernetes/kubeadm/issues/102">https://github.com/kubernetes/kubeadm/issues/102</a> proxy: clusterCIDR not specified, unable to distinguish between internal and external traffic</li>
</ul>


<p>其他一些资源</p>

<ul>
<li><a href="https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md">https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md</a></li>
<li><p><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/</a></p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/">https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/</a> Replication Controllers</p></li>
<li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy</a> RestartPolicy</li>
</ul>


<p>&mdash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[转]一致性Hash]]></title>
    <link href="http://winseliu.com/blog/2017/07/16/consistent-hashing/"/>
    <updated>2017-07-16T01:03:51+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/16/consistent-hashing</id>
    <content type="html"><![CDATA[<p><a href="http://gywbd.github.io/posts/2016/10/consistent-hashing.html">一致性哈希</a></p>

<p>图文并茂，写的非常好。</p>

<p>要点：</p>

<ol>
<li>解决Hash的随机分布带来的增删节点的需重新全部映射的问题：对主机使用同样的函数把主机A分布到环上（其实就是分配一段范围），然后在Hash后在这段范围内的数据全部存储到主机A上。这样增删节点只需要对部分数据重新映射。</li>
</ol>


<p><img src="http://gywbd.github.io/images/ch1.png" alt="" /></p>

<p><img src="http://gywbd.github.io/images/ch8.png" alt="" /></p>

<p><img src="http://gywbd.github.io/images/ch10.png" alt="" /></p>

<ol>
<li>由此又引入了一个优化的点。（随机在环上放置节点）机器硬件不同，能力不同，以及数据分布均衡（热点机器）等的问题。所以，虚拟节点就是用来节点这个问题的。每个节点可以指定分配的虚拟节点数。</li>
</ol>


<p><img src="http://gywbd.github.io/images/ch13.png" alt="" /></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[togo简单的RPM打包工具]]></title>
    <link href="http://winseliu.com/blog/2017/07/15/togo-another-rpmbuild-tool/"/>
    <updated>2017-07-15T15:09:52+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/15/togo-another-rpmbuild-tool</id>
    <content type="html"><![CDATA[<p>源码： <a href="https://github.com/genereese/togo">https://github.com/genereese/togo</a></p>

<h2>安装</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install https://github.com/genereese/togo/releases/download/v2.3r7/togo-2.3-7.noarch.rpm</span></code></pre></td></tr></table></div></figure>


<h2>实际案例使用</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 创建类似rpmbuild的骨架
</span><span class='line'>togo project create my-new-rpm; cd my-new-rpm
</span><span class='line'>
</span><span class='line'># 内容准备
</span><span class='line'>mkdir -p root/usr/local/bin; touch root/usr/local/bin/exmaple.sh
</span><span class='line'>chmod +x root/usr/local/bin/exmaple.sh
</span><span class='line'>
</span><span class='line'># 排除目录、文件
</span><span class='line'>togo file exclude root/usr/local/bin
</span><span class='line'>  Removed '/usr/local/bin' from project ownership.
</span><span class='line'>  Removed '/usr/local' from project ownership.
</span><span class='line'>  Removed '/usr' from project ownership.
</span><span class='line'>
</span><span class='line'># 修改属性，如第二次重新打包就需要修改下release
</span><span class='line'>vi spec/header
</span><span class='line'>
</span><span class='line'># 编译打包
</span><span class='line'>togo build package</span></code></pre></td></tr></table></div></figure>


<h2>成果</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ll rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 2236 Jul 14 12:17 rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>$ rpm -qpl rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>/usr/local/bin/exmaple.sh
</span></code></pre></td></tr></table></div></figure>


<p>打出来的就是第一个标准的rpm包，然后就可以按照rpm包的方式进行处理了：直接安装、或者使用createrepo来制作本地仓库等等。</p>

<p>用来简单打包文件还是挺方便的。相当于把骨架都搭建好了，然后还提供了一些方便的命令来进行维护修改。</p>

<p>还有一个 <a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Helpful_tools">rpmdevtools</a> 也是一个创建编译项目的脚手架，只不过这仅仅是对<a href="https://fedoraproject.org/wiki/Archive:BuildingPackagesGuide?rd=Docs/Drafts/BuildingPackagesGuide#Creating_a_New_Package">rpmbuild方式</a>的辅助。更多的还是需要自己精心的维护spec。</p>

<p>还有提到的 <a href="https://github.com/alanfranz/docker-rpm-builder">docker-rpm-builder</a> 需要centos7。如果要打那种N个环境的rpm包，才能体现出它的优势吧。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[爬虫之CasperJS]]></title>
    <link href="http://winseliu.com/blog/2017/07/08/casperjs-crawler/"/>
    <updated>2017-07-08T15:56:06+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/08/casperjs-crawler</id>
    <content type="html"><![CDATA[<p>用jsoup(java, scala, groovy)爬过数据，用cheerio(nodejs)爬过数据，每次爬取都要对页面HTML结构，数据来源URL进行研究。还要对网站的反扒做一些HEADER的设置。各种繁琐，主要还有一些数据型的网站验证复杂，很难通过简单的方式来破解它的那套反扒流程。</p>

<p><a href="http://docs.casperjs.org/en/latest/modules/casper.html">CasperJS</a>是在<a href="http://phantomjs.org/quick-start.html">phantomjs</a>基础上的一套工具库用来简化phantomjs的操作，降低使用和入门的门槛。而PhantomJS是类似浏览器的一个工具（headless browsers），你可以把它看做浏览器。所以可以通过CasperJS来操作浏览器访问地址，然后加载完页面后再提取数据，这样就不要考虑被反扒的风险，并且获取数据的方式相对容易和简单。</p>

<h2>先从官网的案例体验下HelloWorld以及如何调试</h2>

<p>下载最新的<a href="http://docs.casperjs.org/en/latest/installation.html#installing-from-npm">CasperJS（npm install）</a>即可，PhantomJS下载<a href="https://bitbucket.org/ariya/phantomjs/downloads/">1.9.8</a>版本，不推荐2+版本，有些功能有问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>R:\test&gt;set PATH=C:\Users\winse\AppData\Roaming\npm\node_modules\casperjs\bin;E:\phantomjs-1.9.8-windows;%PATH
</span><span class='line'>
</span><span class='line'>R:\test&gt;cat hello.js
</span><span class='line'>var casper = require('casper').create();
</span><span class='line'>// debugger
</span><span class='line'>
</span><span class='line'>casper.start('http://casperjs.org/', function() {
</span><span class='line'>    this.echo(this.getTitle());
</span><span class='line'>    
</span><span class='line'>    this.echo("Star: " + this.evaluate(function () { 
</span><span class='line'>        return $(".octicon-star").parent().text().trim()
</span><span class='line'>    }) )
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.thenOpen('http://phantomjs.org', function() {
</span><span class='line'>    this.echo(this.getTitle());
</span><span class='line'>    
</span><span class='line'>    this.echo("Intro: " + this.evaluate(function () { 
</span><span class='line'>        return $(".intro h1").innerHTML
</span><span class='line'>        // return document.querySelector(".intro h1").innerHTML
</span><span class='line'>    }) )
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run();
</span><span class='line'>
</span><span class='line'>R:\test&gt;casperjs  hello.js
</span><span class='line'>CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
</span><span class='line'>Star: 6,337 Stargazers
</span><span class='line'>PhantomJS | PhantomJS
</span><span class='line'>Intro: null</span></code></pre></td></tr></table></div></figure>


<p>用js的方式来获取页面数据，非常完美，相比直接通过URL请求来获取数据，CasperJS就是慢了点（有点像我们每次都打开浏览器然后再访问，可以通过建立服务，然后在常驻PhantomJS访问页面）。</p>

<p>上面第二次获取的数据不是我们想要的，这里我们通过调试看看到底是什么原因导致的。在start前增加一行 <code>debugger</code> 。然后执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>casperjs hello.js --verbose --log-level=debug --remote-debugger-port=9000</span></code></pre></td></tr></table></div></figure>


<p>打开浏览器方式 localhost:9000 点击 <strong>about:blank</strong> 链接，然后在Console窗口执行 <code>__run()</code> ，等一下下会停在debugger那一行，再然后就是愉快的debug就好了。</p>

<p>在 <a href="http://phantomjs.org">http://phantomjs.org</a> 那一段的evaluate代码处增加一个断点，运行到该断点后，再次打开 localhost:9000 会多出一个当前访问页面的链接，点击进去就像平时F12看到的调式窗口了。</p>

<ul>
<li><a href="http://phantomjs.org/troubleshooting.html#remote-debugging">http://phantomjs.org/troubleshooting.html#remote-debugging</a></li>
<li><a href="https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs">https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs</a></li>
<li><a href="https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper">https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper</a></li>
<li><a href="https://github.com/ariya/phantomjs/issues/12064">https://github.com/ariya/phantomjs/issues/12064</a></li>
</ul>


<p>注意: <a href="https://www.portablesoft.org/google-chrome-legacy-versions/">Chrome浏览器要用V54版本以下</a> 的。</p>

<p>调试详情如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; $(".intro h1")
</span><span class='line'>null
</span><span class='line'>&gt; $
</span><span class='line'>bound: function () {
</span><span class='line'>        return document.getElementById.apply(document, arguments);
</span><span class='line'>    }
</span><span class='line'>&gt; document.querySelector(".intro h1").innerHTML
</span><span class='line'>"
</span><span class='line'>        Full web stack&lt;br&gt;
</span><span class='line'>        No browser required
</span><span class='line'>      "</span></code></pre></td></tr></table></div></figure>


<p>那我们把js脚本修改成querySelector来获取数据。再次执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>R:\test&gt;casperjs  hello.js
</span><span class='line'>CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
</span><span class='line'>Star: 6,337 Stargazers
</span><span class='line'>PhantomJS | PhantomJS
</span><span class='line'>Intro:
</span><span class='line'>        Full web stack&lt;br&gt;
</span><span class='line'>        No browser required</span></code></pre></td></tr></table></div></figure>


<h2>功能特性</h2>

<ul>
<li>截图</li>
</ul>


<p>有现成的方法，但是需要自己<a href="https://uggedal.com/journal/phantomjs-default-background-color/">处理下背景颜色</a> <a href="http://phantomjs.org/tips-and-tricks.html">Tips and Tricks</a>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cat capture.js
</span><span class='line'>var casper = require('casper').create({
</span><span class='line'>    waitTimeout: 120000,
</span><span class='line'>    logLevel: "debug",
</span><span class='line'>    verbose: true
</span><span class='line'>});
</span><span class='line'>casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')
</span><span class='line'>
</span><span class='line'>casper.start('https://xueqiu.com/2054435398/32283614', function () {
</span><span class='line'>    this.waitForSelector("div.status-content a[title*=xueqiu]");
</span><span class='line'>}).then(function () {
</span><span class='line'>    // white background
</span><span class='line'>    this.evaluate(function () {
</span><span class='line'>        var style = document.createElement('style'),
</span><span class='line'>            text = document.createTextNode('body { background: #fff }');
</span><span class='line'>        style.setAttribute('type', 'text/css');
</span><span class='line'>        style.appendChild(text);
</span><span class='line'>        document.head.insertBefore(style, document.head.firstChild);
</span><span class='line'>    });
</span><span class='line'>}).then(function () {
</span><span class='line'>    this.capture('结庐问山.jpg');
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run()
</span><span class='line'>
</span><span class='line'>&gt; casperjs capture.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk</span></code></pre></td></tr></table></div></figure>


<p>用来截全屏的图片相当厉害，Chrome等自带的截图工具如果内容长了后很慢很麻烦，这种方式毫无压力啊。</p>

<ul>
<li>抓取层次页面</li>
</ul>


<p>一般抓数据有个列表页，然后根据列表页的详情地址，根据详情地址再获取数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cat xueqiu.js
</span><span class='line'>debugger
</span><span class='line'>
</span><span class='line'>var fs = require('fs');
</span><span class='line'>var casper = require('casper').create({
</span><span class='line'>    waitTimeout: 120000,
</span><span class='line'>    logLevel: "debug",
</span><span class='line'>    verbose: true
</span><span class='line'>});
</span><span class='line'>casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')
</span><span class='line'>
</span><span class='line'>var links = []
</span><span class='line'>var basedir = '.'
</span><span class='line'>casper.start('https://xueqiu.com/2054435398/32283614', function () {
</span><span class='line'>    this.waitForSelector("div.status-content a[title*=xueqiu]");
</span><span class='line'>}).then(function () {
</span><span class='line'>    var items = this.evaluate(function () {
</span><span class='line'>        return $("div.status-content a[title*=xueqiu]").map(function (i, a) {
</span><span class='line'>            return $(a).attr('href')
</span><span class='line'>        })
</span><span class='line'>    })
</span><span class='line'>
</span><span class='line'>    for (var i = 0; i &lt; items.length; i++) {
</span><span class='line'>        links.push(items[i]);
</span><span class='line'>    }
</span><span class='line'>    
</span><span class='line'>    fs.write('all.html', this.getHTML(), 'w');
</span><span class='line'>}).then(function () {
</span><span class='line'>    this.eachThen(links, function (link) {
</span><span class='line'>        var pathname = undefined;
</span><span class='line'>        var url = link.data;
</span><span class='line'>
</span><span class='line'>        this.thenOpen(url, function () {
</span><span class='line'>            this.waitForSelector("div.status-content .detail");
</span><span class='line'>        }).then(function () {
</span><span class='line'>            pathname = this.evaluate(function () {
</span><span class='line'>                var style = document.createElement('style'),
</span><span class='line'>                    text = document.createTextNode('body { background: #fff }');
</span><span class='line'>                style.setAttribute('type', 'text/css');
</span><span class='line'>                style.appendChild(text);
</span><span class='line'>                document.head.insertBefore(style, document.head.firstChild);
</span><span class='line'>
</span><span class='line'>                return window.location.pathname;
</span><span class='line'>            });
</span><span class='line'>        }).then(function () {
</span><span class='line'>            if (url.indexOf(pathname))
</span><span class='line'>                this.capture(basedir + pathname + ".jpg");
</span><span class='line'>            else
</span><span class='line'>                this.echo(url);
</span><span class='line'>        });
</span><span class='line'>
</span><span class='line'>    })
</span><span class='line'>
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run()
</span><span class='line'>
</span><span class='line'>&gt; casperjs xueqiu.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk --remote-debugger-port=9000
</span></code></pre></td></tr></table></div></figure>


<p>然后一堆堆的图片就生成出来了。由于访问的速度有限，有利有弊，慢一点还不要做时间上面的控制了，有点像人在操作的感觉。然后处理下异常的个别再导一次就可以了(错误的那一篇还是404的&hellip;哭笑)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$("div.status-content a[title*=xueqiu]").map(function(i, a){ return $(a).attr('href') }).length
</span><span class='line'>177
</span><span class='line'>
</span><span class='line'>$ find . -name '*.jpg' | wc -l
</span><span class='line'>176</span></code></pre></td></tr></table></div></figure>


<p>注意：Windows的命令窗口，多按几次Enter，有时一不小心就进入编辑模式了。</p>

<p>压缩后100多M啊！CasperJS足够强大，更多的模式等待你的开启。就写到此。</p>

<h2>后记</h2>

<p>关于爬虫获取数据 <a href="http://webmagic.io/docs/zh/posts/chx-cases/js-render-page.html">抓取前端渲染的页面</a> 这篇文章讲的挺中肯的，如果可能的话，用作者写的 <a href="https://github.com/code4craft/webmagic/blob/master/README-zh.md">WebMagic</a> 也是一个不错的选择。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[导出微信照片]]></title>
    <link href="http://winseliu.com/blog/2017/06/04/wechat-images-export/"/>
    <updated>2017-06-04T14:53:51+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/04/wechat-images-export</id>
    <content type="html"><![CDATA[<p>开篇寄语：还是脚本厉害啊！</p>

<p>手机空间不够，又不能加卡，只能删删删。想着把手机上的照片拷贝出来啊，手机拍的，在DCIM目录下的还好，但是微信里面的照片我也想备份下来啊。怎么办？</p>

<p>手机上翻一张微信的照片，然后目录在： tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 ，连上电脑一看蒙圈了，这尼玛36(10+26)的平方啊，直接复制完全没反应，在系统上面通过查找*.jpg也不靠谱。还有尼玛的，不是挂在到系统盘的，没办法用脚本。</p>

<p>想着，要不用个助手试试，下载了PP和豌豆荚，导出带反应的都没有啊！你们这程序怎么做的啊！老牌子啊！！！</p>

<p>没办法咯，一个个复制想死的心都有了。最后实在没的办法，用adb shell来整把，然后就一个命令就搞定了（苦笑）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>shell@hydrogen:/sdcard/tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 $ which find
</span><span class='line'>/system/bin/find
</span><span class='line'>shell@hydrogen:/sdcard/tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 $
</span><span class='line'>$ find . -name "*.*" -exec cp {} /sdcard/Download/ \; </span></code></pre></td></tr></table></div></figure>


<p>最后拷贝download文件夹就好了。</p>

<p>总共600M的样子。拷贝的时刻，又TMD没权限，在explorer窗口就看不到文件。好吧，再用命令拷贝一下吧：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\adt-bundle-windows-x86-20140702\platform-tools&gt;adb pull -a /sdcard/Download/ R:\image2\
</span><span class='line'>[ 14%] /sdcard/Download/9d01c6e9b722366970f33c948ca4435f.jpg: 76%</span></code></pre></td></tr></table></div></figure>


<p>好久没弄了，SDK还是14年的，不过还能用啊，赫赫。到此，备份微信图片的工作顺利完成，事情一桩一桩的了。</p>

<p>啥，最后你说还要删掉刚刚复制的图片啊，不能一个个的删啊，好吧，收下我&ndash;|的眼神：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\adt-bundle-windows-x86-20140702\platform-tools&gt;adb shell
</span><span class='line'>shell@hydrogen:/ $ cd /sdcard/Download/
</span><span class='line'>shell@hydrogen:/sdcard/Download $ rm -rf *.jpg
</span><span class='line'>shell@hydrogen:/sdcard/Download $ rm -rf *.png</span></code></pre></td></tr></table></div></figure>


<p>拷贝完后，翻了一翻挺有回忆的。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
