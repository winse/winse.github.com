<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2017-09-20T01:48:25+00:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用U盘安装Centos7]]></title>
    <link href="http://winseliu.com/blog/2017/09/19/os-install-via-usb/"/>
    <updated>2017-09-19T14:26:30+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/19/os-install-via-usb</id>
    <content type="html"><![CDATA[<p>使用U盘安装操作系统，原来一直用 unetbootin-windows 但这次不好使，U盘重新格式化也不行。遇到的几个问题：</p>

<ol>
<li>有光驱最好啊，没光驱才用U盘安装啊！</li>
<li>U盘是否能被识别？安装系统嘛，你的屈就电脑，它不识别你就只能换另一个咯。旧的服务器识别USB3.0有问题。</li>
<li>进BIOS看启动项是否有你的U盘？把U盘的顺序调整到HDD的前面。与第二项是一起的检测的。</li>
<li>做的系统是否正确？下载<a href="http://isoredirect.centos.org/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1708.iso">Minimal.iso</a>，用<a href="https://wiki.centos.org/zh/HowTos/InstallFromUSBkey">采用 Windows iso2usb</a> 把iso载入到U盘。</li>
</ol>


<p>注意1： 看到 ntldr is missing 这样的提示，就可以去再重写一遍U盘了！</p>

<p>注意2： U盘必须是FAT32的！！</p>

<p>安装系统的时刻，问题又来了：</p>

<ul>
<li>dracut_initqueue[599]: Warning: Could not boot</li>
</ul>


<p>找不到镜像。</p>

<p>处理： <strong> 等一段时间后会进行入到 Dracut shell </strong>, 查看下 /dev 下面有哪些磁盘设备。<strong> 最大/后的那个磁盘设备 </strong> 一般就是你的U盘。如我的是 /dev/sdc1 。</p>

<p>CTRL+ALT+DELETE 重新启动，进入CENTOS安装界面启动选项时，按TAB，替换为如下内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vmlinux initrd=initrd.img
</span><span class='line'>inst.stage2=hd:/dev/sdc1 quit</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://m.blog.csdn.net/w_z_z_1991/article/details/41909851">http://m.blog.csdn.net/w_z_z_1991/article/details/41909851</a></li>
<li><a href="http://www.jianshu.com/p/e3cd90c540c3">http://www.jianshu.com/p/e3cd90c540c3</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redmine部署以及插件安装]]></title>
    <link href="http://winseliu.com/blog/2017/09/18/redmine-deploy-and-install-plugins/"/>
    <updated>2017-09-18T15:46:24+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/18/redmine-deploy-and-install-plugins</id>
    <content type="html"><![CDATA[<p>Redmine是类似JIRA的一个项目/BUG管理工具，使用ruby语言编写的。安装相对就麻烦一点，不熟嘛，一堆的东西要安装。有两种简单/傻瓜式的安装方式：</p>

<ul>
<li>bitnami-redmine，相当于一键安装；</li>
<li>docker + redmine，使用docker把所有的依赖都安装好，只需要配置remine即可。</li>
</ul>


<p>这里选择使用docker-compose来安装 <a href="https://github.com/sameersbn/docker-redmine">sameersbn/redmine:3.4.2</a></p>

<h2>部署</h2>

<p>先跑起来，然后再根据需求修改配置。搞得不好的话，重新安装也超级简单，是吧！</p>

<ul>
<li><a href="https://github.com/sameersbn/docker-redmine#quick-start">https://github.com/sameersbn/docker-redmine#quick-start</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir -p /srv/docker/redmine/{redmine,postgresql}
</span><span class='line'>
</span><span class='line'>wget https://raw.githubusercontent.com/sameersbn/docker-redmine/master/docker-compose.yml
</span><span class='line'>docker-compose up
</span></code></pre></td></tr></table></div></figure>


<p>启动后，浏览器访问 <a href="http://HOSTED_IP:10083">http://HOSTED_IP:10083</a> ，使用 admin/admin 登录。</p>

<ul>
<li>重新弄，初始化：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker-compose rm -f 或者 docker-compose down
</span><span class='line'>
</span><span class='line'>rm -rf /srv/docker/redmine/redmine/tmp/*
</span><span class='line'>rm -rf /srv/docker/redmine/postgresql/* 
</span><span class='line'>
</span><span class='line'>docker-compose up --build
</span></code></pre></td></tr></table></div></figure>


<h2>Theme主题</h2>

<ul>
<li><a href="https://github.com/sameersbn/docker-redmine#themes">https://github.com/sameersbn/docker-redmine#themes</a></li>
<li><a href="http://www.redmine.org/projects/redmine/wiki/Themes">http://www.redmine.org/projects/redmine/wiki/Themes</a></li>
<li><a href="https://www.redmineup.com/pages/themes/a1">https://www.redmineup.com/pages/themes/a1</a></li>
</ul>


<p>改头换面，下载主题后放到 /srv/docker/redmine/redmine/themes/ 目录下。然后 <strong> 重启容器 </strong>，再重新登录，修改 <strong> 管理 - 配置 - 显示 - 主题 - A1 </strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s redmine]# ll /srv/docker/redmine/redmine/themes/
</span><span class='line'>total 0
</span><span class='line'>drwxr-xr-x. 6 es es 69 Sep 18 23:38 a1
</span></code></pre></td></tr></table></div></figure>


<h2>Plugins</h2>

<p>有些插件不兼容3.4，注意版本的选择！一下是在3.4下面安装使用的插件：</p>

<ul>
<li><a href="http://www.redmine.org/projects/redmine/wiki/Plugins">http://www.redmine.org/projects/redmine/wiki/Plugins</a></li>
<li><a href="http://www.redmine.org/plugins/clipboard_image_paste">http://www.redmine.org/plugins/clipboard_image_paste</a></li>
<li><a href="https://github.com/peclik/clipboard_image_paste">https://github.com/peclik/clipboard_image_paste</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_checklists">http://www.redmine.org/plugins/redmine_checklists</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_agile">http://www.redmine.org/plugins/redmine_agile</a></li>
<li><a href="https://github.com/paginagmbh/redmine_lightbox2.git">https://github.com/paginagmbh/redmine_lightbox2.git</a></li>
<li><a href="https://github.com/paginagmbh/redmine_lightbox2">https://github.com/paginagmbh/redmine_lightbox2</a></li>
<li><a href="http://www.redmine.org/plugins/mega_calendar">http://www.redmine.org/plugins/mega_calendar</a></li>
<li><a href="https://github.com/berti92/mega_calendar/wiki/Installation">https://github.com/berti92/mega_calendar/wiki/Installation</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_work_time">http://www.redmine.org/plugins/redmine_work_time</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_issue_templates">http://www.redmine.org/plugins/redmine_issue_templates</a></li>
<li>Kanban</li>
<li><a href="http://www.redmine.org/plugins/redhopper">http://www.redmine.org/plugins/redhopper</a></li>
<li><a href="http://www.redmine.org/plugins/redhopper">http://www.redmine.org/plugins/redhopper</a></li>
<li><a href="http://www.redmine.org/plugins/deployer">http://www.redmine.org/plugins/deployer</a></li>
<li><a href="https://github.com/zapic0/deployer">https://github.com/zapic0/deployer</a></li>
<li><a href="http://www.redmine.org/plugins/redmine-ckeditor">http://www.redmine.org/plugins/redmine-ckeditor</a></li>
<li><a href="https://github.com/a-ono/redmine_ckeditor">https://github.com/a-ono/redmine_ckeditor</a></li>
<li><a href="http://www.redmine.org/plugins/apijs">http://www.redmine.org/plugins/apijs</a> 有一些依赖要安装，没用到的可以不安装。</li>
<li><a href="https://www.luigifab.info/redmine/en/apijs.php">https://www.luigifab.info/redmine/en/apijs.php</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s plugins]# sed -i '/haml/s/^/#/' redhopper/Gemfile           
</span><span class='line'>[root@k8s plugins]# mv apijs redmine_apijs
</span><span class='line'>
</span><span class='line'>[root@k8s redmine]# ll /srv/docker/redmine/redmine/plugins/
</span><span class='line'>total 0
</span><span class='line'>drwxr-xr-x.  8 es es 118 Sep 18 14:05 clipboard_image_paste
</span><span class='line'>drwxr-xr-x. 10 es es 212 Sep 18 19:18 deployer
</span><span class='line'>drwxr-xr-x.  7 es es 160 Sep 18 12:00 issuefy
</span><span class='line'>drwxr-xr-x.  4 es es  60 Sep 18 11:59 line_numbers
</span><span class='line'>drwxr-xr-x.  8 es es 182 Sep 17 18:05 mega_calendar
</span><span class='line'>drwxr-xr-x.  6 es es 158 Sep 18 12:00 open_flash_chart
</span><span class='line'>drwxrwxr-x.  8 es es 225 Sep 18 22:15 redhopper
</span><span class='line'>drwxr-xr-x.  9 es es 156 Sep  6 19:02 redmine_agile
</span><span class='line'>drwxr-xr-x.  7 es es 133 Sep 18 22:00 redmine_apijs
</span><span class='line'>drwxr-xr-x. 10 es es 119 Aug 30 21:46 redmine_checklists
</span><span class='line'>drwxr-xr-x.  9 es es 158 Sep 18 19:19 redmine_ckeditor
</span><span class='line'>drwxr-xr-x.  8 es es 221 Sep 18 12:01 redmine_code_review
</span><span class='line'>drwxr-xr-x.  8 es es 252 Sep 18 12:01 redmine_dashboard
</span><span class='line'>drwxr-xr-x.  3 es es  70 Sep 18 12:00 redmine_embedded_video
</span><span class='line'>drwxr-xr-x.  2 es es  78 Sep 18 12:00 redmine_gist
</span><span class='line'>drwxrwxr-x.  8 es es 129 Aug  5 10:52 redmine_issue_templates
</span><span class='line'>drwxr-xr-x.  8 es es 170 Sep 18 17:46 redmine_lightbox2
</span><span class='line'>drwxr-xr-x.  8 es es 160 Mar  5  2017 redmine_work_time</span></code></pre></td></tr></table></div></figure>


<p>不重启容器的话，可以登录到容器把 ~/data/plugins 拷贝到 ~/redmine/plugins 下面，然后执行下面的命令进行更新：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@f0481f5f8cda:/home/redmine/redmine# 
</span><span class='line'>bundle install --without development test
</span><span class='line'>bundle exec rake redmine:plugins:migrate RAILS_ENV=production
</span><span class='line'>
</span><span class='line'>supervisorctl restart unicorn
</span></code></pre></td></tr></table></div></figure>


<h2>其他的一些插件</h2>

<ul>
<li><a href="http://www.redmine.org/plugins/dmsf">http://www.redmine.org/plugins/dmsf</a></li>
<li><a href="https://github.com/danmunn/redmine_dmsf">https://github.com/danmunn/redmine_dmsf</a></li>
<li><a href="http://www.redmine.org/plugins/redmine_git_hosting">http://www.redmine.org/plugins/redmine_git_hosting</a> X</li>
<li><a href="http://www.redmine.org/plugins/redmine_upwork_plugin">http://www.redmine.org/plugins/redmine_upwork_plugin</a></li>
<li><a href="https://github.com/alexbevi/redmine_knowledgebase">https://github.com/alexbevi/redmine_knowledgebase</a></li>
<li><a href="https://github.com/danmunn/redmine_dmsf">https://github.com/danmunn/redmine_dmsf</a></li>
<li><a href="https://github.com/jbox-web/redmine_jenkins">https://github.com/jbox-web/redmine_jenkins</a></li>
<li><a href="https://github.com/masweetman/issue_charts">https://github.com/masweetman/issue_charts</a></li>
<li>3.3.x</li>
<li><a href="http://www.redmine.org/plugins/redmine_pivot_table">http://www.redmine.org/plugins/redmine_pivot_table</a></li>
<li><a href="https://www.redmine.org/plugins/advanced_roadmap_v2">https://www.redmine.org/plugins/advanced_roadmap_v2</a></li>
<li><a href="https://github.com/Coren/redmine_advanced_roadmap_v2">https://github.com/Coren/redmine_advanced_roadmap_v2</a></li>
<li><a href="https://github.com/Loriowar/redmine_issues_tree">https://github.com/Loriowar/redmine_issues_tree</a></li>
<li><a href="https://github.com/speedy32129/projects_show">https://github.com/speedy32129/projects_show</a></li>
</ul>


<h2>参考</h2>

<ul>
<li><a href="https://github.com/bitnami/bitnami-docker-redmine">https://github.com/bitnami/bitnami-docker-redmine</a></li>
<li><a href="http://11398377.blog.51cto.com/11388377/1875686">http://11398377.blog.51cto.com/11388377/1875686</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker Compose入门]]></title>
    <link href="http://winseliu.com/blog/2017/09/17/docker-compose-hello/"/>
    <updated>2017-09-17T00:48:25+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/17/docker-compose-hello</id>
    <content type="html"><![CDATA[<p>使用Docker也一段时间了，一开始直接使用命令行 docker run 来启动的，后面使用 k8s 来管理，对于多机环境来说还是挺方便的。但是如果仅仅是单机上面跑docker容器，安装一套 k8s 的话也挺尴尬的。</p>

<p>docker提供了compose编排的功能，通过配置文件的方式来启动、管理（多）容器的运行。有点启动脚本的意思，当然也包含一些管理的元素，对容器LifeCycle的管理。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s composetest]# docker version
</span><span class='line'>Client:
</span><span class='line'> Version:      1.12.6
</span><span class='line'> API version:  1.24
</span><span class='line'> Go version:   go1.6.4
</span><span class='line'> Git commit:   78d1802
</span><span class='line'> Built:        Tue Jan 10 20:20:01 2017
</span><span class='line'> OS/Arch:      linux/amd64
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Version:      1.12.6
</span><span class='line'> API version:  1.24
</span><span class='line'> Go version:   go1.6.4
</span><span class='line'> Git commit:   78d1802
</span><span class='line'> Built:        Tue Jan 10 20:20:01 2017
</span><span class='line'> OS/Arch:      linux/amd64
</span><span class='line'> 
</span><span class='line'>[root@k8s composetest]# docker-compose version
</span><span class='line'>docker-compose version 1.16.1, build 6d1ac21
</span><span class='line'>docker-py version: 2.5.1
</span><span class='line'>CPython version: 2.7.13
</span><span class='line'>OpenSSL version: OpenSSL 1.0.1t  3 May 2016
</span></code></pre></td></tr></table></div></figure>


<p>docker的版本需要和compose配置的版本适配： <a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a> ，docker-1.12的话，compose version不能高于 2.1。<a href="https://docs.docker.com/compose/compose-file/compose-file-v2/#build">Compose file version 2</a> 。</p>

<p>先安装官网的helloworld来运行一个例子：</p>

<ul>
<li><a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a></li>
<li><a href="https://docs.docker.com/compose/gettingstarted/#prerequisites">https://docs.docker.com/compose/gettingstarted/#prerequisites</a></li>
</ul>


<h2>安装：</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 浏览器下载docker-compose
</span><span class='line'>https://github.com/docker/compose/releases/download/1.16.1/docker-compose-Linux-x86_64
</span><span class='line'>
</span><span class='line'>[root@k8s opt]# cd /usr/local/bin/
</span><span class='line'>[root@k8s bin]# rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring docker-compose-Linux-x86_64 (1)...
</span><span class='line'>  100%    8648 KB    4324 KB/sec    00:00:02       0 Errors  
</span><span class='line'>
</span><span class='line'>[root@k8s bin]# mv docker-compose-Linux-x86_64 docker-compose
</span><span class='line'>[root@k8s bin]# chmod +x docker-compose 
</span></code></pre></td></tr></table></div></figure>


<h2>Hello World:</h2>

<p>官网是一个访问量统计的例子，通过python网站结合redis来实现。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s composetest]# ll
</span><span class='line'>total 16
</span><span class='line'>-rw-r--r--. 1 root root 303 Sep 17 08:09 app.py
</span><span class='line'>-rw-r--r--. 1 root root 112 Sep 17 08:39 docker-compose.yml
</span><span class='line'>-rw-r--r--. 1 root root 114 Sep 17 08:42 Dockerfile
</span><span class='line'>-rw-r--r--. 1 root root  13 Sep 17 08:09 requirements.txt
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat app.py 
</span><span class='line'>from flask import Flask
</span><span class='line'>from redis import Redis
</span><span class='line'>
</span><span class='line'>app = Flask(__name__)
</span><span class='line'>redis = Redis(host='redis', port=6379)
</span><span class='line'>
</span><span class='line'>@app.route('/')
</span><span class='line'>def hello():
</span><span class='line'>  count = redis.incr('hits')
</span><span class='line'>  return 'Hello World! I have been seen {} times.\n'.format(count)
</span><span class='line'>
</span><span class='line'>if __name__ == "__main__":
</span><span class='line'>  app.run(host="0.0.0.0", debug=True)
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat requirements.txt 
</span><span class='line'>flask
</span><span class='line'>redis
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat Dockerfile 
</span><span class='line'>FROM python:3.4-alpine
</span><span class='line'>
</span><span class='line'>ADD . /code
</span><span class='line'>WORKDIR /code
</span><span class='line'>
</span><span class='line'>RUN pip install -r requirements.txt
</span><span class='line'>
</span><span class='line'>CMD ["python", "app.py"]
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# cat docker-compose.yml 
</span><span class='line'>version: '2.1'
</span><span class='line'>services:
</span><span class='line'>  web:
</span><span class='line'>    build: .
</span><span class='line'>    ports:
</span><span class='line'>      - "5000:5000"
</span><span class='line'>  redis:
</span><span class='line'>    image: "redis:alpine"
</span></code></pre></td></tr></table></div></figure>


<p>依赖的镜像可以提前下载好，可以不修改docker配置的情况下来下载，参考<a href="https://raw.githubusercontent.com/winse/shell-not-just-on-work/master/docker-download-mirror.sh">docker-download-mirror.sh</a></p>

<p>写好配置后，运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s composetest]# docker-compose up --build
</span><span class='line'>Building web
</span><span class='line'>Step 1 : FROM python:3.4-alpine
</span><span class='line'> ---&gt; 27a0e572c13a
</span><span class='line'>Step 2 : ADD . /code
</span><span class='line'> ---&gt; 84082044fb5e
</span><span class='line'>Removing intermediate container 7c4675b618da
</span><span class='line'>Step 3 : WORKDIR /code
</span><span class='line'> ---&gt; Running in a014af85b748
</span><span class='line'> ---&gt; 2ada42bd756c
</span><span class='line'>Removing intermediate container a014af85b748
</span><span class='line'>Step 4 : RUN pip install -r requirements.txt
</span><span class='line'> ---&gt; Running in 4be6f8f5c8b8
</span><span class='line'>Collecting flask (from -r requirements.txt (line 1))
</span><span class='line'>  Downloading Flask-0.12.2-py2.py3-none-any.whl (83kB)
</span><span class='line'>Collecting redis (from -r requirements.txt (line 2))
</span><span class='line'>  Downloading redis-2.10.6-py2.py3-none-any.whl (64kB)
</span><span class='line'>Collecting Jinja2&gt;=2.4 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading Jinja2-2.9.6-py2.py3-none-any.whl (340kB)
</span><span class='line'>Collecting click&gt;=2.0 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading click-6.7-py2.py3-none-any.whl (71kB)
</span><span class='line'>Collecting itsdangerous&gt;=0.21 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading itsdangerous-0.24.tar.gz (46kB)
</span><span class='line'>Collecting Werkzeug&gt;=0.7 (from flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading Werkzeug-0.12.2-py2.py3-none-any.whl (312kB)
</span><span class='line'>Collecting MarkupSafe&gt;=0.23 (from Jinja2&gt;=2.4-&gt;flask-&gt;-r requirements.txt (line 1))
</span><span class='line'>  Downloading MarkupSafe-1.0.tar.gz
</span><span class='line'>Building wheels for collected packages: itsdangerous, MarkupSafe
</span><span class='line'>  Running setup.py bdist_wheel for itsdangerous: started
</span><span class='line'>  Running setup.py bdist_wheel for itsdangerous: finished with status 'done'
</span><span class='line'>  Stored in directory: /root/.cache/pip/wheels/fc/a8/66/24d655233c757e178d45dea2de22a04c6d92766abfb741129a
</span><span class='line'>  Running setup.py bdist_wheel for MarkupSafe: started
</span><span class='line'>  Running setup.py bdist_wheel for MarkupSafe: finished with status 'done'
</span><span class='line'>  Stored in directory: /root/.cache/pip/wheels/88/a7/30/e39a54a87bcbe25308fa3ca64e8ddc75d9b3e5afa21ee32d57
</span><span class='line'>Successfully built itsdangerous MarkupSafe
</span><span class='line'>Installing collected packages: MarkupSafe, Jinja2, click, itsdangerous, Werkzeug, flask, redis
</span><span class='line'>Successfully installed Jinja2-2.9.6 MarkupSafe-1.0 Werkzeug-0.12.2 click-6.7 flask-0.12.2 itsdangerous-0.24 redis-2.10.6
</span><span class='line'> ---&gt; ee3e476d4fad
</span><span class='line'>Removing intermediate container 4be6f8f5c8b8
</span><span class='line'>Step 5 : CMD python app.py
</span><span class='line'> ---&gt; Running in f2f9eefe782e
</span><span class='line'> ---&gt; 08e3065107b2
</span><span class='line'>Removing intermediate container f2f9eefe782e
</span><span class='line'>Successfully built 08e3065107b2
</span><span class='line'>Recreating composetest_web_1 ... 
</span><span class='line'>Recreating composetest_web_1
</span><span class='line'>Starting composetest_redis_1 ... 
</span><span class='line'>Recreating composetest_web_1 ... done
</span><span class='line'>Attaching to composetest_redis_1, composetest_web_1
</span><span class='line'>redis_1  | 1:C 17 Sep 00:43:45.012 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
</span><span class='line'>redis_1  | 1:C 17 Sep 00:43:45.013 # Redis version=4.0.1, bits=64, commit=00000000, modified=0, pid=1, just started
</span><span class='line'>redis_1  | 1:C 17 Sep 00:43:45.013 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 * Running mode=standalone, port=6379.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # Server initialized
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 * DB loaded from disk: 0.000 seconds
</span><span class='line'>redis_1  | 1:M 17 Sep 00:43:45.020 * Ready to accept connections
</span><span class='line'>web_1    |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
</span><span class='line'>web_1    |  * Restarting with stat
</span><span class='line'>web_1    |  * Debugger is active!
</span><span class='line'>web_1    |  * Debugger PIN: 175-303-648</span></code></pre></td></tr></table></div></figure>


<p>查看容器状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s opt]# curl http://0.0.0.0:5000/
</span><span class='line'>Hello World! I have been seen 1 times.
</span><span class='line'>[root@k8s opt]# curl http://0.0.0.0:5000/
</span><span class='line'>Hello World! I have been seen 2 times.
</span><span class='line'>
</span><span class='line'>[root@k8s composetest]# docker-compose ps 
</span><span class='line'>       Name                      Command               State           Ports         
</span><span class='line'>-------------------------------------------------------------------------------------
</span><span class='line'>composetest_redis_1   docker-entrypoint.sh redis ...   Up      6379/tcp              
</span><span class='line'>composetest_web_1     python app.py                    Up      0.0.0.0:5000-&gt;5000/tcp
</span><span class='line'>
</span><span class='line'>##
</span><span class='line'>docker-compose rm -f # Remove stopped containers
</span><span class='line'>docker-compose down  # Stop and remove containers, networks, images, and volumes
</span></code></pre></td></tr></table></div></figure>


<h2>其他</h2>

<p>后台运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-compose up -d
</span><span class='line'>$ docker-compose ps</span></code></pre></td></tr></table></div></figure>


<p>在指定容器内执行命令：有点类似 docker exec/kubectl exec</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-compose run web env</span></code></pre></td></tr></table></div></figure>


<p><a href="https://docs.docker.com/compose/production/#deploying-changes">单独编译运行</a> 仅更改过内容的容器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-compose build web
</span><span class='line'>$ docker-compose up --no-deps -d web</span></code></pre></td></tr></table></div></figure>


<p>配置<a href="https://docs.docker.com/compose/extends/#extending-services">复用/覆写</a>：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
</span><span class='line'>
</span><span class='line'># A
</span><span class='line'>webapp:
</span><span class='line'>  build: .
</span><span class='line'>  ports:
</span><span class='line'>    - "8000:8000"
</span><span class='line'>  volumes:
</span><span class='line'>    - "/data"
</span><span class='line'>   
</span><span class='line'># EA   
</span><span class='line'>web:
</span><span class='line'>  extends:
</span><span class='line'>    file: common-services.yml
</span><span class='line'>    service: webapp
</span><span class='line'>    </span></code></pre></td></tr></table></div></figure>


<h2>学习</h2>

<ul>
<li><a href="https://yeasy.gitbooks.io/docker_practice/content/compose/commands.html">Compose 命令</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zookeeper ACL]]></title>
    <link href="http://winseliu.com/blog/2017/09/02/zookeeper-acl/"/>
    <updated>2017-09-02T15:14:55+00:00</updated>
    <id>http://winseliu.com/blog/2017/09/02/zookeeper-acl</id>
    <content type="html"><![CDATA[<p>集群又一次进行安检，SSH躲不过需要升级的，这次还加了hadoop security和zookeeper acl的bug。以前没太在意这些内容，既然安全检查出来了，还是需要处理的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ZooKeeper 未授权访问【原理扫描】
</span><span class='line'>详细描述  ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 
</span><span class='line'>ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 
</span><span class='line'>在通常情况下，zookeeper允许未经授权的访问。
</span><span class='line'>解决办法  为ZooKeeper配置相应的访问权限。 
</span><span class='line'>
</span><span class='line'>方式一： 
</span><span class='line'>1）增加一个认证用户 
</span><span class='line'>addauth digest 用户名:密码明文 
</span><span class='line'>eg. addauth digest user1:password1 
</span><span class='line'>2）设置权限 
</span><span class='line'>setAcl /path auth:用户名:密码明文:权限 
</span><span class='line'>eg. setAcl /test auth:user1:password1:cdrwa 
</span><span class='line'>3）查看Acl设置 
</span><span class='line'>getAcl /path 
</span><span class='line'>
</span><span class='line'>方式二： 
</span><span class='line'>setAcl /path digest:用户名:密码密文:权限
</span><span class='line'>
</span><span class='line'>威胁分值  5.0
</span><span class='line'>危险插件  否
</span><span class='line'>发现日期  2015-02-10
</span></code></pre></td></tr></table></div></figure>


<h2>Zookeeper权限基本知识点、操作</h2>

<ul>
<li><a href="https://zookeeper.apache.org/doc/r3.3.3/zookeeperProgrammers.html#sc_ZooKeeperAccessControl">https://zookeeper.apache.org/doc/r3.3.3/zookeeperProgrammers.html#sc_ZooKeeperAccessControl</a></li>
<li><a href="https://my.oschina.net/guol/blog/1358538">https://my.oschina.net/guol/blog/1358538</a></li>
<li><a href="http://blog.csdn.net/xyang81/article/details/53147894">http://blog.csdn.net/xyang81/article/details/53147894</a></li>
<li><a href="https://ihong5.wordpress.com/2014/07/24/apache-zookeeper-setting-acl-in-zookeeper-client/">https://ihong5.wordpress.com/2014/07/24/apache-zookeeper-setting-acl-in-zookeeper-client/</a></li>
<li><a href="https://zookeeper.apache.org/doc/r3.3.3/zookeeperStarted.html">https://zookeeper.apache.org/doc/r3.3.3/zookeeperStarted.html</a></li>
</ul>


<p>Note also that an ACL pertains only to a specific znode. In particular it does not apply to children. ACL在znode上无继承性，也就是说子znode不会继承父znode的ACL权限.</p>

<ul>
<li>world has a single id, anyone, that represents anyone.</li>
<li>auth doesn&rsquo;t use any id, represents any authenticated user.</li>
<li>digest uses a username:password string to generate MD5 hash which is then used as an ACL ID identity. Authentication is done by sending the username:password in clear text. When used in the ACL the expression will be the username:base64 encoded SHA1 password digest.</li>
<li>ip uses the client host IP as an ACL ID identity. The ACL expression is of the form addr/bits(3.5+) where the most significant bits of addr are matched against the most significant bits of the client host IP.</li>
</ul>


<p>zookeeper的ACL格式为 schema:id:permissions 。模式就是上面列的几种，再加一个super。创建的节点默认权限为 world:anyone:rwadc 表示所有人都对这个节点有rwadc的权限。</p>

<ul>
<li>Create：允许对子节点Create 操作</li>
<li>Read：允许对本节点GetChildren 和GetData 操作</li>
<li>Write ：允许对本节点SetData 操作</li>
<li>Delete ：允许对子节点Delete 操作</li>
<li>Admin ：允许对本节点setAcl 操作</li>
</ul>


<h2>Auth授权</h2>

<p>不需要id，当前 &ldquo;登录&rdquo; 的所有users都有权限（sasl、kerberos这些授权方式不懂，囧)。虽然不需要id，但是格式还得按照 scheme:id:perm 的写法。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 15] setAcl /c auth:rwadc  
</span><span class='line'>auth:rwadc does not have the form scheme:id:perm
</span><span class='line'>Acl is not valid : /c
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 13] addauth digest a:a
</span><span class='line'>[zk: k8s(CONNECTED) 14] addauth digest b:b
</span><span class='line'>[zk: k8s(CONNECTED) 15] addauth digest c:c
</span><span class='line'>[zk: k8s(CONNECTED) 16] create /e e
</span><span class='line'>Created /e
</span><span class='line'>[zk: k8s(CONNECTED) 17] setAcl /e auth::cdrwa
</span><span class='line'>...省略节点输出信息
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 18] getAcl /e
</span><span class='line'>'digest,'a:mDmPUap4qvYwm+PZOtJ/scGyHLY=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'b:+F8zPn3x1CLx3qpYHEaRwIheWcc=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'c:K7CO7OxIfBOQxczG+7FI9BdZ6/s=
</span><span class='line'>: cdrwa</span></code></pre></td></tr></table></div></figure>


<p>id随便写也可以，zookeeper都不记录的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 9] addauth digest hdfs:hdfs    
</span><span class='line'>[zk: localhost:2181(CONNECTED) 10] setAcl /c auth:x:x:rwadc
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 11] getAcl /c               
</span><span class='line'>'digest,'user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'hdfs:0wpra2yK6RCUB9sbo0BkElpzcl8=
</span><span class='line'>: cdrwa</span></code></pre></td></tr></table></div></figure>


<p>也可以对根 / 授权，这样客户端就不能随便在根下面新建节点了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 9] addauth digest user:password    
</span><span class='line'>[zk: localhost:2181(CONNECTED) 21] setAcl / auth::rawdc
</span><span class='line'>
</span><span class='line'>重新登录
</span><span class='line'>[zk: localhost:2181(CONNECTED) 0] ls /
</span><span class='line'>Authentication is not valid : /
</span><span class='line'>[zk: localhost:2181(CONNECTED) 1] getAcl /
</span><span class='line'>'digest,'user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>还原</p>

<p>使用有权限的用户/实例，如果都忘了那就只能放绝招：使用超级管理员登录，重新设置权限为world即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 26] setAcl / world:anyone:cdrwa</span></code></pre></td></tr></table></div></figure>


<h2>Digest</h2>

<p>直接用起来比 auth 简单，直接把密文交给zookeeper。首先得生成对应用户的密码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s zookeeper-3.4.10]# java -cp zookeeper-3.4.10.jar:lib/* org.apache.zookeeper.server.auth.DigestAuthenticationProvider user:password
</span><span class='line'>user:password-&gt;user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>
</span><span class='line'>[root@k8s zookeeper-3.4.10]# java -cp zookeeper-3.4.10.jar:lib/* org.apache.zookeeper.server.auth.DigestAuthenticationProvider es:es
</span><span class='line'>es:es-&gt;es:KiHfMOSWCTgPKpz78IL/6qO8AEE=</span></code></pre></td></tr></table></div></figure>


<p>scheme是digest的时候，id需要密文。通过Zookeeper的客户端编码方式添加认证（登录），digest对应的auth数据是明文。</p>

<p>ACL授权一样使用 setAcl ：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ A实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 17] setAcl /b digest:user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=:cdrwa
</span><span class='line'>和md5密码类似，数据库被盗了，如果是常用的密码会被猜出来
</span><span class='line'>[zk: localhost:2181(CONNECTED) 18] getAcl /b
</span><span class='line'>'digest,'user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'>$$ B实例
</span><span class='line'>重新登录：
</span><span class='line'>[zk: k8s:2181(CONNECTED) 2] ls /b
</span><span class='line'>Authentication is not valid : /b
</span><span class='line'>
</span><span class='line'>$$ A实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 20] create /b/bb ''
</span><span class='line'>Authentication is not valid : /b/bb
</span><span class='line'>[zk: localhost:2181(CONNECTED) 21] addauth digest user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=
</span><span class='line'>[zk: localhost:2181(CONNECTED) 22] create /b/bb ''                                 
</span><span class='line'>Authentication is not valid : /b/bb
</span><span class='line'>
</span><span class='line'># 需要使用明文登录
</span><span class='line'>[zk: localhost:2181(CONNECTED) 23] addauth digest user:password
</span><span class='line'>[zk: localhost:2181(CONNECTED) 24] create /b/bb '' 
</span><span class='line'>Created /b/bb 
</span><span class='line'>
</span><span class='line'># 权限没有继承性
</span><span class='line'>[zk: localhost:2181(CONNECTED) 25] getAcl /b/bb
</span><span class='line'>'world,'anyone
</span><span class='line'>: cdrwa</span></code></pre></td></tr></table></div></figure>


<h1>IP</h1>

<p>ip的权限配置更简单些。逻辑就是匹配客户端的IP地址，在权限IP地址段范围内的才能访问。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ A实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 18] setAcl /i ip:127.0.0.1:cdrwa
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 19] getAcl /i
</span><span class='line'>'ip,'127.0.0.1
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 24] get /i
</span><span class='line'>Authentication is not valid : /i
</span><span class='line'>
</span><span class='line'>咋回事呢，就是本地还没权限？有时可localhost不一定对应127.0.0.1的。。。
</span><span class='line'>
</span><span class='line'>$$ B实例
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkCli.sh -server 127.0.0.1
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 0] get /i
</span><span class='line'>i
</span><span class='line'>...
</span><span class='line'>改成另一个网卡的ip地址
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 1] setAcl /i ip:192.168.191.138:cdrwa
</span><span class='line'>...
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 2] getAcl /i
</span><span class='line'>'ip,'192.168.191.138
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: 127.0.0.1(CONNECTED) 3] get /i
</span><span class='line'>Authentication is not valid : /i
</span><span class='line'>
</span><span class='line'>$$ C实例
</span><span class='line'>用主机名(191.138)登录的实例
</span><span class='line'>[zk: k8s(CONNECTED) 19] get /i
</span><span class='line'>i</span></code></pre></td></tr></table></div></figure>


<h2>超级管理员</h2>

<p>如果权限设置错了，咋办？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: k8s(CONNECTED) 21] setAcl /i ip:192.168.191.0/24:cdrwa                   
</span><span class='line'>Acl is not valid : /i
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 25] setAcl /i ip:192.168.191.0:cdrwa
</span><span class='line'>
</span><span class='line'>[zk: k8s(CONNECTED) 26] getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: k8s(CONNECTED) 27] get /i
</span><span class='line'>Authentication is not valid : /i</span></code></pre></td></tr></table></div></figure>


<p>除非把客户端的ip地址换成 192.168.191.0 否则就访问不了了。</p>

<p>此时需要超级管理员才行，不然真没办法折腾了。（不知道为啥）是可以删掉（特指我当前的环境啊），但是这样数据就没有了啊！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 26] getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 27] delete /i
</span><span class='line'>[zk: localhost:2181(CONNECTED) 28] ls /
</span><span class='line'>[a, b, c, zookeeper, d, e]
</span><span class='line'>[zk: localhost:2181(CONNECTED) 29] ls /i
</span><span class='line'>Node does not exist: /i</span></code></pre></td></tr></table></div></figure>


<p>如果数据很重要，重启后用超级管理员的方式找回密码还是很划的来的。</p>

<ul>
<li><a href="https://community.hortonworks.com/articles/29900/zookeeper-using-superdigest-to-gain-full-access-to.html">https://community.hortonworks.com/articles/29900/zookeeper-using-superdigest-to-gain-full-access-to.html</a></li>
</ul>


<p>用 DigestAuthenticationProvider 加密就不操作了，直接用 es:es 对应的 es:es->es:KiHfMOSWCTgPKpz78IL/6qO8AEE= 作为管理员的账号密码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export SERVER_JVMFLAGS=-Dzookeeper.DigestAuthenticationProvider.superDigest=es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkServer.sh stop
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkServer.sh start
</span><span class='line'>ZooKeeper JMX enabled by default
</span><span class='line'>Using config: /opt/zookeeper-3.4.10/bin/../conf/zoo.cfg
</span><span class='line'>Starting zookeeper ... STARTED
</span><span class='line'>
</span><span class='line'>$$ A实例
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkCli.sh 
</span><span class='line'>[zk: localhost:2181(CONNECTED) 0] get /i
</span><span class='line'>Authentication is not valid : /i
</span><span class='line'>[zk: localhost:2181(CONNECTED) 1] getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 2] addauth digest es:es
</span><span class='line'>[zk: localhost:2181(CONNECTED) 3] get /i
</span><span class='line'>i
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 4] setAcl /i world:anyone:cdrwa
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>$$ B实例
</span><span class='line'>[zk: localhost:2181(CONNECTED) 0] get /i
</span><span class='line'>i
</span><span class='line'>[zk: localhost:2181(CONNECTED) 1] getAcl /i
</span><span class='line'>'world,'anyone
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<h2>实践&mdash;好玩</h2>

<p>权限可以直接在创建的时刻指定：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>create /mynode content digest:user:tpUq/4Pn5A64fVZyQ0gOJ8ZWqkY=:cdrwa</span></code></pre></td></tr></table></div></figure>


<p>也可以一次性设置N个权限：</p>

<p>注：以下操作都是超级管理员登录的窗口，所以不存在权限的问题。想怎么改就怎么改</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>setAcl /i ip:192.168.191.0:cdrwa,ip:127.0.0.1:cdrwa,ip:192.168.191.138:cdrwa
</span><span class='line'>
</span><span class='line'>getAcl /i
</span><span class='line'>'ip,'192.168.191.0
</span><span class='line'>: cdrwa
</span><span class='line'>'ip,'127.0.0.1
</span><span class='line'>: cdrwa
</span><span class='line'>'ip,'192.168.191.138
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>但是，使用ip、digest、word重设权限后，会覆盖旧的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 7] setAcl /i ip:0.0.0.0:cdrwa
</span><span class='line'>[zk: localhost:2181(CONNECTED) 8] getAcl /i
</span><span class='line'>'ip,'0.0.0.0
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'>[zk: localhost:2181(CONNECTED) 15] setAcl /i world:anyone:cdraw
</span><span class='line'>[zk: localhost:2181(CONNECTED) 16] getAcl /i
</span><span class='line'>'world,'anyone
</span><span class='line'>: cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>3.4的版本不支持ip段（3.5应该是ok的）： <a href="https://github.com/apache/zookeeper/blob/release-3.4.10/src/java/main/org/apache/zookeeper/server/auth/IPAuthenticationProvider.java#L114">IPAuthenticationProvider</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public boolean isValid(String id) {
</span><span class='line'>    return addr2Bytes(id) != null;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>可以找对应版本的源码（远程）调试下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s zookeeper-3.4.10]# export SERVER_JVMFLAGS="-Dzookeeper.DigestAuthenticationProvider.superDigest=es:KiHfMOSWCTgPKpz78IL/6qO8AEE= -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005"
</span><span class='line'>[root@k8s zookeeper-3.4.10]# bin/zkServer.sh start
</span></code></pre></td></tr></table></div></figure>


<p>auth的权限比较有意思：自家兄弟添加、排除异己；permission按最新的算</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[zk: localhost:2181(CONNECTED) 21] setAcl /i auth::cdrwa,ip:0.0.0.0:cd
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 22] getAcl /i
</span><span class='line'>'ip,'0.0.0.0
</span><span class='line'>: cd
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'># auth add
</span><span class='line'>[zk: localhost:2181(CONNECTED) 27] addauth digest m:m
</span><span class='line'>[zk: localhost:2181(CONNECTED) 28] addauth digest n:n
</span><span class='line'>[zk: localhost:2181(CONNECTED) 29] setAcl /i auth::cdrwa
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 30] getAcl /i
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'m:WZiIgWqJgd8EQVBh55Bslf/7JRc=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'n:TZ3f1UF7B75EF5g6qWR0VmEvb/s=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'># perm
</span><span class='line'>[zk: localhost:2181(CONNECTED) 31] addauth digest z:z
</span><span class='line'>[zk: localhost:2181(CONNECTED) 32] addauth digest l:l
</span><span class='line'>[zk: localhost:2181(CONNECTED) 33] setAcl /i auth:z:z:cd
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 34] getAcl /i
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cd
</span><span class='line'>'digest,'m:WZiIgWqJgd8EQVBh55Bslf/7JRc=
</span><span class='line'>: cd
</span><span class='line'>'digest,'n:TZ3f1UF7B75EF5g6qWR0VmEvb/s=
</span><span class='line'>: cd
</span><span class='line'>'digest,'z:cOgtYxFOAwKiTCMigcN2j2fFI3c=
</span><span class='line'>: cd
</span><span class='line'>'digest,'l:gdlgatwJdq7uG8kFfIjcIZj0tnQ=
</span><span class='line'>: cd
</span><span class='line'>
</span><span class='line'>可以看到全部变成cd了
</span><span class='line'>
</span><span class='line'>[zk: localhost:2181(CONNECTED) 35] setAcl /i auth:z:z:cdraw
</span><span class='line'>...
</span><span class='line'>[zk: localhost:2181(CONNECTED) 36] getAcl /i               
</span><span class='line'>'digest,'es:KiHfMOSWCTgPKpz78IL/6qO8AEE=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'m:WZiIgWqJgd8EQVBh55Bslf/7JRc=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'n:TZ3f1UF7B75EF5g6qWR0VmEvb/s=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'z:cOgtYxFOAwKiTCMigcN2j2fFI3c=
</span><span class='line'>: cdrwa
</span><span class='line'>'digest,'l:gdlgatwJdq7uG8kFfIjcIZj0tnQ=
</span><span class='line'>: cdrwa
</span><span class='line'>
</span><span class='line'>全部变成cdrwa
</span></code></pre></td></tr></table></div></figure>


<p>我觉得用 auth 设置权限是最保险的，不会搞错了出现自己都访问不了的情况。</p>

<h2>后记</h2>

<p>ok，到此基本的知识点算大概了解了。还有自定义实现授权的provider，这有点高级了有兴趣的自己去看官方文档了。</p>

<p>但是因为权限没有继承关系，像一些开源项目用到zookeeper的话，怎么进行加密呢？所有子目录都一个个的加？或者自定义根路径（chroot）让别人猜不到？</p>

<p>还有像zookeeper自己的目录 /zookeeper ，怎么进行权限管理呢？</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[命令行调用Jenkins2.63打包]]></title>
    <link href="http://winseliu.com/blog/2017/08/30/jenkins-build-via-shell/"/>
    <updated>2017-08-30T17:26:40+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/30/jenkins-build-via-shell</id>
    <content type="html"><![CDATA[<p>Jenkins给集成打包带来了很多的便捷，让不懂开发的同事也能轻松的打包。但是对于开发和运维来说，可能还需要在打包之外做一些事情，以及批量的处理N个打包。</p>

<p>对于研发来说，重复是最难忍受的。Jenkins可以直接通过api来调用查看和处理各种请求。</p>

<p>网络上资料其实挺多的。也有直接一个脚本直接搞定部署的。知其然知其所以然，还是需要自己下功夫理解人家的脚本这样才能更好的用（先不说自己写了）。主要的就是三个步骤：</p>

<ol>
<li>怎么登陆: <a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-Remoteaccess">JenkinsScriptConsole-Remoteaccess</a> .|. <a href="https://wiki.jenkins.io/display/JENKINS/Remote+access+API#RemoteaccessAPI-CSRFProtection">RemoteaccessAPI-CSRFProtection</a></li>
<li>执行build：<a href="http://www.inanzzz.com/index.php/post/jnrg/running-jenkins-build-via-command-line">Running jenkins jobs via command line</a> .|. <a href="https://www.nczonline.net/blog/2015/10/triggering-jenkins-builds-by-url/">Triggering Jenkins builds by URL</a></li>
<li>检查结果：<a href="https://gist.githubusercontent.com/julianchurchill/8780920/raw/ae3ab0c120857b0fe69fe3718d720cb4ef94c4b8/checkJenkins.sh">checkJenkins.sh</a></li>
</ol>


<h2>crumb</h2>

<p>首先来看看crumb是啥</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@iZ9416vn227Z opt]# curl -X POST $JENKINS_PROJ_AUTH_URL/build
</span><span class='line'>&lt;html&gt;
</span><span class='line'>&lt;head&gt;
</span><span class='line'>&lt;meta http-equiv="Content-Type" content="text/html;charset=utf-8"/&gt;
</span><span class='line'>&lt;title&gt;Error 403 No valid crumb was included in the request&lt;/title&gt;
</span><span class='line'>&lt;/head&gt;
</span><span class='line'>&lt;body&gt;&lt;h2&gt;HTTP ERROR 403&lt;/h2&gt;
</span><span class='line'>&lt;p&gt;Problem accessing /job/helloworld/build. Reason:
</span><span class='line'>&lt;pre&gt;    No valid crumb was included in the request&lt;/pre&gt;&lt;/p&gt;&lt;hr&gt;&lt;a href="http://eclipse.org/jetty"&gt;Powered by Jetty:// 9.4.z-SNAPSHOT&lt;/a&gt;&lt;hr/&gt;
</span><span class='line'>
</span><span class='line'>&lt;/body&gt;
</span><span class='line'>&lt;/html&gt;
</span></code></pre></td></tr></table></div></figure>


<p>这里<a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-RemoteaccesswithCSRFprotectionenabled">CSRF</a> 相当于jenkins做的一个权限控制，有两种方式处理：</p>

<p>方法一：取消控制</p>

<ul>
<li><a href="http://www.zhyea.com/2016/10/14/resolve-no-valid-crumb-was-included-in-the-request-error.html">no valid crumb was included in the request解决</a></li>
<li><a href="https://github.com/ghale/gradle-jenkins-plugin/issues/78#issuecomment-215783175">No valid crumb was included in the request</a></li>
</ul>


<p>在菜单 系统管理 –> Configure Global Security 中调整设置: 取消 防止跨站点请求伪造(Prevent Cross Site Request Forgery exploits) 的勾选。 如果还坚持要启用“防止跨站点请求伪造”，就需要先动态获取crumb。</p>

<p>方法二：获取token</p>

<ul>
<li><a href="https://stackoverflow.com/questions/16738441/how-to-request-for-crumb-issuer-for-jenkins">How to request for Crumb issuer for jenkins</a></li>
<li><a href="http://russellsimpkins.blogspot.jp/2014/10/calling-jenkins-job-with-bash-script.html">Calling a jenkins job with a bash script</a></li>
<li><a href="https://support.cloudbees.com/hc/en-us/articles/218889337-How-to-build-a-job-using-the-REST-API-and-cURL-">https://support.cloudbees.com/hc/en-us/articles/218889337-How-to-build-a-job-using-the-REST-API-and-cURL-</a></li>
</ul>


<p>通过URL: crumbIssuer/api/json 获取token的键值，然后把它附加到build请求的HEADER。</p>

<h2>命令行通过URL请求jenkins进行编译</h2>

<ul>
<li><a href="http://blog.csdn.net/xian312854159/article/details/41118245">使用shell脚本curl调用jenkins进行构建并判断是否构建成功 </a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Remote+access+API">Remote access API</a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Authenticating+scripted+clients">https://wiki.jenkins.io/display/JENKINS/Authenticating+scripted+clients</a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console">https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>JENKINS_ID="admin:PASSWORD"
</span><span class='line'>JENKINS_PROJ_AUTH_URL=http://$JENKINS_ID@localhost:18080/job/helloworld
</span><span class='line'>JENKINS_PROJ_URL=http://localhost:18080/job/helloworld
</span><span class='line'>
</span><span class='line'>curl $JENKINS_PROJ_AUTH_URL/lastBuild/api/json
</span><span class='line'>
</span><span class='line'>#Get the current configuration and save it locally
</span><span class='line'>curl -X GET $JENKINS_PROJ_URL/config.xml
</span><span class='line'>
</span><span class='line'>curl 'http://'$JENKINS_ID'@localhost:18080/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,":",//crumb)'
</span><span class='line'>Jenkins-Crumb:a4296173a91d900c11af07d932559fcd
</span><span class='line'>
</span><span class='line'>curl -X POST -H "Jenkins-Crumb:a4296173a91d900c11af07d932559fcd"  $JENKINS_PROJ_AUTH_URL/build
</span><span class='line'>
</span><span class='line'>curl -s $JENKINS_PROJ_AUTH_URL/lastBuild/api/json | jq .
</span><span class='line'>
</span><span class='line'># --- TODO ---
</span><span class='line'>
</span><span class='line'>progress（排队中）|pending（构建中），每三秒去重新获取结果进行判断  
</span><span class='line'>while grep -qE "In progress|pending" build.tmp2;  
</span><span class='line'>
</span><span class='line'>if grep -qE "Success" build.tmp2 ;then  
</span><span class='line'>elif grep -qE "Unstable" build.tmp2 ;then  
</span><span class='line'>elif grep -qE "Failed|Aborted" build.tmp2 ;then  
</span><span class='line'>echo "#Open Link: ${jobPage}${newbuild}/console see details"  
</span></code></pre></td></tr></table></div></figure>


<p>BuildName</p>

<ul>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Build+Name+Setter+Plugin">https://wiki.jenkins.io/display/JENKINS/Build+Name+Setter+Plugin</a></li>
<li><a href="https://stackoverflow.com/questions/42172320/how-to-set-the-jenkins-build-name-based-on-some-conditions">https://stackoverflow.com/questions/42172320/how-to-set-the-jenkins-build-name-based-on-some-conditions</a></li>
<li><a href="https://stackoverflow.com/questions/30111298/how-to-use-build-name-setter-plugin">https://stackoverflow.com/questions/30111298/how-to-use-build-name-setter-plugin</a></li>
</ul>


<p>jenkins的使用案例</p>

<ul>
<li><a href="http://debugtalk.com/post/iOS-Android-Packing-with-Jenkins-details/">http://debugtalk.com/post/iOS-Android-Packing-with-Jenkins-details/</a></li>
</ul>


<h2>参考</h2>

<p>API使用</p>

<ul>
<li><a href="https://gist.githubusercontent.com/julianchurchill/8780920/raw/ae3ab0c120857b0fe69fe3718d720cb4ef94c4b8/checkJenkins.sh">https://gist.githubusercontent.com/julianchurchill/8780920/raw/ae3ab0c120857b0fe69fe3718d720cb4ef94c4b8/checkJenkins.sh</a></li>
<li><a href="https://www.nczonline.net/blog/2015/10/triggering-jenkins-builds-by-url/">Triggering Jenkins builds by URL</a></li>
</ul>


<p>登录/权限问题</p>

<ul>
<li><a href="https://stackoverflow.com/questions/10698419/how-can-a-jenkins-user-authentication-details-be-passed-to-a-script-which-uses">https://stackoverflow.com/questions/10698419/how-can-a-jenkins-user-authentication-details-be-passed-to-a-script-which-uses</a></li>
<li><a href="http://www.scmgalaxy.com/tutorials/ways-to-login-jenkins-using-command-line">http://www.scmgalaxy.com/tutorials/ways-to-login-jenkins-using-command-line</a></li>
<li><a href="https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-Remoteaccess">https://wiki.jenkins.io/display/JENKINS/Jenkins+Script+Console#JenkinsScriptConsole-Remoteaccess</a></li>
<li><a href="http://russellsimpkins.blogspot.jp/2014/10/calling-jenkins-job-with-bash-script.html">Calling a jenkins job with a bash script</a></li>
<li><a href="https://issues.jenkins-ci.org/browse/JENKINS-42200">No valid crumb was included in the request in kubernetes</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vagrant创建自定义的BOX]]></title>
    <link href="http://winseliu.com/blog/2017/08/22/vagrant-create-your-own-box/"/>
    <updated>2017-08-22T23:04:17+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/22/vagrant-create-your-own-box</id>
    <content type="html"><![CDATA[<p>在《奔跑吧Ansible》中接触了Vagrant+VirtualBox，但是感觉一般般，也没觉得很特别的：就自己安装虚拟机差不多嘛。</p>

<p>后面在网上了解了一些关于这两工具，很多人用来搭建开发环境，脑子瞬间被击中了&mdash;还可以这么玩。这样系统重装的时刻就不用那么纠结和犹豫了，很多软件都安装在VirtualBox里面，重装后，直接启动虚拟机，就一切的开发环境的软件就都回来了。还有集群的搭建也挺方便的：由于Vagrant是命令行的方式结合配置来启动了，非常方便。</p>

<p>官方网站 <a href="http://www.vagrantbox.es/">Vagrantbox.es</a> <a href="https://app.vagrantup.com/boxes/search">Discover Vagrant Boxes</a> 有提供一些镜像，如Centos6:</p>

<ul>
<li><a href="https://app.vagrantup.com/centos/boxes/6">https://app.vagrantup.com/centos/boxes/6</a></li>
<li><a href="https://app.vagrantup.com/matchy/boxes/centos6-i386">https://app.vagrantup.com/matchy/boxes/centos6-i386</a> 。</li>
</ul>


<p>但是网络提供的不总能满足需要。所以有时还得亲自下手从零开始创建自己的Box。制作Vagrant的Box需要遵循一些要求/规范，官网有提供文档和说明：</p>

<ul>
<li><a href="https://www.vagrantup.com/docs/boxes/base.html">https://www.vagrantup.com/docs/boxes/base.html</a></li>
<li><a href="https://www.vagrantup.com/docs/virtualbox/boxes.html">https://www.vagrantup.com/docs/virtualbox/boxes.html</a></li>
<li><a href="https://unifreak.github.io/tutorial/Making-my-first-vagrant-box">制作自己第一个 vagrant box</a></li>
<li><a href="http://xuclv.blog.51cto.com/5503169/1239351">如何制作一个vagrant的base box</a></li>
</ul>


<p>为啥用vagrant：<a href="https://www.oschina.net/translate/get-vagrant-up-and-running-in-no-time">https://www.oschina.net/translate/get-vagrant-up-and-running-in-no-time</a></p>

<blockquote><p>在本地开发爽。用Vagrant快，简单，并可帮助你同时管理多个开发环境。</p>

<p>想象一下，你正在和据说15人的团队开发一个应用程序。这个程序真是狂棒！它使用Laravel的PHP框架，Redis和Memcached，ImageMagick和GD的PHP模块，curl，MySQL和PostgreSQL， 甚至MongoDB。 另外，Laravel明确依赖PHP版本5.3.7或更高版本，以及mcrypt的PHP扩展。</p>

<p>理想情况下，你会希望团队所有的15人在开发这个应用程序时，都是相同的开发环境。 但是不是所有的开发团队，都有系统管理的专家或者培养一个系统管理。获得相同设置的开发环境可能是一个非常艰巨的任务。 最重要的是，有些人使用的是Mac，而其他人则使用Linux或Windows。在它之前，开发人员会纠结在无尽的配置中，用电脑扔墙而筋疲力尽。</p></blockquote>

<p>其实，步骤不多也不是很复杂，但是总会遇到一些特定环境的问题。下来是我制作的过程（Vagrant1.9+VirutalBox5.1+Centos6.9_i686）。</p>

<p>还有其他的优点：</p>

<ul>
<li>还有配置化后，就可以可以进行版本管理。</li>
<li>分享。</li>
</ul>


<h2>下载安装系统</h2>

<ul>
<li>下载安装 VirtualBox ：<a href="https://www.virtualbox.org/">https://www.virtualbox.org/</a></li>
<li>下载安装 Vagrant ：<a href="http://www.vagrantup.com/">http://www.vagrantup.com/</a></li>
<li>操作系统 <a href="http://mirrors.zju.edu.cn/centos/6.9/isos/i386/">bin-DVD1.iso</a></li>
</ul>


<p>不要安装LiveDVD的版本会把桌面也安装了，系统大几个G，其实用不到图形界面。用DVD的安装没有mininal的系统。</p>

<h2>系统网络</h2>

<p>安装VirutalBox5.1完后，Windows宿主机多了一个 VirtualBox Host-Only Ethernet Adapter 本地网卡，可以先在VirtualBox菜单 [管理-全局设定-网络] 里删除Host-Only Network网卡。</p>

<p>在安装之前需要先了解VirtualBox的网卡的配置，它的选项/含义和VmWare不太一致，需要单独学习了解下：</p>

<ul>
<li>未指定： 相当于虚拟机没有插上网线的情况，此时与宿主机也连不通。</li>
<li>网络地址转换(NAT)：通过NAT转换仅通过HOST主机访问网络，但是访问不到虚拟机（单向的）。需要通过端口转发功能HOST主机才能连接到虚拟机。单机上网最简单的方式。</li>
<li>NAT网络</li>
<li>桥接网卡：虚拟机桥接到宿主机的一块网卡，直接与外部交换数据包，像是不经过宿主机一样。虚拟机能够设置一个独立的IP，所有网络功能完全和在网络中的真实机器一样(通过路由器来自动分配IP地址)。</li>
<li>内部网络：只虚拟机互通的网络。可以相互访问，前提是在设置网络时，两台虚拟机设置同一网络名称。</li>
<li>仅主机(Host-Only)网络：内部网络和桥接模式的混合，需要一个虚拟的网卡来配合。此时虚拟机可以和宿主机及宿主机所在的局域网通信，无法与外网通信。看F1帮助文档里面的，感觉和内部网络差不多，由于HOST主机 多了个网卡可以和HOST通信（通过Host Only网卡的IP），但虚拟机需要上网的话还需要再多配置一个桥接网络。</li>
<li>通用驱动</li>
</ul>


<p>网上的一些资料：</p>

<ul>
<li><a href="http://www.live-in.org/archives/789.html">http://www.live-in.org/archives/789.html</a></li>
<li><a href="https://liuliqiang.info/post/29/">https://liuliqiang.info/post/29/</a> 非常详细</li>
<li><a href="https://www.douban.com/group/topic/15558388/">https://www.douban.com/group/topic/15558388/</a> 和上一篇一样不知道谁抄谁，都看过就列在这里了</li>
<li><a href="https://serverfault.com/questions/225155/virtualbox-how-to-set-up-networking-so-both-host-and-guest-can-access-internet">VirtualBox: How to set up networking so both host and guest can access internet and talk to each other</a> NAT / host only;   use a Bridge Adapter 桥接</li>
<li><a href="https://superuser.com/questions/521072/cant-ping-guest-os-in-virtualbox-but-guests-can-ping-host">Can&rsquo;t ping guest OS in VirtualBox, but guests can ping host</a></li>
</ul>


<h2>配置</h2>

<p>安装系统后默认eth0的网卡是没有启用的。修改网络配置然后重启网络。</p>

<p>如果网卡启动失败，用 ifconfig -a 看看设备是不是eth0。</p>

<p>接下来就是连接系统，然后配置Vagrant了。</p>

<ul>
<li><a href="https://unifreak.github.io/tutorial/Making-my-first-vagrant-box">制作自己第一个 vagrant box</a></li>
<li><a href="http://xuclv.blog.51cto.com/5503169/1239351">如何制作一个vagrant的base box</a></li>
</ul>


<p>为了后面的配置更加顺利，需要先把网络调通。在虚拟机的黑窗口操作是非常不方便的，添加端口转发然后本地用Putty/git-ssh等工具登录系统操作 <a href="https://stackoverflow.com/questions/9885108/ssh-to-vagrant-box-in-windows">SSH to Vagrant box in Windows?</a> 。</p>

<p>接下来按照官网的说明进行配置：</p>

<ul>
<li><a href="https://www.vagrantup.com/docs/boxes/base.html#quot-vagrant-quot-user">https://www.vagrantup.com/docs/boxes/base.html#quot-vagrant-quot-user</a></li>
<li><a href="https://www.vagrantup.com/docs/virtualbox/boxes.html#to-install-via-the-command-line-">https://www.vagrantup.com/docs/virtualbox/boxes.html#to-install-via-the-command-line-</a></li>
<li><a href="https://www.vagrantup.com/docs/virtualbox/boxes.html#virtual-machine">https://www.vagrantup.com/docs/virtualbox/boxes.html#virtual-machine</a></li>
<li><a href="https://www.vagrantup.com/docs/boxes/base.html#testing-the-box">https://www.vagrantup.com/docs/boxes/base.html#testing-the-box</a></li>
</ul>


<p>步骤如下：</p>

<ol>
<li>增加帐号密码均为 vagrant ，root密码也是 vagrant</li>
<li>配置sudo</li>
<li>配置无密钥登录使用密钥进行登录，同时把insecure的 <a href="https://github.com/mitchellh/vagrant/tree/master/keys">vagrant的公钥</a> 写入authorized_key</li>
<li>安装tools</li>
<li>清理yum缓冲，tmp目录下的内容，以及其他的一些临时文件</li>
<li>删掉、禁用虚拟机多余的设备</li>
<li>第一个网卡设置为NAT（用于vagrant的端口转发，并且这网卡要boot启动啊！） <a href="https://www.vagrantup.com/docs/virtualbox/boxes.html#virtual-machine">boxes.html#virtual-machine</a></li>
<li>打包，进入到虚拟机存储的目录(可以通过【设置-高级】的备份位置确定），然后执行 <code>vagrant package --base centos6_i386</code></li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost ~]# passwd
</span><span class='line'>
</span><span class='line'>[root@localhost ~]# useradd vagrant
</span><span class='line'>[root@localhost ~]# passwd vagrant
</span><span class='line'>
</span><span class='line'>[root@localhost ~]# echo 'vagrant ALL=(ALL) NOPASSWD: ALL' &gt;/etc/sudoers
</span><span class='line'>
</span><span class='line'>[root@localhost ~]# su - vagrant
</span><span class='line'>[vagrant@localhost ~]$ mkdir .ssh && chmod 700 .ssh && cd .ssh
</span><span class='line'>[vagrant@localhost .ssh]$ curl https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant.pub -o authorized_keys 
</span><span class='line'>[vagrant@localhost .ssh]$ chmod 600 authorized_keys 
</span></code></pre></td></tr></table></div></figure>


<p>这里单独把安装tools执行的命令抽取出来：</p>

<ul>
<li><a href="https://superuser.com/questions/412527/modprobe-vboxguest-failed">https://superuser.com/questions/412527/modprobe-vboxguest-failed</a> 关键</li>
<li><a href="https://www.if-not-true-then-false.com/2010/install-virtualbox-guest-additions-on-fedora-centos-red-hat-rhel/comment-page-5/#comment-121648">https://www.if-not-true-then-false.com/2010/install-virtualbox-guest-additions-on-fedora-centos-red-hat-rhel/comment-page-5/#comment-121648</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># wget http://download.virtualbox.org/virtualbox/5.1.26/VBoxGuestAdditions_5.1.26.iso
</span><span class='line'>curl -o VBoxGuestAdditions_5.1.26.iso http://download.virtualbox.org/virtualbox/5.1.26/VBoxGuestAdditions_5.1.26.iso
</span><span class='line'>mkdir /media/VBoxGuestAdditions
</span><span class='line'>mount -o loop,ro VBoxGuestAdditions_5.1.26.iso /media/VBoxGuestAdditions
</span></code></pre></td></tr></table></div></figure>


<p>事情总归不会一帆风顺的，依赖需要进行处理，如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@localhost ~]# sh /media/VBoxGuestAdditions/VBoxLinuxAdditions.run 
</span><span class='line'>Verifying archive integrity... All good.
</span><span class='line'>Uncompressing VirtualBox 5.1.26 Guest Additions for Linux...........
</span><span class='line'>VirtualBox Guest Additions installer
</span><span class='line'>Copying additional installer modules ...
</span><span class='line'>Installing additional modules ...
</span><span class='line'>vboxadd.sh: Starting the VirtualBox Guest Additions.
</span><span class='line'>Failed to set up service vboxadd, please check the log file
</span><span class='line'>/var/log/VBoxGuestAdditions.log for details.
</span><span class='line'>[root@localhost ~]# cat /var/log/VBoxGuestAdditions.log
</span><span class='line'>
</span><span class='line'>vboxadd.sh: failed: Look at /var/log/vboxadd-install.log to find out what went wrong.
</span><span class='line'>vboxadd.sh: failed: Look at /var/log/vboxadd-install.log to find out what went wrong.
</span><span class='line'>vboxadd.sh: failed: modprobe vboxguest failed.
</span><span class='line'>[root@localhost ~]# cat /var/log/vboxadd-install.log
</span><span class='line'>/tmp/vbox.0/Makefile.include.header:112: *** Error: unable to find the sources of your current Linux kernel. Specify KERN_DIR=&lt;directory&gt; and run Make again.  Stop.
</span><span class='line'>Creating user for the Guest Additions.
</span><span class='line'>Creating udev rule for the Guest Additions kernel module.
</span><span class='line'>
</span><span class='line'># 处理
</span><span class='line'>[root@localhost ~]# yum install gcc make patch glibc-headers glibc-devel kernel-headers -y 
</span><span class='line'>[root@localhost ~]# yum install kernel-devel # / yum install kernel-devel-2.6.32-696.el6.i686  
</span><span class='line'>[root@localhost ~]# export KERN_DIR=/usr/src/kernels/2.6.32-696.6.3.el6.i686  &lt;- 根据情况改
</span><span class='line'>[root@localhost ~]# sh /media/VBoxGuestAdditions/VBoxLinuxAdditions.run 
</span><span class='line'>Verifying archive integrity... All good.
</span><span class='line'>Uncompressing VirtualBox 5.1.26 Guest Additions for Linux...........
</span><span class='line'>VirtualBox Guest Additions installer
</span><span class='line'>Removing installed version 5.1.26 of VirtualBox Guest Additions...
</span><span class='line'>vboxadd.sh: Stopping VirtualBox Additions.
</span><span class='line'>Copying additional installer modules ...
</span><span class='line'>Installing additional modules ...
</span><span class='line'>vboxadd.sh: Starting the VirtualBox Guest Additions.
</span><span class='line'>
</span><span class='line'>Could not find the X.Org or XFree86 Window System, skipping.
</span></code></pre></td></tr></table></div></figure>


<p>安装配置(jdk/tomcat/mysql/pgsql/redis/&hellip;)好后，打包前清理缓冲：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum clean all
</span><span class='line'>history -c
</span><span class='line'>rm -rf ~/.bash_history
</span><span class='line'>rm -rf /tmp/* /var/log/* /var/cache/*</span></code></pre></td></tr></table></div></figure>


<p>然后打开windows的命令行，进入到虚拟机磁盘文件目录打包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>C:\Users\XXXX\VirtualBox VMs\centos6_i386&gt;vagrant package --base centos6_i386
</span><span class='line'>2017/08/24 07:18:04 launcher: detected 32bit Windows installation
</span><span class='line'>==&gt; centos6_i386: Clearing any previously set forwarded ports...
</span><span class='line'>==&gt; centos6_i386: Exporting VM...
</span><span class='line'>==&gt; centos6_i386: Compressing package to: C:/Users/XXXX/VirtualBox VMs/centos6_i386/package.box
</span></code></pre></td></tr></table></div></figure>


<h2>搭建开发环境</h2>

<ul>
<li><a href="https://blog.smdcn.net/article/1308.html">使用Vagrant在Windows下部署开发环境</a> 非常好的一篇文章</li>
<li><a href="https://blog.codecentric.de/en/2012/02/automated-virtual-test-environments-with-vagrant-and-puppet/">Automated virtual test-environments with Vagrant and Puppet</a></li>
<li><a href="https://favoorr.github.io/2017/01/06/import-vagrant-box-manually/">手工下载和导入 vagrant 镜像</a> 现在下载很快啊，尽管如此也是能学习一种新的备用方法。</li>
</ul>


<h2>实际操作命令</h2>

<h2>重装系统后再绑定</h2>

<p>重新安装后，vagrant和virtualbox在C盘用户目录的文件没有保存。再次启动发现vagrant是去重新启动一个新的虚拟机。</p>

<p>虚拟机嘛，总还是台机器，不会和对待docker那样操作。很多的文件、配置等等还是存储在虚拟机里面的。现在vagrant和virtualbox脱钩了。我们要做的就是把他们再绑定起来:</p>

<ul>
<li>首先启动直接双击box，启动虚拟机。会在用户目录.VirtualBox下面产生/修改VirtualBox.xml，打开文件找到当前虚拟机MachineEntry对应的uuid。</li>
<li>打开原vagrant的目录下 .vagrant\machines\default\virtualbox 的id文件。内容替换为virtualbox的最新的id。</li>
<li>上面的步骤已经把两者关联起来了，但是无密钥登录不行了。需要重新把github上的内容写入到虚拟机用户vagrant的authorzied_key里面。</li>
</ul>


<p>至此，就可以用 vagrant up 启动虚拟机了。还原绑定成功。</p>

<h2>其他</h2>

<ul>
<li><a href="https://github.com/guigarage/vagrant-binding">java invoke vagrant</a></li>
</ul>


<p>vagrant + virtualbox + nginx cache</p>

<ul>
<li><a href="https://stackoverflow.com/questions/9479117/vagrant-virtualbox-apache2-strange-cache-behaviour">https://stackoverflow.com/questions/9479117/vagrant-virtualbox-apache2-strange-cache-behaviour</a></li>
<li><a href="https://github.com/mitchellh/vagrant/issues/351#issuecomment-1339640">https://github.com/mitchellh/vagrant/issues/351#issuecomment-1339640</a></li>
</ul>


<p>vagrant + java deveploe env</p>

<ul>
<li><a href="https://github.com/rob-murray/vagrant-javadev-box/blob/master/Vagrantfile">https://github.com/rob-murray/vagrant-javadev-box/blob/master/Vagrantfile</a> 案例</li>
<li><a href="https://github.com/rob-murray/vagrant-javadev-box/blob/master/puppet/manifests/base.pp">https://github.com/rob-murray/vagrant-javadev-box/blob/master/puppet/manifests/base.pp</a></li>
<li><a href="https://github.com/spanneberg/vagrant-puppet-demo/blob/master/files/my.cnf">https://github.com/spanneberg/vagrant-puppet-demo/blob/master/files/my.cnf</a></li>
<li><a href="https://blog.codecentric.de/en/2012/02/automated-virtual-test-environments-with-vagrant-and-puppet/">https://blog.codecentric.de/en/2012/02/automated-virtual-test-environments-with-vagrant-and-puppet/</a></li>
</ul>


<p>git</p>

<ul>
<li><a href="https://stackoverflow.com/questions/34252265/how-to-start-mingw-console-gitbash-from-command-line-on-windows">https://stackoverflow.com/questions/34252265/how-to-start-mingw-console-gitbash-from-command-line-on-windows</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kubeadm部署k8s(资源已有)]]></title>
    <link href="http://winseliu.com/blog/2017/08/13/kubeadm-install-k8s-on-centos7-with-resources/"/>
    <updated>2017-08-13T00:05:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/13/kubeadm-install-k8s-on-centos7-with-resources</id>
    <content type="html"><![CDATA[<p>上一篇安装的文章这种代理，这种问题显的有点乱。在本机虚拟机安装调通后，今天把测试环境也升级了一下。安装需要的rpm和docker images可以通过百度网盘下载：<a href="http://pan.baidu.com/s/1hrRs5MW">http://pan.baidu.com/s/1hrRs5MW</a> 。</p>

<p>时间同步，主机名，/etc/hosts，防火墙，selinux, 无密钥登录，安装docker-1.12.6 这些都已经配置好了的。</p>

<ul>
<li>机器：cu[1-5]</li>
<li>主节点： cu3</li>
<li>跳板机： cu2（有外网IP）</li>
</ul>


<h2>首先做YUM本地仓库，把镜像导入到node节点</h2>

<p>首先在一台主机上部署YUM本地仓库</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /var/www/html/kubernetes/
</span><span class='line'>[root@cu2 kubernetes]# createrepo .
</span><span class='line'>[root@cu2 kubernetes]# ll
</span><span class='line'>total 42500
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  8974214 Aug 10 15:22 1a6f5f73f43077a50d877df505481e5a3d765c979b89fda16b8b9622b9ebd9a4-kubeadm-1.7.2-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 17372710 Aug 10 15:22 1e508e26f2b02971a7ff5f034b48a6077d613e0b222e0ec973351117b4ff45ea-kubelet-1.7.2-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  9361006 Aug 10 15:22 dc8329515fc3245404fea51839241b58774e577d7736f99f21276e764c309db5-kubectl-1.7.2-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  7800562 Aug 10 15:22 e7a4403227dd24036f3b0615663a371c4e07a95be5fee53505e647fd8ae58aa6-kubernetes-cni-0.5.1-0.x86_64.rpm
</span><span class='line'>drwxr-xr-x 2 root   root       4096 Aug 10 15:58 repodata
</span></code></pre></td></tr></table></div></figure>


<p>（所有node）导入新镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>在cu2上操作，导入docker镜像
</span><span class='line'>
</span><span class='line'>docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>ssh cu1 docker load &lt;/home/hadoop/kubeadm.tar 
</span><span class='line'>ssh cu3 docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>ssh cu4 docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>ssh cu5 docker load &lt;/home/hadoop/kubeadm.tar
</span><span class='line'>
</span><span class='line'>Loaded image: gcr.io/google_containers/etcd-amd64:3.0.17
</span><span class='line'>Loaded image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-controller-manager-amd64:v1.7.2
</span><span class='line'>Loaded image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.4
</span><span class='line'>Loaded image: gcr.io/google_containers/heapster-amd64:v1.3.0
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-scheduler-amd64:v1.7.2
</span><span class='line'>Loaded image: gcr.io/google_containers/heapster-grafana-amd64:v4.4.1
</span><span class='line'>Loaded image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.4
</span><span class='line'>Loaded image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.4
</span><span class='line'>Loaded image: centos:centos6
</span><span class='line'>Loaded image: gcr.io/google_containers/heapster-influxdb-amd64:v1.1.1
</span><span class='line'>Loaded image: gcr.io/google_containers/pause-amd64:3.0
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-apiserver-amd64:v1.7.2
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-proxy-amd64:v1.7.2
</span><span class='line'>Loaded image: quay.io/coreos/flannel:v0.8.0-amd64
</span></code></pre></td></tr></table></div></figure>


<p>YUM仓库配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>在cu2上操作
</span><span class='line'>
</span><span class='line'>cat &gt; /etc/yum.repos.d/dta.repo  &lt;&lt;EOF
</span><span class='line'>[K8S]
</span><span class='line'>name=K8S Local
</span><span class='line'>baseurl=http://cu2:801/kubernetes
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>for h in cu{1,3:5} ; do scp /etc/yum.repos.d/dta.repo $h:/etc/yum.repos.d/ ; done
</span></code></pre></td></tr></table></div></figure>


<h2>安装kubeadm、kubelet</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pdsh -w cu[1-5] "yum clean all; yum install -y kubelet kubeadm; systemctl enable kubelet; systemctl start kubelet "
</span></code></pre></td></tr></table></div></figure>


<p>问题1</p>

<p>启动完以后，查看 /var/log/messages 日志有如下错误：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Aug 12 23:33:38 cu5 kubelet: error: failed to run Kubelet: invalid kubeconfig: stat /etc/kubernetes/kubelet.conf: no such file or directory</span></code></pre></td></tr></table></div></figure>


<p>不用理会啊，继续执行后面的配置（kubeadm才开始配置）。</p>

<h2>使用kubeadm部署集群</h2>

<h4>master节点</h4>

<p>初始化</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16 --kubernetes-version=v1.7.2 </span></code></pre></td></tr></table></div></figure>


<p>启动后会卡在了 <strong> Created API client, waiting for the control plane to become ready </strong> ， 不要关闭当前的窗口。新开一个窗口，查看并定位解决错误：</p>

<p>问题2</p>

<p>新打开一个窗口，查看 /var/log/messages 有如下错误：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Aug 12 23:40:10 cu3 kubelet: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgroupfs"</span></code></pre></td></tr></table></div></figure>


<p>docker和kubelet的cgroup driver不一样，修改kubelet的配置。把docker启动参数 masq 一起改了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# sed -i 's/KUBELET_CGROUP_ARGS=--cgroup-driver=systemd/KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs/' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 
</span><span class='line'>[root@cu3 ~]# sed -i 's#/usr/bin/dockerd.*#/usr/bin/dockerd --ip-masq=false#' /usr/lib/systemd/system/docker.service
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# systemctl daemon-reload; systemctl restart docker kubelet 
</span></code></pre></td></tr></table></div></figure>


<p>多开几个窗口来解决问题，不会影响kubeadm运行的。就是说，由于其他的问题导致kubeadm中间卡住，只要你解决了问题，kubeadm就会继续配置直到成功。</p>

<p>初始化完后，窗口完整日志如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16 --kubernetes-version=v1.7.2 
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[init] Using Kubernetes version: v1.7.2
</span><span class='line'>[init] Using Authorization modes: [Node RBAC]
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
</span><span class='line'>[certificates] Generated CA certificate and key.
</span><span class='line'>[certificates] Generated API server certificate and key.
</span><span class='line'>[certificates] API Server serving cert is signed for DNS names [cu3 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.0.148]
</span><span class='line'>[certificates] Generated API server kubelet client certificate and key.
</span><span class='line'>[certificates] Generated service account token signing key and public key.
</span><span class='line'>[certificates] Generated front-proxy CA certificate and key.
</span><span class='line'>[certificates] Generated front-proxy client certificate and key.
</span><span class='line'>[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>[apiclient] Created API client, waiting for the control plane to become ready
</span><span class='line'> [apiclient] All control plane components are healthy after 494.001036 seconds
</span><span class='line'>[token] Using token: ad430d.beff5be4b98dceec
</span><span class='line'>[apiconfig] Created RBAC rules
</span><span class='line'>[addons] Applied essential addon: kube-proxy
</span><span class='line'>[addons] Applied essential addon: kube-dns
</span><span class='line'>
</span><span class='line'>Your Kubernetes master has initialized successfully!
</span><span class='line'>
</span><span class='line'>To start using your cluster, you need to run (as a regular user):
</span><span class='line'>
</span><span class='line'>  mkdir -p $HOME/.kube
</span><span class='line'>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>You should now deploy a pod network to the cluster.
</span><span class='line'>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
</span><span class='line'>  http://kubernetes.io/docs/admin/addons/
</span><span class='line'>
</span><span class='line'>You can now join any number of machines by running the following on each node
</span><span class='line'>as root:
</span><span class='line'>
</span><span class='line'>  kubeadm join --token ad430d.beff5be4b98dceec 192.168.0.148:6443
</span></code></pre></td></tr></table></div></figure>


<p>然后按照上面的提示，把客户端kubectl要用的配置准备好：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]#   mkdir -p $HOME/.kube
</span><span class='line'>[root@cu3 ~]#   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>[root@cu3 ~]#   sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span></code></pre></td></tr></table></div></figure>


<p>到这里K8S的基础服务controller，apiserver，scheduler是起来了，但是dns还是有问题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 kubeadm]# kubectl get pods --all-namespaces
</span><span class='line'>NAMESPACE     NAME                          READY     STATUS    RESTARTS   AGE
</span><span class='line'>kube-system   etcd-cu3                      1/1       Running   0          6m
</span><span class='line'>kube-system   kube-apiserver-cu3            1/1       Running   0          5m
</span><span class='line'>kube-system   kube-controller-manager-cu3   1/1       Running   0          6m
</span><span class='line'>kube-system   kube-dns-2425271678-wwnkp     0/3       Pending   0          6m
</span><span class='line'>kube-system   kube-proxy-ptnlx              1/1       Running   0          6m
</span><span class='line'>kube-system   kube-scheduler-cu3            1/1       Running   0          6m
</span></code></pre></td></tr></table></div></figure>


<p>dns的容器是使用bridge网络，需要配置网络才能跑起来。有如下错误日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Aug 12 23:54:04 cu3 kubelet: W0812 23:54:04.800316   12886 cni.go:189] Unable to update cni config: No networks found in /etc/cni/net.d
</span><span class='line'>Aug 12 23:54:04 cu3 kubelet: E0812 23:54:04.800472   12886 kubelet.go:2136] Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span></code></pre></td></tr></table></div></figure>


<p>下载 <a href="https://github.com/winse/docker-hadoop/tree/master/kube-deploy/kubeadm">https://github.com/winse/docker-hadoop/tree/master/kube-deploy/kubeadm</a> 目录下的 flannel 配置：</p>

<p>在官网的基础上 cni-conf.json 增加了： <code>"ipMasq": false,</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置网络
</span><span class='line'>[root@cu3 kubeadm]# kubectl apply -f kube-flannel.yml 
</span><span class='line'>kubectl apply -f kube-flannel-rbac.yml 
</span><span class='line'>serviceaccount "flannel" created
</span><span class='line'>configmap "kube-flannel-cfg" created
</span><span class='line'>daemonset "kube-flannel-ds" created
</span><span class='line'>[root@cu3 kubeadm]# kubectl apply -f kube-flannel-rbac.yml 
</span><span class='line'>clusterrole "flannel" created
</span><span class='line'>clusterrolebinding "flannel" created
</span><span class='line'>
</span><span class='line'># 等待一段时间后，dns的pods也启动好了
</span><span class='line'>[root@cu3 kubeadm]# kubectl get pods --all-namespaces
</span><span class='line'>NAMESPACE     NAME                          READY     STATUS    RESTARTS   AGE
</span><span class='line'>kube-system   etcd-cu3                      1/1       Running   0          7m
</span><span class='line'>kube-system   kube-apiserver-cu3            1/1       Running   0          7m
</span><span class='line'>kube-system   kube-controller-manager-cu3   1/1       Running   0          7m
</span><span class='line'>kube-system   kube-dns-2425271678-wwnkp     3/3       Running   0          8m
</span><span class='line'>kube-system   kube-flannel-ds-dbvkj         2/2       Running   0          38s
</span><span class='line'>kube-system   kube-proxy-ptnlx              1/1       Running   0          8m
</span><span class='line'>kube-system   kube-scheduler-cu3            1/1       Running   0          7m</span></code></pre></td></tr></table></div></figure>


<h4>node节点部署</h4>

<p>配置kubelet、docker</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sed -i 's/KUBELET_CGROUP_ARGS=--cgroup-driver=systemd/KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs/' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 
</span><span class='line'>sed -i 's#/usr/bin/dockerd.*#/usr/bin/dockerd --ip-masq=false#' /usr/lib/systemd/system/docker.service 
</span><span class='line'>
</span><span class='line'>systemctl daemon-reload; systemctl restart docker kubelet </span></code></pre></td></tr></table></div></figure>


<p>注意：加了 ip-masq=false 后，docker0就不能上外网了。也就是单独起的docker容器不能上外网！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ExecStart=/usr/bin/dockerd --ip-masq=false</span></code></pre></td></tr></table></div></figure>


<p>加入集群</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubeadm join --token ad430d.beff5be4b98dceec 192.168.0.148:6443 --skip-preflight-checks
</span><span class='line'>
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[discovery] Trying to connect to API Server "192.168.0.148:6443"
</span><span class='line'>[discovery] Created cluster-info discovery client, requesting info from "https://192.168.0.148:6443"
</span><span class='line'>[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.0.148:6443"
</span><span class='line'>[discovery] Successfully established connection with API Server "192.168.0.148:6443"
</span><span class='line'>[bootstrap] Detected server version: v1.7.2
</span><span class='line'>[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
</span><span class='line'>[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
</span><span class='line'>[csr] Received signed certificate from the API server, generating KubeConfig...
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>
</span><span class='line'>Node join complete:
</span><span class='line'>* Certificate signing request sent to master and response
</span><span class='line'>  received.
</span><span class='line'>* Kubelet informed of new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the master to see this machine join.</span></code></pre></td></tr></table></div></figure>


<p>CU2是跳板机，把kubectl的config配置拷贝过来，然后就可以在CU2上面运行命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# kubectl get nodes
</span><span class='line'>NAME      STATUS     AGE         VERSION
</span><span class='line'>cu2       NotReady   &lt;invalid&gt;   v1.7.2
</span><span class='line'>cu3       Ready      25m         v1.7.2
</span><span class='line'>
</span><span class='line'>[root@cu2 kube-deploy]# kubectl proxy 
</span><span class='line'>Starting to serve on 127.0.0.1:8001</span></code></pre></td></tr></table></div></figure>


<p>我代理做在这台机器啊 <a href="http://localhost:8001/ui">http://localhost:8001/ui</a>。。。咔咔</p>

<p>5台机器都添加后：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 ~]# kubectl get nodes 
</span><span class='line'>NAME      STATUS    AGE       VERSION
</span><span class='line'>cu1       Ready     32s       v1.7.2
</span><span class='line'>cu2       Ready     3m        v1.7.2
</span><span class='line'>cu3       Ready     29m       v1.7.2
</span><span class='line'>cu4       Ready     26s       v1.7.2
</span><span class='line'>cu5       Ready     20s       v1.7.2</span></code></pre></td></tr></table></div></figure>


<p>节点防火墙(由于是云主机，增加防火墙)：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent 
</span><span class='line'>firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent 
</span><span class='line'>firewall-cmd --complete-reload</span></code></pre></td></tr></table></div></figure>


<h2>SOURCE IP测试</h2>

<p>Sourceip的问题应该不存在。。。看了iptables-save的信息，没有cni0/cbr0的相关的数据</p>

<p>还是再来测一遍：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl run centos --image=cu.eshore.cn/library/java:jdk8 --command -- vi 
</span><span class='line'>kubectl scale --replicas=4 deployment/centos
</span><span class='line'>
</span><span class='line'>[root@cu2 kube-deploy]# pods
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE         IP              NODE
</span><span class='line'>default       centos-3954723268-62tpc                 1/1       Running   0          &lt;invalid&gt;   10.244.2.2      cu1
</span><span class='line'>default       centos-3954723268-6cmf9                 1/1       Running   0          &lt;invalid&gt;   10.244.1.2      cu2
</span><span class='line'>default       centos-3954723268-blfc4                 1/1       Running   0          &lt;invalid&gt;   10.244.3.2      cu4
</span><span class='line'>default       centos-3954723268-tb1rn                 1/1       Running   0          &lt;invalid&gt;   10.244.4.2      cu5
</span><span class='line'>default       nexus-djr9c                             1/1       Running   0          2m          192.168.0.37    cu1
</span><span class='line'>
</span><span class='line'># ping互通没问题 TEST
</span><span class='line'>
</span><span class='line'>[root@cu2 hadoop]# ./pod_bash centos-3954723268-62tpc default
</span><span class='line'>[root@centos-3024873821-4490r /]# ping 10.244.4.2 -c 1
</span><span class='line'>
</span><span class='line'># 源IP没问题 TEST
</span><span class='line'>
</span><span class='line'>[root@centos-3954723268-62tpc opt]# yum install epel-release -y  
</span><span class='line'>[root@centos-3954723268-62tpc opt]# yum install -y nginx 
</span><span class='line'>[root@centos-3954723268-62tpc opt]# service nginx start
</span><span class='line'>
</span><span class='line'>[root@centos-3954723268-blfc4 opt]# curl 10.244.2.2
</span><span class='line'>[root@centos-3954723268-tb1rn opt]# curl 10.244.2.2
</span><span class='line'>
</span><span class='line'>[root@centos-3954723268-62tpc opt]# less /var/log/nginx/access.log 
</span></code></pre></td></tr></table></div></figure>


<h4>DNS</h4>

<p>奇了怪了，这次重新安装DNS是没问题的，heaspter安装一次通过。</p>

<p>在cu3起的pods上执行 <code>nslookup kubernetes.default</code> 也是通的！</p>

<h4>监控</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># heaspter
</span><span class='line'>[root@cu2 kubeadm]# kubectl apply -f heapster/influxdb/
</span><span class='line'>deployment "monitoring-grafana" created
</span><span class='line'>service "monitoring-grafana" created
</span><span class='line'>serviceaccount "heapster" created
</span><span class='line'>deployment "heapster" created
</span><span class='line'>service "heapster" created
</span><span class='line'>deployment "monitoring-influxdb" created
</span><span class='line'>service "monitoring-influxdb" created
</span><span class='line'>[root@cu2 kubeadm]# kubectl apply -f heapster/rbac/
</span><span class='line'>clusterrolebinding "heapster" created
</span><span class='line'>
</span><span class='line'># dashboard
</span><span class='line'>[root@cu2 kubeadm]# kubectl apply -f kubernetes-dashboard.yaml 
</span><span class='line'>serviceaccount "kubernetes-dashboard" created
</span><span class='line'>clusterrolebinding "kubernetes-dashboard" created
</span><span class='line'>deployment "kubernetes-dashboard" created
</span><span class='line'>service "kubernetes-dashboard" created
</span><span class='line'>
</span><span class='line'>[root@cu2 kubeadm]# kubectl get service --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1       &lt;none&gt;        443/TCP         18m
</span><span class='line'>kube-system   kube-dns               10.96.0.10      &lt;none&gt;        53/UDP,53/TCP   18m
</span><span class='line'>kube-system   kubernetes-dashboard   10.104.165.81   &lt;none&gt;        80/TCP          5m</span></code></pre></td></tr></table></div></figure>


<p>等一小段时间，查看所有的服务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubeadm]# kubectl get services --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1        &lt;none&gt;        443/TCP         2h
</span><span class='line'>kube-system   heapster               10.102.176.168   &lt;none&gt;        80/TCP          3m
</span><span class='line'>kube-system   kube-dns               10.96.0.10       &lt;none&gt;        53/UDP,53/TCP   2h
</span><span class='line'>kube-system   kubernetes-dashboard   10.110.2.118     &lt;none&gt;        80/TCP          2m
</span><span class='line'>kube-system   monitoring-grafana     10.106.251.155   &lt;none&gt;        80/TCP          3m
</span><span class='line'>kube-system   monitoring-influxdb    10.100.168.147   &lt;none&gt;        8086/TCP        3m</span></code></pre></td></tr></table></div></figure>


<p>直接访问 10.106.251.155 或者查看 monitoring的pod 日志，查看heaspter的状态。dashboard上面出图要等一小段时间才行。</p>

<p>如果通过 monitoring-grafana 的IP访问能看到CLUSTER和POD的监控图，但是dashboard上的图就是出不来，可以重新部署dashboard：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl delete -f kubernetes-dashboard.yaml 
</span><span class='line'>kubectl create -f kubernetes-dashboard.yaml </span></code></pre></td></tr></table></div></figure>


<p>到此整个K8S就在测试环境上重新运行起来了。harbor就不安装了，平时没怎么用，也就5台机器直接save然后load工作量也不多。</p>

<h2>参考</h2>

<ul>
<li><a href="https://github.com/kubernetes/kubernetes/issues/40969">https://github.com/kubernetes/kubernetes/issues/40969</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzI4MTQyMDAxMA==&amp;mid=2247483665&amp;idx=1&amp;sn=d8b61666fe0a0965336d15250e2648cb&amp;scene=0">http://mp.weixin.qq.com/s?__biz=MzI4MTQyMDAxMA==&amp;mid=2247483665&amp;idx=1&amp;sn=d8b61666fe0a0965336d15250e2648cb&amp;scene=0</a></li>
<li><a href="http://cizixs.com/2017/05/23/container-network-cni">http://cizixs.com/2017/05/23/container-network-cni</a></li>
<li><a href="https://github.com/containernetworking/cni/blob/master/SPEC.md#network-configuration">https://github.com/containernetworking/cni/blob/master/SPEC.md#network-configuration</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[保护/加密JAVA代码]]></title>
    <link href="http://winseliu.com/blog/2017/08/09/java-bytecode-security/"/>
    <updated>2017-08-09T18:10:39+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/09/java-bytecode-security</id>
    <content type="html"><![CDATA[<p>由于Java代码生成的是中间过程字节码，javap以及一些反编译的工具基本能看代码的大概，对于提供给客户的代码需要做一些处理：混淆或者加密。下面分几块把在实际操作过程中参考的内容罗列出来，希望对看到本文并感兴趣的你有所帮助。</p>

<h2>自定义ClassLoader</h2>

<p>混淆+ClassLoader</p>

<ul>
<li><a href="http://www.voidcn.com/blog/zmx729618/article/p-4375840.html">java源代码加密+使用proguard混淆java web项目代码+自定义Classloader</a> 思路不错</li>
</ul>


<p>自定义ClassLoader并用Java实现解密</p>

<ul>
<li><a href="http://www.aspphp.online/bianchen/java/gyjava/201701/112687.html">利用DES加密的算法保護Java源代碼</a> 为啥要加密，以及一般的保护措施（混淆、加密盘、自定义classloader）。实现有点low，用Java写的加密人家调试下就全部请求怎么弄的了。</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-secureclass/index.html">运用加密技术保护Java源代码</a> Java实现加解密通过自定义classloader。2001年的文章啊，牛逼</li>
<li><a href="http://blog.csdn.net/dianacody/article/details/38585209">Java代码加密与反编译（二）：用加密算法DES修改classLoader实现对.class文件加密</a> 有点实践了上一篇ibm文章的意思。</li>
</ul>


<p>自定义ClassLoader（jvmti）用C++实现解密</p>

<ul>
<li><a href="https://wenku.baidu.com/view/587af93767ec102de2bd892c.html">ClassLoader加密技术改进研究pdf</a> 理论派。classloader的实现用C++写（loadClass用JNI实现），但是还是需要对原有代码进行一定的修改</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-protectjava/index.html">如何有效的保护 JAVA 程序</a> 这种ClassLoader加密实现有点复杂了，还改java.c的loadClass？2002年的文章啊：解决了 ClassLoader 本身的安全性，其不失为一个比较好安全方案。</li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/]%20%E9%9D%9E%E5%B8%B8%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E4%B8%80%E7%AF%87%E3%80%82%E8%AE%B2%E4%BA%86%E8%87%AA%E5%AE%9A%E4%B9%89classloader%E5%92%8Cjvmti%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%8F%90%E4%BE%9B%E4%BA%86%E6%BA%90%E7%A0%81%E5%B7%A5%E7%A8%8B[JarEncrypt](https://github.com/AloneMonkey/JarEncrypt">jar包加密保护解决方案</a>，参考。</li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a> 用jvmti来实现加解密，牛逼的一篇文章啊！一步步按他的操作可以实现，还附有源码，参考。</li>
</ul>


<p>其他一些</p>

<ul>
<li><a href="http://cjnetwork.iteye.com/blog/851544#bc1819690">java源程序加密解决方案(基于Classloader解密)</a> 本身是一篇很棒的文章，多重加密保障ClassLoader安全。又有大神的回复：java的class加密都可以通过dumpclass来还原出来，囧</li>
<li><a href="http://rednaxelafx.iteye.com/blog/727938">如何dump出一个Java进程里的类对应的Class文件？</a> 大神的sun.jvm.hotspot.tools.jcore.ClassDump文章，只要知道类名就无敌了啊</li>
</ul>


<h2>JNI</h2>

<p>javah</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">Calling native functions from Java with JNI and Maven</a> maven搭建native的环境，整体的结构很值得学习</li>
<li><a href="http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html">http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html</a> maven native插件</li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a> 从生成.h到最后打包一条龙，值得学习。</li>
</ul>


<p>环境部署及入门</p>

<ul>
<li><a href="http://blog.csdn.net/ididcan/article/details/6828982">JNI简单实现Java调用C++/C的HelloWorld</a> 搭开发环境的时刻，可以按照步骤一步步来</li>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a> 直接VS建空项目，不错。思路清晰。中文入门不二之选！</li>
<li><a href="http://www.javamex.com/tutorials/jni/getting_started.shtml">Getting started with JNI</a> 需要小翻个墙啊，有介绍Additional Include Directories的方式配置java的头文件。</li>
<li><a href="https://www.ibm.com/developerworks/java/tutorials/j-jni/j-jni.html">Java programming with JNI</a> 了解JNI没有比这篇更好的文章了，即介绍了java调c++，又介绍了c++调用java。</li>
<li><a href="http://tinggo.iteye.com/blog/1185551">VS项目配置详解</a> VS预定义头：DEBUG，RELEASE的一些头可以定义在配置里面。有点像makefile里面决定打什么版本。</li>
</ul>


<p>配jni.h的 附加目录 的时刻，需要选择 配置 和 平台 的配置！！需要对应好！ jni的.h文件需要放到c++的项目下面去，引用外部的好像找不到，有问题。</p>

<p>java与c++类型之间的转换</p>

<ul>
<li><a href="https://stackoverflow.com/questions/8439233/how-to-convert-jbytearray-to-native-char-in-jni">How to convert jbyteArray to native char* in jni?</a></li>
<li><a href="https://stackoverflow.com/questions/12854333/jni-in-c-to-read-file-to-jbytearray">JNI in C++ to read file to jbyteArray</a></li>
</ul>


<p>JNI调用C++的加密算法</p>

<ul>
<li><a href="http://blog.csdn.net/wtbee/article/details/11658017">Java实现DES对称加密算法（附Android下3DES的JNI源码）</a> 有简单介绍DES的只是。中间换成过他的DES的实现，但是感觉怪怪的，有点不太靠谱。后面换成OPENSSL了。</li>
<li><a href="http://www.cnblogs.com/kolin/p/4256614.html">JNI调用c++实现AES加密解密</a> android的，用的应该也是OPENSSL。可以参考过程</li>
</ul>


<h2>OPENSSL</h2>

<ul>
<li><a href="http://www.qmailer.net/archives/183.html">OpenSSL编程-对称加密及DES/3DES简介</a> 简单的介绍</li>
<li><a href="http://blog.csdn.net/duanxingheng/article/details/11655037">OPENSSL库的使用-DES篇</a> 看看算法还可以。算法介绍，有对OPENSSL DES库的介绍和使用</li>
<li><a href="https://www.madboa.com/geek/openssl/">OpenSSL Command-Line</a></li>
<li><a href="http://www.cnblogs.com/gordon0918/p/5317701.html">openssl 对称加密算法enc命令详解</a> 命令行的使用</li>
<li><a href="https://www.slideshare.net/guanzhi/crypto-with-openssl">https://www.slideshare.net/guanzhi/crypto-with-openssl</a></li>
<li><a href="http://www.linuxjournal.com/article/4822">An Introduction to OpenSSL Programming</a> 2001年的太老了，留个纪念。</li>
</ul>


<p>WINDOWS安装/编译安装OPENSSL然后在VS里面应用：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio">https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio</a></li>
<li><a href="https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012">https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012</a></li>
<li><a href="https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64">https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64</a></li>
<li><a href="http://slproweb.com/products/Win32OpenSSL.html">http://slproweb.com/products/Win32OpenSSL.html</a></li>
</ul>


<p>NuGet安装OpenSSL on VS2015-1.0.2版本：（我用的这种方式）</p>

<ul>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a> VS2015 安装openssl v1.0.2 才有v140的include。 v1.0.2.1安装不了，参考。</li>
</ul>


<p>GCC</p>

<ul>
<li><a href="https://stackoverflow.com/questions/1894013/how-to-use-openssl-in-gcc">How to use OpenSSL in GCC?</a> 加依赖: -L/usr/lib -lssl -lcrypto -o server</li>
</ul>


<p>DES</p>

<ul>
<li><a href="https://my.oschina.net/mawx/blog/85424">https://my.oschina.net/mawx/blog/85424</a> Java DESede用C++ Openssl实现 参考下他的链接</li>
<li><a href="http://www.open-open.com/solution/view/1320502797546">http://www.open-open.com/solution/view/1320502797546</a> Java与C++通过DES、blowfish互相加解密</li>
<li><a href="http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs">http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs</a> OpenSSL DES APIs</li>
</ul>


<p>AES</p>

<ul>
<li><a href="https://www.lovelucy.info/openssl-aes-encryption.html">AES加密和解密——使用openssl编程</a> 参考他的makefile。AES用的是OPENSSL，写的中规中矩</li>
<li><a href="http://www.cnblogs.com/luop/p/4334160.html">密码算法详解——AES</a></li>
<li><a href="http://www.ssdfans.com/?p=238">AES加密算法图解</a> flash动画很赞</li>
<li><a href="http://yuanshuilee.blog.163.com/blog/static/21769727520140942826137/">openssl之aes加密（AES_cbc_encrypt 与 AES_encrypt 的编程案例）</a> 很棒的一篇，参考。</li>
<li><a href="https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/">https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/</a> 高级加密标准AES的工作模式（ECB、CBC、CFB、OFB），还有接口的介绍，非常好的一篇文章</li>
</ul>


<p>AES CBC 相互加解密 Java/PHP/C++ java和c++加解密，互通</p>

<ul>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a> 非常牛逼的一篇，参考。</li>
<li><a href="http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html">http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html</a> Java和C/C++进行DES/AES密文传输</li>
<li><a href="https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl">https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl</a></li>
<li><a href="https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent">https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent</a></li>
<li><a href="http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html">http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html</a> DES 算法的 C++ 与 JAVA 互相加解密</li>
<li><a href="http://juliusdavies.ca/commons-ssl/pbe.html">OpenSSL&rsquo;s &ldquo;enc&rdquo; in Java (PBE / Password Based Encryption)</a></li>
<li><a href="http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html">http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html</a></li>
<li><p><a href="https://ruby-china.org/topics/26490">https://ruby-china.org/topics/26490</a></p></li>
<li><p><a href="https://shanetully.com/2012/06/openssl-rsa-aes-and-c/">OpenSSL, RSA, AES and C++</a> 好鬼长复杂没怎么看，搜AES找到了。</p></li>
</ul>


<h4>OPENSSL MD5： VS + GCC + JAVA + 命令行</h4>

<ul>
<li><a href="http://www.askyb.com/cpp/openssl-md5-hashing-example-in-cpp/">OpenSSL MD5 Hashing Example in C++</a></li>
<li><a href="https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash">https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash</a> LINUX命令行</li>
<li><a href="https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal">https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal</a> md5sum</li>
<li><a href="https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files">https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files</a> 循环算一个目录下文件的MD5</li>
<li><a href="https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC">https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC</a> OPENSSL各种算法的使用</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># SHA256, used in chef cookbooks
</span><span class='line'>openssl dgst -sha256 path/to/myfile
</span><span class='line'># MD5
</span><span class='line'>openssl dgst -md5 path/to/myfile
</span><span class='line'>echo -n 'text to be encrypted' | md5sum -
</span><span class='line'>$ echo -n 123456 | md5sum | awk '{print $1}'
</span><span class='line'>$ echo -n Welcome | md5sum
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# gcc -Wall -lcrypto -lssl opensslmd5.cpp -o md5
</span><span class='line'>[root@cu2 ~]# ./md5
</span><span class='line'>md5 digest: 56ab24c15b72a457069c5ea42fcfc640
</span></code></pre></td></tr></table></div></figure>


<p>makefile</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CC=g++
</span><span class='line'>CFLAGS=-Wall -g -O2
</span><span class='line'>LIBS=-lcrypto
</span><span class='line'>
</span><span class='line'>all: aes
</span><span class='line'>
</span><span class='line'>aes: aes.cc
</span><span class='line'>    $(CC) $(CFLAGS) aes.cc -o $@ $(LIBS)
</span><span class='line'>
</span><span class='line'>clean:
</span><span class='line'>    @rm -f aes
</span></code></pre></td></tr></table></div></figure>


<h4>OPENSSL命令行</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>openssl des3 -nosalt -k abc123 -in file.txt -out file.des3 #不加盐，key为abc123来加密
</span><span class='line'>openssl des3 -d -nosalt -in file.des3 -out f.txt -k abc123#解密
</span><span class='line'>
</span><span class='line'>默认是-salt，加盐的，如果不加盐，则根据pass生成的key和iv不变，例：
</span><span class='line'>
</span><span class='line'>You can get openssl to base64-encode the message by using the -a
</span><span class='line'>stefano:~$ openssl aes-256-cbc -in attack-plan.txt -a
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -a -salt -k abcdefghijklmnop
</span><span class='line'>[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -k abcdefghijklmnop |  openssl aes-128-cbc -d -k abcdefghijklmnop
</span></code></pre></td></tr></table></div></figure>


<h2>其他</h2>

<p>SHELL二进制编码：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script">https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script</a> hexdump</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>el@defiant ~ $ printf '%x\n' 26
</span><span class='line'>el@defiant ~ $ echo $((0xAA))
</span><span class='line'>printf -v result1 "%x" "$decimal1"
</span><span class='line'>% xxd -l 16 -p /dev/random
</span><span class='line'>193f6c54814f0576bc27d51ab39081dc
</span><span class='line'>$ echo -n $'\x12\x34' | xxd -p
</span><span class='line'>
</span><span class='line'>$ echo -n $'\x12\x34' | hexdump -e '"%x"'
</span><span class='line'>
</span><span class='line'>od -vt x1|awk '{$1="";print}'
</span><span class='line'>echo "obase=16; 34" | bc
</span></code></pre></td></tr></table></div></figure>


<p>c++命令行不直接关闭。。。最后用断点的方式替代了，没找到好的方法！！</p>

<p>文件读写</p>

<ul>
<li><a href="http://blog.csdn.net/lightlater/article/details/6364931">C++读写二进制文件</a></li>
<li><a href="http://blog.csdn.net/guyue6670/article/details/6681037">fopen中w w+ wb区别</a> 人家代码写的是w+，加密class后多了0D。后面问了搞C的同事才知道二进制要用wb，C就是一堆坑啊！</li>
</ul>


<p>g++</p>

<ul>
<li><a href="https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope">https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope</a> snprintf</li>
</ul>


<p>git</p>

<ul>
<li><a href="https://git-scm.com/docs/git-archive">https://git-scm.com/docs/git-archive</a> GIT打包</li>
</ul>


<h2>重要的参考文章再列一遍</h2>

<ul>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a></li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/">jar包加密保护解决方案</a> 源码<a href="https://github.com/AloneMonkey/JarEncrypt">JarEncrypt</a></li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a></li>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a></li>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a></li>
</ul>


<p>TODO 编译打包</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">http://www.tricoder.net/blog/?p=197</a></li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NFS on Centos7]]></title>
    <link href="http://winseliu.com/blog/2017/08/05/nfs-on-centos7/"/>
    <updated>2017-08-05T08:38:56+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/05/nfs-on-centos7</id>
    <content type="html"><![CDATA[<h2>参考</h2>

<ul>
<li><a href="https://www.howtoforge.com/nfs-server-and-client-on-centos-7">https://www.howtoforge.com/nfs-server-and-client-on-centos-7</a></li>
<li><a href="http://blog.huatai.me/2014/10/14/CentOS-7-NFS-Server-and-Client-Setup/">http://blog.huatai.me/2014/10/14/CentOS-7-NFS-Server-and-Client-Setup/</a></li>
</ul>


<h2>指令</h2>

<p>安装</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 data]# yum install nfs-utils -y 
</span><span class='line'>[root@cu3 data]# chmod -R 777 /data/k8s-dta
</span><span class='line'>
</span><span class='line'>systemctl enable rpcbind
</span><span class='line'>systemctl enable nfs-server
</span><span class='line'>systemctl enable nfs-lock
</span><span class='line'>systemctl enable nfs-idmap
</span><span class='line'>
</span><span class='line'>systemctl start rpcbind
</span><span class='line'>systemctl start nfs-server
</span><span class='line'>systemctl start nfs-lock
</span><span class='line'>systemctl start nfs-idmap</span></code></pre></td></tr></table></div></figure>


<p>配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 data]# vi /etc/exports
</span><span class='line'>/data/k8s-dta 192.168.0.0/24(rw,sync,no_root_squash,no_all_squash)
</span></code></pre></td></tr></table></div></figure>


<p>说明：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/data/k8s-dta – 共享目录
</span><span class='line'>192.168.0.0/24 – 允许访问NFS的客户端IP地址段
</span><span class='line'>rw – 允许对共享目录进行读写
</span><span class='line'>sync – 实时同步共享目录
</span><span class='line'>no_root_squash – 允许root访问
</span><span class='line'>no_all_squash - 允许用户授权
</span><span class='line'>no_subtree_check - 如果卷的一部分被输出，从客户端发出请求文件的一个常规的调用子目录检查验证卷的相应部分。如果是整个卷输出，禁止这个检查可以加速传输。
</span><span class='line'>no_subtree_check - If only part of a volume is exported, a routine called subtree checking verifies that a file that is requested from the client is in the appropriate part of the volume. If the entire volume is exported, disabling this check will speed up transfers. Setting Up an NFS Server
</span></code></pre></td></tr></table></div></figure>


<p>然后重启服务，并开放防火墙（或者关闭）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>systemctl restart nfs-server
</span><span class='line'>
</span><span class='line'>firewall-cmd --permanent --zone=public --add-service=ssh
</span><span class='line'>firewall-cmd --permanent --zone=public --add-service=nfs
</span><span class='line'>firewall-cmd --reload</span></code></pre></td></tr></table></div></figure>


<h2>客户端配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 opt]# yum install -y nfs-utils
</span><span class='line'>
</span><span class='line'>[root@cu2 opt]# mount cu3:/data/k8s-dta dta
</span><span class='line'>[root@cu2 opt]# touch dta/abc
</span><span class='line'>[root@cu2 opt]# ll dta
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Aug  3  2017 abc
</span><span class='line'>
</span><span class='line'>[root@cu3 data]# ll k8s-dta/
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Aug  3 15:19 abc</span></code></pre></td></tr></table></div></figure>


<h2>后记</h2>

<p>建好NFS服务后，可以把它作为k8s容器的存储，这样就不怕丢数据了。</p>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#writing-to-stable-storage">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#writing-to-stable-storage</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs">https://kubernetes.io/docs/concepts/storage/volumes/#nfs</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/master/examples/volumes/nfs">https://github.com/kubernetes/kubernetes/tree/master/examples/volumes/nfs</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encfs加密文件系统]]></title>
    <link href="http://winseliu.com/blog/2017/08/05/encfs-secure-filesystem/"/>
    <updated>2017-08-05T02:55:57+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/05/encfs-secure-filesystem</id>
    <content type="html"><![CDATA[<p>为了数据安全，最近领导给了个链接让去了解了解 <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-ecryptfs/">eCryptfs</a> 。通过yum和自己手动编译安装后都运行失败，系统的<a href="http://centosfaq.org/centos/about-ecryptfs-utils/#comment-110110">Centos7内核不支持ecryptfs模块</a> 。</p>

<p>通过一个介绍ecryptfs的<a href="https://linux.cn/article-4470-1.html">关联的链接</a> 了解到 <a href="http://www.arg0.net/encfs">encfs</a> 也是做 ecryptfs 类似的事情。然后就去下载安装，最后发现windows下面也可以用（惊喜）。</p>

<p>epel下面已经发布了 encfs 的rpm包。现在只要是仓库有的包就不自己编译（进行过N次升级的洗礼，最终发现yum、rpm才是最终归宿啊）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install fuse 
</span><span class='line'>[root@k8s ~]# yum install encfs
</span><span class='line'>
</span><span class='line'>挂载、创建
</span><span class='line'>[root@k8s shm]# encfs /dev/shm/.test /dev/shm/test
</span><span class='line'>The directory "/dev/shm/.test/" does not exist. Should it be created? (y,n) y
</span><span class='line'>The directory "/dev/shm/test/" does not exist. Should it be created? (y,n) y
</span><span class='line'>Creating new encrypted volume.
</span><span class='line'>Please choose from one of the following options:
</span><span class='line'> enter "x" for expert configuration mode,
</span><span class='line'> enter "p" for pre-configured paranoia mode,
</span><span class='line'> anything else, or an empty line will select standard mode.
</span><span class='line'>?&gt;
</span><span class='line'>
</span><span class='line'>Standard configuration selected.
</span><span class='line'>
</span><span class='line'>Configuration finished.  The filesystem to be created has
</span><span class='line'>the following properties:
</span><span class='line'>Filesystem cipher: "ssl/aes", version 3:0:2
</span><span class='line'>Filename encoding: "nameio/block", version 4:0:2
</span><span class='line'>Key Size: 192 bits
</span><span class='line'>Block Size: 1024 bytes
</span><span class='line'>Each file contains 8 byte header with unique IV data.
</span><span class='line'>Filenames encoded using IV chaining mode.
</span><span class='line'>File holes passed through to ciphertext.
</span><span class='line'>
</span><span class='line'>Now you will need to enter a password for your filesystem.
</span><span class='line'>You will need to remember this password, as there is absolutely
</span><span class='line'>no recovery mechanism.  However, the password can be changed
</span><span class='line'>later using encfsctl.
</span><span class='line'>
</span><span class='line'>New Encfs Password: 123456
</span><span class='line'>Verify Encfs Password:
</span><span class='line'>
</span><span class='line'>[root@k8s shm]# echo $(hostname) &gt; test/hostname.txt
</span><span class='line'>[root@k8s shm]# ll -R -a
</span><span class='line'>.:
</span><span class='line'>total 0
</span><span class='line'>drwxrwxrwt.  4 root root   80 Aug  4 22:04 .
</span><span class='line'>drwxr-xr-x. 20 root root 3260 Aug  4 21:16 ..
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 test
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 .test
</span><span class='line'>
</span><span class='line'>./test:
</span><span class='line'>total 4
</span><span class='line'>drwx------. 2 root root 80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root 80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root  4 Aug  4 22:06 hostname.txt
</span><span class='line'>
</span><span class='line'>./.test:
</span><span class='line'>total 8
</span><span class='line'>drwx------. 2 root root   80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root   80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root 1263 Aug  4 22:04 .encfs6.xml
</span><span class='line'>-rw-r--r--. 1 root root   12 Aug  4 22:06 pAqhW671kQSK4kPLJM-TF6sp
</span><span class='line'>
</span><span class='line'>卸载
</span><span class='line'>[root@k8s shm]# fusermount -u test
</span><span class='line'>[root@k8s shm]# ll -R -a
</span><span class='line'>.:
</span><span class='line'>total 0
</span><span class='line'>drwxrwxrwt.  4 root root   80 Aug  4 22:04 .
</span><span class='line'>drwxr-xr-x. 20 root root 3260 Aug  4 21:16 ..
</span><span class='line'>drwx------.  2 root root   40 Aug  4 22:04 test
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 .test
</span><span class='line'>
</span><span class='line'>./test:
</span><span class='line'>total 0
</span><span class='line'>drwx------. 2 root root 40 Aug  4 22:04 .
</span><span class='line'>drwxrwxrwt. 4 root root 80 Aug  4 22:04 ..
</span><span class='line'>
</span><span class='line'>./.test:
</span><span class='line'>total 8
</span><span class='line'>drwx------. 2 root root   80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root   80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root 1263 Aug  4 22:04 .encfs6.xml
</span><span class='line'>-rw-r--r--. 1 root root   12 Aug  4 22:06 pAqhW671kQSK4kPLJM-TF6sp
</span></code></pre></td></tr></table></div></figure>


<p>注意: 最好将 .encfs6.xml 备份起來, 这个文件损坏或丢失将无法还原加密的文件。</p>

<p>把加密的文件备份到云盘，然后本地挂载就能看到原始内容了。安全的云盘就这么简单的实现了，咔咔。。。</p>

<p>在windows安装 <a href="https://encfsmp.sourceforge.io/download.html">EncFSMP</a> 就可以和在Linux上面一样操作encfs文件系统了。</p>

<blockquote><p>EncFS从原理不同TrueCrypt的容器 ，它存储在一个单一的大文件的加密文件。 相反，EncFS为您添加的每个文件创建单独的文件。 它更好地与云存储服务，每次更改时重新上传整个TrueCrypt容器。</p></blockquote>

<h2>参考链接</h2>

<ul>
<li><a href="http://www.arg0.net/encfs">http://www.arg0.net/encfs</a></li>
<li><a href="https://linux.cn/article-4470-1.html">https://linux.cn/article-4470-1.html</a> 通过这篇文章查看到了encfs</li>
<li><a href="https://github.com/vgough/encfs/blob/master/INSTALL.md">https://github.com/vgough/encfs/blob/master/INSTALL.md</a> 编译安装</li>
<li><a href="http://www.vonwei.com/post/introduceToEncFS.html">http://www.vonwei.com/post/introduceToEncFS.html</a> 中文简单介绍和入门。手动编译，命令的参数也有介绍，还有介绍加密目录的 .encfs6.xml</li>
<li><a href="https://github.com/vgough/encfs/blob/master/encfs/encfs.pod#examples">https://github.com/vgough/encfs/blob/master/encfs/encfs.pod#examples</a></li>
<li><a href="https://github.com/vgough/encfs/blob/master/encfs/encfsctl.pod">https://github.com/vgough/encfs/blob/master/encfs/encfsctl.pod</a></li>
<li><p><a href="https://www.howtoip.com/how-to-encrypt-cloud-storage-on-linux-and-windows-with-encfs/">https://www.howtoip.com/how-to-encrypt-cloud-storage-on-linux-and-windows-with-encfs/</a>  非常棒的教程，linux和windows都介绍了</p></li>
<li><p><a href="http://www.jianshu.com/p/073957902fa9">http://www.jianshu.com/p/073957902fa9</a> 手动编译，以后可能用得到。最后的启动自动加载磁盘可以借鉴。</p></li>
<li><a href="https://github.com/vgough/encfs/issues/66">https://github.com/vgough/encfs/issues/66</a>  encfs on cygwin</li>
<li><a href="https://superuser.com/questions/179150/reading-an-encfs-volume-from-windows">https://superuser.com/questions/179150/reading-an-encfs-volume-from-windows</a></li>
<li><a href="https://encfsmp.sourceforge.io/download.html">https://encfsmp.sourceforge.io/download.html</a> for windows</li>
<li><a href="https://github.com/dokan-dev/dokany">https://github.com/dokan-dev/dokany</a> fuse on windows</li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kubeadm部署kubernetes]]></title>
    <link href="http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/"/>
    <updated>2017-07-30T12:18:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7</id>
    <content type="html"><![CDATA[<p>官网文档差，删文档倒是不手软。使用脚本启动、安装的文档（docker-multinode）已经删掉了，现在都推荐使用kubeadm来进行安装。</p>

<p>本文使用代理在master上安装并缓冲rpm、以及下载docker镜像，然后做本地YUM仓库和拷贝镜像到其他worker节点的方式来部署集群。下一篇再介绍在拥有kubelet/kubeadm rpm、以及k8s docker镜像的情况下怎么去部署一个新的k8s集群。</p>

<p>这里使用两台虚拟机做测试：</p>

<ul>
<li>k8s kube-master : 192.168.191.138</li>
<li>woker1 : 192.168.191.139</li>
</ul>


<h2>修改主机名，改时间、时区，防火墙</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hostnamectl --static set-hostname k8s 
</span><span class='line'>hostname k8s 
</span><span class='line'>
</span><span class='line'>rm -rf /etc/localtime 
</span><span class='line'>ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 
</span><span class='line'>
</span><span class='line'>systemctl disable firewalld ; service firewalld stop
</span></code></pre></td></tr></table></div></figure>


<h2>安装docker</h2>

<ul>
<li><a href="https://docs.docker.com/v1.12/engine/installation/linux/rhel/">https://docs.docker.com/v1.12/engine/installation/linux/rhel/</a></li>
<li><a href="https://yum.dockerproject.org/repo/main/centos/7/Packages/">https://yum.dockerproject.org/repo/main/centos/7/Packages/</a> 打开看下1.12的具体版本</li>
<li><a href="https://docs.docker.com/v1.12/engine/admin/systemd/">https://docs.docker.com/v1.12/engine/admin/systemd/</a>  *</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'
</span><span class='line'>[dockerrepo]
</span><span class='line'>name=Docker Repository
</span><span class='line'>baseurl=https://yum.dockerproject.org/repo/main/centos/7/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=https://yum.dockerproject.org/gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>yum list docker-engine --showduplicates
</span><span class='line'>
</span><span class='line'>yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6 -y
</span><span class='line'>systemctl enable docker ; systemctl start docker
</span></code></pre></td></tr></table></div></figure>


<h2>翻墙安装配置</h2>

<p>具体操作参考 <a href="http://winseliu.com/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks">使用Privoxy把shadowsocks转换为Http代理</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install -y epel-release ; yum install -y python-pip 
</span><span class='line'>[root@k8s ~]# pip install shadowsocks
</span><span class='line'>[root@k8s ~]# vi /etc/shadowsocks.json 
</span><span class='line'>[root@k8s ~]# sslocal -c /etc/shadowsocks.json 
</span><span class='line'>[root@k8s ~]# curl --socks5-hostname 127.0.0.1:1080 www.google.com
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# yum install privoxy -y
</span><span class='line'>[root@k8s ~]# vi /etc/privoxy/config 
</span><span class='line'>...
</span><span class='line'>forward-socks5 / 127.0.0.1:1080 .
</span><span class='line'>listen-address 192.168.191.138:8118
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl enable privoxy
</span><span class='line'>[root@k8s ~]# systemctl start privoxy
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# curl -x 192.168.191.138:8118 www.google.com
</span><span class='line'>
</span><span class='line'>等k8s安装启动好后，把privoxy的服务disable掉
</span><span class='line'>[root@k8s ~]# systemctl disable privoxy.service</span></code></pre></td></tr></table></div></figure>


<h2>下载kubectl（怪了，这个竟然可以直接下载）</h2>

<p>变化好快，现在都1.7.2了！ <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>

<p>在master机器（常用的操作机器）安装即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
</span><span class='line'>chmod +x ./kubectl
</span><span class='line'>mv ./kubectl /usr/local/bin/kubectl
</span><span class='line'>
</span><span class='line'># 启用shell的提示/自动完成autocompletion
</span><span class='line'>echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl version 
</span><span class='line'>Client Version: version.Info{Major:"1", Minor:"7", GitVersion:"v1.7.2", GitCommit:"922a86cfcd65915a9b2f69f3f193b8907d741d9c", GitTreeState:"clean", BuildDate:"2017-07-21T08:23:22Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"linux/amd64"}
</span><span class='line'>The connection to the server localhost:8080 was refused - did you specify the right host or port?
</span></code></pre></td></tr></table></div></figure>


<h2>通过VPN安装kubelet和kubeadm</h2>

<p>参考 <a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm">https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm</a></p>

<p>You will install these packages on all of your machines:</p>

<ul>
<li>kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</li>
<li>kubeadm: the command to bootstrap the cluster.</li>
</ul>


<p>所有机器都要安装的，我们先在master节点上通过代理安装这两个软件，并把安装的所有rpm缓冲起来。</p>

<ul>
<li>配置kubernetes的仓库源：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span><span class='line'>[kubernetes]
</span><span class='line'>name=Kubernetes
</span><span class='line'>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>repo_gpgcheck=1
</span><span class='line'>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
</span><span class='line'>        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 
</span><span class='line'>setenforce 0
</span><span class='line'>
</span><span class='line'>yum-config-manager --enable kubernetes</span></code></pre></td></tr></table></div></figure>


<ul>
<li>YUM配置socks5代理： <a href="https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum">https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum</a></li>
</ul>


<p>修改yum的配置，增加代理，并缓冲（用于其他机器安装）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# vi /etc/yum.conf 
</span><span class='line'>keepcache=1
</span><span class='line'>...
</span><span class='line'>proxy=socks5://127.0.0.1:1080
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装并启动kubelet：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install -y kubelet kubeadm
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl enable kubelet && systemctl start kubelet
</span><span class='line'>Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<h2>通过VPN安装初始化集群（主要是配置代理下载docker容器）</h2>

<p>由于是直接docker去获取镜像的，首先需要修改docker的配置。</p>

<p>参考 <a href="https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy">https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy</a></p>

<ul>
<li>配置代理并重启docker、kubelet</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# systemctl enable docker
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# mkdir -p /etc/systemd/system/docker.service.d/
</span><span class='line'>[root@k8s ~]# vi /etc/systemd/system/docker.service.d/http-proxy.conf
</span><span class='line'>[Service]
</span><span class='line'>Environment="HTTP_PROXY=http://192.168.191.138:8118/" "HTTPS_PROXY=http://192.168.191.138:8118/" "NO_PROXY=localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
</span><span class='line'>                             
</span><span class='line'>[root@k8s ~]# systemctl daemon-reload
</span><span class='line'>[root@k8s ~]# systemctl restart docker</span></code></pre></td></tr></table></div></figure>


<p>docker和kubelet的cgroup驱动方式不同，需要修复配置：<a href="https://github.com/kubernetes/kubeadm/issues/103">https://github.com/kubernetes/kubeadm/issues/103</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>前面已经启动了kubelet，有如下的错误日志
</span><span class='line'>[root@k8s ~]# journalctl -xeu kubelet
</span><span class='line'>Jul 29 09:11:24 k8s kubelet[48557]: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgr
</span><span class='line'>
</span><span class='line'>修改配置
</span><span class='line'>[root@k8s ~]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span><span class='line'>Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs"
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl daemon-reload
</span><span class='line'>[root@k8s ~]# service kubelet restart
</span><span class='line'>Redirecting to /bin/systemctl restart  kubelet.service
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>使用kubeadm进行初始化</li>
</ul>


<p><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a> （可以使用 &ndash;kubernetes-version 来指定k8s的版本）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置代理，kubeadm有部分请求应该也是需要走代理的（前面用脚本安装过multinode on docker的经历猜测的）
</span><span class='line'>
</span><span class='line'>export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
</span><span class='line'>export https_proxy=http://192.168.191.138:8118/
</span><span class='line'>export http_proxy=http://192.168.191.138:8118/
</span><span class='line'>
</span><span class='line'># 使用reset重置，网络代理的配置修改了多次（kubeadm初始换过程失败过），还有前几次的初始化没有配置pod地址段
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm reset
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>[reset] Stopping the kubelet service
</span><span class='line'>[reset] Unmounting mounted directories in "/var/lib/kubelet"
</span><span class='line'>[reset] Removing kubernetes-managed containers
</span><span class='line'>[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/lib/etcd]
</span><span class='line'>[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
</span><span class='line'>[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
</span><span class='line'>
</span><span class='line'># 使用flannel需要指定pod的网卡地址段（文档要整体看一遍才能少踩坑，囧）
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[init] Using Kubernetes version: v1.7.2
</span><span class='line'>[init] Using Authorization modes: [Node RBAC]
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
</span><span class='line'>[certificates] Generated CA certificate and key.
</span><span class='line'>[certificates] Generated API server certificate and key.
</span><span class='line'>[certificates] API Server serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.191.138]
</span><span class='line'>[certificates] Generated API server kubelet client certificate and key.
</span><span class='line'>[certificates] Generated service account token signing key and public key.
</span><span class='line'>[certificates] Generated front-proxy CA certificate and key.
</span><span class='line'>[certificates] Generated front-proxy client certificate and key.
</span><span class='line'>[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
</span><span class='line'>[apiclient] Created API client, waiting for the control plane to become ready  
</span><span class='line'>&lt;-&gt; 这里会停的比较久，要去下载镜像，然后还得启动容器
</span><span class='line'>[apiclient] All control plane components are healthy after 293.004469 seconds
</span><span class='line'>[token] Using token: 2af779.b803df0b1effb3d9
</span><span class='line'>[apiconfig] Created RBAC rules
</span><span class='line'>[addons] Applied essential addon: kube-proxy
</span><span class='line'>[addons] Applied essential addon: kube-dns
</span><span class='line'>
</span><span class='line'>Your Kubernetes master has initialized successfully!
</span><span class='line'>
</span><span class='line'>To start using your cluster, you need to run (as a regular user):
</span><span class='line'>
</span><span class='line'>  mkdir -p $HOME/.kube
</span><span class='line'>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>You should now deploy a pod network to the cluster.
</span><span class='line'>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
</span><span class='line'>  http://kubernetes.io/docs/admin/addons/
</span><span class='line'>
</span><span class='line'>You can now join any number of machines by running the following on each node
</span><span class='line'>as root:
</span><span class='line'>
</span><span class='line'>  kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<p>监控安装情况命令有： <code>docker ps</code>, <code>docker images</code>, <code>journalctl -xeu kubelet</code> (/var/log/messages) 。</p>

<p>如果有镜像下载和容器新增，说明安装过程在进行中。否则得检查下你的代理是否正常工作了！</p>

<p>初始化完成后，配置kubectl的kubeconfig。一般都是主节点了，直接在节点执行下面命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# mkdir -p $HOME/.kube
</span><span class='line'>[root@k8s ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>[root@k8s ~]# chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>[root@k8s ~]# 
</span><span class='line'>[root@k8s ~]# ll ~/.kube/
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x. 3 root root   23 Jul 29 21:39 cache
</span><span class='line'>-rw-------. 1 root root 5451 Jul 29 22:57 config</span></code></pre></td></tr></table></div></figure>


<p><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">使用Kubeadm安装Kubernetes</a> 介绍了很多作者自己安装过程，以及遇到的问题，非常详细。安装的差不多才发现这篇文章，感觉好迟，如果早点找到，至少安装的时刻心安一点啊。</p>

<p>OK，服务启动了，但是 dns容器 还没有正常启动。由于我们的网络组建还没有安装好啊。其实官网也有说明，但是这安装的顺序也是醉了。</p>

<p> <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p>

<h2>安装flannel</h2>

<p>参考： <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span><span class='line'>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.yml</span></code></pre></td></tr></table></div></figure>


<p>flannel启动了后，再等一阵，dns才会启动好。</p>

<h2>安装dashboard</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>现在就一台机器，得让master也能跑pods。 
</span><span class='line'>https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#master-isolation
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
</span><span class='line'>node "k8s" untainted
</span><span class='line'>
</span><span class='line'># https://lukemarsden.github.io/docs/user-guide/ui/
</span><span class='line'># 部署dashboard
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods --all-namespaces 看看dashboard的情况
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get services --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1       &lt;none&gt;        443/TCP         1h
</span><span class='line'>kube-system   kube-dns               10.96.0.10      &lt;none&gt;        53/UDP,53/TCP   1h
</span><span class='line'>kube-system   kubernetes-dashboard   10.107.103.17   &lt;none&gt;        80/TCP          9m</span></code></pre></td></tr></table></div></figure>


<p>用 <a href="https://master:6443/ui">https://master:6443/ui</a> 访问不了，可以直接用k8s的service地址访问 <a href="http://10.107.103.17/#!/overview?namespace=kube-system">http://10.107.103.17/#!/overview?namespace=kube-system</a></p>

<p>或者通过 <strong> proxy </strong> 访问UI：<a href="https://github.com/kubernetes/kubernetes/issues/44275">https://github.com/kubernetes/kubernetes/issues/44275</a></p>

<p>先运行proxy，启动代理程序：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl proxy
</span><span class='line'>Starting to serve on 127.0.0.1:8001</span></code></pre></td></tr></table></div></figure>


<p>然后访问： <a href="http://localhost:8001/ui">http://localhost:8001/ui</a></p>

<h2>所有的pods、镜像、容器</h2>

<p>基本的东西都跑起来，还是挺激动啊！！第N次安装部署K8S了啊，每次都还是得像坐过山车一样啊！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl get pods --all-namespaces -o wide
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE       IP                NODE
</span><span class='line'>kube-system   etcd-k8s                                1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-apiserver-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-controller-manager-k8s             1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-dns-2425271678-qwx9f               3/3       Running   0          9h        10.244.0.2        k8s
</span><span class='line'>kube-system   kube-flannel-ds-s5f63                   2/2       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-proxy-4pjkg                        1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-scheduler-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kubernetes-dashboard-3313488171-xl25m   1/1       Running   0          8h        10.244.0.3        k8s
</span><span class='line'>[root@k8s ~]# docker images
</span><span class='line'>REPOSITORY                                               TAG                 IMAGE ID            CREATED             SIZE
</span><span class='line'>gcr.io/google_containers/kubernetes-dashboard-amd64      v1.6.3              691a82db1ecd        35 hours ago        139 MB
</span><span class='line'>gcr.io/google_containers/kube-apiserver-amd64            v1.7.2              4935105a20b1        8 days ago          186.1 MB
</span><span class='line'>gcr.io/google_containers/kube-proxy-amd64                v1.7.2              13a7af96c7e8        8 days ago          114.7 MB
</span><span class='line'>gcr.io/google_containers/kube-controller-manager-amd64   v1.7.2              2790e95830f6        8 days ago          138 MB
</span><span class='line'>gcr.io/google_containers/kube-scheduler-amd64            v1.7.2              5db1f9874ae0        8 days ago          77.18 MB
</span><span class='line'>quay.io/coreos/flannel                                   v0.8.0-amd64        9db3bab8c19e        2 weeks ago         50.73 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-sidecar-amd64           1.14.4              38bac66034a6        4 weeks ago         41.81 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-kube-dns-amd64          1.14.4              a8e00546bcf3        4 weeks ago         49.38 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64     1.14.4              f7f45b9cb733        4 weeks ago         41.41 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                      3.0.17              243830dae7dd        5 months ago        168.9 MB
</span><span class='line'>gcr.io/google_containers/pause-amd64                     3.0                 99e59f495ffa        15 months ago       746.9 kB
</span><span class='line'>[root@k8s ~]# docker ps 
</span><span class='line'>CONTAINER ID        IMAGE                                                                                                                            COMMAND                  CREATED             STATUS              PORTS               NAMES
</span><span class='line'>631dc2cab02e        gcr.io/google_containers/kubernetes-dashboard-amd64@sha256:2c4421ed80358a0ee97b44357b6cd6dc09be6ccc27dfe9d50c9bfc39a760e5fe      "/dashboard --insecur"   7 hours ago         Up 7 hours                              k8s_kubernetes-dashboard_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
</span><span class='line'>8f5e4d044a6e        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 8 hours ago         Up 8 hours                              k8s_POD_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
</span><span class='line'>65881f9dd2dd        gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:97074c951046e37d3cbb98b82ae85ed15704a290cce66a8314e7f846404edde9           "/sidecar --v=2 --log"   9 hours ago         Up 9 hours                              k8s_sidecar_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>994c2ec99663        gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64@sha256:aeeb994acbc505eabc7415187cd9edb38cbb5364dc1c2fc748154576464b3dc2     "/dnsmasq-nanny -v=2 "   9 hours ago         Up 9 hours                              k8s_dnsmasq_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>5b181a0ed809        gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344          "/kube-dns --domain=c"   9 hours ago         Up 9 hours                              k8s_kubedns_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>a0d3f166e992        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>9cc7d6faf0b0        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/bin/sh -c 'set -e -"   9 hours ago         Up 9 hours                              k8s_install-cni_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>2f41276df8e1        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/opt/bin/flanneld --"   9 hours ago         Up 9 hours                              k8s_kube-flannel_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>bc25b0c70264        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>dc3e5641c273        gcr.io/google_containers/kube-proxy-amd64@sha256:d455480e81d60e0eff3415675278fe3daec6f56c79cd5b33a9b76548d8ab4365                "/usr/local/bin/kube-"   9 hours ago         Up 9 hours                              k8s_kube-proxy_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>6b8b9515f562        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>72418ca8e94f        gcr.io/google_containers/kube-apiserver-amd64@sha256:a9ccc205760319696d2ef0641de4478ee90fb0b75fbe6c09b1d64058c8819f97            "kube-apiserver --ser"   9 hours ago         Up 9 hours                              k8s_kube-apiserver_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
</span><span class='line'>9c9a3f5d8919        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
</span><span class='line'>43a1751ff2bb        gcr.io/google_containers/etcd-amd64@sha256:d83d3545e06fb035db8512e33bd44afb55dea007a3abd7b17742d3ac6d235940                      "etcd --listen-client"   9 hours ago         Up 9 hours                              k8s_etcd_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
</span><span class='line'>b110fff29f66        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
</span><span class='line'>66ae85500128        gcr.io/google_containers/kube-scheduler-amd64@sha256:b2e897138449e7a00508dc589b1d4b71e56498a4d949ff30eb07b1e9d665e439            "kube-scheduler --add"   9 hours ago         Up 9 hours                              k8s_kube-scheduler_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
</span><span class='line'>d4343be2f2d0        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
</span><span class='line'>9934cd83f6b3        gcr.io/google_containers/kube-controller-manager-amd64@sha256:2b268ab9017fadb006ee994f48b7222375fe860dc7bd14bf501b98f0ddc2961b   "kube-controller-mana"   9 hours ago         Up 9 hours                              k8s_kube-controller-manager_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
</span><span class='line'>acc1d7d90180        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
</span><span class='line'>[root@k8s ~]# </span></code></pre></td></tr></table></div></figure>


<h2>Woker节点部署</h2>

<p>时间，主机名，/etc/hosts，防火墙，selinux, 无密钥登录，安装docker-1.12.6就不再赘述了。</p>

<p>直接用master的yum缓冲，还有docker镜像直接拷贝：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master机器已安装httpd服务
</span><span class='line'>
</span><span class='line'>[root@k8s html]# ln -s /var/cache/yum/x86_64/7/kubernetes/packages/ k8s 
</span><span class='line'>[root@k8s k8s]# createrepo .          
</span><span class='line'>
</span><span class='line'># 把镜像全部拷到worker节点
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker save $( echo $( docker images | grep -v REPOSITORY | awk '{print $1}' ) ) | ssh worker1 docker load 
</span><span class='line'>
</span><span class='line'># 配置私有仓库源
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# vi k8s.repo
</span><span class='line'>[k8s]
</span><span class='line'>name=Kubernetes
</span><span class='line'>baseurl=http://master/k8s
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>[root@worker1 yum.repos.d]# yum list | grep k8s 
</span><span class='line'>kubeadm.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubectl.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubelet.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubernetes-cni.x86_64                      0.5.1-0                     k8s      
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# yum install -y kubelet kubeadm                          
</span><span class='line'>
</span><span class='line'># 修改cgroup-driver
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf  
</span><span class='line'>[root@worker1 yum.repos.d]# 
</span><span class='line'>[root@worker1 yum.repos.d]# service docker restart
</span><span class='line'>Redirecting to /bin/systemctl restart  docker.service
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# systemctl daemon-reload
</span><span class='line'>[root@worker1 yum.repos.d]# systemctl enable kubelet.service
</span><span class='line'>[root@worker1 yum.repos.d]# service kubelet restart
</span><span class='line'>Redirecting to /bin/systemctl restart  kubelet.service
</span><span class='line'>
</span><span class='line'># worker节点加入集群（初始化）
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443 --skip-preflight-checks
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[discovery] Trying to connect to API Server "192.168.191.138:6443"
</span><span class='line'>[discovery] Created cluster-info discovery client, requesting info from "https://192.168.191.138:6443"
</span><span class='line'>[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.191.138:6443"
</span><span class='line'>[discovery] Successfully established connection with API Server "192.168.191.138:6443"
</span><span class='line'>[bootstrap] Detected server version: v1.7.2
</span><span class='line'>[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
</span><span class='line'>[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
</span><span class='line'>[csr] Received signed certificate from the API server, generating KubeConfig...
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>
</span><span class='line'>Node join complete:
</span><span class='line'>* Certificate signing request sent to master and response
</span><span class='line'>  received.
</span><span class='line'>* Kubelet informed of new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the master to see this machine join.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get nodes
</span><span class='line'>NAME      STATUS    AGE       VERSION
</span><span class='line'>k8s       Ready     10h       v1.7.2
</span><span class='line'>worker1   Ready     57s       v1.7.2</span></code></pre></td></tr></table></div></figure>


<p>主节点运行的flannel网络组件是个 daemonset 的pod，只要加入到集群就会在每个节点上启动。不需要额外的操作。</p>

<h2>关于重启：</h2>

<p>使用RPM安装的好处是：程序系统都帮你管理了：</p>

<ul>
<li>worker节点重启后，kubelet会把所有的服务都带起来。</li>
<li>master重启后，需要等一段时间，因为pods启动有顺序/依赖：dns需要等flannel，dashboard需要等dns。</li>
</ul>


<h2>POD间连通性测试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl run hello-nginx --image=nginx --port=80
</span><span class='line'>deployment "hello-nginx" created
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS              RESTARTS   AGE
</span><span class='line'>hello-nginx-1507731416-qh3fx   0/1       ContainerCreating   0          8s
</span><span class='line'>
</span><span class='line'># 脚本启动新的dockerd并配置加速器，下载好然后save导入都本地docker实例
</span><span class='line'># https://github.com/winse/docker-hadoop/blob/master/kube-deploy/hadoop/docker-download-mirror.sh
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# ./docker-download-mirror.sh nginx 
</span><span class='line'>Using default tag: latest
</span><span class='line'>latest: Pulling from library/nginx
</span><span class='line'>
</span><span class='line'>94ed0c431eb5: Pull complete 
</span><span class='line'>9406c100a1c3: Pull complete 
</span><span class='line'>aa74daafd50c: Pull complete 
</span><span class='line'>Digest: sha256:788fa27763db6d69ad3444e8ba72f947df9e7e163bad7c1f5614f8fd27a311c3
</span><span class='line'>Status: Downloaded newer image for nginx:latest
</span><span class='line'>eb78099fbf7f: Loading layer [==================================================&gt;] 58.42 MB/58.42 MB
</span><span class='line'>29f11c413898: Loading layer [==================================================&gt;] 52.74 MB/52.74 MB
</span><span class='line'>af5bd3938f60: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>
</span><span class='line'># 拷贝镜像到其他的worker节点，就几台机器搭建register服务感觉太重了
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker save nginx | ssh worker1 docker load
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>
</span><span class='line'># 查看效果
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE
</span><span class='line'>hello-nginx-1507731416-qh3fx   1/1       Running   0          1m
</span><span class='line'>
</span><span class='line'># 扩容
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl scale --replicas=4 deployment/hello-nginx  
</span><span class='line'>deployment "hello-nginx" scaled
</span><span class='line'>[root@k8s ~]# kubectl get pods -o wide
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE       IP           NODE
</span><span class='line'>hello-nginx-1507731416-h39f0   1/1       Running   0          34s       10.244.0.6   k8s
</span><span class='line'>hello-nginx-1507731416-mnj3m   1/1       Running   0          34s       10.244.1.3   worker1
</span><span class='line'>hello-nginx-1507731416-nsdr2   1/1       Running   0          34s       10.244.0.7   k8s
</span><span class='line'>hello-nginx-1507731416-qh3fx   1/1       Running   0          5m        10.244.1.2   worker1
</span><span class='line'>[root@k8s ~]# kubectl delete deployment hello-nginx
</span><span class='line'>
</span><span class='line'>这容器太简洁了，PING都没有啊！！搞个熟悉的linux版本，再跑一遍
</span><span class='line'>
</span><span class='line'>kubectl run centos --image=centos:centos6 --command -- vi 
</span><span class='line'>kubectl scale --replicas=4 deployment/centos
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods  -o wide 
</span><span class='line'>NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
</span><span class='line'>centos-3024873821-4490r   1/1       Running   0          49s       10.244.1.6    worker1
</span><span class='line'>centos-3024873821-k74gn   1/1       Running   0          11s       10.244.0.11   k8s
</span><span class='line'>centos-3024873821-l27xs   1/1       Running   0          11s       10.244.0.10   k8s
</span><span class='line'>centos-3024873821-pbg52   1/1       Running   0          11s       10.244.1.7    worker1
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl exec -ti centos-3024873821-4490r bash
</span><span class='line'>[root@centos-3024873821-4490r /]# yum install -y iputils
</span><span class='line'>[root@centos-3024873821-4490r /]# ping 10.244.0.11 -c 1
</span><span class='line'>
</span><span class='line'>以上IP都是互通的，从master节点PING这些IP也是通的。
</span><span class='line'>
</span><span class='line'># 查看pod状态的命令
</span><span class='line'>kubectl -n ${NAMESPACE} describe pod ${POD_NAME}
</span><span class='line'>kubectl -n ${NAMESPACE} logs ${POD_NAME} -c ${CONTAINER_NAME}</span></code></pre></td></tr></table></div></figure>


<h2>源IP问题</h2>

<p>原来部署hadoop的时刻，已经遇到过了。知道根源所在，但是这次使用的cni（直接改 <code>dockerd --ip-masq=false</code> 配置仅修改的是docker0）。</p>

<p>先来重现下源ip问题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./pod_bash centos-3024873821-t3k3r 
</span><span class='line'>
</span><span class='line'>yum install epel-release -y ; yum install nginx -y ;
</span><span class='line'>service nginx start
</span><span class='line'>
</span><span class='line'>ifconfig
</span><span class='line'>
</span><span class='line'># nginx安装后，访问查看access_log
</span><span class='line'>
</span><span class='line'>less /var/log/nginx/access.log 
</span></code></pre></td></tr></table></div></figure>


<p>在 kube-flannel.yml 中添加 cni-conf.json 网络配置为 <code>"ipMasq": false,</code>，没啥效果，在iptables上面还是有cni的cbr0的MASQUERADE（SNAT）。</p>

<p>注意：重启后，发现一切都正常了。可能是通过apply修改的，没有生效！在配置flannel之前就修改属性应该就ok了！！后面的可以不要看了，方法还比较挫。</p>

<p>用比较极端点的方式，删掉docker0，替换成cni0。 <a href="https://kubernetes.io/docs/getting-started-guides/scratch/#docker">https://kubernetes.io/docs/getting-started-guides/scratch/#docker</a></p>

<p>把docker的网卡设置成cni0(flannel会创建cni0的网卡) :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 清空原来的策略
</span><span class='line'>iptables -t nat -F
</span><span class='line'>ip link set docker0 down
</span><span class='line'>ip link delete docker0
</span><span class='line'>
</span><span class='line'>[root@worker1 ~]# cat /usr/lib/systemd/system/docker.service  | grep dockerd
</span><span class='line'>ExecStart=/usr/bin/dockerd --bridge=cni0 --ip-masq=false 
</span></code></pre></td></tr></table></div></figure>


<p>但是机器重启后cni0这个网卡设备就没有了，导致机器重启后docker启动失败！（cni-conf.json的&#8221;ipMasq&#8221;: false是有效果的，但是好像得是新建的网卡设备才行！）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; Aug 01 08:36:10 k8s dockerd[943]: time="2017-08-01T08:36:10.017266292+08:00" level=fatal msg="Error starting daemon: Error initializing network controller: Error creating default \"bridge\" network: bridge device with non default name cni0 must be created manually"
</span><span class='line'>
</span><span class='line'>ip link add name cni0 type bridge
</span><span class='line'>ip link set dev cni0 mtu 1460
</span><span class='line'># 让flannel来设置IP地址
</span><span class='line'># ip addr add $NODE_X_BRIDGE_ADDR dev cni0
</span><span class='line'>ip link set dev cni0 up
</span><span class='line'>
</span><span class='line'>systemctl restart docker kubelet
</span></code></pre></td></tr></table></div></figure>


<p>另一种网络部署方式 kubenet + hostroutes ： <a href="https://jishu.io/kubernetes/deploy-production-ready-kubernetes-cluster-on-aliyun/">https://jishu.io/kubernetes/deploy-production-ready-kubernetes-cluster-on-aliyun/</a></p>

<h2>DNS</h2>

<p><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># cat busybox.yaml
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  namespace: default
</span><span class='line'>spec:
</span><span class='line'>  containers:
</span><span class='line'>  - image: busybox
</span><span class='line'>    command:
</span><span class='line'>      - sleep
</span><span class='line'>      - "3600"
</span><span class='line'>    imagePullPolicy: IfNotPresent
</span><span class='line'>    name: busybox
</span><span class='line'>  restartPolicy: Always
</span><span class='line'>
</span><span class='line'>kubectl create -f busybox.yaml
</span><span class='line'>kubectl exec -ti busybox -- nslookup kubernetes.default
</span><span class='line'>kubectl exec busybox cat /etc/resolv.conf
</span></code></pre></td></tr></table></div></figure>


<h2>DNS问题</h2>

<p>在master节点上的POD容器内访问DNS（service）服务，但是返回数据却是域名服务内部POD的IP，而不是Service服务的IP地址。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl describe services kube-dns -n kube-system
</span><span class='line'>Name:                   kube-dns
</span><span class='line'>Namespace:              kube-system
</span><span class='line'>Labels:                 k8s-app=kube-dns
</span><span class='line'>                        kubernetes.io/cluster-service=true
</span><span class='line'>                        kubernetes.io/name=KubeDNS
</span><span class='line'>Annotations:            &lt;none&gt;
</span><span class='line'>Selector:               k8s-app=kube-dns
</span><span class='line'>Type:                   ClusterIP
</span><span class='line'>IP:                     10.96.0.10
</span><span class='line'>Port:                   dns     53/UDP
</span><span class='line'>Endpoints:              10.244.0.30:53
</span><span class='line'>Port:                   dns-tcp 53/TCP
</span><span class='line'>Endpoints:              10.244.0.30:53
</span><span class='line'>Session Affinity:       None
</span><span class='line'>Events:                 &lt;none&gt;
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl exec -ti centos-3024873821-b6d48 -- nslookup kubernetes.default
</span><span class='line'>;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</span><span class='line'>;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</span></code></pre></td></tr></table></div></figure>


<h4>相关问题的一些资源：</h4>

<ul>
<li>*<a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">kubernetes pods replying with unexpected source for DNS queries</a></li>
<li><a href="https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477">https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477</a></li>
<li><p><a href="https://github.com/coreos/coreos-kubernetes/issues/572">cni plugin + flannel on v1.3: pods can&rsquo;t route to service IPs</a></p></li>
<li><p><a href="https://www.slideshare.net/kubecon/container-network-interface-network-plugins-for-kubernetes-and-beyond">Container Network Interface: Network Plugins for Kubernetes and beyond</a></p></li>
<li><a href="http://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/">Understanding CNI (Container Networking Interface)</a></li>
<li><a href="https://feisky.gitbooks.io/kubernetes/network/flannel/">Kubernetes指南 - flannel</a></li>
<li>Pod to external traffic is not masqueraded <a href="https://github.com/kubernetes/kubernetes/issues/40761">https://github.com/kubernetes/kubernetes/issues/40761</a></li>
</ul>


<h4>解决方法：</h4>

<p><strong> kube-proxy加上 &ndash;masquerade-all 解决了。</strong></p>

<h4>处理方法：</h4>

<blockquote><p><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a>
kubeadm installs add-on components via the API server. Right now this is the internal DNS server and the kube-proxy DaemonSet.</p></blockquote>

<p>修改有技巧，正如官网文档所说：kube-proxy是内部容器启动的。没找到yaml配置，不能直接改配置文件，这里有如下两种方式修改：</p>

<ul>
<li>通过Dashboard页面的编辑对配置进行修改</li>
<li>通过edit命令对配置进行修改：<code>kubectl edit daemonset kube-proxy -n=kube-system</code> 命令添加 <code>- --masquerade-all</code></li>
</ul>


<h2>Heapster</h2>

<p>参考</p>

<ul>
<li><a href="https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md">https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md</a></li>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/">https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# git clone https://github.com/kubernetes/heapster.git
</span><span class='line'>Cloning into 'heapster'...
</span><span class='line'>remote: Counting objects: 26084, done.
</span><span class='line'>remote: Total 26084 (delta 0), reused 0 (delta 0), pack-reused 26084
</span><span class='line'>Receiving objects: 100% (26084/26084), 36.33 MiB | 2.66 MiB/s, done.
</span><span class='line'>Resolving deltas: 100% (13084/13084), done.
</span><span class='line'>Checking out files: 100% (2531/2531), done.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# cd heapster/
</span><span class='line'>[root@k8s heapster]# kubectl create -f deploy/kube-config/influxdb/
</span><span class='line'>deployment "monitoring-grafana" created
</span><span class='line'>service "monitoring-grafana" created
</span><span class='line'>serviceaccount "heapster" created
</span><span class='line'>deployment "heapster" created
</span><span class='line'>service "heapster" created
</span><span class='line'>deployment "monitoring-influxdb" created
</span><span class='line'>service "monitoring-influxdb" created
</span><span class='line'>[root@k8s heapster]# kubectl create -f deploy/kube-config/rbac/heapster-rbac.yaml 
</span><span class='line'>clusterrolebinding "heapster" created
</span></code></pre></td></tr></table></div></figure>


<p>其他资源：</p>

<ul>
<li><a href="http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/">http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/</a></li>
<li><a href="http://www.pangxie.space/docker/727">http://www.pangxie.space/docker/727</a></li>
<li><a href="http://jerrymin.blog.51cto.com/3002256/1904460">http://jerrymin.blog.51cto.com/3002256/1904460</a></li>
<li><a href="http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer</a></li>
</ul>


<p>DNS的问题耗了比较多的时间。弄好了DNS后，以及heapster的docker镜像的下载都OK的话，就万事俱备了。最后重新启动下dashboard就行了：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl delete -f kubernetes-dashboard.yaml 
</span><span class='line'>[root@k8s ~]# kubectl create -f kubernetes-dashboard.yaml 
</span></code></pre></td></tr></table></div></figure>


<p>然后就可以在dashboard上看到美美的曲线图了。</p>

<h2>harbor</h2>

<p>参考 <a href="https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md">https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md</a></p>

<p>日新月异啊，1.1.2版本了！！ 用迅雷直接下载 <a href="https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz">https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz</a>  这个地址。</p>

<p>操作方式还是和原来的版本一样。也就是说可以用原来简化的脚本来安装！</p>

<p>搭建好了后，会基本的使用就差不多了。测试环境资源有限，并且其实用save和load也能解决（咔咔）。</p>

<h2>livenessProbe - Nexus的无响应处理</h2>

<p>在 <a href="https://github.com/winse/docker-hadoop/blob/master/kube-deploy/nexus-rc.yaml">github仓库</a> 上有一份开发环境的NEXUS的启动脚本，从一开始的单pods，改成replicationcontroller。觉得万事大吉了。</p>

<p>但，现在又出现一个问题，就是容器还在，但是8081不提供服务了。这很尴尬，其他开发人员说nexus又不能访问了，我想不对，不是已经改成rc了么，容器应该不会挂才对啊。上环境一看，容器是在，但是服务是真没响应。</p>

<p>怎么办？</p>

<p>搞定时任务，觉得有点low。后面想如果判断一下服务不能访问了就重启，其实k8s已经想到了这一点了，提供了<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-a-liveness-http-request">存活探针livenessProbe</a> 。直接按照官网给的http的例子写就行了。等过几天看效果。</p>

<h2>参考</h2>

<p>官方的一些资源</p>

<ul>
<li><a href="https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy">https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></li>
<li><a href="https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/">https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection">https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#environment-variables">https://kubernetes.io/docs/admin/kubeadm/#environment-variables</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/</a> 怎么升级，以及如何制定特定的k8s版本</li>
</ul>


<p>使用kubeadm安装集群</p>

<ul>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/</a> 参考</li>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/</a>  weave net网络</li>
<li><a href="https://www.kubernetes.org.cn/1165.html">https://www.kubernetes.org.cn/1165.html</a> 就是上面第一篇，但是排版看起来跟舒服点</li>
<li><a href="http://hairtaildai.com/blog/11">http://hairtaildai.com/blog/11</a> 安装似乎太顺利了，都没有遇到啥问题？</li>
<li><a href="https://my.oschina.net/xdatk/blog/895645">https://my.oschina.net/xdatk/blog/895645</a> 这篇不推荐，太繁琐了。很多贴的是内容，不知道改过啥！</li>
</ul>


<p>DNS问题参考</p>

<ul>
<li><a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries</a></li>
<li><a href="https://kubernetes.io/docs/admin/kube-proxy/">https://kubernetes.io/docs/admin/kube-proxy/</a></li>
<li><p><a href="https://docs.docker.com/engine/admin/systemd/#httphttps-proxy">https://docs.docker.com/engine/admin/systemd/#httphttps-proxy</a></p></li>
<li><p><a href="https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html">https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html</a> 命令行编辑的方法在这里看到的</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/34101">https://github.com/kubernetes/kubernetes/issues/34101</a>
Ok, so it turns out that this flag is not enough, we still have an issue reaching kubernetes service IP. The simplest solution to this is to run kube-proxy with &ndash;proxy-mode=userspace. To enable this, you can use kubectl -n kube-system edit ds kube-proxy-amd64 &amp;&amp; kubectl -n kube-system delete pods -l name=kube-proxy-amd64.</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/36835">https://github.com/kubernetes/kubernetes/issues/36835</a> To enable off-cluster bridging when &ndash;proxy-mode=iptables, also set &ndash;cluster-cidr.</p></li>
<li><a href="https://github.com/kubernetes/kubeadm/issues/102">https://github.com/kubernetes/kubeadm/issues/102</a> proxy: clusterCIDR not specified, unable to distinguish between internal and external traffic</li>
</ul>


<p>其他一些资源</p>

<ul>
<li><a href="https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md">https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md</a></li>
<li><p><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/</a></p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/">https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/</a> Replication Controllers</p></li>
<li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy</a> RestartPolicy</li>
</ul>


<p>&mdash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[转]一致性Hash]]></title>
    <link href="http://winseliu.com/blog/2017/07/16/consistent-hashing/"/>
    <updated>2017-07-16T01:03:51+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/16/consistent-hashing</id>
    <content type="html"><![CDATA[<p><a href="http://gywbd.github.io/posts/2016/10/consistent-hashing.html">一致性哈希</a></p>

<p>图文并茂，写的非常好。</p>

<p>要点：</p>

<ol>
<li>解决Hash的随机分布带来的增删节点的需重新全部映射的问题：对主机使用同样的函数把主机A分布到环上（其实就是分配一段范围），然后在Hash后在这段范围内的数据全部存储到主机A上。这样增删节点只需要对部分数据重新映射。</li>
</ol>


<p><img src="http://gywbd.github.io/images/ch1.png" alt="" /></p>

<p><img src="http://gywbd.github.io/images/ch8.png" alt="" /></p>

<p><img src="http://gywbd.github.io/images/ch10.png" alt="" /></p>

<ol>
<li>由此又引入了一个优化的点。（随机在环上放置节点）机器硬件不同，能力不同，以及数据分布均衡（热点机器）等的问题。所以，虚拟节点就是用来节点这个问题的。每个节点可以指定分配的虚拟节点数。</li>
</ol>


<p><img src="http://gywbd.github.io/images/ch13.png" alt="" /></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[togo简单的RPM打包工具]]></title>
    <link href="http://winseliu.com/blog/2017/07/15/togo-another-rpmbuild-tool/"/>
    <updated>2017-07-15T15:09:52+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/15/togo-another-rpmbuild-tool</id>
    <content type="html"><![CDATA[<p>源码： <a href="https://github.com/genereese/togo">https://github.com/genereese/togo</a></p>

<h2>安装</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install https://github.com/genereese/togo/releases/download/v2.3r7/togo-2.3-7.noarch.rpm</span></code></pre></td></tr></table></div></figure>


<h2>实际案例使用</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 创建类似rpmbuild的骨架
</span><span class='line'>togo project create my-new-rpm; cd my-new-rpm
</span><span class='line'>
</span><span class='line'># 内容准备
</span><span class='line'>mkdir -p root/usr/local/bin; touch root/usr/local/bin/exmaple.sh
</span><span class='line'>chmod +x root/usr/local/bin/exmaple.sh
</span><span class='line'>
</span><span class='line'># 排除目录、文件
</span><span class='line'>togo file exclude root/usr/local/bin
</span><span class='line'>  Removed '/usr/local/bin' from project ownership.
</span><span class='line'>  Removed '/usr/local' from project ownership.
</span><span class='line'>  Removed '/usr' from project ownership.
</span><span class='line'>
</span><span class='line'># 修改属性，如第二次重新打包就需要修改下release
</span><span class='line'>vi spec/header
</span><span class='line'>
</span><span class='line'># 编译打包
</span><span class='line'>togo build package</span></code></pre></td></tr></table></div></figure>


<h2>成果</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ll rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 2236 Jul 14 12:17 rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>$ rpm -qpl rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>/usr/local/bin/exmaple.sh
</span></code></pre></td></tr></table></div></figure>


<p>打出来的就是第一个标准的rpm包，然后就可以按照rpm包的方式进行处理了：直接安装、或者使用createrepo来制作本地仓库等等。</p>

<p>用来简单打包文件还是挺方便的。相当于把骨架都搭建好了，然后还提供了一些方便的命令来进行维护修改。</p>

<p>还有一个 <a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Helpful_tools">rpmdevtools</a> 也是一个创建编译项目的脚手架，只不过这仅仅是对<a href="https://fedoraproject.org/wiki/Archive:BuildingPackagesGuide?rd=Docs/Drafts/BuildingPackagesGuide#Creating_a_New_Package">rpmbuild方式</a>的辅助。更多的还是需要自己精心的维护spec。</p>

<p>还有提到的 <a href="https://github.com/alanfranz/docker-rpm-builder">docker-rpm-builder</a> 需要centos7。如果要打那种N个环境的rpm包，才能体现出它的优势吧。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[爬虫之CasperJS]]></title>
    <link href="http://winseliu.com/blog/2017/07/08/casperjs-crawler/"/>
    <updated>2017-07-08T15:56:06+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/08/casperjs-crawler</id>
    <content type="html"><![CDATA[<p>用jsoup(java, scala, groovy)爬过数据，用cheerio(nodejs)爬过数据，每次爬取都要对页面HTML结构，数据来源URL进行研究。还要对网站的反扒做一些HEADER的设置。各种繁琐，主要还有一些数据型的网站验证复杂，很难通过简单的方式来破解它的那套反扒流程。</p>

<p><a href="http://docs.casperjs.org/en/latest/modules/casper.html">CasperJS</a>是在<a href="http://phantomjs.org/quick-start.html">phantomjs</a>基础上的一套工具库用来简化phantomjs的操作，降低使用和入门的门槛。而PhantomJS是类似浏览器的一个工具（headless browsers），你可以把它看做浏览器。所以可以通过CasperJS来操作浏览器访问地址，然后加载完页面后再提取数据，这样就不要考虑被反扒的风险，并且获取数据的方式相对容易和简单。</p>

<h2>先从官网的案例体验下HelloWorld以及如何调试</h2>

<p>下载最新的<a href="http://docs.casperjs.org/en/latest/installation.html#installing-from-npm">CasperJS（npm install）</a>即可，PhantomJS下载<a href="https://bitbucket.org/ariya/phantomjs/downloads/">1.9.8</a>版本，不推荐2+版本，有些功能有问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>R:\test&gt;set PATH=C:\Users\winse\AppData\Roaming\npm\node_modules\casperjs\bin;E:\phantomjs-1.9.8-windows;%PATH
</span><span class='line'>
</span><span class='line'>R:\test&gt;cat hello.js
</span><span class='line'>var casper = require('casper').create();
</span><span class='line'>// debugger
</span><span class='line'>
</span><span class='line'>casper.start('http://casperjs.org/', function() {
</span><span class='line'>    this.echo(this.getTitle());
</span><span class='line'>    
</span><span class='line'>    this.echo("Star: " + this.evaluate(function () { 
</span><span class='line'>        return $(".octicon-star").parent().text().trim()
</span><span class='line'>    }) )
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.thenOpen('http://phantomjs.org', function() {
</span><span class='line'>    this.echo(this.getTitle());
</span><span class='line'>    
</span><span class='line'>    this.echo("Intro: " + this.evaluate(function () { 
</span><span class='line'>        return $(".intro h1").innerHTML
</span><span class='line'>        // return document.querySelector(".intro h1").innerHTML
</span><span class='line'>    }) )
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run();
</span><span class='line'>
</span><span class='line'>R:\test&gt;casperjs  hello.js
</span><span class='line'>CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
</span><span class='line'>Star: 6,337 Stargazers
</span><span class='line'>PhantomJS | PhantomJS
</span><span class='line'>Intro: null</span></code></pre></td></tr></table></div></figure>


<p>用js的方式来获取页面数据，非常完美，相比直接通过URL请求来获取数据，CasperJS就是慢了点（有点像我们每次都打开浏览器然后再访问，可以通过建立服务，然后在常驻PhantomJS访问页面）。</p>

<p>上面第二次获取的数据不是我们想要的，这里我们通过调试看看到底是什么原因导致的。在start前增加一行 <code>debugger</code> 。然后执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>casperjs hello.js --verbose --log-level=debug --remote-debugger-port=9000</span></code></pre></td></tr></table></div></figure>


<p>打开浏览器方式 localhost:9000 点击 <strong>about:blank</strong> 链接，然后在Console窗口执行 <code>__run()</code> ，等一下下会停在debugger那一行，再然后就是愉快的debug就好了。</p>

<p>在 <a href="http://phantomjs.org">http://phantomjs.org</a> 那一段的evaluate代码处增加一个断点，运行到该断点后，再次打开 localhost:9000 会多出一个当前访问页面的链接，点击进去就像平时F12看到的调式窗口了。</p>

<ul>
<li><a href="http://phantomjs.org/troubleshooting.html#remote-debugging">http://phantomjs.org/troubleshooting.html#remote-debugging</a></li>
<li><a href="https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs">https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs</a></li>
<li><a href="https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper">https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper</a></li>
<li><a href="https://github.com/ariya/phantomjs/issues/12064">https://github.com/ariya/phantomjs/issues/12064</a></li>
</ul>


<p>注意: <a href="https://www.portablesoft.org/google-chrome-legacy-versions/">Chrome浏览器要用V54版本以下</a> 的。</p>

<p>调试详情如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; $(".intro h1")
</span><span class='line'>null
</span><span class='line'>&gt; $
</span><span class='line'>bound: function () {
</span><span class='line'>        return document.getElementById.apply(document, arguments);
</span><span class='line'>    }
</span><span class='line'>&gt; document.querySelector(".intro h1").innerHTML
</span><span class='line'>"
</span><span class='line'>        Full web stack&lt;br&gt;
</span><span class='line'>        No browser required
</span><span class='line'>      "</span></code></pre></td></tr></table></div></figure>


<p>那我们把js脚本修改成querySelector来获取数据。再次执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>R:\test&gt;casperjs  hello.js
</span><span class='line'>CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
</span><span class='line'>Star: 6,337 Stargazers
</span><span class='line'>PhantomJS | PhantomJS
</span><span class='line'>Intro:
</span><span class='line'>        Full web stack&lt;br&gt;
</span><span class='line'>        No browser required</span></code></pre></td></tr></table></div></figure>


<h2>功能特性</h2>

<ul>
<li>截图</li>
</ul>


<p>有现成的方法，但是需要自己<a href="https://uggedal.com/journal/phantomjs-default-background-color/">处理下背景颜色</a> <a href="http://phantomjs.org/tips-and-tricks.html">Tips and Tricks</a>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cat capture.js
</span><span class='line'>var casper = require('casper').create({
</span><span class='line'>    waitTimeout: 120000,
</span><span class='line'>    logLevel: "debug",
</span><span class='line'>    verbose: true
</span><span class='line'>});
</span><span class='line'>casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')
</span><span class='line'>
</span><span class='line'>casper.start('https://xueqiu.com/2054435398/32283614', function () {
</span><span class='line'>    this.waitForSelector("div.status-content a[title*=xueqiu]");
</span><span class='line'>}).then(function () {
</span><span class='line'>    // white background
</span><span class='line'>    this.evaluate(function () {
</span><span class='line'>        var style = document.createElement('style'),
</span><span class='line'>            text = document.createTextNode('body { background: #fff }');
</span><span class='line'>        style.setAttribute('type', 'text/css');
</span><span class='line'>        style.appendChild(text);
</span><span class='line'>        document.head.insertBefore(style, document.head.firstChild);
</span><span class='line'>    });
</span><span class='line'>}).then(function () {
</span><span class='line'>    this.capture('结庐问山.jpg');
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run()
</span><span class='line'>
</span><span class='line'>&gt; casperjs capture.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk</span></code></pre></td></tr></table></div></figure>


<p>用来截全屏的图片相当厉害，Chrome等自带的截图工具如果内容长了后很慢很麻烦，这种方式毫无压力啊。</p>

<ul>
<li>抓取层次页面</li>
</ul>


<p>一般抓数据有个列表页，然后根据列表页的详情地址，根据详情地址再获取数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cat xueqiu.js
</span><span class='line'>debugger
</span><span class='line'>
</span><span class='line'>var fs = require('fs');
</span><span class='line'>var casper = require('casper').create({
</span><span class='line'>    waitTimeout: 120000,
</span><span class='line'>    logLevel: "debug",
</span><span class='line'>    verbose: true
</span><span class='line'>});
</span><span class='line'>casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')
</span><span class='line'>
</span><span class='line'>var links = []
</span><span class='line'>var basedir = '.'
</span><span class='line'>casper.start('https://xueqiu.com/2054435398/32283614', function () {
</span><span class='line'>    this.waitForSelector("div.status-content a[title*=xueqiu]");
</span><span class='line'>}).then(function () {
</span><span class='line'>    var items = this.evaluate(function () {
</span><span class='line'>        return $("div.status-content a[title*=xueqiu]").map(function (i, a) {
</span><span class='line'>            return $(a).attr('href')
</span><span class='line'>        })
</span><span class='line'>    })
</span><span class='line'>
</span><span class='line'>    for (var i = 0; i &lt; items.length; i++) {
</span><span class='line'>        links.push(items[i]);
</span><span class='line'>    }
</span><span class='line'>    
</span><span class='line'>    fs.write('all.html', this.getHTML(), 'w');
</span><span class='line'>}).then(function () {
</span><span class='line'>    this.eachThen(links, function (link) {
</span><span class='line'>        var pathname = undefined;
</span><span class='line'>        var url = link.data;
</span><span class='line'>
</span><span class='line'>        this.thenOpen(url, function () {
</span><span class='line'>            this.waitForSelector("div.status-content .detail");
</span><span class='line'>        }).then(function () {
</span><span class='line'>            pathname = this.evaluate(function () {
</span><span class='line'>                var style = document.createElement('style'),
</span><span class='line'>                    text = document.createTextNode('body { background: #fff }');
</span><span class='line'>                style.setAttribute('type', 'text/css');
</span><span class='line'>                style.appendChild(text);
</span><span class='line'>                document.head.insertBefore(style, document.head.firstChild);
</span><span class='line'>
</span><span class='line'>                return window.location.pathname;
</span><span class='line'>            });
</span><span class='line'>        }).then(function () {
</span><span class='line'>            if (url.indexOf(pathname))
</span><span class='line'>                this.capture(basedir + pathname + ".jpg");
</span><span class='line'>            else
</span><span class='line'>                this.echo(url);
</span><span class='line'>        });
</span><span class='line'>
</span><span class='line'>    })
</span><span class='line'>
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run()
</span><span class='line'>
</span><span class='line'>&gt; casperjs xueqiu.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk --remote-debugger-port=9000
</span></code></pre></td></tr></table></div></figure>


<p>然后一堆堆的图片就生成出来了。由于访问的速度有限，有利有弊，慢一点还不要做时间上面的控制了，有点像人在操作的感觉。然后处理下异常的个别再导一次就可以了(错误的那一篇还是404的&hellip;哭笑)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$("div.status-content a[title*=xueqiu]").map(function(i, a){ return $(a).attr('href') }).length
</span><span class='line'>177
</span><span class='line'>
</span><span class='line'>$ find . -name '*.jpg' | wc -l
</span><span class='line'>176</span></code></pre></td></tr></table></div></figure>


<p>注意：Windows的命令窗口，多按几次Enter，有时一不小心就进入编辑模式了。</p>

<p>压缩后100多M啊！CasperJS足够强大，更多的模式等待你的开启。就写到此。</p>

<h2>后记</h2>

<p>关于爬虫获取数据 <a href="http://webmagic.io/docs/zh/posts/chx-cases/js-render-page.html">抓取前端渲染的页面</a> 这篇文章讲的挺中肯的，如果可能的话，用作者写的 <a href="https://github.com/code4craft/webmagic/blob/master/README-zh.md">WebMagic</a> 也是一个不错的选择。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[导出微信照片]]></title>
    <link href="http://winseliu.com/blog/2017/06/04/wechat-images-export/"/>
    <updated>2017-06-04T14:53:51+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/04/wechat-images-export</id>
    <content type="html"><![CDATA[<p>开篇寄语：还是脚本厉害啊！</p>

<p>手机空间不够，又不能加卡，只能删删删。想着把手机上的照片拷贝出来啊，手机拍的，在DCIM目录下的还好，但是微信里面的照片我也想备份下来啊。怎么办？</p>

<p>手机上翻一张微信的照片，然后目录在： tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 ，连上电脑一看蒙圈了，这尼玛36(10+26)的平方啊，直接复制完全没反应，在系统上面通过查找*.jpg也不靠谱。还有尼玛的，不是挂在到系统盘的，没办法用脚本。</p>

<p>想着，要不用个助手试试，下载了PP和豌豆荚，导出带反应的都没有啊！你们这程序怎么做的啊！老牌子啊！！！</p>

<p>没办法咯，一个个复制想死的心都有了。最后实在没的办法，用adb shell来整把，然后就一个命令就搞定了（苦笑）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>shell@hydrogen:/sdcard/tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 $ which find
</span><span class='line'>/system/bin/find
</span><span class='line'>shell@hydrogen:/sdcard/tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 $
</span><span class='line'>$ find . -name "*.*" -exec cp {} /sdcard/Download/ \; </span></code></pre></td></tr></table></div></figure>


<p>最后拷贝download文件夹就好了。</p>

<p>总共600M的样子。拷贝的时刻，又TMD没权限，在explorer窗口就看不到文件。好吧，再用命令拷贝一下吧：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\adt-bundle-windows-x86-20140702\platform-tools&gt;adb pull -a /sdcard/Download/ R:\image2\
</span><span class='line'>[ 14%] /sdcard/Download/9d01c6e9b722366970f33c948ca4435f.jpg: 76%</span></code></pre></td></tr></table></div></figure>


<p>好久没弄了，SDK还是14年的，不过还能用啊，赫赫。到此，备份微信图片的工作顺利完成，事情一桩一桩的了。</p>

<p>啥，最后你说还要删掉刚刚复制的图片啊，不能一个个的删啊，好吧，收下我&ndash;|的眼神：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\adt-bundle-windows-x86-20140702\platform-tools&gt;adb shell
</span><span class='line'>shell@hydrogen:/ $ cd /sdcard/Download/
</span><span class='line'>shell@hydrogen:/sdcard/Download $ rm -rf *.jpg
</span><span class='line'>shell@hydrogen:/sdcard/Download $ rm -rf *.png</span></code></pre></td></tr></table></div></figure>


<p>拷贝完后，翻了一翻挺有回忆的。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jenkins Start Guide]]></title>
    <link href="http://winseliu.com/blog/2017/06/04/jenkins-start-guide/"/>
    <updated>2017-06-04T10:19:23+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/04/jenkins-start-guide</id>
    <content type="html"><![CDATA[<p>从原始的Eclipse右键导出打包，到后面使用maven打包，就单自己一个人使用开发部署是完全没问题的。现在的jenkins是对工具的封装、可视化和自动化，对于团队合作还是有一定的作用的，时时刻刻告诉我们代码是可运行的。</p>

<p>但是如果一个很久前的项目，又需要新加/修改功能，一下子还捡不起来，不放心啊还得验证一把。还有就是，测试有时刻他们自己打包，不会的还的教她们使用工具，人家烦自己也累。</p>

<p>jenkins是一个持续集成的工具，原来也接触过，但是都没用起来，都是搞开发，大部分时刻都能自己搞定。当下由于情况比较特殊，很多代码都直接在生产改，测试环境就不顾上了，但是测试环境不能总是旧代码啊，就想着有个自动化的东西来进行部署。</p>

<p>主要就是完成一个代码自动化部署的工作：自己搭建一个jenkins，从oschina上拉代码，编译后部署到tomcat并重启。</p>

<h2><a href="https://jenkins.io/download/">安装Jenkins</a></h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war
</span><span class='line'>nohup java -jar jenkins.war --httpPort=8081 &gt;/var/log/jenkins.log 2&gt;&1 & </span></code></pre></td></tr></table></div></figure>


<h2>建立到oschina的无密钥登录</h2>

<p>由于项目是私有的，通过https需要输入密码，还是git方式无密钥登录方式便捷一些。本地linux执行ssh-keygen，然后把 id_rsa.pub 的内容拷贝到项目的公钥处进行配置。可以参考文档： <a href="http://git.mydoc.io/?t=154712">http://git.mydoc.io/?t=154712</a>。</p>

<p>也可以结合 本地ssh-agent 和 ssh-forward 来弄。</p>

<h2>配置项目</h2>

<p>第一次登录需要进行一些配置，默认创建的admin密码会保存在 ~/.jenkins/secrets/initialAdminPassword 。（在初始化页面创建新用户报错，也不知道啥原因。登录后再建吧）</p>

<p>新版本的按照默认安装插件还不够，需要再添加一些。登录成功后，添加如下插件：</p>

<ul>
<li>Deploy to container Plugin  把war发布到容器tomcat&hellip;</li>
<li>Nexus Artifact Uploader  上传jar到私服</li>
<li><p>Maven Integration plugin 集成maven</p></li>
<li><p>ThinBackup 备份也是有必要的，用的越久越是必要！！</p></li>
</ul>


<p>配置maven：</p>

<p>自己下载个maven解压后，在jenkins - Global Tool Configuration上面配置maven地址即可（把 自动安装 的勾去掉就可以填地址了）</p>

<p>然后配置JOB：</p>

<ul>
<li>构建一个maven项目：填任务的名称，然后点击左下角的OK</li>
<li>源码管理git: 填写地址，然后新增Credentials - SSH Username with private key - From the Jenkins master ~/.ssh 起一个容易区分的名字</li>
<li>构建触发器： Build periodically - 0 0 * * * 每天一次</li>
<li>Build：web/pom.xml ; clean package -Papp,dist -DskipTests 就是mvn命令的一串参数</li>
<li>Post Steps: Run only if build succeeds - Execute Shell</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/apache-tomcat-8.0.26/bin/shutdown.sh ; sleep 1 
</span><span class='line'>rm -rf /opt/apache-tomcat-8.0.26/webapps/app.war 
</span><span class='line'>cp $WORKSPACE/web/app/target/app.war /opt/apache-tomcat-8.0.26/webapps 
</span><span class='line'>cd /opt/apache-tomcat-8.0.26/webapps ; ./deploy.sh 
</span><span class='line'>BUILD_ID=dontKillMe nohup /opt/apache-tomcat-8.0.26/bin/startup.sh & 
</span><span class='line'>sleep 3</span></code></pre></td></tr></table></div></figure>


<p>注意：这里的BUILD_ID挺有意思的！！！</p>

<p>也可以配置 <strong>构建后操作</strong> 把包发布到tomcat manager（呵呵，无奈原始包webapps下的都被我删了)，就用脚本弄了。</p>

<h2>构建</h2>

<p>完成上面的操作后，就可以执行跑一次看看效果了。其他的还有很多功能：权限等。</p>

<h2>多节点(集群)</h2>

<p>如果只有一台jenkins的时刻，远程发布项目一般都scp或者使用tomcat-manager进行处理，如果把部署的机器作为jenkins node的话，就可以把部署的任务放到该节点本地跑，就不需要考虑远程部署的问题了。</p>

<p>配置节点： <a href="http://blog.csdn.net/e295166319/article/details/54134487">windows</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>用法   : 只允许运行绑定到这台机器的Job
</span><span class='line'>  启动方法 ： Launch slave agents via SSH（在主机配置无密钥登录，填用户、Private key：From the Jenkins master ~/.ssh）</span></code></pre></td></tr></table></div></figure>


<p>配置好后，在界面点击 <code>Launch agent</code>，会把agent拷贝到机器并启动agent。</p>

<p>然后任务的话，配置 <strong> Restrict where this project can be run </strong> 。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.cnblogs.com/gao241/archive/2013/03/20/2971416.html">Jenkins配置基于角色的项目权限管理</a></li>
<li><a href="http://www.cnblogs.com/zz0412/p/jenkins_jj_14.html">Jenkins进阶系列之——14配置Jenkins用户和权限</a></li>
<li><a href="https://wiki.jenkins-ci.org/display/JENKINS/Spawning+processes+from+build">https://wiki.jenkins-ci.org/display/JENKINS/Spawning+processes+from+build</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-jenkins/">https://www.ibm.com/developerworks/cn/java/j-lo-jenkins/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[追生产的一次优化]]></title>
    <link href="http://winseliu.com/blog/2017/06/01/optimize-java-on-production-environment/"/>
    <updated>2017-06-01T00:36:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/01/optimize-java-on-production-environment</id>
    <content type="html"><![CDATA[<p>最近闲得慌啊，本来不是自己职能范围内的。但是看着一台机器每天负载50+的跑，不舒服，就想去折腾折腾把负载降下来。</p>

<p>进程图：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>top - 08:01:24 up 1203 days,  9:06,  4 users,  load average: 31.41, 32.97, 32.38
</span><span class='line'>Tasks: 569 total,  11 running, 558 sleeping,   0 stopped,   0 zombie
</span><span class='line'>Cpu(s): 20.1%us, 68.1%sy,  0.0%ni,  6.0%id,  0.1%wa,  0.0%hi,  5.7%si,  0.0%st
</span><span class='line'>Mem:  49420852k total, 31831356k used, 17589496k free,   358748k buffers
</span><span class='line'>Swap: 33791992k total,   519332k used, 33272660k free, 18614472k cached
</span><span class='line'>
</span><span class='line'>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                       
</span><span class='line'> 2340 omc       20   0 29.2g 8.5g  11m S 598.1 18.1   3436:40 java                                                                                                                         
</span><span class='line'>31349 omc       20   0 8071m 563m  11m S 348.4  1.2   1735:33 java                                                                                                                         
</span><span class='line'>28147 omc       20   0 15.5g 1.5g  14m S 341.9  3.2   1959:42 java                                                                                                                         
</span><span class='line'>   61 root      20   0     0    0    0 S 48.9  0.0  83728:05 ksoftirqd/14                                                                                                                  
</span><span class='line'>   73 root      20   0     0    0    0 S 48.2  0.0  82342:12 ksoftirqd/17                                                                                                                  
</span><span class='line'>    9 root      20   0     0    0    0 S 46.9  0.0  85312:03 ksoftirqd/1                                                                                                                   
</span><span class='line'>   13 root      20   0     0    0    0 S 46.6  0.0  84297:57 ksoftirqd/2                                                                                                                   
</span><span class='line'>   25 root      20   0     0    0    0 S 45.3  0.0  82811:49 ksoftirqd/5                                                                                                                   
</span><span class='line'>   89 root      20   0     0    0    0 S 45.3  0.0  84608:31 ksoftirqd/21                                                                                                                  
</span><span class='line'>   65 root      20   0     0    0    0 S 44.9  0.0  83475:48 ksoftirqd/15                                                                                                                  
</span><span class='line'>   17 root      20   0     0    0    0 R 44.6  0.0  83990:21 ksoftirqd/3                                                                                                                   
</span><span class='line'>   57 root      20   0     0    0    0 S 44.6  0.0  84625:38 ksoftirqd/13                                                                                                                  
</span><span class='line'>   33 root      20   0     0    0    0 R 44.0  0.0  80537:34 ksoftirqd/7                                                                                                                   
</span><span class='line'>    4 root      20   0     0    0    0 R 43.3  0.0  81489:54 ksoftirqd/0                                                                                                                   
</span><span class='line'>   41 root      20   0     0    0    0 R 42.0  0.0  82651:17 ksoftirqd/9                                                                                                                   
</span><span class='line'>   37 root      20   0     0    0    0 S 40.0  0.0  82636:26 ksoftirqd/8                                                                                                                   
</span><span class='line'>   85 root      20   0     0    0    0 S 39.7  0.0  84557:49 ksoftirqd/20                                                                                                                  
</span><span class='line'>   21 root      20   0     0    0    0 S 38.7  0.0  83271:24 ksoftirqd/4                                                                                                                   
</span><span class='line'>   53 root      20   0     0    0    0 R 36.1  0.0  82083:15 ksoftirqd/12                                                                                                                  
</span><span class='line'>   45 root      20   0     0    0    0 R 35.8  0.0  86230:39 ksoftirqd/10                                                                                                                  
</span><span class='line'>   93 root      20   0     0    0    0 R 35.4  0.0  86416:12 ksoftirqd/22                                                                                                                  
</span><span class='line'>   69 root      20   0     0    0    0 R 35.1  0.0  82726:46 ksoftirqd/16                                                                                                                  
</span><span class='line'>   29 root      20   0     0    0    0 S 34.8  0.0  78415:22 ksoftirqd/6                                                                                                                   
</span><span class='line'>   77 root      20   0     0    0    0 R 33.1  0.0  82419:34 ksoftirqd/18                                                                                                                  
</span><span class='line'>   81 root      20   0     0    0    0 S 30.2  0.0  80141:58 ksoftirqd/19                                                                                                                  
</span><span class='line'>   97 root      20   0     0    0    0 R 21.3  0.0  85993:03 ksoftirqd/23                                                                                                                  
</span><span class='line'>   49 root      20   0     0    0    0 S 21.0  0.0  86742:13 ksoftirqd/11                                                                                                                  
</span><span class='line'>28418 nobody    20   0  855m  32m 1144 S 20.7  0.1  72:23.66 gmetad</span></code></pre></td></tr></table></div></figure>


<p>线程图：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>top - 08:03:20 up 1203 days,  9:08,  4 users,  load average: 31.07, 32.36, 32.23
</span><span class='line'>Tasks: 940 total,  31 running, 909 sleeping,   0 stopped,   0 zombie
</span><span class='line'>Cpu(s): 20.0%us, 70.0%sy,  0.0%ni,  4.6%id,  0.0%wa,  0.0%hi,  5.4%si,  0.0%st
</span><span class='line'>Mem:  49420852k total, 31845576k used, 17575276k free,   358776k buffers
</span><span class='line'>Swap: 33791992k total,   519332k used, 33272660k free, 18615376k cached
</span><span class='line'>
</span><span class='line'>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                       
</span><span class='line'>28174 omc       20   0 15.5g 1.5g  14m R 59.9  3.2 307:28.86 java                                                                                                                          
</span><span class='line'>28203 omc       20   0 15.5g 1.5g  14m S 55.7  3.2 272:43.21 java                                                                                                                          
</span><span class='line'> 2416 omc       20   0 29.2g 8.5g  11m R 55.4 18.1 274:31.07 java                                                                                                                          
</span><span class='line'>31384 omc       20   0 8071m 563m  11m R 53.7  1.2 240:45.47 java                                                                                                                          
</span><span class='line'> 2409 omc       20   0 29.2g 8.5g  11m S 53.1 18.1 245:56.03 java                                                                                                                          
</span><span class='line'>28197 omc       20   0 15.5g 1.5g  14m S 52.4  3.2 279:04.35 java                                                                                                                          
</span><span class='line'> 2406 omc       20   0 29.2g 8.5g  11m R 51.8 18.1 249:00.25 java                                                                                                                          
</span><span class='line'>28208 omc       20   0 15.5g 1.5g  14m R 51.8  3.2 300:50.49 java                                                                                                                          
</span><span class='line'> 2412 omc       20   0 29.2g 8.5g  11m S 51.5 18.1 232:11.81 java                                                                                                                          
</span><span class='line'> 2415 omc       20   0 29.2g 8.5g  11m R 51.5 18.1 234:57.25 java                                                                                                                          
</span><span class='line'> 2391 omc       20   0 29.2g 8.5g  11m R 51.1 18.1 301:52.48 java                                                                                                                          
</span><span class='line'>28175 omc       20   0 15.5g 1.5g  14m R 51.1  3.2 299:18.11 java                                                                                                                          
</span><span class='line'>31383 omc       20   0 8071m 563m  11m R 50.8  1.2 242:23.43 java                                                                                                                          
</span><span class='line'>16662 omc       20   0 29.2g 8.5g  11m R 49.5 18.1   3:26.22 java                                                                                                                          
</span><span class='line'>31381 omc       20   0 8071m 563m  11m R 49.5  1.2 237:05.25 java                                                                                                                          
</span><span class='line'>   41 root      20   0     0    0    0 S 48.9  0.0  82652:00 ksoftirqd/9                                                                                                                   
</span><span class='line'>   17 root      20   0     0    0    0 S 47.9  0.0  83990:59 ksoftirqd/3                                                                                                                   
</span><span class='line'>   65 root      20   0     0    0    0 S 47.9  0.0  83476:26 ksoftirqd/15                                                                                                                  
</span><span class='line'> 2408 omc       20   0 29.2g 8.5g  11m R 47.9 18.1 249:43.27 java                                                                                                                          
</span><span class='line'>31382 omc       20   0 8071m 563m  11m R 47.9  1.2 237:07.76 java                                                                                                                          
</span><span class='line'>   49 root      20   0     0    0    0 S 47.3  0.0  86743:04 ksoftirqd/11                                                                                                                  
</span><span class='line'>   89 root      20   0     0    0    0 R 46.6  0.0  84609:14 ksoftirqd/21                                                                                                                  
</span><span class='line'>   81 root      20   0     0    0    0 S 46.3  0.0  80142:39 ksoftirqd/19                                                                                                                  
</span><span class='line'>   61 root      20   0     0    0    0 R 46.0  0.0  83728:50 ksoftirqd/14                                                                                                                  
</span><span class='line'>31376 omc       20   0 8071m 563m  11m R 45.3  1.2 306:00.66 java                                                                                                                          
</span><span class='line'>   33 root      20   0     0    0    0 R 45.0  0.0  80538:15 ksoftirqd/7                                                                                                                   
</span><span class='line'>31385 omc       20   0 8071m 563m  11m R 45.0  1.2 272:52.36 java                                                                                                                          
</span><span class='line'>   13 root      20   0     0    0    0 S 44.7  0.0  84298:42 ksoftirqd/2                                                                                                                   
</span><span class='line'>   73 root      20   0     0    0    0 S 43.7  0.0  82342:53 ksoftirqd/17                                                                                                                  
</span><span class='line'>   53 root      20   0     0    0    0 R 43.4  0.0  82083:54 ksoftirqd/12                                                                                                                  
</span><span class='line'>   97 root      20   0     0    0    0 S 43.4  0.0  85993:53 ksoftirqd/23                                                                                                                  
</span><span class='line'>   45 root      20   0     0    0    0 R 42.4  0.0  86231:24 ksoftirqd/10                                                                                                                  
</span><span class='line'>   77 root      20   0     0    0    0 S 42.1  0.0  82420:20 ksoftirqd/18                                                                                                                  
</span><span class='line'> 2407 omc       20   0 29.2g 8.5g  11m R 41.1 18.1 240:01.88 java                                                                                                                          
</span><span class='line'> 2410 omc       20   0 29.2g 8.5g  11m R 40.8 18.1 227:49.76 java                                                                                                                          
</span><span class='line'>   85 root      20   0     0    0    0 R 40.5  0.0  84558:37 ksoftirqd/20                                                                                                                  
</span><span class='line'>28196 omc       20   0 15.5g 1.5g  14m R 38.2  3.2 276:56.00 java                                                                                                                          
</span><span class='line'>   29 root      20   0     0    0    0 S 37.9  0.0  78416:08 ksoftirqd/6                                                                                                                   
</span><span class='line'>   37 root      20   0     0    0    0 S 37.9  0.0  82637:15 ksoftirqd/8                                                                                                                   
</span><span class='line'> 2411 omc       20   0 29.2g 8.5g  11m R 37.9 18.1 247:22.02 java                                                                                                                          
</span><span class='line'> 2360 omc       20   0 29.2g 8.5g  11m S 37.6 18.1 179:49.10 java                                                                                                                          
</span><span class='line'> 2413 omc       20   0 29.2g 8.5g  11m S 36.9 18.1 233:48.03 java                                                                                                                          
</span><span class='line'>   69 root      20   0     0    0    0 R 36.3  0.0  82727:24 ksoftirqd/16                                                                                                                  
</span><span class='line'>    4 root      20   0     0    0    0 R 35.6  0.0  81490:34 ksoftirqd/0                                                                                                                   
</span><span class='line'>31369 omc       20   0 8071m 563m  11m R 35.6  1.2 192:32.42 java                                                                                                                          
</span><span class='line'>   21 root      20   0     0    0    0 S 35.0  0.0  83272:02 ksoftirqd/4                                                                                                                   
</span><span class='line'>28167 omc       20   0 15.5g 1.5g  14m R 33.7  3.2 197:02.78 java                                                                                                                          
</span><span class='line'>   25 root      20   0     0    0    0 S 27.2  0.0  82812:29 ksoftirqd/5                                                                                                                   
</span><span class='line'>   93 root      20   0     0    0    0 R 25.9  0.0  86416:55 ksoftirqd/22</span></code></pre></td></tr></table></div></figure>


<p>按照网络上的文档，查cpu时间很长的、占用很高的线程，然后拿着ID转成16进程到jstack里面去对：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[omc@cu-omc1 ~]$ jstack 28147
</span><span class='line'>2017-06-01 08:07:13
</span><span class='line'>Full thread dump Java HotSpot(TM) 64-Bit Server VM (23.7-b01 mixed mode):
</span><span class='line'>...
</span><span class='line'>"Timer-0" daemon prio=10 tid=0x00007fbd84850000 nid=0x6e27 in Object.wait() [0x00007fbe31f98000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at java.util.TimerThread.mainLoop(Timer.java:552)
</span><span class='line'>        - locked &lt;0x0000000767760360&gt; (a java.util.TaskQueue)
</span><span class='line'>        at java.util.TimerThread.run(Timer.java:505)
</span><span class='line'>
</span><span class='line'>"schedulerFactory_QuartzSchedulerThread" prio=10 tid=0x00007fbd843f6000 nid=0x6e26 in Object.wait() [0x00007fbe32099000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at org.quartz.core.QuartzSchedulerThread.run(QuartzSchedulerThread.java:311)
</span><span class='line'>        - locked &lt;0x0000000767770098&gt; (a java.lang.Object)
</span><span class='line'>
</span><span class='line'>"schedulerFactory_Worker-2" prio=10 tid=0x00007fbd848cd000 nid=0x6e25 in Object.wait() [0x00007fbe3219a000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:568)
</span><span class='line'>        - locked &lt;0x00000007677ebb38&gt; (a java.lang.Object)
</span><span class='line'>
</span><span class='line'>"schedulerFactory_Worker-1" prio=10 tid=0x00007fbd848b3000 nid=0x6e24 in Object.wait() [0x00007fbe3229b000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:568)
</span><span class='line'>        - locked &lt;0x00000007677ec710&gt; (a java.lang.Object)
</span><span class='line'>...
</span><span class='line'>"GC task thread#17 (ParallelGC)" prio=10 tid=0x00007fbe64035000 nid=0x6e06 runnable 
</span><span class='line'>
</span><span class='line'>"VM Periodic Task Thread" prio=10 tid=0x00007fbe6411f800 nid=0x6e0e waiting on condition 
</span><span class='line'>
</span><span class='line'>JNI global references: 321
</span><span class='line'>
</span><span class='line'>[omc@cu-omc1 ~]$ echo "obase=16;28203" | bc
</span><span class='line'>6E2B
</span><span class='line'>[omc@cu-omc1 ~]$ cat | while read id ; do echo "obase=16;$id" | bc ; done &lt;&lt;EOF
</span><span class='line'>28174
</span><span class='line'>28203
</span><span class='line'>28197
</span><span class='line'>28208
</span><span class='line'>28175
</span><span class='line'>28196
</span><span class='line'>28167
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>6E0E
</span><span class='line'>6E2B
</span><span class='line'>6E25
</span><span class='line'>6E30
</span><span class='line'>6E0F
</span><span class='line'>6E24
</span><span class='line'>6E07
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/linux-jdk7-jstack.png" alt="" /></p>

<p>基本都是sleep，wait的线程占用cpu很大。并且导致了系统cpu软中断处理进程ksoftirqd占用了大部分系统资源。系统不停的在处理上下文，负载奇高：</p>

<p><img src="http://winseliu.com/images/blogs/linux-jdk7-vmstat.png" alt="" /></p>

<p>ksoftirqd 不知道干嘛的，/proc/interrupts 看不懂，查了sleep和wait的区别，strace、iostat、jmap、jstack、jstat、vmstat、pidstat、还有看到内存补齐的一些文章，反正就是找不到北。</p>

<p>一开始以为是quartz的问题，对比了其他机器的quartz应用，有怀疑过版本问题（quartz-1.8.6, 2.2.0）；有试着去减少simplethreadpool的默认线程数（org.quartz.threadPool.threadCount），CPU占用是会少一点点，但是ksoftirqd还是压力很大，系统还是很大部分消耗在上下文切换，路子不对。</p>

<p>问题环境：</p>

<ul>
<li>Red Hat Enterprise Linux Server release 6.3 (Santiago)/2.6.32-279.el6.x86_64</li>
<li>Spring + quartz-2.2.&frac12;</li>
<li>jdk1.7.0_17</li>
</ul>


<p>完全没辙，不是功能代码的问题啊。搞到12点，困死了，回去睡个觉。今天一早起来，想想，不如换个 <strong>JDK8</strong> 试试吧（按照部署要求jdk放local目录下，要ROOT密码的昨晚就没动）。我勒个去，重启了感觉世界都变亮了。上下文切换cs 1w不到，us、sy基本忽略不计啊。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ vmstat -a 1
</span><span class='line'>procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
</span><span class='line'> r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st
</span><span class='line'> 0  0 517160 25052176 12486824 10402340    0    0     2    31    0    0  4  9 86  0  0
</span><span class='line'> 0  0 517160 25052732 12486972 10401996    0    0     0  4676 4548 4806  0  0 99  0  0
</span><span class='line'> 1  0 517160 25052468 12486972 10402356    0    0     0     0 4044 4419  0  0 99  0  0
</span><span class='line'> 0  1 517160 25053664 12486852 10401992    0    0     0  8100 7608 5311  0  0 95  4  0
</span><span class='line'> 0  1 517160 25054800 12486852 10402084    0    0     0  8228 7847 5408  1  1 95  4  0
</span><span class='line'> 0  1 517160 25054924 12486852 10402380    0    0     0  8200 8075 4929  0  0 95  4  0
</span><span class='line'> 1  1 517160 25054868 12486852 10402112    0    0     0  7484 7898 5754  1  1 94  4  0
</span><span class='line'> 2  1 517160 25055544 12486848 10402148    0    0     0  8224 7537 4428  0  0 95  4  0</span></code></pre></td></tr></table></div></figure>


<p>好吧，以后优化的第一步就是换JDK .__. 。就像优化数据库第一步就建索引 V.V 。应该是JDK8对object.wait调用linux系统调用进行了优化。</p>

<h2>有点意思</h2>

<ul>
<li><a href="http://coderplay.iteye.com/blog/1481211">从Java视角理解CPU上下文切换(Context Switch)</a></li>
<li><a href="http://coderplay.iteye.com/blog/1485760">从Java视角理解CPU缓存(CPU Cache)</a></li>
<li><a href="http://coderplay.iteye.com/blog/1486649">从Java视角理解伪共享(False Sharing)</a></li>
<li><a href="https://github.com/LMAX-Exchange/disruptor">disruptor</a></li>
<li><a href="http://www.cnblogs.com/zhiranok/archive/2012/08/13/context_switch_1.html">http://www.cnblogs.com/zhiranok/archive/2012/08/13/context_switch_1.html</a></li>
<li><a href="http://www.bijishequ.com/detail/60264?p=">http://www.bijishequ.com/detail/60264?p=</a></li>
<li><a href="http://9leg.com/java/2016/08/09/cpu-consumption-analysis.html">http://9leg.com/java/2016/08/09/cpu-consumption-analysis.html</a></li>
</ul>


<blockquote><p>us过高
当us值过高时，表示运行的应用消耗了大部分的cpu。在这种情况下，对于java应用而言，最重要的是找到具体消耗cpu的线程所执行的代码，可以采用如下方法。</p>

<p>首先通过linux命令top命令查看us过高的pid值</p>

<p>通过top -Hp pid查看该pid进程下的线程的cpu消耗状况，得到具体pid值</p>

<p>将pid值转化为16进制，这个转化后的值对应nid值的线程</p>

<p>通过jstack pid grep -C 20 “16进制的值” 命令查看运行程序的线程信息</p>

<p>该线程就是消耗cpu的线程，在采样时须多执行几次上述的过程，以确保找到真实的消耗cpu的线程。</p>

<p>java应用造成us过高的原因主要是线程一直处于可运行的状态Runnable，通常是这些线程在执行无阻塞、循环、正则或纯粹的计算等动作造成。 另外一个可能会造成us过高的原因是频繁的gc。如每次请求都需要分配较多内存，当访问量高时就导致不断的进行gc，系统响应速度下降， 进而造成堆积的请求更多，消耗的内存严重不足，最严重的时候会导致系统不断进行FullGC，对于频繁的gc需要通过分析jvm内存的消耗来查找原因。</p>

<p>sy过高
当sy值过高时，表示linux花费了更多的时间在进行线程切换。java应用造成这种现象的主要原因是启动的线程比较多， 且这些线程多处于不断的阻塞（例如锁等待，io等待）和执行状态的变化过程中，这就导致了操作系统要不断的切换执行的线程， 产生大量的上下文切换。在这种情况下，对java应用而言，最重要的是找出不断切换状态的原因， 可采用的方法为通过kill -3 pid 或jstack -l pid的方法dump出java应用程序的线程信息，查看线程的状态信息以及锁信息， 找出等待状态或锁竞争过多的线程。</p></blockquote>

<ul>
<li><a href="http://yaocoder.blog.51cto.com/2668309/1543352">http://yaocoder.blog.51cto.com/2668309/1543352</a></li>
</ul>


<p>strace -T -r -c -p pid
pstack pid
trace -p tid</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive on Spark预测性执行BUG一枚]]></title>
    <link href="http://winseliu.com/blog/2017/05/23/spark-on-hive-speculation-shit-bug/"/>
    <updated>2017-05-23T12:11:49+00:00</updated>
    <id>http://winseliu.com/blog/2017/05/23/spark-on-hive-speculation-shit-bug</id>
    <content type="html"><![CDATA[<p>为了平复难以平复的痛苦，难以掩饰的激动，把这次遇到并解决的记录下。尽管最终解决的patch是官网的: <a href="https://issues.apache.org/jira/browse/HIVE-13066">Hive on Spark gives incorrect results when speculation is on</a>。</p>

<p>版本说明下：
* hive-1.2.1
* spark-1.3.1</p>

<p>在没有启动spark.speculation前，有个别任务执行非常慢，非常之讨厌。而启用预测性执行后，时不时任务会有些会失败，让人很烦躁。但是吧，也不算故障，说来也奇怪，重启下后再次查询问题就不出现了，也就没太在意。</p>

<p>今天数据量比较大，并且是上头检查。妈蛋，搞成了故障，没得办法，必须把原因找出来了。下来就帖日志了：</p>

<p>应用SQL查询报错日志：啥也看不到，就知道Hive查询报错，只能拿着时间去查Hive日志</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ERROR] 14:19:56.685 [RMI TCP Connection(7)-192.168.31.11] c.e.z.h.s.BaseHiveQueryService | Error while processing statement: FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask
</span><span class='line'>java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask
</span><span class='line'>        at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
</span><span class='line'>        at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:392)
</span><span class='line'>        at org.apache.hive.jdbc.HivePreparedStatement.executeQuery(HivePreparedStatement.java:109)
</span><span class='line'>        at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96)
</span><span class='line'>        at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96)
</span><span class='line'>        at com.eshore.zhfx.hbase.service.BaseHiveQueryService.listIteratorInternal(BaseHiveQueryService.java:101)
</span><span class='line'>        at com.eshore.zhfx.hbase.service.BaseHiveQueryService.listIterator(BaseHiveQueryService.java:80)
</span><span class='line'>        at com.eshore.zhfx.hbase.QueryService.getAccessLogIterator(QueryService.java:140)
</span><span class='line'>        at com.eshore.zhfx.hbase.QueryService$$FastClassByCGLIB$$a60bf6f7.invoke(&lt;generated&gt;)
</span><span class='line'>        at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191)
</span><span class='line'>        at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:688)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
</span><span class='line'>        at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:50)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:50)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:89)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:621)
</span><span class='line'>        at com.eshore.zhfx.hbase.QueryService$$EnhancerByCGLIB$$9a4ab584.getAccessLogIterator(&lt;generated&gt;)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>        at java.lang.reflect.Method.invoke(Method.java:601)
</span><span class='line'>        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:309)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
</span><span class='line'>        at org.springframework.remoting.support.RemoteInvocationTraceInterceptor.invoke(RemoteInvocationTraceInterceptor.java:77)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
</span><span class='line'>        at com.sun.proxy.$Proxy22.getAccessLogIterator(Unknown Source)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</span></code></pre></td></tr></table></div></figure>


<p>HIVE服务日志：rename错了，但是也好像看不到啥。知道那个节点有问题了，去查节点日志</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2017-05-23 14:19:20,509 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) - 2017-05-23 14:19:20,508 WARN  [task-result-getter-1] scheduler.TaskSetManager: Lost task 2199.1 in stage 2.0 (TID 4517, hadoop-slaver41): java.lang.IllegalStateException: Hit error while closing operators - failing tree: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>2017-05-23 14:19:20,509 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:195)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:58)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:106)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at scala.collection.Iterator$class.foreach(Iterator.scala:727)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.scheduler.Task.run(Task.scala:64)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at java.lang.Thread.run(Thread.java:722)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) - Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.commit(FileSinkOperator.java:237)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.access$200(FileSinkOperator.java:143)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1051)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:616)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,511 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:172)
</span><span class='line'>2017-05-23 14:19:20,511 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  ... 15 more
</span><span class='line'>2017-05-23 14:19:20,511 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) - </span></code></pre></td></tr></table></div></figure>


<p>Task错误节点错误日志：这日志没啥。重名，拿名称去查namenode日志看看是啥子？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: FS[24]: records written - 0
</span><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: Final Path: FS hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0
</span><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: Writing to temp file: FS hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0
</span><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: New Final Path: FS hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>17/05/23 14:19:19 INFO compress.CodecPool: Got brand-new compressor [.snappy]
</span><span class='line'>org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.commit(FileSinkOperator.java:237)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.access$200(FileSinkOperator.java:143)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1051)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:616)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:172)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:58)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:106)
</span><span class='line'>        at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
</span><span class='line'>        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
</span><span class='line'>        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
</span><span class='line'>        at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>        at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>        at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>        at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
</span><span class='line'>        at org.apache.spark.scheduler.Task.run(Task.scala:64)
</span><span class='line'>        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
</span><span class='line'>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
</span><span class='line'>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
</span><span class='line'>        at java.lang.Thread.run(Thread.java:722)</span></code></pre></td></tr></table></div></figure>


<p>Namenode日志：有点点线索了，分配了两次，导致了第二个任务写入的时刻报错！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ grep '_tmp.002199' hadoop/logs/hadoop-hadoop-namenode-hadoop-master2.log.1
</span><span class='line'>2017-05-23 14:19:01,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0. BP-1414312971-192.168.32.11-1392479369615 blk_1219124858_145508182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-ad2eac59-1e38-4019-a5ac-64c465366186:NORMAL:192.168.32.93:50010|RBW], ReplicaUnderConstruction[[DISK]DS-90c8cbe3-fd70-4ad7-938a-4248b4435df7:NORMAL:192.168.32.136:50010|RBW], ReplicaUnderConstruction[[DISK]DS-9da76df9-47f0-4e25-b375-e1bf32f4cf52:NORMAL:192.168.36.58:50010|RBW]]}
</span><span class='line'>2017-05-23 14:19:14,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 is closed by DFSClient_attempt_201705231411_0000_m_001585_0_1316598676_51
</span><span class='line'>2017-05-23 14:19:20,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0. BP-1414312971-192.168.32.11-1392479369615 blk_1219125517_145508841{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-4d4c90f0-1ddf-4800-b33a-e776e58dc744:NORMAL:192.168.32.61:50010|RBW], ReplicaUnderConstruction[[DISK]DS-948cd823-5a4c-4673-8ace-99f02a26522b:NORMAL:192.168.32.52:50010|RBW], ReplicaUnderConstruction[[DISK]DS-7818addb-3881-446e-abb3-2c178be6bb63:NORMAL:192.168.32.176:50010|RBW]]}
</span><span class='line'>2017-05-23 14:19:20,478 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 is closed by DFSClient_attempt_201705231411_0000_m_001345_1_1292482540_51
</span><span class='line'>2017-05-23 14:19:20,480 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy because destination exists</span></code></pre></td></tr></table></div></figure>


<p>好了，看到这里，驴脑袋还没怀疑到是预测性执行导致的问题。当时想为啥会出现同一个文件名呢：SPARK ON HIVE多个stage执行导致的? 但是重启后报一样的错误，002199是哪里产生，怎么产生的？</p>

<p>MAP太多了000000又循环了一轮？看了执行的map数也就2600啊，不应该啊。</p>

<p>那么这个文件名是哪里产生的呢？然后就搞了下远程调试：没啥用，错误是在task上发生的，调试hive-driver没啥用，但是有意外收获</p>

<ul>
<li><a href="http://www.winseliu.com/blog/2014/06/21/upgrade-hive/">http://www.winseliu.com/blog/2014/06/21/upgrade-hive/</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started">https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hive]$ DEBUG=true bin/hive
</span><span class='line'>Listening for transport dt_socket at address: 8000
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/home/hadoop/apache-hive-1.2.1-bin/conf/hive-log4j.properties
</span><span class='line'>hive&gt; set hive.execution.engine=spark; '查询之前需要设置下引擎，故障得先处理。搞成默认的mr跑是成功的
</span><span class='line'>hive&gt;                                  'SQLSQLSQL...执行刚报错的SQL
</span><span class='line'>Query ID = hadoop_20170523173748_7660d9fb-9683-4792-8315-a51f6dcc270b
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 48a8668b-1c59-4cbf-b1e2-e19612ee77d0
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2017-05-23 17:38:15,730 Stage-0_0: 0/2609
</span><span class='line'>2017-05-23 17:38:16,739 Stage-0_0: 0(+159)/2609
</span><span class='line'>...
</span><span class='line'>2017-05-23 17:39:23,182 Stage-0_0: 2162(+447)/2609
</span><span class='line'>2017-05-23 17:39:24,188 Stage-0_0: 2167(+608)/2609
</span><span class='line'>2017-05-23 17:39:25,195 Stage-0_0: 2201(+836,-1)/2609
</span><span class='line'>2017-05-23 17:39:26,201 Stage-0_0: 2215(+832,-2)/2609
</span><span class='line'>2017-05-23 17:39:27,207 Stage-0_0: 2227(+820,-2)/2609
</span><span class='line'>2017-05-23 17:39:28,213 Stage-0_0: 2250(+797,-2)/2609
</span><span class='line'>2017-05-23 17:39:29,219 Stage-0_0: 2280(+767,-2)/2609
</span><span class='line'>2017-05-23 17:39:30,224 Stage-0_0: 2338(+709,-2)/2609
</span><span class='line'>2017-05-23 17:39:31,230 Stage-0_0: 2350(+696,-3)/2609
</span><span class='line'>2017-05-23 17:39:32,236 Stage-0_0: 2359(+684,-6)/2609
</span><span class='line'>2017-05-23 17:39:33,243 Stage-0_0: 2363(+676,-10)/2609
</span><span class='line'>2017-05-23 17:39:34,249 Stage-0_0: 2365(+673,-12)/2609
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>有报错了，赶紧去web页面看了下结果，好家伙，全部是Speculation的报错：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-speculation.jpg" alt="" /></p>

<p>在结合前面的namenode的日志，基本就走到正道上面。然后 <strong> hive spark speculation </strong> 一股沟，没错第一条就是hive官网的bug啊。</p>

<ul>
<li><a href="https://issues.apache.org/jira/browse/HIVE-13066">https://issues.apache.org/jira/browse/HIVE-13066</a></li>
</ul>


<p>然后就是打patch修改HivePairFlatMapFunction，验证是OK的。至少原来出错的语句完美跑完。</p>

<h2>总结下</h2>

<p>就是前段集成攻城狮把网络回环的问题处理了，导致网络状态好的不要不要的啊！把那些有备用10M网卡全部停了，集群的机器的网络好了N倍。第二个就是数据量实在大，其实speculation有启动，但是最先完成的还是先启动的，又没有把预测执行kill掉并且还运行完了最终还保存到同名文件。最后让我又一次体验了一把找开源软件BUG激情四射的半天。</p>

<p>记录聊以慰藉！！</p>

<hr />

<p>other : SparkClientImpl LeaseExpiredException No lease on  File does not exist</p>

<ul>
<li><a href="https://stackoverflow.com/questions/26842933/leaseexpiredexception-no-lease-error-on-hdfs-failed-to-close-file">LeaseExpiredException: No lease error on HDFS (Failed to close file)</a></li>
<li><a href="https://stackoverflow.com/questions/7559880/leaseexpiredexception-no-lease-error-on-hdfs">LeaseExpiredException: No lease error on HDFS</a></li>
<li><a href="http://www.jianshu.com/p/f5ec6c7bb176">http://www.jianshu.com/p/f5ec6c7bb176</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet批量自动化部署实战]]></title>
    <link href="http://winseliu.com/blog/2017/05/05/puppet-automate-deploy-hosts/"/>
    <updated>2017-05-05T00:33:37+00:00</updated>
    <id>http://winseliu.com/blog/2017/05/05/puppet-automate-deploy-hosts</id>
    <content type="html"><![CDATA[<p>断断续续使用Puppet近一年，多次体验到Puppet的强大：SSH更新、需ROOT权限批量处理等等。这次集群新上架了又爽了一把。把整个过程记录下来，方便今后参考。</p>

<p>运维的同事也想了解puppet，在docker容器上安装了一遍，把具体的内容附上：<a href="http://winseliu.com/files/expect+puppet.txt">expect+puppet.txt</a></p>

<p>这次操作是对以前零零碎碎积累的一次检验和温习。需要用到的工具比较多：</p>

<ul>
<li>RPM打包、本地YUM仓库 - RPMBUILD、CREATEREPO</li>
<li>SSH无密钥登录 - EXPECT&amp;FOR</li>
<li>时间同步、host配置 - SCP、SSH&amp;FOR</li>
<li>创建用户、新用户无密钥等 - PUPPET</li>
<li>ssh_known_hosts - PUPPETDB</li>
<li>rhel.repo、gmond、时区设置 - PUPPET</li>
</ul>


<p>远程配置机器首先当然是进行无密钥登录的设置，这样才能进行批量操作，不然几百台机器每次都需要干预太烦人、工作量太大。无密钥登录使用原来写好的EXPECT脚本，使用FOR循环执行，等待结果即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 ~]# cat ssh-copy-id.expect 
</span><span class='line'>#!/usr/bin/expect  
</span><span class='line'>
</span><span class='line'>## Usage $0 [user@]host password
</span><span class='line'>
</span><span class='line'>set host [lrange $argv 0 0];
</span><span class='line'>set password [lrange $argv 1 1] ;
</span><span class='line'>
</span><span class='line'>set timeout 30;
</span><span class='line'>
</span><span class='line'>spawn ssh-copy-id $host ;
</span><span class='line'>
</span><span class='line'>expect {
</span><span class='line'>  "(yes/no)?" { send yes\n; exp_continue; }
</span><span class='line'>  "password:" { send $password\n; exp_continue; }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>exec sleep 1;
</span><span class='line'>
</span><span class='line'># 用for，不要用while
</span><span class='line'>for h in `cat /etc/hosts | grep -v '^#' | grep slaver | grep -E '\.36\.|\.37\.' | awk '{print $2}' ` ; do 
</span><span class='line'>  ./ssh-copy-id.expect $h 'PASSWD';
</span><span class='line'>done
</span></code></pre></td></tr></table></div></figure>


<p>做好无密钥登录，拷贝 /etc/hosts, /etc/cron.daily/ntp.cron, /etc/yum.repos.d/puppet.repo 到全部的新机器。这里puppet.repo是自己编译搭建的私有仓库（具体编译配置步骤查看puppet分类下的文章），通过 <code>yum install mcollective-plugins-simple</code> 就可以把mcolletive和puppet-agent安装好。把所有步骤封装到一个prepare.sh脚本，内容如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'># must be hostname!!
</span><span class='line'>HOSTS="$@"
</span><span class='line'>PASSWD=${PASSWD:-'root'}
</span><span class='line'>PUPPETSERVER="hadoop-master1"
</span><span class='line'>
</span><span class='line'>for h in $HOSTS ; do ./ssh-copy-id.expect $h "$PASSWD" ; done
</span><span class='line'>
</span><span class='line'>for h in $HOSTS ; do
</span><span class='line'>scp /etc/hosts $h:/etc ;
</span><span class='line'>scp /etc/yum.repos.d/puppet.repo $h:/etc/yum.repos.d/ ;
</span><span class='line'>scp /etc/cron.daily/ntp.cron $h:/etc/cron.daily/ ;
</span><span class='line'>
</span><span class='line'>ssh $h '
</span><span class='line'>#ntpdate cu-omc1 #着重注意
</span><span class='line'>rm -rf /etc/yum.repos.d/CentOS-*
</span><span class='line'>yum install mcollective-plugins-simple -y
</span><span class='line'>' ;
</span><span class='line'>
</span><span class='line'>scp /etc/puppetlabs/mcollective/server.cfg $h:/etc/puppetlabs/mcollective/
</span><span class='line'>ssh $h "
</span><span class='line'>sed -i '/HOSTNAME/ {
</span><span class='line'>i \
</span><span class='line'>HOSTNAME=$h
</span><span class='line'>d
</span><span class='line'>} ' /etc/sysconfig/network
</span><span class='line'>hostname $h
</span><span class='line'>
</span><span class='line'>echo -e '\n\n[agent]\nserver = $PUPPETSERVER\ncertname=$h' &gt; /etc/puppetlabs/puppet/puppet.conf
</span><span class='line'>chkconfig mcollective on
</span><span class='line'>service mcollective start
</span><span class='line'>"
</span><span class='line'>
</span><span class='line'>done
</span></code></pre></td></tr></table></div></figure>


<p>然后执行 <code>./prepare.sh hadoop-slaver{200..500}</code> 就可以了。</p>

<p>接下来重点讲讲PUPPET配置的编写。</p>

<p>首先根据当前需要创建的用户、组把创建用户的配置写好：</p>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.10/quick_start_user_group.html">https://docs.puppet.com/puppet/4.10/quick_start_user_group.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 ~]# puppet resource -e group hadoop
</span><span class='line'>group { 'hadoop':
</span><span class='line'>  ensure =&gt; 'present',
</span><span class='line'>  gid    =&gt; '501',
</span><span class='line'>}
</span><span class='line'>[root@hadoop-master1 ~]# puppet resource -e user hadoop
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  gid              =&gt; '501',
</span><span class='line'>  groups           =&gt; ['wheel'],
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; '$6$AfnA...uIhHC9I.',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  uid              =&gt; '501',
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>添加require、groups，然后删除uid、gid。最后需要添加 managehome => true, 否则用户目录就不会自动创建：</p>

<ul>
<li><a href="http://www.dbalex.com/category/devops/puppet">http://www.dbalex.com/category/devops/puppet</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 默认不创建用户目录
</span><span class='line'>[root@hadoop-slaver200 ~]# su - hadoop
</span><span class='line'>su: warning: cannot change directory to /home/hadoop: No such file or directory
</span><span class='line'>-bash-4.1$ 
</span><span class='line'>
</span><span class='line'># 创建用户配置成品
</span><span class='line'>group { 'hadoop':
</span><span class='line'>  ensure =&gt; 'present',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  groups           =&gt; ['hadoop', 'wheel'],
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; '$6$Af...IhHC9I.',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  managehome       =&gt; true,
</span><span class='line'>  require          =&gt; Group['hadoop'],
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://ask.puppet.com/question/15753/how-can-i-chown-directories-recursivley/">https://ask.puppet.com/question/15753/how-can-i-chown-directories-recursivley/</a></li>
<li><a href="https://serverfault.com/questions/542947/issue-with-changing-permission-and-owner-recursively-on-files-with-puppet-and-va">https://serverfault.com/questions/542947/issue-with-changing-permission-and-owner-recursively-on-files-with-puppet-and-va</a></li>
<li><a href="https://serverfault.com/questions/416254/adding-an-existing-user-to-a-group-with-puppet">https://serverfault.com/questions/416254/adding-an-existing-user-to-a-group-with-puppet</a></li>
</ul>


<p>添加好用户后，就是把无密钥登录也让PUPPET来弄。其实就是把 id_rsa.pub 的内容写入都行机器的 authorized_keys ，PUPPET已经自带了这个类：ssh_authorized_key。把id_ras.pub的内容（中间的内容）赋值给 key 属性即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh_authorized_key {'root@hadoop-master1':
</span><span class='line'>  user =&gt; 'root',
</span><span class='line'>  type =&gt; 'ssh-rsa',
</span><span class='line'>  key =&gt; 'AAAAB3NzaC1y...O1Q==',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>ssh_authorized_key {'hadoop@hadoop-master1':
</span><span class='line'>  user =&gt; 'hadoop',
</span><span class='line'>  type =&gt; 'ssh-rsa',
</span><span class='line'>  key =&gt; 'AAAAB3Nza...IZYPw==',
</span><span class='line'>  require  =&gt; User['hadoop'],
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>无密钥登录比较容易，没有涉及到收集节点信息。仅仅把公钥写入新机器还不够，还得把 known_hosts 也处理好，不然第一次连接新机器都需要输入一下yes。内容如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-slaver200 ~]$ ssh hadoop-slaver202
</span><span class='line'>The authenticity of host 'hadoop-slaver202 (192.168.36.59)' can't be established.
</span><span class='line'>RSA key fingerprint is fe:7e:26:c4:56:ea:f4:21:61:82:6d:9b:4a:72:93:a4.
</span><span class='line'>Are you sure you want to continue connecting (yes/no)? </span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_virtual.html">https://docs.puppet.com/puppet/4.4/lang_virtual.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_collectors.html">https://docs.puppet.com/puppet/4.4/lang_collectors.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_exported.html">https://docs.puppet.com/puppet/4.4/lang_exported.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_resources_advanced.html#amending-attributes-with-a-collector">https://docs.puppet.com/puppet/4.4/lang_resources_advanced.html#amending-attributes-with-a-collector</a></li>
<li><a href="https://docs.puppet.com/puppet/latest/types/ssh_authorized_key.html">https://docs.puppet.com/puppet/latest/types/ssh_authorized_key.html</a></li>
<li><a href="https://www.puppetcookbook.com/posts/install-package.html">https://www.puppetcookbook.com/posts/install-package.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.10/lang_conditional.html">https://docs.puppet.com/puppet/4.10/lang_conditional.html</a></li>
</ul>


<p>正如上面官网介绍的，需要用到虚拟资源，自动把新机器指纹（fingerprint）写入到机器需要PUPPETDB的支持，安装配置又需要PGSQL的配合。需要耗费一番功夫，但是还是划得来的（具体安装步骤查看puppet分类下的文章）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if $hostname =~ /^hadoop-/ {
</span><span class='line'>
</span><span class='line'>  $host_aliases = [ $ipaddress, $hostname ]
</span><span class='line'>  
</span><span class='line'>  # Export hostkeys from all hosts.
</span><span class='line'>  @@sshkey { $::fqdn:
</span><span class='line'>    ensure =&gt; present,
</span><span class='line'>    host_aliases =&gt; $host_aliases,
</span><span class='line'>    type =&gt; 'ssh-rsa',
</span><span class='line'>    key =&gt; $sshrsakey,
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  if $hostname =~ /^hadoop-master/ {
</span><span class='line'>    # realize all exported
</span><span class='line'>    Sshkey &lt;&lt;| |&gt;&gt;
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>先在所有slaver机器运行一遍 puppet agent -t ，然后再在master节点把收集的指纹写入到 /etc/ssh/ssh_known_hosts 。</p>

<p>这里说个插曲：机器的hosts和hostname是通过 FOR&amp;SSH 命令来统一修改的，有些可能没有配置好导致机器的主机名有重复。通过执行配置known_hosts竟然帮我找出了hostname重复的机器，意外的收获。该问题的处理我是直接登录到PGSQL改了对应表的数据处理的。</p>

<p>到这里机器基本能用了。主机名、hosts、时间同步、hadoop用户以及master到该用户的无密钥登录都已经配置好了。</p>

<p>接下来把实战过程中安装gmond的步骤帖出来：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ cd /etc/puppetlabs/code/environments/production/manifests/
</span><span class='line'>
</span><span class='line'>$$ vi change_site.sh
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>## Usage:
</span><span class='line'>##  ./change_site.sh nrpe.site
</span><span class='line'>##
</span><span class='line'>
</span><span class='line'>[[ $# != 1 ]] && exit 1
</span><span class='line'>
</span><span class='line'>cd $(cd $(dirname $0); pwd)
</span><span class='line'>
</span><span class='line'>rm -rf site.pp
</span><span class='line'>ln -s $1 site.pp
</span><span class='line'>
</span><span class='line'>$$ vi pexec.sh
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>## Usage:
</span><span class='line'>##   ./pexec.sh /cu-ud/ sudo_revert.site 
</span><span class='line'>##
</span><span class='line'>
</span><span class='line'>case $# in
</span><span class='line'>1)
</span><span class='line'>  FUNC="$1"
</span><span class='line'>  HOST_PARAM=
</span><span class='line'>  ;;
</span><span class='line'>2)
</span><span class='line'>  FUNC="$2"
</span><span class='line'>  HOST_PARAM="-I $1"
</span><span class='line'>  ;;
</span><span class='line'>*)
</span><span class='line'>  while [ $# -gt 1 ] ; do 
</span><span class='line'>    HOST_PARAM="$HOST_PARAM -I $1"
</span><span class='line'>    shift
</span><span class='line'>  done
</span><span class='line'>  FUNC=$1
</span><span class='line'>  ;;
</span><span class='line'>esac
</span><span class='line'>
</span><span class='line'>cd $(cd $(dirname $0); pwd)
</span><span class='line'>
</span><span class='line'>./change_site.sh "$FUNC"
</span><span class='line'>
</span><span class='line'>if [[ "$HOST_PARAM" != "" && ! "$HOST_PARAM" =~ */* ]] ; then
</span><span class='line'>  mco shell $HOST_PARAM run -- `which puppet` agent -t
</span><span class='line'>else
</span><span class='line'>  mco puppet $HOST_PARAM runall 20
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<p>由于机器增加比较多，且网络环境变的复杂化。把原来的2个分组修改成4个。不同的网络段和功能分别设置不同的广播端口。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ./pexec.sh /hadoop-slaver.$/ gmond.site 
</span><span class='line'>
</span><span class='line'># 采集数据的节点重启后，其他发送数据的节点貌似都需要重启。
</span><span class='line'>$ screen
</span><span class='line'>$ for ((i=1;i&lt;=53;i++)); do  mco shell -I /hadoop-slaver${i}.$/ run -- ' service gmond restart ' ; done 
</span><span class='line'># 这个确认搞的很麻烦，
</span><span class='line'># 想通过ganglia-web获取数据然后判断是否有数据进行重启。</span></code></pre></td></tr></table></div></figure>


<p>Ganglia删除某节点后，如果要从rrds上去掉改节点的信息，需要：重启对应收集的gmond，对应集群的rrds目录，然后重启gmetad。或者等够一段时间，gmetad会自动去掉。</p>

<h2>总结</h2>

<p>现在添加机器，直接连上puppetserver机器然后执行几个命令就可以搞定；</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>HOST=new-host-name 
</span><span class='line'># 无密钥登录和puppet/mco
</span><span class='line'>PASSWD=new-host-root-password ./prepare.sh $HOST
</span><span class='line'>
</span><span class='line'>./pexec.sh $HOST new-hadoop.site
</span><span class='line'>./pexec.sh $HOST gmond.site # 当前需要到web界面确认新节点的数据是否被采集</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s Hadoop Deploy]]></title>
    <link href="http://winseliu.com/blog/2017/04/14/k8s-hadoop-deploy/"/>
    <updated>2017-04-14T02:56:39+00:00</updated>
    <id>http://winseliu.com/blog/2017/04/14/k8s-hadoop-deploy</id>
    <content type="html"><![CDATA[<p>折磨了一个多星期，最后还是调通了。折磨源于不自知，源于孤单，源于自负，后来通过扩展、查阅资料、请教同事顺利解决。简单部署可以查看<a href="https://github.com/winse/docker-hadoop">README.md</a> 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6 -y
</span><span class='line'>
</span><span class='line'>cd kube-deploy
</span><span class='line'>vi hosts
</span><span class='line'>vi k8s.profile
</span><span class='line'># 把deploy同步到其他实体机，同时把k8s.profile映射到/etc/profile.d
</span><span class='line'>./rsync-deploy.sh
</span><span class='line'>
</span><span class='line'>cd docker-multinode/
</span><span class='line'>./master.sh or ./worker.sh
</span><span class='line'>
</span><span class='line'>docker save gcr.io/google_containers/etcd-amd64:3.0.4 | docker-bs load
</span><span class='line'>docker save quay.io/coreos/flannel:v0.6.1-amd64 | docker-bs load
</span><span class='line'>
</span><span class='line'>cd kube-deploy/hadoop/kubenetes/
</span><span class='line'>./prepare.sh
</span><span class='line'>kubectl create -f hadoop-master2.yaml
</span><span class='line'>kubectl create -f hadoop-slaver.yaml </span></code></pre></td></tr></table></div></figure>


<p>Tip：其实使用一套配置就可以启动多个集群，在 <code>kubectl create</code> 后面加上 <code>-n namespace</code> 即可。</p>

<p>比如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubenetes]# kubectl create namespace hd1
</span><span class='line'>[root@cu2 kubenetes]# kubectl create namespace hd2
</span><span class='line'>
</span><span class='line'>[root@cu2 kubenetes]# ./prepare.sh hd1
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-master2.yaml -n hd1
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-slaver.yaml -n hd1
</span><span class='line'>[root@cu2 kubenetes]# ./prepare.sh hd2
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-master2.yaml -n hd2
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-slaver.yaml -n hd2
</span><span class='line'>
</span><span class='line'>[root@cu2 kubenetes]# kubectl get pods --all-namespaces
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE
</span><span class='line'>hd1           hadoop-master2                          1/1       Running   0          28s
</span><span class='line'>hd1           slaver-rc-fdcsw                         1/1       Running   0          18s
</span><span class='line'>hd1           slaver-rc-qv964                         1/1       Running   0          18s
</span><span class='line'>hd2           hadoop-master2                          1/1       Running   0          26s
</span><span class='line'>hd2           slaver-rc-0vdfk                         1/1       Running   0          17s
</span><span class='line'>hd2           slaver-rc-r7g84                         1/1       Running   0          17s
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>现在想来其实就是 <strong> dockerd &ndash;ip-masq=false </strong>的问题（所有涉及的dockerd都需要加）。 还有就是一台机器单机下的容器互相访问，源IP都错也是安装了openvpn所导致，对所有过eth0的都加了MASQUERADE。</p>

<p>根源就在于请求的源地址被替换，也就是iptables的转发进行了SNAT。关于iptables转发这篇文章讲的非常清晰；<a href="http://fancyxinyu.blog.163.com/blog/static/18232136620136185434661/">IPtables之四：NAT原理和配置  </a> 。</p>

<h2>所遇到的问题</h2>

<p>没加ip-masq之前，namenode收到datanode的请求后，源地址是flannel.0的ip: 10.1.98.0。</p>

<p>namenode对应的日志为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2017-04-09 07:22:06,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.1.98.0, datanodeUuid=5086c549-f3bb-4ef6-8f56-05b1f7adb7d3, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-522174fa-6e7b-4c3f-ae99-23c3018e35d7;nsid=1613705851;c=0) storage 5086c549-f3bb-4ef6-8f56-05b1f7adb7d3
</span><span class='line'>2017-04-09 07:22:06,920 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.1.98.0:50010
</span><span class='line'>2017-04-09 07:22:06,921 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.1.98.0:50010</span></code></pre></td></tr></table></div></figure>


<p>一开始以为是flannel的问题，换成yum安装，然后同时flannel把backend切换成vxlan后，还是一样的问题。</p>

<p>最后请教搞网络的同事，应该是请求的源地址被替换了，也就定位到iptables。然后通过查看文档，其实前面也有看到过对应的文章，但是看不明白不知道缘由。</p>

<ul>
<li><a href="https://groups.google.com/d/msg/kubernetes-users/P4uh7y383oo/bPzIRaxhs5gJ">Networking Problem in creating HDFS cluster. - Eugene Yakubovich </a></li>
<li><a href="https://groups.google.com/d/msg/kubernetes-users/P4uh7y383oo/a1GIV4hcAgAJ">Networking Problem in creating HDFS cluster. - Huihui He </a></li>
<li><a href="https://developer.ibm.com/recipes/tutorials/networking-your-docker-containers-using-docker0-bridge/">Networking your docker containers using docker0 bridge</a></li>
</ul>


<p>iptables的部分相关信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# iptables -S -t nat
</span><span class='line'>...
</span><span class='line'>-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
</span><span class='line'>-A PREROUTING -j PREROUTING_direct
</span><span class='line'>-A PREROUTING -j PREROUTING_ZONES_SOURCE
</span><span class='line'>-A PREROUTING -j PREROUTING_ZONES
</span><span class='line'>-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
</span><span class='line'>-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
</span><span class='line'>-A OUTPUT -j OUTPUT_direct
</span><span class='line'>-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
</span><span class='line'>-A POSTROUTING -s 10.1.34.0/24 ! -o docker0 -j MASQUERADE
</span><span class='line'>-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
</span><span class='line'>-A POSTROUTING -j POSTROUTING_direct
</span><span class='line'>-A POSTROUTING -j POSTROUTING_ZONES_SOURCE
</span><span class='line'>-A POSTROUTING -j POSTROUTING_ZONES
</span><span class='line'>-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
</span><span class='line'>-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
</span><span class='line'>-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -m mark --mark 0x4000/0x4000 -j MASQUERADE
</span><span class='line'>-A KUBE-SEP-75CPIAPDB4MAVFWI -s 10.1.40.3/32 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-75CPIAPDB4MAVFWI -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp" -m tcp -j DNAT --to-destination 10.1.40.3:53
</span><span class='line'>-A KUBE-SEP-IWNPEB4T46P6VG5J -s 192.168.0.148/32 -m comment --comment "default/kubernetes:https" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-IWNPEB4T46P6VG5J -p tcp -m comment --comment "default/kubernetes:https" -m recent --set --name KUBE-SEP-IWNPEB4T46P6VG5J --mask 255.255.255.255 --rsource -m tcp -j DNAT --to-destination 192.168.0.148:6443
</span><span class='line'>-A KUBE-SEP-UYUINV25NDNSKNUW -s 10.1.40.3/32 -m comment --comment "kube-system/kube-dns:dns" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-UYUINV25NDNSKNUW -p udp -m comment --comment "kube-system/kube-dns:dns" -m udp -j DNAT --to-destination 10.1.40.3:53
</span><span class='line'>-A KUBE-SEP-XDHL2OHX2ICPQHKI -s 10.1.40.2/32 -m comment --comment "kube-system/kubernetes-dashboard:" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-XDHL2OHX2ICPQHKI -p tcp -m comment --comment "kube-system/kubernetes-dashboard:" -m tcp -j DNAT --to-destination 10.1.40.2:9090
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.1/32 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-SVC-NPX46M4PTMTKRN6Y
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.95/32 -p tcp -m comment --comment "kube-system/kubernetes-dashboard: cluster IP" -m tcp --dport 80 -j KUBE-SVC-XGLOHA7QRQ3V22RZ
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.10/32 -p udp -m comment --comment "kube-system/kube-dns:dns cluster IP" -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.10/32 -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4
</span><span class='line'>-A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
</span><span class='line'>-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-SEP-75CPIAPDB4MAVFWI
</span><span class='line'>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -m recent --rcheck --seconds 10800 --reap --name KUBE-SEP-IWNPEB4T46P6VG5J --mask 255.255.255.255 --rsource -j KUBE-SEP-IWNPEB4T46P6VG5J
</span><span class='line'>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -j KUBE-SEP-IWNPEB4T46P6VG5J
</span><span class='line'>-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment "kube-system/kube-dns:dns" -j KUBE-SEP-UYUINV25NDNSKNUW
</span><span class='line'>-A KUBE-SVC-XGLOHA7QRQ3V22RZ -m comment --comment "kube-system/kubernetes-dashboard:" -j KUBE-SEP-XDHL2OHX2ICPQHKI</span></code></pre></td></tr></table></div></figure>


<p>在dockerd服务脚本加上 <code>--ip-masq=false</code> 后，<code>-A POSTROUTING -s 10.1.34.0/24 ! -o docker0 -j MASQUERADE</code> 这一句就没有了，也就是不会进行源地址重写了，这样请求发送到namenode后还是datanode容器的IP。问题解决，原因简单的让人欲哭无泪啊。</p>

<p>写yaml遇到的一些其他问题：</p>

<ul>
<li><a href="http://andykdocs.de/development/Docker/Fixing+the+Docker+TERM+variable+issue">Fixing the Docker TERM variable issue</a></li>
<li><a href="http://stackoverflow.com/questions/27195466/hdfs-datanode-denied-communication-with-namenode-because-hostname-cannot-be-reso">hdfs Datanode denied communication with namenode because hostname cannot be resolved</a></li>
</ul>


<p>当然还有很多其他的问题，这篇就写这么多，优化工作后面的弄好了再写。</p>

<h2>中间过程步骤记录</h2>

<p>主要就是记录心路历程，如果以后遇到同样的问题能让自己快速回想起来。如果仅仅为了部署，可以跳过该部分，直接后最后的常用命令。</p>

<p>记录下中间 <strong>通过yum安装etcd和flanneld</strong> 的过程。物理机安装flanneld会把配置docker环境变量（/run/flannel/subnet.env）加入启动脚本。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>安装docker-v1.12
</span><span class='line'>https://docs.docker.com/v1.12/
</span><span class='line'>https://docs.docker.com/v1.12/engine/installation/linux/centos/
</span><span class='line'>
</span><span class='line'># 删掉原来的
</span><span class='line'>yum-config-manager --disable docker-ce*
</span><span class='line'>yum remove -y docker-ce*
</span><span class='line'>
</span><span class='line'>sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'
</span><span class='line'>[dockerrepo]
</span><span class='line'>name=Docker Repository
</span><span class='line'>baseurl=https://yum.dockerproject.org/repo/main/centos/7/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=https://yum.dockerproject.org/gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>https://yum.dockerproject.org/repo/main/centos/7/Packages/
</span><span class='line'>[root@cu3 ~]# yum --showduplicates list docker-engine | expand
</span><span class='line'>docker-engine.x86_64             1.12.6-1.el7.centos                  dockerrepo
</span><span class='line'>
</span><span class='line'>[root@cu3 yum.repos.d]# yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/
</span><span class='line'>
</span><span class='line'>cat &gt; /etc/yum.repos.d/virt7-docker-common-release.repo &lt;&lt;EOF
</span><span class='line'>[virt7-docker-common-release]
</span><span class='line'>name=virt7-docker-common-release
</span><span class='line'>baseurl=http://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/
</span><span class='line'>gpgcheck=0
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>yum -y install --enablerepo=virt7-docker-common-release etcd flannel
</span><span class='line'>yum -y install --enablerepo=virt7-docker-common-release flannel
</span><span class='line'>
</span><span class='line'>- ETCD配置
</span><span class='line'>[root@cu3 docker-multinode]# 
</span><span class='line'>etcdctl mkdir /kube-centos/network
</span><span class='line'>etcdctl set /kube-centos/network/config "{ \"Network\": \"10.1.0.0/16\", \"SubnetLen\": 24, \"Backend\": { \"Type\": \"vxlan\" } }"
</span><span class='line'>
</span><span class='line'>- FlANNEL
</span><span class='line'>[root@cu3 ~]# cat /etc/sysconfig/flanneld
</span><span class='line'># Flanneld configuration options  
</span><span class='line'>
</span><span class='line'># etcd url location.  Point this to the server where etcd runs
</span><span class='line'>FLANNEL_ETCD_ENDPOINTS="http://cu3:2379"
</span><span class='line'>
</span><span class='line'># etcd config key.  This is the configuration key that flannel queries
</span><span class='line'># For address range assignment
</span><span class='line'>FLANNEL_ETCD_PREFIX="/kube-centos/network"
</span><span class='line'>
</span><span class='line'># Any additional options that you want to pass
</span><span class='line'>#FLANNEL_OPTIONS=""
</span><span class='line'>
</span><span class='line'>[root@cu2 yum.repos.d]# systemctl daemon-reload
</span><span class='line'>
</span><span class='line'>[root@cu2 yum.repos.d]# cat /run/flannel/subnet.env
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# systemctl cat docker
</span><span class='line'>...
</span><span class='line'># /usr/lib/systemd/system/docker.service.d/flannel.conf
</span><span class='line'>[Service]
</span><span class='line'>EnvironmentFile=-/run/flannel/docker </span></code></pre></td></tr></table></div></figure>


<p>测试过程中有yaml配置中启动sshd，然后启动容器后，通过手动启动namenode、datanode的方式来测试：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd hadoop-2.6.5
</span><span class='line'>gosu hadoop mkdir /data/bigdata
</span><span class='line'>gosu hadoop sbin/hadoop-daemon.sh start datanode 
</span><span class='line'>
</span><span class='line'>cd hadoop-2.6.5/
</span><span class='line'>gosu hadoop  bin/hadoop namenode -format 
</span><span class='line'>gosu hadoop sbin/hadoop-daemon.sh start namenode</span></code></pre></td></tr></table></div></figure>


<p>后来发现问题出在iptables后，又回到原来的docker-bootstrap启动，需要删除flannel.1的网络：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum安装flanneld后停止 https://kubernetes.io/docs/getting-started-guides/scratch/
</span><span class='line'>ip link set flannel.1 down
</span><span class='line'>ip link delete flannel.1
</span><span class='line'>route -n
</span><span class='line'>
</span><span class='line'>rm /usr/lib/systemd/system/docker.service.d/flannel.conf </span></code></pre></td></tr></table></div></figure>


<p>开了防火墙的话，把容器的端加入到信任列表：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>systemctl enable firewalld && systemctl start firewalld
</span><span class='line'>
</span><span class='line'>firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent 
</span><span class='line'>firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent 
</span><span class='line'>firewall-cmd --reload</span></code></pre></td></tr></table></div></figure>


<h2>一些有趣的命令</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>查看用了哪些镜像
</span><span class='line'>
</span><span class='line'>[root@cu2 /]# kubectl get pods --all-namespaces -o jsonpath="{..image}" |\
</span><span class='line'> tr -s '[[:space:]]' '\n' |\
</span><span class='line'> sort |\
</span><span class='line'> uniq -c
</span><span class='line'>      2 gcr.io/google_containers/dnsmasq-metrics-amd64:1.0
</span><span class='line'>      2 gcr.io/google_containers/exechealthz-amd64:1.2
</span><span class='line'>     12 gcr.io/google_containers/hyperkube-amd64:v1.5.5
</span><span class='line'>      2 gcr.io/google_containers/kube-addon-manager-amd64:v6.1
</span><span class='line'>      2 gcr.io/google_containers/kubedns-amd64:1.9
</span><span class='line'>      2 gcr.io/google_containers/kube-dnsmasq-amd64:1.4
</span><span class='line'>      2 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.0
</span><span class='line'>    
</span><span class='line'>      
</span><span class='line'>修改默认kubectl的配置
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# vi $KUBECONFIG 
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Config
</span><span class='line'>preferences: {}
</span><span class='line'>current-context: default
</span><span class='line'>clusters:
</span><span class='line'>- cluster:
</span><span class='line'>    server: http://localhost:8080
</span><span class='line'>  name: default
</span><span class='line'>contexts:
</span><span class='line'>- context:
</span><span class='line'>    cluster: default
</span><span class='line'>    user: ""
</span><span class='line'>    namespace: kube-system
</span><span class='line'>  name: default
</span><span class='line'>users: {}
</span><span class='line'>
</span><span class='line'>如果kubectl没有下载，可以从镜像启动的容器里面获取
</span><span class='line'>
</span><span class='line'>[root@cu2 docker-multinode]# docker exec -ti 0c0360bcc2c3 bash
</span><span class='line'>root@cu2:/# cp kubectl /var/run/
</span><span class='line'>
</span><span class='line'>[root@cu2 run]# mv kubectl /data/kubernetes/kube-deploy/docker-multinode/
</span><span class='line'>
</span><span class='line'>获取容器IP
</span><span class='line'>
</span><span class='line'>https://kubernetes.io/docs/user-guide/jsonpath/
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o wide -l run=redis -o jsonpath={..podIP}
</span><span class='line'>10.1.75.2 10.1.75.3 10.1.58.3 10.1.58.2 10.1.33.3
</span><span class='line'>
</span><span class='line'>网络共用: --net
</span><span class='line'>
</span><span class='line'>docker run -ti --entrypoint=sh --net=container:8e9f21956469f4ef7e5b9d91798788ab83f380795d2825cdacae0ed28f5ba03b gcr.io/google_containers/skydns-amd64:1.0
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>格式化输出
</span><span class='line'>
</span><span class='line'>kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}"  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# export POD_COL="custom-columns=NAME:.metadata.name,RESTARTS:.status.containerStatuses[*].restartCount,CONTAINERS:.spec.containers[*].name,IP:.status.podIP,HOST:.spec.nodeName"
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o $POD_COL 
</span><span class='line'>
</span><span class='line'>kubectl get po -l k8s-app=kube-dns -o=custom-columns=NAME:.metadata.name,CONTAINERS:.spec.containers[*].name
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# kubectl get po --all-namespaces -o=custom-columns=NAME:.metadata.name,CONTAINERS:.spec.containers[*].name
</span><span class='line'>
</span><span class='line'>kubectl get po --all-namespaces {range .items[*]}{.metadata.name}{“\t”}{end}
</span><span class='line'>
</span><span class='line'>备份
</span><span class='line'>
</span><span class='line'>echo "$(docker ps  | grep -v IMAGE | awk '{print $2}' )
</span><span class='line'>$(docker-bs ps | grep -v IMAGE | awk '{print $2}' )" | sort -u | while read image ; do docker save $image&gt;$(echo $image | tr '[/:]' _).tar ; done
</span><span class='line'>
</span><span class='line'>加Label
</span><span class='line'>
</span><span class='line'>cat /etc/hosts | grep -E "\scu[0-9]\s" | awk '{print "kubectl label nodes "$1" hostname="$2}' | while read line ; do sh -c "$line" ; done
</span><span class='line'>
</span><span class='line'>扩容
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# kubectl run redis --image=redis:3.2.8 
</span><span class='line'>[root@cu2 kubernetes]# kubectl scale --replicas=9 deployment/redis
</span><span class='line'>
</span><span class='line'> echo " $( kubectl describe pods hadoop-master2 | grep -E "Node|Container ID" | awk -F/ '{print $NF}' | tr '\n' ' ' | awk '{print "ssh "$1" \rdocker exec -ti "$2" bash"}' ) "
</span><span class='line'> </span></code></pre></td></tr></table></div></figure>


<p>测试DNS是否成功：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# vi busybox.yaml
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  namespace: default
</span><span class='line'>spec:
</span><span class='line'>  containers:
</span><span class='line'>  - image: busybox
</span><span class='line'>    command:
</span><span class='line'>      - sleep
</span><span class='line'>      - "3600"
</span><span class='line'>    imagePullPolicy: IfNotPresent
</span><span class='line'>    name: busybox
</span><span class='line'>  restartPolicy: Always
</span><span class='line'>
</span><span class='line'>[root@cu3 kube-deploy]# kubectl create -f busybox.yaml 
</span><span class='line'>pod "busybox" created
</span><span class='line'>[root@cu3 kube-deploy]# kubectl get pods 
</span><span class='line'>NAME      READY     STATUS              RESTARTS   AGE
</span><span class='line'>busybox   0/1       ContainerCreating   0          11s
</span><span class='line'>[root@cu3 kube-deploy]# kubectl get pods 
</span><span class='line'>NAME      READY     STATUS    RESTARTS   AGE
</span><span class='line'>busybox   1/1       Running   0          1m
</span><span class='line'>[root@cu3 kube-deploy]# kubectl exec -ti busybox -- nslookup kubernetes.default
</span><span class='line'>Server:    10.0.0.10
</span><span class='line'>Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local
</span><span class='line'>
</span><span class='line'>Name:      kubernetes.default
</span><span class='line'>Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local
</span><span class='line'>
</span><span class='line'>用容器的MYSQL的做客户端
</span><span class='line'>
</span><span class='line'>kubectl run -it --rm --image=mysql:5.6 mysql-client -- mysql -h mysql -ppassword
</span></code></pre></td></tr></table></div></figure>


<p>小结一点：日志的重要性！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubenetes]# docker ps -a | grep kubelet
</span><span class='line'>[root@cu2 kubenetes]# docker logs --tail=200 7432da457558
</span><span class='line'>
</span><span class='line'>E0417 11:39:40.194844   22528 configmap.go:174] Couldn't get configMap hadoop/dta-hadoop-config: configmaps "dta-hadoop-config" not found
</span><span class='line'>E0417 11:39:40.194910   22528 configmap.go:174] Couldn't get configMap hadoop/dta-bin-config: configmaps "dta-bin-config" not found
</span></code></pre></td></tr></table></div></figure>


<p>监控heapster的一些错误，还没调好</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# kubectl exec -ti heapster-564189836-shn2q -n kube-system -- sh
</span><span class='line'>/ # 
</span><span class='line'>/ # 
</span><span class='line'>没pod的数据
</span><span class='line'>/ # /heapster --source=https://kubernetes.default --sink=log --heapster-port=8083 -v 10
</span><span class='line'>
</span><span class='line'>E0329 10:11:53.823641       1 reflector.go:203] k8s.io/heapster/metrics/processors/node_autoscaling_enricher.go:100: Failed to list *api.Node: Get https://kubernetes.default/api/v1/nodes?resourceVersion=0: dial tcp 10.0.0.1:443: i/o timeout
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>$heapster/metrics
</span><span class='line'>$heapster/api/v1/model/debug/allkeys
</span></code></pre></td></tr></table></div></figure>


<p>其他一些配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>other_args=" --registry-mirror=https://docker.mirrors.ustc.edu.cn "
</span><span class='line'>
</span><span class='line'>--insecure-registry gcr.io 
</span><span class='line'>
</span><span class='line'>iptables -S -t nat
</span></code></pre></td></tr></table></div></figure>


<h2>其他一些资源</h2>

<ul>
<li><a href="https://kubernetes.io/docs/concepts/cluster-administration/resource-usage-monitoring/">https://kubernetes.io/docs/concepts/cluster-administration/resource-usage-monitoring/</a></li>
<li><p><a href="https://github.com/kubernetes/heapster/tree/v1.3.0/deploy/kube-config/influxdb">https://github.com/kubernetes/heapster/tree/v1.3.0/deploy/kube-config/influxdb</a></p></li>
<li><p><a href="https://github.com/kubernetes/heapster/blob/master/docs/debugging.md">https://github.com/kubernetes/heapster/blob/master/docs/debugging.md</a></p></li>
<li><p><a href="https://docs.docker.com/v1.12/engine/installation/linux/centos/">https://docs.docker.com/v1.12/engine/installation/linux/centos/</a></p></li>
<li><p><a href="https://github.com/CodisLabs/codis/blob/release3.2/Dockerfile">https://github.com/CodisLabs/codis/blob/release3.2/Dockerfile</a></p></li>
<li><a href="https://github.com/sporkmonger/redis-k8s/blob/master/redis.yaml">https://github.com/sporkmonger/redis-k8s/blob/master/redis.yaml</a></li>
<li><a href="https://github.com/sobotklp/kubernetes-redis-cluster/blob/master/redis-cluster.yml">https://github.com/sobotklp/kubernetes-redis-cluster/blob/master/redis-cluster.yml</a></li>
</ul>


<p>statefulset</p>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/run-stateful-application/">https://kubernetes.io/docs/tutorials/stateful-application/run-stateful-application/</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/run-replicated-stateful-application/">https://kubernetes.io/docs/tutorials/stateful-application/run-replicated-stateful-application/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
