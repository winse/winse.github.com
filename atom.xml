<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2017-08-10T04:07:31+00:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[保护/加密JAVA代码]]></title>
    <link href="http://winseliu.com/blog/2017/08/09/java-bytecode-security/"/>
    <updated>2017-08-09T18:10:39+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/09/java-bytecode-security</id>
    <content type="html"><![CDATA[<p>由于Java代码生成的是中间过程字节码，javap以及一些反编译的工具基本能看代码的大概，对于提供给客户的代码需要做一些处理：混淆或者加密。下面分几块把在实际操作过程中参考的内容罗列出来，希望对看到本文并感兴趣的你有所帮助。</p>

<h2>自定义ClassLoader</h2>

<p>混淆+ClassLoader</p>

<ul>
<li><a href="http://www.voidcn.com/blog/zmx729618/article/p-4375840.html">java源代码加密+使用proguard混淆java web项目代码+自定义Classloader</a> 思路不错</li>
</ul>


<p>自定义ClassLoader并用Java实现解密</p>

<ul>
<li><a href="http://www.aspphp.online/bianchen/java/gyjava/201701/112687.html">利用DES加密的算法保護Java源代碼</a> 为啥要加密，以及一般的保护措施（混淆、加密盘、自定义classloader）。实现有点low，用Java写的加密人家调试下就全部请求怎么弄的了。</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-secureclass/index.html">运用加密技术保护Java源代码</a> Java实现加解密通过自定义classloader。2001年的文章啊，牛逼</li>
<li><a href="http://blog.csdn.net/dianacody/article/details/38585209">Java代码加密与反编译（二）：用加密算法DES修改classLoader实现对.class文件加密</a> 有点实践了上一篇ibm文章的意思。</li>
</ul>


<p>自定义ClassLoader（jvmti）用C++实现解密</p>

<ul>
<li><a href="https://wenku.baidu.com/view/587af93767ec102de2bd892c.html">ClassLoader加密技术改进研究pdf</a> 理论派。classloader的实现用C++写（loadClass用JNI实现），但是还是需要对原有代码进行一定的修改</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-protectjava/index.html">如何有效的保护 JAVA 程序</a> 这种ClassLoader加密实现有点复杂了，还改java.c的loadClass？2002年的文章啊：解决了 ClassLoader 本身的安全性，其不失为一个比较好安全方案。</li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/]%20%E9%9D%9E%E5%B8%B8%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E4%B8%80%E7%AF%87%E3%80%82%E8%AE%B2%E4%BA%86%E8%87%AA%E5%AE%9A%E4%B9%89classloader%E5%92%8Cjvmti%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%8F%90%E4%BE%9B%E4%BA%86%E6%BA%90%E7%A0%81%E5%B7%A5%E7%A8%8B[JarEncrypt](https://github.com/AloneMonkey/JarEncrypt">jar包加密保护解决方案</a>，参考。</li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a> 用jvmti来实现加解密，牛逼的一篇文章啊！一步步按他的操作可以实现，还附有源码，参考。</li>
</ul>


<p>其他一些</p>

<ul>
<li><a href="http://cjnetwork.iteye.com/blog/851544#bc1819690">java源程序加密解决方案(基于Classloader解密)</a> 本身是一篇很棒的文章，多重加密保障ClassLoader安全。又有大神的回复：java的class加密都可以通过dumpclass来还原出来，囧</li>
<li><a href="http://rednaxelafx.iteye.com/blog/727938">如何dump出一个Java进程里的类对应的Class文件？</a> 大神的sun.jvm.hotspot.tools.jcore.ClassDump文章，只要知道类名就无敌了啊</li>
</ul>


<h2>JNI</h2>

<p>javah</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">Calling native functions from Java with JNI and Maven</a> maven搭建native的环境，整体的结构很值得学习</li>
<li><a href="http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html">http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html</a> maven native插件</li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a> 从生成.h到最后打包一条龙，值得学习。</li>
</ul>


<p>环境部署及入门</p>

<ul>
<li><a href="http://blog.csdn.net/ididcan/article/details/6828982">JNI简单实现Java调用C++/C的HelloWorld</a> 搭开发环境的时刻，可以按照步骤一步步来</li>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a> 直接VS建空项目，不错。思路清晰。中文入门不二之选！</li>
<li><a href="http://www.javamex.com/tutorials/jni/getting_started.shtml">Getting started with JNI</a> 需要小翻个墙啊，有介绍Additional Include Directories的方式配置java的头文件。</li>
<li><a href="https://www.ibm.com/developerworks/java/tutorials/j-jni/j-jni.html">Java programming with JNI</a> 了解JNI没有比这篇更好的文章了，即介绍了java调c++，又介绍了c++调用java。</li>
<li><a href="http://tinggo.iteye.com/blog/1185551">VS项目配置详解</a> VS预定义头：DEBUG，RELEASE的一些头可以定义在配置里面。有点像makefile里面决定打什么版本。</li>
</ul>


<p>配jni.h的 附加目录 的时刻，需要选择 配置 和 平台 的配置！！需要对应好！ jni的.h文件需要放到c++的项目下面去，引用外部的好像找不到，有问题。</p>

<p>java与c++类型之间的转换</p>

<ul>
<li><a href="https://stackoverflow.com/questions/8439233/how-to-convert-jbytearray-to-native-char-in-jni">How to convert jbyteArray to native char* in jni?</a></li>
<li><a href="https://stackoverflow.com/questions/12854333/jni-in-c-to-read-file-to-jbytearray">JNI in C++ to read file to jbyteArray</a></li>
</ul>


<p>JNI调用C++的加密算法</p>

<ul>
<li><a href="http://blog.csdn.net/wtbee/article/details/11658017">Java实现DES对称加密算法（附Android下3DES的JNI源码）</a> 有简单介绍DES的只是。中间换成过他的DES的实现，但是感觉怪怪的，有点不太靠谱。后面换成OPENSSL了。</li>
<li><a href="http://www.cnblogs.com/kolin/p/4256614.html">JNI调用c++实现AES加密解密</a> android的，用的应该也是OPENSSL。可以参考过程</li>
</ul>


<h2>OPENSSL</h2>

<ul>
<li><a href="http://www.qmailer.net/archives/183.html">OpenSSL编程-对称加密及DES/3DES简介</a> 简单的介绍</li>
<li><a href="http://blog.csdn.net/duanxingheng/article/details/11655037">OPENSSL库的使用-DES篇</a> 看看算法还可以。算法介绍，有对OPENSSL DES库的介绍和使用</li>
<li><a href="https://www.madboa.com/geek/openssl/">OpenSSL Command-Line</a></li>
<li><a href="http://www.cnblogs.com/gordon0918/p/5317701.html">openssl 对称加密算法enc命令详解</a> 命令行的使用</li>
<li><a href="https://www.slideshare.net/guanzhi/crypto-with-openssl">https://www.slideshare.net/guanzhi/crypto-with-openssl</a></li>
<li><a href="http://www.linuxjournal.com/article/4822">An Introduction to OpenSSL Programming</a> 2001年的太老了，留个纪念。</li>
</ul>


<p>WINDOWS安装/编译安装OPENSSL然后在VS里面应用：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio">https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio</a></li>
<li><a href="https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012">https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012</a></li>
<li><a href="https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64">https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64</a></li>
<li><a href="http://slproweb.com/products/Win32OpenSSL.html">http://slproweb.com/products/Win32OpenSSL.html</a></li>
</ul>


<p>NuGet安装OpenSSL on VS2015-1.0.2版本：（我用的这种方式）</p>

<ul>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a> VS2015 安装openssl v1.0.2 才有v140的include。 v1.0.2.1安装不了，参考。</li>
</ul>


<p>GCC</p>

<ul>
<li><a href="https://stackoverflow.com/questions/1894013/how-to-use-openssl-in-gcc">How to use OpenSSL in GCC?</a> 加依赖: -L/usr/lib -lssl -lcrypto -o server</li>
</ul>


<p>DES</p>

<ul>
<li><a href="https://my.oschina.net/mawx/blog/85424">https://my.oschina.net/mawx/blog/85424</a> Java DESede用C++ Openssl实现 参考下他的链接</li>
<li><a href="http://www.open-open.com/solution/view/1320502797546">http://www.open-open.com/solution/view/1320502797546</a> Java与C++通过DES、blowfish互相加解密</li>
<li><a href="http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs">http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs</a> OpenSSL DES APIs</li>
</ul>


<p>AES</p>

<ul>
<li><a href="https://www.lovelucy.info/openssl-aes-encryption.html">AES加密和解密——使用openssl编程</a> 参考他的makefile。AES用的是OPENSSL，写的中规中矩</li>
<li><a href="http://www.cnblogs.com/luop/p/4334160.html">密码算法详解——AES</a></li>
<li><a href="http://www.ssdfans.com/?p=238">AES加密算法图解</a> flash动画很赞</li>
<li><a href="http://yuanshuilee.blog.163.com/blog/static/21769727520140942826137/">openssl之aes加密（AES_cbc_encrypt 与 AES_encrypt 的编程案例）</a> 很棒的一篇，参考。</li>
<li><a href="https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/">https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/</a> 高级加密标准AES的工作模式（ECB、CBC、CFB、OFB），还有接口的介绍，非常好的一篇文章</li>
</ul>


<p>== TODO ==
AES CBC 相互加解密 Java/PHP/C++ java和c++加解密有用？能否互通？java c++的aes加密</p>

<ul>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a> 非常牛逼的一篇，参考。</li>
<li><a href="http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html">http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html</a> Java和C/C++进行DES/AES密文传输</li>
<li><a href="https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl">https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl</a></li>
<li><a href="https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent">https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent</a></li>
<li><a href="http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html">http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html</a> DES 算法的 C++ 与 JAVA 互相加解密</li>
<li><a href="http://juliusdavies.ca/commons-ssl/pbe.html">OpenSSL&rsquo;s &ldquo;enc&rdquo; in Java (PBE / Password Based Encryption)</a></li>
<li><a href="http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html">http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html</a></li>
<li><p><a href="https://ruby-china.org/topics/26490">https://ruby-china.org/topics/26490</a></p></li>
<li><p><a href="https://shanetully.com/2012/06/openssl-rsa-aes-and-c/">OpenSSL, RSA, AES and C++</a> 好鬼长复杂没怎么看，搜AES找到了。</p></li>
</ul>


<h4>OPENSSL MD5： VS + GCC + JAVA + 命令行</h4>

<ul>
<li><a href="http://www.askyb.com/cpp/openssl-md5-hashing-example-in-cpp/">OpenSSL MD5 Hashing Example in C++</a></li>
<li><a href="https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash">https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash</a> LINUX命令行</li>
<li><a href="https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal">https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal</a> md5sum</li>
<li><a href="https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files">https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files</a> 循环算一个目录下文件的MD5</li>
<li><a href="https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC">https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC</a> OPENSSL各种算法的使用</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># SHA256, used in chef cookbooks
</span><span class='line'>openssl dgst -sha256 path/to/myfile
</span><span class='line'># MD5
</span><span class='line'>openssl dgst -md5 path/to/myfile
</span><span class='line'>echo -n 'text to be encrypted' | md5sum -
</span><span class='line'>$ echo -n 123456 | md5sum | awk '{print $1}'
</span><span class='line'>$ echo -n Welcome | md5sum
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# gcc -Wall -lcrypto -lssl opensslmd5.cpp -o md5
</span><span class='line'>[root@cu2 ~]# ./md5
</span><span class='line'>md5 digest: 56ab24c15b72a457069c5ea42fcfc640
</span></code></pre></td></tr></table></div></figure>


<p>makefile</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CC=g++
</span><span class='line'>CFLAGS=-Wall -g -O2
</span><span class='line'>LIBS=-lcrypto
</span><span class='line'>
</span><span class='line'>all: aes
</span><span class='line'>
</span><span class='line'>aes: aes.cc
</span><span class='line'>    $(CC) $(CFLAGS) aes.cc -o $@ $(LIBS)
</span><span class='line'>
</span><span class='line'>clean:
</span><span class='line'>    @rm -f aes
</span></code></pre></td></tr></table></div></figure>


<h4>OPENSSL命令行</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>openssl des3 -nosalt -k abc123 -in file.txt -out file.des3 #不加盐，key为abc123来加密
</span><span class='line'>openssl des3 -d -nosalt -in file.des3 -out f.txt -k abc123#解密
</span><span class='line'>
</span><span class='line'>默认是-salt，加盐的，如果不加盐，则根据pass生成的key和iv不变，例：
</span><span class='line'>
</span><span class='line'>You can get openssl to base64-encode the message by using the -a
</span><span class='line'>stefano:~$ openssl aes-256-cbc -in attack-plan.txt -a
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -a -salt -k abcdefghijklmnop
</span><span class='line'>[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -k abcdefghijklmnop |  openssl aes-128-cbc -d -k abcdefghijklmnop
</span></code></pre></td></tr></table></div></figure>


<h2>其他</h2>

<p>SHELL二进制编码：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script">https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script</a> hexdump</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>el@defiant ~ $ printf '%x\n' 26
</span><span class='line'>el@defiant ~ $ echo $((0xAA))
</span><span class='line'>printf -v result1 "%x" "$decimal1"
</span><span class='line'>% xxd -l 16 -p /dev/random
</span><span class='line'>193f6c54814f0576bc27d51ab39081dc
</span><span class='line'>$ echo -n $'\x12\x34' | xxd -p
</span><span class='line'>
</span><span class='line'>$ echo -n $'\x12\x34' | hexdump -e '"%x"'
</span><span class='line'>
</span><span class='line'>od -vt x1|awk '{$1="";print}'
</span><span class='line'>echo "obase=16; 34" | bc
</span></code></pre></td></tr></table></div></figure>


<p>c++命令行不直接关闭。。。最后用断点的方式替代了，没找到好的方法！！</p>

<p>文件读写</p>

<ul>
<li><a href="http://blog.csdn.net/lightlater/article/details/6364931">C++读写二进制文件</a></li>
<li><a href="http://blog.csdn.net/guyue6670/article/details/6681037">fopen中w w+ wb区别</a> 人家代码写的是w+，加密class后多了0D。后面问了搞C的同事才知道二进制要用wb，C就是一堆坑啊！</li>
</ul>


<p>g++</p>

<ul>
<li><a href="https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope">https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope</a> snprintf</li>
</ul>


<p>git</p>

<ul>
<li><a href="https://git-scm.com/docs/git-archive">https://git-scm.com/docs/git-archive</a> GIT打包</li>
</ul>


<h2>重要的参考文章再列一遍</h2>

<ul>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a></li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/">jar包加密保护解决方案</a> 源码<a href="https://github.com/AloneMonkey/JarEncrypt">JarEncrypt</a></li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a></li>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a></li>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nfs on Centos7]]></title>
    <link href="http://winseliu.com/blog/2017/08/05/nfs-on-centos7/"/>
    <updated>2017-08-05T08:38:56+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/05/nfs-on-centos7</id>
    <content type="html"><![CDATA[<h2>参考</h2>

<ul>
<li><a href="https://www.howtoforge.com/nfs-server-and-client-on-centos-7">https://www.howtoforge.com/nfs-server-and-client-on-centos-7</a></li>
<li><a href="http://blog.huatai.me/2014/10/14/CentOS-7-NFS-Server-and-Client-Setup/">http://blog.huatai.me/2014/10/14/CentOS-7-NFS-Server-and-Client-Setup/</a></li>
</ul>


<h2>指令</h2>

<p>安装</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 data]# yum install nfs-utils -y 
</span><span class='line'>[root@cu3 data]# chmod -R 777 /data/k8s-dta
</span><span class='line'>
</span><span class='line'>systemctl enable rpcbind
</span><span class='line'>systemctl enable nfs-server
</span><span class='line'>systemctl enable nfs-lock
</span><span class='line'>systemctl enable nfs-idmap
</span><span class='line'>
</span><span class='line'>systemctl start rpcbind
</span><span class='line'>systemctl start nfs-server
</span><span class='line'>systemctl start nfs-lock
</span><span class='line'>systemctl start nfs-idmap</span></code></pre></td></tr></table></div></figure>


<p>配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 data]# vi /etc/exports
</span><span class='line'>/data/k8s-dta 192.168.0.0/24(rw,sync,no_root_squash,no_all_squash)
</span></code></pre></td></tr></table></div></figure>


<p>说明：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/data/k8s-dta – 共享目录
</span><span class='line'>192.168.0.0/24 – 允许访问NFS的客户端IP地址段
</span><span class='line'>rw – 允许对共享目录进行读写
</span><span class='line'>sync – 实时同步共享目录
</span><span class='line'>no_root_squash – 允许root访问
</span><span class='line'>no_all_squash - 允许用户授权
</span><span class='line'>no_subtree_check - 如果卷的一部分被输出，从客户端发出请求文件的一个常规的调用子目录检查验证卷的相应部分。如果是整个卷输出，禁止这个检查可以加速传输。
</span><span class='line'>no_subtree_check - If only part of a volume is exported, a routine called subtree checking verifies that a file that is requested from the client is in the appropriate part of the volume. If the entire volume is exported, disabling this check will speed up transfers. Setting Up an NFS Server
</span></code></pre></td></tr></table></div></figure>


<p>然后重启服务，并开放防火墙（或者关闭）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>systemctl restart nfs-server
</span><span class='line'>
</span><span class='line'>firewall-cmd --permanent --zone=public --add-service=ssh
</span><span class='line'>firewall-cmd --permanent --zone=public --add-service=nfs
</span><span class='line'>firewall-cmd --reload</span></code></pre></td></tr></table></div></figure>


<h2>客户端配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 opt]# yum install -y nfs-utils
</span><span class='line'>
</span><span class='line'>[root@cu2 opt]# mount cu3:/data/k8s-dta dta
</span><span class='line'>[root@cu2 opt]# touch dta/abc
</span><span class='line'>[root@cu2 opt]# ll dta
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Aug  3  2017 abc
</span><span class='line'>
</span><span class='line'>[root@cu3 data]# ll k8s-dta/
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Aug  3 15:19 abc</span></code></pre></td></tr></table></div></figure>


<h2>后记</h2>

<p>建好NFS服务后，可以把它作为k8s容器的存储，这样就不怕丢数据了。</p>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#writing-to-stable-storage">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#writing-to-stable-storage</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs">https://kubernetes.io/docs/concepts/storage/volumes/#nfs</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/master/examples/volumes/nfs">https://github.com/kubernetes/kubernetes/tree/master/examples/volumes/nfs</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encfs加密文件系统]]></title>
    <link href="http://winseliu.com/blog/2017/08/05/encfs-secure-filesystem/"/>
    <updated>2017-08-05T02:55:57+00:00</updated>
    <id>http://winseliu.com/blog/2017/08/05/encfs-secure-filesystem</id>
    <content type="html"><![CDATA[<p>为了数据安全，最近领导给了个链接让去了解了解 <a href="https://www.ibm.com/developerworks/cn/linux/l-cn-ecryptfs/">eCryptfs</a> 。通过yum和自己手动编译安装后都运行失败，系统的<a href="http://centosfaq.org/centos/about-ecryptfs-utils/#comment-110110">Centos7内核不支持ecryptfs模块</a> 。</p>

<p>通过一个介绍ecryptfs的<a href="https://linux.cn/article-4470-1.html">关联的链接</a> 了解到 <a href="http://www.arg0.net/encfs">encfs</a> 也是做 ecryptfs 类似的事情。然后就去下载安装，最后发现windows下面也可以用（惊喜）。</p>

<p>epel下面已经发布了 encfs 的rpm包。现在只要是仓库有的包就不自己编译（进行过N次升级的洗礼，最终发现yum、rpm才是最终归宿啊）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install fuse 
</span><span class='line'>[root@k8s ~]# yum install encfs
</span><span class='line'>
</span><span class='line'>挂载、创建
</span><span class='line'>[root@k8s shm]# encfs /dev/shm/.test /dev/shm/test
</span><span class='line'>The directory "/dev/shm/.test/" does not exist. Should it be created? (y,n) y
</span><span class='line'>The directory "/dev/shm/test/" does not exist. Should it be created? (y,n) y
</span><span class='line'>Creating new encrypted volume.
</span><span class='line'>Please choose from one of the following options:
</span><span class='line'> enter "x" for expert configuration mode,
</span><span class='line'> enter "p" for pre-configured paranoia mode,
</span><span class='line'> anything else, or an empty line will select standard mode.
</span><span class='line'>?&gt;
</span><span class='line'>
</span><span class='line'>Standard configuration selected.
</span><span class='line'>
</span><span class='line'>Configuration finished.  The filesystem to be created has
</span><span class='line'>the following properties:
</span><span class='line'>Filesystem cipher: "ssl/aes", version 3:0:2
</span><span class='line'>Filename encoding: "nameio/block", version 4:0:2
</span><span class='line'>Key Size: 192 bits
</span><span class='line'>Block Size: 1024 bytes
</span><span class='line'>Each file contains 8 byte header with unique IV data.
</span><span class='line'>Filenames encoded using IV chaining mode.
</span><span class='line'>File holes passed through to ciphertext.
</span><span class='line'>
</span><span class='line'>Now you will need to enter a password for your filesystem.
</span><span class='line'>You will need to remember this password, as there is absolutely
</span><span class='line'>no recovery mechanism.  However, the password can be changed
</span><span class='line'>later using encfsctl.
</span><span class='line'>
</span><span class='line'>New Encfs Password: 123456
</span><span class='line'>Verify Encfs Password:
</span><span class='line'>
</span><span class='line'>[root@k8s shm]# echo $(hostname) &gt; test/hostname.txt
</span><span class='line'>[root@k8s shm]# ll -R -a
</span><span class='line'>.:
</span><span class='line'>total 0
</span><span class='line'>drwxrwxrwt.  4 root root   80 Aug  4 22:04 .
</span><span class='line'>drwxr-xr-x. 20 root root 3260 Aug  4 21:16 ..
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 test
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 .test
</span><span class='line'>
</span><span class='line'>./test:
</span><span class='line'>total 4
</span><span class='line'>drwx------. 2 root root 80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root 80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root  4 Aug  4 22:06 hostname.txt
</span><span class='line'>
</span><span class='line'>./.test:
</span><span class='line'>total 8
</span><span class='line'>drwx------. 2 root root   80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root   80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root 1263 Aug  4 22:04 .encfs6.xml
</span><span class='line'>-rw-r--r--. 1 root root   12 Aug  4 22:06 pAqhW671kQSK4kPLJM-TF6sp
</span><span class='line'>
</span><span class='line'>卸载
</span><span class='line'>[root@k8s shm]# fusermount -u test
</span><span class='line'>[root@k8s shm]# ll -R -a
</span><span class='line'>.:
</span><span class='line'>total 0
</span><span class='line'>drwxrwxrwt.  4 root root   80 Aug  4 22:04 .
</span><span class='line'>drwxr-xr-x. 20 root root 3260 Aug  4 21:16 ..
</span><span class='line'>drwx------.  2 root root   40 Aug  4 22:04 test
</span><span class='line'>drwx------.  2 root root   80 Aug  4 22:06 .test
</span><span class='line'>
</span><span class='line'>./test:
</span><span class='line'>total 0
</span><span class='line'>drwx------. 2 root root 40 Aug  4 22:04 .
</span><span class='line'>drwxrwxrwt. 4 root root 80 Aug  4 22:04 ..
</span><span class='line'>
</span><span class='line'>./.test:
</span><span class='line'>total 8
</span><span class='line'>drwx------. 2 root root   80 Aug  4 22:06 .
</span><span class='line'>drwxrwxrwt. 4 root root   80 Aug  4 22:04 ..
</span><span class='line'>-rw-r--r--. 1 root root 1263 Aug  4 22:04 .encfs6.xml
</span><span class='line'>-rw-r--r--. 1 root root   12 Aug  4 22:06 pAqhW671kQSK4kPLJM-TF6sp
</span></code></pre></td></tr></table></div></figure>


<p>注意: 最好将 .encfs6.xml 备份起來, 这个文件损坏或丢失将无法还原加密的文件。</p>

<p>把加密的文件备份到云盘，然后本地挂载就能看到原始内容了。安全的云盘就这么简单的实现了，咔咔。。。</p>

<p>在windows安装 <a href="https://encfsmp.sourceforge.io/download.html">EncFSMP</a> 就可以和在Linux上面一样操作encfs文件系统了。</p>

<blockquote><p>EncFS从原理不同TrueCrypt的容器 ，它存储在一个单一的大文件的加密文件。 相反，EncFS为您添加的每个文件创建单独的文件。 它更好地与云存储服务，每次更改时重新上传整个TrueCrypt容器。</p></blockquote>

<h2>参考链接</h2>

<ul>
<li><a href="http://www.arg0.net/encfs">http://www.arg0.net/encfs</a></li>
<li><a href="https://linux.cn/article-4470-1.html">https://linux.cn/article-4470-1.html</a> 通过这篇文章查看到了encfs</li>
<li><a href="https://github.com/vgough/encfs/blob/master/INSTALL.md">https://github.com/vgough/encfs/blob/master/INSTALL.md</a> 编译安装</li>
<li><a href="http://www.vonwei.com/post/introduceToEncFS.html">http://www.vonwei.com/post/introduceToEncFS.html</a> 中文简单介绍和入门。手动编译，命令的参数也有介绍，还有介绍加密目录的 .encfs6.xml</li>
<li><a href="https://github.com/vgough/encfs/blob/master/encfs/encfs.pod#examples">https://github.com/vgough/encfs/blob/master/encfs/encfs.pod#examples</a></li>
<li><a href="https://github.com/vgough/encfs/blob/master/encfs/encfsctl.pod">https://github.com/vgough/encfs/blob/master/encfs/encfsctl.pod</a></li>
<li><p><a href="https://www.howtoip.com/how-to-encrypt-cloud-storage-on-linux-and-windows-with-encfs/">https://www.howtoip.com/how-to-encrypt-cloud-storage-on-linux-and-windows-with-encfs/</a>  非常棒的教程，linux和windows都介绍了</p></li>
<li><p><a href="http://www.jianshu.com/p/073957902fa9">http://www.jianshu.com/p/073957902fa9</a> 手动编译，以后可能用得到。最后的启动自动加载磁盘可以借鉴。</p></li>
<li><a href="https://github.com/vgough/encfs/issues/66">https://github.com/vgough/encfs/issues/66</a>  encfs on cygwin</li>
<li><a href="https://superuser.com/questions/179150/reading-an-encfs-volume-from-windows">https://superuser.com/questions/179150/reading-an-encfs-volume-from-windows</a></li>
<li><a href="https://encfsmp.sourceforge.io/download.html">https://encfsmp.sourceforge.io/download.html</a> for windows</li>
<li><a href="https://github.com/dokan-dev/dokany">https://github.com/dokan-dev/dokany</a> fuse on windows</li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kubeadm部署kubernetes]]></title>
    <link href="http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/"/>
    <updated>2017-07-30T12:18:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7</id>
    <content type="html"><![CDATA[<p>官网文档差，删文档倒是不手软。使用脚本启动、安装的文档（docker-multinode）已经删掉了，现在都推荐使用kubeadm来进行安装。</p>

<p>本文使用代理在master上安装并缓冲rpm、以及下载docker镜像，然后做本地YUM仓库和拷贝镜像到其他worker节点的方式来部署集群。下一篇再介绍在拥有kubelet/kubeadm rpm、以及k8s docker镜像的情况下怎么去部署一个新的k8s集群。</p>

<p>这里使用两台虚拟机做测试：</p>

<ul>
<li>k8s kube-master : 192.168.191.138</li>
<li>woker1 : 192.168.191.139</li>
</ul>


<h2>修改主机名，改时间、时区，防火墙</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hostnamectl --static set-hostname k8s 
</span><span class='line'>hostname k8s 
</span><span class='line'>
</span><span class='line'>rm -rf /etc/localtime 
</span><span class='line'>ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 
</span><span class='line'>
</span><span class='line'>systemctl disable firewalld ; service firewalld stop
</span></code></pre></td></tr></table></div></figure>


<h2>安装docker</h2>

<ul>
<li><a href="https://docs.docker.com/v1.12/engine/installation/linux/rhel/">https://docs.docker.com/v1.12/engine/installation/linux/rhel/</a></li>
<li><a href="https://yum.dockerproject.org/repo/main/centos/7/Packages/">https://yum.dockerproject.org/repo/main/centos/7/Packages/</a> 打开看下1.12的具体版本</li>
<li><a href="https://docs.docker.com/v1.12/engine/admin/systemd/">https://docs.docker.com/v1.12/engine/admin/systemd/</a>  *</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'
</span><span class='line'>[dockerrepo]
</span><span class='line'>name=Docker Repository
</span><span class='line'>baseurl=https://yum.dockerproject.org/repo/main/centos/7/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=https://yum.dockerproject.org/gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>yum list docker-engine --showduplicates
</span><span class='line'>
</span><span class='line'>yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6 -y
</span><span class='line'>systemctl enable docker ; systemctl start docker
</span></code></pre></td></tr></table></div></figure>


<h2>翻墙安装配置</h2>

<p>具体操作参考 <a href="http://winseliu.com/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks">使用Privoxy把shadowsocks转换为Http代理</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install -y epel-release ; yum install -y python-pip 
</span><span class='line'>[root@k8s ~]# pip install shadowsocks
</span><span class='line'>[root@k8s ~]# vi /etc/shadowsocks.json 
</span><span class='line'>[root@k8s ~]# sslocal -c /etc/shadowsocks.json 
</span><span class='line'>[root@k8s ~]# curl --socks5-hostname 127.0.0.1:1080 www.google.com
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# yum install privoxy -y
</span><span class='line'>[root@k8s ~]# vi /etc/privoxy/config 
</span><span class='line'>...
</span><span class='line'>forward-socks5 / 127.0.0.1:1080 .
</span><span class='line'>listen-address 192.168.191.138:8118
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl enable privoxy
</span><span class='line'>[root@k8s ~]# systemctl start privoxy
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# curl -x 192.168.191.138:8118 www.google.com
</span><span class='line'>
</span><span class='line'>等k8s安装启动好后，把privoxy的服务disable掉
</span><span class='line'>[root@k8s ~]# systemctl disable privoxy.service</span></code></pre></td></tr></table></div></figure>


<h2>下载kubectl（怪了，这个竟然可以直接下载）</h2>

<p>变化好快，现在都1.7.2了！ <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>

<p>在master机器（常用的操作机器）安装即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
</span><span class='line'>chmod +x ./kubectl
</span><span class='line'>mv ./kubectl /usr/local/bin/kubectl
</span><span class='line'>
</span><span class='line'># 启用shell的提示/自动完成autocompletion
</span><span class='line'>echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl version 
</span><span class='line'>Client Version: version.Info{Major:"1", Minor:"7", GitVersion:"v1.7.2", GitCommit:"922a86cfcd65915a9b2f69f3f193b8907d741d9c", GitTreeState:"clean", BuildDate:"2017-07-21T08:23:22Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"linux/amd64"}
</span><span class='line'>The connection to the server localhost:8080 was refused - did you specify the right host or port?
</span></code></pre></td></tr></table></div></figure>


<h2>通过VPN安装kubelet和kubeadm</h2>

<p>参考 <a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm">https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm</a></p>

<p>You will install these packages on all of your machines:</p>

<ul>
<li>kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</li>
<li>kubeadm: the command to bootstrap the cluster.</li>
</ul>


<p>所有机器都要安装的，我们先在master节点上通过代理安装这两个软件，并把安装的所有rpm缓冲起来。</p>

<ul>
<li>配置kubernetes的仓库源：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span><span class='line'>[kubernetes]
</span><span class='line'>name=Kubernetes
</span><span class='line'>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>repo_gpgcheck=1
</span><span class='line'>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
</span><span class='line'>        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 
</span><span class='line'>setenforce 0
</span><span class='line'>
</span><span class='line'>yum-config-manager --enable kubernetes</span></code></pre></td></tr></table></div></figure>


<ul>
<li>YUM配置socks5代理： <a href="https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum">https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum</a></li>
</ul>


<p>修改yum的配置，增加代理，并缓冲（用于其他机器安装）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# vi /etc/yum.conf 
</span><span class='line'>keepcache=1
</span><span class='line'>...
</span><span class='line'>proxy=socks5://127.0.0.1:1080
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装并启动kubelet：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install -y kubelet kubeadm
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl enable kubelet && systemctl start kubelet
</span><span class='line'>Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<h2>通过VPN安装初始化集群（主要是配置代理下载docker容器）</h2>

<p>由于是直接docker去获取镜像的，首先需要修改docker的配置。</p>

<p>参考 <a href="https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy">https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy</a></p>

<ul>
<li>配置代理并重启docker、kubelet</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# systemctl enable docker
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# mkdir -p /etc/systemd/system/docker.service.d/
</span><span class='line'>[root@k8s ~]# vi /etc/systemd/system/docker.service.d/http-proxy.conf
</span><span class='line'>[Service]
</span><span class='line'>Environment="HTTP_PROXY=http://192.168.191.138:8118/" "HTTPS_PROXY=http://192.168.191.138:8118/" "NO_PROXY=localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
</span><span class='line'>                             
</span><span class='line'>[root@k8s ~]# systemctl daemon-reload
</span><span class='line'>[root@k8s ~]# systemctl restart docker</span></code></pre></td></tr></table></div></figure>


<p>docker和kubelet的cgroup驱动方式不同，需要修复配置：<a href="https://github.com/kubernetes/kubeadm/issues/103">https://github.com/kubernetes/kubeadm/issues/103</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>前面已经启动了kubelet，有如下的错误日志
</span><span class='line'>[root@k8s ~]# journalctl -xeu kubelet
</span><span class='line'>Jul 29 09:11:24 k8s kubelet[48557]: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgr
</span><span class='line'>
</span><span class='line'>修改配置
</span><span class='line'>[root@k8s ~]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span><span class='line'>Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs"
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# systemctl daemon-reload
</span><span class='line'>[root@k8s ~]# service kubelet restart
</span><span class='line'>Redirecting to /bin/systemctl restart  kubelet.service
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>使用kubeadm进行初始化</li>
</ul>


<p><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a> （可以使用 &ndash;kubernetes-version 来指定k8s的版本）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置代理，kubeadm有部分请求应该也是需要走代理的（前面用脚本安装过multinode on docker的经历猜测的）
</span><span class='line'>
</span><span class='line'>export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
</span><span class='line'>export https_proxy=http://192.168.191.138:8118/
</span><span class='line'>export http_proxy=http://192.168.191.138:8118/
</span><span class='line'>
</span><span class='line'># 使用reset重置，网络代理的配置修改了多次（kubeadm初始换过程失败过），还有前几次的初始化没有配置pod地址段
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm reset
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>[reset] Stopping the kubelet service
</span><span class='line'>[reset] Unmounting mounted directories in "/var/lib/kubelet"
</span><span class='line'>[reset] Removing kubernetes-managed containers
</span><span class='line'>[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/lib/etcd]
</span><span class='line'>[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
</span><span class='line'>[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
</span><span class='line'>
</span><span class='line'># 使用flannel需要指定pod的网卡地址段（文档要整体看一遍才能少踩坑，囧）
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[init] Using Kubernetes version: v1.7.2
</span><span class='line'>[init] Using Authorization modes: [Node RBAC]
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
</span><span class='line'>[certificates] Generated CA certificate and key.
</span><span class='line'>[certificates] Generated API server certificate and key.
</span><span class='line'>[certificates] API Server serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.191.138]
</span><span class='line'>[certificates] Generated API server kubelet client certificate and key.
</span><span class='line'>[certificates] Generated service account token signing key and public key.
</span><span class='line'>[certificates] Generated front-proxy CA certificate and key.
</span><span class='line'>[certificates] Generated front-proxy client certificate and key.
</span><span class='line'>[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
</span><span class='line'>[apiclient] Created API client, waiting for the control plane to become ready  
</span><span class='line'>&lt;-&gt; 这里会停的比较久，要去下载镜像，然后还得启动容器
</span><span class='line'>[apiclient] All control plane components are healthy after 293.004469 seconds
</span><span class='line'>[token] Using token: 2af779.b803df0b1effb3d9
</span><span class='line'>[apiconfig] Created RBAC rules
</span><span class='line'>[addons] Applied essential addon: kube-proxy
</span><span class='line'>[addons] Applied essential addon: kube-dns
</span><span class='line'>
</span><span class='line'>Your Kubernetes master has initialized successfully!
</span><span class='line'>
</span><span class='line'>To start using your cluster, you need to run (as a regular user):
</span><span class='line'>
</span><span class='line'>  mkdir -p $HOME/.kube
</span><span class='line'>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>You should now deploy a pod network to the cluster.
</span><span class='line'>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
</span><span class='line'>  http://kubernetes.io/docs/admin/addons/
</span><span class='line'>
</span><span class='line'>You can now join any number of machines by running the following on each node
</span><span class='line'>as root:
</span><span class='line'>
</span><span class='line'>  kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<p>监控安装情况命令有： <code>docker ps</code>, <code>docker images</code>, <code>journalctl -xeu kubelet</code> (/var/log/messages) 。</p>

<p>如果有镜像下载和容器新增，说明安装过程在进行中。否则得检查下你的代理是否正常工作了！</p>

<p>初始化完成后，配置kubectl的kubeconfig。一般都是主节点了，直接在节点执行下面命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# mkdir -p $HOME/.kube
</span><span class='line'>[root@k8s ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>[root@k8s ~]# chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>[root@k8s ~]# 
</span><span class='line'>[root@k8s ~]# ll ~/.kube/
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x. 3 root root   23 Jul 29 21:39 cache
</span><span class='line'>-rw-------. 1 root root 5451 Jul 29 22:57 config</span></code></pre></td></tr></table></div></figure>


<p><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">使用Kubeadm安装Kubernetes</a> 介绍了很多作者自己安装过程，以及遇到的问题，非常详细。安装的差不多才发现这篇文章，感觉好迟，如果早点找到，至少安装的时刻心安一点啊。</p>

<p>OK，服务启动了，但是 dns容器 还没有正常启动。由于我们的网络组建还没有安装好啊。其实官网也有说明，但是这安装的顺序也是醉了。</p>

<p> <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p>

<h2>安装flannel</h2>

<p>参考： <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span><span class='line'>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.yml</span></code></pre></td></tr></table></div></figure>


<p>flannel启动了后，再等一阵，dns才会启动好。</p>

<h2>安装dashboard</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>现在就一台机器，得让master也能跑pods。 
</span><span class='line'>https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#master-isolation
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
</span><span class='line'>node "k8s" untainted
</span><span class='line'>
</span><span class='line'># https://lukemarsden.github.io/docs/user-guide/ui/
</span><span class='line'># 部署dashboard
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods --all-namespaces 看看dashboard的情况
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get services --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.96.0.1       &lt;none&gt;        443/TCP         1h
</span><span class='line'>kube-system   kube-dns               10.96.0.10      &lt;none&gt;        53/UDP,53/TCP   1h
</span><span class='line'>kube-system   kubernetes-dashboard   10.107.103.17   &lt;none&gt;        80/TCP          9m</span></code></pre></td></tr></table></div></figure>


<p>用 <a href="https://master:6443/ui">https://master:6443/ui</a> 访问不了，可以直接用k8s的service地址访问 <a href="http://10.107.103.17/#!/overview?namespace=kube-system">http://10.107.103.17/#!/overview?namespace=kube-system</a></p>

<p>或者通过 <strong> proxy </strong> 访问UI：<a href="https://github.com/kubernetes/kubernetes/issues/44275">https://github.com/kubernetes/kubernetes/issues/44275</a></p>

<p>先运行proxy，启动代理程序：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl proxy
</span><span class='line'>Starting to serve on 127.0.0.1:8001</span></code></pre></td></tr></table></div></figure>


<p>然后访问： <a href="http://localhost:8001/ui">http://localhost:8001/ui</a></p>

<h2>所有的pods、镜像、容器</h2>

<p>基本的东西都跑起来，还是挺激动啊！！第N次安装部署K8S了啊，每次都还是得像坐过山车一样啊！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl get pods --all-namespaces -o wide
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE       IP                NODE
</span><span class='line'>kube-system   etcd-k8s                                1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-apiserver-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-controller-manager-k8s             1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-dns-2425271678-qwx9f               3/3       Running   0          9h        10.244.0.2        k8s
</span><span class='line'>kube-system   kube-flannel-ds-s5f63                   2/2       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-proxy-4pjkg                        1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kube-scheduler-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
</span><span class='line'>kube-system   kubernetes-dashboard-3313488171-xl25m   1/1       Running   0          8h        10.244.0.3        k8s
</span><span class='line'>[root@k8s ~]# docker images
</span><span class='line'>REPOSITORY                                               TAG                 IMAGE ID            CREATED             SIZE
</span><span class='line'>gcr.io/google_containers/kubernetes-dashboard-amd64      v1.6.3              691a82db1ecd        35 hours ago        139 MB
</span><span class='line'>gcr.io/google_containers/kube-apiserver-amd64            v1.7.2              4935105a20b1        8 days ago          186.1 MB
</span><span class='line'>gcr.io/google_containers/kube-proxy-amd64                v1.7.2              13a7af96c7e8        8 days ago          114.7 MB
</span><span class='line'>gcr.io/google_containers/kube-controller-manager-amd64   v1.7.2              2790e95830f6        8 days ago          138 MB
</span><span class='line'>gcr.io/google_containers/kube-scheduler-amd64            v1.7.2              5db1f9874ae0        8 days ago          77.18 MB
</span><span class='line'>quay.io/coreos/flannel                                   v0.8.0-amd64        9db3bab8c19e        2 weeks ago         50.73 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-sidecar-amd64           1.14.4              38bac66034a6        4 weeks ago         41.81 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-kube-dns-amd64          1.14.4              a8e00546bcf3        4 weeks ago         49.38 MB
</span><span class='line'>gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64     1.14.4              f7f45b9cb733        4 weeks ago         41.41 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                      3.0.17              243830dae7dd        5 months ago        168.9 MB
</span><span class='line'>gcr.io/google_containers/pause-amd64                     3.0                 99e59f495ffa        15 months ago       746.9 kB
</span><span class='line'>[root@k8s ~]# docker ps 
</span><span class='line'>CONTAINER ID        IMAGE                                                                                                                            COMMAND                  CREATED             STATUS              PORTS               NAMES
</span><span class='line'>631dc2cab02e        gcr.io/google_containers/kubernetes-dashboard-amd64@sha256:2c4421ed80358a0ee97b44357b6cd6dc09be6ccc27dfe9d50c9bfc39a760e5fe      "/dashboard --insecur"   7 hours ago         Up 7 hours                              k8s_kubernetes-dashboard_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
</span><span class='line'>8f5e4d044a6e        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 8 hours ago         Up 8 hours                              k8s_POD_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
</span><span class='line'>65881f9dd2dd        gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:97074c951046e37d3cbb98b82ae85ed15704a290cce66a8314e7f846404edde9           "/sidecar --v=2 --log"   9 hours ago         Up 9 hours                              k8s_sidecar_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>994c2ec99663        gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64@sha256:aeeb994acbc505eabc7415187cd9edb38cbb5364dc1c2fc748154576464b3dc2     "/dnsmasq-nanny -v=2 "   9 hours ago         Up 9 hours                              k8s_dnsmasq_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>5b181a0ed809        gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344          "/kube-dns --domain=c"   9 hours ago         Up 9 hours                              k8s_kubedns_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>a0d3f166e992        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>9cc7d6faf0b0        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/bin/sh -c 'set -e -"   9 hours ago         Up 9 hours                              k8s_install-cni_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>2f41276df8e1        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/opt/bin/flanneld --"   9 hours ago         Up 9 hours                              k8s_kube-flannel_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>bc25b0c70264        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
</span><span class='line'>dc3e5641c273        gcr.io/google_containers/kube-proxy-amd64@sha256:d455480e81d60e0eff3415675278fe3daec6f56c79cd5b33a9b76548d8ab4365                "/usr/local/bin/kube-"   9 hours ago         Up 9 hours                              k8s_kube-proxy_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>6b8b9515f562        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
</span><span class='line'>72418ca8e94f        gcr.io/google_containers/kube-apiserver-amd64@sha256:a9ccc205760319696d2ef0641de4478ee90fb0b75fbe6c09b1d64058c8819f97            "kube-apiserver --ser"   9 hours ago         Up 9 hours                              k8s_kube-apiserver_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
</span><span class='line'>9c9a3f5d8919        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
</span><span class='line'>43a1751ff2bb        gcr.io/google_containers/etcd-amd64@sha256:d83d3545e06fb035db8512e33bd44afb55dea007a3abd7b17742d3ac6d235940                      "etcd --listen-client"   9 hours ago         Up 9 hours                              k8s_etcd_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
</span><span class='line'>b110fff29f66        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
</span><span class='line'>66ae85500128        gcr.io/google_containers/kube-scheduler-amd64@sha256:b2e897138449e7a00508dc589b1d4b71e56498a4d949ff30eb07b1e9d665e439            "kube-scheduler --add"   9 hours ago         Up 9 hours                              k8s_kube-scheduler_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
</span><span class='line'>d4343be2f2d0        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
</span><span class='line'>9934cd83f6b3        gcr.io/google_containers/kube-controller-manager-amd64@sha256:2b268ab9017fadb006ee994f48b7222375fe860dc7bd14bf501b98f0ddc2961b   "kube-controller-mana"   9 hours ago         Up 9 hours                              k8s_kube-controller-manager_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
</span><span class='line'>acc1d7d90180        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
</span><span class='line'>[root@k8s ~]# </span></code></pre></td></tr></table></div></figure>


<h2>Woker节点部署</h2>

<p>时间，主机名，/etc/hosts，防火墙，selinux, 无密钥登录，安装docker-1.12.6就不再赘述了。</p>

<p>直接用master的yum缓冲，还有docker镜像直接拷贝：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># master机器已安装httpd服务
</span><span class='line'>
</span><span class='line'>[root@k8s html]# ln -s /var/cache/yum/x86_64/7/kubernetes/packages/ k8s 
</span><span class='line'>[root@k8s k8s]# createrepo .          
</span><span class='line'>
</span><span class='line'># 把镜像全部拷到worker节点
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker save $( echo $( docker images | grep -v REPOSITORY | awk '{print $1}' ) ) | ssh worker1 docker load 
</span><span class='line'>
</span><span class='line'># 配置私有仓库源
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# vi k8s.repo
</span><span class='line'>[k8s]
</span><span class='line'>name=Kubernetes
</span><span class='line'>baseurl=http://master/k8s
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>[root@worker1 yum.repos.d]# yum list | grep k8s 
</span><span class='line'>kubeadm.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubectl.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubelet.x86_64                             1.7.2-0                     k8s      
</span><span class='line'>kubernetes-cni.x86_64                      0.5.1-0                     k8s      
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# yum install -y kubelet kubeadm                          
</span><span class='line'>
</span><span class='line'># 修改cgroup-driver
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf  
</span><span class='line'>[root@worker1 yum.repos.d]# 
</span><span class='line'>[root@worker1 yum.repos.d]# service docker restart
</span><span class='line'>Redirecting to /bin/systemctl restart  docker.service
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# systemctl daemon-reload
</span><span class='line'>[root@worker1 yum.repos.d]# systemctl enable kubelet.service
</span><span class='line'>[root@worker1 yum.repos.d]# service kubelet restart
</span><span class='line'>Redirecting to /bin/systemctl restart  kubelet.service
</span><span class='line'>
</span><span class='line'># worker节点加入集群（初始化）
</span><span class='line'>
</span><span class='line'>[root@worker1 yum.repos.d]# kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443 --skip-preflight-checks
</span><span class='line'>[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
</span><span class='line'>[preflight] Skipping pre-flight checks
</span><span class='line'>[discovery] Trying to connect to API Server "192.168.191.138:6443"
</span><span class='line'>[discovery] Created cluster-info discovery client, requesting info from "https://192.168.191.138:6443"
</span><span class='line'>[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.191.138:6443"
</span><span class='line'>[discovery] Successfully established connection with API Server "192.168.191.138:6443"
</span><span class='line'>[bootstrap] Detected server version: v1.7.2
</span><span class='line'>[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
</span><span class='line'>[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
</span><span class='line'>[csr] Received signed certificate from the API server, generating KubeConfig...
</span><span class='line'>[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
</span><span class='line'>
</span><span class='line'>Node join complete:
</span><span class='line'>* Certificate signing request sent to master and response
</span><span class='line'>  received.
</span><span class='line'>* Kubelet informed of new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the master to see this machine join.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get nodes
</span><span class='line'>NAME      STATUS    AGE       VERSION
</span><span class='line'>k8s       Ready     10h       v1.7.2
</span><span class='line'>worker1   Ready     57s       v1.7.2</span></code></pre></td></tr></table></div></figure>


<p>主节点运行的flannel网络组件是个 daemonset 的pod，只要加入到集群就会在每个节点上启动。不需要额外的操作。</p>

<h2>关于重启：</h2>

<p>使用RPM安装的好处是：程序系统都帮你管理了：</p>

<ul>
<li>worker节点重启后，kubelet会把所有的服务都带起来。</li>
<li>master重启后，需要等一段时间，因为pods启动有顺序/依赖：dns需要等flannel，dashboard需要等dns。</li>
</ul>


<h2>POD间连通性测试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl run hello-nginx --image=nginx --port=80
</span><span class='line'>deployment "hello-nginx" created
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS              RESTARTS   AGE
</span><span class='line'>hello-nginx-1507731416-qh3fx   0/1       ContainerCreating   0          8s
</span><span class='line'>
</span><span class='line'># 脚本启动新的dockerd并配置加速器，下载好然后save导入都本地docker实例
</span><span class='line'># https://github.com/winse/docker-hadoop/blob/master/kube-deploy/hadoop/docker-download-mirror.sh
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# ./docker-download-mirror.sh nginx 
</span><span class='line'>Using default tag: latest
</span><span class='line'>latest: Pulling from library/nginx
</span><span class='line'>
</span><span class='line'>94ed0c431eb5: Pull complete 
</span><span class='line'>9406c100a1c3: Pull complete 
</span><span class='line'>aa74daafd50c: Pull complete 
</span><span class='line'>Digest: sha256:788fa27763db6d69ad3444e8ba72f947df9e7e163bad7c1f5614f8fd27a311c3
</span><span class='line'>Status: Downloaded newer image for nginx:latest
</span><span class='line'>eb78099fbf7f: Loading layer [==================================================&gt;] 58.42 MB/58.42 MB
</span><span class='line'>29f11c413898: Loading layer [==================================================&gt;] 52.74 MB/52.74 MB
</span><span class='line'>af5bd3938f60: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>
</span><span class='line'># 拷贝镜像到其他的worker节点，就几台机器搭建register服务感觉太重了
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker save nginx | ssh worker1 docker load
</span><span class='line'>Loaded image: nginx:latest
</span><span class='line'>
</span><span class='line'># 查看效果
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE
</span><span class='line'>hello-nginx-1507731416-qh3fx   1/1       Running   0          1m
</span><span class='line'>
</span><span class='line'># 扩容
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl scale --replicas=4 deployment/hello-nginx  
</span><span class='line'>deployment "hello-nginx" scaled
</span><span class='line'>[root@k8s ~]# kubectl get pods -o wide
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE       IP           NODE
</span><span class='line'>hello-nginx-1507731416-h39f0   1/1       Running   0          34s       10.244.0.6   k8s
</span><span class='line'>hello-nginx-1507731416-mnj3m   1/1       Running   0          34s       10.244.1.3   worker1
</span><span class='line'>hello-nginx-1507731416-nsdr2   1/1       Running   0          34s       10.244.0.7   k8s
</span><span class='line'>hello-nginx-1507731416-qh3fx   1/1       Running   0          5m        10.244.1.2   worker1
</span><span class='line'>[root@k8s ~]# kubectl delete deployment hello-nginx
</span><span class='line'>
</span><span class='line'>这容器太简洁了，PING都没有啊！！搞个熟悉的linux版本，再跑一遍
</span><span class='line'>
</span><span class='line'>kubectl run centos --image=centos:centos6 --command -- vi 
</span><span class='line'>kubectl scale --replicas=4 deployment/centos
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods  -o wide 
</span><span class='line'>NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
</span><span class='line'>centos-3024873821-4490r   1/1       Running   0          49s       10.244.1.6    worker1
</span><span class='line'>centos-3024873821-k74gn   1/1       Running   0          11s       10.244.0.11   k8s
</span><span class='line'>centos-3024873821-l27xs   1/1       Running   0          11s       10.244.0.10   k8s
</span><span class='line'>centos-3024873821-pbg52   1/1       Running   0          11s       10.244.1.7    worker1
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl exec -ti centos-3024873821-4490r bash
</span><span class='line'>[root@centos-3024873821-4490r /]# yum install -y iputils
</span><span class='line'>[root@centos-3024873821-4490r /]# ping 10.244.0.11 -c 1
</span><span class='line'>
</span><span class='line'>以上IP都是互通的，从master节点PING这些IP也是通的。
</span><span class='line'>
</span><span class='line'># 查看pod状态的命令
</span><span class='line'>kubectl -n ${NAMESPACE} describe pod ${POD_NAME}
</span><span class='line'>kubectl -n ${NAMESPACE} logs ${POD_NAME} -c ${CONTAINER_NAME}</span></code></pre></td></tr></table></div></figure>


<h2>源IP问题</h2>

<p>原来部署hadoop的时刻，已经遇到过了。知道根源所在，但是这次使用的cni（直接改 <code>dockerd --ip-masq=false</code> 配置仅修改的是docker0）。</p>

<p>先来重现下源ip问题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./pod_bash centos-3024873821-t3k3r 
</span><span class='line'>
</span><span class='line'>yum install epel-release -y ; yum install nginx -y ;
</span><span class='line'>service nginx start
</span><span class='line'>
</span><span class='line'>ifconfig
</span><span class='line'>
</span><span class='line'># nginx安装后，访问查看access_log
</span><span class='line'>
</span><span class='line'>less /var/log/nginx/access.log 
</span></code></pre></td></tr></table></div></figure>


<p>在 kube-flannel.yml 中添加 cni-conf.json 网络配置为 <code>"ipMasq": false,</code>，没啥效果，在iptables上面还是有cni的cbr0的MASQUERADE（SNAT）。</p>

<p>用比较极端点的方式，删掉docker0，替换成cni0。 <a href="https://kubernetes.io/docs/getting-started-guides/scratch/#docker">https://kubernetes.io/docs/getting-started-guides/scratch/#docker</a></p>

<p>把docker的网卡设置成cni0 :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -t nat -F
</span><span class='line'>ip link set docker0 down
</span><span class='line'>ip link delete docker0
</span><span class='line'>
</span><span class='line'>[root@worker1 ~]# cat /usr/lib/systemd/system/docker.service  | grep dockerd
</span><span class='line'>ExecStart=/usr/bin/dockerd --bridge=cni0 --ip-masq=false 
</span></code></pre></td></tr></table></div></figure>


<p>但是机器重启后cni0这个网卡设备就没有了，导致机器重启后docker启动失败！TODO：这个问题还挺麻烦，以后再针对性的处理！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; Aug 01 08:36:10 k8s dockerd[943]: time="2017-08-01T08:36:10.017266292+08:00" level=fatal msg="Error starting daemon: Error initializing network controller: Error creating default \"bridge\" network: bridge device with non default name cni0 must be created manually"
</span><span class='line'>
</span><span class='line'>ip link add name cni0 type bridge
</span><span class='line'>ip link set dev cni0 mtu 1460
</span><span class='line'># 让flannel来设置IP地址
</span><span class='line'># ip addr add $NODE_X_BRIDGE_ADDR dev cni0
</span><span class='line'>ip link set dev cni0 up
</span><span class='line'>
</span><span class='line'>systemctl restart docker kubelet
</span></code></pre></td></tr></table></div></figure>


<h2>DNS</h2>

<p><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># cat busybox.yaml
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  namespace: default
</span><span class='line'>spec:
</span><span class='line'>  containers:
</span><span class='line'>  - image: busybox
</span><span class='line'>    command:
</span><span class='line'>      - sleep
</span><span class='line'>      - "3600"
</span><span class='line'>    imagePullPolicy: IfNotPresent
</span><span class='line'>    name: busybox
</span><span class='line'>  restartPolicy: Always
</span><span class='line'>
</span><span class='line'>kubectl create -f busybox.yaml
</span><span class='line'>kubectl exec -ti busybox -- nslookup kubernetes.default
</span><span class='line'>kubectl exec busybox cat /etc/resolv.conf
</span></code></pre></td></tr></table></div></figure>


<h2>DNS问题</h2>

<p>在master节点上的POD容器内访问DNS（service）服务，但是返回数据却是域名服务内部POD的IP，而不是Service服务的IP地址。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl describe services kube-dns -n kube-system
</span><span class='line'>Name:                   kube-dns
</span><span class='line'>Namespace:              kube-system
</span><span class='line'>Labels:                 k8s-app=kube-dns
</span><span class='line'>                        kubernetes.io/cluster-service=true
</span><span class='line'>                        kubernetes.io/name=KubeDNS
</span><span class='line'>Annotations:            &lt;none&gt;
</span><span class='line'>Selector:               k8s-app=kube-dns
</span><span class='line'>Type:                   ClusterIP
</span><span class='line'>IP:                     10.96.0.10
</span><span class='line'>Port:                   dns     53/UDP
</span><span class='line'>Endpoints:              10.244.0.30:53
</span><span class='line'>Port:                   dns-tcp 53/TCP
</span><span class='line'>Endpoints:              10.244.0.30:53
</span><span class='line'>Session Affinity:       None
</span><span class='line'>Events:                 &lt;none&gt;
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl exec -ti centos-3024873821-b6d48 -- nslookup kubernetes.default
</span><span class='line'>;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</span><span class='line'>;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</span></code></pre></td></tr></table></div></figure>


<h4>相关问题的一些资源：</h4>

<ul>
<li>*<a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">kubernetes pods replying with unexpected source for DNS queries</a></li>
<li><a href="https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477">https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477</a></li>
<li><p><a href="https://github.com/coreos/coreos-kubernetes/issues/572">cni plugin + flannel on v1.3: pods can&rsquo;t route to service IPs</a></p></li>
<li><p><a href="https://www.slideshare.net/kubecon/container-network-interface-network-plugins-for-kubernetes-and-beyond">Container Network Interface: Network Plugins for Kubernetes and beyond</a></p></li>
<li><a href="http://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/">Understanding CNI (Container Networking Interface)</a></li>
<li><a href="https://feisky.gitbooks.io/kubernetes/network/flannel/">Kubernetes指南 - flannel</a></li>
</ul>


<h4>解决方法：</h4>

<p><strong> kube-proxy加上 &ndash;masquerade-all 解决了。</strong></p>

<h4>处理方法：</h4>

<blockquote><p><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a>
kubeadm installs add-on components via the API server. Right now this is the internal DNS server and the kube-proxy DaemonSet.</p></blockquote>

<p>修改有技巧，由于kube-proxy是内部容器启动的。也没找到yaml配置，不能直接改配置文件，这里有如下两种方式修改：</p>

<ul>
<li>通过Dashboard页面的编辑对配置进行修改</li>
<li>通过edit命令对配置进行修改：<code>kubectl edit daemonset kube-proxy -n=kube-system</code> 命令添加 <code>- --masquerade-all</code></li>
</ul>


<h2>Heapster</h2>

<p>参考</p>

<ul>
<li><a href="https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md">https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md</a></li>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/">https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# git clone https://github.com/kubernetes/heapster.git
</span><span class='line'>Cloning into 'heapster'...
</span><span class='line'>remote: Counting objects: 26084, done.
</span><span class='line'>remote: Total 26084 (delta 0), reused 0 (delta 0), pack-reused 26084
</span><span class='line'>Receiving objects: 100% (26084/26084), 36.33 MiB | 2.66 MiB/s, done.
</span><span class='line'>Resolving deltas: 100% (13084/13084), done.
</span><span class='line'>Checking out files: 100% (2531/2531), done.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# cd heapster/
</span><span class='line'>[root@k8s heapster]# kubectl create -f deploy/kube-config/influxdb/
</span><span class='line'>deployment "monitoring-grafana" created
</span><span class='line'>service "monitoring-grafana" created
</span><span class='line'>serviceaccount "heapster" created
</span><span class='line'>deployment "heapster" created
</span><span class='line'>service "heapster" created
</span><span class='line'>deployment "monitoring-influxdb" created
</span><span class='line'>service "monitoring-influxdb" created
</span><span class='line'>[root@k8s heapster]# kubectl create -f deploy/kube-config/rbac/heapster-rbac.yaml 
</span><span class='line'>clusterrolebinding "heapster" created
</span></code></pre></td></tr></table></div></figure>


<p>其他资源：</p>

<ul>
<li><a href="http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/">http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/</a></li>
<li><a href="http://www.pangxie.space/docker/727">http://www.pangxie.space/docker/727</a></li>
<li><a href="http://jerrymin.blog.51cto.com/3002256/1904460">http://jerrymin.blog.51cto.com/3002256/1904460</a></li>
<li><a href="http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer</a></li>
</ul>


<p>DNS的问题耗了比较多的时间。弄好了DNS后，以及docker镜像的下载都OK的话，就万事俱备了。最后重新启动下dashboard就行了：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl delete -f kubernetes-dashboard.yaml 
</span><span class='line'>[root@k8s ~]# kubectl create -f kubernetes-dashboard.yaml 
</span></code></pre></td></tr></table></div></figure>


<p>然后就可以在dashboard上看到美美的曲线图了。</p>

<h2>harbor</h2>

<p>参考 <a href="https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md">https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md</a></p>

<p>日新月异啊，1.1.2版本了！！ 用迅雷直接下载 <a href="https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz">https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz</a>  这个地址。</p>

<p>操作方式还是和原来的版本一样。也就是说可以用原来简化的脚本来安装！</p>

<p>搭建好了后，会基本的使用就差不多了。测试环境资源有限，并且其实用save和load也能解决（咔咔）。</p>

<h2>参考</h2>

<p>官方的一些资源</p>

<ul>
<li><a href="https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy">https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></li>
<li><a href="https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/">https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection">https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#environment-variables">https://kubernetes.io/docs/admin/kubeadm/#environment-variables</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/</a> 怎么升级，以及如何制定特定的k8s版本</li>
</ul>


<p>使用kubeadm安装集群</p>

<ul>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/</a></li>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/</a>  weave net网络</li>
<li><a href="https://www.kubernetes.org.cn/1165.html">https://www.kubernetes.org.cn/1165.html</a> 就是上面第一篇，但是排版看起来跟舒服点</li>
<li><a href="http://hairtaildai.com/blog/11">http://hairtaildai.com/blog/11</a> 安装似乎太顺利了，都没有遇到啥问题？</li>
<li><a href="https://my.oschina.net/xdatk/blog/895645">https://my.oschina.net/xdatk/blog/895645</a> 这篇不推荐，太繁琐了，可以作为参考。很多贴的是内容，不知道改过啥！</li>
</ul>


<p>DNS问题参考</p>

<ul>
<li><a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries</a></li>
<li><a href="https://kubernetes.io/docs/admin/kube-proxy/">https://kubernetes.io/docs/admin/kube-proxy/</a></li>
<li><p><a href="https://docs.docker.com/engine/admin/systemd/#httphttps-proxy">https://docs.docker.com/engine/admin/systemd/#httphttps-proxy</a></p></li>
<li><p><a href="https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html">https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html</a> 命令行编辑的方法在这里看到的
$ kubectl edit deployments kube-scheduler -n=kube-system
$ kubectl edit deployments kube-controller-manager -n=kube-system
$ kubectl edit daemonset kubelet -n=kube-system  &lt;===
$ kubectl get nodes -o yaml | grep &lsquo;kubeletVersion|kubeProxyVersion&rsquo;</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/34101">https://github.com/kubernetes/kubernetes/issues/34101</a>
Ok, so it turns out that this flag is not enough, we still have an issue reaching kubernetes service IP. The simplest solution to this is to run kube-proxy with &ndash;proxy-mode=userspace. To enable this, you can use kubectl -n kube-system edit ds kube-proxy-amd64 &amp;&amp; kubectl -n kube-system delete pods -l name=kube-proxy-amd64.</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/36835">https://github.com/kubernetes/kubernetes/issues/36835</a> To enable off-cluster bridging when &ndash;proxy-mode=iptables, also set &ndash;cluster-cidr.</p></li>
<li><a href="https://github.com/kubernetes/kubeadm/issues/102">https://github.com/kubernetes/kubeadm/issues/102</a> proxy: clusterCIDR not specified, unable to distinguish between internal and external traffic</li>
</ul>


<p>其他一些资源</p>

<ul>
<li><a href="https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md">https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md</a></li>
<li><p><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/</a>
kubectl get pod -l app=nginx -o jsonpath=&lsquo;{range .items[*]}{.metadata.name}{&ldquo;\t&rdquo;}{.spec.containers[0].image}{&ldquo;\n&rdquo;}{end}&rsquo;
kubectl patch statefulset web -p &lsquo;{&ldquo;spec&rdquo;:{&ldquo;updateStrategy&rdquo;:{&ldquo;type&rdquo;:&ldquo;RollingUpdate&rdquo;}}}</p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/">https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/</a> Replication Controllers</p></li>
<li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy</a> RestartPolicy</li>
</ul>


<p>&mdash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[转]一致性Hash]]></title>
    <link href="http://winseliu.com/blog/2017/07/16/consistent-hashing/"/>
    <updated>2017-07-16T01:03:51+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/16/consistent-hashing</id>
    <content type="html"><![CDATA[<p><a href="http://gywbd.github.io/posts/2016/10/consistent-hashing.html">一致性哈希</a></p>

<p>图文并茂，写的非常好。</p>

<p>要点：</p>

<ol>
<li>解决Hash的随机分布带来的增删节点的需重新全部映射的问题：对主机使用同样的函数把主机A分布到环上（其实就是分配一段范围），然后在Hash后在这段范围内的数据全部存储到主机A上。这样增删节点只需要对部分数据重新映射。</li>
</ol>


<p><img src="http://gywbd.github.io/images/ch1.png" alt="" /></p>

<p><img src="http://gywbd.github.io/images/ch8.png" alt="" /></p>

<p><img src="http://gywbd.github.io/images/ch10.png" alt="" /></p>

<ol>
<li>由此又引入了一个优化的点。（随机在环上放置节点）机器硬件不同，能力不同，以及数据分布均衡（热点机器）等的问题。所以，虚拟节点就是用来节点这个问题的。每个节点可以指定分配的虚拟节点数。</li>
</ol>


<p><img src="http://gywbd.github.io/images/ch13.png" alt="" /></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[togo简单的RPM打包工具]]></title>
    <link href="http://winseliu.com/blog/2017/07/15/togo-another-rpmbuild-tool/"/>
    <updated>2017-07-15T15:09:52+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/15/togo-another-rpmbuild-tool</id>
    <content type="html"><![CDATA[<p>源码： <a href="https://github.com/genereese/togo">https://github.com/genereese/togo</a></p>

<h2>安装</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install https://github.com/genereese/togo/releases/download/v2.3r7/togo-2.3-7.noarch.rpm</span></code></pre></td></tr></table></div></figure>


<h2>实际案例使用</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 创建类似rpmbuild的骨架
</span><span class='line'>togo project create my-new-rpm; cd my-new-rpm
</span><span class='line'>
</span><span class='line'># 内容准备
</span><span class='line'>mkdir -p root/usr/local/bin; touch root/usr/local/bin/exmaple.sh
</span><span class='line'>chmod +x root/usr/local/bin/exmaple.sh
</span><span class='line'>
</span><span class='line'># 排除目录、文件
</span><span class='line'>togo file exclude root/usr/local/bin
</span><span class='line'>  Removed '/usr/local/bin' from project ownership.
</span><span class='line'>  Removed '/usr/local' from project ownership.
</span><span class='line'>  Removed '/usr' from project ownership.
</span><span class='line'>
</span><span class='line'># 修改属性，如第二次重新打包就需要修改下release
</span><span class='line'>vi spec/header
</span><span class='line'>
</span><span class='line'># 编译打包
</span><span class='line'>togo build package</span></code></pre></td></tr></table></div></figure>


<h2>成果</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ll rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>-rw-r--r-- 1 root root 2236 Jul 14 12:17 rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>$ rpm -qpl rpms/my-new-rpm-1.0-1.noarch.rpm
</span><span class='line'>/usr/local/bin/exmaple.sh
</span></code></pre></td></tr></table></div></figure>


<p>打出来的就是第一个标准的rpm包，然后就可以按照rpm包的方式进行处理了：直接安装、或者使用createrepo来制作本地仓库等等。</p>

<p>用来简单打包文件还是挺方便的。相当于把骨架都搭建好了，然后还提供了一些方便的命令来进行维护修改。</p>

<p>还有一个 <a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package#Helpful_tools">rpmdevtools</a> 也是一个创建编译项目的脚手架，只不过这仅仅是对<a href="https://fedoraproject.org/wiki/Archive:BuildingPackagesGuide?rd=Docs/Drafts/BuildingPackagesGuide#Creating_a_New_Package">rpmbuild方式</a>的辅助。更多的还是需要自己精心的维护spec。</p>

<p>还有提到的 <a href="https://github.com/alanfranz/docker-rpm-builder">docker-rpm-builder</a> 需要centos7。如果要打那种N个环境的rpm包，才能体现出它的优势吧。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[爬虫之CasperJS]]></title>
    <link href="http://winseliu.com/blog/2017/07/08/casperjs-crawler/"/>
    <updated>2017-07-08T15:56:06+00:00</updated>
    <id>http://winseliu.com/blog/2017/07/08/casperjs-crawler</id>
    <content type="html"><![CDATA[<p>用jsoup(java, scala, groovy)爬过数据，用cheerio(nodejs)爬过数据，每次爬取都要对页面HTML结构，数据来源URL进行研究。还要对网站的反扒做一些HEADER的设置。各种繁琐，主要还有一些数据型的网站验证复杂，很难通过简单的方式来破解它的那套反扒流程。</p>

<p><a href="http://docs.casperjs.org/en/latest/modules/casper.html">CasperJS</a>是在<a href="http://phantomjs.org/quick-start.html">phantomjs</a>基础上的一套工具库用来简化phantomjs的操作，降低使用和入门的门槛。而PhantomJS是类似浏览器的一个工具（headless browsers），你可以把它看做浏览器。所以可以通过CasperJS来操作浏览器访问地址，然后加载完页面后再提取数据，这样就不要考虑被反扒的风险，并且获取数据的方式相对容易和简单。</p>

<h2>先从官网的案例体验下HelloWorld以及如何调试</h2>

<p>下载最新的<a href="http://docs.casperjs.org/en/latest/installation.html#installing-from-npm">CasperJS（npm install）</a>即可，PhantomJS下载<a href="https://bitbucket.org/ariya/phantomjs/downloads/">1.9.8</a>版本，不推荐2+版本，有些功能有问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>R:\test&gt;set PATH=C:\Users\winse\AppData\Roaming\npm\node_modules\casperjs\bin;E:\phantomjs-1.9.8-windows;%PATH
</span><span class='line'>
</span><span class='line'>R:\test&gt;cat hello.js
</span><span class='line'>var casper = require('casper').create();
</span><span class='line'>// debugger
</span><span class='line'>
</span><span class='line'>casper.start('http://casperjs.org/', function() {
</span><span class='line'>    this.echo(this.getTitle());
</span><span class='line'>    
</span><span class='line'>    this.echo("Star: " + this.evaluate(function () { 
</span><span class='line'>        return $(".octicon-star").parent().text().trim()
</span><span class='line'>    }) )
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.thenOpen('http://phantomjs.org', function() {
</span><span class='line'>    this.echo(this.getTitle());
</span><span class='line'>    
</span><span class='line'>    this.echo("Intro: " + this.evaluate(function () { 
</span><span class='line'>        return $(".intro h1").innerHTML
</span><span class='line'>        // return document.querySelector(".intro h1").innerHTML
</span><span class='line'>    }) )
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run();
</span><span class='line'>
</span><span class='line'>R:\test&gt;casperjs  hello.js
</span><span class='line'>CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
</span><span class='line'>Star: 6,337 Stargazers
</span><span class='line'>PhantomJS | PhantomJS
</span><span class='line'>Intro: null</span></code></pre></td></tr></table></div></figure>


<p>用js的方式来获取页面数据，非常完美，相比直接通过URL请求来获取数据，CasperJS就是慢了点（有点像我们每次都打开浏览器然后再访问，可以通过建立服务，然后在常驻PhantomJS访问页面）。</p>

<p>上面第二次获取的数据不是我们想要的，这里我们通过调试看看到底是什么原因导致的。在start前增加一行 <code>debugger</code> 。然后执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>casperjs hello.js --verbose --log-level=debug --remote-debugger-port=9000</span></code></pre></td></tr></table></div></figure>


<p>打开浏览器方式 localhost:9000 点击 <strong>about:blank</strong> 链接，然后在Console窗口执行 <code>__run()</code> ，等一下下会停在debugger那一行，再然后就是愉快的debug就好了。</p>

<p>在 <a href="http://phantomjs.org">http://phantomjs.org</a> 那一段的evaluate代码处增加一个断点，运行到该断点后，再次打开 localhost:9000 会多出一个当前访问页面的链接，点击进去就像平时F12看到的调式窗口了。</p>

<ul>
<li><a href="http://phantomjs.org/troubleshooting.html#remote-debugging">http://phantomjs.org/troubleshooting.html#remote-debugging</a></li>
<li><a href="https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs">https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs</a></li>
<li><a href="https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper">https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper</a></li>
<li><a href="https://github.com/ariya/phantomjs/issues/12064">https://github.com/ariya/phantomjs/issues/12064</a></li>
</ul>


<p>注意: <a href="https://www.portablesoft.org/google-chrome-legacy-versions/">Chrome浏览器要用V54版本以下</a> 的。</p>

<p>调试详情如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; $(".intro h1")
</span><span class='line'>null
</span><span class='line'>&gt; $
</span><span class='line'>bound: function () {
</span><span class='line'>        return document.getElementById.apply(document, arguments);
</span><span class='line'>    }
</span><span class='line'>&gt; document.querySelector(".intro h1").innerHTML
</span><span class='line'>"
</span><span class='line'>        Full web stack&lt;br&gt;
</span><span class='line'>        No browser required
</span><span class='line'>      "</span></code></pre></td></tr></table></div></figure>


<p>那我们把js脚本修改成querySelector来获取数据。再次执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>R:\test&gt;casperjs  hello.js
</span><span class='line'>CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
</span><span class='line'>Star: 6,337 Stargazers
</span><span class='line'>PhantomJS | PhantomJS
</span><span class='line'>Intro:
</span><span class='line'>        Full web stack&lt;br&gt;
</span><span class='line'>        No browser required</span></code></pre></td></tr></table></div></figure>


<h2>功能特性</h2>

<ul>
<li>截图</li>
</ul>


<p>有现成的方法，但是需要自己<a href="https://uggedal.com/journal/phantomjs-default-background-color/">处理下背景颜色</a> <a href="http://phantomjs.org/tips-and-tricks.html">Tips and Tricks</a>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cat capture.js
</span><span class='line'>var casper = require('casper').create({
</span><span class='line'>    waitTimeout: 120000,
</span><span class='line'>    logLevel: "debug",
</span><span class='line'>    verbose: true
</span><span class='line'>});
</span><span class='line'>casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')
</span><span class='line'>
</span><span class='line'>casper.start('https://xueqiu.com/2054435398/32283614', function () {
</span><span class='line'>    this.waitForSelector("div.status-content a[title*=xueqiu]");
</span><span class='line'>}).then(function () {
</span><span class='line'>    // white background
</span><span class='line'>    this.evaluate(function () {
</span><span class='line'>        var style = document.createElement('style'),
</span><span class='line'>            text = document.createTextNode('body { background: #fff }');
</span><span class='line'>        style.setAttribute('type', 'text/css');
</span><span class='line'>        style.appendChild(text);
</span><span class='line'>        document.head.insertBefore(style, document.head.firstChild);
</span><span class='line'>    });
</span><span class='line'>}).then(function () {
</span><span class='line'>    this.capture('结庐问山.jpg');
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run()
</span><span class='line'>
</span><span class='line'>&gt; casperjs capture.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk</span></code></pre></td></tr></table></div></figure>


<p>用来截全屏的图片相当厉害，Chrome等自带的截图工具如果内容长了后很慢很麻烦，这种方式毫无压力啊。</p>

<ul>
<li>抓取层次页面</li>
</ul>


<p>一般抓数据有个列表页，然后根据列表页的详情地址，根据详情地址再获取数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; cat xueqiu.js
</span><span class='line'>debugger
</span><span class='line'>
</span><span class='line'>var fs = require('fs');
</span><span class='line'>var casper = require('casper').create({
</span><span class='line'>    waitTimeout: 120000,
</span><span class='line'>    logLevel: "debug",
</span><span class='line'>    verbose: true
</span><span class='line'>});
</span><span class='line'>casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')
</span><span class='line'>
</span><span class='line'>var links = []
</span><span class='line'>var basedir = '.'
</span><span class='line'>casper.start('https://xueqiu.com/2054435398/32283614', function () {
</span><span class='line'>    this.waitForSelector("div.status-content a[title*=xueqiu]");
</span><span class='line'>}).then(function () {
</span><span class='line'>    var items = this.evaluate(function () {
</span><span class='line'>        return $("div.status-content a[title*=xueqiu]").map(function (i, a) {
</span><span class='line'>            return $(a).attr('href')
</span><span class='line'>        })
</span><span class='line'>    })
</span><span class='line'>
</span><span class='line'>    for (var i = 0; i &lt; items.length; i++) {
</span><span class='line'>        links.push(items[i]);
</span><span class='line'>    }
</span><span class='line'>    
</span><span class='line'>    fs.write('all.html', this.getHTML(), 'w');
</span><span class='line'>}).then(function () {
</span><span class='line'>    this.eachThen(links, function (link) {
</span><span class='line'>        var pathname = undefined;
</span><span class='line'>        var url = link.data;
</span><span class='line'>
</span><span class='line'>        this.thenOpen(url, function () {
</span><span class='line'>            this.waitForSelector("div.status-content .detail");
</span><span class='line'>        }).then(function () {
</span><span class='line'>            pathname = this.evaluate(function () {
</span><span class='line'>                var style = document.createElement('style'),
</span><span class='line'>                    text = document.createTextNode('body { background: #fff }');
</span><span class='line'>                style.setAttribute('type', 'text/css');
</span><span class='line'>                style.appendChild(text);
</span><span class='line'>                document.head.insertBefore(style, document.head.firstChild);
</span><span class='line'>
</span><span class='line'>                return window.location.pathname;
</span><span class='line'>            });
</span><span class='line'>        }).then(function () {
</span><span class='line'>            if (url.indexOf(pathname))
</span><span class='line'>                this.capture(basedir + pathname + ".jpg");
</span><span class='line'>            else
</span><span class='line'>                this.echo(url);
</span><span class='line'>        });
</span><span class='line'>
</span><span class='line'>    })
</span><span class='line'>
</span><span class='line'>});
</span><span class='line'>
</span><span class='line'>casper.run()
</span><span class='line'>
</span><span class='line'>&gt; casperjs xueqiu.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk --remote-debugger-port=9000
</span></code></pre></td></tr></table></div></figure>


<p>然后一堆堆的图片就生成出来了。由于访问的速度有限，有利有弊，慢一点还不要做时间上面的控制了，有点像人在操作的感觉。然后处理下异常的个别再导一次就可以了(错误的那一篇还是404的&hellip;哭笑)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$("div.status-content a[title*=xueqiu]").map(function(i, a){ return $(a).attr('href') }).length
</span><span class='line'>177
</span><span class='line'>
</span><span class='line'>$ find . -name '*.jpg' | wc -l
</span><span class='line'>176</span></code></pre></td></tr></table></div></figure>


<p>注意：Windows的命令窗口，多按几次Enter，有时一不小心就进入编辑模式了。</p>

<p>压缩后100多M啊！CasperJS足够强大，更多的模式等待你的开启。就写到此。</p>

<h2>后记</h2>

<p>关于爬虫获取数据 <a href="http://webmagic.io/docs/zh/posts/chx-cases/js-render-page.html">抓取前端渲染的页面</a> 这篇文章讲的挺中肯的，如果可能的话，用作者写的 <a href="https://github.com/code4craft/webmagic/blob/master/README-zh.md">WebMagic</a> 也是一个不错的选择。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[导出微信照片]]></title>
    <link href="http://winseliu.com/blog/2017/06/04/wechat-images-export/"/>
    <updated>2017-06-04T14:53:51+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/04/wechat-images-export</id>
    <content type="html"><![CDATA[<p>开篇寄语：还是脚本厉害啊！</p>

<p>手机空间不够，又不能加卡，只能删删删。想着把手机上的照片拷贝出来啊，手机拍的，在DCIM目录下的还好，但是微信里面的照片我也想备份下来啊。怎么办？</p>

<p>手机上翻一张微信的照片，然后目录在： tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 ，连上电脑一看蒙圈了，这尼玛36(10+26)的平方啊，直接复制完全没反应，在系统上面通过查找*.jpg也不靠谱。还有尼玛的，不是挂在到系统盘的，没办法用脚本。</p>

<p>想着，要不用个助手试试，下载了PP和豌豆荚，导出带反应的都没有啊！你们这程序怎么做的啊！老牌子啊！！！</p>

<p>没办法咯，一个个复制想死的心都有了。最后实在没的办法，用adb shell来整把，然后就一个命令就搞定了（苦笑）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>shell@hydrogen:/sdcard/tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 $ which find
</span><span class='line'>/system/bin/find
</span><span class='line'>shell@hydrogen:/sdcard/tencent/MicroMsg/ea722ad09b762f27f86b29ac43bf6eb8/image2 $
</span><span class='line'>$ find . -name "*.*" -exec cp {} /sdcard/Download/ \; </span></code></pre></td></tr></table></div></figure>


<p>最后拷贝download文件夹就好了。</p>

<p>总共600M的样子。拷贝的时刻，又TMD没权限，在explorer窗口就看不到文件。好吧，再用命令拷贝一下吧：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\adt-bundle-windows-x86-20140702\platform-tools&gt;adb pull -a /sdcard/Download/ R:\image2\
</span><span class='line'>[ 14%] /sdcard/Download/9d01c6e9b722366970f33c948ca4435f.jpg: 76%</span></code></pre></td></tr></table></div></figure>


<p>好久没弄了，SDK还是14年的，不过还能用啊，赫赫。到此，备份微信图片的工作顺利完成，事情一桩一桩的了。</p>

<p>啥，最后你说还要删掉刚刚复制的图片啊，不能一个个的删啊，好吧，收下我&ndash;|的眼神：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\usr\share\adt-bundle-windows-x86-20140702\platform-tools&gt;adb shell
</span><span class='line'>shell@hydrogen:/ $ cd /sdcard/Download/
</span><span class='line'>shell@hydrogen:/sdcard/Download $ rm -rf *.jpg
</span><span class='line'>shell@hydrogen:/sdcard/Download $ rm -rf *.png</span></code></pre></td></tr></table></div></figure>


<p>拷贝完后，翻了一翻挺有回忆的。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jenkins Start Guide]]></title>
    <link href="http://winseliu.com/blog/2017/06/04/jenkins-start-guide/"/>
    <updated>2017-06-04T10:19:23+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/04/jenkins-start-guide</id>
    <content type="html"><![CDATA[<p>从原始的Eclipse右键导出打包，到后面使用maven打包，就单自己一个人使用开发部署是完全没问题的。现在的jenkins是对工具的封装、可视化和自动化，对于团队合作还是有一定的作用的，时时刻刻告诉我们代码是可运行的。</p>

<p>但是如果一个很久前的项目，又需要新加/修改功能，一下子还捡不起来，不放心啊还得验证一把。还有就是，测试有时刻他们自己打包，不会的还的教她们使用工具，人家烦自己也累。</p>

<p>jenkins是一个持续集成的工具，原来也接触过，但是都没用起来，都是搞开发，大部分时刻都能自己搞定。当下由于情况比较特殊，很多代码都直接在生产改，测试环境就不顾上了，但是测试环境不能总是旧代码啊，就想着有个自动化的东西来进行部署。</p>

<p>主要就是完成一个代码自动化部署的工作：自己搭建一个jenkins，从oschina上拉代码，编译后部署到tomcat并重启。</p>

<h2><a href="https://jenkins.io/download/">安装Jenkins</a></h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war
</span><span class='line'>nohup java -jar jenkins.war --httpPort=8081 &gt;/var/log/jenkins.log 2&gt;&1 & </span></code></pre></td></tr></table></div></figure>


<h2>建立到oschina的无密钥登录</h2>

<p>由于项目是私有的，通过https需要输入密码，还是git方式无密钥登录方式便捷一些。本地linux执行ssh-keygen，然后把 id_rsa.pub 的内容拷贝到项目的公钥处进行配置。可以参考文档： <a href="http://git.mydoc.io/?t=154712">http://git.mydoc.io/?t=154712</a>。</p>

<p>也可以结合 本地ssh-agent 和 ssh-forward 来弄。</p>

<h2>配置项目</h2>

<p>第一次登录需要进行一些配置，默认创建的admin密码会保存在 ~/.jenkins/secrets/initialAdminPassword 。（在初始化页面创建新用户报错，也不知道啥原因。登录后再建吧）</p>

<p>新版本的按照默认安装插件还不够，需要再添加一些。登录成功后，添加如下插件：</p>

<ul>
<li>Deploy to container Plugin  把war发布到容器tomcat&hellip;</li>
<li>Nexus Artifact Uploader  上传jar到私服</li>
<li><p>Maven Integration plugin 集成maven</p></li>
<li><p>ThinBackup 备份也是有必要的，用的越久越是必要！！</p></li>
</ul>


<p>配置maven：</p>

<p>自己下载个maven解压后，在jenkins - Global Tool Configuration上面配置maven地址即可（把 自动安装 的勾去掉就可以填地址了）</p>

<p>然后配置JOB：</p>

<ul>
<li>构建一个maven项目：填任务的名称，然后点击左下角的OK</li>
<li>源码管理git: 填写地址，然后新增Credentials - SSH Username with private key - From the Jenkins master ~/.ssh 起一个容易区分的名字</li>
<li>构建触发器： Build periodically - 0 0 * * * 每天一次</li>
<li>Build：web/pom.xml ; clean package -Papp,dist -DskipTests 就是mvn命令的一串参数</li>
<li>Post Steps: Run only if build succeeds - Execute Shell</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/apache-tomcat-8.0.26/bin/shutdown.sh ; sleep 1 
</span><span class='line'>rm -rf /opt/apache-tomcat-8.0.26/webapps/app.war 
</span><span class='line'>cp $WORKSPACE/web/app/target/app.war /opt/apache-tomcat-8.0.26/webapps 
</span><span class='line'>cd /opt/apache-tomcat-8.0.26/webapps ; ./deploy.sh 
</span><span class='line'>BUILD_ID=dontKillMe nohup /opt/apache-tomcat-8.0.26/bin/startup.sh & 
</span><span class='line'>sleep 3</span></code></pre></td></tr></table></div></figure>


<p>注意：这里的BUILD_ID挺有意思的！！！</p>

<p>也可以配置 <strong>构建后操作</strong> 把包发布到tomcat manager（呵呵，无奈原始包webapps下的都被我删了)，就用脚本弄了。</p>

<h2>构建</h2>

<p>完成上面的操作后，就可以执行跑一次看看效果了。其他的还有很多功能：权限等。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.cnblogs.com/gao241/archive/2013/03/20/2971416.html">Jenkins配置基于角色的项目权限管理</a></li>
<li><a href="http://www.cnblogs.com/zz0412/p/jenkins_jj_14.html">Jenkins进阶系列之——14配置Jenkins用户和权限</a></li>
<li><a href="https://wiki.jenkins-ci.org/display/JENKINS/Spawning+processes+from+build">https://wiki.jenkins-ci.org/display/JENKINS/Spawning+processes+from+build</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-jenkins/">https://www.ibm.com/developerworks/cn/java/j-lo-jenkins/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[追生产的一次优化]]></title>
    <link href="http://winseliu.com/blog/2017/06/01/optimize-java-on-production-environment/"/>
    <updated>2017-06-01T00:36:33+00:00</updated>
    <id>http://winseliu.com/blog/2017/06/01/optimize-java-on-production-environment</id>
    <content type="html"><![CDATA[<p>最近闲得慌啊，本来不是自己职能范围内的。但是看着一台机器每天负载50+的跑，不舒服，就想去折腾折腾把负载降下来。</p>

<p>进程图：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>top - 08:01:24 up 1203 days,  9:06,  4 users,  load average: 31.41, 32.97, 32.38
</span><span class='line'>Tasks: 569 total,  11 running, 558 sleeping,   0 stopped,   0 zombie
</span><span class='line'>Cpu(s): 20.1%us, 68.1%sy,  0.0%ni,  6.0%id,  0.1%wa,  0.0%hi,  5.7%si,  0.0%st
</span><span class='line'>Mem:  49420852k total, 31831356k used, 17589496k free,   358748k buffers
</span><span class='line'>Swap: 33791992k total,   519332k used, 33272660k free, 18614472k cached
</span><span class='line'>
</span><span class='line'>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                       
</span><span class='line'> 2340 omc       20   0 29.2g 8.5g  11m S 598.1 18.1   3436:40 java                                                                                                                         
</span><span class='line'>31349 omc       20   0 8071m 563m  11m S 348.4  1.2   1735:33 java                                                                                                                         
</span><span class='line'>28147 omc       20   0 15.5g 1.5g  14m S 341.9  3.2   1959:42 java                                                                                                                         
</span><span class='line'>   61 root      20   0     0    0    0 S 48.9  0.0  83728:05 ksoftirqd/14                                                                                                                  
</span><span class='line'>   73 root      20   0     0    0    0 S 48.2  0.0  82342:12 ksoftirqd/17                                                                                                                  
</span><span class='line'>    9 root      20   0     0    0    0 S 46.9  0.0  85312:03 ksoftirqd/1                                                                                                                   
</span><span class='line'>   13 root      20   0     0    0    0 S 46.6  0.0  84297:57 ksoftirqd/2                                                                                                                   
</span><span class='line'>   25 root      20   0     0    0    0 S 45.3  0.0  82811:49 ksoftirqd/5                                                                                                                   
</span><span class='line'>   89 root      20   0     0    0    0 S 45.3  0.0  84608:31 ksoftirqd/21                                                                                                                  
</span><span class='line'>   65 root      20   0     0    0    0 S 44.9  0.0  83475:48 ksoftirqd/15                                                                                                                  
</span><span class='line'>   17 root      20   0     0    0    0 R 44.6  0.0  83990:21 ksoftirqd/3                                                                                                                   
</span><span class='line'>   57 root      20   0     0    0    0 S 44.6  0.0  84625:38 ksoftirqd/13                                                                                                                  
</span><span class='line'>   33 root      20   0     0    0    0 R 44.0  0.0  80537:34 ksoftirqd/7                                                                                                                   
</span><span class='line'>    4 root      20   0     0    0    0 R 43.3  0.0  81489:54 ksoftirqd/0                                                                                                                   
</span><span class='line'>   41 root      20   0     0    0    0 R 42.0  0.0  82651:17 ksoftirqd/9                                                                                                                   
</span><span class='line'>   37 root      20   0     0    0    0 S 40.0  0.0  82636:26 ksoftirqd/8                                                                                                                   
</span><span class='line'>   85 root      20   0     0    0    0 S 39.7  0.0  84557:49 ksoftirqd/20                                                                                                                  
</span><span class='line'>   21 root      20   0     0    0    0 S 38.7  0.0  83271:24 ksoftirqd/4                                                                                                                   
</span><span class='line'>   53 root      20   0     0    0    0 R 36.1  0.0  82083:15 ksoftirqd/12                                                                                                                  
</span><span class='line'>   45 root      20   0     0    0    0 R 35.8  0.0  86230:39 ksoftirqd/10                                                                                                                  
</span><span class='line'>   93 root      20   0     0    0    0 R 35.4  0.0  86416:12 ksoftirqd/22                                                                                                                  
</span><span class='line'>   69 root      20   0     0    0    0 R 35.1  0.0  82726:46 ksoftirqd/16                                                                                                                  
</span><span class='line'>   29 root      20   0     0    0    0 S 34.8  0.0  78415:22 ksoftirqd/6                                                                                                                   
</span><span class='line'>   77 root      20   0     0    0    0 R 33.1  0.0  82419:34 ksoftirqd/18                                                                                                                  
</span><span class='line'>   81 root      20   0     0    0    0 S 30.2  0.0  80141:58 ksoftirqd/19                                                                                                                  
</span><span class='line'>   97 root      20   0     0    0    0 R 21.3  0.0  85993:03 ksoftirqd/23                                                                                                                  
</span><span class='line'>   49 root      20   0     0    0    0 S 21.0  0.0  86742:13 ksoftirqd/11                                                                                                                  
</span><span class='line'>28418 nobody    20   0  855m  32m 1144 S 20.7  0.1  72:23.66 gmetad</span></code></pre></td></tr></table></div></figure>


<p>线程图：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>top - 08:03:20 up 1203 days,  9:08,  4 users,  load average: 31.07, 32.36, 32.23
</span><span class='line'>Tasks: 940 total,  31 running, 909 sleeping,   0 stopped,   0 zombie
</span><span class='line'>Cpu(s): 20.0%us, 70.0%sy,  0.0%ni,  4.6%id,  0.0%wa,  0.0%hi,  5.4%si,  0.0%st
</span><span class='line'>Mem:  49420852k total, 31845576k used, 17575276k free,   358776k buffers
</span><span class='line'>Swap: 33791992k total,   519332k used, 33272660k free, 18615376k cached
</span><span class='line'>
</span><span class='line'>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                       
</span><span class='line'>28174 omc       20   0 15.5g 1.5g  14m R 59.9  3.2 307:28.86 java                                                                                                                          
</span><span class='line'>28203 omc       20   0 15.5g 1.5g  14m S 55.7  3.2 272:43.21 java                                                                                                                          
</span><span class='line'> 2416 omc       20   0 29.2g 8.5g  11m R 55.4 18.1 274:31.07 java                                                                                                                          
</span><span class='line'>31384 omc       20   0 8071m 563m  11m R 53.7  1.2 240:45.47 java                                                                                                                          
</span><span class='line'> 2409 omc       20   0 29.2g 8.5g  11m S 53.1 18.1 245:56.03 java                                                                                                                          
</span><span class='line'>28197 omc       20   0 15.5g 1.5g  14m S 52.4  3.2 279:04.35 java                                                                                                                          
</span><span class='line'> 2406 omc       20   0 29.2g 8.5g  11m R 51.8 18.1 249:00.25 java                                                                                                                          
</span><span class='line'>28208 omc       20   0 15.5g 1.5g  14m R 51.8  3.2 300:50.49 java                                                                                                                          
</span><span class='line'> 2412 omc       20   0 29.2g 8.5g  11m S 51.5 18.1 232:11.81 java                                                                                                                          
</span><span class='line'> 2415 omc       20   0 29.2g 8.5g  11m R 51.5 18.1 234:57.25 java                                                                                                                          
</span><span class='line'> 2391 omc       20   0 29.2g 8.5g  11m R 51.1 18.1 301:52.48 java                                                                                                                          
</span><span class='line'>28175 omc       20   0 15.5g 1.5g  14m R 51.1  3.2 299:18.11 java                                                                                                                          
</span><span class='line'>31383 omc       20   0 8071m 563m  11m R 50.8  1.2 242:23.43 java                                                                                                                          
</span><span class='line'>16662 omc       20   0 29.2g 8.5g  11m R 49.5 18.1   3:26.22 java                                                                                                                          
</span><span class='line'>31381 omc       20   0 8071m 563m  11m R 49.5  1.2 237:05.25 java                                                                                                                          
</span><span class='line'>   41 root      20   0     0    0    0 S 48.9  0.0  82652:00 ksoftirqd/9                                                                                                                   
</span><span class='line'>   17 root      20   0     0    0    0 S 47.9  0.0  83990:59 ksoftirqd/3                                                                                                                   
</span><span class='line'>   65 root      20   0     0    0    0 S 47.9  0.0  83476:26 ksoftirqd/15                                                                                                                  
</span><span class='line'> 2408 omc       20   0 29.2g 8.5g  11m R 47.9 18.1 249:43.27 java                                                                                                                          
</span><span class='line'>31382 omc       20   0 8071m 563m  11m R 47.9  1.2 237:07.76 java                                                                                                                          
</span><span class='line'>   49 root      20   0     0    0    0 S 47.3  0.0  86743:04 ksoftirqd/11                                                                                                                  
</span><span class='line'>   89 root      20   0     0    0    0 R 46.6  0.0  84609:14 ksoftirqd/21                                                                                                                  
</span><span class='line'>   81 root      20   0     0    0    0 S 46.3  0.0  80142:39 ksoftirqd/19                                                                                                                  
</span><span class='line'>   61 root      20   0     0    0    0 R 46.0  0.0  83728:50 ksoftirqd/14                                                                                                                  
</span><span class='line'>31376 omc       20   0 8071m 563m  11m R 45.3  1.2 306:00.66 java                                                                                                                          
</span><span class='line'>   33 root      20   0     0    0    0 R 45.0  0.0  80538:15 ksoftirqd/7                                                                                                                   
</span><span class='line'>31385 omc       20   0 8071m 563m  11m R 45.0  1.2 272:52.36 java                                                                                                                          
</span><span class='line'>   13 root      20   0     0    0    0 S 44.7  0.0  84298:42 ksoftirqd/2                                                                                                                   
</span><span class='line'>   73 root      20   0     0    0    0 S 43.7  0.0  82342:53 ksoftirqd/17                                                                                                                  
</span><span class='line'>   53 root      20   0     0    0    0 R 43.4  0.0  82083:54 ksoftirqd/12                                                                                                                  
</span><span class='line'>   97 root      20   0     0    0    0 S 43.4  0.0  85993:53 ksoftirqd/23                                                                                                                  
</span><span class='line'>   45 root      20   0     0    0    0 R 42.4  0.0  86231:24 ksoftirqd/10                                                                                                                  
</span><span class='line'>   77 root      20   0     0    0    0 S 42.1  0.0  82420:20 ksoftirqd/18                                                                                                                  
</span><span class='line'> 2407 omc       20   0 29.2g 8.5g  11m R 41.1 18.1 240:01.88 java                                                                                                                          
</span><span class='line'> 2410 omc       20   0 29.2g 8.5g  11m R 40.8 18.1 227:49.76 java                                                                                                                          
</span><span class='line'>   85 root      20   0     0    0    0 R 40.5  0.0  84558:37 ksoftirqd/20                                                                                                                  
</span><span class='line'>28196 omc       20   0 15.5g 1.5g  14m R 38.2  3.2 276:56.00 java                                                                                                                          
</span><span class='line'>   29 root      20   0     0    0    0 S 37.9  0.0  78416:08 ksoftirqd/6                                                                                                                   
</span><span class='line'>   37 root      20   0     0    0    0 S 37.9  0.0  82637:15 ksoftirqd/8                                                                                                                   
</span><span class='line'> 2411 omc       20   0 29.2g 8.5g  11m R 37.9 18.1 247:22.02 java                                                                                                                          
</span><span class='line'> 2360 omc       20   0 29.2g 8.5g  11m S 37.6 18.1 179:49.10 java                                                                                                                          
</span><span class='line'> 2413 omc       20   0 29.2g 8.5g  11m S 36.9 18.1 233:48.03 java                                                                                                                          
</span><span class='line'>   69 root      20   0     0    0    0 R 36.3  0.0  82727:24 ksoftirqd/16                                                                                                                  
</span><span class='line'>    4 root      20   0     0    0    0 R 35.6  0.0  81490:34 ksoftirqd/0                                                                                                                   
</span><span class='line'>31369 omc       20   0 8071m 563m  11m R 35.6  1.2 192:32.42 java                                                                                                                          
</span><span class='line'>   21 root      20   0     0    0    0 S 35.0  0.0  83272:02 ksoftirqd/4                                                                                                                   
</span><span class='line'>28167 omc       20   0 15.5g 1.5g  14m R 33.7  3.2 197:02.78 java                                                                                                                          
</span><span class='line'>   25 root      20   0     0    0    0 S 27.2  0.0  82812:29 ksoftirqd/5                                                                                                                   
</span><span class='line'>   93 root      20   0     0    0    0 R 25.9  0.0  86416:55 ksoftirqd/22</span></code></pre></td></tr></table></div></figure>


<p>按照网络上的文档，查cpu时间很长的、占用很高的线程，然后拿着ID转成16进程到jstack里面去对：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[omc@cu-omc1 ~]$ jstack 28147
</span><span class='line'>2017-06-01 08:07:13
</span><span class='line'>Full thread dump Java HotSpot(TM) 64-Bit Server VM (23.7-b01 mixed mode):
</span><span class='line'>...
</span><span class='line'>"Timer-0" daemon prio=10 tid=0x00007fbd84850000 nid=0x6e27 in Object.wait() [0x00007fbe31f98000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at java.util.TimerThread.mainLoop(Timer.java:552)
</span><span class='line'>        - locked &lt;0x0000000767760360&gt; (a java.util.TaskQueue)
</span><span class='line'>        at java.util.TimerThread.run(Timer.java:505)
</span><span class='line'>
</span><span class='line'>"schedulerFactory_QuartzSchedulerThread" prio=10 tid=0x00007fbd843f6000 nid=0x6e26 in Object.wait() [0x00007fbe32099000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at org.quartz.core.QuartzSchedulerThread.run(QuartzSchedulerThread.java:311)
</span><span class='line'>        - locked &lt;0x0000000767770098&gt; (a java.lang.Object)
</span><span class='line'>
</span><span class='line'>"schedulerFactory_Worker-2" prio=10 tid=0x00007fbd848cd000 nid=0x6e25 in Object.wait() [0x00007fbe3219a000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:568)
</span><span class='line'>        - locked &lt;0x00000007677ebb38&gt; (a java.lang.Object)
</span><span class='line'>
</span><span class='line'>"schedulerFactory_Worker-1" prio=10 tid=0x00007fbd848b3000 nid=0x6e24 in Object.wait() [0x00007fbe3229b000]
</span><span class='line'>   java.lang.Thread.State: TIMED_WAITING (on object monitor)
</span><span class='line'>        at java.lang.Object.wait(Native Method)
</span><span class='line'>        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:568)
</span><span class='line'>        - locked &lt;0x00000007677ec710&gt; (a java.lang.Object)
</span><span class='line'>...
</span><span class='line'>"GC task thread#17 (ParallelGC)" prio=10 tid=0x00007fbe64035000 nid=0x6e06 runnable 
</span><span class='line'>
</span><span class='line'>"VM Periodic Task Thread" prio=10 tid=0x00007fbe6411f800 nid=0x6e0e waiting on condition 
</span><span class='line'>
</span><span class='line'>JNI global references: 321
</span><span class='line'>
</span><span class='line'>[omc@cu-omc1 ~]$ echo "obase=16;28203" | bc
</span><span class='line'>6E2B
</span><span class='line'>[omc@cu-omc1 ~]$ cat | while read id ; do echo "obase=16;$id" | bc ; done &lt;&lt;EOF
</span><span class='line'>28174
</span><span class='line'>28203
</span><span class='line'>28197
</span><span class='line'>28208
</span><span class='line'>28175
</span><span class='line'>28196
</span><span class='line'>28167
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>6E0E
</span><span class='line'>6E2B
</span><span class='line'>6E25
</span><span class='line'>6E30
</span><span class='line'>6E0F
</span><span class='line'>6E24
</span><span class='line'>6E07
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://winseliu.com/images/blogs/linux-jdk7-jstack.png" alt="" /></p>

<p>基本都是sleep，wait的线程占用cpu很大。并且导致了系统cpu软中断处理进程ksoftirqd占用了大部分系统资源。系统不停的在处理上下文，负载奇高：</p>

<p><img src="http://winseliu.com/images/blogs/linux-jdk7-vmstat.png" alt="" /></p>

<p>ksoftirqd 不知道干嘛的，/proc/interrupts 看不懂，查了sleep和wait的区别，strace、iostat、jmap、jstack、jstat、vmstat、pidstat、还有看到内存补齐的一些文章，反正就是找不到北。</p>

<p>一开始以为是quartz的问题，对比了其他机器的quartz应用，有怀疑过版本问题（quartz-1.8.6, 2.2.0）；有试着去减少simplethreadpool的默认线程数（org.quartz.threadPool.threadCount），CPU占用是会少一点点，但是ksoftirqd还是压力很大，系统还是很大部分消耗在上下文切换，路子不对。</p>

<p>问题环境：</p>

<ul>
<li>Red Hat Enterprise Linux Server release 6.3 (Santiago)/2.6.32-279.el6.x86_64</li>
<li>Spring + quartz-2.2.&frac12;</li>
<li>jdk1.7.0_17</li>
</ul>


<p>完全没辙，不是功能代码的问题啊。搞到12点，困死了，回去睡个觉。今天一早起来，想想，不如换个 <strong>JDK8</strong> 试试吧（按照部署要求jdk放local目录下，要ROOT密码的昨晚就没动）。我勒个去，重启了感觉世界都变亮了。上下文切换cs 1w不到，us、sy基本忽略不计啊。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ vmstat -a 1
</span><span class='line'>procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
</span><span class='line'> r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st
</span><span class='line'> 0  0 517160 25052176 12486824 10402340    0    0     2    31    0    0  4  9 86  0  0
</span><span class='line'> 0  0 517160 25052732 12486972 10401996    0    0     0  4676 4548 4806  0  0 99  0  0
</span><span class='line'> 1  0 517160 25052468 12486972 10402356    0    0     0     0 4044 4419  0  0 99  0  0
</span><span class='line'> 0  1 517160 25053664 12486852 10401992    0    0     0  8100 7608 5311  0  0 95  4  0
</span><span class='line'> 0  1 517160 25054800 12486852 10402084    0    0     0  8228 7847 5408  1  1 95  4  0
</span><span class='line'> 0  1 517160 25054924 12486852 10402380    0    0     0  8200 8075 4929  0  0 95  4  0
</span><span class='line'> 1  1 517160 25054868 12486852 10402112    0    0     0  7484 7898 5754  1  1 94  4  0
</span><span class='line'> 2  1 517160 25055544 12486848 10402148    0    0     0  8224 7537 4428  0  0 95  4  0</span></code></pre></td></tr></table></div></figure>


<p>好吧，以后优化的第一步就是换JDK .__. 。就像优化数据库第一步就建索引 V.V 。应该是JDK8对object.wait调用linux系统调用进行了优化。</p>

<h2>有点意思</h2>

<ul>
<li><a href="http://coderplay.iteye.com/blog/1481211">从Java视角理解CPU上下文切换(Context Switch)</a></li>
<li><a href="http://coderplay.iteye.com/blog/1485760">从Java视角理解CPU缓存(CPU Cache)</a></li>
<li><a href="http://coderplay.iteye.com/blog/1486649">从Java视角理解伪共享(False Sharing)</a></li>
<li><a href="https://github.com/LMAX-Exchange/disruptor">disruptor</a></li>
<li><a href="http://www.cnblogs.com/zhiranok/archive/2012/08/13/context_switch_1.html">http://www.cnblogs.com/zhiranok/archive/2012/08/13/context_switch_1.html</a></li>
<li><a href="http://www.bijishequ.com/detail/60264?p=">http://www.bijishequ.com/detail/60264?p=</a></li>
<li><a href="http://9leg.com/java/2016/08/09/cpu-consumption-analysis.html">http://9leg.com/java/2016/08/09/cpu-consumption-analysis.html</a></li>
</ul>


<blockquote><p>us过高
当us值过高时，表示运行的应用消耗了大部分的cpu。在这种情况下，对于java应用而言，最重要的是找到具体消耗cpu的线程所执行的代码，可以采用如下方法。</p>

<p>首先通过linux命令top命令查看us过高的pid值</p>

<p>通过top -Hp pid查看该pid进程下的线程的cpu消耗状况，得到具体pid值</p>

<p>将pid值转化为16进制，这个转化后的值对应nid值的线程</p>

<p>通过jstack pid grep -C 20 “16进制的值” 命令查看运行程序的线程信息</p>

<p>该线程就是消耗cpu的线程，在采样时须多执行几次上述的过程，以确保找到真实的消耗cpu的线程。</p>

<p>java应用造成us过高的原因主要是线程一直处于可运行的状态Runnable，通常是这些线程在执行无阻塞、循环、正则或纯粹的计算等动作造成。 另外一个可能会造成us过高的原因是频繁的gc。如每次请求都需要分配较多内存，当访问量高时就导致不断的进行gc，系统响应速度下降， 进而造成堆积的请求更多，消耗的内存严重不足，最严重的时候会导致系统不断进行FullGC，对于频繁的gc需要通过分析jvm内存的消耗来查找原因。</p>

<p>sy过高
当sy值过高时，表示linux花费了更多的时间在进行线程切换。java应用造成这种现象的主要原因是启动的线程比较多， 且这些线程多处于不断的阻塞（例如锁等待，io等待）和执行状态的变化过程中，这就导致了操作系统要不断的切换执行的线程， 产生大量的上下文切换。在这种情况下，对java应用而言，最重要的是找出不断切换状态的原因， 可采用的方法为通过kill -3 pid 或jstack -l pid的方法dump出java应用程序的线程信息，查看线程的状态信息以及锁信息， 找出等待状态或锁竞争过多的线程。</p></blockquote>

<ul>
<li><a href="http://yaocoder.blog.51cto.com/2668309/1543352">http://yaocoder.blog.51cto.com/2668309/1543352</a></li>
</ul>


<p>strace -T -r -c -p pid
pstack pid
trace -p tid</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hive on Spark预测性执行BUG一枚]]></title>
    <link href="http://winseliu.com/blog/2017/05/23/spark-on-hive-speculation-shit-bug/"/>
    <updated>2017-05-23T12:11:49+00:00</updated>
    <id>http://winseliu.com/blog/2017/05/23/spark-on-hive-speculation-shit-bug</id>
    <content type="html"><![CDATA[<p>为了平复难以平复的痛苦，难以掩饰的激动，把这次遇到并解决的记录下。尽管最终解决的patch是官网的: <a href="https://issues.apache.org/jira/browse/HIVE-13066">Hive on Spark gives incorrect results when speculation is on</a>。</p>

<p>版本说明下：
* hive-1.2.1
* spark-1.3.1</p>

<p>在没有启动spark.speculation前，有个别任务执行非常慢，非常之讨厌。而启用预测性执行后，时不时任务会有些会失败，让人很烦躁。但是吧，也不算故障，说来也奇怪，重启下后再次查询问题就不出现了，也就没太在意。</p>

<p>今天数据量比较大，并且是上头检查。妈蛋，搞成了故障，没得办法，必须把原因找出来了。下来就帖日志了：</p>

<p>应用SQL查询报错日志：啥也看不到，就知道Hive查询报错，只能拿着时间去查Hive日志</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ERROR] 14:19:56.685 [RMI TCP Connection(7)-192.168.31.11] c.e.z.h.s.BaseHiveQueryService | Error while processing statement: FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask
</span><span class='line'>java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.spark.SparkTask
</span><span class='line'>        at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
</span><span class='line'>        at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:392)
</span><span class='line'>        at org.apache.hive.jdbc.HivePreparedStatement.executeQuery(HivePreparedStatement.java:109)
</span><span class='line'>        at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96)
</span><span class='line'>        at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96)
</span><span class='line'>        at com.eshore.zhfx.hbase.service.BaseHiveQueryService.listIteratorInternal(BaseHiveQueryService.java:101)
</span><span class='line'>        at com.eshore.zhfx.hbase.service.BaseHiveQueryService.listIterator(BaseHiveQueryService.java:80)
</span><span class='line'>        at com.eshore.zhfx.hbase.QueryService.getAccessLogIterator(QueryService.java:140)
</span><span class='line'>        at com.eshore.zhfx.hbase.QueryService$$FastClassByCGLIB$$a60bf6f7.invoke(&lt;generated&gt;)
</span><span class='line'>        at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191)
</span><span class='line'>        at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:688)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
</span><span class='line'>        at org.springframework.aop.framework.adapter.AfterReturningAdviceInterceptor.invoke(AfterReturningAdviceInterceptor.java:50)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:50)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:89)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:621)
</span><span class='line'>        at com.eshore.zhfx.hbase.QueryService$$EnhancerByCGLIB$$9a4ab584.getAccessLogIterator(&lt;generated&gt;)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
</span><span class='line'>        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span class='line'>        at java.lang.reflect.Method.invoke(Method.java:601)
</span><span class='line'>        at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:309)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)
</span><span class='line'>        at org.springframework.remoting.support.RemoteInvocationTraceInterceptor.invoke(RemoteInvocationTraceInterceptor.java:77)
</span><span class='line'>        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
</span><span class='line'>        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
</span><span class='line'>        at com.sun.proxy.$Proxy22.getAccessLogIterator(Unknown Source)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span class='line'>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</span></code></pre></td></tr></table></div></figure>


<p>HIVE服务日志：rename错了，但是也好像看不到啥。知道那个节点有问题了，去查节点日志</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2017-05-23 14:19:20,509 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) - 2017-05-23 14:19:20,508 WARN  [task-result-getter-1] scheduler.TaskSetManager: Lost task 2199.1 in stage 2.0 (TID 4517, hadoop-slaver41): java.lang.IllegalStateException: Hit error while closing operators - failing tree: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>2017-05-23 14:19:20,509 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:195)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:58)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:106)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at scala.collection.Iterator$class.foreach(Iterator.scala:727)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.scheduler.Task.run(Task.scala:64)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at java.lang.Thread.run(Thread.java:722)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) - Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.commit(FileSinkOperator.java:237)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.access$200(FileSinkOperator.java:143)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1051)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:616)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,510 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>2017-05-23 14:19:20,511 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:172)
</span><span class='line'>2017-05-23 14:19:20,511 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) -  ... 15 more
</span><span class='line'>2017-05-23 14:19:20,511 INFO  client.SparkClientImpl (SparkClientImpl.java:run(569)) - </span></code></pre></td></tr></table></div></figure>


<p>Task错误节点错误日志：这日志没啥。重名，拿名称去查namenode日志看看是啥子？</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: FS[24]: records written - 0
</span><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: Final Path: FS hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0
</span><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: Writing to temp file: FS hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0
</span><span class='line'>17/05/23 14:19:18 INFO exec.FileSinkOperator: New Final Path: FS hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>17/05/23 14:19:19 INFO compress.CodecPool: Got brand-new compressor [.snappy]
</span><span class='line'>org.apache.hadoop.hive.ql.metadata.HiveException: Unable to rename output from: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to: hdfs://zfcluster/hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.commit(FileSinkOperator.java:237)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.access$200(FileSinkOperator.java:143)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:1051)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:616)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.Operator.close(Operator.java:630)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.spark.SparkMapRecordHandler.close(SparkMapRecordHandler.java:172)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.spark.HiveMapFunctionResultList.closeRecordProcessor(HiveMapFunctionResultList.java:58)
</span><span class='line'>        at org.apache.hadoop.hive.ql.exec.spark.HiveBaseFunctionResultList$ResultIterator.hasNext(HiveBaseFunctionResultList.java:106)
</span><span class='line'>        at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:41)
</span><span class='line'>        at scala.collection.Iterator$class.foreach(Iterator.scala:727)
</span><span class='line'>        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
</span><span class='line'>        at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>        at org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$2.apply(AsyncRDDActions.scala:114)
</span><span class='line'>        at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>        at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1576)
</span><span class='line'>        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
</span><span class='line'>        at org.apache.spark.scheduler.Task.run(Task.scala:64)
</span><span class='line'>        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
</span><span class='line'>        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
</span><span class='line'>        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
</span><span class='line'>        at java.lang.Thread.run(Thread.java:722)</span></code></pre></td></tr></table></div></figure>


<p>Namenode日志：有点点线索了，分配了两次，导致了第二个任务写入的时刻报错！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ grep '_tmp.002199' hadoop/logs/hadoop-hadoop-namenode-hadoop-master2.log.1
</span><span class='line'>2017-05-23 14:19:01,591 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0. BP-1414312971-192.168.32.11-1392479369615 blk_1219124858_145508182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-ad2eac59-1e38-4019-a5ac-64c465366186:NORMAL:192.168.32.93:50010|RBW], ReplicaUnderConstruction[[DISK]DS-90c8cbe3-fd70-4ad7-938a-4248b4435df7:NORMAL:192.168.32.136:50010|RBW], ReplicaUnderConstruction[[DISK]DS-9da76df9-47f0-4e25-b375-e1bf32f4cf52:NORMAL:192.168.36.58:50010|RBW]]}
</span><span class='line'>2017-05-23 14:19:14,939 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 is closed by DFSClient_attempt_201705231411_0000_m_001585_0_1316598676_51
</span><span class='line'>2017-05-23 14:19:20,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0. BP-1414312971-192.168.32.11-1392479369615 blk_1219125517_145508841{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-4d4c90f0-1ddf-4800-b33a-e776e58dc744:NORMAL:192.168.32.61:50010|RBW], ReplicaUnderConstruction[[DISK]DS-948cd823-5a4c-4673-8ace-99f02a26522b:NORMAL:192.168.32.52:50010|RBW], ReplicaUnderConstruction[[DISK]DS-7818addb-3881-446e-abb3-2c178be6bb63:NORMAL:192.168.32.176:50010|RBW]]}
</span><span class='line'>2017-05-23 14:19:20,478 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 is closed by DFSClient_attempt_201705231411_0000_m_001345_1_1292482540_51
</span><span class='line'>2017-05-23 14:19:20,480 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_task_tmp.-ext-10001/_tmp.002199_0 to /hive/scratchdir/hadoop/64801461-94aa-4e17-afee-494e77b49998/hive_2017-05-23_14-18-38_278_4858034238266422677-2/-mr-10000/.hive-staging_hive_2017-05-23_14-18-38_278_4858034238266422677-2/_tmp.-ext-10001/002199_0.snappy because destination exists</span></code></pre></td></tr></table></div></figure>


<p>好了，看到这里，驴脑袋还没怀疑到是预测性执行导致的问题。当时想为啥会出现同一个文件名呢：SPARK ON HIVE多个stage执行导致的? 但是重启后报一样的错误，002199是哪里产生，怎么产生的？</p>

<p>MAP太多了000000又循环了一轮？看了执行的map数也就2600啊，不应该啊。</p>

<p>那么这个文件名是哪里产生的呢？然后就搞了下远程调试：没啥用，错误是在task上发生的，调试hive-driver没啥用，但是有意外收获</p>

<ul>
<li><a href="http://www.winseliu.com/blog/2014/06/21/upgrade-hive/">http://www.winseliu.com/blog/2014/06/21/upgrade-hive/</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started">https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hive]$ DEBUG=true bin/hive
</span><span class='line'>Listening for transport dt_socket at address: 8000
</span><span class='line'>
</span><span class='line'>Logging initialized using configuration in file:/home/hadoop/apache-hive-1.2.1-bin/conf/hive-log4j.properties
</span><span class='line'>hive&gt; set hive.execution.engine=spark; '查询之前需要设置下引擎，故障得先处理。搞成默认的mr跑是成功的
</span><span class='line'>hive&gt;                                  'SQLSQLSQL...执行刚报错的SQL
</span><span class='line'>Query ID = hadoop_20170523173748_7660d9fb-9683-4792-8315-a51f6dcc270b
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Spark Job = 48a8668b-1c59-4cbf-b1e2-e19612ee77d0
</span><span class='line'>
</span><span class='line'>Query Hive on Spark job[0] stages:
</span><span class='line'>0
</span><span class='line'>
</span><span class='line'>Status: Running (Hive on Spark job[0])
</span><span class='line'>Job Progress Format
</span><span class='line'>CurrentTime StageId_StageAttemptId: SucceededTasksCount(+RunningTasksCount-FailedTasksCount)/TotalTasksCount [StageCost]
</span><span class='line'>2017-05-23 17:38:15,730 Stage-0_0: 0/2609
</span><span class='line'>2017-05-23 17:38:16,739 Stage-0_0: 0(+159)/2609
</span><span class='line'>...
</span><span class='line'>2017-05-23 17:39:23,182 Stage-0_0: 2162(+447)/2609
</span><span class='line'>2017-05-23 17:39:24,188 Stage-0_0: 2167(+608)/2609
</span><span class='line'>2017-05-23 17:39:25,195 Stage-0_0: 2201(+836,-1)/2609
</span><span class='line'>2017-05-23 17:39:26,201 Stage-0_0: 2215(+832,-2)/2609
</span><span class='line'>2017-05-23 17:39:27,207 Stage-0_0: 2227(+820,-2)/2609
</span><span class='line'>2017-05-23 17:39:28,213 Stage-0_0: 2250(+797,-2)/2609
</span><span class='line'>2017-05-23 17:39:29,219 Stage-0_0: 2280(+767,-2)/2609
</span><span class='line'>2017-05-23 17:39:30,224 Stage-0_0: 2338(+709,-2)/2609
</span><span class='line'>2017-05-23 17:39:31,230 Stage-0_0: 2350(+696,-3)/2609
</span><span class='line'>2017-05-23 17:39:32,236 Stage-0_0: 2359(+684,-6)/2609
</span><span class='line'>2017-05-23 17:39:33,243 Stage-0_0: 2363(+676,-10)/2609
</span><span class='line'>2017-05-23 17:39:34,249 Stage-0_0: 2365(+673,-12)/2609
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>有报错了，赶紧去web页面看了下结果，好家伙，全部是Speculation的报错：</p>

<p><img src="http://winseliu.com/images/blogs/hive-on-spark-speculation.jpg" alt="" /></p>

<p>在结合前面的namenode的日志，基本就走到正道上面。然后 <strong> hive spark speculation </strong> 一股沟，没错第一条就是hive官网的bug啊。</p>

<ul>
<li><a href="https://issues.apache.org/jira/browse/HIVE-13066">https://issues.apache.org/jira/browse/HIVE-13066</a></li>
</ul>


<p>然后就是打patch修改HivePairFlatMapFunction，验证是OK的。至少原来出错的语句完美跑完。</p>

<h2>总结下</h2>

<p>就是前段集成攻城狮把网络回环的问题处理了，导致网络状态好的不要不要的啊！把那些有备用10M网卡全部停了，集群的机器的网络好了N倍。第二个就是数据量实在大，其实speculation有启动，但是最先完成的还是先启动的，又没有把预测执行kill掉并且还运行完了最终还保存到同名文件。最后让我又一次体验了一把找开源软件BUG激情四射的半天。</p>

<p>记录聊以慰藉！！</p>

<hr />

<p>other : SparkClientImpl LeaseExpiredException No lease on  File does not exist</p>

<ul>
<li><a href="https://stackoverflow.com/questions/26842933/leaseexpiredexception-no-lease-error-on-hdfs-failed-to-close-file">LeaseExpiredException: No lease error on HDFS (Failed to close file)</a></li>
<li><a href="https://stackoverflow.com/questions/7559880/leaseexpiredexception-no-lease-error-on-hdfs">LeaseExpiredException: No lease error on HDFS</a></li>
<li><a href="http://www.jianshu.com/p/f5ec6c7bb176">http://www.jianshu.com/p/f5ec6c7bb176</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet批量自动化部署实战]]></title>
    <link href="http://winseliu.com/blog/2017/05/05/puppet-automate-deploy-hosts/"/>
    <updated>2017-05-05T00:33:37+00:00</updated>
    <id>http://winseliu.com/blog/2017/05/05/puppet-automate-deploy-hosts</id>
    <content type="html"><![CDATA[<p>断断续续使用Puppet近一年，多次体验到Puppet的强大：SSH更新、需ROOT权限批量处理等等。这次集群新上架了又爽了一把。把整个过程记录下来，方便今后参考。</p>

<p>运维的同事也想了解puppet，在docker容器上安装了一遍，把具体的内容附上：<a href="http://winseliu.com/files/expect+puppet.txt">expect+puppet.txt</a></p>

<p>这次操作是对以前零零碎碎积累的一次检验和温习。需要用到的工具比较多：</p>

<ul>
<li>RPM打包、本地YUM仓库 - RPMBUILD、CREATEREPO</li>
<li>SSH无密钥登录 - EXPECT&amp;FOR</li>
<li>时间同步、host配置 - SCP、SSH&amp;FOR</li>
<li>创建用户、新用户无密钥等 - PUPPET</li>
<li>ssh_known_hosts - PUPPETDB</li>
<li>rhel.repo、gmond、时区设置 - PUPPET</li>
</ul>


<p>远程配置机器首先当然是进行无密钥登录的设置，这样才能进行批量操作，不然几百台机器每次都需要干预太烦人、工作量太大。无密钥登录使用原来写好的EXPECT脚本，使用FOR循环执行，等待结果即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 ~]# cat ssh-copy-id.expect 
</span><span class='line'>#!/usr/bin/expect  
</span><span class='line'>
</span><span class='line'>## Usage $0 [user@]host password
</span><span class='line'>
</span><span class='line'>set host [lrange $argv 0 0];
</span><span class='line'>set password [lrange $argv 1 1] ;
</span><span class='line'>
</span><span class='line'>set timeout 30;
</span><span class='line'>
</span><span class='line'>spawn ssh-copy-id $host ;
</span><span class='line'>
</span><span class='line'>expect {
</span><span class='line'>  "(yes/no)?" { send yes\n; exp_continue; }
</span><span class='line'>  "password:" { send $password\n; exp_continue; }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>exec sleep 1;
</span><span class='line'>
</span><span class='line'># 用for，不要用while
</span><span class='line'>for h in `cat /etc/hosts | grep -v '^#' | grep slaver | grep -E '\.36\.|\.37\.' | awk '{print $2}' ` ; do 
</span><span class='line'>  ./ssh-copy-id.expect $h 'PASSWD';
</span><span class='line'>done
</span></code></pre></td></tr></table></div></figure>


<p>做好无密钥登录，拷贝 /etc/hosts, /etc/cron.daily/ntp.cron, /etc/yum.repos.d/puppet.repo 到全部的新机器。这里puppet.repo是自己编译搭建的私有仓库（具体编译配置步骤查看puppet分类下的文章），通过 <code>yum install mcollective-plugins-simple</code> 就可以把mcolletive和puppet-agent安装好。把所有步骤封装到一个prepare.sh脚本，内容如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'># must be hostname!!
</span><span class='line'>HOSTS="$@"
</span><span class='line'>PASSWD=${PASSWD:-'root'}
</span><span class='line'>PUPPETSERVER="hadoop-master1"
</span><span class='line'>
</span><span class='line'>for h in $HOSTS ; do ./ssh-copy-id.expect $h "$PASSWD" ; done
</span><span class='line'>
</span><span class='line'>for h in $HOSTS ; do
</span><span class='line'>scp /etc/hosts $h:/etc ;
</span><span class='line'>scp /etc/yum.repos.d/puppet.repo $h:/etc/yum.repos.d/ ;
</span><span class='line'>scp /etc/cron.daily/ntp.cron $h:/etc/cron.daily/ ;
</span><span class='line'>
</span><span class='line'>ssh $h '
</span><span class='line'>#ntpdate cu-omc1 #着重注意
</span><span class='line'>rm -rf /etc/yum.repos.d/CentOS-*
</span><span class='line'>yum install mcollective-plugins-simple -y
</span><span class='line'>' ;
</span><span class='line'>
</span><span class='line'>scp /etc/puppetlabs/mcollective/server.cfg $h:/etc/puppetlabs/mcollective/
</span><span class='line'>ssh $h "
</span><span class='line'>sed -i '/HOSTNAME/ {
</span><span class='line'>i \
</span><span class='line'>HOSTNAME=$h
</span><span class='line'>d
</span><span class='line'>} ' /etc/sysconfig/network
</span><span class='line'>hostname $h
</span><span class='line'>
</span><span class='line'>echo -e '\n\n[agent]\nserver = $PUPPETSERVER\ncertname=$h' &gt; /etc/puppetlabs/puppet/puppet.conf
</span><span class='line'>chkconfig mcollective on
</span><span class='line'>service mcollective start
</span><span class='line'>"
</span><span class='line'>
</span><span class='line'>done
</span></code></pre></td></tr></table></div></figure>


<p>然后执行 <code>./prepare.sh hadoop-slaver{200..500}</code> 就可以了。</p>

<p>接下来重点讲讲PUPPET配置的编写。</p>

<p>首先根据当前需要创建的用户、组把创建用户的配置写好：</p>

<ul>
<li><a href="https://docs.puppet.com/puppet/4.10/quick_start_user_group.html">https://docs.puppet.com/puppet/4.10/quick_start_user_group.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 ~]# puppet resource -e group hadoop
</span><span class='line'>group { 'hadoop':
</span><span class='line'>  ensure =&gt; 'present',
</span><span class='line'>  gid    =&gt; '501',
</span><span class='line'>}
</span><span class='line'>[root@hadoop-master1 ~]# puppet resource -e user hadoop
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  gid              =&gt; '501',
</span><span class='line'>  groups           =&gt; ['wheel'],
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; '$6$AfnA...uIhHC9I.',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  uid              =&gt; '501',
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>添加require、groups，然后删除uid、gid。最后需要添加 managehome => true, 否则用户目录就不会自动创建：</p>

<ul>
<li><a href="http://www.dbalex.com/category/devops/puppet">http://www.dbalex.com/category/devops/puppet</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 默认不创建用户目录
</span><span class='line'>[root@hadoop-slaver200 ~]# su - hadoop
</span><span class='line'>su: warning: cannot change directory to /home/hadoop: No such file or directory
</span><span class='line'>-bash-4.1$ 
</span><span class='line'>
</span><span class='line'># 创建用户配置成品
</span><span class='line'>group { 'hadoop':
</span><span class='line'>  ensure =&gt; 'present',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>user { 'hadoop':
</span><span class='line'>  ensure           =&gt; 'present',
</span><span class='line'>  groups           =&gt; ['hadoop', 'wheel'],
</span><span class='line'>  home             =&gt; '/home/hadoop',
</span><span class='line'>  password         =&gt; '$6$Af...IhHC9I.',
</span><span class='line'>  password_max_age =&gt; '99999',
</span><span class='line'>  password_min_age =&gt; '0',
</span><span class='line'>  shell            =&gt; '/bin/bash',
</span><span class='line'>  managehome       =&gt; true,
</span><span class='line'>  require          =&gt; Group['hadoop'],
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://ask.puppet.com/question/15753/how-can-i-chown-directories-recursivley/">https://ask.puppet.com/question/15753/how-can-i-chown-directories-recursivley/</a></li>
<li><a href="https://serverfault.com/questions/542947/issue-with-changing-permission-and-owner-recursively-on-files-with-puppet-and-va">https://serverfault.com/questions/542947/issue-with-changing-permission-and-owner-recursively-on-files-with-puppet-and-va</a></li>
<li><a href="https://serverfault.com/questions/416254/adding-an-existing-user-to-a-group-with-puppet">https://serverfault.com/questions/416254/adding-an-existing-user-to-a-group-with-puppet</a></li>
</ul>


<p>添加好用户后，就是把无密钥登录也让PUPPET来弄。其实就是把 id_rsa.pub 的内容写入都行机器的 authorized_keys ，PUPPET已经自带了这个类：ssh_authorized_key。把id_ras.pub的内容（中间的内容）赋值给 key 属性即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh_authorized_key {'root@hadoop-master1':
</span><span class='line'>  user =&gt; 'root',
</span><span class='line'>  type =&gt; 'ssh-rsa',
</span><span class='line'>  key =&gt; 'AAAAB3NzaC1y...O1Q==',
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>ssh_authorized_key {'hadoop@hadoop-master1':
</span><span class='line'>  user =&gt; 'hadoop',
</span><span class='line'>  type =&gt; 'ssh-rsa',
</span><span class='line'>  key =&gt; 'AAAAB3Nza...IZYPw==',
</span><span class='line'>  require  =&gt; User['hadoop'],
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>无密钥登录比较容易，没有涉及到收集节点信息。仅仅把公钥写入新机器还不够，还得把 known_hosts 也处理好，不然第一次连接新机器都需要输入一下yes。内容如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-slaver200 ~]$ ssh hadoop-slaver202
</span><span class='line'>The authenticity of host 'hadoop-slaver202 (192.168.36.59)' can't be established.
</span><span class='line'>RSA key fingerprint is fe:7e:26:c4:56:ea:f4:21:61:82:6d:9b:4a:72:93:a4.
</span><span class='line'>Are you sure you want to continue connecting (yes/no)? </span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_virtual.html">https://docs.puppet.com/puppet/4.4/lang_virtual.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_collectors.html">https://docs.puppet.com/puppet/4.4/lang_collectors.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_exported.html">https://docs.puppet.com/puppet/4.4/lang_exported.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.4/lang_resources_advanced.html#amending-attributes-with-a-collector">https://docs.puppet.com/puppet/4.4/lang_resources_advanced.html#amending-attributes-with-a-collector</a></li>
<li><a href="https://docs.puppet.com/puppet/latest/types/ssh_authorized_key.html">https://docs.puppet.com/puppet/latest/types/ssh_authorized_key.html</a></li>
<li><a href="https://www.puppetcookbook.com/posts/install-package.html">https://www.puppetcookbook.com/posts/install-package.html</a></li>
<li><a href="https://docs.puppet.com/puppet/4.10/lang_conditional.html">https://docs.puppet.com/puppet/4.10/lang_conditional.html</a></li>
</ul>


<p>正如上面官网介绍的，需要用到虚拟资源，自动把新机器指纹（fingerprint）写入到机器需要PUPPETDB的支持，安装配置又需要PGSQL的配合。需要耗费一番功夫，但是还是划得来的（具体安装步骤查看puppet分类下的文章）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if $hostname =~ /^hadoop-/ {
</span><span class='line'>
</span><span class='line'>  $host_aliases = [ $ipaddress, $hostname ]
</span><span class='line'>  
</span><span class='line'>  # Export hostkeys from all hosts.
</span><span class='line'>  @@sshkey { $::fqdn:
</span><span class='line'>    ensure =&gt; present,
</span><span class='line'>    host_aliases =&gt; $host_aliases,
</span><span class='line'>    type =&gt; 'ssh-rsa',
</span><span class='line'>    key =&gt; $sshrsakey,
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  if $hostname =~ /^hadoop-master/ {
</span><span class='line'>    # realize all exported
</span><span class='line'>    Sshkey &lt;&lt;| |&gt;&gt;
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>先在所有slaver机器运行一遍 puppet agent -t ，然后再在master节点把收集的指纹写入到 /etc/ssh/ssh_known_hosts 。</p>

<p>这里说个插曲：机器的hosts和hostname是通过 FOR&amp;SSH 命令来统一修改的，有些可能没有配置好导致机器的主机名有重复。通过执行配置known_hosts竟然帮我找出了hostname重复的机器，意外的收获。该问题的处理我是直接登录到PGSQL改了对应表的数据处理的。</p>

<p>到这里机器基本能用了。主机名、hosts、时间同步、hadoop用户以及master到该用户的无密钥登录都已经配置好了。</p>

<p>接下来把实战过程中安装gmond的步骤帖出来：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$$ cd /etc/puppetlabs/code/environments/production/manifests/
</span><span class='line'>
</span><span class='line'>$$ vi change_site.sh
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>## Usage:
</span><span class='line'>##  ./change_site.sh nrpe.site
</span><span class='line'>##
</span><span class='line'>
</span><span class='line'>[[ $# != 1 ]] && exit 1
</span><span class='line'>
</span><span class='line'>cd $(cd $(dirname $0); pwd)
</span><span class='line'>
</span><span class='line'>rm -rf site.pp
</span><span class='line'>ln -s $1 site.pp
</span><span class='line'>
</span><span class='line'>$$ vi pexec.sh
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>## Usage:
</span><span class='line'>##   ./pexec.sh /cu-ud/ sudo_revert.site 
</span><span class='line'>##
</span><span class='line'>
</span><span class='line'>case $# in
</span><span class='line'>1)
</span><span class='line'>  FUNC="$1"
</span><span class='line'>  HOST_PARAM=
</span><span class='line'>  ;;
</span><span class='line'>2)
</span><span class='line'>  FUNC="$2"
</span><span class='line'>  HOST_PARAM="-I $1"
</span><span class='line'>  ;;
</span><span class='line'>*)
</span><span class='line'>  while [ $# -gt 1 ] ; do 
</span><span class='line'>    HOST_PARAM="$HOST_PARAM -I $1"
</span><span class='line'>    shift
</span><span class='line'>  done
</span><span class='line'>  FUNC=$1
</span><span class='line'>  ;;
</span><span class='line'>esac
</span><span class='line'>
</span><span class='line'>cd $(cd $(dirname $0); pwd)
</span><span class='line'>
</span><span class='line'>./change_site.sh "$FUNC"
</span><span class='line'>
</span><span class='line'>if [[ "$HOST_PARAM" != "" && ! "$HOST_PARAM" =~ */* ]] ; then
</span><span class='line'>  mco shell $HOST_PARAM run -- `which puppet` agent -t
</span><span class='line'>else
</span><span class='line'>  mco puppet $HOST_PARAM runall 20
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<p>由于机器增加比较多，且网络环境变的复杂化。把原来的2个分组修改成4个。不同的网络段和功能分别设置不同的广播端口。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ./pexec.sh /hadoop-slaver.$/ gmond.site 
</span><span class='line'>
</span><span class='line'># 采集数据的节点重启后，其他发送数据的节点貌似都需要重启。
</span><span class='line'>$ screen
</span><span class='line'>$ for ((i=1;i&lt;=53;i++)); do  mco shell -I /hadoop-slaver${i}.$/ run -- ' service gmond restart ' ; done 
</span><span class='line'># 这个确认搞的很麻烦，
</span><span class='line'># 想通过ganglia-web获取数据然后判断是否有数据进行重启。</span></code></pre></td></tr></table></div></figure>


<p>Ganglia删除某节点后，如果要从rrds上去掉改节点的信息，需要：重启对应收集的gmond，对应集群的rrds目录，然后重启gmetad。或者等够一段时间，gmetad会自动去掉。</p>

<h2>总结</h2>

<p>现在添加机器，直接连上puppetserver机器然后执行几个命令就可以搞定；</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>HOST=new-host-name 
</span><span class='line'># 无密钥登录和puppet/mco
</span><span class='line'>PASSWD=new-host-root-password ./prepare.sh $HOST
</span><span class='line'>
</span><span class='line'>./pexec.sh $HOST new-hadoop.site
</span><span class='line'>./pexec.sh $HOST gmond.site # 当前需要到web界面确认新节点的数据是否被采集</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s Hadoop Deploy]]></title>
    <link href="http://winseliu.com/blog/2017/04/14/k8s-hadoop-deploy/"/>
    <updated>2017-04-14T02:56:39+00:00</updated>
    <id>http://winseliu.com/blog/2017/04/14/k8s-hadoop-deploy</id>
    <content type="html"><![CDATA[<p>折磨了一个多星期，最后还是调通了。折磨源于不自知，源于孤单，源于自负，后来通过扩展、查阅资料、请教同事顺利解决。简单部署可以查看<a href="https://github.com/winse/docker-hadoop">README.md</a> 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6 -y
</span><span class='line'>
</span><span class='line'>cd kube-deploy
</span><span class='line'>vi hosts
</span><span class='line'>vi k8s.profile
</span><span class='line'># 把deploy同步到其他实体机，同时把k8s.profile映射到/etc/profile.d
</span><span class='line'>./rsync-deploy.sh
</span><span class='line'>
</span><span class='line'>cd docker-multinode/
</span><span class='line'>./master.sh or ./worker.sh
</span><span class='line'>
</span><span class='line'>docker save gcr.io/google_containers/etcd-amd64:3.0.4 | docker-bs load
</span><span class='line'>docker save quay.io/coreos/flannel:v0.6.1-amd64 | docker-bs load
</span><span class='line'>
</span><span class='line'>cd kube-deploy/hadoop/kubenetes/
</span><span class='line'>./prepare.sh
</span><span class='line'>kubectl create -f hadoop-master2.yaml
</span><span class='line'>kubectl create -f hadoop-slaver.yaml </span></code></pre></td></tr></table></div></figure>


<p>Tip：其实使用一套配置就可以启动多个集群，在 <code>kubectl create</code> 后面加上 <code>-n namespace</code> 即可。</p>

<p>比如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubenetes]# kubectl create namespace hd1
</span><span class='line'>[root@cu2 kubenetes]# kubectl create namespace hd2
</span><span class='line'>
</span><span class='line'>[root@cu2 kubenetes]# ./prepare.sh hd1
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-master2.yaml -n hd1
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-slaver.yaml -n hd1
</span><span class='line'>[root@cu2 kubenetes]# ./prepare.sh hd2
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-master2.yaml -n hd2
</span><span class='line'>[root@cu2 kubenetes]# kubectl create -f hadoop-slaver.yaml -n hd2
</span><span class='line'>
</span><span class='line'>[root@cu2 kubenetes]# kubectl get pods --all-namespaces
</span><span class='line'>NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE
</span><span class='line'>hd1           hadoop-master2                          1/1       Running   0          28s
</span><span class='line'>hd1           slaver-rc-fdcsw                         1/1       Running   0          18s
</span><span class='line'>hd1           slaver-rc-qv964                         1/1       Running   0          18s
</span><span class='line'>hd2           hadoop-master2                          1/1       Running   0          26s
</span><span class='line'>hd2           slaver-rc-0vdfk                         1/1       Running   0          17s
</span><span class='line'>hd2           slaver-rc-r7g84                         1/1       Running   0          17s
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>现在想来其实就是 <strong> dockerd &ndash;ip-masq=false </strong>的问题（所有涉及的dockerd都需要加）。 还有就是一台机器单机下的容器互相访问，源IP都错也是安装了openvpn所导致，对所有过eth0的都加了MASQUERADE。</p>

<p>根源就在于请求的源地址被替换，也就是iptables的转发进行了SNAT。关于iptables转发这篇文章讲的非常清晰；<a href="http://fancyxinyu.blog.163.com/blog/static/18232136620136185434661/">IPtables之四：NAT原理和配置  </a> 。</p>

<h2>所遇到的问题</h2>

<p>没加ip-masq之前，namenode收到datanode的请求后，源地址是flannel.0的ip: 10.1.98.0。</p>

<p>namenode对应的日志为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2017-04-09 07:22:06,920 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.1.98.0, datanodeUuid=5086c549-f3bb-4ef6-8f56-05b1f7adb7d3, infoPort=50075, ipcPort=50020, storageInfo=lv=-56;cid=CID-522174fa-6e7b-4c3f-ae99-23c3018e35d7;nsid=1613705851;c=0) storage 5086c549-f3bb-4ef6-8f56-05b1f7adb7d3
</span><span class='line'>2017-04-09 07:22:06,920 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.1.98.0:50010
</span><span class='line'>2017-04-09 07:22:06,921 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.1.98.0:50010</span></code></pre></td></tr></table></div></figure>


<p>一开始以为是flannel的问题，换成yum安装，然后同时flannel把backend切换成vxlan后，还是一样的问题。</p>

<p>最后请教搞网络的同事，应该是请求的源地址被替换了，也就定位到iptables。然后通过查看文档，其实前面也有看到过对应的文章，但是看不明白不知道缘由。</p>

<ul>
<li><a href="https://groups.google.com/d/msg/kubernetes-users/P4uh7y383oo/bPzIRaxhs5gJ">Networking Problem in creating HDFS cluster. - Eugene Yakubovich </a></li>
<li><a href="https://groups.google.com/d/msg/kubernetes-users/P4uh7y383oo/a1GIV4hcAgAJ">Networking Problem in creating HDFS cluster. - Huihui He </a></li>
<li><a href="https://developer.ibm.com/recipes/tutorials/networking-your-docker-containers-using-docker0-bridge/">Networking your docker containers using docker0 bridge</a></li>
</ul>


<p>iptables的部分相关信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# iptables -S -t nat
</span><span class='line'>...
</span><span class='line'>-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
</span><span class='line'>-A PREROUTING -j PREROUTING_direct
</span><span class='line'>-A PREROUTING -j PREROUTING_ZONES_SOURCE
</span><span class='line'>-A PREROUTING -j PREROUTING_ZONES
</span><span class='line'>-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
</span><span class='line'>-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
</span><span class='line'>-A OUTPUT -j OUTPUT_direct
</span><span class='line'>-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
</span><span class='line'>-A POSTROUTING -s 10.1.34.0/24 ! -o docker0 -j MASQUERADE
</span><span class='line'>-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
</span><span class='line'>-A POSTROUTING -j POSTROUTING_direct
</span><span class='line'>-A POSTROUTING -j POSTROUTING_ZONES_SOURCE
</span><span class='line'>-A POSTROUTING -j POSTROUTING_ZONES
</span><span class='line'>-A KUBE-MARK-DROP -j MARK --set-xmark 0x8000/0x8000
</span><span class='line'>-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
</span><span class='line'>-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -m mark --mark 0x4000/0x4000 -j MASQUERADE
</span><span class='line'>-A KUBE-SEP-75CPIAPDB4MAVFWI -s 10.1.40.3/32 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-75CPIAPDB4MAVFWI -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp" -m tcp -j DNAT --to-destination 10.1.40.3:53
</span><span class='line'>-A KUBE-SEP-IWNPEB4T46P6VG5J -s 192.168.0.148/32 -m comment --comment "default/kubernetes:https" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-IWNPEB4T46P6VG5J -p tcp -m comment --comment "default/kubernetes:https" -m recent --set --name KUBE-SEP-IWNPEB4T46P6VG5J --mask 255.255.255.255 --rsource -m tcp -j DNAT --to-destination 192.168.0.148:6443
</span><span class='line'>-A KUBE-SEP-UYUINV25NDNSKNUW -s 10.1.40.3/32 -m comment --comment "kube-system/kube-dns:dns" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-UYUINV25NDNSKNUW -p udp -m comment --comment "kube-system/kube-dns:dns" -m udp -j DNAT --to-destination 10.1.40.3:53
</span><span class='line'>-A KUBE-SEP-XDHL2OHX2ICPQHKI -s 10.1.40.2/32 -m comment --comment "kube-system/kubernetes-dashboard:" -j KUBE-MARK-MASQ
</span><span class='line'>-A KUBE-SEP-XDHL2OHX2ICPQHKI -p tcp -m comment --comment "kube-system/kubernetes-dashboard:" -m tcp -j DNAT --to-destination 10.1.40.2:9090
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.1/32 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-SVC-NPX46M4PTMTKRN6Y
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.95/32 -p tcp -m comment --comment "kube-system/kubernetes-dashboard: cluster IP" -m tcp --dport 80 -j KUBE-SVC-XGLOHA7QRQ3V22RZ
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.10/32 -p udp -m comment --comment "kube-system/kube-dns:dns cluster IP" -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU
</span><span class='line'>-A KUBE-SERVICES -d 10.0.0.10/32 -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp cluster IP" -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4
</span><span class='line'>-A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
</span><span class='line'>-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment "kube-system/kube-dns:dns-tcp" -j KUBE-SEP-75CPIAPDB4MAVFWI
</span><span class='line'>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -m recent --rcheck --seconds 10800 --reap --name KUBE-SEP-IWNPEB4T46P6VG5J --mask 255.255.255.255 --rsource -j KUBE-SEP-IWNPEB4T46P6VG5J
</span><span class='line'>-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https" -j KUBE-SEP-IWNPEB4T46P6VG5J
</span><span class='line'>-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment "kube-system/kube-dns:dns" -j KUBE-SEP-UYUINV25NDNSKNUW
</span><span class='line'>-A KUBE-SVC-XGLOHA7QRQ3V22RZ -m comment --comment "kube-system/kubernetes-dashboard:" -j KUBE-SEP-XDHL2OHX2ICPQHKI</span></code></pre></td></tr></table></div></figure>


<p>在dockerd服务脚本加上 <code>--ip-masq=false</code> 后，<code>-A POSTROUTING -s 10.1.34.0/24 ! -o docker0 -j MASQUERADE</code> 这一句就没有了，也就是不会进行源地址重写了，这样请求发送到namenode后还是datanode容器的IP。问题解决，原因简单的让人欲哭无泪啊。</p>

<p>写yaml遇到的一些其他问题：</p>

<ul>
<li><a href="http://andykdocs.de/development/Docker/Fixing+the+Docker+TERM+variable+issue">Fixing the Docker TERM variable issue</a></li>
<li><a href="http://stackoverflow.com/questions/27195466/hdfs-datanode-denied-communication-with-namenode-because-hostname-cannot-be-reso">hdfs Datanode denied communication with namenode because hostname cannot be resolved</a></li>
</ul>


<p>当然还有很多其他的问题，这篇就写这么多，优化工作后面的弄好了再写。</p>

<h2>中间过程步骤记录</h2>

<p>主要就是记录心路历程，如果以后遇到同样的问题能让自己快速回想起来。如果仅仅为了部署，可以跳过该部分，直接后最后的常用命令。</p>

<p>记录下中间 <strong>通过yum安装etcd和flanneld</strong> 的过程。物理机安装flanneld会把配置docker环境变量（/run/flannel/subnet.env）加入启动脚本。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>安装docker-v1.12
</span><span class='line'>https://docs.docker.com/v1.12/
</span><span class='line'>https://docs.docker.com/v1.12/engine/installation/linux/centos/
</span><span class='line'>
</span><span class='line'># 删掉原来的
</span><span class='line'>yum-config-manager --disable docker-ce*
</span><span class='line'>yum remove -y docker-ce*
</span><span class='line'>
</span><span class='line'>sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'
</span><span class='line'>[dockerrepo]
</span><span class='line'>name=Docker Repository
</span><span class='line'>baseurl=https://yum.dockerproject.org/repo/main/centos/7/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=https://yum.dockerproject.org/gpg
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>https://yum.dockerproject.org/repo/main/centos/7/Packages/
</span><span class='line'>[root@cu3 ~]# yum --showduplicates list docker-engine | expand
</span><span class='line'>docker-engine.x86_64             1.12.6-1.el7.centos                  dockerrepo
</span><span class='line'>
</span><span class='line'>[root@cu3 yum.repos.d]# yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/
</span><span class='line'>
</span><span class='line'>cat &gt; /etc/yum.repos.d/virt7-docker-common-release.repo &lt;&lt;EOF
</span><span class='line'>[virt7-docker-common-release]
</span><span class='line'>name=virt7-docker-common-release
</span><span class='line'>baseurl=http://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/
</span><span class='line'>gpgcheck=0
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>yum -y install --enablerepo=virt7-docker-common-release etcd flannel
</span><span class='line'>yum -y install --enablerepo=virt7-docker-common-release flannel
</span><span class='line'>
</span><span class='line'>- ETCD配置
</span><span class='line'>[root@cu3 docker-multinode]# 
</span><span class='line'>etcdctl mkdir /kube-centos/network
</span><span class='line'>etcdctl set /kube-centos/network/config "{ \"Network\": \"10.1.0.0/16\", \"SubnetLen\": 24, \"Backend\": { \"Type\": \"vxlan\" } }"
</span><span class='line'>
</span><span class='line'>- FlANNEL
</span><span class='line'>[root@cu3 ~]# cat /etc/sysconfig/flanneld
</span><span class='line'># Flanneld configuration options  
</span><span class='line'>
</span><span class='line'># etcd url location.  Point this to the server where etcd runs
</span><span class='line'>FLANNEL_ETCD_ENDPOINTS="http://cu3:2379"
</span><span class='line'>
</span><span class='line'># etcd config key.  This is the configuration key that flannel queries
</span><span class='line'># For address range assignment
</span><span class='line'>FLANNEL_ETCD_PREFIX="/kube-centos/network"
</span><span class='line'>
</span><span class='line'># Any additional options that you want to pass
</span><span class='line'>#FLANNEL_OPTIONS=""
</span><span class='line'>
</span><span class='line'>[root@cu2 yum.repos.d]# systemctl daemon-reload
</span><span class='line'>
</span><span class='line'>[root@cu2 yum.repos.d]# cat /run/flannel/subnet.env
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# systemctl cat docker
</span><span class='line'>...
</span><span class='line'># /usr/lib/systemd/system/docker.service.d/flannel.conf
</span><span class='line'>[Service]
</span><span class='line'>EnvironmentFile=-/run/flannel/docker </span></code></pre></td></tr></table></div></figure>


<p>测试过程中有yaml配置中启动sshd，然后启动容器后，通过手动启动namenode、datanode的方式来测试：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd hadoop-2.6.5
</span><span class='line'>gosu hadoop mkdir /data/bigdata
</span><span class='line'>gosu hadoop sbin/hadoop-daemon.sh start datanode 
</span><span class='line'>
</span><span class='line'>cd hadoop-2.6.5/
</span><span class='line'>gosu hadoop  bin/hadoop namenode -format 
</span><span class='line'>gosu hadoop sbin/hadoop-daemon.sh start namenode</span></code></pre></td></tr></table></div></figure>


<p>后来发现问题出在iptables后，又回到原来的docker-bootstrap启动，需要删除flannel.1的网络：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum安装flanneld后停止 https://kubernetes.io/docs/getting-started-guides/scratch/
</span><span class='line'>ip link set flannel.1 down
</span><span class='line'>ip link delete flannel.1
</span><span class='line'>route -n
</span><span class='line'>
</span><span class='line'>rm /usr/lib/systemd/system/docker.service.d/flannel.conf </span></code></pre></td></tr></table></div></figure>


<p>开了防火墙的话，把容器的端加入到信任列表：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>systemctl enable firewalld && systemctl start firewalld
</span><span class='line'>
</span><span class='line'>firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent 
</span><span class='line'>firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent 
</span><span class='line'>firewall-cmd --reload</span></code></pre></td></tr></table></div></figure>


<h2>一些有趣的命令</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>查看用了哪些镜像
</span><span class='line'>
</span><span class='line'>[root@cu2 /]# kubectl get pods --all-namespaces -o jsonpath="{..image}" |\
</span><span class='line'> tr -s '[[:space:]]' '\n' |\
</span><span class='line'> sort |\
</span><span class='line'> uniq -c
</span><span class='line'>      2 gcr.io/google_containers/dnsmasq-metrics-amd64:1.0
</span><span class='line'>      2 gcr.io/google_containers/exechealthz-amd64:1.2
</span><span class='line'>     12 gcr.io/google_containers/hyperkube-amd64:v1.5.5
</span><span class='line'>      2 gcr.io/google_containers/kube-addon-manager-amd64:v6.1
</span><span class='line'>      2 gcr.io/google_containers/kubedns-amd64:1.9
</span><span class='line'>      2 gcr.io/google_containers/kube-dnsmasq-amd64:1.4
</span><span class='line'>      2 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.0
</span><span class='line'>    
</span><span class='line'>      
</span><span class='line'>修改默认kubectl的配置
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# vi $KUBECONFIG 
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Config
</span><span class='line'>preferences: {}
</span><span class='line'>current-context: default
</span><span class='line'>clusters:
</span><span class='line'>- cluster:
</span><span class='line'>    server: http://localhost:8080
</span><span class='line'>  name: default
</span><span class='line'>contexts:
</span><span class='line'>- context:
</span><span class='line'>    cluster: default
</span><span class='line'>    user: ""
</span><span class='line'>    namespace: kube-system
</span><span class='line'>  name: default
</span><span class='line'>users: {}
</span><span class='line'>
</span><span class='line'>如果kubectl没有下载，可以从镜像启动的容器里面获取
</span><span class='line'>
</span><span class='line'>[root@cu2 docker-multinode]# docker exec -ti 0c0360bcc2c3 bash
</span><span class='line'>root@cu2:/# cp kubectl /var/run/
</span><span class='line'>
</span><span class='line'>[root@cu2 run]# mv kubectl /data/kubernetes/kube-deploy/docker-multinode/
</span><span class='line'>
</span><span class='line'>获取容器IP
</span><span class='line'>
</span><span class='line'>https://kubernetes.io/docs/user-guide/jsonpath/
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o wide -l run=redis -o jsonpath={..podIP}
</span><span class='line'>10.1.75.2 10.1.75.3 10.1.58.3 10.1.58.2 10.1.33.3
</span><span class='line'>
</span><span class='line'>网络共用: --net
</span><span class='line'>
</span><span class='line'>docker run -ti --entrypoint=sh --net=container:8e9f21956469f4ef7e5b9d91798788ab83f380795d2825cdacae0ed28f5ba03b gcr.io/google_containers/skydns-amd64:1.0
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>格式化输出
</span><span class='line'>
</span><span class='line'>kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}"  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# export POD_COL="custom-columns=NAME:.metadata.name,RESTARTS:.status.containerStatuses[*].restartCount,CONTAINERS:.spec.containers[*].name,IP:.status.podIP,HOST:.spec.nodeName"
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o $POD_COL 
</span><span class='line'>
</span><span class='line'>kubectl get po -l k8s-app=kube-dns -o=custom-columns=NAME:.metadata.name,CONTAINERS:.spec.containers[*].name
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# kubectl get po --all-namespaces -o=custom-columns=NAME:.metadata.name,CONTAINERS:.spec.containers[*].name
</span><span class='line'>
</span><span class='line'>kubectl get po --all-namespaces {range .items[*]}{.metadata.name}{“\t”}{end}
</span><span class='line'>
</span><span class='line'>备份
</span><span class='line'>
</span><span class='line'>echo "$(docker ps  | grep -v IMAGE | awk '{print $2}' )
</span><span class='line'>$(docker-bs ps | grep -v IMAGE | awk '{print $2}' )" | sort -u | while read image ; do docker save $image&gt;$(echo $image | tr '[/:]' _).tar ; done
</span><span class='line'>
</span><span class='line'>加Label
</span><span class='line'>
</span><span class='line'>cat /etc/hosts | grep -E "\scu[0-9]\s" | awk '{print "kubectl label nodes "$1" hostname="$2}' | while read line ; do sh -c "$line" ; done
</span><span class='line'>
</span><span class='line'>扩容
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# kubectl run redis --image=redis:3.2.8 
</span><span class='line'>[root@cu2 kubernetes]# kubectl scale --replicas=9 deployment/redis
</span><span class='line'>
</span><span class='line'> echo " $( kubectl describe pods hadoop-master2 | grep -E "Node|Container ID" | awk -F/ '{print $NF}' | tr '\n' ' ' | awk '{print "ssh "$1" \rdocker exec -ti "$2" bash"}' ) "
</span><span class='line'> </span></code></pre></td></tr></table></div></figure>


<p>测试DNS是否成功：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# vi busybox.yaml
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  namespace: default
</span><span class='line'>spec:
</span><span class='line'>  containers:
</span><span class='line'>  - image: busybox
</span><span class='line'>    command:
</span><span class='line'>      - sleep
</span><span class='line'>      - "3600"
</span><span class='line'>    imagePullPolicy: IfNotPresent
</span><span class='line'>    name: busybox
</span><span class='line'>  restartPolicy: Always
</span><span class='line'>
</span><span class='line'>[root@cu3 kube-deploy]# kubectl create -f busybox.yaml 
</span><span class='line'>pod "busybox" created
</span><span class='line'>[root@cu3 kube-deploy]# kubectl get pods 
</span><span class='line'>NAME      READY     STATUS              RESTARTS   AGE
</span><span class='line'>busybox   0/1       ContainerCreating   0          11s
</span><span class='line'>[root@cu3 kube-deploy]# kubectl get pods 
</span><span class='line'>NAME      READY     STATUS    RESTARTS   AGE
</span><span class='line'>busybox   1/1       Running   0          1m
</span><span class='line'>[root@cu3 kube-deploy]# kubectl exec -ti busybox -- nslookup kubernetes.default
</span><span class='line'>Server:    10.0.0.10
</span><span class='line'>Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local
</span><span class='line'>
</span><span class='line'>Name:      kubernetes.default
</span><span class='line'>Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local
</span><span class='line'>
</span><span class='line'>用容器的MYSQL的做客户端
</span><span class='line'>
</span><span class='line'>kubectl run -it --rm --image=mysql:5.6 mysql-client -- mysql -h mysql -ppassword
</span></code></pre></td></tr></table></div></figure>


<p>小结一点：日志的重要性！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubenetes]# docker ps -a | grep kubelet
</span><span class='line'>[root@cu2 kubenetes]# docker logs --tail=200 7432da457558
</span><span class='line'>
</span><span class='line'>E0417 11:39:40.194844   22528 configmap.go:174] Couldn't get configMap hadoop/dta-hadoop-config: configmaps "dta-hadoop-config" not found
</span><span class='line'>E0417 11:39:40.194910   22528 configmap.go:174] Couldn't get configMap hadoop/dta-bin-config: configmaps "dta-bin-config" not found
</span></code></pre></td></tr></table></div></figure>


<p>监控heapster的一些错误，还没调好</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# kubectl exec -ti heapster-564189836-shn2q -n kube-system -- sh
</span><span class='line'>/ # 
</span><span class='line'>/ # 
</span><span class='line'>没pod的数据
</span><span class='line'>/ # /heapster --source=https://kubernetes.default --sink=log --heapster-port=8083 -v 10
</span><span class='line'>
</span><span class='line'>E0329 10:11:53.823641       1 reflector.go:203] k8s.io/heapster/metrics/processors/node_autoscaling_enricher.go:100: Failed to list *api.Node: Get https://kubernetes.default/api/v1/nodes?resourceVersion=0: dial tcp 10.0.0.1:443: i/o timeout
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>$heapster/metrics
</span><span class='line'>$heapster/api/v1/model/debug/allkeys
</span></code></pre></td></tr></table></div></figure>


<p>其他一些配置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>other_args=" --registry-mirror=https://docker.mirrors.ustc.edu.cn "
</span><span class='line'>
</span><span class='line'>--insecure-registry gcr.io 
</span><span class='line'>
</span><span class='line'>iptables -S -t nat
</span></code></pre></td></tr></table></div></figure>


<h2>其他一些资源</h2>

<ul>
<li><a href="https://kubernetes.io/docs/concepts/cluster-administration/resource-usage-monitoring/">https://kubernetes.io/docs/concepts/cluster-administration/resource-usage-monitoring/</a></li>
<li><p><a href="https://github.com/kubernetes/heapster/tree/v1.3.0/deploy/kube-config/influxdb">https://github.com/kubernetes/heapster/tree/v1.3.0/deploy/kube-config/influxdb</a></p></li>
<li><p><a href="https://github.com/kubernetes/heapster/blob/master/docs/debugging.md">https://github.com/kubernetes/heapster/blob/master/docs/debugging.md</a></p></li>
<li><p><a href="https://docs.docker.com/v1.12/engine/installation/linux/centos/">https://docs.docker.com/v1.12/engine/installation/linux/centos/</a></p></li>
<li><p><a href="https://github.com/CodisLabs/codis/blob/release3.2/Dockerfile">https://github.com/CodisLabs/codis/blob/release3.2/Dockerfile</a></p></li>
<li><a href="https://github.com/sporkmonger/redis-k8s/blob/master/redis.yaml">https://github.com/sporkmonger/redis-k8s/blob/master/redis.yaml</a></li>
<li><a href="https://github.com/sobotklp/kubernetes-redis-cluster/blob/master/redis-cluster.yml">https://github.com/sobotklp/kubernetes-redis-cluster/blob/master/redis-cluster.yml</a></li>
</ul>


<p>statefulset</p>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/run-stateful-application/">https://kubernetes.io/docs/tutorials/stateful-application/run-stateful-application/</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateful-application/run-replicated-stateful-application/">https://kubernetes.io/docs/tutorials/stateful-application/run-replicated-stateful-application/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s Harbor Config]]></title>
    <link href="http://winseliu.com/blog/2017/03/30/k8s-harbor-config/"/>
    <updated>2017-03-30T06:21:50+00:00</updated>
    <id>http://winseliu.com/blog/2017/03/30/k8s-harbor-config</id>
    <content type="html"><![CDATA[<p>为了对比，还是想写写在centos7上面<a href="https://github.com/vmware/harbor/tree/master/make/kubernetes">安装Harbor</a>：太简单了，想想当初在6上面安装那酸爽($.$)。。。</p>

<h2>环境说明</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# yum install -y redhat-lsb
</span><span class='line'>[root@cu2 kube-deploy]# lsb_release -a
</span><span class='line'>LSB Version:    :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch
</span><span class='line'>Distributor ID: CentOS
</span><span class='line'>Description:    CentOS Linux release 7.3.1611 (Core) 
</span><span class='line'>Release:        7.3.1611
</span><span class='line'>Codename:       Core
</span><span class='line'>
</span><span class='line'>[root@cu2 kube-deploy]# docker version
</span><span class='line'>Client:
</span><span class='line'> Version:      1.12.6
</span><span class='line'> API version:  1.24
</span><span class='line'> Go version:   go1.6.4
</span><span class='line'> Git commit:   78d1802
</span><span class='line'> Built:        Tue Jan 10 20:20:01 2017
</span><span class='line'> OS/Arch:      linux/amd64
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Version:      1.12.6
</span><span class='line'> API version:  1.24
</span><span class='line'> Go version:   go1.6.4
</span><span class='line'> Git commit:   78d1802
</span><span class='line'> Built:        Tue Jan 10 20:20:01 2017
</span><span class='line'> OS/Arch:      linux/amd64
</span></code></pre></td></tr></table></div></figure>


<h2>使用docker-multinode搭建的环境</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# kubectl version
</span><span class='line'>Client Version: version.Info{Major:"1", Minor:"5", GitVersion:"v1.5.6", GitCommit:"114f8911f9597be669a747ab72787e0bd74c9359", GitTreeState:"clean", BuildDate:"2017-03-28T13:36:31Z", GoVersion:"go1.7.4", Compiler:"gc", Platform:"linux/amd64"}
</span><span class='line'>Server Version: version.Info{Major:"1", Minor:"5", GitVersion:"v1.5.6", GitCommit:"114f8911f9597be669a747ab72787e0bd74c9359", GitTreeState:"clean", BuildDate:"2017-03-28T13:36:31Z", GoVersion:"go1.7.4", Compiler:"gc", Platform:"linux/amd64"}</span></code></pre></td></tr></table></div></figure>


<h2>安装配置</h2>

<ul>
<li>证书准备</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /data/kubernetes/
</span><span class='line'>[root@cu2 kubernetes]# cd kube-deploy/
</span><span class='line'>[root@cu2 kube-deploy]# cat easy-rsa.sh 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'># cd /data/kubernetes
</span><span class='line'>cd ..
</span><span class='line'>
</span><span class='line'>git clone https://github.com/OpenVPN/easy-rsa.git
</span><span class='line'>cd easy-rsa/easyrsa3
</span><span class='line'>
</span><span class='line'>echo "# ======  CA  ======= #"
</span><span class='line'>./easyrsa init-pki
</span><span class='line'>./easyrsa build-ca #记住输入的密码，下面颁发证书还会用到
</span><span class='line'>
</span><span class='line'>echo "# ======  CERT  ======= #"
</span><span class='line'>./easyrsa gen-req cu nopass
</span><span class='line'>./easyrsa sign-req server cu #commonName填将要用到的域名咯</span></code></pre></td></tr></table></div></figure>


<ul>
<li>下载离线镜像</li>
</ul>


<p><a href="http://pan.baidu.com/s/1c1Rtnag">harbor-offline-installer-0.5.0.tgz</a>，加载harbor.0.5.0.tgz里面的镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 harbor-make]# docker images 
</span><span class='line'>REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE
</span><span class='line'>vmware/harbor-jobservice                              0.5.0               1700fbe602a0        3 months ago        148.4 MB
</span><span class='line'>vmware/harbor-ui                                      0.5.0               6db5718f2012        3 months ago        209.6 MB
</span><span class='line'>vmware/harbor-db                                      0.5.0               c401344852c6        3 months ago        326.8 MB
</span><span class='line'>nginx                                                 1.11.5              cc16e49f1304        4 months ago        181.4 MB
</span><span class='line'>registry                                              2.5.0               44a8766d1758        8 months ago        33.28 MB
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>修改配置和yaml配置的镜像名称</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 harbor-make]# vi harbor.cfg
</span><span class='line'>
</span><span class='line'>hostname = cu.eshore.cn
</span><span class='line'>ui_url_protocol = https
</span><span class='line'>ssl_cert = /data/kubernetes/easy-rsa/easyrsa3/pki/issued/cu.crt
</span><span class='line'>ssl_cert_key = /data/kubernetes/easy-rsa/easyrsa3/pki/private/cu.key 
</span><span class='line'>
</span><span class='line'>[root@cu2 harbor-make]# find kubernetes/ -name "*.rc.yaml" 
</span><span class='line'>kubernetes/nginx/nginx.rc.yaml
</span><span class='line'>kubernetes/mysql/mysql.rc.yaml
</span><span class='line'>kubernetes/registry/registry.rc.yaml
</span><span class='line'>kubernetes/ui/ui.rc.yaml
</span><span class='line'>kubernetes/jobservice/jobservice.rc.yaml</span></code></pre></td></tr></table></div></figure>


<ul>
<li>启动</li>
</ul>


<p>k8s启动的配置用github上最新的，不要用release下面的！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 harbor-make]# cd kubernetes/
</span><span class='line'>[root@cu2 kubernetes]# python prepare 
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# cat kube.sh 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>OP=${1:-"apply"}
</span><span class='line'>
</span><span class='line'>kubectl $OP -f pv/
</span><span class='line'>
</span><span class='line'>kubectl $OP -f jobservice/jobservice.cm.yaml
</span><span class='line'>kubectl $OP -f mysql/mysql.cm.yaml
</span><span class='line'>kubectl $OP -f nginx/nginx.cm.yaml
</span><span class='line'>kubectl $OP -f registry/registry.cm.yaml
</span><span class='line'>kubectl $OP -f ui/ui.cm.yaml
</span><span class='line'>
</span><span class='line'>kubectl $OP -f jobservice/jobservice.svc.yaml
</span><span class='line'>kubectl $OP -f mysql/mysql.svc.yaml
</span><span class='line'>kubectl $OP -f nginx/nginx.svc.yaml
</span><span class='line'>kubectl $OP -f registry/registry.svc.yaml
</span><span class='line'>kubectl $OP -f ui/ui.svc.yaml
</span><span class='line'>
</span><span class='line'>kubectl $OP -f registry/registry.rc.yaml 
</span><span class='line'>kubectl $OP -f mysql/mysql.rc.yaml 
</span><span class='line'>kubectl $OP -f jobservice/jobservice.rc.yaml 
</span><span class='line'>kubectl $OP -f ui/ui.rc.yaml 
</span><span class='line'>kubectl $OP -f nginx/nginx.rc.yaml
</span></code></pre></td></tr></table></div></figure>


<p>客户端CA</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kube-deploy]# cat rsync-deploy.sh 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>SERVICES="$@"
</span><span class='line'>HOSTS=$(echo cu{1..5} )
</span><span class='line'>
</span><span class='line'>#########
</span><span class='line'># Harbor
</span><span class='line'>if echo "$SERVICES" | grep harbor &gt;/dev/null ; then 
</span><span class='line'>
</span><span class='line'>  sed -i '/cu.eshore.cn/d' /etc/hosts
</span><span class='line'>
</span><span class='line'>  cat &gt;&gt;/etc/hosts &lt;&lt;EOF
</span><span class='line'>$( kubectl get service nginx -n default -o jsonpath="{..clusterIP}" ) cu.eshore.cn
</span><span class='line'>EOF
</span><span class='line'>  echo "Updated Local Hosts"
</span><span class='line'>
</span><span class='line'>  for h in $HOSTS ; do
</span><span class='line'>    if [[ $h != "$(hostname)" ]] ; then
</span><span class='line'>      rsync -az /etc/hosts $h:/etc/
</span><span class='line'>    fi
</span><span class='line'>
</span><span class='line'>    ssh $h "mkdir -p /etc/docker/certs.d/cu.eshore.cn/"
</span><span class='line'>    rsync -az /data/kubernetes/easy-rsa/easyrsa3/pki/ca.crt $h:/etc/docker/certs.d/cu.eshore.cn/
</span><span class='line'>
</span><span class='line'>    ssh $h "docker login -u admin -p Harbor12345 cu.eshore.cn"
</span><span class='line'>  done
</span><span class='line'>  echo "Harbor Rsync Succeeded"
</span><span class='line'>
</span><span class='line'>fi 
</span></code></pre></td></tr></table></div></figure>


<p>搞定，上传下载一个镜像试试：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu1 dev]# docker build -t cu.eshore.cn/library/codis:3.2 codis/
</span><span class='line'>[root@cu1 dev]# docker push cu.eshore.cn/library/codis:3.2
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker pull cu.eshore.cn/library/codis:3.2
</span><span class='line'>3.2: Pulling from library/codis
</span><span class='line'>386a066cd84a: Already exists 
</span><span class='line'>a3ed95caeb02: Pull complete 
</span><span class='line'>b1d31257c103: Pull complete 
</span><span class='line'>0e627f083b66: Pull complete 
</span><span class='line'>83912002f3f9: Pull complete 
</span><span class='line'>fc5e0ef7d361: Pull complete 
</span><span class='line'>47fe51a74a06: Pull complete 
</span><span class='line'>08dacccac43c: Pull complete 
</span><span class='line'>ec5a5e8fd71b: Pull complete 
</span><span class='line'>83f9da97d228: Pull complete 
</span><span class='line'>d4735c06cafa: Pull complete 
</span><span class='line'>3a4dc262a84d: Pull complete 
</span><span class='line'>bcf78ab0a1a9: Pull complete 
</span><span class='line'>7ac5a6fd0bf8: Pull complete 
</span><span class='line'>Digest: sha256:1c9280840222d736b7419b7e896b6286709d08e53890ae9e3d18062d61a9ad58
</span><span class='line'>Status: Downloaded newer image for cu.eshore.cn/library/codis:3.2
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# docker pull cu.eshore.cn/library/codis:3.2
</span><span class='line'>...
</span><span class='line'>layers from manifest don't match image configuration 暂时不清楚啥问题，临时解决。。。囧
</span><span class='line'>[root@cu2 data]# docker save cu.eshore.cn/library/codis:3.2 | ssh cu3 docker load</span></code></pre></td></tr></table></div></figure>


<h2>小结</h2>

<p>高版本的docker和k8s对环境变量和config volumes都支持，配置相对就很简单。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Codis使用进阶]]></title>
    <link href="http://winseliu.com/blog/2017/03/23/codis-usage2/"/>
    <updated>2017-03-23T09:48:55+00:00</updated>
    <id>http://winseliu.com/blog/2017/03/23/codis-usage2</id>
    <content type="html"><![CDATA[<p>去年年中的时刻有安装过codis。当时因为任务紧就使用jedis的ShardedJedisPool功能粗略的解决，由于是自己手动路由和管理，维护起来太难，特别是当初设置的实例数不够用时，相当麻烦。</p>

<p>年初项目各种测试，于是有些闲暇的时间，重新弄一弄redis cluster。算是搭建一个环境来测试：</p>

<p>版本：</p>

<ul>
<li>codis-3.2</li>
<li>centos6</li>
</ul>


<h2>测试环境编译安装</h2>

<p>现在的版本已经有了全部的依赖，直接编译即可。（centos6和官网提供的编译版本不兼容）</p>

<ul>
<li><a href="https://github.com/CodisLabs/codis/blob/release3.2/doc/tutorial_zh.md#0-%E4%B8%8B%E8%BD%BD%E4%B8%8E%E7%BC%96%E8%AF%91">官网文档</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar zxvf go1.6.2.linux-amd64.tar.gz 
</span><span class='line'>
</span><span class='line'>/etc/profile
</span><span class='line'>export GOROOT=/opt/go
</span><span class='line'>export GOPATH=/opt/gopath
</span><span class='line'>export PATH=$GOPATH/bin:$GOROOT/bin:$PATH
</span><span class='line'>
</span><span class='line'>-
</span><span class='line'>
</span><span class='line'>[root@cu2 CodisLabs]# pwd
</span><span class='line'>/opt/go/src/github.com/CodisLabs
</span><span class='line'>
</span><span class='line'># @2017-06-05
</span><span class='line'># 如果下载的是tar.gz，直接在CodisLabs目录下解压，然后做个软链接
</span><span class='line'># cd $GOPATH ; mkdir -p src/github.com/CodisLabs/
</span><span class='line'># cd src/github.com/CodisLabs/; ln -s codis-3.2-rc2 codis
</span><span class='line'>[root@cu2 CodisLabs]# git clone --branch release3.2  https://github.com/CodisLabs/codis.git 
</span><span class='line'>
</span><span class='line'>[root@cu2 CodisLabs]# cd codis/
</span><span class='line'>
</span><span class='line'># 安装一些依赖
</span><span class='line'># # ./autogen.sh: line 5: autoconf: command not found
</span><span class='line'># yum install autoconf 
</span><span class='line'>[root@cu2 codis]# make 
</span><span class='line'>
</span><span class='line'>[root@cu2 codis]# ll bin/
</span><span class='line'>total 101292
</span><span class='line'>drwxr-xr-x 4 root root     4096 Mar 15 12:58 assets
</span><span class='line'>-rwxr-xr-x 1 root root 21036930 Mar 15 12:58 codis-admin
</span><span class='line'>-rwxr-xr-x 1 root root 22343059 Mar 15 12:58 codis-dashboard
</span><span class='line'>-rwxr-xr-x 1 root root 18378506 Mar 15 12:58 codis-fe
</span><span class='line'>-rwxr-xr-x 1 root root 22675153 Mar 15 12:58 codis-proxy
</span><span class='line'>-rwxr-xr-x 1 root root  7982967 Mar 15 12:58 codis-server
</span><span class='line'>-rwxr-xr-x 1 root root  5580431 Mar 15 12:58 redis-benchmark
</span><span class='line'>-rwxr-xr-x 1 root root  5712419 Mar 15 12:58 redis-cli
</span><span class='line'>-rw-r--r-- 1 root root      170 Mar 15 12:58 version
</span><span class='line'>[root@cu2 codis]# cat bin/version 
</span><span class='line'>version = 2017-03-15 00:40:41 +0800 @be9ee25c63a64396b5fb0076447be560497b909d @3.2-beta-10-gbe9ee25
</span><span class='line'>compile = 2017-03-15 12:58:23 +0800 by go version go1.6.2 linux/amd64
</span><span class='line'>
</span><span class='line'># 生成默认配置
</span><span class='line'>[root@cu2 codis]# bin/codis-dashboard --default-config | tee dashboard.toml
</span><span class='line'>[root@cu2 codis]# bin/codis-proxy --default-config | tee proxy.toml
</span></code></pre></td></tr></table></div></figure>


<h2>生产部署</h2>

<p>把测试环境的GOPATH和GOROOT全部拷贝到生产即可。这里上面已经生成了dashboard和proxy的配置了哦！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ud@cu-ud6 opt]$ ll
</span><span class='line'>drwxrwxr-x.  2 ud   ud   4096 3月  18 00:10 bin
</span><span class='line'>drwxr-xr-x. 11 ud   ud   4096 4月  20 2016 go
</span><span class='line'>drwxr-xr-x.  4 ud   ud   4096 3月  15 12:58 gopath
</span><span class='line'>drwxr-xr-x.  8 ud   ud   4096 3月  17 20:13 jdk1.8.0_92
</span><span class='line'>drwxr-xr-x. 10 ud   ud   4096 2月  20 2014 zookeeper-3.4.6
</span><span class='line'>
</span><span class='line'>[ud@cu-ud6 opt]$ ll bin
</span><span class='line'>总用量 24
</span><span class='line'>-rw-rw-r--. 1 ud ud 234 3月  17 20:36 codis.profile
</span><span class='line'>lrwxrwxrwx. 1 ud ud  54 3月  17 20:34 redis-cli -&gt; ../gopath/src/github.com/CodisLabs/codis/bin/redis-cli
</span><span class='line'>-rwxrwxr-x. 1 ud ud 487 3月  17 20:54 start-codis-dashboard.sh
</span><span class='line'>-rwxrwxr-x. 1 ud ud 310 3月  18 00:10 start-codis-proxy.sh
</span><span class='line'>-rwxrwxr-x. 1 ud ud 335 3月  17 21:17 start-redis.sh
</span><span class='line'>-rwxrwxr-x. 1 ud ud 323 3月  17 20:55 start-zoo.sh
</span><span class='line'>
</span><span class='line'>[ud@cu-ud6 opt]$ for f in $( find bin -type f ) ; do echo " =============== $f ================= "; cat "$f" ; done
</span><span class='line'> =============== bin/codis.profile ================= 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>export GOROOT=/opt/go
</span><span class='line'>export GOPATH=/opt/gopath
</span><span class='line'>export CODIS_HOME=$GOPATH/src/github.com/CodisLabs/codis/
</span><span class='line'>export LOG_DIR=/var/log
</span><span class='line'>
</span><span class='line'>export JAVA_HOME=/opt/jdk1.8.0_92
</span><span class='line'>
</span><span class='line'>export PATH=$JAVA_HOME/bin:$GOPATH/bin:$GOROOT/bin:$PATH
</span><span class='line'>
</span><span class='line'> =============== bin/start-zoo.sh ================= 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>CODIS_BIN="${BASH_SOURCE-$0}"
</span><span class='line'>CODIS_BIN="$(dirname "${CODIS_BIN}")"
</span><span class='line'>CODIS_BINDIR="$(cd "${CODIS_BIN}"; pwd)"
</span><span class='line'>
</span><span class='line'>source $CODIS_BINDIR/codis.profile
</span><span class='line'>
</span><span class='line'>export ZOO_LOG_DIR=$LOG_DIR
</span><span class='line'>
</span><span class='line'>cd /opt/zookeeper-3.4.6
</span><span class='line'>sed 's@dataDir=/tmp/zookeeper@dataDir=/data/zookeeper@' conf/zoo_sample.cfg &gt;conf/zoo.cfg
</span><span class='line'>
</span><span class='line'>bin/zkServer.sh start
</span><span class='line'>
</span><span class='line'> =============== bin/start-codis-dashboard.sh ================= 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>CODIS_BIN="${BASH_SOURCE-$0}"
</span><span class='line'>CODIS_BIN="$(dirname "${CODIS_BIN}")"
</span><span class='line'>CODIS_BINDIR="$(cd "${CODIS_BIN}"; pwd)"
</span><span class='line'>
</span><span class='line'>source $CODIS_BINDIR/codis.profile
</span><span class='line'>
</span><span class='line'>cd $CODIS_HOME
</span><span class='line'>nohup bin/codis-dashboard \
</span><span class='line'>  --ncpu=4 \
</span><span class='line'>  --config=dashboard.toml \
</span><span class='line'>  --log=$LOG_DIR/codis_dashboard.log \
</span><span class='line'>  --log-level=INFO \
</span><span class='line'>  &gt;/dev/null 2&gt;&1 &
</span><span class='line'>
</span><span class='line'>nohup bin/codis-fe \
</span><span class='line'>  --ncpu=4 \
</span><span class='line'>  --zookeeper=127.0.0.1:2181 \
</span><span class='line'>  --listen=0.0.0.0:28080 \
</span><span class='line'>  --log=$LOG_DIR/codis_fe.log \
</span><span class='line'>  --log-level=INFO \
</span><span class='line'>  &gt;/dev/null 2&gt;&1 &
</span><span class='line'>
</span><span class='line'> =============== bin/start-codis-proxy.sh ================= 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>CODIS_BIN="${BASH_SOURCE-$0}"
</span><span class='line'>CODIS_BIN="$(dirname "${CODIS_BIN}")"
</span><span class='line'>CODIS_BINDIR="$(cd "${CODIS_BIN}"; pwd)"
</span><span class='line'>
</span><span class='line'>source $CODIS_BINDIR/codis.profile
</span><span class='line'>
</span><span class='line'>cd $CODIS_HOME
</span><span class='line'>nohup bin/codis-proxy \
</span><span class='line'>  --ncpu=24 \
</span><span class='line'>  --config=proxy.toml \
</span><span class='line'>  --log=$LOG_DIR/codis_proxy.log \
</span><span class='line'>  --log-level=INFO \
</span><span class='line'>  &gt;/dev/null 2&gt;&1 &
</span><span class='line'>
</span><span class='line'> =============== bin/start-redis.sh ================= 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>CODIS_BIN="${BASH_SOURCE-$0}"
</span><span class='line'>CODIS_BIN="$(dirname "${CODIS_BIN}")"
</span><span class='line'>CODIS_BINDIR="$(cd "${CODIS_BIN}"; pwd)"
</span><span class='line'>
</span><span class='line'>source $CODIS_BINDIR/codis.profile
</span><span class='line'>
</span><span class='line'>PORT=${1:-6379}
</span><span class='line'>
</span><span class='line'>cd $CODIS_HOME
</span><span class='line'>bin/codis-server --daemonize yes --port $PORT --pidfile /var/run/redis_$PORT.pid --logfile $LOG_DIR/redis_$PORT.log --save "" --bind $(hostname) 
</span></code></pre></td></tr></table></div></figure>


<p>环境：</p>

<ul>
<li>zookeeper: cu-ud6</li>
<li>dashboard: cu-ud6</li>
<li>fa: cu-ud6</li>
<li>proxy: cu-ud6/7/8</li>
<li>redis: cu-ud6/7/8:6378/6379</li>
<li>nginx代理: cu-ud9</li>
</ul>


<p>web界面添加步骤：</p>

<ul>
<li>界面上添加proxy : cu6/7/8:11080</li>
<li>再添加group，填数字: &frac12;/&frac34;/5/6</li>
<li>然后添加server : cu-ud6/7/8:6378/6379</li>
<li>最后分配slots</li>
</ul>


<p><img src="http://winseliu.com/images/blogs/codis.jpg" alt="" /></p>

<p>nginx1.11新版本已经支持tcp的代理，可以实现proxy的负载均衡：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 编译Nginx
</span><span class='line'>./configure --with-stream --with-http_ssl_module --with-pcre=src/pcre --with-zlib=src/zlib --prefix=/usr/local/nginx
</span><span class='line'>make && make install
</span><span class='line'>
</span><span class='line'>[ud@cu-ud9 nginx]$ cat conf/nginx.conf
</span><span class='line'>
</span><span class='line'>#user  nobody;
</span><span class='line'>worker_processes  1;
</span><span class='line'>
</span><span class='line'>#error_log  logs/error.log;
</span><span class='line'>error_log  /var/log/nginx_error.log  notice;
</span><span class='line'>#error_log  logs/error.log  info;
</span><span class='line'>
</span><span class='line'>#pid        logs/nginx.pid;
</span><span class='line'>
</span><span class='line'>events {
</span><span class='line'>    worker_connections  1024;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>stream {
</span><span class='line'>  upstream proxy {
</span><span class='line'>    hash   $remote_addr;
</span><span class='line'>    server cu-ud6:19000;
</span><span class='line'>    server cu-ud7:19000;
</span><span class='line'>    server cu-ud8:19000;
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  server {
</span><span class='line'>    listen cu-ud9:19000;
</span><span class='line'>    proxy_timeout 600s;
</span><span class='line'>    proxy_pass proxy;
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'># 测试获取数据
</span><span class='line'>[ud@cu-ud6 opt]$ bin/redis-cli -h cu-ud6 -p 6379 scan 0 # 样本Key
</span><span class='line'>[ud@cu-ud6 opt]$ bin/redis-cli -h cu-ud9 -p 19000
</span><span class='line'>&gt; get XXX
</span></code></pre></td></tr></table></div></figure>


<p>重置统计量：</p>

<ul>
<li><a href="https://github.com/CodisLabs/codis/issues/1049">https://github.com/CodisLabs/codis/issues/1049</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ud@cu-ud6 codis]$ bin/codis-admin --proxy=cu-ud6:11080 --reset-stats</span></code></pre></td></tr></table></div></figure>


<h2>问题</h2>

<p>pipeline量太大，修改proxy的 backend_max_pipeline/session_max_pipeline 。同时在客户端代码里面执行一定量的pipe后执行sync。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2017/03/18 00:01:23 session.go:79: [INFO] session [0xc839888d80] create: {"ops":0,"create":1489766483,"remote":"192.168.32.182:57029"}
</span><span class='line'>2017/03/18 00:01:24 session.go:86: [INFO] session [0xc834a06d80] closed: {"ops":39601,"create":1489766483,"lastop":1489766484,"remote":"192.168.32.182:57028"}, error: too many pipelined r
</span><span class='line'>equests</span></code></pre></td></tr></table></div></figure>


<p>sync还是会超时，修改nginx的proxy_timeout以及客户端初始化的timeout参数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>new JedisPool(new GenericObjectPoolConfig(), "cu-ud9", 19000, 10 * 60 * 1000)</span></code></pre></td></tr></table></div></figure>


<p>W：感觉proxy还是会有停顿，sync后有时会出现几分钟时间没响应。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s Harbor Config on Centos6]]></title>
    <link href="http://winseliu.com/blog/2017/03/12/k8s-harbor-config-on-centos6/"/>
    <updated>2017-03-12T15:21:30+00:00</updated>
    <id>http://winseliu.com/blog/2017/03/12/k8s-harbor-config-on-centos6</id>
    <content type="html"><![CDATA[<h2>前传</h2>

<p>前面有写在 centos6 安装k8s的文章，后来重启一台worker节点后该节点的网络就不通了 <strong> connect: Invalid argument </strong> 。更新到最新的0.7.0后worker节点重启网络都能正常连通。</p>

<ul>
<li><a href="https://github.com/coreos/flannel/issues/180">https://github.com/coreos/flannel/issues/180</a></li>
</ul>


<p>言归正传，来说说harbor的安装。想的是安装一个类似maven私服的功能（原来都是一台机一台机的save/load，麻烦）：</p>

<ul>
<li>本来安装registry就好了，每次都要加端口很烦有没有！！！</li>
<li>弄了个service整到80端口，还得加 <strong> &ndash;insecure-registry </strong> 参数。还行吧，但是没有图形界面</li>
<li>好了，看到有人用nexus3做docker私服。主要吧真没弄通，第二nexus3不会用！反正就是没搭成功了。</li>
<li>本来前面有看到过vmware harbor，但是官网说是要docker1.10+的，差点就打消念头了，但是nexus3实在是搞不懂，只能硬着头皮尝试下harbor。</li>
</ul>


<p>这hardor是一坑货啊，功能是狠牛逼但是文档版本都对不上的！！！</p>

<p>这里还是在 centos6 上面安装。并且老版本k8s-1.2各种配置不能用，一个个坑填的好苦！行，先爽一把，看看修改后的简单的安装操作流程：</p>

<h2>简单配置</h2>

<p>版本信息</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# lsb_release -a
</span><span class='line'>LSB Version:    :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch
</span><span class='line'>Distributor ID: CentOS
</span><span class='line'>Description:    CentOS release 6.8 (Final)
</span><span class='line'>Release:        6.8
</span><span class='line'>Codename:       Final
</span><span class='line'>[root@cu2 ~]# docker version
</span><span class='line'>Client version: 1.7.1
</span><span class='line'>Client API version: 1.19
</span><span class='line'>Go version (client): go1.4.2
</span><span class='line'>Git commit (client): 786b29d/1.7.1
</span><span class='line'>OS/Arch (client): linux/amd64
</span><span class='line'>Server version: 1.7.1
</span><span class='line'>Server API version: 1.19
</span><span class='line'>Go version (server): go1.4.2
</span><span class='line'>Git commit (server): 786b29d/1.7.1
</span><span class='line'>OS/Arch (server): linux/amd64</span></code></pre></td></tr></table></div></figure>


<ul>
<li>创建CA和证书</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubernetes]# git clone https://github.com/OpenVPN/easy-rsa.git
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa init-pki
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa build-ca #记住输入的密码，下面颁发证书还会用到
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa gen-req cu nopass
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa sign-req server cu #commonName填将要用到的域名咯
</span><span class='line'>
</span><span class='line'>生成的key和证书在pki/private和pki/issued下</span></code></pre></td></tr></table></div></figure>


<ul>
<li>下载配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/winse/docker-hadoop.git
</span><span class='line'>cd docker-hadoop/k8s-centos6/containers/harbor-make/</span></code></pre></td></tr></table></div></figure>


<ul>
<li>修改harbor.cfg配置</li>
</ul>


<p>把 <strong>域名</strong> 和 <strong>证书路径</strong> 修改成自己的。</p>

<ul>
<li>生成ConfigMaps配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scl enable python27 bash
</span><span class='line'>python2.7 kubernetes/prepare </span></code></pre></td></tr></table></div></figure>


<ul>
<li>创建服务和容器</li>
</ul>


<p>这里需要先下载官网的离线包harbor-offline-installer-0.5.0.tgz，加载harbor.0.5.0.tgz里面的镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 harbor]# docker images 
</span><span class='line'>REPOSITORY                                            TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
</span><span class='line'>gcr.io/google_containers/heapster-grafana-amd64       v4.0.2              74d2c72849cc        7 weeks ago         131.5 MB
</span><span class='line'>gcr.io/google_containers/heapster-influxdb-amd64      v1.1.1              55d63942e2eb        7 weeks ago         11.59 MB
</span><span class='line'>gcr.io/google_containers/heapster-amd64               v1.3.0-beta.1       026fb02eca65        7 weeks ago         101.3 MB
</span><span class='line'>quay.io/coreos/flannel                                v0.7.0-amd64        072e88d50780        8 weeks ago         73.75 MB
</span><span class='line'>gcr.io/google_containers/kubernetes-dashboard-amd64   v1.5.1              9af7d5c61ccf        8 weeks ago         103.6 MB
</span><span class='line'>vmware/harbor-log                                     0.5.0               5cccdd11efe0        3 months ago        190.5 MB
</span><span class='line'>vmware/harbor-jobservice                              0.5.0               573d0bbd91ee        3 months ago        169.4 MB
</span><span class='line'>vmware/harbor-ui                                      0.5.0               990d3476bf93        3 months ago        233 MB
</span><span class='line'>vmware/harbor-db                                      0.5.0               9a595c26d6bc        3 months ago        326.8 MB
</span><span class='line'>nginx                                                 1.11.5              98f8314de615        4 months ago        181.4 MB
</span><span class='line'>gcr.io/google_containers/hyperkube-amd64              v1.2.7              1dd7250ed1b3        4 months ago        231.4 MB
</span><span class='line'>quay.io/coreos/flannel                                v0.6.1-amd64        ef86f3a53de0        6 months ago        27.89 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                   3.0.4               ef5e89d609f1        7 months ago        39.62 MB
</span><span class='line'>registry                                              2.5.0               8cc599785872        7 months ago        33.28 MB
</span><span class='line'>gcr.io/google_containers/kube2sky-amd64               1.15                f93305484d65        10 months ago       29.16 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                   2.2.5               a6752fb962b5        11 months ago       30.45 MB
</span><span class='line'>gcr.io/google_containers/skydns-amd64                 1.0                 a925f95d080a        11 months ago       15.57 MB
</span><span class='line'>gcr.io/google_containers/exechealthz-amd64            1.0                 5b9ac190b20c        11 months ago       7.116 MB
</span><span class='line'>gcr.io/google_containers/pause                        2.0                 9981ca1bbdb5        17 months ago       350.2 kB
</span><span class='line'>
</span><span class='line'>---
</span><span class='line'>
</span><span class='line'>cd kubernetes/
</span><span class='line'>sh apply.sh</span></code></pre></td></tr></table></div></figure>


<ul>
<li>手动修复容器的配置文件</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sh config.sh</span></code></pre></td></tr></table></div></figure>


<p>CentOS6-K8S上面麻烦点，在CentOS7-K8S_V1.5+上面ConfigMap Volumn是可以用的，就不需要自己手动拷贝配置了。</p>

<ul>
<li>使用</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 easyrsa3]# kubectl get services 
</span><span class='line'>NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)             AGE
</span><span class='line'>jobservice   10.0.0.154   &lt;none&gt;        80/TCP              1d
</span><span class='line'>kubernetes   10.0.0.1     &lt;none&gt;        443/TCP             2d
</span><span class='line'>mysql        10.0.0.176   &lt;none&gt;        3306/TCP            1d
</span><span class='line'>nginx        10.0.0.78    &lt;none&gt;        80/TCP,443/TCP      1d
</span><span class='line'>registry     10.0.0.46    &lt;none&gt;        5000/TCP,5001/TCP   1d
</span><span class='line'>ui           10.0.0.11    &lt;none&gt;        80/TCP              1d
</span><span class='line'>
</span><span class='line'># 域名
</span><span class='line'>[root@cu3 ~]# vi /etc/hosts
</span><span class='line'>10.0.0.78 cu.eshore.cn
</span><span class='line'>
</span><span class='line'># 证书
</span><span class='line'>[root@cu3 ~]# mkdir -p /etc/docker/certs.d/cu.eshore.cn/
</span><span class='line'>
</span><span class='line'>[root@cu2 pki]# scp ca.crt cu3:/etc/docker/certs.d/cu.eshore.cn/
</span><span class='line'>
</span><span class='line'># 登录
</span><span class='line'>[root@cu3 certs.d]# docker login cu.eshore.cn
</span><span class='line'>Username: admin
</span><span class='line'>Password: Harbor12345
</span><span class='line'>Email: 1
</span><span class='line'>WARNING: login credentials saved in /root/.docker/config.json
</span><span class='line'>Login Succeeded
</span><span class='line'>
</span><span class='line'># https://cu.eshore.cn 通过WEB页面创建项目 google_containers
</span><span class='line'>
</span><span class='line'># PUSH
</span><span class='line'>[root@cu3 certs.d]# docker tag gcr.io/google_containers/pause:2.0 cu.eshore.cn/google_containers/pause:2.0
</span><span class='line'>
</span><span class='line'>[root@cu3 certs.d]# docker push cu.eshore.cn/google_containers/pause:2.0
</span><span class='line'>The push refers to a repository [cu.eshore.cn/google_containers/pause] (len: 1)
</span><span class='line'>9981ca1bbdb5: Image already exists 
</span><span class='line'>6995a49b90f2: Image successfully pushed 
</span><span class='line'>Digest: sha256:139471770ffc22a2f15ae2ad8e3a0b3b9cbd620ad32400c7e8024a3d09ebec7d
</span></code></pre></td></tr></table></div></figure>


<h1>&mdash;&mdash; 下面是记流水账内容 &mdash;&mdash;</h1>

<h2>简单搭建配置</h2>

<p>参考阅读</p>

<ul>
<li><a href="http://www.zoues.com/2017/02/19/vmware-harbor-%E5%9C%A8-kubernetes-%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E3%80%90zoues-com%E3%80%91/">在 KUBERNETES 上的部署 VMWare Harbor</a></li>
<li><a href="https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md">主干文档 Integration with Kubernetes </a></li>
<li><a href="https://github.com/vmware/harbor/blob/master/docs/installation_guide.md">https://github.com/vmware/harbor/blob/master/docs/installation_guide.md</a></li>
<li><a href="https://github.com/vmware/harbor/tree/00259567a8b59758930950440a0ecfd6061db485/make/kubernetes">https://github.com/vmware/harbor/tree/00259567a8b59758930950440a0ecfd6061db485/make/kubernetes</a></li>
</ul>


<p>简略步骤：</p>

<ul>
<li>下载0.5.0的离线压缩包 harbor-offline-installer-0.5.0.tgz</li>
<li>把镜像加载到本地（解压offline后在目录下有tgz的镜像压缩包） <code>docker load -i harbor.0.5.0.tgz</code></li>
<li>下载github主干的源码 harbor-master.zip ，对是主干，不是release页面的源码！！！（香菇，release源码包里面的k8s配置文件尽然是不配套的，那打什么版本咯！！文档也不说明下。非常非常感谢 www.zoues.com 博主，这才是明灯啊）</li>
<li>安装python2.7（prepare脚本需要） <code>yum install centos-release-scl; yum install -y python27</code></li>
<li>解压进入到 harbor-master/make 目录</li>
<li>修改harbor.cfg文件配置。（这里我就改了域名而已，会有https的问题。先不管跑起来先，后面在讲https的处理）</li>
<li>执行prepare脚本，用于生成配置键值对cm文件（ConfigMaps）。</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 make]# python kubernetes/prepare 
</span><span class='line'>Traceback (most recent call last):
</span><span class='line'>  File "kubernetes/prepare", line 145, in &lt;module&gt;
</span><span class='line'>    pkey = subprocess.check_output(['openssl','genrsa','4096'], stderr=devnull)
</span><span class='line'>AttributeError: 'module' object has no attribute 'check_output'
</span><span class='line'>
</span><span class='line'>&gt; Python should be version 2.7 or higher. Note that you may have to install Python on Linux distributions (Gentoo, Arch) that do not come with a Python interpreter installed by default
</span><span class='line'>
</span><span class='line'>https://github.com/h2oai/h2o-2/wiki/installing-python-2.7-on-centos-6.3.-follow-this-sequence-exactly-for-centos-machine-only
</span><span class='line'>https://gist.github.com/dalegaspi/dec44117fa5e7597a559  我按这个小写的安装的
</span><span class='line'>[root@cu2 make]# yum install centos-release-scl
</span><span class='line'>[root@cu2 make]# yum install -y python27
</span><span class='line'>
</span><span class='line'>[root@cu2 make]# scl enable python27 bash
</span><span class='line'>[root@cu2 make]# /opt/rh/python27/root/usr/bin/python -V
</span><span class='line'>Python 2.7.8
</span><span class='line'>
</span><span class='line'>[root@cu2 make]# less harbor.cfg 
</span><span class='line'>
</span><span class='line'>[root@cu2 make]# /opt/rh/python27/root/usr/bin/python kubernetes/prepare 
</span><span class='line'>Warning: Key(ldap_searchdn) is not existing. Use empty string as default
</span><span class='line'>Warning: Key(ldap_search_pwd) is not existing. Use empty string as default
</span><span class='line'>Warning: Key(ldap_filter) is not existing. Use empty string as default</span></code></pre></td></tr></table></div></figure>


<ul>
<li>然后就是愉快的执行apply就好：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl apply -f pv/
</span><span class='line'>
</span><span class='line'>kubectl apply -f jobservice/jobservice.cm.yaml
</span><span class='line'>kubectl apply -f mysql/mysql.cm.yaml
</span><span class='line'>kubectl apply -f nginx/nginx.cm.yaml
</span><span class='line'>kubectl apply -f registry/registry.cm.yaml
</span><span class='line'>kubectl apply -f ui/ui.cm.yaml
</span><span class='line'>
</span><span class='line'>kubectl apply -f jobservice/jobservice.svc.yaml
</span><span class='line'>kubectl apply -f mysql/mysql.svc.yaml
</span><span class='line'>kubectl apply -f nginx/nginx.svc.yaml
</span><span class='line'>kubectl apply -f registry/registry.svc.yaml
</span><span class='line'>kubectl apply -f ui/ui.svc.yaml
</span><span class='line'>
</span><span class='line'>kubectl apply -f registry/registry.rc.yaml
</span><span class='line'>kubectl apply -f mysql/mysql.rc.yaml
</span><span class='line'>kubectl apply -f jobservice/jobservice.rc.yaml
</span><span class='line'>kubectl apply -f ui/ui.rc.yaml
</span><span class='line'>kubectl apply -f nginx/nginx.rc.yaml
</span></code></pre></td></tr></table></div></figure>


<p>由于ConfigMaps方式不能正确的创建文件需要把配置文件拷贝到对应容器的config目录下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sh config.sh</span></code></pre></td></tr></table></div></figure>


<p>除了nginx报https的证书问题外，其他都正常跑起来了。把nginx.conf的https server部分先删掉，先查看效果。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubernetes]# kubectl get rc
</span><span class='line'>NAME            DESIRED   CURRENT   AGE
</span><span class='line'>jobservice-rc   1         1         4h
</span><span class='line'>mysql-rc        1         1         4h
</span><span class='line'>nginx-rc        1         1         4h
</span><span class='line'>registry-rc     1         1         4h
</span><span class='line'>ui-rc           1         1         4h
</span><span class='line'>[root@cu2 kubernetes]# kubectl get pods
</span><span class='line'>NAME                       READY     STATUS    RESTARTS   AGE
</span><span class='line'>jobservice-rc-3hhea        1/1       Running   0          4h
</span><span class='line'>k8s-master-192.168.0.214   4/4       Running   28         2d
</span><span class='line'>k8s-proxy-192.168.0.214    1/1       Running   4          2d
</span><span class='line'>mysql-rc-nyk6z             1/1       Running   0          4h
</span><span class='line'>nexus-3126345715-mfteg     1/1       Running   0          2d # 这个是maven私服
</span><span class='line'>nginx-rc-93cdr             1/1       Running   15         4h
</span><span class='line'>registry-rc-qbdfk          1/1       Running   12         4h
</span><span class='line'>ui-rc-7e76i                1/1       Running   10         4h
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# kubectl get services nginx
</span><span class='line'>NAME      CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
</span><span class='line'>nginx     10.0.0.78    &lt;none&gt;        80/TCP,443/TCP   1d
</span></code></pre></td></tr></table></div></figure>


<p>访问nginx：</p>

<p><img src="http://winseliu.com/images/blogs/k8s-harbor.jpg" alt="" /></p>

<p>安装完了后，使用harbor.cfg配置文件里面的admin和密码进行登录。然后看看官网的操作文档 <a href="https://github.com/vmware/harbor/blob/master/docs/user_guide.md">https://github.com/vmware/harbor/blob/master/docs/user_guide.md</a></p>

<p>现在PUSH要加 <code>--insecure-registry</code> 参数，还得重启docker太麻烦了。等下先弄https，搞好后添加证书直接push比较爽。</p>

<h2>修改配置过程中遇到的一些问题</h2>

<p>pvc在v1.2的时刻不支持selector。使用volumeName属性来代替。</p>

<ul>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/">https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/</a></li>
<li><a href="https://kubernetes.io/docs/user-guide/persistent-volumes/#persistentvolumeclaims">https://kubernetes.io/docs/user-guide/persistent-volumes/#persistentvolumeclaims</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/v1.2.7/docs/user-guide/persistent-volumes/claims">https://github.com/kubernetes/kubernetes/tree/v1.2.7/docs/user-guide/persistent-volumes/claims</a></li>
<li><a href="https://kubernetes.io/docs/resources-reference/v1.5/#persistentvolumeclaim-v1">https://kubernetes.io/docs/resources-reference/v1.5/#persistentvolumeclaim-v1</a></li>
<li><a href="http://blog.fleeto.us/translation/persistent-volumes">http://blog.fleeto.us/translation/persistent-volumes</a></li>
</ul>


<p>巨坑，键名对不能用下划线、不能大写字母，到1.4才修复。</p>

<ul>
<li><a href="https://github.com/kubernetes/kubernetes/issues/23722">Allow underscore in configMapKeyRef key&rsquo;s</a></li>
</ul>


<p>configmap~volumn用于创建volumns好像有问题，没有创建对应文件。</p>

<ul>
<li><a href="https://kubernetes.io/docs/user-guide/configmap/">https://kubernetes.io/docs/user-guide/configmap/</a></li>
<li><a href="http://stackoverflow.com/questions/36187624/kubernetes-configmap-volume-doesnt-create-file-in-container">http://stackoverflow.com/questions/36187624/kubernetes-configmap-volume-doesnt-create-file-in-container</a></li>
</ul>


<p>在1.5.3上面是可以生成的。。。囧，相比puppet的文档，k8s的文档真的差了十万八千里啊！！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s kube-deploy]# kubectl logs nginx-rc-fr52v
</span><span class='line'>https.crt
</span><span class='line'>https.key
</span><span class='line'>nginx.conf</span></code></pre></td></tr></table></div></figure>


<p>后面看到nginx的v1.2用了secrets修改后也不行。</p>

<ul>
<li><a href="https://github.com/kubernetes/kubernetes/blob/release-1.2/examples/https-nginx/nginx-app.yaml">https://github.com/kubernetes/kubernetes/blob/release-1.2/examples/https-nginx/nginx-app.yaml</a> 看到1.2使用secret volumes</li>
<li><a href="https://github.com/kubernetes/kubernetes/blob/52f4d3806919e4ec16cb17336a1802461cf40a46/test/kubemark/resources/hollow-node_template.yaml">https://github.com/kubernetes/kubernetes/blob/52f4d3806919e4ec16cb17336a1802461cf40a46/test/kubemark/resources/hollow-node_template.yaml</a></li>
<li><a href="https://kubernetes.io/docs/user-guide/secrets/">https://kubernetes.io/docs/user-guide/secrets/</a></li>
<li><a href="https://kubernetes.io/docs/user-guide/configmap/">https://kubernetes.io/docs/user-guide/configmap/</a></li>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/downward-api-volume-expose-pod-information/">https://kubernetes.io/docs/tasks/configure-pod-container/downward-api-volume-expose-pod-information/</a></li>
</ul>


<p>其实就是docker版本老的不支持shared，其实在kubelet的容器里面是创建了对应的文件的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># docker logs
</span><span class='line'>I0316 08:22:19.729825   13206 volumes.go:279] Used volume plugin "kubernetes.io/configmap" to mount config
</span><span class='line'>I0316 08:22:19.729860   13206 configmap.go:118] Setting up volume config for pod cfe8b3f6-09fb-11e7-bdde-020047eb000e at /var/lib/kubelet/pods/cfe8b3f6-09fb-11e7-bdde-020047eb000e/volumes/kubernetes.io~configmap/config
</span><span class='line'>I0316 08:22:19.729915   13206 volumes.go:279] Used volume plugin "kubernetes.io/empty-dir" to mount wrapped_config
</span><span class='line'>...
</span><span class='line'>I0316 08:22:19.733309   13206 configmap.go:145] Received configMap default/harbor-ui-config containing (30) pieces of data, 3739 total bytes
</span><span class='line'>I0316 08:22:19.733470   13206 atomic_writer.go:316] /var/lib/kubelet/pods/cfe8b3f6-09fb-11e7-bdde-020047eb000e/volumes/kubernetes.io~configmap/config: current paths:   [app.conf private_key.pem]
</span><span class='line'>I0316 08:22:19.733493   13206 atomic_writer.go:328] /var/lib/kubelet/pods/cfe8b3f6-09fb-11e7-bdde-020047eb000e/volumes/kubernetes.io~configmap/config: new paths:       [app.conf private_key.pem]
</span><span class='line'>I0316 08:22:19.733502   13206 atomic_writer.go:331] /var/lib/kubelet/pods/cfe8b3f6-09fb-11e7-bdde-020047eb000e/volumes/kubernetes.io~configmap/config: paths to remove: map[]
</span><span class='line'>I0316 08:22:19.733552   13206 atomic_writer.go:136] pod default/ui-rc-psjzs volume config: no update required for target directory /var/lib/kubelet/pods/cfe8b3f6-09fb-11e7-bdde-020047eb000e/volumes/kubernetes.io~configmap/config
</span><span class='line'>
</span><span class='line'>[root@cu3 config]# docker exec -ti b34c51260dda bash
</span><span class='line'>root@cu3:/# ls -al /var/lib/kubelet/pods/cfe8b3f6-09fb-11e7-bdde-020047eb000e/volumes/kubernetes.io~configmap/config
</span><span class='line'>total 4
</span><span class='line'>drwxrwxrwt 3 root root  120 Mar 16 04:08 .
</span><span class='line'>drwxr-xr-x 3 root root 4096 Mar 16 04:08 ..
</span><span class='line'>drwxr-xr-x 2 root root   80 Mar 16 04:08 ..3983_16_03_04_08_50.565987072
</span><span class='line'>lrwxrwxrwx 1 root root   31 Mar 16 04:08 ..data -&gt; ..3983_16_03_04_08_50.565987072
</span><span class='line'>lrwxrwxrwx 1 root root   15 Mar 16 04:08 app.conf -&gt; ..data/app.conf
</span><span class='line'>lrwxrwxrwx 1 root root   22 Mar 16 04:08 private_key.pem -&gt; ..data/private_key.pem</span></code></pre></td></tr></table></div></figure>


<p>最后放弃了，直接用脚本来创建文件，然后把文件拷贝到对应的机器。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubernetes]# cd harbor-make/kubernetes/
</span><span class='line'>[root@cu2 kubernetes]# sh config.sh </span></code></pre></td></tr></table></div></figure>


<h2>HTTPS</h2>

<ul>
<li><a href="http://www.pangxie.space/docker/353">Docker部署认证私有仓库(registry2.x+nginx)-centos7</a></li>
<li><a href="https://github.com/vmware/harbor/blob/master/docs/configure_https.md">Configuring Harbor with HTTPS Access</a></li>
</ul>


<p>生成CA和证书</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 kubernetes]# git clone https://github.com/OpenVPN/easy-rsa.git
</span><span class='line'>
</span><span class='line'>https://github.com/OpenVPN/easy-rsa/blob/master/README.quickstart.md
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# ll
</span><span class='line'>total 56
</span><span class='line'>-rwxr-xr-x 1 root root 35253 Mar 13 01:04 easyrsa
</span><span class='line'>-rw-r--r-- 1 root root  4560 Mar 13 01:04 openssl-1.0.cnf
</span><span class='line'>-rw-r--r-- 1 root root  8126 Mar 13 01:04 vars.example
</span><span class='line'>drwxr-xr-x 2 root root  4096 Mar 13 01:04 x509-types
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa init-pki
</span><span class='line'>
</span><span class='line'>init-pki complete; you may now create a CA or requests.
</span><span class='line'>Your newly created PKI dir is: /data/kubernetes/easy-rsa/easyrsa3/pki
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa build-ca
</span><span class='line'>Generating a 2048 bit RSA private key
</span><span class='line'>.............................+++
</span><span class='line'>..............................................+++
</span><span class='line'>writing new private key to '/data/kubernetes/easy-rsa/easyrsa3/pki/private/ca.key.Nj5oHgfZC5'
</span><span class='line'>Enter PEM pass phrase: 123456
</span><span class='line'>Verifying - Enter PEM pass phrase: 123456
</span><span class='line'>-----
</span><span class='line'>You are about to be asked to enter information that will be incorporated
</span><span class='line'>into your certificate request.
</span><span class='line'>What you are about to enter is what is called a Distinguished Name or a DN.
</span><span class='line'>There are quite a few fields but you can leave some blank
</span><span class='line'>For some fields there will be a default value,
</span><span class='line'>If you enter '.', the field will be left blank.
</span><span class='line'>-----
</span><span class='line'>Common Name (eg: your user, host, or server name) [Easy-RSA CA]:eshore.cn
</span><span class='line'>
</span><span class='line'>CA creation complete and you may now import and sign cert requests.
</span><span class='line'>Your new CA certificate file for publishing is at:
</span><span class='line'>/data/kubernetes/easy-rsa/easyrsa3/pki/ca.crt
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa gen-req cu nopass
</span><span class='line'>Generating a 2048 bit RSA private key
</span><span class='line'>..........+++
</span><span class='line'>.................................+++
</span><span class='line'>writing new private key to '/data/kubernetes/easy-rsa/easyrsa3/pki/private/cu.key.LQX3Dr2jG3'
</span><span class='line'>-----
</span><span class='line'>You are about to be asked to enter information that will be incorporated
</span><span class='line'>into your certificate request.
</span><span class='line'>What you are about to enter is what is called a Distinguished Name or a DN.
</span><span class='line'>There are quite a few fields but you can leave some blank
</span><span class='line'>For some fields there will be a default value,
</span><span class='line'>If you enter '.', the field will be left blank.
</span><span class='line'>-----
</span><span class='line'>Common Name (eg: your user, host, or server name) [cu]:cu.eshore.cn
</span><span class='line'>
</span><span class='line'>Keypair and certificate request completed. Your files are:
</span><span class='line'>req: /data/kubernetes/easy-rsa/easyrsa3/pki/reqs/cu.req
</span><span class='line'>key: /data/kubernetes/easy-rsa/easyrsa3/pki/private/cu.key
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# ./easyrsa sign-req server cu
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>You are about to sign the following certificate.
</span><span class='line'>Please check over the details shown below for accuracy. Note that this request
</span><span class='line'>has not been cryptographically verified. Please be sure it came from a trusted
</span><span class='line'>source or that you have verified the request checksum with the sender.
</span><span class='line'>
</span><span class='line'>Request subject, to be signed as a server certificate for 3650 days:
</span><span class='line'>
</span><span class='line'>subject=
</span><span class='line'>    commonName                = cu.eshore.cn
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Type the word 'yes' to continue, or any other input to abort.
</span><span class='line'>  Confirm request details: yes
</span><span class='line'>Using configuration from /data/kubernetes/easy-rsa/easyrsa3/openssl-1.0.cnf
</span><span class='line'>Enter pass phrase for /data/kubernetes/easy-rsa/easyrsa3/pki/private/ca.key:
</span><span class='line'>Check that the request matches the signature
</span><span class='line'>Signature ok
</span><span class='line'>The Subject's Distinguished Name is as follows
</span><span class='line'>commonName            :PRINTABLE:'cu.eshore.cn'
</span><span class='line'>Certificate is to be certified until Mar 10 23:36:42 2027 GMT (3650 days)
</span><span class='line'>
</span><span class='line'>Write out database with 1 new entries
</span><span class='line'>Data Base Updated
</span><span class='line'>
</span><span class='line'>Certificate created at: /data/kubernetes/easy-rsa/easyrsa3/pki/issued/cu.crt
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# 
</span><span class='line'>
</span><span class='line'>这里得用签发server端证书，如果是client使用时会报错： v2 ping attempt failed with error: Get https://cu.eshore.cn/v2/: x509: certificate specifies an incompatible key usage
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 easyrsa3]# tree .
</span><span class='line'>.
</span><span class='line'>├── easyrsa
</span><span class='line'>├── openssl-1.0.cnf
</span><span class='line'>├── pki
</span><span class='line'>│   ├── ca.crt
</span><span class='line'>│   ├── certs_by_serial
</span><span class='line'>│   │   └── 01.pem
</span><span class='line'>│   ├── index.txt
</span><span class='line'>│   ├── index.txt.attr
</span><span class='line'>│   ├── index.txt.old
</span><span class='line'>│   ├── issued
</span><span class='line'>│   │   └── cu.crt
</span><span class='line'>│   ├── private
</span><span class='line'>│   │   ├── ca.key
</span><span class='line'>│   │   └── cu.key
</span><span class='line'>│   ├── reqs
</span><span class='line'>│   │   └── cu.req
</span><span class='line'>│   ├── serial
</span><span class='line'>│   └── serial.old
</span><span class='line'>├── vars.example
</span><span class='line'>└── x509-types
</span><span class='line'>    ├── ca
</span><span class='line'>    ├── client
</span><span class='line'>    ├── COMMON
</span><span class='line'>    └── server
</span><span class='line'>
</span><span class='line'>6 directories, 18 files</span></code></pre></td></tr></table></div></figure>


<p>重新执行以下上面的步骤，配置关联比较多。https和http请求地址会有冲突。</p>

<p>重新配置后，把ca.cert拷贝到docker节点，然后登录、创建项目、提交项目即可。最开始有帖操作的代码，这里不重复了。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[k8s在Centos6部署实践]]></title>
    <link href="http://winseliu.com/blog/2017/03/05/k8s-docker-multinode-on-centos6/"/>
    <updated>2017-03-05T00:49:29+00:00</updated>
    <id>http://winseliu.com/blog/2017/03/05/k8s-docker-multinode-on-centos6</id>
    <content type="html"><![CDATA[<p>2017-3-17 08:33:56 折腾了大半个月，写点小结。在centos6 + docker-1.7 + k8s-1.2 是能用起来，安装了dashboard、nexus2、harbor，但是对于一些新的东西不能用，并且k8s官网文档不分版本并且没讲明白docker兼容的版本（至少官网文档），感觉人家就是行到自己这里就不行，各种折腾然后到后面是版本问题。docker和k8s在容器大热的当前，版本更新太快了，docker都到1.17了。综上，如果在centos6上面玩玩了解了k8s的概况还是好的，但是真的要用还是升级centos7吧。</p>

<p>configmap-volumes真是好东西，没办法docker-1.7不支持shared volume。</p>

<p>&ndash;</p>

<p>centos6系统比较&#8221;老&#8221;啊，既没有systemd，也没有docker-engine。网上各种资料要么是原始安装（非bootstrap docker），要么就是在centos7上装的。不太想在系统上做安装，按照kube-deploy的docker-multinode的脚本来进行修改安装，版本不兼容需要开推土机填坑啊，centos6上面的docker才1.7还不能用kubernetes-1.3，dashboard也需要自己安装。</p>

<p>环境描述：</p>

<ul>
<li>cu2: bootstrap(etcd, flannel), main(hyperkube, pause, kubernetes-dashboard)</li>
<li>cu4、cu5: bootstrap(flannel), main(hyperkube, pause)</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# docker -H unix:///var/run/docker-bootstrap.sock ps | grep -v IMAGE | awk '{print $2}' | sort -u
</span><span class='line'>gcr.io/google_containers/etcd-amd64:3.0.4
</span><span class='line'>quay.io/coreos/flannel:v0.6.1-amd64
</span><span class='line'>[root@cu4 ~]# docker -H unix:///var/run/docker-bootstrap.sock ps | grep -v IMAGE | awk '{print $2}' | sort -u
</span><span class='line'>quay.io/coreos/flannel:v0.6.1-amd64
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# docker images
</span><span class='line'>REPOSITORY                                            TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
</span><span class='line'>bigdata                                               v1                  9e30d146824b        38 hours ago        457.2 MB
</span><span class='line'>gcr.io/google_containers/heapster-grafana-amd64       v4.0.2              74d2c72849cc        6 weeks ago         131.5 MB
</span><span class='line'>gcr.io/google_containers/heapster-influxdb-amd64      v1.1.1              55d63942e2eb        6 weeks ago         11.59 MB
</span><span class='line'>gcr.io/google_containers/heapster-amd64               v1.3.0-beta.1       026fb02eca65        6 weeks ago         101.3 MB
</span><span class='line'>gcr.io/google_containers/kubernetes-dashboard-amd64   v1.5.1              9af7d5c61ccf        7 weeks ago         103.6 MB
</span><span class='line'>gcr.io/google_containers/hyperkube-amd64              v1.2.7              1dd7250ed1b3        4 months ago        231.4 MB
</span><span class='line'>quay.io/coreos/flannel                                v0.6.1-amd64        ef86f3a53de0        6 months ago        27.89 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                   3.0.4               ef5e89d609f1        6 months ago        39.62 MB
</span><span class='line'>gcr.io/google_containers/kube2sky-amd64               1.15                f93305484d65        10 months ago       29.16 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                   2.2.5               a6752fb962b5        10 months ago       30.45 MB
</span><span class='line'>gcr.io/google_containers/skydns-amd64                 1.0                 a925f95d080a        11 months ago       15.57 MB
</span><span class='line'>gcr.io/google_containers/exechealthz-amd64            1.0                 5b9ac190b20c        11 months ago       7.116 MB
</span><span class='line'>gcr.io/google_containers/pause                        2.0                 9981ca1bbdb5        17 months ago       350.2 kB
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>etcd，flannel，和kubernetes-dashboard用的是docker-multinode时的版本。</li>
<li>kubelet是1.2的最新版v1.2.7。</li>
<li>pause:2.0是启动apiserver、controller容器时自动下载的版本。</li>
<li>新增DNS镜像（2017-3-6 02:07:14）</li>
<li>新增heapster镜像（2017-3-6 17:00:48）</li>
</ul>


<p>最好每台机器都load所有镜像。</p>

<h2>准备</h2>

<ul>
<li>安装docker，<a href="https://wiki.centos.org/zh/Cloud/Docker">Docker</a> <a href="http://winseliu.com/blog/2014/09/27/docker-start-guide-on-centos/">Docker入门</a></li>
<li>代理，<a href="http://winseliu.com/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks/">Privoxy</a></li>
<li>镜像导入导出，<a href="http://winseliu.com/blog/2017/02/06/docker-http-proxy-and-save-reload/">Docker save/load</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8"
</span><span class='line'>export https_proxy=http://localhost:8118/
</span><span class='line'>export http_proxy=http://localhost:8118/</span></code></pre></td></tr></table></div></figure>


<h2>先看操作和效果（看了菜单再看吃不吃）</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 下载部署脚本 
</span><span class='line'># https://github.com/winse/docker-hadoop/tree/master/k8s-centos6/docker-multinode
</span><span class='line'>
</span><span class='line'>## 防火墙，关闭selinux
</span><span class='line'># 或者最后面增加 iptables -A INPUT -s 10.0.0.0/8 -j ACCEPT
</span><span class='line'>iptables -I INPUT 1 -s 10.0.0.0/8 -j ACCEPT
</span><span class='line'>
</span><span class='line'>## 先把镜像全部下载下来 git pull ...
</span><span class='line'>* 在master节点
</span><span class='line'>[root@cu2 ~]# docker images
</span><span class='line'>REPOSITORY                                            TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
</span><span class='line'>bigdata                                               v1                  9e30d146824b        2 days ago          457.2 MB
</span><span class='line'>redis                                                 3.2.8               c30a7507ec4d        6 days ago          182.9 MB
</span><span class='line'>gcr.io/google_containers/heapster-grafana-amd64       v4.0.2              74d2c72849cc        6 weeks ago         131.5 MB
</span><span class='line'>gcr.io/google_containers/heapster-influxdb-amd64      v1.1.1              55d63942e2eb        6 weeks ago         11.59 MB
</span><span class='line'>gcr.io/google_containers/heapster-amd64               v1.3.0-beta.1       026fb02eca65        6 weeks ago         101.3 MB
</span><span class='line'>gcr.io/google_containers/kubernetes-dashboard-amd64   v1.5.1              9af7d5c61ccf        7 weeks ago         103.6 MB
</span><span class='line'>gcr.io/google_containers/hyperkube-amd64              v1.2.7              1dd7250ed1b3        4 months ago        231.4 MB
</span><span class='line'>quay.io/coreos/flannel                                v0.6.1-amd64        ef86f3a53de0        6 months ago        27.89 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                   3.0.4               ef5e89d609f1        6 months ago        39.62 MB
</span><span class='line'>gcr.io/google_containers/kube2sky-amd64               1.15                f93305484d65        10 months ago       29.16 MB
</span><span class='line'>gcr.io/google_containers/etcd-amd64                   2.2.5               a6752fb962b5        10 months ago       30.45 MB
</span><span class='line'>gcr.io/google_containers/skydns-amd64                 1.0                 a925f95d080a        11 months ago       15.57 MB
</span><span class='line'>gcr.io/google_containers/exechealthz-amd64            1.0                 5b9ac190b20c        11 months ago       7.116 MB
</span><span class='line'>gcr.io/google_containers/pause                        2.0                 9981ca1bbdb5        17 months ago       350.2 kB
</span><span class='line'>
</span><span class='line'>## 下载kubectl
</span><span class='line'>https://storage.googleapis.com/kubernetes-release/release/v1.2.7/bin/linux/amd64/kubectl 
</span><span class='line'># https://kubernetes.io/docs/user-guide/prereqs/
</span><span class='line'># https://kubernetes.io/docs/user-guide/kubectl/kubectl_version/
</span><span class='line'>
</span><span class='line'>## 环境变量
</span><span class='line'># https://kubernetes.io/docs/user-guide/kubeconfig-file/
</span><span class='line'>export KUBECONFIG=/var/lib/kubelet/kubeconfig/kubeconfig.yaml
</span><span class='line'>export PATH=...加kubectl所在文件夹
</span><span class='line'>
</span><span class='line'>## 启动MASTER
</span><span class='line'>./master.sh
</span><span class='line'>
</span><span class='line'>## 测试效果
</span><span class='line'>curl -fsSL http://localhost:2379/health
</span><span class='line'>curl -s http://localhost:8080/healthz
</span><span class='line'>curl -s http://localhost:8080/api
</span><span class='line'>kubectl get ns
</span><span class='line'>kubectl create namespace kube-system
</span><span class='line'>
</span><span class='line'>* 在worker节点
</span><span class='line'>[root@cu3 ~]# docker images
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>## 启动WORKER
</span><span class='line'>MASTER_IP=cu2 ./worker.sh
</span></code></pre></td></tr></table></div></figure>


<p>小状况：在第一次启动master脚本可能会有点问题：setup-files容器运行可能不正常，需要从googleapi下载easy-rsa.tar.gz，可以先手动下载到/root/kube目录，然后运行setup-files。sh脚本。如果不急的话等上一段时间多run几次后好像也能跑起来（囧）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# docker exec -ti kube_kubelet_624b2 bash
</span><span class='line'>root@cu2:/# /setup-files.sh IP:10.0.0.1,DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc,DNS:kubernetes.default.svc.cluster.local
</span><span class='line'>
</span><span class='line'>然后再次提交dashboard：
</span><span class='line'>[root@cu2 docker-multinode-centos6]# ./dashboard.sh 
</span></code></pre></td></tr></table></div></figure>


<p>然后启动应用，测试多节点的情况下启动的容器网络能否互通：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 运行查看容器
</span><span class='line'>[root@cu2 ~]# kubectl run redis --image=bigdata:v1 -r 5 --command -- /usr/sbin/sshd -D
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o wide
</span><span class='line'>NAME                       READY     STATUS    RESTARTS   AGE       NODE
</span><span class='line'>k8s-master-192.168.0.214   4/4       Running   22         1h        192.168.0.214
</span><span class='line'>k8s-proxy-192.168.0.214    1/1       Running   0          1h        192.168.0.214
</span><span class='line'>redis-2212193268-1789v     1/1       Running   0          1h        192.168.0.174
</span><span class='line'>redis-2212193268-1j4ej     1/1       Running   0          1h        192.168.0.174
</span><span class='line'>redis-2212193268-8dbmq     1/1       Running   0          1h        192.168.0.30
</span><span class='line'>redis-2212193268-a447n     1/1       Running   0          1h        192.168.0.30
</span><span class='line'>redis-2212193268-tu5fl     1/1       Running   0          1h        192.168.0.214
</span><span class='line'>
</span><span class='line'>https://kubernetes.io/docs/user-guide/jsonpath/
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o wide -l run=redis -o jsonpath={..podIP}
</span><span class='line'>10.1.75.2 10.1.75.3 10.1.58.3 10.1.58.2 10.1.33.3
</span><span class='line'>
</span><span class='line'>## 登录容器
</span><span class='line'># 用ssh登录
</span><span class='line'>[root@cu2 ~]# kubectl describe pods redis-2212193268-tu5fl | grep IP
</span><span class='line'>IP:             10.1.33.3
</span><span class='line'>[root@cu2 ~]# ssh 10.1.33.3
</span><span class='line'>The authenticity of host '10.1.33.3 (10.1.33.3)' can't be established.
</span><span class='line'>RSA key fingerprint is e5:58:ae:3b:54:c9:bb:0d:4c:9b:bc:fd:04:fe:be:cc.
</span><span class='line'>Are you sure you want to continue connecting (yes/no)? yes
</span><span class='line'>Warning: Permanently added '10.1.33.3' (RSA) to the list of known hosts.
</span><span class='line'>root@10.1.33.3's password: 
</span><span class='line'>Last login: Sat Mar  4 18:17:51 2017 from 10.1.61.1
</span><span class='line'>[root@redis-2212193268-tu5fl ~]# exit
</span><span class='line'>logout
</span><span class='line'>Connection to 10.1.33.3 closed.
</span><span class='line'>
</span><span class='line'># exec登录
</span><span class='line'>[root@cu2 ~]# kubectl exec -ti redis-2212193268-tu5fl bash
</span><span class='line'>[root@redis-2212193268-tu5fl /]# 
</span><span class='line'>
</span><span class='line'>## ping五台机器全部节点的机器都是互通的
</span><span class='line'>[root@redis-2212193268-tu5fl /]# ping 10.1.75.2
</span><span class='line'>PING 10.1.75.2 (10.1.75.2) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.1.75.2: icmp_seq=1 ttl=60 time=1.15 ms
</span><span class='line'>...
</span><span class='line'>[root@redis-2212193268-tu5fl /]# ping 10.1.75.3
</span><span class='line'>PING 10.1.75.3 (10.1.75.3) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.1.75.3: icmp_seq=1 ttl=60 time=1.23 ms
</span><span class='line'>...
</span><span class='line'>[root@redis-2212193268-tu5fl /]# ping 10.1.58.3
</span><span class='line'>PING 10.1.58.3 (10.1.58.3) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.1.58.3: icmp_seq=1 ttl=60 time=1.60 ms
</span><span class='line'>...
</span><span class='line'>[root@redis-2212193268-tu5fl /]# ping 10.1.58.2
</span><span class='line'>PING 10.1.58.2 (10.1.58.2) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.1.58.2: icmp_seq=1 ttl=60 time=1.39 ms
</span><span class='line'>...
</span><span class='line'>[root@redis-2212193268-tu5fl /]# ping 10.1.33.3         
</span><span class='line'>PING 10.1.33.3 (10.1.33.3) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.1.33.3: icmp_seq=1 ttl=64 time=0.036 ms
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>全部启动好后dashboard的效果图：</p>

<p><img src="http://winseliu.com/images/blogs/k8s-dashboard.jpg" alt="" /></p>

<h2>从脚本中学习</h2>

<p>官网这份<a href="https://kubernetes.io/docs/getting-started-guides/scratch/#starting-cluster-services">Creating a Custom Cluster from Scratch</a> 看的糊里糊涂，真不是给入门级的同学看的。需要有一定的实践经验才能看的懂。</p>

<p>另辟蹊径，根据docker-multi的启动脚本来拆分学习然后模拟动手实践。在根据 <a href="https://kubernetes.io/docs/getting-started-guides/docker-multinode/">Portable Multi-Node Cluster</a> 文档学习操作的时刻不理解bootstrap docker以及main docker的含义。</p>

<p>这次通过单独运行提取每个函数运行后才理解，其实就相当于跑两个docker应用程序，互相不影响。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# ps aux|grep docker
</span><span class='line'>root      5310  0.0  0.2 645128 19180 pts/1    Sl   13:14   0:01 docker -d -H unix:///var/run/docker-bootstrap.sock -p /var/run/docker-bootstrap.pid --iptables=false --ip-masq=false --bridge=none --graph=/var/lib/docker-bootstrap --exec-root=/var/run/docker-bootstrap
</span><span class='line'>root      5782  1.1  0.5 2788284 43620 pts/1   Sl   13:14   0:23 /usr/bin/docker -d --mtu=1464 --bip=10.1.33.1/24
</span><span class='line'>root     10935  0.0  0.0 103316   896 pts/1    S+   13:47   0:00 grep docker
</span></code></pre></td></tr></table></div></figure>


<p>bootstrap docker启动后，容器etcd和flannel启动都很顺利。</p>

<p>以下的问题都是在自己虚拟机试，弄好后再放到测试环境的。</p>

<ul>
<li>问题1： 执行docker0网卡重置失败</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bigdata1 data]# ip link set docker0 down
</span><span class='line'>[root@bigdata1 data]# ip link del docker0
</span><span class='line'>RTNETLINK answers: Operation not supported
</span><span class='line'>
</span><span class='line'>[root@bigdata1 data]# ip addr 
</span><span class='line'>
</span><span class='line'>删不掉，但是可以修改ip地址来实现相似的效果
</span><span class='line'>
</span><span class='line'>ifconfig docker0 ${FLANNEL_SUBNET}
</span><span class='line'>或者 
</span><span class='line'>[root@bigdata1 data]# ip link set dev docker0 mtu 1460
</span><span class='line'>[root@bigdata1 data]# ip addr del 172.17.42.1/16 dev docker0
</span><span class='line'>[root@bigdata1 data]# ip addr add ${FLANNEL_SUBNET} dev docker0
</span><span class='line'>[root@bigdata1 data]# ip link set dev docker0 up
</span><span class='line'>[root@bigdata1 data]# ifconfig # 查看重新分配的IP
</span><span class='line'>
</span><span class='line'>先添加参数在前端运行
</span><span class='line'>[root@bigdata1 data]# docker -d --mtu=1472 --bip=10.1.42.1/24
</span><span class='line'>
</span><span class='line'>启动
</span><span class='line'>[root@bigdata1 data]# sed -i 's/other_args=/other_args="--mtu=1472 --bip=10.1.42.1/24"/' /etc/sysconfig/docker
</span><span class='line'>[root@bigdata1 data]# service docker start
</span><span class='line'>Starting docker:                                           [确定]
</span><span class='line'>[root@bigdata1 data]# service docker status
</span><span class='line'>docker (pid  4542) 正在运行...</span></code></pre></td></tr></table></div></figure>


<ul>
<li>问题2：volumns mount不支持shared</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bigdata1 data]# echo $KUBELET_MOUNTS
</span><span class='line'>-v /sys:/sys:rw -v /var/run:/var/run:rw -v /run:/run:rw -v /var/lib/docker:/var/lib/docker:rw -v /var/lib/kubelet:/var/lib/kubelet:shared -v /var/log/containers:/var/log/containers:rw
</span><span class='line'>
</span><span class='line'>[root@bigdata1 data]# mkdir -p /var/lib/kubelet
</span><span class='line'>[root@bigdata1 data]# mount --bind /var/lib/kubelet /var/lib/kubelet
</span><span class='line'>[root@bigdata1 data]# mount --make-shared /var/lib/kubelet
</span><span class='line'>
</span><span class='line'>[root@bigdata1 data]# docker run -d \
</span><span class='line'>&gt;     --net=host \
</span><span class='line'>&gt;     --pid=host \
</span><span class='line'>&gt;     --privileged \
</span><span class='line'>&gt;     --name kube_kubelet_$(kube::helpers::small_sha) \
</span><span class='line'>&gt;     ${KUBELET_MOUNTS} \
</span><span class='line'>&gt;     gcr.io/google_containers/hyperkube-${ARCH}:${K8S_VERSION} \
</span><span class='line'>&gt;     /hyperkube kubelet \
</span><span class='line'>&gt;       --allow-privileged \
</span><span class='line'>&gt;       --api-servers=http://localhost:8080 \
</span><span class='line'>&gt;       --config=/etc/kubernetes/manifests-multi \
</span><span class='line'>&gt;       --cluster-dns=10.0.0.10 \
</span><span class='line'>&gt;       --cluster-domain=cluster.local \
</span><span class='line'>&gt;       ${CNI_ARGS} \
</span><span class='line'>&gt;       ${CONTAINERIZED_FLAG} \
</span><span class='line'>&gt;       --hostname-override=${IP_ADDRESS} \
</span><span class='line'>&gt;       --v=2
</span><span class='line'>Error response from daemon: invalid mode for volumes-from: shared
</span><span class='line'>
</span><span class='line'># 改成z -- 2017-3-16 19:15:57不支持shared，后面会遇到volume的问题！
</span><span class='line'>    KUBELET_MOUNT="-v /var/lib/kubelet:/var/lib/kubelet:z"
</span><span class='line'>  
</span><span class='line'>[root@bigdata1 ~]# echo $KUBELET_MOUNTS
</span><span class='line'>-v /sys:/sys:rw -v /var/run:/var/run:rw -v /run:/run:rw -v /var/lib/docker:/var/lib/docker:rw -v /var/lib/kubelet:/var/lib/kubelet:z -v /var/log/containers:/var/log/containers:rw</span></code></pre></td></tr></table></div></figure>


<ul>
<li>问题3：cgroup问题</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Error: failed to run Kubelet: failed to get mounted cgroup subsystems: failed to find cgroup mounts
</span><span class='line'>failed to run Kubelet: failed to get mounted cgroup subsystems: failed to find cgroup mounts
</span><span class='line'>
</span><span class='line'>centos7 
</span><span class='line'>[root@k8s docker.service.d]# ll /sys/fs/cgroup/
</span><span class='line'>blkio/            cpuacct/          cpuset/           freezer/          memory/           net_cls,net_prio/ perf_event/       systemd/          
</span><span class='line'>cpu/              cpu,cpuacct/      devices/          hugetlb/          net_cls/          net_prio/         pids/             
</span><span class='line'>
</span><span class='line'>centos6
</span><span class='line'>http://wushank.blog.51cto.com/3489095/1203545
</span><span class='line'>[root@bigdata1 bin]# ls /cgroup/
</span><span class='line'>blkio  cpu  cpuacct  cpuset  devices  freezer  memory  net_cls
</span><span class='line'>
</span><span class='line'>把/cgroup加入到卷映射路径
</span><span class='line'>  KUBELET_MOUNTS="\
</span><span class='line'>    ${ROOTFS_MOUNT} \
</span><span class='line'>    -v /sys:/sys:rw \
</span><span class='line'>    -v /cgroup:/cgroup:rw \
</span><span class='line'>    -v /var/run:/var/run:rw \
</span><span class='line'>    -v /run:/run:rw \
</span><span class='line'>    -v /var/lib/docker:/var/lib/docker:rw \
</span><span class='line'>    ${KUBELET_MOUNT} \
</span><span class='line'>    -v /var/log/containers:/var/log/containers:rw"</span></code></pre></td></tr></table></div></figure>


<ul>
<li>问题4：再说版本，v1.3+的版本在centos6上运行kubelet报错：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bigdata1 ~]# docker logs 7a2f7aec2239
</span><span class='line'>...
</span><span class='line'>E0228 10:56:05.408129    2516 kubelet.go:2049] Container runtime sanity check failed: container runtime version is older than 1.21</span></code></pre></td></tr></table></div></figure>


<p>1.3以上的版本都会报这个错。kubernetes用1.2.7的版本即可。</p>

<ul>
<li><p>问题5：dashboard/dns配置注意点</p></li>
<li><p>imagePullPolicy 就是个坑啊！改成IfNotPresent <a href="https://kubernetes.io/docs/user-guide/images/">https://kubernetes.io/docs/user-guide/images/</a></p></li>
<li>namespace 也不能改，好像会写数据库然后指定的namespace就是kube-system</li>
<li>apiserver 由于没有addon-manager的支持，暂时使用http获取数据（DNS的问题确认了很久，kube2sky容器日志有报错，修改server地址为http方式才解决）</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 docker-multinode-centos6]# docker exec -ti 193863bc646b bash
</span><span class='line'>[root@redis-2212193268-0ovu7 /]# nslookup kubernetes.default
</span><span class='line'>Server:         10.0.0.10
</span><span class='line'>Address:        10.0.0.10#53
</span><span class='line'>
</span><span class='line'>Name:   kubernetes.default.svc.cluster.local
</span><span class='line'>Address: 10.0.0.1</span></code></pre></td></tr></table></div></figure>


<p>处理完以上问题，K8S集群就跑起来了，然后整合成开始用的脚本。当然后续还有很多工作，不仅仅是怎么用，还有一些其他辅助的软件需要配置和安装。</p>

<h2>监控</h2>

<ul>
<li><a href="https://kubernetes.io/docs/user-guide/monitoring/">Resource Usage Monitoring</a></li>
<li><a href="https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md">Run Heapster in a Kubernetes cluster with an InfluxDB backend and a Grafana UI</a></li>
<li><a href="http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/">Kubernetes集群性能监控&ndash;Heapster</a></li>
<li><a href="http://www.pangxie.space/docker/727">Kubernetes部署监控(Heapster+Influxdb+Grafana)-centos7</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>可以通过4194访问cAdvisor  &lt;http://www.dockone.io/article/page-46&gt;
</span><span class='line'>http://cu2:4194/containers/
</span><span class='line'>
</span><span class='line'>[root@cu2 influxdb]# kubectl create -f ./
</span><span class='line'>deployment "monitoring-grafana" created
</span><span class='line'>service "monitoring-grafana" created
</span><span class='line'>deployment "heapster" created
</span><span class='line'>service "heapster" created
</span><span class='line'>deployment "monitoring-influxdb" created
</span><span class='line'>service "monitoring-influxdb" created
</span><span class='line'>
</span><span class='line'>[root@cu2 influxdb]# kubectl get pods --namespace=kube-system -o wide
</span><span class='line'>NAME                                    READY     STATUS             RESTARTS   AGE       NODE
</span><span class='line'>heapster-2621086088-s77cl               0/1       CrashLoopBackOff   2          37s       192.168.0.148
</span><span class='line'>kube-dns-v8-00p5h                       4/4       Running            1          5h        192.168.0.174
</span><span class='line'>kubernetes-dashboard-2845140353-l7o8o   1/1       Running            0          5h        192.168.0.30
</span><span class='line'>monitoring-grafana-1501214244-kw3im     1/1       Running            0          37s       192.168.0.148
</span><span class='line'>monitoring-influxdb-3498630124-241tx    1/1       Running            0          37s       192.168.0.30
</span><span class='line'>
</span><span class='line'>第一次启动heapster失败，定位机器查看日志
</span><span class='line'>[root@cu3 ~]# docker logs aad68dd07ff8
</span><span class='line'>I0306 09:06:25.611251       1 heapster.go:71] /heapster --source=kubernetes:https://kubernetes.default --sink=influxdb:http://monitoring-influxdb:8086
</span><span class='line'>I0306 09:06:25.611523       1 heapster.go:72] Heapster version v1.3.0-beta.1
</span><span class='line'>F0306 09:06:25.611555       1 heapster.go:174] Failed to create source provide: open /var/run/secrets/kubernetes.io/serviceaccount/token: no such file or directory
</span><span class='line'>
</span><span class='line'>https://github.com/kubernetes/heapster/blob/master/docs/source-configuration.md 改成http
</span><span class='line'>
</span><span class='line'>重新加载
</span><span class='line'>[root@cu2 influxdb]# for file in * ; do sed -e "s|MASTER_IP|${IP_ADDRESS}|g" $file | kubectl apply -f - ; done
</span><span class='line'>deployment "monitoring-grafana" configured
</span><span class='line'>service "monitoring-grafana" configured
</span><span class='line'>deployment "heapster" configured
</span><span class='line'>service "heapster" configured
</span><span class='line'>deployment "monitoring-influxdb" configured
</span><span class='line'>service "monitoring-influxdb" configured
</span><span class='line'>
</span><span class='line'>[root@cu2 influxdb]# kubectl get service --namespace=kube-system -o wide
</span><span class='line'>NAME                   CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE       SELECTOR
</span><span class='line'>heapster               10.0.0.54    &lt;none&gt;        80/TCP          8m        k8s-app=heapster
</span><span class='line'>kube-dns               10.0.0.10    &lt;none&gt;        53/UDP,53/TCP   6h        k8s-app=kube-dns
</span><span class='line'>kubernetes-dashboard   10.0.0.181   nodes         80/TCP          6h        app=kubernetes-dashboard
</span><span class='line'>monitoring-grafana     10.0.0.220   &lt;none&gt;        80/TCP          8m        k8s-app=grafana
</span><span class='line'>monitoring-influxdb    10.0.0.223   &lt;none&gt;        8086/TCP        8m        k8s-app=influxdb
</span><span class='line'>
</span><span class='line'>浏览器访问grafana 登录：admin/admin
</span><span class='line'>http://10.0.0.220/
</span></code></pre></td></tr></table></div></figure>


<p>安装好监控后，dashboard也有图标了。</p>

<p><img src="http://winseliu.com/images/blogs/k8s-dashboard-pro.jpg" alt="" /></p>

<h4>某机器数据不显示问题定位</h4>

<p>原来是三台机器的，后面增加了148的机器进来。添加heapster监控后，就148机器图形显示不出来。并且dashboard的 148 Node 页面的 <strong> Conditions - Last heartbeat time </strong> 没显示内容。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# kubectl get services --all-namespaces
</span><span class='line'>NAMESPACE     NAME                   CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
</span><span class='line'>default       kubernetes             10.0.0.1     &lt;none&gt;        443/TCP         1d
</span><span class='line'>kube-system   heapster               10.0.0.196   &lt;none&gt;        80/TCP          12m
</span><span class='line'>kube-system   kube-dns               10.0.0.10    &lt;none&gt;        53/UDP,53/TCP   21h
</span><span class='line'>kube-system   kubernetes-dashboard   10.0.0.181   nodes         80/TCP          21h
</span><span class='line'>kube-system   monitoring-grafana     10.0.0.215   &lt;none&gt;        80/TCP          12m
</span><span class='line'>kube-system   monitoring-influxdb    10.0.0.226   &lt;none&gt;        8086/TCP        12m
</span><span class='line'>
</span><span class='line'>查看接口
</span><span class='line'>https://github.com/kubernetes/heapster/blob/master/docs/debugging.md
</span><span class='line'>
</span><span class='line'>  http://10.0.0.196/metrics
</span><span class='line'>
</span><span class='line'>  这里没有148机器的key
</span><span class='line'>  http://10.0.0.196/api/v1/model/debug/allkeys
</span><span class='line'>
</span><span class='line'>  http://192.168.0.30:10255/stats/container/
</span><span class='line'>
</span><span class='line'>https://github.com/kubernetes/heapster/blob/master/docs/sink-configuration.md
</span><span class='line'>
</span><span class='line'>等到heapster机器运行命令，改下端口，日志输出详细点
</span><span class='line'>/ # /heapster --source=kubernetes:http://192.168.0.214:8080?inClusterConfig=false --sink=log --heapster-port=8083 -v 10
</span><span class='line'>
</span><span class='line'>  http://192.168.0.214:8080/api/v1/nodes
</span><span class='line'>  Node
</span><span class='line'>  Pod
</span><span class='line'>  Namespace
</span><span class='line'>  
</span><span class='line'>148机器的10255和4194端口都正常运行，heapster从148也获取到数据了。但是最后log输出的时刻没有148机器。系统时间？抱着尝试的心态改了一下，148的机器快了几分钟。
</span><span class='line'>
</span><span class='line'>果不其然啊！！同步时间后监控图就显示出来了。</span></code></pre></td></tr></table></div></figure>


<h2>后续学习操作</h2>

<ul>
<li>安全HTTPS <a href="https://kubernetes.io/docs/admin/authentication/#creating-certificates">https://kubernetes.io/docs/admin/authentication/#creating-certificates</a></li>
<li>register <a href="http://www.pangxie.space/docker/643">http://www.pangxie.space/docker/643</a> k8s版本旧的话很麻烦</li>
<li><a href="https://kubernetes.io/docs/tasks/">https://kubernetes.io/docs/tasks/</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/blob/release-1.2/examples/redis/redis-controller.yaml">https://github.com/kubernetes/kubernetes/blob/release-1.2/examples/redis/redis-controller.yaml</a></li>
</ul>


<p>阿里云的镜像加速还是很赞的，由于我域名是在万网注册的本来就有账号，登录就能看到加速的地址，非常的方便。科技大学的加速镜像也很赞！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu1 ~]# cat /etc/sysconfig/docker
</span><span class='line'>...
</span><span class='line'>#other_args=" --registry-mirror=https://us69kjun.mirror.aliyuncs.com "
</span><span class='line'>other_args=" --registry-mirror=https://docker.mirrors.ustc.edu.cn "
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>有趣的命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>https://kubernetes.io/docs/user-guide/jsonpath/
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o wide -l run=redis -o jsonpath={..podIP}
</span><span class='line'>10.1.75.2 10.1.75.3 10.1.58.3 10.1.58.2 10.1.33.3
</span><span class='line'>
</span><span class='line'>修改启动entry，以及网络共用
</span><span class='line'>docker run -ti --entrypoint=sh --net=container:8e9f21956469f4ef7e5b9d91798788ab83f380795d2825cdacae0ed28f5ba03b gcr.io/google_containers/skydns-amd64:1.0
</span><span class='line'>
</span><span class='line'>https://kubernetes.io/docs/tasks/kubectl/list-all-running-container-images/
</span><span class='line'>[root@cu2 ~]# kubectl get pods --all-namespaces -o jsonpath="{..image}" |\
</span><span class='line'>&gt; tr -s '[[:space:]]' '\n' |\
</span><span class='line'>&gt; sort |\
</span><span class='line'>&gt; uniq -c
</span><span class='line'>      2 gcr.io/google_containers/etcd-amd64:2.2.5
</span><span class='line'>      2 gcr.io/google_containers/exechealthz-amd64:1.0
</span><span class='line'>      2 gcr.io/google_containers/heapster-amd64:v1.3.0-beta.1
</span><span class='line'>      2 gcr.io/google_containers/heapster-grafana-amd64:v4.0.2
</span><span class='line'>      2 gcr.io/google_containers/heapster-influxdb-amd64:v1.1.1
</span><span class='line'>     10 gcr.io/google_containers/hyperkube-amd64:v1.2.7
</span><span class='line'>      2 gcr.io/google_containers/kube2sky-amd64:1.15
</span><span class='line'>      2 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.1
</span><span class='line'>      2 gcr.io/google_containers/skydns-amd64:1.0
</span><span class='line'>      2 redis:3.2.8
</span><span class='line'>
</span><span class='line'>kubectl get pods --all-namespaces -o jsonpath="{.items[*].spec.containers[*].image}"
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# export POD_COL="custom-columns=NAME:.metadata.name,RESTARTS:.status.containerStatuses[*].restartCount,CONTAINERS:.spec.containers[*].name,IP:.status.podIP,HOST:.spec.nodeName"
</span><span class='line'>[root@cu2 ~]# kubectl get pods -o $POD_COL 
</span><span class='line'>
</span><span class='line'># 加label
</span><span class='line'>[root@cu2 ~]# cat /etc/hosts | grep -E "\scu[0-9]\s" | awk '{print "kubectl label nodes "$1" hostname="$2}' | while read line ; do sh -c "$line" ; done
</span><span class='line'>
</span><span class='line'>[root@cu2 kubernetes]# kubectl run redis --image=redis:3.2.8 
</span><span class='line'>[root@cu2 kubernetes]# kubectl scale --replicas=9 deployment/redis</span></code></pre></td></tr></table></div></figure>


<h2>其他参考</h2>

<p>纯手动安装，所有应用都作为服务启动
* <a href="http://chenguomin.blog.51cto.com/8794192/1828905">http://chenguomin.blog.51cto.com/8794192/1828905</a> 网络使用flannel、DNS的安装配置
* <a href="http://www.pangxie.space/docker/618">http://www.pangxie.space/docker/618</a>
* <a href="https://xuxinkun.github.io/2016/03/27/k8s-service/">https://xuxinkun.github.io/2016/03/27/k8s-service/</a> service是在防火墙做的跳转 => iptables -S -t nat</p>

<p>介绍
* <a href="http://www.infoq.com/cn/articles/kubernetes-and-cloud-native-applications-part01">http://www.infoq.com/cn/articles/kubernetes-and-cloud-native-applications-part01</a>
* <a href="http://www.codingwater.org/2016/08/25/Docker-Kubernetes-Intro/">http://www.codingwater.org/2016/08/25/Docker-Kubernetes-Intro/</a>
* <a href="https://github.com/kubernetes/kubernetes/tree/v1.0.1/cluster/addons/dns">https://github.com/kubernetes/kubernetes/tree/v1.0.1/cluster/addons/dns</a></p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s集群部署]]></title>
    <link href="http://winseliu.com/blog/2017/02/25/k8s-docker-multinode/"/>
    <updated>2017-02-25T13:25:26+00:00</updated>
    <id>http://winseliu.com/blog/2017/02/25/k8s-docker-multinode</id>
    <content type="html"><![CDATA[<p>前面讲了在本机windows安装方式，最近在linux多机器上尝试部署并操作。</p>

<p>先看官网的文档<a href="https://kubernetes.io/docs/getting-started-guides/docker-multinode/">Portable Multi-Node Cluster</a>。这里根据文章进行实际操作记录下来，k8s是真的好用管理起来很方便。</p>

<h2>安装docker（on centos7）</h2>

<h4>不正确的打开方式</h4>

<p>不要用这种方式安装</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install docker
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker -v
</span><span class='line'>Docker version 1.12.5, build 047e51b/1.12.5</span></code></pre></td></tr></table></div></figure>


<p>否则运行报错的daemon语句，报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s docker-multinode]# docker daemon -H unix:///var/run/docker-bootstrap.sock -p /var/run/docker-bootstrap.pid --iptables=false --ip-masq=false --bridge=none --graph=/var/lib/docker-bootstrap --exec-root=/var/run/docker-bootstrap
</span><span class='line'>exec: "dockerd": executable file not found in $PATH</span></code></pre></td></tr></table></div></figure>


<p>先清理旧的软件</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum remove docker -y
</span><span class='line'>yum remove container-selinux -y
</span><span class='line'>yum remove docker-common -y</span></code></pre></td></tr></table></div></figure>


<h4>安装docker的正确姿势</h4>

<ul>
<li><a href="https://docs.docker.com/engine/installation/linux/centos/">Get Docker for CentOS</a></li>
</ul>


<p>变化很快，直接按官网的操作。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# yum install -y yum-utils
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# yum-config-manager --add-repo https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo
</span><span class='line'>Loaded plugins: fastestmirror, langpacks
</span><span class='line'>Repository base is listed more than once in the configuration
</span><span class='line'>Repository updates is listed more than once in the configuration
</span><span class='line'>Repository extras is listed more than once in the configuration
</span><span class='line'>Repository centosplus is listed more than once in the configuration
</span><span class='line'>adding repo from: https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo
</span><span class='line'>grabbing file https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo to /etc/yum.repos.d/docker.repo
</span><span class='line'>repo saved to /etc/yum.repos.d/docker.repo
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# yum makecache fast
</span><span class='line'>[root@k8s ~]# yum -y install docker-engine
</span><span class='line'>
</span><span class='line'># 把保存数据的目录转移到大磁盘下面去
</span><span class='line'>先启动服务来产生docker目录
</span><span class='line'>[root@k8s ~]# service docker start
</span><span class='line'>[root@k8s ~]# service docker stop
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# rm -rf /var/lib/docker/
</span><span class='line'>[root@k8s ~]# ln -s /data/var/lib/docker /var/lib/</span></code></pre></td></tr></table></div></figure>


<h2>安装k8s</h2>

<ul>
<li><a href="https://kubernetes.io/docs/getting-started-guides/docker-multinode/">Portable Multi-Node Cluster</a></li>
</ul>


<h4>准备</h4>

<ul>
<li><a href="https://kubernetes.io/docs/user-guide/prereqs/">Installing and Setting up kubectl</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/kubectl/">https://kubernetes.io/docs/getting-started-guides/kubectl/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 删除旧的容器
</span><span class='line'>[root@k8s docker-multinode]# docker rm -f `docker ps -a | grep -v IMAGE | awk '{print $1}'`
</span><span class='line'>[root@k8s docker-multinode]# docker ps -a
</span><span class='line'>
</span><span class='line'># 下载部署的工具
</span><span class='line'>[root@k8s ~]# yum install git -y
</span><span class='line'>[root@k8s ~]# git clone https://github.com/kubernetes/kube-deploy
</span><span class='line'>
</span><span class='line'># kubectl安装，需要代理你懂得 
</span><span class='line'>export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8"
</span><span class='line'>export https_proxy=http://k8s:8118/
</span><span class='line'>export http_proxy=http://k8s:8118/
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
</span><span class='line'>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
</span><span class='line'>                                 Dload  Upload   Total   Spent    Left  Speed
</span><span class='line'>100 48.0M  100 48.0M    0     0  1692k      0  0:00:29  0:00:29 --:--:-- 2351k
</span><span class='line'>[root@k8s ~]# chmod +x kubectl 
</span><span class='line'>[root@k8s ~]# mkdir ~/bin
</span><span class='line'>[root@k8s ~]# mv ./kubectl ~/bin/
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# source &lt;(kubectl completion bash)
</span><span class='line'>[root@k8s ~]# echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc
</span><span class='line'>== 修改成下面的语句，不然你scp、rsync就不能用了: https://my.oschina.net/leejun2005/blog/342865
</span><span class='line'>== export PATH=~/bin:$PATH
</span><span class='line'>== [[ $- == *i* ]] && source &lt;(kubectl completion bash)
</span></code></pre></td></tr></table></div></figure>


<h4>启动master</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# cd kube-deploy/docker-multinode/
</span><span class='line'>[root@k8s docker-multinode]# ./master.sh 
</span><span class='line'>+++ [0206 19:07:23] K8S_VERSION is set to: v1.5.2
</span><span class='line'>+++ [0206 19:07:23] ETCD_VERSION is set to: 3.0.4
</span><span class='line'>+++ [0206 19:07:23] FLANNEL_VERSION is set to: v0.6.1
</span><span class='line'>+++ [0206 19:07:23] FLANNEL_IPMASQ is set to: true
</span><span class='line'>+++ [0206 19:07:23] FLANNEL_NETWORK is set to: 10.1.0.0/16
</span><span class='line'>+++ [0206 19:07:23] FLANNEL_BACKEND is set to: udp
</span><span class='line'>+++ [0206 19:07:23] RESTART_POLICY is set to: unless-stopped
</span><span class='line'>+++ [0206 19:07:23] MASTER_IP is set to: localhost
</span><span class='line'>+++ [0206 19:07:23] ARCH is set to: amd64
</span><span class='line'>+++ [0206 19:07:23] IP_ADDRESS is set to: 192.168.1.112
</span><span class='line'>+++ [0206 19:07:23] USE_CNI is set to: false
</span><span class='line'>+++ [0206 19:07:23] USE_CONTAINERIZED is set to: false
</span><span class='line'>+++ [0206 19:07:23] --------------------------------------------
</span><span class='line'>+++ [0206 19:07:23] Killing docker bootstrap...
</span><span class='line'>+++ [0206 19:07:24] Killing all kubernetes containers...
</span><span class='line'>Do you want to clean /var/lib/kubelet? [Y/n] y
</span><span class='line'>+++ [0206 19:07:27] Launching docker bootstrap...
</span><span class='line'>+++ [0206 19:07:28] Launching etcd...
</span><span class='line'>3ff0f0fd7a08282930449b2f496f786b9857f6290698d612cebc2086d1a1765c
</span><span class='line'>+++ [0206 19:07:31] Launching flannel...
</span><span class='line'>{"action":"set","node":{"key":"/coreos.com/network/config","value":"{ \"Network\": \"10.1.0.0/16\", \"Backend\": {\"Type\": \"udp\"}}","modifiedIndex":4,"createdIndex":4}}
</span><span class='line'>3651d077f453900a898ce6ad9fe67a7422f0c8084ec86b6e6a1a2ab6b9b1c629
</span><span class='line'>+++ [0206 19:07:33] FLANNEL_SUBNET is set to: 10.1.42.1/24
</span><span class='line'>+++ [0206 19:07:33] FLANNEL_MTU is set to: 1472
</span><span class='line'>+++ [0206 19:07:33] Restarting main docker daemon...
</span><span class='line'>+++ [0206 19:07:38] Restarted docker with the new flannel settings
</span><span class='line'>+++ [0206 19:07:38] Launching Kubernetes master components...
</span><span class='line'>d10130677853022fe37742437e39b21b3fcfbb90b3f24075457f469e238b0712
</span><span class='line'>+++ [0206 19:07:42] Done. It may take about a minute before apiserver is up.
</span><span class='line'>
</span><span class='line'>[root@k8s docker-multinode]# docker ps -a
</span><span class='line'>...一堆容器列表</span></code></pre></td></tr></table></div></figure>


<p>如果有问题基本就是防火墙的问题（我遇到过的啊，下载镜像和本地firewall设置的问题）。</p>

<p>上面安装kubectl时已经配置了代理地址。如果部署master的时刻pull镜像出错，那还得需要给docker配置代理增加配置 <strong> /etc/systemd/system/docker.service.d/http-proxy.conf </strong> / <strong> /usr/lib/systemd/system/docker.service </strong> 参考 <a href="https://docs.docker.com/engine/admin/systemd/#http-proxy">https://docs.docker.com/engine/admin/systemd/#http-proxy</a> 。具体错误详情及处理查看下面的【问题及处理】部分</p>

<p><strong>安装启动好</strong>后，就可以通过浏览器图形界面来管理集群了(dashboard启动有问题的话查看后面的问题处理)： <a href="http://k8s:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default">http://k8s:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default</a></p>

<h4>启动worker</h4>

<p>下载安装软件的工作这里就不帖了，和master一样的：安装git、clone kube-deploy、docker。</p>

<p>防火墙配置，master/slaves之间互通</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>centos7 firewall的add-source不知道怎么用的，反正加了地址也没效果；后面通过rule规则来实现。
</span><span class='line'>[root@bigdata-dev ~]# vi /etc/firewalld/zones/public.xml
</span><span class='line'>&lt;?xml version="1.0" encoding="utf-8"?&gt;
</span><span class='line'>&lt;zone&gt;
</span><span class='line'>  &lt;rule family="ipv4"&gt;
</span><span class='line'>    &lt;source address="192.168.1.112/32"/&gt;
</span><span class='line'>    &lt;accept/&gt;
</span><span class='line'>  &lt;/rule&gt;
</span><span class='line'>  &lt;service name="ssh"/&gt;
</span><span class='line'>  &lt;port protocol="tcp" port="80"/&gt;
</span><span class='line'>  &lt;port protocol="tcp" port="6379"/&gt;
</span><span class='line'>  &lt;port protocol="tcp" port="8080"/&gt;
</span><span class='line'>&lt;/zone&gt;
</span><span class='line'>[root@bigdata-dev ~]# firewall-cmd --complete-reload
</span><span class='line'>success
</span><span class='line'>[root@bigdata-dev ~]# firewall-cmd --list-all
</span><span class='line'>public (active)
</span><span class='line'>  target: default
</span><span class='line'>  icmp-block-inversion: no
</span><span class='line'>  interfaces: p4p1
</span><span class='line'>  sources: 
</span><span class='line'>  services: ssh
</span><span class='line'>  ports: 80/tcp 6379/tcp 8080/tcp
</span><span class='line'>  protocols: 
</span><span class='line'>  masquerade: no
</span><span class='line'>  forward-ports: 
</span><span class='line'>  sourceports: 
</span><span class='line'>  icmp-blocks: 
</span><span class='line'>  rich rules: 
</span><span class='line'>        rule family="ipv4" source address="192.168.1.112/32" accept
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# cat /etc/firewalld/zones/public.xml
</span><span class='line'>&lt;?xml version="1.0" encoding="utf-8"?&gt;
</span><span class='line'>&lt;zone&gt;
</span><span class='line'>  &lt;rule family="ipv4"&gt;
</span><span class='line'>    &lt;source address="192.168.1.248"/&gt;
</span><span class='line'>    &lt;accept/&gt;
</span><span class='line'>  &lt;/rule&gt;
</span><span class='line'>  &lt;service name="ssh"/&gt;
</span><span class='line'>  &lt;port protocol="tcp" port="6443"/&gt;
</span><span class='line'>  &lt;port protocol="tcp" port="2379"/&gt;
</span><span class='line'>  &lt;port protocol="tcp" port="8118"/&gt;
</span><span class='line'>&lt;/zone&gt;</span></code></pre></td></tr></table></div></figure>


<p>加载已经下载的镜像。从master拷贝过来（save/load）不要浪费VPN流量啦：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bigdata-dev docker-multinode]# docker load &lt;k8s.tar</span></code></pre></td></tr></table></div></figure>


<p>运行worker启动脚本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 设置代理。如果有docker镜像下载失败的话再配置docker环境变量
</span><span class='line'>export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8"
</span><span class='line'>export https_proxy=http://k8s:8118/
</span><span class='line'>export http_proxy=http://k8s:8118/
</span><span class='line'>
</span><span class='line'>[root@bigdata-dev docker-multinode]# export MASTER_IP=192.168.1.112 
</span><span class='line'>[root@bigdata-dev docker-multinode]# ./worker.sh 
</span><span class='line'>+++ [0208 08:59:37] K8S_VERSION is set to: v1.5.2
</span><span class='line'>+++ [0208 08:59:37] ETCD_VERSION is set to: 3.0.4
</span><span class='line'>+++ [0208 08:59:37] FLANNEL_VERSION is set to: v0.6.1
</span><span class='line'>+++ [0208 08:59:37] FLANNEL_IPMASQ is set to: true
</span><span class='line'>+++ [0208 08:59:37] FLANNEL_NETWORK is set to: 10.1.0.0/16
</span><span class='line'>+++ [0208 08:59:37] FLANNEL_BACKEND is set to: udp
</span><span class='line'>+++ [0208 08:59:37] RESTART_POLICY is set to: unless-stopped
</span><span class='line'>+++ [0208 08:59:37] MASTER_IP is set to: 192.168.1.112
</span><span class='line'>+++ [0208 08:59:37] ARCH is set to: amd64
</span><span class='line'>+++ [0208 08:59:37] IP_ADDRESS is set to: 192.168.1.248
</span><span class='line'>+++ [0208 08:59:37] USE_CNI is set to: false
</span><span class='line'>+++ [0208 08:59:37] USE_CONTAINERIZED is set to: false
</span><span class='line'>+++ [0208 08:59:37] --------------------------------------------
</span><span class='line'>+++ [0208 08:59:37] Killing all kubernetes containers...
</span><span class='line'>+++ [0208 08:59:37] Launching docker bootstrap...
</span><span class='line'>+++ [0208 08:59:38] Launching flannel...
</span><span class='line'>+++ [0208 08:59:39] FLANNEL_SUBNET is set to: 10.1.42.1/24
</span><span class='line'>+++ [0208 08:59:39] FLANNEL_MTU is set to: 1472
</span><span class='line'>+++ [0208 08:59:39] Restarting main docker daemon...
</span><span class='line'>+++ [0208 08:59:43] Restarted docker with the new flannel settings
</span><span class='line'>+++ [0208 08:59:43] Launching Kubernetes worker components...
</span><span class='line'>1ce6ee6af709485668c9f170b1bc234b34d55d18e53116295c887c88046ca231
</span><span class='line'>+++ [0208 08:59:44] Done. After about a minute the node should be ready.</span></code></pre></td></tr></table></div></figure>


<h2>查看集群状态</h2>

<p>安装好了后，需要学习基本的管理操作</p>

<ul>
<li>交互式的学习一些基本概念命令 <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Kubernetes Basics</a></li>
<li>常用的kubectl命令册子 <a href="https://kubernetes.io/docs/user-guide/kubectl-cheatsheet/">kubectl Cheat Sheet</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl cluster-info
</span><span class='line'>Kubernetes master is running at http://localhost:8080
</span><span class='line'>KubeDNS is running at http://localhost:8080/api/v1/proxy/namespaces/kube-system/services/kube-dns
</span><span class='line'>kubernetes-dashboard is running at http://localhost:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard
</span><span class='line'>
</span><span class='line'>To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get service
</span><span class='line'>NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
</span><span class='line'>kubernetes   10.0.0.1     &lt;none&gt;        443/TCP   16d
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get nodes
</span><span class='line'>NAME            STATUS    AGE
</span><span class='line'>192.168.1.112   Ready     16d
</span><span class='line'>192.168.1.248   Ready     16d
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods --namespace=kube-system
</span><span class='line'>NAME                                    READY     STATUS    RESTARTS   AGE
</span><span class='line'>k8s-master-192.168.1.112                4/4       Running   9          1d
</span><span class='line'>k8s-proxy-v1-4hp8c                      1/1       Running   0          1d
</span><span class='line'>k8s-proxy-v1-htrrf                      1/1       Running   0          1d
</span><span class='line'>kube-addon-manager-192.168.1.112        2/2       Running   0          1d
</span><span class='line'>kube-dns-4101612645-q0kcw               4/4       Running   0          1d
</span><span class='line'>kubernetes-dashboard-3543765157-hsls9   1/1       Running   0          1d
</span><span class='line'>
</span><span class='line'>dashboard运行正常的话，就可以通过浏览器查看以及管理集群
</span><span class='line'>== https://kubernetes.io/docs/user-guide/ui/
</span><span class='line'>== 走socks5代理
</span><span class='line'>http://k8s:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default</span></code></pre></td></tr></table></div></figure>


<h2>问题及处理</h2>

<p>镜像或者启动失败的问题可以 <strong>set -x</strong> 输出脚本调试信息，获取到出错位置的命令单独重新执行来定位。</p>

<p>另一种情况，脚本启动完成后，服务不能正常运行。重启机器，再次运行master后就不能访问dashboard了，把master机器的防火墙关闭就行了。github上有同样的一个问题<a href="https://github.com/kubernetes/dashboard/issues/916">https://github.com/kubernetes/dashboard/issues/916</a></p>

<p>处理定位问题步骤如下：</p>

<p>清理所有重新弄，无济于事</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker kill $(docker ps -q)
</span><span class='line'>docker rm $(docker ps -aq)
</span><span class='line'>[reboot]
</span><span class='line'>sudo rm -R /var/lib/kubelet
</span><span class='line'>sudo rm -R /var/run/kubernetes
</span><span class='line'>
</span><span class='line'>./turndown.sh & ./master.sh 
</span><span class='line'>kubectl get pods --namespace=kube-system # 显示的dashboard容器启动总是失败，可以通过kubectl logs/docker logs查看。</span></code></pre></td></tr></table></div></figure>


<p>重新定位问题</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>既然关闭防火墙能正常运行，下面通过拦截日志查看封堵日志
</span><span class='line'>[root@k8s ~]# firewall-cmd --set-log-denied=all
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# less /var/log/messages
</span><span class='line'>Feb 25 00:04:30 k8s kernel: XFS (dm-32): Unmounting Filesystem
</span><span class='line'>Feb 25 00:04:30 k8s kernel: XFS (dm-32): Mounting V5 Filesystem
</span><span class='line'>Feb 25 00:04:30 k8s kernel: XFS (dm-32): Ending clean mount
</span><span class='line'>Feb 25 00:04:32 k8s kernel: FINAL_REJECT: IN=docker0 OUT= PHYSIN=veth2fd9745 MAC=02:42:cf:c5:2c:da:02:42:0a:01:49:03:08:00 SRC=10.1.73.3 DST=192.168.1.112 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=11531 DF PROTO=TCP SPT=38734 DPT=6443 WINDOW=28640 RES=0x00 SYN URGP=0 
</span><span class='line'>Feb 25 00:04:33 k8s kernel: FINAL_REJECT: IN=docker0 OUT= PHYSIN=veth2fd9745 MAC=02:42:cf:c5:2c:da:02:42:0a:01:49:03:08:00 SRC=10.1.73.3 DST=192.168.1.112 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=11532 DF PROTO=TCP SPT=38734 DPT=6443 WINDOW=28640 RES=0x00 SYN URGP=0 
</span><span class='line'>Feb 25 00:04:33 k8s dockerd: time="2017-02-25T00:04:33.935301481+08:00" level=error msg="containerd: deleting container" error="exit status 1: \"container dcb4a44031b96470eaef50eb8ac4ee2b9f958906702d94645c3a45c4852b6335 does not exist\\none or more of the container deletions failed\\n\""
</span><span class='line'>Feb 25 00:04:34 k8s kernel: XFS (dm-32): Unmounting Filesystem
</span><span class='line'>Feb 25 00:04:35 k8s systemd-udevd: inotify_add_watch(7, /dev/dm-32, 10) failed: No such file or directory
</span><span class='line'>Feb 25 00:04:36 k8s systemd-udevd: inotify_add_watch(7, /dev/dm-32, 10) failed: No such file or directory
</span><span class='line'>Feb 25 00:04:36 k8s dockerd: time="2017-02-25T00:04:36.406470062+08:00" level=error msg="Handler for GET /v1.25/containers/5bd86339f0dcd513da632ec300d4235d8a09c3f9546f751ac8874de411de3c10/json returned error: No such container: 5bd86339f0dcd513da632ec300d4235d8a09c3f9546f751ac8874de411de3c10"
</span><span class='line'>可以看出访问的端口6443被拦截了</span></code></pre></td></tr></table></div></figure>


<p>开放6443端口dashboard启动成功（直接把放开ip段也行）。通过浏览器能正常访问</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# firewall-cmd --zone=public --add-port=6443/tcp --permanent
</span><span class='line'>success
</span><span class='line'>[root@k8s ~]# firewall-cmd --reload
</span><span class='line'>success
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods --namespace=kube-system
</span><span class='line'>NAME                                    READY     STATUS    RESTARTS   AGE
</span><span class='line'>k8s-master-192.168.1.112                4/4       Running   1          9m
</span><span class='line'>k8s-proxy-v1-nzkgt                      1/1       Running   0          9m
</span><span class='line'>kube-addon-manager-192.168.1.112        2/2       Running   0          8m
</span><span class='line'>kube-dns-4101612645-k4j0s               4/4       Running   4          9m
</span><span class='line'>kubernetes-dashboard-3543765157-h5g5f   1/1       Running   6          9m
</span><span class='line'>等所有都Running才能通过dashboard查看</span></code></pre></td></tr></table></div></figure>


<h2>使用</h2>

<p>使用已有镜像（网上、本地）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl run hello-nginx --image=nginx --port=80
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                           READY     STATUS    RESTARTS   AGE
</span><span class='line'>hello-nginx-2471083592-94pm7   1/1       Running   0          19m
</span><span class='line'>[root@k8s ~]# kubectl describe pod hello-nginx-2471083592-94pm7
</span><span class='line'>Name:           hello-nginx-2471083592-94pm7
</span><span class='line'>Namespace:      default
</span><span class='line'>Node:           192.168.1.248/192.168.1.248
</span><span class='line'>Start Time:     Fri, 24 Feb 2017 12:37:30 +0800
</span><span class='line'>Labels:         pod-template-hash=2471083592
</span><span class='line'>                run=hello-nginx
</span><span class='line'>Status:         Running
</span><span class='line'>IP:             10.1.42.3
</span><span class='line'>Controllers:    ReplicaSet/hello-nginx-2471083592</span></code></pre></td></tr></table></div></figure>


<p>查看到pod的ip，登录Node对应的机器就可以直接通过IP访问了。IP与flannel0网卡在同一网段。</p>

<p>定制镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# docker pull centos:centos5
</span><span class='line'>[root@k8s ~]# docker pull centos:centos6
</span><span class='line'>[root@k8s ~]# docker pull centos:centos7
</span><span class='line'>
</span><span class='line'>把最新的修改提交保存为行的镜像。
</span><span class='line'>登录centos6，安装sshd后，启动sshd服务（产生key）。清理yum缓冲、临时文件/tmp、以及history等。写Dockerfile减小镜像的大小： https://hui.lu/reduce-docker-image-size/  
</span><span class='line'>[root@k8s ~]# docker run -t -i centos:centos6 
</span><span class='line'>...yum install -y openssh-server openssh-clients ; service sshd start ; yum clean all ; history -c ; rm -rf /tmp/*
</span><span class='line'>
</span><span class='line'>提交的名字一定要打标签tag
</span><span class='line'>[root@k8s ~]# docker ps -a
</span><span class='line'>[root@k8s ~]# docker commit CONTAINER_ID bigdata:v1
</span><span class='line'>查看下版本的历史
</span><span class='line'>[root@k8s ~]# docker history bigdata:v1
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# docker images
</span><span class='line'>[root@k8s ~]# docker save centos:centos5 centos:centos6 centos:centos7 bigdata:v1 &gt;bigdata.tar
</span><span class='line'>
</span><span class='line'>拷贝
</span><span class='line'>[root@bigdata-dev ~]# scp k8s:~/bigdata.tar ./
</span><span class='line'>centos.tar                                                                                                                                               100%  668MB  11.1MB/s   01:00    
</span><span class='line'>[root@bigdata-dev ~]# docker load &lt;bigdata.tar
</span><span class='line'>[root@bigdata-dev ~]# docker images
</span><span class='line'> 
</span><span class='line'>真正的跑自己的镜像
</span><span class='line'>[root@k8s ~]# kubectl run hadoop --image=bigdata:v1 --command -- /usr/sbin/sshd -D
</span><span class='line'>deployment "hadoop" created</span></code></pre></td></tr></table></div></figure>


<p>查看运行情况以及一些简单操作</p>

<ul>
<li><a href="https://kubernetes.io/docs/user-guide/debugging-pods-and-replication-controllers/">https://kubernetes.io/docs/user-guide/debugging-pods-and-replication-controllers/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                      READY     STATUS    RESTARTS   AGE
</span><span class='line'>hadoop-2607718808-cqx2n   1/1       Running   0          2h
</span><span class='line'>[root@k8s ~]# kubectl describe pods hadoop-2607718808-cqx2n
</span><span class='line'>通过输出信息中Node和IP即可通过登录主机（IP与flannel0网卡在同一网段）
</span><span class='line'>
</span><span class='line'>也可以通过kubectl来登录
</span><span class='line'>[root@k8s ~]# kubectl exec hadoop-2607718808-cqx2n -i -t -- bash 
</span><span class='line'>[root@hadoop-2607718808-cqx2n /]# 
</span><span class='line'>[root@hadoop-2607718808-cqx2n /]# ifconfig 
</span><span class='line'>eth0      Link encap:Ethernet  HWaddr 02:42:0A:01:49:02  
</span><span class='line'>          inet addr:10.1.73.2  Bcast:0.0.0.0  Mask:255.255.255.0
</span><span class='line'>          inet6 addr: fe80::42:aff:fe01:4902/64 Scope:Link
</span><span class='line'>          UP BROADCAST RUNNING MULTICAST  MTU:1472  Metric:1
</span><span class='line'>          RX packets:8 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>          collisions:0 txqueuelen:0 
</span><span class='line'>          RX bytes:648 (648.0 b)  TX bytes:648 (648.0 b)
</span><span class='line'>
</span><span class='line'>lo        Link encap:Local Loopback  
</span><span class='line'>          inet addr:127.0.0.1  Mask:255.0.0.0
</span><span class='line'>          inet6 addr: ::1/128 Scope:Host
</span><span class='line'>          UP LOOPBACK RUNNING  MTU:65536  Metric:1
</span><span class='line'>          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>          collisions:0 txqueuelen:1 
</span><span class='line'>          RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubectl scale --replicas=4 deployment/hadoop
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                      READY     STATUS    RESTARTS   AGE
</span><span class='line'>hadoop-2607718808-0dzm6   1/1       Running   0          15s
</span><span class='line'>hadoop-2607718808-9twzq   1/1       Running   0          15s
</span><span class='line'>hadoop-2607718808-cqx2n   1/1       Running   0          6h
</span><span class='line'>hadoop-2607718808-k243d   1/1       Running   0          15s
</span><span class='line'>
</span><span class='line'>登上以及启动的机器
</span><span class='line'>[root@k8s ~]# kubectl exec hadoop-2607718808-cqx2n -i -t -- bash
</span><span class='line'>[root@hadoop-2607718808-cqx2n /]# 
</span><span class='line'>
</span><span class='line'>改变部署实例个数
</span><span class='line'>[root@k8s ~]# kubectl scale --replicas=2 deployment/hadoop
</span><span class='line'>deployment "hadoop" scaled
</span><span class='line'>[root@k8s ~]# kubectl get pods
</span><span class='line'>NAME                      READY     STATUS    RESTARTS   AGE
</span><span class='line'>hadoop-2607718808-cqx2n   1/1       Running   0          6h
</span><span class='line'>hadoop-2607718808-k243d   1/1       Running   0          9m</span></code></pre></td></tr></table></div></figure>


<h2>小结</h2>

<p>通过脚本来安装其实不难，就是要翻墙以及一些防火墙的设置需要特别的注意。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s Minikube on Windows]]></title>
    <link href="http://winseliu.com/blog/2017/02/08/k8s-minikube-on-windows/"/>
    <updated>2017-02-08T14:50:06+00:00</updated>
    <id>http://winseliu.com/blog/2017/02/08/k8s-minikube-on-windows</id>
    <content type="html"><![CDATA[<p>在windows配置minikube需要先安装docker，或者更直接点的说就是需要docker一样的依赖环境（都是通过iso装载到虚拟机，我们这里不考虑iso内部的软件配置）。先安装docker会把这些依赖都配置好。</p>

<p>系统当前的版本不支持直接安装<a href="https://docs.docker.com/docker-for-windows/">Docker</a>（This version of Docker requires Windows 10 Pro, Enterprise or Education edition with a mininum build number of 10586, Please use <a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox</a>），</p>

<ul>
<li><a href="https://docs.docker.com/toolbox/toolbox_install_windows/">https://docs.docker.com/toolbox/toolbox_install_windows/</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226#.qvn9h99l4">Tutorial : Getting Started with Kubernetes on your Windows Laptop with Minikube</a></li>
<li><a href="https://blogs.msdn.microsoft.com/wasimbloch/2017/01/23/setting-up-kubernetes-on-windows10-laptop-with-minikube/">Setting up Kubernetes on Windows10 Laptop with Minikube use Hyper-V</a></li>
</ul>


<p>如果直接全部安装toolbox的VirtualBox、git的应该一切顺利的。由于已有cygwin，想着复用下结果惹了一身骚。</p>

<p>按照自己的安装过程，先介绍下配合cygwin安装docker，然后再介绍全部按官网的工具安装k8s。</p>

<h2>仅尝试Docker，不安装k8s</h2>

<p>但是不想安装git直接使用cygwin来代替。刚刚开始的时刻出现了一些理解上的偏差，后来查询start.sh脚本后大概了解到快捷方式、脚本内容后问题就迎刃而解。</p>

<p>先安装docker toolbox：先禁用windows的Hyper-V；安装时去掉git组件。</p>

<p>安装完成后，启动cygwin的命令行（不要用Docker的快捷图标启动）。然后进行如下配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@Lenovo-PC ~
</span><span class='line'>$ cd "C:\Program Files\Docker Toolbox"
</span><span class='line'>
</span><span class='line'>做一个c盘的映射
</span><span class='line'>winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
</span><span class='line'>$ ll /
</span><span class='line'>...
</span><span class='line'>lrwxrwxrwx   1 winse None               11 Apr  5  2016 c -&gt; /cygdrive/c
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>根据cygwin的路径配置VirtualBox的路径
</span><span class='line'>winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
</span><span class='line'>$ export VBOX_MSI_INSTALL_PATH="/cygdrive/c/Program Files/Oracle/VirtualBox/"
</span><span class='line'>
</span><span class='line'>首先下载boot2docker.iso到 C:\Users\winse\.docker\machine\cache\boot2docker.iso
</span><span class='line'>https://github.com/boot2docker/boot2docker/releases/download/v1.13.0/boot2docker.iso...
</span><span class='line'>
</span><span class='line'>创建一个空的clear脚本（cygwin没有包括clear脚本）
</span><span class='line'>winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
</span><span class='line'>$ touch ~/bin/clear && chmod +x ~/bin/clear
</span><span class='line'>
</span><span class='line'># 启动
</span><span class='line'>winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
</span><span class='line'>$ ./start.sh
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>                        ##         .
</span><span class='line'>                  ## ## ##        ==
</span><span class='line'>               ## ## ## ## ##    ===
</span><span class='line'>           /"""""""""""""""""\___/ ===
</span><span class='line'>      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~
</span><span class='line'>           \______ o           __/
</span><span class='line'>             \    \         __/
</span><span class='line'>              \____\_______/
</span><span class='line'>
</span><span class='line'>docker is configured to use the default machine with IP 192.168.99.100
</span><span class='line'>For help getting started, check out the docs at https://docs.docker.com
</span><span class='line'>
</span><span class='line'>Start interactive shell
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC ~
</span><span class='line'>$ docker run hello-world
</span><span class='line'>time="2017-02-08T22:48:33+08:00" level=warning msg="Unable to use system certificate pool: crypto/x509: system root pool is not available on Windows"
</span><span class='line'>Unable to find image 'hello-world:latest' locally
</span><span class='line'>latest: Pulling from library/hello-world
</span><span class='line'>78445dd45222: Pulling fs layer
</span><span class='line'>78445dd45222: Verifying Checksum
</span><span class='line'>78445dd45222: Download complete
</span><span class='line'>78445dd45222: Pull complete
</span><span class='line'>Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7
</span><span class='line'>Status: Downloaded newer image for hello-world:latest
</span><span class='line'>
</span><span class='line'>Hello from Docker!
</span><span class='line'>This message shows that your installation appears to be working correctly.
</span><span class='line'>
</span><span class='line'>To generate this message, Docker took the following steps:
</span><span class='line'> 1. The Docker client contacted the Docker daemon.
</span><span class='line'> 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
</span><span class='line'> 3. The Docker daemon created a new container from that image which runs the
</span><span class='line'>    executable that produces the output you are currently reading.
</span><span class='line'> 4. The Docker daemon streamed that output to the Docker client, which sent it
</span><span class='line'>    to your terminal.
</span><span class='line'>
</span><span class='line'>To try something more ambitious, you can run an Ubuntu container with:
</span><span class='line'> $ docker run -it ubuntu bash
</span><span class='line'>
</span><span class='line'>Share images, automate workflows, and more with a free Docker ID:
</span><span class='line'> https://cloud.docker.com/
</span><span class='line'>
</span><span class='line'>For more examples and ideas, visit:
</span><span class='line'> https://docs.docker.com/engine/userguide/
</span></code></pre></td></tr></table></div></figure>


<h2>使用默认安装，并安装k8s</h2>

<p>由于cygwin的路径与windows的不兼容，而git bash则本身依托于windows的命令行的，兼容性方面更优。</p>

<p>重新安装Docker ToolBox，安装时选择git。</p>

<p>下载minikube需要的一些软件：</p>

<ul>
<li><a href="https://github.com/kubernetes/minikube/releases">minikube.exe</a></li>
<li><a href="https://github.com/kubernetes/minikube/blob/v0.16.0/README.md">minikube文档</a></li>
<li><a href="https://storage.googleapis.com/kubernetes-release/release/v1.5.2/bin/windows/amd64/kubectl.exe">kubectl.exe</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226#.pg14q9wst">Tutorial : Getting Started with Kubernetes on your Windows Laptop with Minikube</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/">Hello Minikube On OS X</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/minikube/">Running Kubernetes Locally via Minikube</a></li>
</ul>


<p>下载minikube和kubectl放到PATH路径下（bin目录已经在PATH中）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\bin&gt;dir
</span><span class='line'>...
</span><span class='line'>2017-02-08  14:05        50,735,616 kubectl.exe
</span><span class='line'>2017-02-08  11:22        84,239,872 minikube-windows-amd64.exe
</span><span class='line'>2017-02-08  11:25    &lt;SYMLINK&gt;      minikube.exe [minikube-windows-amd64.exe] （mklink minikube.exe minikube-windows-amd64.exe）</span></code></pre></td></tr></table></div></figure>


<p>运行 <strong>Docker Quickstart Terminal</strong> (这个快捷方式会先启动docker的虚拟机)，或者直接打开 C:\Program Files\Git\bin\bash.exe 执行如下命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>查看帮助
</span><span class='line'>winse@Lenovo-PC MINGW64 ~
</span><span class='line'>$ minikube start --help
</span><span class='line'>Starts a local kubernetes cluster using Virtualbox. This command
</span><span class='line'>assumes you already have Virtualbox installed.
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>设置代理: 老外的教程都很简单就成功，但是我们操作一堆问题，主要就是万恶的防火墙！！！
</span><span class='line'>winse@Lenovo-PC MINGW64 ~
</span><span class='line'>$ export HTTPS_PROXY=http://localhost:8118
</span><span class='line'>$ export HTTP_PROXY=http://localhost:8118
</span><span class='line'>$ export NO_PROXY="192.168.0.0/16"
</span><span class='line'>
</span><span class='line'>启动
</span><span class='line'>winse@Lenovo-PC MINGW64 ~
</span><span class='line'>$ minikube start --v=7 --logtostderr
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 ~
</span><span class='line'>$ minikube status
</span><span class='line'>minikubeVM: Running
</span><span class='line'>localkube: Running
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 ~
</span><span class='line'>$ kubectl get nodes
</span><span class='line'>NAME       STATUS    AGE
</span><span class='line'>minikube   Ready     3h</span></code></pre></td></tr></table></div></figure>


<h4>再次启动，添加代理参数后dashboard才正常运行</h4>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/">https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226">https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
</span><span class='line'>$ minikube start --docker-env HTTP_PROXY=http://192.168.99.1:8118 --docker-env HTTPS_PROXY=http://192.168.99.1:8118
</span><span class='line'>Starting local Kubernetes cluster...
</span><span class='line'>Kubectl is now configured to use the cluster.
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
</span><span class='line'>$ minikube status
</span><span class='line'>minikubeVM: Running
</span><span class='line'>localkube: Running
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
</span><span class='line'>$ kubectl cluster-info
</span><span class='line'>Kubernetes master is running at https://192.168.99.100:8443
</span><span class='line'>KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns
</span><span class='line'>kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard
</span><span class='line'>
</span><span class='line'>To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
</span><span class='line'>
</span><span class='line'>#Open dashboard
</span><span class='line'>https://github.com/kubernetes/minikube/issues/379
</span><span class='line'>https://github.com/kubernetes/minikube/issues/522
</span><span class='line'>winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
</span><span class='line'>$ minikube dashboard
</span><span class='line'>Opening kubernetes dashboard in default browser...
</span><span class='line'>
</span><span class='line'>运行实例
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl get nodes
</span><span class='line'>NAME       STATUS    AGE
</span><span class='line'>minikube   Ready     8h
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl run hello-nginx --image=nginx --port=80
</span><span class='line'>deployment "hello-nginx" created
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe get pods
</span><span class='line'>NAME                           READY     STATUS              RESTARTS   AGE
</span><span class='line'>hello-nginx-2471083592-cgn29   0/1       ContainerCreating   0          19s
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe get pods
</span><span class='line'>NAME                           READY     STATUS             RESTARTS   AGE
</span><span class='line'>hello-nginx-2471083592-cgn29   0/1       ImagePullBackOff   0          3m
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe describe pod hello-nginx-2471083592-cgn29
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe expose deployment hello-nginx --type=NodePort
</span><span class='line'>service "hello-nginx" exposed
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe get services
</span><span class='line'>NAME          CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE
</span><span class='line'>hello-nginx   10.0.0.145   &lt;nodes&gt;       80:31570/TCP   1m
</span><span class='line'>kubernetes    10.0.0.1     &lt;none&gt;        443/TCP        9h
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe describe service hello-nginx
</span><span class='line'>Name:                   hello-nginx
</span><span class='line'>Namespace:              default
</span><span class='line'>Labels:                 run=hello-nginx
</span><span class='line'>Selector:               run=hello-nginx
</span><span class='line'>Type:                   NodePort
</span><span class='line'>IP:                     10.0.0.145
</span><span class='line'>Port:                   &lt;unset&gt; 80/TCP
</span><span class='line'>NodePort:               &lt;unset&gt; 31570/TCP
</span><span class='line'>Endpoints:              172.17.0.4:80
</span><span class='line'>Session Affinity:       None
</span><span class='line'>No events.
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ minikube service --url=true hello-nginx
</span><span class='line'>http://192.168.99.100:31570
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe logs hello-nginx-2471083592-cgn29
</span><span class='line'>172.17.0.1 - - [10/Feb/2017:02:07:53 +0000] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36" "-"
</span><span class='line'>172.17.0.1 - - [10/Feb/2017:02:07:54 +0000] "GET /favicon.ico HTTP/1.1" 404 571 "http://192.168.99.100:31570/" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36" "-"
</span><span class='line'>2017/02/10 02:07:54 [error] 6#6: *1 open() "/usr/share/nginx/html/favicon.ico" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: "GET /favicon.ico HTTP/1.1", host: "192.168.99.100:31570", referrer: "http://192.168.99.100:31570/"
</span><span class='line'>
</span><span class='line'>水平扩展
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe scale --replicas=3 deployment/hello-nginx
</span><span class='line'>deployment "hello-nginx" scaled
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC MINGW64 /e/local/home/k8s
</span><span class='line'>$ kubectl.exe get deployment
</span><span class='line'>NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span><span class='line'>hello-nginx   3         3         3            1           21m</span></code></pre></td></tr></table></div></figure>


<p>暂时还不清楚负载均衡是怎么弄的。这个三个应用pods其实是在一个内网（172.17.0.4/5/6），对外有一个服务（10.0.0.145）。</p>

<p>基本的安装过程先记录这么多。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker代理配置以及导入导出]]></title>
    <link href="http://winseliu.com/blog/2017/02/06/docker-http-proxy-and-save-reload/"/>
    <updated>2017-02-06T00:40:09+00:00</updated>
    <id>http://winseliu.com/blog/2017/02/06/docker-http-proxy-and-save-reload</id>
    <content type="html"><![CDATA[<h2>代理</h2>

<p>关于http代理服务器的搭建，如果有外（国）网机器，直接用squid建就行了 <a href="http://dockone.io/article/1380">使用Squid3搭建Docker镜像下载代理</a> 。如果已有shadowsocks的代理，可以用privoxy转成http代理服务器。</p>

<ul>
<li>网上参考</li>
</ul>


<p><a href="http://nknu.net/proxy-configuration-for-docker-on-centos-7/">http://nknu.net/proxy-configuration-for-docker-on-centos-7/</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Edit /etc/sysconfig/docker and add the following lines:
</span><span class='line'>HTTP_PROXY='http://user:password@proxy-host:proxy-port'
</span><span class='line'>HTTPS_PROXY='http://user:password@proxy-host:proxy-port'
</span><span class='line'>
</span><span class='line'>For those settings to be taken into account, you’ll need to restart your docker daemon:
</span><span class='line'># systemctl restart docker</span></code></pre></td></tr></table></div></figure>


<ul>
<li>官网文档</li>
</ul>


<p><a href="https://docs.docker.com/engine/admin/systemd/#http-proxy">https://docs.docker.com/engine/admin/systemd/#http-proxy</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s docker.service.d]# pwd
</span><span class='line'>/etc/systemd/system/docker.service.d
</span><span class='line'>[root@k8s docker.service.d]# cat http-proxy.conf 
</span><span class='line'>[Service]
</span><span class='line'>Environment="HTTP_PROXY=http://127.0.0.1:8118/" "NO_PROXY=localhost,127.0.0.1"
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>查看配置的环境变量是否生效
</span><span class='line'>$ sudo systemctl daemon-reload
</span><span class='line'>$ sudo service docker start
</span><span class='line'>$ sudo systemctl show --property Environment docker
</span><span class='line'>
</span><span class='line'>配置代理后下载google容器杠杠的
</span><span class='line'>[root@k8s docker-multinode]# docker pull gcr.io/google_containers/etcd-amd64:3.0.4
</span></code></pre></td></tr></table></div></figure>


<p>如果是自己编译的docker，自启动配置可以参考：<a href="https://github.com/docker/docker/blob/master/contrib/init/systemd/docker.socket">https://github.com/docker/docker/blob/master/contrib/init/systemd/docker.socket</a></p>

<h2>导入导出</h2>

<p><a href="https://tuhrig.de/difference-between-save-and-export-in-docker/">https://tuhrig.de/difference-between-save-and-export-in-docker/</a></p>

<p>对于已经通过代理下载的docker，可以通过导入导出到另外的机器。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# docker save `docker images | grep -v TAG | awk '{print $1":"$2}'` &gt;k8s.tar
</span><span class='line'>
</span><span class='line'>[root@k8s data]# docker load &lt;k8s.tar
</span><span class='line'>0341ae9b0004: Loading layer [==================================================&gt;]  89.1 MB/89.1 MB
</span><span class='line'>Loaded image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.0
</span><span class='line'>011b303988d2: Loading layer [==================================================&gt;]  5.05 MB/5.05 MB
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
</span><span class='line'>596242791254: Loading layer [==================================================&gt;] 792.1 kB/792.1 kB
</span><span class='line'>4e504f64df23: Loading layer [==================================================&gt;]  5.29 MB/5.29 MB
</span><span class='line'>2897536d1f1f: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB
</span><span class='line'>ae11e34e71e6: Loading layer [==================================================&gt;] 10.75 kB/10.75 kB
</span><span class='line'>81620de5436f: Loading layer [==================================================&gt;]  2.56 kB/2.56 kB
</span><span class='line'>77cb0f2fbaed: Loading layer [==================================================&gt;] 50.33 MB/50.33 MB
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-addon-manager-amd64:v6.1
</span><span class='line'>9007f5987db3: Loading layer [==================================================&gt;]  5.05 MB/5.05 MB
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
</span><span class='line'>d41159f2130e: Loading layer [==================================================&gt;] 9.201 MB/9.201 MB
</span><span class='line'>Loaded image: gcr.io/google_containers/dnsmasq-metrics-amd64:1.0
</span><span class='line'>2c84284818d1: Loading layer [==================================================&gt;] 1.312 MB/1.312 MB
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
</span><span class='line'>5e47621858b3: Loading layer [==================================================&gt;] 38.51 MB/38.51 MB
</span><span class='line'>Loaded image: gcr.io/google_containers/etcd-amd64:3.0.4
</span><span class='line'>b6ca02dfe5e6: Loading layer [==================================================&gt;] 128.9 MB/128.9 MB
</span><span class='line'>c2c974a0ae12: Loading layer [==================================================&gt;] 231.6 MB/231.6 MB
</span><span class='line'>88e4c6b7e766: Loading layer [==================================================&gt;] 25.09 kB/25.09 kB
</span><span class='line'>96257390754d: Loading layer [==================================================&gt;] 10.75 kB/10.75 kB
</span><span class='line'>36bd77066b3a: Loading layer [==================================================&gt;]  7.68 kB/7.68 kB
</span><span class='line'>6e833518b289: Loading layer [==================================================&gt;] 28.16 kB/28.16 kB
</span><span class='line'>88d2c1399894: Loading layer [==================================================&gt;] 11.78 kB/11.78 kB
</span><span class='line'>b857f858f4ad: Loading layer [==================================================&gt;] 46.08 kB/46.08 kB
</span><span class='line'>13da16246a77: Loading layer [==================================================&gt;] 56.58 MB/56.58 MB
</span><span class='line'>98a8cc89f2d0: Loading layer [==================================================&gt;] 4.608 kB/4.608 kB
</span><span class='line'>1b7eeaac3364: Loading layer [==================================================&gt;]  5.12 kB/5.12 kB
</span><span class='line'>c85758bfcfdf: Loading layer [==================================================&gt;] 153.9 MB/153.9 MB
</span><span class='line'>Loaded image: gcr.io/google_containers/hyperkube-amd64:v1.5.2
</span><span class='line'>3fc666989c1d: Loading layer [==================================================&gt;] 5.046 MB/5.046 MB
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
</span><span class='line'>9eed5e14d7fb: Loading layer [==================================================&gt;] 348.7 kB/348.7 kB
</span><span class='line'>00dc4ffe8624: Loading layer [==================================================&gt;]  2.56 kB/2.56 kB
</span><span class='line'>Loaded image: gcr.io/google_containers/kube-dnsmasq-amd64:1.4
</span><span class='line'>8ac8bfaff55a: Loading layer [==================================================&gt;] 1.293 MB/1.293 MB
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
</span><span class='line'>dc978cfc3e09: Loading layer [==================================================&gt;] 7.279 MB/7.279 MB
</span><span class='line'>99740866972b: Loading layer [==================================================&gt;] 7.168 kB/7.168 kB
</span><span class='line'>Loaded image: gcr.io/google_containers/exechealthz-amd64:1.2
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
</span><span class='line'>41ff149e94f2: Loading layer [==================================================&gt;] 748.5 kB/748.5 kB
</span><span class='line'>Loaded image: gcr.io/google_containers/pause-amd64:3.0
</span><span class='line'>b79219965469: Loading layer [==================================================&gt;] 45.91 MB/45.91 MB
</span><span class='line'>Loaded image: gcr.io/google_containers/kubedns-amd64:1.9</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
