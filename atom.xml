<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Winse Blog]]></title>
  <link href="http://winseliu.com/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-02-01T19:38:15+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ganglia扩展-Python]]></title>
    <link href="http://winseliu.com/blog/2016/02/01/ganglia-python-extension/"/>
    <updated>2016-02-01T18:23:43+08:00</updated>
    <id>http://winseliu.com/blog/2016/02/01/ganglia-python-extension</id>
    <content type="html"><![CDATA[<h2>安装</h2>

<p>默认安装会检查Python环境，符合条件会自动的安装Python模块。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia-3.7.2]# yum install -y python-devel
</span><span class='line'>[root@cu2 ganglia-3.7.2]# ./configure --with-gmetad --enable-gexec --enable-status --prefix=/usr/local/ganglia
</span><span class='line'>...
</span><span class='line'>Checking for python
</span><span class='line'>checking for python... /usr/bin/python
</span><span class='line'>checking Python version... 2.6
</span><span class='line'>checking Python support... yes
</span><span class='line'>checking Perl support... no
</span><span class='line'>checking for pkg-config... /usr/bin/pkg-config
</span><span class='line'>checking pkg-config is at least version 0.9.0... yes
</span><span class='line'>...
</span><span class='line'>[root@cu2 ganglia-3.7.2]# make && make install</span></code></pre></td></tr></table></div></figure>


<h2>安装成功</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia]# pwd
</span><span class='line'>/usr/local/ganglia
</span><span class='line'>[root@cu2 ganglia]# ll lib64/ganglia/
</span><span class='line'>total 704
</span><span class='line'>-rwxr-xr-x 1 root root 87344 Feb  1 16:52 modcpu.so
</span><span class='line'>-rwxr-xr-x 1 root root 84566 Feb  1 16:52 moddisk.so
</span><span class='line'>-rwxr-xr-x 1 root root 17896 Feb  1 16:52 modgstatus.so
</span><span class='line'>-rwxr-xr-x 1 root root 84526 Feb  1 16:52 modload.so
</span><span class='line'>-rwxr-xr-x 1 root root 86280 Feb  1 16:52 modmem.so
</span><span class='line'>-rwxr-xr-x 1 root root 31695 Feb  1 16:52 modmulticpu.so
</span><span class='line'>-rwxr-xr-x 1 root root 84928 Feb  1 16:52 modnet.so
</span><span class='line'>-rwxr-xr-x 1 root root 84246 Feb  1 16:52 modproc.so
</span><span class='line'>-rwxr-xr-x 1 root root 53994 Feb  1 16:52 modpython.so
</span><span class='line'>-rwxr-xr-x 1 root root 85584 Feb  1 16:52 modsys.so
</span><span class='line'>[root@cu2 ganglia]# ll etc/conf.d/
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 408 Feb  1 16:52 modpython.conf
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia]# vi etc/gmetad.conf
</span><span class='line'> rrdtool_dir
</span><span class='line'>
</span><span class='line'>[root@cu2 ganglia]# cat etc/conf.d/modpython.conf 
</span><span class='line'>/*
</span><span class='line'>  params - path to the directory where mod_python
</span><span class='line'>           should look for python metric modules
</span><span class='line'>
</span><span class='line'>  the "pyconf" files in the include directory below
</span><span class='line'>  will be scanned for configurations for those modules
</span><span class='line'>*/
</span><span class='line'>modules {
</span><span class='line'>  module {
</span><span class='line'>    name = "python_module"
</span><span class='line'>    path = "modpython.so"
</span><span class='line'>    params = "/usr/local/ganglia/lib64/ganglia/python_modules"
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>include ("/usr/local/ganglia/etc/conf.d/*.pyconf")
</span></code></pre></td></tr></table></div></figure>


<h2>Hello World</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ganglia]# cd lib64/ganglia/
</span><span class='line'>[root@cu2 ganglia]# mkdir python_modules
</span><span class='line'>[root@cu2 ganglia]# cd python_modules/
</span><span class='line'>
</span><span class='line'>[root@cu2 python_modules]# cp ~/ganglia-3.7.2/gmond/python_modules/example/example.py ./
</span><span class='line'>[root@cu2 python_modules]# 
</span><span class='line'>
</span><span class='line'>[root@cu2 python_modules]# cd /usr/local/ganglia/etc/conf.d/
</span><span class='line'>[root@cu2 conf.d]# vi example.pyconf
</span><span class='line'>modules {
</span><span class='line'>  module {
</span><span class='line'>    name = "example"
</span><span class='line'>    language = "python"
</span><span class='line'>    param RandomMax {
</span><span class='line'>      value = 600
</span><span class='line'>    }
</span><span class='line'>    param ConstantValue {
</span><span class='line'>      value = 112
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>collection_group {
</span><span class='line'>  collect_every = 10
</span><span class='line'>  time_threshold = 50
</span><span class='line'>  metric {
</span><span class='line'>    name = "PyRandom_Numbers"
</span><span class='line'>    title = "Random"
</span><span class='line'>    value_threshold = 70
</span><span class='line'>  }
</span><span class='line'>  metric {
</span><span class='line'>    name = "PyConstant_Number"
</span><span class='line'>    title = "Constant"
</span><span class='line'>    value_threshold = 70
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@cu2 conf.d]# service gmond restart
</span></code></pre></td></tr></table></div></figure>


<p><strong>example.py</strong> 初始化函数 <code>metric_init</code> 从 <strong>example.pyconf</strong> 文件获取配置、返回可用指标对象（ <code>call_back</code> 关联执行的handler; <code>groups</code> 数据的分组）。</p>

<p>模块中必须包含的三个方法是：</p>

<ul>
<li>def metric_init(params):</li>
<li>def metric_cleanup():</li>
<li>def metric_handler(name):</li>
</ul>


<p>前面两个方法的名字必须是一定的，而最后一个 metric_handler与 <code>metric_init</code> 返回对象的callback对应。<code>__main__</code> 函数用于debug，可以单独调试该模块，以检测是否有错。
更详细的内容看官网的文档<a href="https://github.com/ganglia/monitor-core/wiki/Ganglia-GMond-Python-Modules">Ganglia-GMond-Python-Modules</a></p>

<h2>参考</h2>

<ul>
<li><a href="https://github.com/ganglia/monitor-core/wiki/Ganglia-GMond-Python-Modules">https://github.com/ganglia/monitor-core/wiki/Ganglia-GMond-Python-Modules</a></li>
<li><a href="http://www.cnblogs.com/marysam/archive/2012/01/03/2311187.html">http://www.cnblogs.com/marysam/archive/2012/01/03/2311187.html</a></li>
<li><a href="http://blog.csdn.net/cloudeep/article/details/5669295">http://blog.csdn.net/cloudeep/article/details/5669295</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pdsh]]></title>
    <link href="http://winseliu.com/blog/2016/01/25/pdsh-simple-usage/"/>
    <updated>2016-01-25T19:50:35+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/25/pdsh-simple-usage</id>
    <content type="html"><![CDATA[<p>弄hadoop总是需要折腾不少机器，单单执行 <code>rsync</code> 就挺折腾人的，有时还要排除部分机器来查看一堆机器使用内存情况，等等。以前都使用 <code>expect</code> 结合 <code>for in</code> 来实现，总归简单用着也觉得还行。</p>

<p>但是最近，升级hadoop、tez、安装ganglia被折腾的不行。复制 <code>for</code> 语句到累，原来看过 <code>pdsh</code> 的介绍，不过原来就部署4-5台机器，最近查找Ganglia安装问题的博文里面再次 <code>pdsh</code> ，觉得非常亲切和简洁。再次安装使用也就有了本文。</p>

<h2>安装</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@bigdatamgr1 pdsh-2.29]# umask 0022
</span><span class='line'>[root@bigdatamgr1 pdsh-2.29]# ./configure -h
</span><span class='line'>[root@bigdatamgr1 pdsh-2.29]# ./configure --with-dshgroups  --with-exec --with-ssh 
</span><span class='line'>[root@bigdatamgr1 pdsh-2.29]# make && make install
</span></code></pre></td></tr></table></div></figure>


<p>挺多选项的，用 <code>disgroups</code> 加上 <code>ssh</code> 差不多够用了，以后不够用的时刻再慢慢研究这些选项。</p>

<h2>简单使用</h2>

<p>使用pdsh管理机器的前提是已经建立了到目标机器的SSH无密钥登录，而建立这N台机器的无秘钥登录还是少不了 <code>expect</code> (当然你愿意一个个输入yes和密码也是OK的)！</p>

<ul>
<li>加载的模块</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 查看，安装的ssh/exec
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -L
</span><span class='line'>
</span><span class='line'># 设置默认使用的模块
</span><span class='line'>[eshore@bigdatamgr1 ~]$ export PDSH_RCMD_TYPE=exec
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2] ssh %h hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>
</span><span class='line'># 命令行指定模块
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -R ssh -w bigdata1,bigdata2 hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>
</span><span class='line'># 一个个的指定
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ssh:bigdata1,ssh:bigdata2 hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ssh:bigdata[1,2] hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata1: bigdata1
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>主机加载</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2,5,6-8] -X nodes hostname
</span><span class='line'>bigdata5: bigdata5
</span><span class='line'>bigdata6: bigdata6
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata8: bigdata8
</span><span class='line'>bigdata7: bigdata7
</span></code></pre></td></tr></table></div></figure>


<p>pdsh除了使用 <code>-w</code> 来指定主机列表，还可以通过文件来指定，如编译时的 <code>--with-machines</code> ，同时可以通过读取默认的位置的文件来获取。在编译pdsh时可以通过 <code>--with-dshgroups</code> 参数来激活此选项，默认可以将一组主机列表写入一个文件中并放到本地主机的 <code>~/.dsh/group</code> 或 <code>/etc/dsh/group</code> 目录下，这样就可以通过 <code>-g</code> 参数调用了。同时 <code>-X groupname</code> 可以用来排除主机列表中属于groupname组的主机（下面会提到group分组）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ export PDSH_RCMD_TYPE=ssh
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ mkdir -p .dsh/group
</span><span class='line'>[eshore@bigdatamgr1 ~]$ cd .dsh/group/
</span><span class='line'>[eshore@bigdatamgr1 group]$ vi nodes
</span><span class='line'>bigdata1
</span><span class='line'>bigdata3
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -g nodes hostname
</span><span class='line'>bigdata3: bigdata3
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-8] -X nodes hostname
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata8: bigdata8
</span><span class='line'>bigdata5: bigdata5
</span><span class='line'>bigdata6: bigdata6
</span><span class='line'>bigdata4: bigdata4
</span><span class='line'>bigdata7: bigdata7</span></code></pre></td></tr></table></div></figure>


<p><code>-w</code> 参数也可以用来读取特定文件中的主机列表，同时结合其他规则和进行过滤（具体查看man帮助）。<code>-x</code> 在主机列表基础上进行过滤（提供多一种的方式来实现过滤）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ cat slaves | head -2
</span><span class='line'>bigdata1
</span><span class='line'>bigdata2
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves hostname | head -5
</span><span class='line'>bigdata8: bigdata8
</span><span class='line'>bigdata6: bigdata6
</span><span class='line'>bigdata5: bigdata5
</span><span class='line'>bigdata2: bigdata2
</span><span class='line'>bigdata3: bigdata3
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves,-bigdata[2-8]
</span><span class='line'>pdsh&gt; hostname
</span><span class='line'>bigdata1: bigdata1
</span><span class='line'>pdsh&gt; 
</span><span class='line'>pdsh&gt; exit
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves,-/bigdata.?/
</span><span class='line'>pdsh@bigdatamgr1: no remote hosts specified
</span><span class='line'>
</span><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves -x bigdata[1-7] hostname
</span><span class='line'>bigdata8: bigdata8
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>输出格式化</li>
</ul>


<p>当一台主机的输出多余一行时，pdsh输出的内容看起来并不和谐。使用dshbak格式化</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2] free -m  | dshbak -c
</span><span class='line'>----------------
</span><span class='line'>bigdata1
</span><span class='line'>----------------
</span><span class='line'>             total       used       free     shared    buffers     cached
</span><span class='line'>Mem:         64405      59207       5198          0        429      31356
</span><span class='line'>-/+ buffers/cache:      27420      36985
</span><span class='line'>Swap:        65535         57      65478
</span><span class='line'>----------------
</span><span class='line'>bigdata2
</span><span class='line'>----------------
</span><span class='line'>             total       used       free     shared    buffers     cached
</span><span class='line'>Mem:         64405      58192       6213          0        505      29847
</span><span class='line'>-/+ buffers/cache:      27838      36566
</span><span class='line'>Swap:        65535         58      65477
</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pdsh -w ssh:user00[1-10] "date"
</span><span class='line'>此命令用于在user001到user0010上执行date命令。
</span><span class='line'>pdsh -w ssh:user0[10-31],/1$/ "uptime"
</span><span class='line'>此命令在选择远程主机时使用了正则表达式，表示在user010到user031中选择以1结尾的主机名，即在user011、user021、user031上执行uptime命令
</span><span class='line'>
</span><span class='line'>-l    指定在远程主机上使用的用户名称。例如：
</span><span class='line'>pdsh -R ssh -l opsuser -w user00[1-9] "date"
</span><span class='line'>
</span><span class='line'>-f    设置同时连接到远程主机的个数
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://ixdba.blog.51cto.com/2895551/1550184">并行分布式运维工具pdsh</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Some quick tips on how to get started using pdsh:
</span><span class='line'>Set up your environment:
</span><span class='line'>export PDSH_SSH_ARGS_APPEND=”-o ConnectTimeout=5 -o CheckHostIP=no -o StrictHostKeyChecking=no” (Add this to your .bashrc to save time.)</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://radfest.wordpress.com/2012/05/24/parallel-remote-shelling-via-pdsh/">Parallel remote &ldquo;shelling&rdquo; via pdsh</a></li>
<li><a href="http://kumu-linux.github.io/blog/2013/06/19/pdsh/">Pdsh使用方法</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装配置Ganglia(2)]]></title>
    <link href="http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/"/>
    <updated>2016-01-23T17:47:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2</id>
    <content type="html"><![CDATA[<p>前一篇介绍了全部手工安装Ganglia的文章，当时安装测试的环境比较简单。按照网上的步骤安装好，看到图了以为就懂了。Ganglia的基本多播/单播的概念都没弄懂。</p>

<p>这次有机会把Ganglia安装到正式环境，由于网络复杂一些，遇到新的问题。也更进一步的了解了Ganglia。</p>

<p>后端Gmetad(ganglia meta daemon)和Gmond(ganglia monitoring daemon)是Ganglia的两个组件。</p>

<p>Gmetad负责收集各个cluster的数据，并更新到rrd数据库中；Gmond把本机的数据UDP广播（或者单播给某台机），同时收集集群节点的数据供Gmetad读取。Gmetad并不用于监控数据的汇总，是对已经采集好的全部数据处理并存储到rrdtool数据库。</p>

<h2>搭建yum环境</h2>

<p>由于正式环境没有提供外网环境，所以需要把安装光盘拷贝到机器，作为yum的本地源。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mount -t iso9660 -o loop rhel-server-6.4-x86_64-dvd\[ED2000.COM\].iso iso/
</span><span class='line'>ln -s iso rhel6.4
</span><span class='line'>
</span><span class='line'>vi /etc/yum.repos.d/rhel.repo 
</span><span class='line'>[os]
</span><span class='line'>name = Linux OS Packages
</span><span class='line'>baseurl = file:///opt/rhel6.4
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck = 0
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>再极端点，yum程序都没有安装。到 Packages 目录用 rpm 安装 <code>yum*</code> 。</p>

<p>安装httpd后，把 rhel6.4 源建一个软链接到 <code>/var/www/html/rhel6.4</code> ，其他机器就可以使用该源来进行安装软件了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat /etc/yum.repos.d/rhel.repo
</span><span class='line'>[http]
</span><span class='line'>name=LOCAL YUM server
</span><span class='line'>baseurl = http://cu-omc1/rhel6.4
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0</span></code></pre></td></tr></table></div></figure>


<h2>使用yum安装依赖</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install -y gcc gd httpd php php-devel php-mysql php-pear php-common php-gd php-mbstring php-cli 
</span><span class='line'>
</span><span class='line'>yum install -y rrdtool 
</span><span class='line'>
</span><span class='line'>yum install -y apr*
</span><span class='line'>
</span><span class='line'># 编译Ganglia时加 --with-libpcre=no 可以不安装pcre
</span><span class='line'>yum install -y pcre*
</span><span class='line'>
</span><span class='line'># yum install -y zlib-devel
</span></code></pre></td></tr></table></div></figure>


<h2>(仅)编译安装Ganglia</h2>

<p>下载下面的软件(yum没有这些软件)：</p>

<ul>
<li><a href="http://rpm.pbone.net/index.php3/stat/4/idpl/15992683/dir/scientific_linux_6/com/rrdtool-devel-1.3.8-6.el6.x86_64.rpm.html">rrdtool-devel-1.3.8-6.el6.x86_64.rpm</a></li>
<li><a href="http://download.savannah.gnu.org/releases/confuse/">confuse-2.7.tar.gz</a></li>
<li><a href="http://sourceforge.net/projects/ganglia/files/ganglia%20monitoring%20core/">ganglia</a></li>
<li><a href="http://sourceforge.net/projects/ganglia/files/ganglia-web/">ganglia-web</a></li>
</ul>


<p>安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>umask 0022 # 临时修改下，不然后面会遇到权限问题
</span><span class='line'>
</span><span class='line'>rpm -ivh rrdtool-devel-1.3.8-6.el6.x86_64.rpm 
</span><span class='line'>
</span><span class='line'># yum install -y libconfuse*
</span><span class='line'>tar zxf confuse-2.7.tar.gz
</span><span class='line'>cd confuse-2.7
</span><span class='line'>./configure CFLAGS=-fPIC --disable-nls
</span><span class='line'>make && make install
</span><span class='line'>
</span><span class='line'>tar zxf ganglia-3.7.2.tar.gz 
</span><span class='line'>cd ganglia-3.7.2
</span><span class='line'>./configure --with-gmetad --enable-gexec --enable-status --prefix=/usr/local/ganglia
</span><span class='line'># 可选项，用于指定默认配置位置 `-sysconfdir=/etc/ganglia`
</span><span class='line'>make && make install
</span><span class='line'>
</span><span class='line'>cp gmetad/gmetad.init /etc/init.d/gmetad
</span><span class='line'>chkconfig gmetad on
</span><span class='line'>chkconfig --list | grep gm
</span><span class='line'>
</span><span class='line'>df -h # 把rrds目录放到最大的分区，再做个链接到data目录下
</span><span class='line'>mkdir -p /data/ganglia/rrds
</span><span class='line'>chown nobody:nobody /data/ganglia/rrds
</span><span class='line'>ln -s /usr/local/ganglia/sbin/gmetad /usr/sbin/gmetad
</span><span class='line'>
</span><span class='line'>gmetad -h # 查看默认的config位置。下面两个步骤二选一根据是否配置 sysconfdir 选项
</span><span class='line'># cp gmetad/gmetad.conf /etc/ganglia/
</span><span class='line'>vi /etc/init.d/gmetad 
</span><span class='line'>  /usr/local/ganglia/etc/gmetad.conf #修改原来的默认配置路径
</span><span class='line'> 
</span><span class='line'>cd ganglia-3.7.2/gmond/
</span><span class='line'>ln -s /usr/local/ganglia/sbin/gmond /usr/sbin/gmond
</span><span class='line'>cp gmond.init /etc/init.d/gmond
</span><span class='line'>chkconfig gmond on
</span><span class='line'>chkconfig --list gmond
</span><span class='line'>  
</span><span class='line'>gmond -h # 查看默认的config位置。
</span><span class='line'>./gmond -t &gt;/usr/local/ganglia/etc/gmond.conf
</span><span class='line'>vi /etc/init.d/gmond 
</span><span class='line'>  /usr/local/ganglia/etc/gmond.conf #修改原来的默认配置路径
</span></code></pre></td></tr></table></div></figure>


<h2>配置</h2>

<ul>
<li>Ganglia配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi /usr/local/ganglia/etc/gmetad.conf
</span><span class='line'>  datasource "HADOOP" hadoop-master1
</span><span class='line'>  datasource "CU" cu-ud1
</span><span class='line'>  rrd_rootdir "/data/ganglia/rrds"
</span><span class='line'>  gridname "bigdata"
</span><span class='line'>
</span><span class='line'>vi /usr/local/ganglia/etc/gmond.conf
</span><span class='line'>  cluster {
</span><span class='line'>   name = "CU"
</span><span class='line'>
</span><span class='line'>  udp_send_channel {
</span><span class='line'>   bind_hostname = yes
</span></code></pre></td></tr></table></div></figure>


<p><a href="http://ixdba.blog.51cto.com/2895551/1149003">http://ixdba.blog.51cto.com/2895551/1149003</a></p>

<p>Ganglia的收集数据工作可以工作在单播（unicast)或多播(multicast)模式下，默认为多播模式。</p>

<ul>
<li>单播：发送自己 <strong>收集</strong> 到的监控数据到特定的一台或几台机器上，可以跨网段</li>
<li>多播：发送自己收集到的监控数据到同一网段内所有的机器上，同时收集同一网段内的所有机器发送过来的监控数据。因为是以广播包的形式发送，因此需要同一网段内。但同一网段内，又可以定义不同的发送通道。</li>
</ul>


<p>主机多网卡(多IP)情况下需要绑定到特定的IP，设置bind_hostname来设置要绑定的IP地址。单IP情况下可以不需要考虑。</p>

<p>多播情况下只能在单一网段进行，如果集群存在多个网段，可以分拆成多个子集群（data_source)，或者使用单播来进行配置。期望配置简单点的话，配置多个 data_source 。</p>

<ul>
<li><code>data_source "cluster-db" node1 node2</code>  定义集群名称，以及获取集群监控数据的节点。由于采用multicast模式，每台gmond节点都有本集群内节点服务器的所有监控数据，因此不必把所有节点都列出来。node1 node2是or的关系，如果node1无法下载，则才会尝试去node2下载，所以它们应该都是同一个集群的节点，保存着同样的数据。</li>
<li><code>cluster.name</code> 本节点属于哪个cluster，需要与data_source对应。</li>
<li><code>host.location</code> 类似于hostname的作用。</li>
<li><code>udp_send_channel.mcast_join/host</code> 多播地址，工作在239.2.11.71通道下。如果使用单播模式，则要写host=node1，单播模式下可以配置多个upd_send_channel</li>
<li><code>udp_recv_channel.mcast_join</code></li>
</ul>


<p><strong>参考思路</strong> (未具体实践)：多网段情况可以用单播解决，要是单网段要配置多个data_source(集群)那就换个多播的端口吧！</p>

<h2>启动以及测试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service httpd restart
</span><span class='line'>service gmetad start
</span><span class='line'>service gmond start
</span><span class='line'>
</span><span class='line'>service gmond status
</span><span class='line'>
</span><span class='line'>netstat -anp | grep -E "gmond|gmetad"
</span><span class='line'>
</span><span class='line'># 启动如果有问题，使用调试模式启动查找问题
</span><span class='line'>/usr/sbin/gmetad -d 10
</span><span class='line'>
</span><span class='line'>/usr/local/ganglia/bin/gstat -a
</span><span class='line'>/usr/local/ganglia/bin/gstat -a -i hadoop-master1
</span><span class='line'>
</span><span class='line'>telnet localhost 8649
</span><span class='line'>telnet localhost 8651</span></code></pre></td></tr></table></div></figure>


<h2>安装GWeb</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd ~/ganglia-web-3.7.1
</span><span class='line'>vi Makefile # 一次性配置好，不再需要去修改conf_default.php
</span><span class='line'>  GDESTDIR = /var/www/html/ganglia
</span><span class='line'>  GCONFDIR = /usr/local/ganglia/etc/
</span><span class='line'>  GWEB_STATEDIR = /var/www/html/ganglia
</span><span class='line'>  # Gmetad rootdir (parent location of rrd folder)
</span><span class='line'>  GMETAD_ROOTDIR = /data/ganglia
</span><span class='line'>  APACHE_USER = apache
</span><span class='line'>make install
</span><span class='line'>
</span><span class='line'># 注意：内网还是需要改下 conf_default.php 一堆jquery的js。
</span><span class='line'># 如果Web不能访问，查看下防火墙以及SELinux
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>httpd登录密码配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>htpasswd -c /var/www/html/ganglia/etc/htpasswd.users gangliaadmin 
</span><span class='line'>
</span><span class='line'>vi /etc/httpd/conf/httpd.conf 
</span><span class='line'>
</span><span class='line'>  &lt;Directory "/var/www/html/ganglia"&gt;
</span><span class='line'>  #  SSLRequireSSL
</span><span class='line'>     Options None
</span><span class='line'>     AllowOverride None
</span><span class='line'>     &lt;IfVersion &gt;= 2.3&gt;
</span><span class='line'>        &lt;RequireAll&gt;
</span><span class='line'>           Require all granted
</span><span class='line'>  #        Require host 127.0.0.1
</span><span class='line'>
</span><span class='line'>           AuthName "Ganglia Access"
</span><span class='line'>           AuthType Basic
</span><span class='line'>           AuthUserFile /var/www/html/ganglia/etc/htpasswd.users
</span><span class='line'>           Require valid-user
</span><span class='line'>        &lt;/RequireAll&gt;
</span><span class='line'>     &lt;/IfVersion&gt;
</span><span class='line'>     &lt;IfVersion &lt; 2.3&gt;
</span><span class='line'>        Order allow,deny
</span><span class='line'>        Allow from all
</span><span class='line'>  #     Order deny,allow
</span><span class='line'>  #     Deny from all
</span><span class='line'>  #     Allow from 127.0.0.1
</span><span class='line'>
</span><span class='line'>        AuthName "Ganglia Access"
</span><span class='line'>        AuthType Basic
</span><span class='line'>        AuthUserFile /var/www/html/ganglia/etc/htpasswd.users
</span><span class='line'>        Require valid-user
</span><span class='line'>     &lt;/IfVersion&gt;
</span><span class='line'>  &lt;/Directory&gt;
</span><span class='line'>
</span><span class='line'>service httpd restart
</span></code></pre></td></tr></table></div></figure>


<h2>集群配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /usr/local 
</span><span class='line'>for h in cu-ud1 cu-ud2 hadoop-master1 hadoop-master2 ; do 
</span><span class='line'>  cd /usr/local;
</span><span class='line'>  rsync -vaz  ganglia $h:/usr/local/ ;
</span><span class='line'>  ssh $h ln -s /usr/local/ganglia/sbin/gmond /usr/sbin/gmond ;
</span><span class='line'>  scp /etc/init.d/gmond $h:/etc/init.d/ ;
</span><span class='line'>  ssh $h "chkconfig gmond on" ;
</span><span class='line'>  ssh $h "yum install apr* -y" ; 
</span><span class='line'>  ssh $h "service gmond start" ; 
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'># 不同的集群，cluster.name需要修改
</span><span class='line'>
</span><span class='line'>telnet hadoop-master1 8649
</span><span class='line'>netstat -anp | grep gm
</span></code></pre></td></tr></table></div></figure>


<p>要是集群有变动，添加还好，删除的话，会存在原来的旧数据，页面会提示机器down掉了。可以删除rrds目录下对应集群中节点的数据，然后重庆gmetad/httpd即可。</p>

<h2>参考</h2>

<h3>内容</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>防火墙规则设置
</span><span class='line'>iptables -I INPUT 3 -p tcp -m tcp --dport 80 -j ACCEPT
</span><span class='line'>iptables -I INPUT 3 -p udp -m udp --dport 8649 -j ACCEPT
</span><span class='line'>
</span><span class='line'>service iptables save
</span><span class='line'>service iptables restart
</span><span class='line'>
</span><span class='line'>关闭selinux
</span><span class='line'>vi /etc/selinux/config
</span><span class='line'>SELINUX=disabled
</span><span class='line'>setenforce 0
</span></code></pre></td></tr></table></div></figure>


<p>实际应用中，需要监控的机器往往在不同的网段内，这个时候，就不能用gmond默认的多播方式（用于同一个网段内）来传送数据，必须使用单播的方法。</p>

<p>gmond可以配置成为一个cluster，这些gmond节点之间相互发送各自的监控数据。所以每个gmond节点上实际上都会有 cluster内的所有节点的监控数据。gmetad只需要去某一个节点获取数据就可以了。</p>

<p>web front-end 一个基于web的监控界面，通常和Gmetad安装在同一个节点上(还需确认是否可以不在一个节点上，因为php的配置文件中ms可配置gmetad的地址及端口)，它从Gmetad取数据，并且读取rrd数据库，生成图片，显示出来。</p>

<p>gmetad周期性的去gmond节点或者gmetad节点poll数据。一个gmetad可以设置多个datasource，每个datasource可以有多个备份，一个失败还可以去其他host取数据。Gmetad只有tcp通道，一方面他向datasource发送请求，另一方面会使用一个tcp端口，发 布自身收集的xml文件，默认使用8651端口。所以gmetad即可以从gmond也可以从其他的gmetad得到xml数据。</p>

<p>对于IO来说，Gmetad默认15秒向gmond取一次xml数据，如果gmond和gmetad都是在同一个节点，这样就相当于本地io请求。同时gmetad请求完xml文件后，还需要对其解析，也就是说按默认设置每15秒需要解析一个10m级别的xml文件，这样cpu的压力就会很大。同时它还有写入RRD数据库，还要处理来自web客户端的解析请求，也会读RRD数据库。这样本身的IO CPU 网络压力就很大，因此这个节点至少应该是个空闲的而且能力比较强的节点。</p>

<ul>
<li>多播模式配置
这个是默认的方式，基本上不需要修改配置文件，且所有节点的配置是一样的。这种模式的好处是所有的节点上的 gmond 都有完备的数据，gmetad 连接其中任意一个就可以获取整个集群的所有监控数据，很方便。
其中可能要修改的是 mcast_if 这个参数，用于指定多播的网络接口。如果有多个网卡，要填写对应的内网接口。</li>
<li>单播模式配置
监控机上的接收 Channel 配置。我们使用 UDP 单播模式，非常简单。我们的集群有部分机器在另一个机房，所以监听了 0.0.0.0，如果整个集群都在一个内网中，建议只 bind 内网地址。如果有防火墙，要打开相关的端口。</li>
<li>最重要的配置项是 data_source: <code>data_source "my-cluster" localhost:8648</code> 如果使用的是默认的 8649 端口，则端口部分可以省略。如果有多个集群，则可以指定多个 data_source，每行一个。</li>
<li>最后是 gridname 配置，用于给整个 Grid 命名</li>
<li><a href="https://github.com/ganglia/gmond_python_modules">https://github.com/ganglia/gmond_python_modules</a></li>
</ul>


<h3>网址</h3>

<ul>
<li><a href="http://yhz.me/blog/Install-Ganglia-On-CentOS.html">在 CentOS 6.5 上安装 Ganglia 3.6.0</a></li>
<li>*<a href="http://ixdba.blog.51cto.com/2895551/1149003">分布式监控系统ganglia配置文档</a></li>
<li><p>*<a href="http://www.3mu.me/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%80%E6%BA%90%E7%9B%91%E6%8E%A7%E8%BD%AF%E4%BB%B6ganglia-%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/">企业级开源监控软件Ganglia 安装与配置</a></p></li>
<li><p>*<a href="http://jerrypeng.me/2014/07/04/server-side-java-monitoring-ganglia/">Java 服务端监控方案（二. Ganglia 篇）</a></p></li>
<li><a href="http://jerrypeng.me/2014/07/22/server-side-java-monitoring-nagios/">Java 服务端监控方案（三. Nagios 篇）</a></li>
<li><p><a href="https://github.com/ganglia/ganglia-web/wiki/Nagios-Integration">https://github.com/ganglia/ganglia-web/wiki/Nagios-Integration</a></p></li>
<li><p><a href="https://ganglia.wikimedia.org/latest/">维基百科Ganglia</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[坑]]></title>
    <link href="http://winseliu.com/blog/2016/01/19/hole/"/>
    <updated>2016-01-19T16:53:29+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/19/hole</id>
    <content type="html"><![CDATA[<ul>
<li>Set</li>
</ul>


<p><img src="http://winseliu.com/images/blogs/hole-set-add-diff.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Set&lt;BlockedInfo&gt; diffs = new HashSet&lt;&gt;();
</span><span class='line'>diffs.addAll(oldBlockedList);
</span><span class='line'>diffs.addAll(newBlockedList);
</span><span class='line'>Iterator&lt;BlockedInfo&gt; iterator = diffs.iterator();
</span><span class='line'>while (iterator.hasNext()) {
</span><span class='line'>  BlockedInfo i = iterator.next();
</span><span class='line'>  if (oldBlockedList.contains(i) && newBlockedList.contains(i)) {
</span><span class='line'>      iterator.remove();
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>第二段代码希望找出前后两个list的差别，即XOR的效果。但是。。。为什么呢？想一想。</p>

<p>用guava库一行代码搞定：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Sets.difference(Sets.union(oldBlockedList, newBlockedList), Sets.intersection(oldBlockedList, newBlockedList))</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[配置TEZ-UI]]></title>
    <link href="http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run/"/>
    <updated>2016-01-12T20:28:35+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/12/tez-ui-config-and-run</id>
    <content type="html"><![CDATA[<p>tez-ui很早就出来了，荒废了很多时间。今天才把它配置出来，效果挺不错的，和spark-web差不多。</p>

<p>记录了在hive-1.2.1上配置tez-0.7.0过程，配置运行hadoop2.6.3-timeline以及为tez添加tez-ui特性的步骤。</p>

<h2>编译tez-0.7.0</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ mvn package -Dhadoop.version=2.6.3 -DskipTests
</span><span class='line'>
</span><span class='line'>[INFO] Reactor Summary:
</span><span class='line'>[INFO] 
</span><span class='line'>[INFO] tez ................................................ SUCCESS [  0.831 s]
</span><span class='line'>[INFO] tez-api ............................................ SUCCESS [  6.580 s]
</span><span class='line'>[INFO] tez-common ......................................... SUCCESS [  0.124 s]
</span><span class='line'>[INFO] tez-runtime-internals .............................. SUCCESS [  0.676 s]
</span><span class='line'>[INFO] tez-runtime-library ................................ SUCCESS [  1.378 s]
</span><span class='line'>[INFO] tez-mapreduce ...................................... SUCCESS [  0.989 s]
</span><span class='line'>[INFO] tez-examples ....................................... SUCCESS [  0.105 s]
</span><span class='line'>[INFO] tez-dag ............................................ SUCCESS [  2.391 s]
</span><span class='line'>[INFO] tez-tests .......................................... SUCCESS [  0.187 s]
</span><span class='line'>[INFO] tez-ui ............................................. SUCCESS [02:23 min]
</span><span class='line'>[INFO] tez-plugins ........................................ SUCCESS [  0.017 s]
</span><span class='line'>[INFO] tez-yarn-timeline-history .......................... SUCCESS [  0.595 s]
</span><span class='line'>[INFO] tez-yarn-timeline-history-with-acls ................ SUCCESS [  0.316 s]
</span><span class='line'>[INFO] tez-mbeans-resource-calculator ..................... SUCCESS [  0.189 s]
</span><span class='line'>[INFO] tez-tools .......................................... SUCCESS [  0.017 s]
</span><span class='line'>[INFO] tez-dist ........................................... SUCCESS [ 16.554 s]
</span><span class='line'>[INFO] Tez ................................................ SUCCESS [  0.015 s]
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] BUILD SUCCESS
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] Total time: 02:55 min
</span><span class='line'>[INFO] Finished at: 2016-01-12T19:08:50+08:00
</span><span class='line'>[INFO] Final Memory: 63M/756M
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span></code></pre></td></tr></table></div></figure>


<h2>tez嵌入到hive</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 上传tez程序到hdfs
</span><span class='line'>[hadoop@cu2 ~]$ cd sources/apache-tez-0.7.0-src/tez-dist/target/
</span><span class='line'>[hadoop@cu2 target]$ hadoop fs -mkdir -p /apps/tez-0.7.0
</span><span class='line'>[hadoop@cu2 target]$ hadoop fs -put tez-0.7.0.tar.gz /apps/tez-0.7.0/
</span><span class='line'>
</span><span class='line'>// TEZ_CONF_DIR = HADOOP_CONF_DIR
</span><span class='line'>[hadoop@cu2 ~]$ cd hadoop-2.6.3/etc/hadoop/
</span><span class='line'>[hadoop@cu2 hadoop]$ vi tez-site.xml
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>&lt;value&gt;${fs.defaultFS}/apps/tez-0.7.0/tez-0.7.0.tar.gz&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>// 本地tez jars加入HADOOP_CLASSPATH
</span><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ cd tez-dist/target/
</span><span class='line'>archive-tmp/              maven-archiver/           tez-0.7.0/                tez-0.7.0-minimal.tar.gz  tez-0.7.0.tar.gz          tez-dist-0.7.0-tests.jar  
</span><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ cd tez-dist/target/
</span><span class='line'>[hadoop@cu2 target]$ mv tez-0.7.0 ~/
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ vi apache-hive-1.2.1-bin/conf/hive-env.sh
</span><span class='line'>
</span><span class='line'>// 多个jline版本 http://stackoverflow.com/questions/28997441/hive-startup-error-terminal-initialization-failed-falling-back-to-unsupporte
</span><span class='line'>export HADOOP_USER_CLASSPATH_FIRST=true
</span><span class='line'>export TEZ_HOME=/home/hadoop/tez-0.7.0
</span><span class='line'>export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/*:$TEZ_HOME/lib/*
</span><span class='line'>
</span><span class='line'>// http://stackoverflow.com/questions/26988388/hive-0-14-0-not-starting [/tmp/hive on HDFS should be writable. Current permissions are: rwxrwxr-x]
</span><span class='line'>// hive.metastore.warehouse.dir  hive.exec.scratchdir
</span><span class='line'>[hadoop@cu2 hive]$ rm -rf /tmp/hive
</span><span class='line'>[hadoop@cu2 hive]$ hadoop fs -rmr /tmp/hive
</span><span class='line'>// 或者修改权限 hadoop fs -chmod 777 /tmp/hive</span></code></pre></td></tr></table></div></figure>


<h2>启用/使用tez</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop]$ cat ~/hive/conf/hive-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hive.execution.engine&lt;/name&gt;
</span><span class='line'>&lt;value&gt;tez&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ bin/hive
</span><span class='line'>...
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2;
</span><span class='line'>Query ID = hadoop_20160112200359_f8be3d1c-9adc-42c0-abb9-2643dfef2cc7
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1452600034599_0001)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 20.83 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>67
</span><span class='line'>Time taken: 27.823 seconds, Fetched: 1 row(s)
</span></code></pre></td></tr></table></div></figure>


<h2>部署/启动hadoop-timeline</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop]$ vi etc/hadoop/yarn-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.hostname&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;hadoop-master2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.http-cross-origin.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.resourcemanager.system-metrics-publisher.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ for h in hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/yarn-daemon.sh start timelineserver
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/stop-all.sh
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/start-all.sh
</span></code></pre></td></tr></table></div></figure>


<h2>部署tez-ui</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 放置tez-ui
</span><span class='line'>[hadoop@cu2 target]$ cd ../../tez-ui/
</span><span class='line'>[hadoop@cu2 tez-ui]$ cd target/
</span><span class='line'>[hadoop@cu2 target]$ ll
</span><span class='line'>total 1476
</span><span class='line'>drwxrwxr-x 3 hadoop hadoop    4096 Jan 12 19:08 classes
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop    4096 Jan 12 19:08 maven-archiver
</span><span class='line'>drwxrwxr-x 8 hadoop hadoop    4096 Jan 12 19:08 tez-ui-0.7.0
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop    3058 Jan 12 19:08 tez-ui-0.7.0-tests.jar
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop 1491321 Jan 12 19:08 tez-ui-0.7.0.war
</span><span class='line'>[hadoop@cu2 target]$ mv tez-ui-0.7.0 ~/
</span><span class='line'>
</span><span class='line'>// 部署tez-ui
</span><span class='line'>[hadoop@cu2 ~]$ cd apache-tomcat-7.0.67/conf/
</span><span class='line'>修改端口为9999
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ vi conf/server.xml 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ cd conf/Catalina/localhost/
</span><span class='line'>[hadoop@cu2 localhost]$ vi tez-ui.xml
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ bin/startup.sh 
</span><span class='line'>
</span><span class='line'>// tez添加tez-ui功能
</span><span class='line'>[hadoop@cu2 hive]$ vi ~/hadoop-2.6.3/etc/hadoop/tez-site.xml 
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>&lt;value&gt;${fs.defaultFS}/apps/tez-0.7.0/tez-0.7.0.tar.gz&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.history.logging.service.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.tez-ui.history-url.base&lt;/name&gt;
</span><span class='line'>&lt;value&gt;http://hadoop-master2:9999/tez-ui/&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span></code></pre></td></tr></table></div></figure>


<p>再运行一遍hive，查询一两个SQL。</p>

<p>最终效果：</p>

<p><img src="http://winseliu.com/images/blogs/tez-ui.png" alt="" /></p>

<h2>参考</h2>

<ul>
<li><a href="http://tez.apache.org/install.html">http://tez.apache.org/install.html</a></li>
<li><a href="http://tez.apache.org/tez-ui.html">http://tez.apache.org/tez-ui.html</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html">http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(4)HA升级]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/"/>
    <updated>2016-01-07T23:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade</id>
    <content type="html"><![CDATA[<p>官网的文档[HDFSHighAvailabilityWithQJM.html]和[HdfsRollingUpgrade.html]（Note that rolling upgrade is supported only from Hadoop-2.4.0 onwards.）很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<ol>
<li>关闭所有的namenode，部署新版本的hadoop</li>
<li>启动所有的journalnode，是所有！！升级namenode的同时，也会升级所有journalnode！！</li>
<li>使用-upgrade选项启动一台namenode。启动的这台namenode会直接进入active状态，升级本地的元数据，同时会升级shared edit log（也就是journalnode的数据）</li>
<li>使用-bootstrapStandby启动其他namenode，同步更新。不能使用-upgrade选项！（我也没试，不知道试了是啥效果）</li>
</ol>


<h2>关闭集群，部署新版本的hadoop</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/08 09:10:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/08 09:10:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping zkfc
</span><span class='line'>hadoop-master2: stopping zkfc
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ~/hadoop-2.6.3
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ ll
</span><span class='line'>total 52
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 bin
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop    32 Jan  8 06:05 etc -&gt; /home/hadoop/hadoop-2.2.0/ha-etc
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 include
</span><span class='line'>drwxr-xr-x 3 hadoop hadoop  4096 Dec 18 01:52 lib
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 libexec
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 15429 Dec 18 01:52 LICENSE.txt
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop  4096 Jan  8 03:37 logs
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   101 Dec 18 01:52 NOTICE.txt
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  1366 Dec 18 01:52 README.txt
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 sbin
</span><span class='line'>drwxr-xr-x 3 hadoop hadoop  4096 Jan  7 08:00 share
</span><span class='line'>
</span><span class='line'>#// 同步
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs ~/hadoop-2.6.3 $h:~/ ; done</span></code></pre></td></tr></table></div></figure>


<h2>启动所有Journalnode</h2>

<p>2.6和2.2用的是一份配置！etc通过软链接到2.2的ha-etc配置。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/hadoop-daemons.sh --hostnames "hadoop-master1" --script /home/hadoop/hadoop-2.2.0/bin/hdfs start journalnode
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
</span><span class='line'>31047 JournalNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>31097 Jps</span></code></pre></td></tr></table></div></figure>


<h2>升级一台namenode</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ bin/hdfs namenode -upgrade
</span><span class='line'>...
</span><span class='line'>16/01/08 09:13:54 INFO namenode.NameNode: createNameNode [-upgrade]
</span><span class='line'>...
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSImage: Starting upgrade of local storage directories.
</span><span class='line'>   old LV = -47; old CTime = 0.
</span><span class='line'>   new LV = -60; new CTime = 1452244437060
</span><span class='line'>16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>官网文档上说，除了升级了namenode的本地元数据外，sharededitlog也被升级了的。</p>

<p>查看journalnode的日志，确实journalnode也升级了：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-journalnode-hadoop-master1.log 
</span><span class='line'>...
</span><span class='line'>2016-01-08 09:13:57,070 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Starting upgrade of edits directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,072 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Starting upgrade of edits directory: .
</span><span class='line'>   old LV = -47; old CTime = 0.
</span><span class='line'>   new LV = -60; new CTime = 1452244437060
</span><span class='line'>2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,222 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastWriterEpoch from 2 to 3 for client /172.17.0.1
</span><span class='line'>2016-01-08 09:16:57,731 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 3 to 4 for client /172.17.0.1
</span><span class='line'>2016-01-08 09:16:57,735 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/data/journal/zfcluster)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>升级的namenode是前台运行的，不要关闭这个进程。接下来把另一台namenode同步一下。</p>

<h2>同步另一台namenode</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>...
</span><span class='line'>=====================================================
</span><span class='line'>About to bootstrap Standby ID nn2 from:
</span><span class='line'>           Nameservice ID: zfcluster
</span><span class='line'>        Other Namenode ID: nn1
</span><span class='line'>  Other NN's HTTP address: http://hadoop-master1:50070
</span><span class='line'>  Other NN's IPC  address: hadoop-master1/172.17.0.1:8020
</span><span class='line'>             Namespace ID: 639021326
</span><span class='line'>            Block pool ID: BP-1695500896-172.17.0.1-1452152050513
</span><span class='line'>               Cluster ID: CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
</span><span class='line'>           Layout version: -60
</span><span class='line'>       isUpgradeFinalized: false
</span><span class='line'>=====================================================
</span><span class='line'>16/01/08 09:15:19 INFO ha.BootstrapStandby: The active NameNode is in Upgrade. Prepare the upgrade for the standby NameNode as well.
</span><span class='line'>16/01/08 09:15:19 INFO common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 5008@hadoop-master2
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Opening connection to http://hadoop-master1:50070/imagetransfer?getimage=1&txid=1126&storageInfo=-60:639021326:1452244437060:CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001126 size 977 bytes.
</span><span class='line'>16/01/08 09:15:21 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h2>重新启动集群</h2>

<p>ctrl+c关闭hadoop-master1 upgrade的namenode。启动整个集群。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</span><span class='line'>16/01/08 09:16:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: journalnode running as process 31047. Stop it first.
</span><span class='line'>16/01/08 09:16:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
</span><span class='line'>31047 JournalNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>31596 DFSZKFailoverController
</span><span class='line'>31655 Jps
</span><span class='line'>31294 NameNode
</span></code></pre></td></tr></table></div></figure>


<h2>后记：Journalnode重置</h2>

<p>在HA和non-HA环境来回的切换，最后启动HA时master起不来，执行bootstrapStandby也不行。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-01-08 06:15:36,746 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [172.17.0.1:8485]. Skipping.
</span><span class='line'>org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 1/1. 1 exceptions thrown:
</span><span class='line'>172.17.0.1:8485: Asked for firstTxId 1022 which is in the middle of file /data/journal/zfcluster/current/edits_0000000000000001021-0000000000000001022
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FileJournalManager.getRemoteEditLogs(FileJournalManager.java:198)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:640)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:181)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:203)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:17453)
</span><span class='line'>        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>关闭集群，启动journalnode，跳转到没有问题的namenode机器，执行initializeSharedEdits命令。然后在有问题的namenode上重新初始化！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh</span></code></pre></td></tr></table></div></figure>


<p>后话（谨慎，没有试验过，猜想而已）： 其实上面HA升级的步骤，如果upgrade时没用启动journalnode，导致了问题的话，把journalnode重置应该也是可以的。</p>

<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(3)HA配置]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/"/>
    <updated>2016-01-07T23:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha</id>
    <content type="html"><![CDATA[<p>官网的文档[HDFSHighAvailabilityWithQJM.html]很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<h2>配置</h2>

<p>hadoop-master1和hadoop-master2之间无密钥登录（failover要用到）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-keygen
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master2
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master1</span></code></pre></td></tr></table></div></figure>


<p>配置文件修改：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/core-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hdfs://zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/tmp&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/hdfs-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span><span class='line'>&lt;value&gt; &lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.nameservices&lt;/name&gt;
</span><span class='line'>&lt;value&gt;zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.namenodes.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;nn1,nn2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;qjournal://hadoop-master1:8485/zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.client.failover.proxy.provider.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/journal&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
</span><span class='line'>&lt;value&gt;sshfence&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
</span><span class='line'>&lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>启动</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ..
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.2.0 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>#// 此时可以启动datanode，通过50070端口看namenode的状态
</span><span class='line'>
</span><span class='line'>#// Automatic failover，zkfc和namenode没有启动顺序的问题！
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs zkfc -formatZK
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs haadmin -failover nn1 nn2
</span><span class='line'>
</span><span class='line'>#// 测试failover，把一个active的namenode直接kill掉，看看另一个是否变成active！
</span><span class='line'>
</span><span class='line'># 重启
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/07 10:57:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/07 10:58:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: no zkfc to stop
</span><span class='line'>hadoop-master1: no zkfc to stop
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>16/01/07 10:59:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>16/01/07 10:59:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ jps
</span><span class='line'>15241 DFSZKFailoverController
</span><span class='line'>14882 NameNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>18715 Jps
</span><span class='line'>15076 JournalNode</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html</a></li>
<li><a href="http://www.xlgps.com/article/40993.html">http://www.xlgps.com/article/40993.html</a></li>
<li><a href="http://hbase.apache.org/book.html#basic.prerequisites">http://hbase.apache.org/book.html#basic.prerequisites</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(2)2.2升级到2.6]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/"/>
    <updated>2016-01-07T22:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade</id>
    <content type="html"><![CDATA[<p>升级的命令很简单，但是不要瞎整！升级就一个命令就搞定了！</p>

<h2>部署2.6.3</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.6.3.tar.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.6.3/share/
</span><span class='line'>[hadoop@hadoop-master1 share]$ rm -rf doc/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ rm -rf lib/native/*
</span><span class='line'>
</span><span class='line'>#// 拷贝四个配置文件到hadoop-2.6.3
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ cd etc/hadoop/
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/*-site.xml ./
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/slaves ./
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cd 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span></code></pre></td></tr></table></div></figure>


<h2>升级（最佳方式）</h2>

<p>直接使用upgrade选项启动dfs即可。（secondarynamenode不要单独操作来升级，反正就是执行upgrade启动dfs就好了）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade
</span><span class='line'>
</span><span class='line'>// 2.2和2.6都没有这个命令
</span><span class='line'>// hadoop dfsadmin -upgradeProgress status
</span><span class='line'>hadoop dfsadmin -finalizeUpgrade
</span></code></pre></td></tr></table></div></figure>


<p>参考[Hadoop: The Definitive Guide/Chapter 10. Administering Hadoop/Maintenance/Upgrades]</p>

<h2>瞎整1</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先停集群
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</span></code></pre></td></tr></table></div></figure>


<p>直接在原来的2.2基础上启动，datanode启动没问题，但是namenode报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-namenode-hadoop-master1.log 
</span><span class='line'>...
</span><span class='line'>2016-01-07 08:05:23,582 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
</span><span class='line'>java.io.IOException: 
</span><span class='line'>File system image contains an old layout version -47.
</span><span class='line'>An upgrade to version -60 is required.
</span><span class='line'>Please restart NameNode with the "-rollingUpgrade started" option if a rolling upgrade is already started; or restart NameNode with the "-upgrade" option to start a new upgrade.
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:232)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:764)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:748)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
</span><span class='line'>2016-01-07 08:05:23,583 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
</span><span class='line'>2016-01-07 08:05:23,585 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
</span><span class='line'>/************************************************************
</span><span class='line'>SHUTDOWN_MSG: Shutting down NameNode at hadoop-master1/172.17.0.1
</span><span class='line'>************************************************************/</span></code></pre></td></tr></table></div></figure>


<p>重新启动，使用upgrade选项启动：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade</span></code></pre></td></tr></table></div></figure>


<p>或者还原到2.2：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># **所有**slaver节点的VERSION改回47
</span><span class='line'>[hadoop@hadoop-slaver3 ~]$ vi /data/tmp/dfs/data/current/VERSION 
</span><span class='line'>...
</span><span class='line'>layoutVersion=-47
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh -rollback
</span></code></pre></td></tr></table></div></figure>


<h2>原理</h2>

<p>升级的时刻，首先备份原来的数据到previous目录下，升级后的放置到current目录下。namenode这样没啥大问题，但是datanode也是这样结构current和previous，那相当有问题，那数据量不是翻倍了？</p>

<p>查看数据后，发现一个名字的文件current和previous里面使用的是一个inode。也就是说用的是硬链接，数据只有一份！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop fs -put *.txt /
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver3 ~]$ cd /data/tmp/dfs/data/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ test current/finalized/subdir0/subdir0/blk_1073741825 -ef previous/finalized/blk_1073741825
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ echo $?
</span><span class='line'>0
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i current/finalized/subdir0/subdir0/blk_1073741825 
</span><span class='line'>142510 current/finalized/subdir0/subdir0/blk_1073741825
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i previous/finalized/blk_1073741825
</span><span class='line'>142510 previous/finalized/blk_1073741825
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-Docker中安装(1)]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/"/>
    <updated>2016-01-07T21:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker</id>
    <content type="html"><![CDATA[<h2>集群机器准备</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# docker -v
</span><span class='line'>Docker version 1.6.2, build 7c8fca2/1.6.2
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker images
</span><span class='line'>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
</span><span class='line'>centos              centos6             62068de82c82        4 months ago        250.7 MB
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-master1 -h hadoop-master1 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>c975b0e41429a3c214e86552f2a9f599ba8ee7487e8fbdc25fd59d29adacca4f
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-master2 -h hadoop-master2 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>fac1d2ee4a05ab8457f4bd6756622ac8236f64423544150d355f9e3091764d8f
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-slaver1 -h hadoop-slaver1 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>cc8734f2a0963a030b994f69be697308a13e511557eaefc7d4aca7e300950ded
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-slaver2 -h hadoop-slaver2 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>7e4b5410a7cb8585436775f15609708b309a5b83930da74d6571533251c26355
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-slaver3 -h hadoop-slaver3 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>26018b256403d956b4272b6bda09a58d1fc6938591d18f9892ba72782c41880b
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker ps -a
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND               CREATED              STATUS              PORTS               NAMES
</span><span class='line'>26018b256403        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver3      
</span><span class='line'>7e4b5410a7cb        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver2      
</span><span class='line'>cc8734f2a096        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver1      
</span><span class='line'>fac1d2ee4a05        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-master2      
</span><span class='line'>c975b0e41429        centos:centos6      "/usr/sbin/sshd -D"   8 minutes ago        Up 8 minutes                            hadoop-master1      
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker ps | grep hadoop | awk '{print $1}' | xargs -I{} docker inspect -f ' ' {}
</span><span class='line'>172.17.0.6 hadoop-slaver3
</span><span class='line'>172.17.0.5 hadoop-slaver2
</span><span class='line'>172.17.0.4 hadoop-slaver1
</span><span class='line'>172.17.0.3 hadoop-master2
</span><span class='line'>172.17.0.2 hadoop-master1</span></code></pre></td></tr></table></div></figure>


<p>重启docker后，可以直接通过名称启动即可：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# service docker start
</span><span class='line'>Starting docker:                                           [  OK  ]
</span><span class='line'>[root@cu2 ~]# docker start hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3
</span><span class='line'>hadoop-master1
</span><span class='line'>hadoop-master2
</span><span class='line'>hadoop-slaver1
</span><span class='line'>hadoop-slaver2
</span><span class='line'>hadoop-slaver3</span></code></pre></td></tr></table></div></figure>


<p>重启后，hosts文件会被重置！最好就是测试好之前不要重启docker！</p>

<h2>机器配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# ssh root@172.17.0.2
</span><span class='line'>root@172.17.0.2's password: 
</span><span class='line'>Last login: Thu Jan  7 06:17:11 2016 from 172.17.42.1
</span><span class='line'>[root@hadoop-master1 ~]# 
</span><span class='line'>[root@hadoop-master1 ~]# vi /etc/hosts
</span><span class='line'>127.0.0.1       localhost
</span><span class='line'>::1     localhost ip6-localhost ip6-loopback
</span><span class='line'>fe00::0 ip6-localnet
</span><span class='line'>ff00::0 ip6-mcastprefix
</span><span class='line'>ff02::1 ip6-allnodes
</span><span class='line'>ff02::2 ip6-allrouters
</span><span class='line'>
</span><span class='line'>172.17.0.6 hadoop-slaver3
</span><span class='line'>172.17.0.5 hadoop-slaver2
</span><span class='line'>172.17.0.4 hadoop-slaver1
</span><span class='line'>172.17.0.3 hadoop-master2
</span><span class='line'>172.17.0.2 hadoop-master1
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 ~]# ssh-keygen
</span><span class='line'>[root@hadoop-master1 ~]# 
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-master1
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-master2
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver1
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver2
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver3
</span><span class='line'>
</span><span class='line'># 拷贝hosts
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp /etc/hosts $h:/etc/ ; done
</span><span class='line'>
</span><span class='line'># 安装需要的软件
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h "yum install man rsync curl wget tar" ; done
</span><span class='line'>
</span><span class='line'># 创建用户
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h useradd hadoop ; done
</span><span class='line'>
</span><span class='line'>#// 把要设置的密码拷贝一下，接下来直接右键（CRT）粘贴弄5次就可以了。如果是几十几百台机器可以使用expect来实现
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h passwd hadoop ; done
</span><span class='line'>New password: hadoop
</span><span class='line'>BAD PASSWORD: it is based on a dictionary word
</span><span class='line'>BAD PASSWORD: is too simple
</span><span class='line'>Retype new password: hadoop
</span><span class='line'>Changing password for user hadoop.
</span><span class='line'>passwd: all authentication tokens updated successfully.
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'># 建立数据目录，赋权给hadoop用户
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h "mkdir /data; chown hadoop:hadoop /data" ; done
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 ~]# su - hadoop
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-keygen 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-master1
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-master2
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver1
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver2
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver3
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ll
</span><span class='line'>total 139036
</span><span class='line'>drwxr-xr-x 9 hadoop hadoop      4096 Oct  7  2013 hadoop-2.2.0
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 142362384 Jan  7 07:14 jdk-7u60-linux-x64.gz
</span><span class='line'>drwxr-xr-x 8 hadoop hadoop      4096 Jan  7 07:11 zookeeper-3.4.6
</span><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf jdk-7u60-linux-x64.gz 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.2.0.tar.gz 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf zookeeper-3.4.6.tar.gz 
</span><span class='line'>
</span><span class='line'># 清理生产上无用的数据
</span><span class='line'>[hadoop@hadoop-master1 ~]$ rm hadoop-2.2.0.tar.gz zookeeper-3.4.6.tar.gz jdk-7u60-linux-x64.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd zookeeper-3.4.6/
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ rm -rf docs/ src/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ cd ../hadoop-2.2.0/
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd share/
</span><span class='line'>[hadoop@hadoop-master1 share]$ rm -rf doc/</span></code></pre></td></tr></table></div></figure>


<h2>程序配置与启动</h2>

<ul>
<li>java</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ cd
</span><span class='line'>[hadoop@hadoop-master1 ~]$ vi .bashrc 
</span><span class='line'>...
</span><span class='line'>JAVA_HOME=~/jdk1.7.0_60
</span><span class='line'>PATH=$JAVA_HOME/bin:$PATH
</span><span class='line'>
</span><span class='line'>export JAVA_HOME PATH</span></code></pre></td></tr></table></div></figure>


<p>退出shell再登录，或者source .bashrc！</p>

<ul>
<li>zookeeper</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ cd zookeeper-3.4.6/conf
</span><span class='line'>[hadoop@hadoop-master1 conf]$ cp zoo_sample.cfg zoo.cfg
</span><span class='line'>[hadoop@hadoop-master1 conf]$ vi zoo.cfg 
</span><span class='line'>...
</span><span class='line'>dataDir=/data/zookeeper
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ mkdir /data/zookeeper
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd ~/zookeeper-3.4.6/
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ bin/zkServer.sh start
</span><span class='line'>JMX enabled by default
</span><span class='line'>Using config: /home/hadoop/zookeeper-3.4.6/bin/../conf/zoo.cfg
</span><span class='line'>Starting zookeeper ... STARTED
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ 
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ jps
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>265 Jps
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ less zookeeper.out </span></code></pre></td></tr></table></div></figure>


<ul>
<li>hadoop</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ cd ~/hadoop-2.2.0/etc/hadoop/
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ rm *.cmd
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi hadoop-env.sh 
</span><span class='line'># 修改java_home和pid
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi core-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hdfs://hadoop-master1:9000&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/tmp&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi hdfs-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span><span class='line'>&lt;value&gt; &lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi mapred-site.xml
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
</span><span class='line'>&lt;value&gt;yarn&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:10020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:19888&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi yarn-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8032&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8030&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8031&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8033&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8080&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<p>启动Hadoop</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop version
</span><span class='line'>Hadoop 2.2.0
</span><span class='line'>Subversion https://svn.apache.org/repos/asf/hadoop/common -r 1529768
</span><span class='line'>Compiled by hortonmu on 2013-10-07T06:28Z
</span><span class='line'>Compiled with protoc 2.5.0
</span><span class='line'>From source with checksum 79e53ce7994d1628b240f09af91e1af4
</span><span class='line'>This command was run using /home/hadoop/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop namenode -format
</span><span class='line'>
</span><span class='line'># 默认自带的libhadoop有点问题，start-dfs.sh通过hdfs getconf -namenodes输出信息导致执行错误
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ rm lib/native/libh*
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r jdk1.7.0_60 $h:~/ ; done
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r hadoop-2.2.0 $h:~/ ; done
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r .bashrc $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ jps
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>3995 NameNode
</span><span class='line'>4187 Jps</span></code></pre></td></tr></table></div></figure>


<p>通过CRT的Port Forwarding的dynamic socket5，浏览器配置socket5代理就可以通过50070端口查看hadoop hdfs集群的状态了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Postgresql入门]]></title>
    <link href="http://winseliu.com/blog/2015/12/13/postgresql-start-guide/"/>
    <updated>2015-12-13T23:19:55+08:00</updated>
    <id>http://winseliu.com/blog/2015/12/13/postgresql-start-guide</id>
    <content type="html"><![CDATA[<p>简单介绍下软件的安装，配置。同时实践下从mysql迁移到postgres。</p>

<h2>安装配置</h2>

<p>这里直接使用rpm包来安装。如果是centos6.6以下版本的系统需要更新openssl。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 postgres]# ll
</span><span class='line'>total 20708
</span><span class='line'>-rw-r--r-- 1 root root  1593932 Dec 11 10:02 openssl-1.0.1e-42.el6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  1085208 Dec 11 09:12 postgresql94-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root   541376 Dec 11 09:12 postgresql94-contrib-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  1600736 Dec 11 09:12 postgresql94-devel-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root 11485008 Dec 11 09:13 postgresql94-docs-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root   198968 Dec 11 09:12 postgresql94-libs-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root    60688 Dec 11 09:12 postgresql94-plperl-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root    68884 Dec 11 09:12 postgresql94-plpython-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  4556880 Dec 11 09:11 postgresql94-server-9.4.5-1PGDG.rhel6.x86_64.rpm</span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装命令：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum install -y openssl-1.0.1e-42.el6.x86_64.rpm 
</span><span class='line'>
</span><span class='line'># useradd postgres
</span><span class='line'># rpm -i postgresql94-*</span></code></pre></td></tr></table></div></figure>


<ul>
<li>配置环境变量、初始化数据库、启动数据库：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># su - postgres
</span><span class='line'>$ vi .bash_profile
</span><span class='line'>
</span><span class='line'>export PGDATA=/var/lib/pgsql/9.4/data
</span><span class='line'>PG_HOME=/usr/pgsql-9.4
</span><span class='line'>PATH=$PG_HOME/bin:$PATH
</span><span class='line'>export PATH
</span><span class='line'>
</span><span class='line'>$ initdb
</span><span class='line'>
</span><span class='line'>$ vi $PGDATA/pg_hba.conf
</span><span class='line'>  host    all             all              192.168.0.0/16          md5
</span><span class='line'>
</span><span class='line'>$ vi /var/lib/pgsql/9.4/data/postgresql.conf
</span><span class='line'>  listen_addresses = '*'
</span><span class='line'>
</span><span class='line'># 切回root
</span><span class='line'>
</span><span class='line'># service postgresql-9.4 start
</span><span class='line'># chkconfig postgresql-9.4 on --level 2345</span></code></pre></td></tr></table></div></figure>


<p>pg_hba.conf用来控制什么用于可以被远程访问。而postgresql.conf修改的监听的地址，默认是localhost改成*后就可以所有地址都可以访问了。</p>

<ul>
<li>建立库，创建数据库用户</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ psql 
</span><span class='line'>
</span><span class='line'> create user dpi;
</span><span class='line'> create database dpi owner dpi;
</span><span class='line'> alter user dpi with password 'XXXX';</span></code></pre></td></tr></table></div></figure>


<p>建表：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE TABLE t_dta_illegalweb (
</span><span class='line'>...
</span><span class='line'>  day varchar(10) DEFAULT NULL,
</span><span class='line'>...
</span><span class='line'>);
</span><span class='line'>
</span><span class='line'>create or replace function t_dta_illegalweb_insert_trigger()
</span><span class='line'>returns trigger as $$
</span><span class='line'>begin
</span><span class='line'>  return null;
</span><span class='line'>end; 
</span><span class='line'>$$ language plpgsql;
</span><span class='line'>
</span><span class='line'>CREATE TRIGGER trigger_t_dta_illegalweb_insert
</span><span class='line'>    BEFORE INSERT ON t_dta_illegalweb
</span><span class='line'>    FOR EACH ROW EXECUTE PROCEDURE t_dta_illegalweb_insert_trigger();
</span></code></pre></td></tr></table></div></figure>


<p>后面会使用分区表，先把触发器都建好。把框框搭好，后面修改就行了。</p>

<h2>数据迁移</h2>

<ol>
<li>postgres创建表：</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151211 (check(day = '2015-12-11')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151210 (check(day = '2015-12-10')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151209 (check(day = '2015-12-09')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151208 (check(day = '2015-12-08')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151207 (check(day = '2015-12-07')) INHERITS (t_dta_illegalweb);</span></code></pre></td></tr></table></div></figure>


<ol>
<li>mysql导出数据：</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>select * from t_dta_illegalweb where day='2015-12-09' into outfile '/tmp/etl/t_dta_illegalweb20151209.sql'  fields terminated by '|';
</span><span class='line'>select * from t_dta_illegalweb where day='2015-12-08' into outfile '/tmp/etl/t_dta_illegalweb20151208.sql'  fields terminated by '|';
</span><span class='line'>select * from t_dta_illegalweb where day='2015-12-07' into outfile '/tmp/etl/t_dta_illegalweb20151207.sql'  fields terminated by '|';</span></code></pre></td></tr></table></div></figure>


<p>数据在mysql服务器的/tmp/etl目录下面。如果mysql和postgres不在同一台机，需要把这些文件拷贝到postgres的服务器。</p>

<ol>
<li>导入数据到postgres:</li>
</ol>


<p>用psql登录dpi，然后执行copy命令把数据导入到对应的表。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>\copy  t_dta_illegalweb20151209 from  '/tmp/etl/t_dta_illegalweb20151209.sql' using delimiters '|' ;
</span><span class='line'>\copy  t_dta_illegalweb20151208 from  '/tmp/etl/t_dta_illegalweb20151208.sql' using delimiters '|' ;
</span><span class='line'>\copy  t_dta_illegalweb20151207 from  '/tmp/etl/t_dta_illegalweb20151207.sql' using delimiters '|' ;</span></code></pre></td></tr></table></div></figure>


<h2>程序修改</h2>

<p>程序修改是一件头痛的事情，虽然大部分都是SQL，但是MYSQL的比较宽泛，很多语句都兼容不报错也能出来想要的结果。但是这些语句在postgres下面执行是会报错的。比如说，select count(*)对所有数据count的时刻不能加order by（提示要groupby）；再比如，mysql遇到字符串字段和数字比较会统一转换成数字比较，等等这些在postgres中都需要在SQL中显示的转换的。</p>

<p>那么postgres的类型转换怎么实现呢？两种形式cast(X as TYPE) 或者 X::TYPE。</p>

<p>由于程序是用hibernate来做数据库访问的，会遇到如下的问题</p>

<ul>
<li>如果用hql的话CAST函数hibernate首先会进行转换。（转换类型与hibernate对象的类型不匹配）</li>
<li>而用X::TYPE会把:TYPE作为一个name parameter。</li>
<li>不用hql用sql的话，要自己做对象转换，这是我们不愿意去做的事情（不然用hibernate干嘛）</li>
</ul>


<p>各种尝试过后，修改PostgreSQLDialect来实现，添加一个自定义的hibernate函数，把字符串转成bigint即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import java.sql.Types;
</span><span class='line'>
</span><span class='line'>import org.hibernate.Hibernate;
</span><span class='line'>import org.hibernate.dialect.function.SQLFunctionTemplate;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>public class PostgreSQLDialect extends org.hibernate.dialect.PostgreSQLDialect {
</span><span class='line'>  
</span><span class='line'>  public PostgreSQLDialect() {
</span><span class='line'>      super();
</span><span class='line'>      registerFunction( "bigint", new SQLFunctionTemplate(Hibernate.BIG_INTEGER, "cast(?1 as bigint)") );
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>使用如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>StringBuilder hql = new StringBuilder("from IllegalWebInfo where 1=1 ");
</span><span class='line'>List&lt;Object&gt; params = new ArrayList&lt;&gt;();
</span><span class='line'>
</span><span class='line'>String domain = queryBean.getDomain();
</span><span class='line'>if (StringUtils.isNotBlank(domain)) {
</span><span class='line'>  hql.append(" and ").append("domain=?");
</span><span class='line'>  params.add(domain.toLowerCase());
</span><span class='line'>}
</span><span class='line'>String houseId = queryBean.getHouseId();
</span><span class='line'>if (StringUtils.isNotBlank(houseId)) {
</span><span class='line'>  hql.append(" and ").append("houseId=?");
</span><span class='line'>  params.add(houseId);
</span><span class='line'>}
</span><span class='line'>String day = queryBean.getDay();
</span><span class='line'>if (StringUtils.isNotBlank(day)) {
</span><span class='line'>  hql.append(" and ").append("day=?");
</span><span class='line'>  params.add(day);
</span><span class='line'>}
</span><span class='line'>int threshold = queryBean.getThreshold();
</span><span class='line'>if(threshold &gt; 0){
</span><span class='line'>  hql.append(" and ").append("bigint(visitsCount) &gt;= ?");
</span><span class='line'>  params.add(BigInteger.valueOf(threshold)); // 注意这里的类型转换，把int装成bigint
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>Object[] paramArray = params.toArray();
</span><span class='line'>String detailHQL = hql.toString(); // + " order by bigint(visitsCount) desc ";
</span><span class='line'>List&lt;ActiveResourcesDomainInfo&gt; hist = activeResourcesDomainDao.findPageable(detailHQL, currentPage, pageSize, paramArray);
</span><span class='line'>
</span><span class='line'>String countHQL = "select count(*) " + hql;
</span><span class='line'>long count = (long) illegalWebDao.findByHql(countHQL, paramArray).iterator().next();</span></code></pre></td></tr></table></div></figure>


<h2>定时任务，创建和更新触发器函数</h2>

<p>函数：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>create or replace function create_partition_table_everyday (t TEXT) returns timestamp as $$
</span><span class='line'>declare 
</span><span class='line'>  i int;
</span><span class='line'>  cnt int;
</span><span class='line'>  stmt text;
</span><span class='line'>  select_stmt text;
</span><span class='line'>  day date;
</span><span class='line'>  isInherit BOOLEAN;
</span><span class='line'>begin
</span><span class='line'>
</span><span class='line'>  day := now() + interval '-1 day';
</span><span class='line'>  stmt := 'CREATE TABLE IF NOT EXISTS ' || t || to_char(day, 'YYYYMMDD') || '(check(day = ''' || to_char(day, 'YYYY-MM-DD') || ''')) INHERITS (' || t || ')';
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>
</span><span class='line'>  day := now() + interval '-183 day';
</span><span class='line'>  stmt := 'DROP TABLE IF EXISTS ' || t || to_char(day, 'YYYYMMDD');
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>
</span><span class='line'>BEGIN
</span><span class='line'>  day := now() + interval '-32 day';
</span><span class='line'>  stmt := 'ALTER TABLE IF EXISTS ' || t || to_char(day, 'YYYYMMDD') || ' NO INHERIT ' || t;
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>EXCEPTION WHEN OTHERS THEN
</span><span class='line'>  RAISE INFO '[WARN] % %', SQLERRM, SQLSTATE;
</span><span class='line'>END;
</span><span class='line'>
</span><span class='line'>  i := 0;
</span><span class='line'>  cnt := 6; -- 用于生成触发器分发最近几天的insert功能
</span><span class='line'>
</span><span class='line'>  day := now() + interval '-1 day';
</span><span class='line'>  stmt :=         ' create or replace function ' || t || '_insert_trigger() returns trigger as $' || '$ ';
</span><span class='line'>  stmt := stmt || ' begin ';
</span><span class='line'>  stmt := stmt || ' if (new.day = ''' || to_char(day, 'YYYY-MM-DD') || ''') then INSERT INTO ' || t || to_char(day, 'YYYYMMDD') || ' VALUES (new.*); ';
</span><span class='line'>  while i &lt; cnt 
</span><span class='line'>  loop
</span><span class='line'>      day := day + interval '-1 day';
</span><span class='line'>      stmt := stmt || ' elsif (new.day = ''' || to_char(day, 'YYYY-MM-DD') || ''') then INSERT INTO ' || t || to_char(day, 'YYYYMMDD') || ' VALUES (new.*); ';
</span><span class='line'>
</span><span class='line'>      i := i + 1;
</span><span class='line'>  end loop;
</span><span class='line'>  stmt := stmt || ' else raise exception ''DATE out of range. Fix the ' || t || '_insert_trigger() func!!''; ';
</span><span class='line'>  stmt := stmt || ' end if; ';
</span><span class='line'>  stmt := stmt || ' return null; ';
</span><span class='line'>  stmt := stmt || ' end;  ';
</span><span class='line'>  stmt := stmt || ' $' || '$ language plpgsql; ';
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>
</span><span class='line'>  return now();
</span><span class='line'>end;
</span><span class='line'>$$ language plpgsql;
</span></code></pre></td></tr></table></div></figure>


<p>脚本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>vi update_dta_postgres.sh
</span><span class='line'>
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>source ~/.bash_profile
</span><span class='line'>
</span><span class='line'>psql -d dpi -c "select create_partition_table_everyday('t_dta_illegalweb')"
</span><span class='line'>psql -d dpi -c "select create_partition_table_everyday('t_dta_activeresources_domain')"
</span><span class='line'>psql -d dpi -c "select create_partition_table_everyday('t_dta_activeresources_ip')"
</span><span class='line'>
</span><span class='line'>$ 
</span><span class='line'>chmod +x update_dta_postgres.sh 
</span><span class='line'>crontab -e
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>10 0 * * * sh ~/scripts/update_dta_postgres.sh &gt;~/scripts/update_dta_postgres.log 2&gt;&1</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://stackoverflow.com/questions/22648597/linux-centos-yum-error-package-requires-libcrypto-so-10openssl-1-0-1-ec64bi">http://stackoverflow.com/questions/22648597/linux-centos-yum-error-package-requires-libcrypto-so-10openssl-1-0-1-ec64bi</a></li>
<li><a href="http://twpug.net/docs/postgresql-doc-8.0-zh_TW/functions-comparison.html">http://twpug.net/docs/postgresql-doc-8.0-zh_TW/functions-comparison.html</a></li>
<li><a href="http://stackoverflow.com/questions/7690329/check-if-table-inherits-from-other-table-in-postgresql">http://stackoverflow.com/questions/7690329/check-if-table-inherits-from-other-table-in-postgresql</a></li>
<li><a href="http://www.jaredlog.com/?p=137">http://www.jaredlog.com/?p=137</a></li>
<li><a href="http://www.anicehumble.com/2011/08/postgresql-catch-exception-rocks.html">http://www.anicehumble.com/2011/08/postgresql-catch-exception-rocks.html</a></li>
<li><a href="http://stackoverflow.com/questions/4877637/postgresql-exception-handling">http://stackoverflow.com/questions/4877637/postgresql-exception-handling</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭梯笔记]]></title>
    <link href="http://winseliu.com/blog/2015/11/22/gfw-ladder/"/>
    <updated>2015-11-22T20:51:35+08:00</updated>
    <id>http://winseliu.com/blog/2015/11/22/gfw-ladder</id>
    <content type="html"><![CDATA[<h2>准备一个SSH账号</h2>

<ul>
<li><a href="http://www.99ssh.net/">http://www.99ssh.net/</a></li>
</ul>


<h2>SSH -N -D 或者MyEnTunnel</h2>

<ul>
<li><code>ssh -N -D [PORT] [USER@IP]</code></li>
<li><a href="http://www.99ssh.net/help/newsshow.php?cid=19&amp;id=21">http://www.99ssh.net/help/newsshow.php?cid=19&amp;id=21</a></li>
</ul>


<p>使用MyEnTunel的话，设置程序为【启动软件时自动连接】，同时把程序的快捷方式加到【C:\Users\winse\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup\】目录下。</p>

<h2>Chrome + SwitchyOmega + gfwlist</h2>

<ul>
<li><a href="https://github.com/FelisCatus/SwitchyOmega/releases">https://github.com/FelisCatus/SwitchyOmega/releases</a> SwitchySharp升级版本</li>
<li><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a></li>
</ul>


<p>可以做到智能代理功能，gfwlist的才会走代理。加速访问国内网站，同时减少不必要的流量。</p>

<h2>Firefox + FoxyProxy + gfwlist</h2>

<ul>
<li><a href="http://mozilla.com.cn/thread-230260-1-1.html">http://mozilla.com.cn/thread-230260-1-1.html</a></li>
<li><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a></li>
</ul>


<p>Chrome的版本速度快一点。配置好后，等待一段时间就智能的适配了，firefox的等的时间略长。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx再折腾---统一访问入口]]></title>
    <link href="http://winseliu.com/blog/2015/11/11/nginx-build-unified-access/"/>
    <updated>2015-11-11T11:04:04+08:00</updated>
    <id>http://winseliu.com/blog/2015/11/11/nginx-build-unified-access</id>
    <content type="html"><![CDATA[<p>快照目录文件太多，准备安装一个方式分目录。但是又要能保证原来的访问方式不变化！使用rewrite和try_files成功实现。</p>

<h2>目录结构:</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@Lenovo-PC /cygdrive/f/temp
</span><span class='line'>$ ls -R
</span><span class='line'>.:
</span><span class='line'>1.jpg  snapshot  snapshot-1  snapshot-2  snapshot-3  snapshot-4
</span><span class='line'>
</span><span class='line'>./snapshot:
</span><span class='line'>0.html
</span><span class='line'>
</span><span class='line'>./snapshot-1:
</span><span class='line'>1.html
</span><span class='line'>
</span><span class='line'>./snapshot-2:
</span><span class='line'>2.html
</span><span class='line'>
</span><span class='line'>./snapshot-3:
</span><span class='line'>3.html
</span><span class='line'>
</span><span class='line'>./snapshot-4:
</span><span class='line'>4.html</span></code></pre></td></tr></table></div></figure>


<h2>Nginx配置尝试一:</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>    location /snapshot {
</span><span class='line'>        root   /home/hadoop/html-snapshot;
</span><span class='line'>        add_header content-type "text/html";
</span><span class='line'>
</span><span class='line'>        rewrite ^/snapshot/.*/(.*)$  /snapshot/$1 break ;
</span><span class='line'>        
</span><span class='line'>        try_files $uri /snapshot-1/$uri /snapshot-3/$uri;
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    location ~ /snapshot-\d+ {
</span><span class='line'>        root   /home/hadoop/html-snapshot;
</span><span class='line'>
</span><span class='line'>        rewrite ^/(.*)/.*/(.*)$ /$1/$2 break;
</span><span class='line'>    }</span></code></pre></td></tr></table></div></figure>


<p>这种方式是不行的，try_files要求除最后一个配置外其他都是文件！</p>

<blockquote><p>It is possible to check directory’s existence by specifying a slash at the end of a name, e.g. “$uri/”. If none of the files were found, an internal redirect to the uri specified in the last parameter is made.  [<a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files">http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files</a>]</p></blockquote>

<p>也就是说，中间配置路径，nginx只把他们当做本地的去看待！文件存在就返回结果，否则直接重定向到最后一个路径！！</p>

<h2>Nginx配置尝试二：</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>    location /snapshot {
</span><span class='line'>        root   F:/temp;
</span><span class='line'>        add_header content-type "text/html";
</span><span class='line'>
</span><span class='line'>        rewrite ^/snapshot/.*/(.*)$  /snapshot/$1 break ;
</span><span class='line'>
</span><span class='line'>        try_files $uri @backup;
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    location ~ /snapshot-\d+ {
</span><span class='line'>        root   F:/temp;
</span><span class='line'>
</span><span class='line'>      try_files $uri @backup;
</span><span class='line'>    }
</span><span class='line'>  
</span><span class='line'>    location @backup {
</span><span class='line'>      # 这里的顺序不能颠倒，[.*]会匹配所有的！
</span><span class='line'>        rewrite ^/(.*)-3/(.*)$ /$1-4/$2 last;
</span><span class='line'>        rewrite ^/(.*)-2/(.*)$ /$1-3/$2 last;
</span><span class='line'>        rewrite ^/(.*)-1/(.*)$ /$1-2/$2 last;
</span><span class='line'>        rewrite ^/(.*)/(.*)$ /$1-1/$2 last;
</span><span class='line'>    }</span></code></pre></td></tr></table></div></figure>


<p>这里使用循环的方式在backup的location中进行处理，一个个的循环查找。使用了正则表达式和一个统一rewrite的location。</p>

<h2>Nginx配置尝试三：</h2>

<p>上面发现，其实try_files都是去查找文件，其实目录结构和访问路径是匹配的，只是请求一开始就带snaphost，倒是每次都需要处理。如果请求过来的就没有带snaphost的话！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>    location / {
</span><span class='line'>        root   F:/temp;
</span><span class='line'>        add_header content-type "text/html";
</span><span class='line'>
</span><span class='line'>        try_files /snapshot/$uri /snapshot-1/$uri  /snapshot-2/$uri  /snapshot-3/$uri  /snapshot-4/$uri;
</span><span class='line'>    }</span></code></pre></td></tr></table></div></figure>


<p>一个location配置就行了！</p>

<h2>Nginx配置完善版：</h2>

<p>转变思路后，最开始就把请求的前置snapshot去掉rewrite去掉就行了！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>    location /snapshot {
</span><span class='line'>        root   F:/temp;
</span><span class='line'>        add_header content-type "text/html";
</span><span class='line'>      
</span><span class='line'>      rewrite ^/snapshot/.*/(.*)$  /$1 break ;
</span><span class='line'>
</span><span class='line'>        try_files /snapshot/$uri /snapshot-1/$uri  /snapshot-2/$uri  /snapshot-3/$uri  /snapshot-4/$uri;
</span><span class='line'>    }</span></code></pre></td></tr></table></div></figure>


<h2>nginx添加模块</h2>

<p>当我们启用 &ndash;with-debug 选项重新构建好调试版的 Nginx 之后，还需要同时在配置文件中通过标准的 error_log 配置指令为错误日志使用 debug 日志级别（这同时也是最低的日志级别）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>error_log logs/error.log debug;</span></code></pre></td></tr></table></div></figure>


<p>添加echo模块：</p>

<p>下载zlib、pcre、echo：</p>

<ul>
<li><a href="http://www.zlib.net/">http://www.zlib.net/</a></li>
<li><a href="http://www.pcre.org/">http://www.pcre.org/</a></li>
<li><a href="https://github.com/openresty/echo-nginx-module">https://github.com/openresty/echo-nginx-module</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar zxvf zlib-1.2.8.tar.gz 
</span><span class='line'>mv zlib-1.2.8 src/zlib
</span><span class='line'>tar zxvf pcre-8.36.tar.gz 
</span><span class='line'>mv pcre-8.36 src/pcre
</span><span class='line'>
</span><span class='line'>./configure --prefix=/home/hadoop/nginx --add-module=/home/hadoop/echo-nginx-module-0.58  --with-pcre=src/pcre --with-zlib=src/zlib --with-debug 
</span><span class='line'>#[hadoop@cu2 nginx-1.7.10]$ ./configure --prefix=/home/hadoop/nginx --with-http_ssl_module --with-pcre=src/pcre/ --with-zlib=src/zlib/ --with-debug
</span><span class='line'>make -j2
</span><span class='line'>make install</span></code></pre></td></tr></table></div></figure>


<p>编译成功后，就能在location里面直接echo，页面访问时就能看到echo内容了。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.cnblogs.com/cgli/archive/2011/05/16/2047920.html">http://www.cnblogs.com/cgli/archive/2011/05/16/2047920.html</a></li>
<li><a href="http://www.cnblogs.com/tohilary/archive/2012/08/24/2653904.html">http://www.cnblogs.com/tohilary/archive/2012/08/24/2653904.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[树莓派raspberrypi2简单使用]]></title>
    <link href="http://winseliu.com/blog/2015/11/04/raspberrypi-start-guide/"/>
    <updated>2015-11-04T11:52:18+08:00</updated>
    <id>http://winseliu.com/blog/2015/11/04/raspberrypi-start-guide</id>
    <content type="html"><![CDATA[<h2>买的东西地址：</h2>

<p>现在想来，其实可以多加100，买一整套的比较方便。内存卡还有外壳都在里面。</p>

<ul>
<li><p><a href="https://item.taobao.com/item.htm?id=520179324500&amp;ali_refid=a3_420434_1006:1103723226:N:%E6%A0%91%E8%8E%93%E6%B4%BE2+b%2B:fc636846d2212679077e26f5f9f14118&amp;ali_trackid=1_fc636846d2212679077e26f5f9f14118&amp;spm=a230r.1.0.0.vhiQsb&amp;qq-pf-to=pcqq.c2c">树莓派2b 树莓派raspberry Pi 2代B型四核开发板 官方正品 树莓派</a></p></li>
<li><p><a href="http://item.jd.com/679773.html">闪迪（SanDisk）至尊高速移动MicroSDHC UHS-I存储卡 TF卡 32GB Class10 读速48Mb/s</a></p></li>
<li><a href="http://item.jd.com/667570.html">迅捷（FAST）FW150US 超小型150M无线USB网卡</a></li>
<li><p><a href="https://detail.tmall.com/item.htm?_u=4jgup6l1c31&amp;id=45729451918">USB转TTL PL2303HX模块 STC单片机下载线刷机线 升级串口模块</a></p></li>
<li><p><a href="http://item.jd.com/629794.html">雷柏（Rapoo）1860 无线光学键鼠套装</a>  质量一般。临时用用，可以考虑不买！</p></li>
</ul>


<h2>安装系统</h2>

<ul>
<li>显示器： 恰好同时有HDMI的接口和显示器。如果没有，那就要考虑直接把系统写到SD卡了！！</li>
<li>无线键盘、鼠标</li>
<li>电源： 一般的手机充电器都可以，用充电宝也是OK的</li>
<li><a href="https://www.raspberrypi.org/help/noobs-setup/">NOOBS</a>

<ul>
<li>NOOBS_v1_4_2.zip</li>
<li>SDFormatterv4.zip</li>
</ul>
</li>
</ul>


<p>插上SD卡，安装系统就行了。</p>

<p><img src="http://winseliu.com/images/blogs/raspberrypi-os-install.png" alt="" /></p>

<h2>无线网卡</h2>

<p>网站上没说有linux的驱动，但是直接插上后是能检测到设备的！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pi@raspberrypi:~$ lsusb
</span><span class='line'>Bus 001 Device 004: ID 0bda:8179 Realtek Semiconductor Corp. 
</span><span class='line'>Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet Adapter
</span><span class='line'>Bus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. 
</span><span class='line'>Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub</span></code></pre></td></tr></table></div></figure>


<p>ifconfig也能查看到wlan0的无线网卡。接下来修改配置，添加用户密码即可。</p>

<p>配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pi@raspberrypi:~$ cat /etc/network/interfaces
</span><span class='line'># Please note that this file is written to be used with dhcpcd.
</span><span class='line'># For static IP, consult /etc/dhcpcd.conf and 'man dhcpcd.conf'.
</span><span class='line'>
</span><span class='line'>auto lo
</span><span class='line'>iface lo inet loopback
</span><span class='line'>
</span><span class='line'>auto eth0
</span><span class='line'>allow-hotplug eth0
</span><span class='line'>#iface eth0 inet manual
</span><span class='line'>iface eth0 inet dhcp
</span><span class='line'>
</span><span class='line'>auto wlan0
</span><span class='line'>allow-hotplug wlan0
</span><span class='line'>#iface wlan0 inet manual
</span><span class='line'>iface wlan0 inet dhcp
</span><span class='line'>wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf
</span><span class='line'>
</span><span class='line'>auto wlan1
</span><span class='line'>allow-hotplug wlan1
</span><span class='line'>iface wlan1 inet manual
</span><span class='line'>wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf
</span><span class='line'>
</span><span class='line'>pi@raspberrypi:~$ sudo cat /etc/wpa_supplicant/wpa_supplicant.conf
</span><span class='line'>ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev
</span><span class='line'>update_config=1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>network={
</span><span class='line'>ssid="winse.liu"
</span><span class='line'>psk="MIMA"
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>network={
</span><span class='line'>ssid="1108"
</span><span class='line'>psk="MIMA"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>USB转串口使用COM控制raspberry</h2>

<p>在淘宝上面买的，我系统是win10，抱着尝试下的心态也很便宜就买了一个。买来后，安装了win7的驱动，能用。</p>

<p>配置见图：</p>

<p><img src="http://winseliu.com/images/blogs/raspberrypi-gpio.png" alt="" /></p>

<p><img src="http://winseliu.com/images/blogs/raspberrypi-usb-com-install.jpg" alt="" /></p>

<p><img src="http://winseliu.com/images/blogs/raspberrypi-usb-com-config.jpg" alt="" /></p>

<p>最终效果：</p>

<p><img src="http://winseliu.com/images/blogs/raspberrypi-finished.jpg" alt="" /></p>

<h2>用到的一些命令</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo raspi-config
</span><span class='line'>修改配置，默认使用图形界面登录，可以使用`Boot Options`修改为文本console模式
</span><span class='line'>
</span><span class='line'>sudo iwlist wlan0 scan | grep ESSID
</span><span class='line'>查看可用的无线
</span><span class='line'>
</span><span class='line'>systemctl list-units
</span><span class='line'>
</span><span class='line'>sudo apt-get install screen
</span><span class='line'>
</span><span class='line'>sudo apt-get -y install vim
</span><span class='line'>sudo apt-get install nginx
</span><span class='line'>systemctl status nginx.service
</span><span class='line'>sudo cp /etc/skel/.* /home/robot/</span></code></pre></td></tr></table></div></figure>


<p>手机放一个热点出来，然后手机安装一个ssh的工具(JuiceSSH v2.0.2)就可以控制树莓派了。</p>

<p>网上有用手机当屏幕，然后键盘连树莓派usb，结合来控制树莓派。一开始挺新奇的，后来感觉挺扯淡的！不过学习到了screen的程序，自动登录啥的没弄成，直接输入用户密码登录也行了。在boot选项看到有自动登录，不知道有没有用。现在有无线网卡和com来控制，感觉已经够用了。</p>

<h2>参考</h2>

<ul>
<li><a href="https://www.raspberrypi.org/forums/viewtopic.php?f=91&amp;t=4751&amp;sid=661d1a59e4f85f333b40e6e46db58d32">Getting Started with the Raspberry Pi</a></li>
<li><a href="http://blog.csdn.net/c80486/article/details/8545307">树莓派(raspberry pi)学习15: 使用WIFI网卡连接无线网络</a></li>
<li><a href="http://blog.csdn.net/cugbabybear/article/details/23048741">windows下 用串行连接控制树莓派</a></li>
<li><a href="http://www.alsrobot.cn/article-141.html">【创客学堂】如何在windows系统下用串口通信完爆raspberry pi（树莓派）</a></li>
<li><a href="http://shumeipai.nxez.com/2013/10/10/raspberry-pi-pick-kindle-display.html">视频详解树莓派如何外接Kindle显示器</a></li>
<li><p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-screen/index.html">linux 技巧：使用 screen 管理你的远程会话</a></p></li>
<li><p><a href="http://www.bkjia.com/Pythonjc/818142.html">RASPBERRY PI wifi配置</a></p></li>
<li><p><a href="http://blog.sina.com.cn/s/blog_3cb6a78c0101a0fe.html">Raspberry Pi 连接无线网卡</a></p></li>
<li><p><a href="http://davidrobot.com/2014/11/raspberry_pi_model_b_plus_startup.html">开机篇 – 树莓派 Raspberry Pi Model B+ 入手折腾记 (1)</a></p></li>
<li><p><a href="http://shumeipai.nxez.com/2013/09/07/no-screen-unknow-ip-login-pi.html#more-184">没有显示器且IP未知的情况下登录树莓派</a></p></li>
<li><p><a href="http://www.pc6.com/az/104761.html">JuiceSSH v2.0.2</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cacti批量添加配置]]></title>
    <link href="http://winseliu.com/blog/2015/10/13/cacti-batch-adding-configurations/"/>
    <updated>2015-10-13T08:35:50+08:00</updated>
    <id>http://winseliu.com/blog/2015/10/13/cacti-batch-adding-configurations</id>
    <content type="html"><![CDATA[<h2>所有机器SNMP配置同步</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>for h in `cat /etc/hosts| grep hadoop|awk '{print $2}'` ; do scp -r /etc/snmp/snmpd.conf $h:/etc/snmp/ ; done
</span><span class='line'>
</span><span class='line'>for h in `cat /etc/hosts| grep hadoop|awk '{print $2}'` ; do ssh $h "service snmpd start" ; done</span></code></pre></td></tr></table></div></figure>


<h2>Cacti批量添加配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>批量添加device。ip也可以为hostname；template为机器模板；version为SNMP的版本
</span><span class='line'>[root@cu-omc1 cacti]# for h in `cat /etc/hosts | grep hadoop | awk '{print $2}'` ; do php cli/add_device.php --description="$h" --ip="$h" --template=9 --version=2 ; done
</span><span class='line'>
</span><span class='line'>了解参数
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --list-hosts
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --list-graph-templates --host-template-id=9
</span><span class='line'>Known Graph Templates:(id, name)
</span><span class='line'>29      Host MIB - Processes
</span><span class='line'>35      ucd/net - Users Logged On
</span><span class='line'>36      ucd/net - TCP Current Established
</span><span class='line'>37      ucd/net - Uptime
</span><span class='line'>38      ucd/net - TCP Counters
</span><span class='line'>39      ucd/net - Memory Usage (enhanced)
</span><span class='line'>40      ucd/net - Load Average (enhanced)
</span><span class='line'>41      ucd/net - CPU Usage (enhanced)
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --list-snmp-queries
</span><span class='line'>Known SNMP Queries:(id, name)
</span><span class='line'>1       SNMP - Interface Statistics
</span><span class='line'>2       ucd/net -  Get Monitored Partitions
</span><span class='line'>3       Karlnet - Wireless Bridge Statistics
</span><span class='line'>4       Netware - Get Available Volumes
</span><span class='line'>6       Unix - Get Mounted Partitions
</span><span class='line'>7       Netware - Get Processor Information
</span><span class='line'>8       SNMP - Get Mounted Partitions
</span><span class='line'>9       SNMP - Get Processor Information
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --list-snmp-fields --host-id=2 --snmp-query-id=1
</span><span class='line'>Known SNMP Fields for host-id 2: (name)
</span><span class='line'>ifAlias
</span><span class='line'>ifDescr
</span><span class='line'>ifHighSpeed
</span><span class='line'>ifHwAddr
</span><span class='line'>ifIndex
</span><span class='line'>ifIP
</span><span class='line'>ifName
</span><span class='line'>ifOperStatus
</span><span class='line'>ifSpeed
</span><span class='line'>ifType
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --list-snmp-values --host-id=2 --snmp-query-id=1 --snmp-field=ifIP
</span><span class='line'>Known values for ifIP for host 2: (name)
</span><span class='line'>127.0.0.1
</span><span class='line'>192.168.20.11
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php  --list-graph-templates 
</span><span class='line'>Known Graph Templates:(id, name)
</span><span class='line'>2       Interface - Traffic (bits/sec)
</span><span class='line'>3       ucd/net - Available Disk Space
</span><span class='line'>4       ucd/net - CPU Usage
</span><span class='line'>5       Karlnet - Wireless Levels
</span><span class='line'>6       Karlnet - Wireless Transmissions
</span><span class='line'>7       Unix - Ping Latency
</span><span class='line'>8       Unix - Processes
</span><span class='line'>9       Unix - Load Average
</span><span class='line'>10      Unix - Logged in Users
</span><span class='line'>11      ucd/net - Load Average
</span><span class='line'>12      Linux - Memory Usage
</span><span class='line'>13      ucd/net - Memory Usage
</span><span class='line'>14      Netware - File System Cache
</span><span class='line'>15      Netware - CPU Utilization
</span><span class='line'>16      Netware - File System Activity
</span><span class='line'>17      Netware - Logged In Users
</span><span class='line'>18      Cisco - CPU Usage
</span><span class='line'>19      Netware - Volume Information
</span><span class='line'>20      Netware - Directory Information
</span><span class='line'>21      Unix - Available Disk Space
</span><span class='line'>22      Interface - Errors/Discards
</span><span class='line'>23      Interface - Unicast Packets
</span><span class='line'>24      Interface - Non-Unicast Packets
</span><span class='line'>25      Interface - Traffic (bytes/sec)
</span><span class='line'>26      Host MIB - Available Disk Space
</span><span class='line'>27      Host MIB - CPU Utilization
</span><span class='line'>28      Host MIB - Logged in Users
</span><span class='line'>29      Host MIB - Processes
</span><span class='line'>30      Netware - Open Files
</span><span class='line'>31      Interface - Traffic (bits/sec, 95th Percentile)
</span><span class='line'>32      Interface - Traffic (bits/sec, Total Bandwidth)
</span><span class='line'>33      Interface - Traffic (bytes/sec, Total Bandwidth)
</span><span class='line'>34      SNMP - Generic OID Template
</span><span class='line'>35      ucd/net - Users Logged On
</span><span class='line'>36      ucd/net - TCP Current Established
</span><span class='line'>37      ucd/net - Uptime
</span><span class='line'>38      ucd/net - TCP Counters
</span><span class='line'>39      ucd/net - Memory Usage (enhanced)
</span><span class='line'>40      ucd/net - Load Average (enhanced)
</span><span class='line'>41      ucd/net - CPU Usage (enhanced)
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php  --list-query-types  --snmp-query-id=1
</span><span class='line'>Known SNMP Query Types: (id, name)
</span><span class='line'>2       In/Out Errors/Discarded Packets
</span><span class='line'>3       In/Out Non-Unicast Packets
</span><span class='line'>4       In/Out Unicast Packets
</span><span class='line'>9       In/Out Bytes (64-bit Counters)
</span><span class='line'>13      In/Out Bits
</span><span class='line'>14      In/Out Bits (64-bit Counters)
</span><span class='line'>16      In/Out Bytes
</span><span class='line'>20      In/Out Bits with 95th Percentile
</span><span class='line'>21      In/Out Bits with Total Bandwidth
</span><span class='line'>22      In/Out Bytes with Total Bandwidth
</span><span class='line'>
</span><span class='line'>先测试单机添加，对应到Device页面点击`Create Graphs for this Host`添加图像的操作
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --host-id=2 --graph-type=cg --graph-template-id=40
</span><span class='line'>Graph Added - graph-id: (5) - data-source-ids: (8, 9, 10)
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --host-id=2 --graph-type=cg --graph-template-id=41
</span><span class='line'>Graph Added - graph-id: (6) - data-source-ids: (11, 12, 13, 14)
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --host-id=2 --graph-type=cg --graph-template-id=39
</span><span class='line'>Graph Added - graph-id: (7) - data-source-ids: (15, 16, 17, 18, 19)
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --host-id=2 --graph-type=cg --graph-template-id=38
</span><span class='line'>
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --host-id="2" --graph-type=ds  --graph-template-id=2 --snmp-query-id=1 --snmp-query-type-id=16 --snmp-field=ifIP --snmp-value="192.168.20.11"
</span><span class='line'>Graph Added - graph-id: (9) - data-source-ids: (24, 24)
</span><span class='line'>
</span><span class='line'>批量操作
</span><span class='line'>添加Graph Templates
</span><span class='line'>[root@cu-omc1 cacti]# php cli/add_graphs.php --list-hosts | awk '{print $1}' | while read line ; do 
</span><span class='line'>&gt;  php cli/add_graphs.php --host-id=$line --graph-type=cg --graph-template-id=41
</span><span class='line'>&gt;  php cli/add_graphs.php --host-id=$line --graph-type=cg --graph-template-id=40
</span><span class='line'>&gt;  php cli/add_graphs.php --host-id=$line --graph-type=cg --graph-template-id=39
</span><span class='line'>&gt;  php cli/add_graphs.php --host-id=$line --graph-type=cg --graph-template-id=38
</span><span class='line'>&gt; done
</span><span class='line'>
</span><span class='line'>添加Data Query。比较复杂点，需要查询匹配
</span><span class='line'>php cli/add_graphs.php --list-hosts | awk '{print $1}' | while read line ; do 
</span><span class='line'>  php cli/add_graphs.php --host-id=$line --graph-type=ds  --graph-template-id=2 --snmp-query-id=1 --snmp-query-type-id=16 --snmp-field=ifIP --snmp-value=$(grep "`php cli/add_graphs.php --list-hosts | grep "^$line\s" | awk '{print $2}'`\s" /etc/hosts | awk '{print $1}')
</span><span class='line'>done</span></code></pre></td></tr></table></div></figure>


<h2>其他命令</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>dmesg |grep eth0
</span><span class='line'>
</span><span class='line'>iftop –i eth0 –B
</span><span class='line'>
</span><span class='line'>sar -n DEV 1 100 
</span><span class='line'>
</span><span class='line'>ethtool eth0
</span><span class='line'>
</span><span class='line'>[omc@cu-omc1 ~]$ sort -k 2 /tmp/cacti.list &gt; /tmp/cacti.sort.list
</span><span class='line'>[omc@cu-omc1 ~]$ grep hadoop /etc/hosts | sort -k 2 | join -j 2 - /tmp/cacti.sort.list </span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://www.educity.cn/net/1619986.html">http://www.educity.cn/net/1619986.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nagios监控主机]]></title>
    <link href="http://winseliu.com/blog/2015/09/25/nagios-start-guide/"/>
    <updated>2015-09-25T17:40:58+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/25/nagios-start-guide</id>
    <content type="html"><![CDATA[<p>和Cacti查看时间序列图形不同，Nagios更多的是状态的预警。</p>

<ul>
<li>下载应用</li>
</ul>


<p>到<a href="http://sourceforge.net/projects/nagios/files/?source=navbar">sourceforge</a>下面最新版的应用。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios]# cat /etc/redhat-release 
</span><span class='line'>CentOS release 6.6 (Final)
</span><span class='line'>[root@cu2 nagios]# ll
</span><span class='line'>-rw-r--r--  1 root root 11206656 Sep 23 12:47 nagios-4.1.1.tar.gz
</span><span class='line'>-rw-r--r--  1 root root  2677352 Sep 23 12:47 nagios-plugins-2.1.1.tar.gz
</span><span class='line'>-rw-r--r--  1 root root   419695 Sep 23 15:18 nrpe-2.15.tar.gz</span></code></pre></td></tr></table></div></figure>


<ul>
<li>新增nagios用户</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios]# useradd nagios
</span><span class='line'>[root@cu2 nagios]# groupadd nagcmd
</span><span class='line'>[root@cu2 nagios]# usermod -G nagcmd nagios
</span><span class='line'>[root@cu2 nagios]# usermod -G nagcmd apache 
</span><span class='line'># 如果已经安装了httpd，查看下是哪个用户进程，把该用户加入到nagcmd组。修改后需要重启httpd</span></code></pre></td></tr></table></div></figure>


<ul>
<li>编译Nagios服务端</li>
</ul>


<p>由于前面安装Cacti已经把依赖都安装了，如gcc、gd、httpd、php php-devel php-mysql php-pear php-common php-gd php-mbstring php-cli。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios]# cd nagios-4.1.1/
</span><span class='line'>[root@cu2 nagios-4.1.1]# ./configure --with-command-group=nagcmd
</span><span class='line'>...
</span><span class='line'>Creating sample config files in sample-config/ ...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>*** Configuration summary for nagios 4.1.1 08-19-2015 ***:
</span><span class='line'>
</span><span class='line'> General Options:
</span><span class='line'> -------------------------
</span><span class='line'>        Nagios executable:  nagios
</span><span class='line'>        Nagios user/group:  nagios,nagios
</span><span class='line'>       Command user/group:  nagios,nagcmd
</span><span class='line'>             Event Broker:  yes
</span><span class='line'>        Install ${prefix}:  /usr/local/nagios
</span><span class='line'>    Install ${includedir}:  /usr/local/nagios/include/nagios
</span><span class='line'>                Lock file:  ${prefix}/var/nagios.lock
</span><span class='line'>   Check result directory:  ${prefix}/var/spool/checkresults
</span><span class='line'>           Init directory:  /etc/rc.d/init.d
</span><span class='line'>  Apache conf.d directory:  /etc/httpd/conf.d
</span><span class='line'>             Mail program:  /bin/mail
</span><span class='line'>                  Host OS:  linux-gnu
</span><span class='line'>          IOBroker Method:  epoll
</span><span class='line'>
</span><span class='line'> Web Interface Options:
</span><span class='line'> ------------------------
</span><span class='line'>                 HTML URL:  http://localhost/nagios/
</span><span class='line'>                  CGI URL:  http://localhost/nagios/cgi-bin/
</span><span class='line'> Traceroute (used by WAP):  
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Review the options above for accuracy.  If they look okay,
</span><span class='line'>type 'make all' to compile the main program and CGIs.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# make all
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>*** Compile finished ***
</span><span class='line'>
</span><span class='line'>If the main program and CGIs compiled without any errors, you
</span><span class='line'>can continue with installing Nagios as follows (type 'make'
</span><span class='line'>without any arguments for a list of all possible options):
</span><span class='line'>
</span><span class='line'>  make install
</span><span class='line'>     - This installs the main program, CGIs, and HTML files
</span><span class='line'>
</span><span class='line'>  make install-init
</span><span class='line'>     - This installs the init script in /etc/rc.d/init.d
</span><span class='line'>
</span><span class='line'>  make install-commandmode
</span><span class='line'>     - This installs and configures permissions on the
</span><span class='line'>       directory for holding the external command file
</span><span class='line'>
</span><span class='line'>  make install-config
</span><span class='line'>     - This installs *SAMPLE* config files in /usr/local/nagios/etc
</span><span class='line'>       You'll have to modify these sample files before you can
</span><span class='line'>       use Nagios.  Read the HTML documentation for more info
</span><span class='line'>       on doing this.  Pay particular attention to the docs on
</span><span class='line'>       object configuration files, as they determine what/how
</span><span class='line'>       things get monitored!
</span><span class='line'>
</span><span class='line'>  make install-webconf
</span><span class='line'>     - This installs the Apache config file for the Nagios
</span><span class='line'>       web interface
</span><span class='line'>
</span><span class='line'>  make install-exfoliation
</span><span class='line'>     - This installs the Exfoliation theme for the Nagios
</span><span class='line'>       web interface
</span><span class='line'>
</span><span class='line'>  make install-classicui
</span><span class='line'>     - This installs the classic theme for the Nagios
</span><span class='line'>       web interface
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>*** Support Notes *******************************************
</span><span class='line'>
</span><span class='line'>If you have questions about configuring or running Nagios,
</span><span class='line'>please make sure that you:
</span><span class='line'>
</span><span class='line'>     - Look at the sample config files
</span><span class='line'>     - Read the documentation on the Nagios Library at:
</span><span class='line'>           https://library.nagios.com
</span><span class='line'>
</span><span class='line'>before you post a question to one of the mailing lists.
</span><span class='line'>Also make sure to include pertinent information that could
</span><span class='line'>help others help you.  This might include:
</span><span class='line'>
</span><span class='line'>     - What version of Nagios you are using
</span><span class='line'>     - What version of the plugins you are using
</span><span class='line'>     - Relevant snippets from your config files
</span><span class='line'>     - Relevant error messages from the Nagios log file
</span><span class='line'>
</span><span class='line'>For more information on obtaining support for Nagios, visit:
</span><span class='line'>
</span><span class='line'>       https://support.nagios.com
</span><span class='line'>
</span><span class='line'>*************************************************************
</span><span class='line'>
</span><span class='line'>Enjoy.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# make install
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>*** Main program, CGIs and HTML files installed ***
</span><span class='line'>
</span><span class='line'>You can continue with installing Nagios as follows (type 'make'
</span><span class='line'>without any arguments for a list of all possible options):
</span><span class='line'>
</span><span class='line'>  make install-init
</span><span class='line'>     - This installs the init script in /etc/rc.d/init.d
</span><span class='line'>
</span><span class='line'>  make install-commandmode
</span><span class='line'>     - This installs and configures permissions on the
</span><span class='line'>       directory for holding the external command file
</span><span class='line'>
</span><span class='line'>  make install-config
</span><span class='line'>     - This installs sample config files in /usr/local/nagios/etc
</span><span class='line'>
</span><span class='line'>make[1]: Leaving directory `/data/nagios/nagios-4.1.1'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# make install-init
</span><span class='line'>/usr/bin/install -c -m 755 -d -o root -g root /etc/rc.d/init.d
</span><span class='line'>/usr/bin/install -c -m 755 -o root -g root daemon-init /etc/rc.d/init.d/nagios
</span><span class='line'>
</span><span class='line'>*** Init script installed ***
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# make install-config
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>*** Config files installed ***
</span><span class='line'>
</span><span class='line'>Remember, these are *SAMPLE* config files.  You'll need to read
</span><span class='line'>the documentation for more information on how to actually define
</span><span class='line'>services, hosts, etc. to fit your particular needs.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# make install-commandmode
</span><span class='line'>/usr/bin/install -c -m 775 -o nagios -g nagcmd -d /usr/local/nagios/var/rw
</span><span class='line'>chmod g+s /usr/local/nagios/var/rw
</span><span class='line'>
</span><span class='line'>*** External command directory configured ***
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# vi /usr/local/nagios/etc/objects/contacts.cfg 
</span><span class='line'>...修改define contact定义中的mail为你邮件。
</span><span class='line'>define contact{
</span><span class='line'>        contact_name                    nagiosadmin             ; Short name of user
</span><span class='line'>        use                             generic-contact         ; Inherit default values from generic-contact template (defined above)
</span><span class='line'>        alias                           Nagios Admin            ; Full name of user
</span><span class='line'>
</span><span class='line'>        email                           1234@XXX.cn      ; &lt;&lt;***** CHANGE THIS TO YOUR EMAIL ADDRESS ******
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>      
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# make install-webconf
</span><span class='line'>/usr/bin/install -c -m 644 sample-config/httpd.conf /etc/httpd/conf.d/nagios.conf
</span><span class='line'>
</span><span class='line'>*** Nagios/Apache conf file installed ***
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios-4.1.1]# htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin
</span><span class='line'>New password: 
</span><span class='line'>Re-type new password: 
</span><span class='line'>Adding password for user nagiosadmin
</span><span class='line'>#[root@cu-omc1 nagios-4.1.1]# chmod 644 /usr/local/nagios/etc/htpasswd.users 
</span><span class='line'>[root@cu2 nagios-4.1.1]# service httpd restart
</span><span class='line'>Stopping httpd:                                            [  OK  ]
</span><span class='line'>Starting httpd: httpd: Could not reliably determine the server's fully qualified domain name, using 192.168.0.214 for ServerName
</span><span class='line'>                                                           [  OK  ]
</span><span class='line'>                                             </span></code></pre></td></tr></table></div></figure>


<ul>
<li>编译nagios-plugin</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>如果configure没有mysql和ssl，先安装依赖
</span><span class='line'>yum -y install mysql-devel openssl
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios]# cd nagios-plugins-2.1.1/
</span><span class='line'>[root@cu2 nagios-plugins-2.1.1]# ./configure --with-nagios-user=nagios --with-nagios-group=nagios
</span><span class='line'>...
</span><span class='line'>            --with-apt-get-command: 
</span><span class='line'>              --with-ping6-command: /bin/ping6 -n -U -w %d -c %d %s
</span><span class='line'>               --with-ping-command: /bin/ping -n -U -w %d -c %d %s
</span><span class='line'>                       --with-ipv6: yes
</span><span class='line'>                      --with-mysql: /usr/bin/mysql_config
</span><span class='line'>                    --with-openssl: yes
</span><span class='line'>                     --with-gnutls: no
</span><span class='line'>               --enable-extra-opts: yes
</span><span class='line'>                       --with-perl: /usr/bin/perl
</span><span class='line'>             --enable-perl-modules: no
</span><span class='line'>                     --with-cgiurl: /nagios/cgi-bin
</span><span class='line'>               --with-trusted-path: /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin
</span><span class='line'>                   --enable-libtap: no
</span><span class='line'>[root@cu2 nagios-plugins-2.1.1]# make 
</span><span class='line'>[root@cu2 nagios-plugins-2.1.1]# make install</span></code></pre></td></tr></table></div></figure>


<p>打开浏览器，使用nagiosadmin和刚刚用htpasswd设置的密码登录就可以localhost的状态了。</p>

<p>手动制造一点异常，如登录用户超过50个。然后看刚刚设置的邮箱是否收到邮件提醒。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios]# service nagios status
</span><span class='line'>nagios (pid 53764) is running...
</span><span class='line'>[root@cu2 nagios]# lsof -p 53764
</span><span class='line'>nagios  53764 nagios    4u   REG                8,3    12715   280762 /usr/local/nagios/var/nagios.log
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios]# less /usr/local/nagios/var/nagios.log
</span><span class='line'>看看是否有错误，然后做相应的处理
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios]# yum install mail -y</span></code></pre></td></tr></table></div></figure>


<ul>
<li>被监控机器安装nrpe</li>
</ul>


<p>程序编译都在cu2上面操作，编译完后，把编译安装的程序直接scp到其他机器就可以了。被监控机器需要nagios-plugin和nrpe。</p>

<p>编译之前可以先看看nrpe-2.15/docs/NRPE.pdf，讲的很详细和清楚。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios-plugins-2.1.1]# cd ../nrpe-2.15
</span><span class='line'>[root@cu2 nrpe-2.15]# ./configure 
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>*** Configuration summary for nrpe 2.15 09-06-2013 ***:
</span><span class='line'>
</span><span class='line'> General Options:
</span><span class='line'> -------------------------
</span><span class='line'> NRPE port:    5666
</span><span class='line'> NRPE user:    nagios
</span><span class='line'> NRPE group:   nagios
</span><span class='line'> Nagios user:  nagios
</span><span class='line'> Nagios group: nagios
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Review the options above for accuracy.  If they look okay,
</span><span class='line'>type 'make all' to compile the NRPE daemon and client.
</span><span class='line'>
</span><span class='line'>[root@cu2 nrpe-2.15]# make all
</span><span class='line'>cd ./src/; make ; cd ..
</span><span class='line'>make[1]: Entering directory `/data/nagios/nrpe-2.15/src'
</span><span class='line'>gcc -g -O2 -I/usr/include/openssl -I/usr/include -DHAVE_CONFIG_H -I ../include -I ./../include -o nrpe ./nrpe.c ./utils.c ./acl.c -L/usr/lib64  -lssl -lcrypto -lnsl -lwrap  
</span><span class='line'>gcc -g -O2 -I/usr/include/openssl -I/usr/include -DHAVE_CONFIG_H -I ../include -I ./../include -o check_nrpe ./check_nrpe.c ./utils.c -L/usr/lib64  -lssl -lcrypto -lnsl 
</span><span class='line'>make[1]: Leaving directory `/data/nagios/nrpe-2.15/src'
</span><span class='line'>
</span><span class='line'>*** Compile finished ***
</span><span class='line'>
</span><span class='line'>If the NRPE daemon and client compiled without any errors, you
</span><span class='line'>can continue with the installation or upgrade process.
</span><span class='line'>
</span><span class='line'>Read the PDF documentation (NRPE.pdf) for information on the next
</span><span class='line'>steps you should take to complete the installation or upgrade.
</span><span class='line'>
</span><span class='line'>[root@cu2 nrpe-2.15]# make install-plugin
</span><span class='line'>cd ./src/ && make install-plugin
</span><span class='line'>make[1]: Entering directory `/data/nagios/nrpe-2.15/src'
</span><span class='line'>/usr/bin/install -c -m 775 -o nagios -g nagios -d /usr/local/nagios/libexec
</span><span class='line'>/usr/bin/install -c -m 775 -o nagios -g nagios check_nrpe /usr/local/nagios/libexec
</span><span class='line'>make[1]: Leaving directory `/data/nagios/nrpe-2.15/src'
</span><span class='line'>[root@cu2 nrpe-2.15]# make install-daemon
</span><span class='line'>cd ./src/ && make install-daemon
</span><span class='line'>make[1]: Entering directory `/data/nagios/nrpe-2.15/src'
</span><span class='line'>/usr/bin/install -c -m 775 -o nagios -g nagios -d /usr/local/nagios/bin
</span><span class='line'>/usr/bin/install -c -m 775 -o nagios -g nagios nrpe /usr/local/nagios/bin
</span><span class='line'>make[1]: Leaving directory `/data/nagios/nrpe-2.15/src'
</span><span class='line'>[root@cu2 nrpe-2.15]# make install-daemon-config
</span><span class='line'>/usr/bin/install -c -m 775 -o nagios -g nagios -d /usr/local/nagios/etc
</span><span class='line'>/usr/bin/install -c -m 644 -o nagios -g nagios sample-config/nrpe.cfg /usr/local/nagios/etc
</span><span class='line'>
</span><span class='line'># 启动nrpe服务
</span><span class='line'>[root@cu2 nrpe-2.15]#  /usr/local/nagios/bin/nrpe -c /usr/local/nagios/etc/nrpe.cfg -d
</span><span class='line'>
</span><span class='line'>[root@cu2 nrpe-2.15]# /usr/local/nagios/libexec/check_nrpe -H localhost
</span><span class='line'>CHECK_NRPE: Error - Could not complete SSL handshake.
</span><span class='line'>[root@cu2 nrpe-2.15]# /usr/local/nagios/libexec/check_nrpe -H 127.0.0.1
</span><span class='line'>NRPE v2.15</span></code></pre></td></tr></table></div></figure>


<p>注意： 如果需要启用传递参数功能需要添加参数<code>--enable-command-args</code>，同时修改配置<code>dont_blame_nrpe=1</code>。<a href="http://www.cppblog.com/fwxjj/archive/2011/10/28/159262.aspx">http://www.cppblog.com/fwxjj/archive/2011/10/28/159262.aspx</a></p>

<p>拷贝程序到其他机器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 local]# scp -r nagios cu3:/usr/local/
</span><span class='line'>
</span><span class='line'>[root@cu3 ~]# cd /usr/local/nagios/
</span><span class='line'>[root@cu3 nagios]# bin/nrpe -c etc/nrpe.cfg -d
</span><span class='line'>[root@cu3 nagios]# 
</span><span class='line'>[root@cu3 nagios]# libexec/check_nrpe -H 127.0.0.1
</span><span class='line'>NRPE v2.15</span></code></pre></td></tr></table></div></figure>


<p>修改配置，添加可以访问nrpe的白名单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu3 nagios]# vi etc/nrpe.cfg 
</span><span class='line'>...修改
</span><span class='line'>allowed_hosts=127.0.0.1,192.168.0.0/24
</span><span class='line'>...查看
</span><span class='line'>command[check_users]=/usr/local/nagios/libexec/check_users -w 5 -c 10
</span><span class='line'>command[check_load]=/usr/local/nagios/libexec/check_load -w 15,10,5 -c 30,25,20
</span><span class='line'>command[check_hda1]=/usr/local/nagios/libexec/check_disk -w 20% -c 10% -p /dev/hda1
</span><span class='line'>command[check_zombie_procs]=/usr/local/nagios/libexec/check_procs -w 5 -c 10 -s Z
</span><span class='line'>command[check_total_procs]=/usr/local/nagios/libexec/check_procs -w 150 -c 200 
</span><span class='line'>
</span><span class='line'>nrpe.cfg最下面是nrpe的command，nagios配置中会用到
</span><span class='line'>
</span><span class='line'>[root@cu3 nagios]# pkill nrpe
</span><span class='line'>[root@cu3 nagios]# bin/nrpe -c etc/nrpe.cfg -d</span></code></pre></td></tr></table></div></figure>


<p>再回到cu2，把cu3加入nagios管理列表中：</p>

<p>首先，nagios的配置入口为etc/nagios.cfg。其他配置文件都是通过cfg_file去定位的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios]# vi etc/nagios.cfg 
</span><span class='line'>...添加
</span><span class='line'>cfg_file=/usr/local/nagios/etc/objects/hosts.cfg
</span><span class='line'>cfg_file=/usr/local/nagios/etc/objects/localhost.cfg
</span><span class='line'>cfg_file=/usr/local/nagios/etc/objects/cu3.cfg
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios]# vi etc/objects/commands.cfg 
</span><span class='line'>...添加
</span><span class='line'># 'check_nrpe' command definition
</span><span class='line'>define command{
</span><span class='line'>        command_name check_nrpe
</span><span class='line'>        command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios]# vi etc/objects/cu3.cfg 
</span><span class='line'>...新增
</span><span class='line'>
</span><span class='line'>define host{
</span><span class='line'>        use                     linux-server            ; Name of host template to use
</span><span class='line'>                                                        ; This host definition will inherit all variables that are defined
</span><span class='line'>                                                        ; in (or inherited by) the linux-server host template definition.
</span><span class='line'>        host_name               cu3
</span><span class='line'>        alias                   cu3
</span><span class='line'>        address                 192.168.0.148
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>define service{
</span><span class='line'>        use                             generic-service         ; Name of service template to use
</span><span class='line'>        host_name                       cu3
</span><span class='line'>        service_description             PING
</span><span class='line'>        check_command                   check_ping!100.0,20%!500.0,60%
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>define service{
</span><span class='line'>        use                             generic-service         ; Name of service template to use
</span><span class='line'>        host_name                       cu3
</span><span class='line'>        service_description             Root Partition
</span><span class='line'>        check_command                   check_nrpe!check_hda1
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>define service{
</span><span class='line'>        use                             generic-service         ; Name of service template to use
</span><span class='line'>        host_name                       cu3
</span><span class='line'>        service_description             Current Users
</span><span class='line'>        check_command                   check_nrpe!check_users
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>define service{
</span><span class='line'>        use                             generic-service         ; Name of service template to use
</span><span class='line'>        host_name                       cu3
</span><span class='line'>        service_description             Total Processes
</span><span class='line'>        check_command                   check_nrpe!check_total_procs
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>define service{
</span><span class='line'>        use                             generic-service         ; Name of service template to use
</span><span class='line'>        host_name                       cu3
</span><span class='line'>        service_description             Current Load
</span><span class='line'>        check_command                   check_nrpe!check_load
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>[root@cu2 nagios]# vi etc/objects/hosts.cfg 
</span><span class='line'>... 新增
</span><span class='line'>define hostgroup{
</span><span class='line'>        hostgroup_name  linux-servers ; The name of the hostgroup
</span><span class='line'>        alias           Linux Servers ; Long name of the group
</span><span class='line'>        members         localhost,cu3,cu4,cu5,cu1     ; Comma separated list of hosts that belong to this group
</span><span class='line'>        }
</span></code></pre></td></tr></table></div></figure>


<p>配置完后，校验配置，然后重启nagios。然后就可以打开浏览器查看cu3状态。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 nagios]# bin/nagios -v etc/nagios.cfg 
</span><span class='line'>
</span><span class='line'>Nagios Core 4.1.1
</span><span class='line'>Copyright (c) 2009-present Nagios Core Development Team and Community Contributors
</span><span class='line'>Copyright (c) 1999-2009 Ethan Galstad
</span><span class='line'>Last Modified: 08-19-2015
</span><span class='line'>License: GPL
</span><span class='line'>
</span><span class='line'>Website: https://www.nagios.org
</span><span class='line'>Reading configuration data...
</span><span class='line'>   Read main config file okay...
</span><span class='line'>   Read object config files okay...
</span><span class='line'>
</span><span class='line'>Running pre-flight check on configuration data...
</span><span class='line'>
</span><span class='line'>Checking objects...
</span><span class='line'>        Checked 23 services.
</span><span class='line'>        Checked 4 hosts.
</span><span class='line'>        Checked 1 host groups.
</span><span class='line'>        Checked 0 service groups.
</span><span class='line'>        Checked 1 contacts.
</span><span class='line'>        Checked 1 contact groups.
</span><span class='line'>        Checked 25 commands.
</span><span class='line'>        Checked 5 time periods.
</span><span class='line'>        Checked 0 host escalations.
</span><span class='line'>        Checked 0 service escalations.
</span><span class='line'>Checking for circular paths...
</span><span class='line'>        Checked 4 hosts
</span><span class='line'>        Checked 0 service dependencies
</span><span class='line'>        Checked 0 host dependencies
</span><span class='line'>        Checked 5 timeperiods
</span><span class='line'>Checking global event handlers...
</span><span class='line'>Checking obsessive compulsive processor commands...
</span><span class='line'>Checking misc settings...
</span><span class='line'>
</span><span class='line'>Total Warnings: 0
</span><span class='line'>Total Errors:   0
</span><span class='line'>
</span><span class='line'>Things look okay - No serious problems were detected during the pre-flight check
</span><span class='line'>[root@cu2 nagios]# service nagios restart
</span><span class='line'>Running configuration check...
</span><span class='line'>Stopping nagios: done.
</span><span class='line'>Starting nagios: done.</span></code></pre></td></tr></table></div></figure>


<h2>后记</h2>

<p>技巧：配置服务的时刻，制定host_name可以使用正则表达式，一个服务通吃。对于功能类似的机器，可以减少很多工作量：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vi etc/nagios.cfg 
</span><span class='line'>... 修改
</span><span class='line'>use_regexp_matching=1
</span><span class='line'>use_true_regexp_matching=1
</span><span class='line'>
</span><span class='line'>vi cu.cfg
</span><span class='line'>... 
</span><span class='line'>define service{
</span><span class='line'>        use                             generic-service         ; Name of service template to use
</span><span class='line'>        host_name                       cu.*
</span><span class='line'>        service_description             Current Load
</span><span class='line'>        check_command                   check_nrpe!check_load
</span><span class='line'>        }</span></code></pre></td></tr></table></div></figure>


<p>基本功能就算配置好了，如果出现异常就能得到邮件提醒。</p>

<h2>后后后记(2015-12-7 21:42:03)</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar zxvf nagios-plugins-2.1.1.tar.gz 
</span><span class='line'>tar zxvf nrpe-2.15.tar.gz 
</span><span class='line'>
</span><span class='line'>ps axu|grep httpd
</span><span class='line'>useradd nagios
</span><span class='line'>groupadd nagcmd
</span><span class='line'>usermod -G nagcmd nagios
</span><span class='line'>usermod -G nagcmd apache 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>yum -y install mysql-devel openssl
</span><span class='line'>cd nagios-plugins-2.1.1/
</span><span class='line'>./configure --with-nagios-user=nagios --with-nagios-group=nagios
</span><span class='line'>make && make install
</span><span class='line'>
</span><span class='line'>cd ../nrpe-2.15
</span><span class='line'>./configure 
</span><span class='line'>make all
</span><span class='line'>make install-plugin
</span><span class='line'>make install-daemon
</span><span class='line'>make install-daemon-config
</span><span class='line'>
</span><span class='line'>cd /usr/local/
</span><span class='line'>for h in `cat /etc/hosts | grep hadoop | awk '{print $2}'` ; do rsync -vaz nagios root@$h:/usr/local/  ; done 
</span><span class='line'>
</span><span class='line'>rsync --dry-run -vaz nagios nagios-client &gt; nagios-client.list
</span><span class='line'>rsync --dry-run --include-from=nagios-client.list --exclude=* -vaz nagios nagios-clint
</span><span class='line'>
</span><span class='line'>for h in `cat /etc/hosts | grep "-" | grep -v omc1 | awk '{print $2}'` ; do 
</span><span class='line'>  rsync  --include-from=nagios-client.list --exclude=* -vaz nagios $h:/usr/local/  ;
</span><span class='line'>  ssh $h "pkill nrpe; cd /usr/local/nagios ; bin/nrpe -c etc/nrpe.cfg -d"  ; 
</span><span class='line'>  echo $h; ssh $h "if ! ps aux|grep nrpe | grep -v grep  | grep nrpe ; then cd /usr/local/nagios ; bin/nrpe -c etc/nrpe.cfg -d ; fi"   ;
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'># nrpe下面有init-script，拷贝到/etc/init.d/下面就可以用service来进行启动了。
</span><span class='line'>cp init-script /etc/init.d/nrpe
</span><span class='line'>chmod +x /etc/init.d/nrpe
</span><span class='line'>service nrpe start
</span><span class='line'>chkconfig --add nrpe
</span><span class='line'>
</span><span class='line'>umask 0022
</span><span class='line'>cd 
</span><span class='line'>tar zxvf nagios-4.1.1.tar.gz 
</span><span class='line'>cd nagios-4.1.1
</span><span class='line'>./configure --with-command-group=nagcmd
</span><span class='line'>make all
</span><span class='line'>make install
</span><span class='line'> make install-init
</span><span class='line'>make install-config
</span><span class='line'>make install-commandmode
</span><span class='line'>make install-webconf
</span><span class='line'>htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin
</span><span class='line'>chmod 644 /usr/local/nagios/etc/htpasswd.users 
</span><span class='line'>service httpd restart
</span><span class='line'>service nagios start
</span><span class='line'>
</span><span class='line'>##======================================================================
</span><span class='line'>
</span><span class='line'>修改 vi nagios.cfg
</span><span class='line'>
</span><span class='line'>  cfg_file=/usr/local/nagios/etc/objects/hosts.cfg
</span><span class='line'>  cfg_file=/usr/local/nagios/etc/objects/cu.cfg
</span><span class='line'>
</span><span class='line'>  use_regexp_matching=1
</span><span class='line'>
</span><span class='line'>添加 for h in `cat /etc/hosts | grep "-" | grep -v omc1 | awk '{print $2}'` ; do echo "
</span><span class='line'>&gt; define host {
</span><span class='line'>&gt; use linux-server
</span><span class='line'>&gt; host_name HN-${h#*-}
</span><span class='line'>&gt; alias HN-${h#*-}
</span><span class='line'>&gt; address $h
</span><span class='line'>&gt; }
</span><span class='line'>&gt; " ; done &gt;hosts.cfg
</span><span class='line'>
</span><span class='line'>define hostgroup{
</span><span class='line'>        hostgroup_name  cu servers
</span><span class='line'>        alias           cu servers
</span><span class='line'>        members         HN-omc*, HN-uc*, HN-ud*, HN-db*
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>define hostgroup{
</span><span class='line'>        hostgroup_name  hadoop slavers
</span><span class='line'>        alias           hadoop slavers
</span><span class='line'>        members         HN-slaver*, HN-master*
</span><span class='line'>        }
</span><span class='line'>      
</span><span class='line'>添加 vi commands.cfg    
</span><span class='line'>
</span><span class='line'># 'check_nrpe' command definition
</span><span class='line'>define command{
</span><span class='line'>        command_name check_nrpe
</span><span class='line'>        command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>编辑 vi /etc/mail.rc 
</span><span class='line'>
</span><span class='line'>set from=eshore_notify@189.cn
</span><span class='line'>set smtp=smtp.189.cn
</span><span class='line'>set smtp-auth-user=XXX
</span><span class='line'>set smtp-auth-password=XXX
</span><span class='line'>set smtp-auth=login
</span><span class='line'>
</span><span class='line'>echo test  | /bin/mail -s "** Service Alert **" XXX@189.cn
</span><span class='line'>
</span><span class='line'>##-----------------------------------
</span><span class='line'>[root@dr01 ~]# umount /root/.gvfs
</span><span class='line'>
</span><span class='line'>command_line  /usr/lib/nagios/plugins/check_disk -w $ARG1$ -c $ARG2$  -u GB -A -i .gvfs
</span><span class='line'>   </span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://nagios-cn.sourceforge.net/nagios-cn/beginning.html#quickstart-fedora">http://nagios-cn.sourceforge.net/nagios-cn/beginning.html#quickstart-fedora</a></li>
<li><a href="http://skypegnu1.blog.51cto.com/8991766/1532948">http://skypegnu1.blog.51cto.com/8991766/1532948</a></li>
<li><a href="http://nagios-cn.sourceforge.net/nagios-cn/beginning.html#monitoring-linux">http://nagios-cn.sourceforge.net/nagios-cn/beginning.html#monitoring-linux</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cacti监控主机]]></title>
    <link href="http://winseliu.com/blog/2015/09/22/cacti-start-guide/"/>
    <updated>2015-09-22T14:33:36+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/22/cacti-start-guide</id>
    <content type="html"><![CDATA[<p>其实通过yum好依赖的php、rrdtool、snmp后，安装配置Cacti其实很简单。</p>

<h2>环境说明</h2>

<p>五台机器：cu1~cu5(centos6.6)， 其中仅cu2作为cacti服务器，所有服务器都安装snmp服务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cu1     192.168.0.37 
</span><span class='line'>cu2     192.168.0.214 
</span><span class='line'>cu3     192.168.0.148 
</span><span class='line'>cu4     192.168.0.30 
</span><span class='line'>cu5     192.168.0.174 </span></code></pre></td></tr></table></div></figure>


<h2>软件安装</h2>

<p>版本信息在贴的内容中体现。PHP不会，仅仅作为一个工具来使用。</p>

<h3>Cacti服务器机器安装</h3>

<p>mysql数据库5.1</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# rpm -q mysql 
</span><span class='line'>mysql-5.1.73-5.el6_6.x86_64</span></code></pre></td></tr></table></div></figure>


<p>首先用yum安装依赖软件php，httpd，snmp和<strong>rrdtool</strong>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# yum install epel-release
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# yum install httpd php php-devel php-mysql php-pear php-common php-gd php-mbstring php-cli php-snmp net-snmp net-snmp-utils net-snmp-libs rrdtool 
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  net-snmp-libs.x86_64 1:5.5-54.el6_7.1 net-snmp-utils.x86_64 1:5.5-54.el6_7.1 php.x86_64 0:5.3.3-46.el6_6          php-cli.x86_64 0:5.3.3-46.el6_6   php-common.x86_64 0:5.3.3-46.el6_6
</span><span class='line'>  php-devel.x86_64 0:5.3.3-46.el6_6     php-gd.x86_64 0:5.3.3-46.el6_6         php-mbstring.x86_64 0:5.3.3-46.el6_6 php-mysql.x86_64 0:5.3.3-46.el6_6 php-pear.noarch 1:1.9.4-4.el6     
</span><span class='line'>  php-snmp.x86_64 0:5.3.3-46.el6_6      rrdtool.x86_64 0:1.3.8-7.el6          
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  autoconf.noarch 0:2.63-5.1.el6               automake.noarch 0:1.11.1-4.el6                  dejavu-fonts-common.noarch 0:2.33-1.el6   dejavu-lgc-sans-mono-fonts.noarch 0:2.33-1.el6  
</span><span class='line'>  dejavu-sans-mono-fonts.noarch 0:2.33-1.el6   fontpackages-filesystem.noarch 0:1.41-1.1.el6   lm_sensors-libs.x86_64 0:3.1.1-17.el6     net-snmp.x86_64 1:5.5-54.el6_7.1                
</span><span class='line'>  php-pdo.x86_64 0:5.3.3-46.el6_6             
</span><span class='line'>
</span><span class='line'>Updated:
</span><span class='line'>  httpd.x86_64 0:2.2.15-47.el6.centos                                                                                                                                                       
</span><span class='line'>
</span><span class='line'>Dependency Updated:
</span><span class='line'>  httpd-tools.x86_64 0:2.2.15-47.el6.centos                                                                                                                                                 
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# service httpd start
</span><span class='line'>Starting httpd: httpd: Could not reliably determine the server's fully qualified domain name, using 192.168.0.214 for ServerName
</span><span class='line'>                                                           [  OK  ]
</span><span class='line'>[root@cu2 ~]# service snmpd start
</span><span class='line'>Starting snmpd:                                            [  OK  ]
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# vi /etc/snmp/snmpd.conf 
</span><span class='line'>     41 #com2sec notConfigUser  default       public
</span><span class='line'>     42 com2sec notConfigUser  192.168.0.214       public
</span><span class='line'>   ...
</span><span class='line'>     63 #access  notConfigGroup ""      any       noauth    exact  systemview none none
</span><span class='line'>     64 access  notConfigGroup ""      any       noauth    exact  all none none
</span><span class='line'>   ...
</span><span class='line'>     86 ##           incl/excl subtree                          mask
</span><span class='line'>     87 view all    included  .1                               80  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# service snmpd restart
</span><span class='line'>
</span><span class='line'># 使用snmpwalk可以得到数据
</span><span class='line'>[root@cu2 ~]# snmpwalk -Os -c public -v 1 cu2 system
</span><span class='line'>[root@cu2 ~]# snmpwalk -v 1 -c public localhost IP-MIB::ipAdEntIfIndex</span></code></pre></td></tr></table></div></figure>


<p>然后，把Cacti应用解压到httpd默认目录下/var/www/html。同时配置cacti连接到数据库。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /var/www/html/
</span><span class='line'>[root@cu2 html]# tar zxvf cacti-0.8.8f.tar.gz 
</span><span class='line'>
</span><span class='line'>[root@cu2 html]# ln -s cacti-0.8.8f cacti
</span><span class='line'>
</span><span class='line'>[root@cu2 html]$ mysql -u root -p -h 127.0.0.1
</span><span class='line'>Enter password: 
</span><span class='line'>mysql&gt; 
</span><span class='line'>mysql&gt; create database cacti character set UTF8;
</span><span class='line'>mysql&gt; grant all on cacti.* to cacti@'%' identified by 'cacti';
</span><span class='line'>mysql&gt; flush privileges;
</span><span class='line'>mysql&gt; source /var/www/html/cacti/cacti.sql;
</span><span class='line'>
</span><span class='line'>[root@cu2 html]# vi cacti/include/config.php 
</span><span class='line'>$database_type = "mysql";
</span><span class='line'>$database_default = "cacti";
</span><span class='line'>$database_hostname = "127.0.0.1";
</span><span class='line'>$database_username = "cacti";
</span><span class='line'>$database_password = "cacti";
</span><span class='line'>$database_port = "3306";
</span><span class='line'>
</span><span class='line'>[root@cu2 html]$ vi /etc/php.ini 
</span><span class='line'>date.timezone = "Asia/Shanghai"
</span><span class='line'>
</span><span class='line'># 重启httpd服务
</span><span class='line'>
</span><span class='line'>[root@cu2 cacti]# php poller.php 
</span><span class='line'>
</span><span class='line'>[root@cu2 cacti]# crontab -e
</span><span class='line'>* * * * * php /var/www/html/cacti/poller.php &gt; /var/www/html/cacti/log/cron.log 2&gt;&1
</span></code></pre></td></tr></table></div></figure>


<p>打开浏览器访问：<a href="http://cu2/cacti/">http://cu2/cacti/</a> 首先会进入到install步骤，按照提示一步下一步，最后输入admin/admin登录。点击右上角的Preview View就可以看到图了。</p>

<p>如果启动错误，查看日志文件看日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 cacti]# less /var/log/httpd/error_log 
</span><span class='line'>[root@cu2 cacti]# less log/cacti.log </span></code></pre></td></tr></table></div></figure>


<h3>添加插件</h3>

<p>（网上很多文章都要打补丁，我这里的版本是最新的，同时plugin的补丁没有对应的版本，这里直接安装插件）</p>

<p>从<a href="http://docs.cacti.net/plugins">http://docs.cacti.net/plugins</a>下载<a href="http://docs.cacti.net/plugin:monitor">monitor</a>。把下载文件解压到plugins目录下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 plugins]# pwd
</span><span class='line'>/var/www/html/cacti/plugins
</span><span class='line'>[root@cu2 plugins]# ll
</span><span class='line'>-rw-r--r-- 1 1000 users   44 Jul 20 21:42 index.php
</span><span class='line'>drwxr-xr-x 4 root root  4096 Oct  6  2011 monitor</span></code></pre></td></tr></table></div></figure>


<p>然后进入Plugin Management页面<a href="http://cu2/cacti/plugins.php">http://cu2/cacti/plugins.php</a>，就能看到Monitor插件。点击表格Actions列的<strong>安装和启用</strong>图标（按钮），启用后，最上面页签会增加新的页签项monitor。</p>

<p>点击monitor页签，可以查看机器存活的状态。</p>

<p>同时Settings页面多了Misc选项卡，可以配置修改monitor属性。</p>

<p>注意：网上版本资料都有配置config.php添加plugins变量。我这里没进行这个操作也是ok的，安装-启用成功后会把monitor下面的sql更新到数据库，不需要手动执行。</p>

<h3>安装spine</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>注意：设置下umask避免不需要的麻烦： umask 0022
</span><span class='line'>[root@cu2 ~] tar zxvf cacti-spine-0.8.8f.tar.gz
</span><span class='line'>
</span><span class='line'>[root@cu2 cacti-spine-0.8.8f]# yum install -y mysql-devel net-snmp-devel
</span><span class='line'>
</span><span class='line'>[root@cu2 cacti-spine-0.8.8f]# ./configure --prefix=/usr/local/cacti-spine
</span><span class='line'>[root@cu2 cacti-spine-0.8.8f]# make && make install
</span><span class='line'># 如果make缺少报了错，需要重新configuration一遍
</span><span class='line'>
</span><span class='line'>[root@cu2 cacti-spine-0.8.8f]# cd /usr/local/cacti-spine/etc
</span><span class='line'>[root@cu2 etc]# mv spine.conf.dist spine.conf
</span><span class='line'>[root@cu2 etc]# vi spine.conf 
</span><span class='line'>DB_Host         127.0.0.1
</span><span class='line'>DB_Database     cacti
</span><span class='line'>DB_User         cacti
</span><span class='line'>DB_Pass         cacti
</span><span class='line'>DB_Port         3306
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>然后修改<a href="http://hadoop-master2/cacti/settings.php">Cacti</a>使用spine来获取信息。</li>
</ul>


<p>在[Settings]-[Paths]添加Spine Poller File Path为<code>/usr/local/cacti-spine/bin/spine</code>。在[Poller]选项卡，[Poller Type]修改为spine，[Poller Interval]和[Cron Interval]修改为一分钟即Every Minute。</p>

<ul>
<li>添加“每分钟”流量视图:</li>
</ul>


<p>点击Console -> Data Templates -> [Interface -> Traffic ] 添加“每分钟”流量视图，将轮询时间设置为60秒，Heartbeat时间设置为120秒(traffic_in/traffic_out里面的Heartbeat时间也设置为120秒)</p>

<h2>被监控机器配置</h2>

<p>被监控的机器，仅仅需要安装snmp即可。然后配置snpmd.conf即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu5 ~]# yum install  net-snmp net-snmp-utils net-snmp-libs -y
</span><span class='line'>[root@cu5 ~]# vi /etc/snmp/snmpd.conf 
</span><span class='line'>     41 #com2sec notConfigUser  default       public
</span><span class='line'>     42 com2sec notConfigUser  192.168.0.214       public
</span><span class='line'>   ...
</span><span class='line'>     63 #access  notConfigGroup ""      any       noauth    exact  systemview none none
</span><span class='line'>     64 access  notConfigGroup ""      any       noauth    exact  all none none
</span><span class='line'>   ...
</span><span class='line'>     86 ##           incl/excl subtree                          mask
</span><span class='line'>     87 view all    included  .1                               80  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# service snmpd restart</span></code></pre></td></tr></table></div></figure>


<p>然后在Cacti的web页面添加Device(主机)：</p>

<ul>
<li>点击Console->Devices，打开设备管理页面。</li>
<li>点击右上角的add，添加一个新的机器</li>
<li>当主机的信息填好之后，点击Create

<ul>
<li>Host Template就是一个模板，会事先建立一些Associated Graph Templates和Associated Data Queries的数据，如Load Average，Memory Uages等。如果不确定直接选None即可。</li>
<li>SNMP Version选<code>Version 2</code>，SNMP Community与snmpd.conf中对应，如果安装上面操作，默认即可。</li>
</ul>
</li>
<li>此时你的页面左上角应该显示：Save Successful，并且已经显示出了主机信息和SNMP信息，如果SNMP信息显示 SNMP error，请查看最后的问题综述。</li>
<li>这时我们就可以添加相应的监控项了，在页面最下方的Associated Graph Templates中添加图形模板，在Associated Data Queries中添加数据模板。</li>
<li>保存，点击右上角的Create Graphs for this Host，来为刚才通过模板所获得到的数据进行画图。</li>
<li>选择好需要画图的项目后，点击右下角的Create，左上角会出现被创建出来的画图项。</li>
</ul>


<p>总结就是添加设备，然后生成图形，最后等待生成画图查看。</p>

<p>在Graphs界面左边显示树新添加主机。</p>

<ul>
<li>在Cacti界面Graph Trees中，选择进入节点(或者系统默认的Default Tree)。</li>
<li>添加一个新的显示项，在Tree Item Type中选择Host，然后在下面的Host中选择我们刚才创建的主机。点击Create。</li>
</ul>


<p><a href="http://docs.cacti.net/templates">http://docs.cacti.net/templates</a></p>

<h2>进阶</h2>

<p><a href="http://skypegnu1.blog.51cto.com/8991766/1537374">http://skypegnu1.blog.51cto.com/8991766/1537374</a></p>

<blockquote><p>cacti是如何获取数据呢？  <br/>
    其实cacti获取数据的方式是多样化的，通过周期性的执行某个脚本，或者使用snmp，更或者是ssh，这些都是根据实际需要以及方便性来抉择。cacti需要周期性的驱动这些获取数据的脚本执行，并把取得的数据保存至相应的rrd数据库中。
cacti是如何保存数据（创建rrd，并更新数据）呢？
    这就是数据模板的功能。
cacti是如何展示数据（绘图）呢？
    这就是图形模板的功能。</p></blockquote>

<p><a href="http://skypegnu1.blog.51cto.com/8991766/1537615">http://skypegnu1.blog.51cto.com/8991766/1537615</a>
<a href="http://skypegnu1.blog.51cto.com/8991766/1538459">http://skypegnu1.blog.51cto.com/8991766/1538459</a>
<a href="http://skypegnu1.blog.51cto.com/8991766/1547029">http://skypegnu1.blog.51cto.com/8991766/1547029</a></p>

<h2>资料</h2>

<p>入门的文档不错，可以到<a href="http://vdisk.weibo.com/u/1554831624">微盘</a>下载。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Cacti.0.8_Beginner.Guide.pdf
</span><span class='line'>
</span><span class='line'>Cacti实战指南--备份还原.pdf
</span><span class='line'>Cacti实战指南-完美部署.pdf
</span><span class='line'>Cacti实战指南-巧设轮询.pdf
</span><span class='line'>Cacti实战指南-插件安装.pdf
</span><span class='line'>Cacti实战指南-用户权限.pdf
</span><span class='line'>Cacti实战指南-邮件预警.pdf
</span><span class='line'>Cacti实战指南-阀值预警.pdf
</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><p>先看这个文档 <a href="http://blog.chinaunix.net/attachment/attach/21/08/97/212108972176206e1112f29600926449bdeedb3970.pdf">http://blog.chinaunix.net/attachment/attach/21/08/97/212108972176206e1112f29600926449bdeedb3970.pdf</a></p></li>
<li><p><a href="http://blog.csdn.net/chen3888015/article/details/8233125">http://blog.csdn.net/chen3888015/article/details/8233125</a></p></li>
<li><p><a href="http://www.cacti.net/downloads/docs/pdf/manual.pdf">http://www.cacti.net/downloads/docs/pdf/manual.pdf</a></p></li>
<li><p><a href="http://wenku.baidu.com/view/57aa69487fd5360cba1adb40.html?re=view">http://wenku.baidu.com/view/57aa69487fd5360cba1adb40.html?re=view</a></p></li>
<li><p><a href="http://wenku.baidu.com/view/b2d1f6c689eb172ded63b7f9.html?re=view">http://wenku.baidu.com/view/b2d1f6c689eb172ded63b7f9.html?re=view</a></p></li>
<li><p><a href="http://www.ehowstuff.com/how-to-install-and-configure-epel-repository-on-centos-6-2/">http://www.ehowstuff.com/how-to-install-and-configure-epel-repository-on-centos-6-2/</a></p></li>
<li><a href="http://www.ehowstuff.com/how-to-install-cacti-on-centos-6-2-using-epel-repository/">http://www.ehowstuff.com/how-to-install-cacti-on-centos-6-2-using-epel-repository/</a></li>
<li><a href="http://www.ehowstuff.com/how-to-setup-and-configure-cacti-on-centos-6-2/">http://www.ehowstuff.com/how-to-setup-and-configure-cacti-on-centos-6-2/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决SecureCRT【zmodem Transfer Canceled by Remote Side】问题]]></title>
    <link href="http://winseliu.com/blog/2015/09/21/solve-securecrt-zmodem-transfer-canceled-by-remote-side/"/>
    <updated>2015-09-21T16:02:18+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/21/solve-securecrt-zmodem-transfer-canceled-by-remote-side</id>
    <content type="html"><![CDATA[<p>处理方法很简单，解决后，对于ssh机器之间多次跳转的文件传输操作会方便很多。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>写到/etc/profile以后就可以直接使用了
</span><span class='line'>[root@af042cb4b34c ~]# alias rz="rz -e"
</span><span class='line'>
</span><span class='line'>[root@af042cb4b34c ~]# cd /usr/share/cacti/
</span><span class='line'>[root@af042cb4b34c cacti]# cd plugins
</span><span class='line'>[root@af042cb4b34c plugins]# rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring monitor-v1.3-1.tgz...
</span><span class='line'>  100%     231 KB     231 KB/sec    00:00:01       0 Errors  
</span><span class='line'>
</span><span class='line'>[root@af042cb4b34c plugins]# ll
</span><span class='line'>total 236
</span><span class='line'>-rw-r--r-- 1 root root     44 Aug  7  2013 index.php
</span><span class='line'>-rw-r--r-- 1 root root 236682 Sep 21 07:54 monitor-v1.3-1.tgz</span></code></pre></td></tr></table></div></figure>


<p>zmoden还是有比较多的限制。sftp还是不能少啊！！</p>

<h2>参考</h2>

<ul>
<li><a href="http://iamhere1.blog.163.com/blog/static/23612284201372322622902/">http://iamhere1.blog.163.com/blog/static/23612284201372322622902/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[【linux 101 Hacks】读后感]]></title>
    <link href="http://winseliu.com/blog/2015/09/13/review-linux-101-hacks/"/>
    <updated>2015-09-13T13:12:53+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/13/review-linux-101-hacks</id>
    <content type="html"><![CDATA[<p>本书讲了linux维护和管理过程中常用的命令。</p>

<p>分12个章节，分别将了目录切换、日期、SSH远程登录、常用linux命令、PS1-4操作提示符、解压缩、命令历史记录、系统管理、容器服务器Apache、脚本环境变量、性能监控等。</p>

<p>介绍的命令有：cd, dirs, pushd, popd, cdpath, <strong>alias</strong>, mkdir, eval, date, hwclock, ssh, grep, find, 输出重定向, join, tr, xargs, sort, uniq, cut, stat, diff, ac, ps1, ps2, ps3, ps4, PROMPT_COMMAND, zip, unzip, tar, gzip, bzip2, HISTTIMEFORMAT, HISTSIZE, HISTIGNORE, fdisk, mke2fsk, mount, tune2fs, useradd, adduser, passwd, groupadd, id, ssh-copy-id, ssh-agent, crontab, apachectl, httpd, <strong>.bash_rc</strong>, .bash_profile, 单引号, 双引号, free, top, ps, df, kill, du, lsof, sar, vmstat, netstat, sysctl, nice, renice等等。</p>

<p>下面结合工作中的一些实践，谈一谈</p>

<h2>技巧一：登录服务器</h2>

<p>不管是正式环境还是云端的测试环境，一般提供给我们访问的只有一个入口（也就是常说的跳板机），登录跳板机后然后才能连接其他服务器。常用的工具有【SecureCRT】和【Xshell】，它们的使用方式基本相同。</p>

<p>最佳实践：连接跳板机的同时，建立自己机器和内网机器之间的隧道，即可以方便浏览器的访问，同时也可以使用sftp直接传输文件到内网机器。</p>

<p><img src="http://winseliu.com/images/blogs/linux-101-hacks-review-securecrt-config.png" alt="" /></p>

<p><img src="http://winseliu.com/images/blogs/linux-101-hacks-review-securecrt-web.png" alt="" /></p>

<h2>技巧二：ssh-copy-id【hack 72】</h2>

<p>想不通，现在的教程都使用【复制-添加-修改权限】公钥的方式来进行无密钥登录配置。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ scp .ssh/id_rsa.pub 172.17.0.3:~/master_id_rsa.pub
</span><span class='line'>hadoop@172.17.0.3's password: 
</span><span class='line'>id_rsa.pub                                                                                                                     100%  403     0.4KB/s   00:00    
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh 172.17.0.3
</span><span class='line'>hadoop@172.17.0.3's password: 
</span><span class='line'>Last login: Sun Sep 13 11:41:17 2015 from 172.17.0.2
</span><span class='line'>[hadoop@hadoop-slaver1 ~]$ cat master_id_rsa.pub &gt;&gt; .ssh/authorized_keys 
</span><span class='line'>[hadoop@hadoop-slaver1 ~]$ ll -d .ssh
</span><span class='line'>drwx------. 2 hadoop hadoop 4096 Mar 10  2015 .ssh
</span><span class='line'>[hadoop@hadoop-slaver1 ~]$ ll .ssh/authorized_keys 
</span><span class='line'>-rw-------. 1 hadoop hadoop 403 Sep 13 11:58 .ssh/authorized_keys</span></code></pre></td></tr></table></div></figure>


<p>处理一个ssh无密钥登录搞N多的步骤，还不一定能成功！其实使用ssh-copy-id的命令就行了，不知道各类书籍上面都使用老旧的方法，都是抄来的吗？！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-slaver1 ~]$ ssh-copy-id -i .ssh/id_rsa.pub 172.17.0.2
</span><span class='line'>The authenticity of host '172.17.0.2 (172.17.0.2)' can't be established.
</span><span class='line'>RSA key fingerprint is aa:41:79:6d:9d:c2:ec:f1:29:71:43:24:39:09:58:b6.
</span><span class='line'>Are you sure you want to continue connecting (yes/no)? yes
</span><span class='line'>Warning: Permanently added '172.17.0.2' (RSA) to the list of known hosts.
</span><span class='line'>hadoop@172.17.0.2's password: 
</span><span class='line'>Now try logging into the machine, with "ssh '172.17.0.2'", and check in:
</span><span class='line'>
</span><span class='line'>  .ssh/authorized_keys
</span><span class='line'>
</span><span class='line'>to make sure we haven't added extra keys that you weren't expecting.</span></code></pre></td></tr></table></div></figure>


<h2>技巧三：查看机器</h2>

<p>碰到不认识的人，我们都会上下打量。机器也一样，首先要了解机器，才能充分的发挥自己的性能。存储不够要么删点，要么加磁盘等等。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>uname -a
</span><span class='line'>cat /etc/redhat-release 
</span><span class='line'>ifconfig
</span><span class='line'>
</span><span class='line'>date
</span><span class='line'>
</span><span class='line'>df -h , df -Tha
</span><span class='line'>free -m 
</span><span class='line'>uptime
</span><span class='line'>top
</span><span class='line'>ps aux , ps auxf
</span><span class='line'>netstat -atp
</span><span class='line'>du -h --max-depth=1
</span><span class='line'>lsof -i:[PORT]
</span><span class='line'>
</span><span class='line'>cat /etc/hosts</span></code></pre></td></tr></table></div></figure>


<h2>技巧四：管道</h2>

<p>一个命令的结果直接输出给另一个命令。就像水从一个结头通过管子直接流向下一个结头一样。中间不需要落地，直接立即用于下一个命令，直到结果输出。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat /etc/hosts | grep 'hadoop' | awk '{print $2}' | while read h ; do echo $h ; done</span></code></pre></td></tr></table></div></figure>


<p>shell的命令那么多，简单功能的材料都准备好了，就像堆积木一样，叠加后总能实现你想得到的效果。</p>

<p>在进行一次性文件拷贝时，如果文件数量过多，可以先打包然后传到远程机器再解压：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar zc nginx | ssh bigdata1 'tar zx'</span></code></pre></td></tr></table></div></figure>


<h2>技巧N：查看帮助</h2>

<p>写java的没看过开源项目不要说自己会java，写shell没用过man不要说自己会shell！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>man [CMD]
</span><span class='line'>info [CMD]
</span><span class='line'>[CMD] help
</span><span class='line'>[CMD] -h
</span><span class='line'>[CMD] -help</span></code></pre></td></tr></table></div></figure>


<p>总有一款适合你，带着实践和问题的目的去学/写，能更好的把握它。（shell的命令太多，不要寄希望于看一个宝典就能写好！实践出真知，真正用到的才是实用的）</p>

<h2>技巧N-1：调试Shell脚本</h2>

<p>Shell脚本/命令在执行前会对变量进行解析、处理。查看最终执行的命令，能让我们了解到脚本不正确的地方，然后及时进行更正。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>set命令的参数说明
</span><span class='line'>-v      Print shell input lines as they are read.
</span><span class='line'>-x      After  expanding each simple command, for command, case command, select command, or arithmetic for command, 
</span><span class='line'>display the expanded value of PS4, followed by the command and its expanded arguments or associated word list.
</span><span class='line'>    
</span><span class='line'>[hadoop@hadoop-master2 ~]$ set -x
</span><span class='line'>[hadoop@hadoop-master2 1]$ cmd=*
</span><span class='line'>+ cmd='*'
</span><span class='line'>[hadoop@hadoop-master2 1]$ echo $cmd
</span><span class='line'>+ echo 2 file
</span><span class='line'>2 file
</span><span class='line'>[hadoop@hadoop-master2 1]$ echo "$cmd" # 双引号
</span><span class='line'>+ echo '*'
</span><span class='line'>*
</span><span class='line'>[hadoop@hadoop-master2 1]# echo '$cmd' # 单引号
</span><span class='line'>+ echo '$cmd'
</span><span class='line'>$cmd</span></code></pre></td></tr></table></div></figure>


<p>调试脚本</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 1]# vi run.sh
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>bin=$(dir=`dirname $0`; cd $dir ; pwd)
</span><span class='line'>
</span><span class='line'>cd $bin
</span><span class='line'>ls -l
</span><span class='line'>
</span><span class='line'>[root@hadoop-master2 1]# sh -x run.sh 
</span><span class='line'>+++ dirname run.sh
</span><span class='line'>++ dir=.
</span><span class='line'>++ cd .
</span><span class='line'>++ pwd
</span><span class='line'>+ bin=/tmp/1
</span><span class='line'>+ cd /tmp/1
</span><span class='line'>+ ls -l
</span><span class='line'>total 8
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop 4096 Sep 13 20:33 2
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop    0 Sep 13 20:33 file
</span><span class='line'>-rw-r--r-- 1 root   root     66 Sep 13 21:12 run.sh</span></code></pre></td></tr></table></div></figure>


<h2>技巧N-2：历史history</h2>

<p>历史如足迹。如果你要学习前辈的经验，理着他的足迹，一步步的走！</p>

<p>很多书上说的，<code>CTRL+R, !!, !-1, CTRL+P, ![CMD], !!:$, !^, ![CMD]:2, ![CMD]:$</code>用于获取以后执行的命令或者参数，多半好看不实用。会写的也就前面1-2个命令重复用一下，上下方向键就可以了，不会写的用history查看全部慢慢学更实际点。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>历史记录执行时间
</span><span class='line'>export HISTTIMEFORMAT='%F %T '
</span><span class='line'>输出最近10条历史
</span><span class='line'>alias hist10='history 10'
</span><span class='line'>
</span><span class='line'>持久化保存的历史记录数
</span><span class='line'>vi ~/.bash_profile
</span><span class='line'>HISTSIZE=450
</span><span class='line'>HISTFILESIZE=450
</span><span class='line'># HISTFILE
</span><span class='line'>
</span><span class='line'>忽略连续重复的命令
</span><span class='line'>export HISTCONTROL=ignoredups
</span><span class='line'>
</span><span class='line'>忽略重复的命令
</span><span class='line'>export HISTCONTROL=erasedups
</span><span class='line'>
</span><span class='line'>忽略指定的命令
</span><span class='line'>export HISTIGNORE='pwd:ls'</span></code></pre></td></tr></table></div></figure>


<h2>技巧N-3：shell之grep awk sed vi</h2>

<p>这些就不是看看man就能上手的，细嚼慢咽找几本书翻翻！！</p>

<p>推荐两本书： [sed与awk(第二版)], [Shell脚本学习指南]</p>

<h2>技巧N-4：批量处理之神：expect/for/while</h2>

<p>传入用户（与ssh的用户一致）密码，进行SSH无密钥认证：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 1]# vi ssh-copy-id.expect
</span><span class='line'>#!/usr/bin/expect  
</span><span class='line'>
</span><span class='line'>## Usage $0 [user@]host password
</span><span class='line'>
</span><span class='line'>set host [lrange $argv 0 0];
</span><span class='line'>set password [lrange $argv 1 1] ;
</span><span class='line'>
</span><span class='line'>set timeout 30;
</span><span class='line'>
</span><span class='line'>spawn ssh-copy-id $host ;
</span><span class='line'>
</span><span class='line'>expect {
</span><span class='line'>  "(yes/no)?" { send yes\n; exp_continue; }
</span><span class='line'>  "password:" { send $password\n; exp_continue; }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>exec sleep 1;
</span><span class='line'>
</span><span class='line'>批量处理
</span><span class='line'>[root@hadoop-master2 1]# for h in `cat /etc/hosts | grep hadoop | awk '{print $2}' ` ; do ./ssh-copy-id.expect $h root-password ; done</span></code></pre></td></tr></table></div></figure>


<p>传入新用户名称和密码，新建用户：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master2 1]# vi passwd.expect
</span><span class='line'>#!/usr/bin/expect  
</span><span class='line'>
</span><span class='line'>## Usage $0 host username password
</span><span class='line'>
</span><span class='line'>set host [lrange $argv 0 0];
</span><span class='line'>set username [lrange $argv 1 1];
</span><span class='line'>set password [lrange $argv 2 2] ;
</span><span class='line'>
</span><span class='line'>set timeout 30;
</span><span class='line'>
</span><span class='line'>##
</span><span class='line'>
</span><span class='line'>spawn ssh $host useradd $username ;
</span><span class='line'>
</span><span class='line'>exec sleep 1;
</span><span class='line'>
</span><span class='line'>##
</span><span class='line'>
</span><span class='line'>spawn ssh $host passwd $username ;
</span><span class='line'>
</span><span class='line'>## password and repasswd all use this
</span><span class='line'>expect {
</span><span class='line'>  "password:" { send $password\n; exp_continue; }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>exec sleep 1;
</span><span class='line'>
</span><span class='line'>批量处理
</span><span class='line'>[root@hadoop-master2 1]# for h in `cat /etc/hosts | grep hadoop | awk '{print $2}' ` ; do ./passwd.expect $h hadoop hadoop-password ; done</span></code></pre></td></tr></table></div></figure>


<h2>最后</h2>

<p>当然还有很多命令，xargs, if等需要在实践中慢慢积累，shell博大精深继续码字！cdpath眼前一亮，alias还可以这么用！！</p>

<p>在linux把xml转成properties键值对形式的命令，觉得也挺有意思的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 ~]$ vi format.xslt
</span><span class='line'>&lt;xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;
</span><span class='line'>&lt;xsl:output method="text" encoding="iso-8859-1"/&gt;
</span><span class='line'>
</span><span class='line'>&lt;xsl:strip-space elements="*" /&gt;
</span><span class='line'>
</span><span class='line'>&lt;xsl:template match="/*/child::*"&gt;
</span><span class='line'>&lt;xsl:for-each select="child::*"&gt;
</span><span class='line'>&lt;xsl:if test="position() != last()"&gt;&lt;xsl:value-of select="normalize-space(.)"/&gt;=&lt;/xsl:if&gt;
</span><span class='line'>&lt;xsl:if test="position() = last()"&gt;&lt;xsl:value-of select="normalize-space(.)"/&gt; &lt;xsl:text&gt;&#xa;&lt;/xsl:text&gt; &lt;/xsl:if&gt;
</span><span class='line'>&lt;/xsl:for-each&gt;
</span><span class='line'>&lt;/xsl:template&gt;
</span><span class='line'>
</span><span class='line'>&lt;/xsl:stylesheet&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 ~]$ xsltproc format.xslt ~/hadoop-2.2.0/etc/hadoop/yarn-site.xml
</span><span class='line'>yarn.nodemanager.aux-services=mapreduce_shuffle
</span><span class='line'>yarn.nodemanager.aux-services.mapreduce.shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
</span><span class='line'>yarn.resourcemanager.address=hadoop-master1:8032
</span><span class='line'>yarn.resourcemanager.scheduler.address=hadoop-master1:8030
</span><span class='line'>yarn.resourcemanager.resource-tracker.address=hadoop-master1:8031
</span><span class='line'>yarn.resourcemanager.admin.address=hadoop-master1:8033
</span><span class='line'>yarn.resourcemanager.webapp.address=hadoop-master1:8088
</span><span class='line'>yarn.nodemanager.resource.memory-mb=51200=yarn-default.xml
</span><span class='line'>yarn.scheduler.minimum-allocation-mb=1024=yarn-default.xml</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Oozie Start Guide]]></title>
    <link href="http://winseliu.com/blog/2015/09/08/oozie-start-guide/"/>
    <updated>2015-09-08T11:15:14+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/08/oozie-start-guide</id>
    <content type="html"><![CDATA[<h2>步骤记录</h2>

<p>说明：cu2就是hadoop-master2</p>

<ol>
<li>打包</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 oozie-4.2.0]$ vi bin/mkdistro.sh 
</span><span class='line'>MVN_OPTS="-Dbuild.time=${DATETIME} -Dvc.revision=${VC_REV} -Dvc.url=${VC_URL} "
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/mkdistro.sh -DskipTests -Dmaven.javadoc.skip=true</span></code></pre></td></tr></table></div></figure>


<ol>
<li>依赖</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>打包后，文件的位置
</span><span class='line'>[hadoop@cu2 ~]$ tar zxvf sources/oozie-4.2.0/distro/target/oozie-4.2.0-distro.tar.gz
</span><span class='line'>
</span><span class='line'>下载 &lt;http://dev.sencha.com/deploy/ext-2.2.zip&gt;
</span><span class='line'>
</span><span class='line'>yum install zip
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ mkdir libext
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ cd libext/
</span><span class='line'>[hadoop@cu2 libext]$ ll
</span><span class='line'>total 7584
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop 6800612 Sep  7 16:00 ext-2.2.zip
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop  960372 Feb 28  2015 mysql-connector-java-5.1.34.jar</span></code></pre></td></tr></table></div></figure>


<ol>
<li>安装</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/oozie-setup.sh prepare-war
</span><span class='line'>
</span><span class='line'>setup后，生成的war的位置：/home/hadoop/oozie-4.2.0/oozie-server/webapps/oozie.war</span></code></pre></td></tr></table></div></figure>


<ol>
<li>初始化数据库</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>创建数据库用户
</span><span class='line'>
</span><span class='line'>CREATE DATABASE oozie;
</span><span class='line'>GRANT ALL ON oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';
</span><span class='line'>FLUSH PRIVILEGES;
</span><span class='line'>GRANT ALL ON oozie.* TO 'oozie'@'localhost'  IDENTIFIED BY 'oozie';
</span><span class='line'>FLUSH PRIVILEGES;
</span><span class='line'>
</span><span class='line'>show grants for oozie;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ vi conf/oozie-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;oozie.service.JPAService.jdbc.driver&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;oozie.service.JPAService.jdbc.url&lt;/name&gt;&lt;value&gt;jdbc:mysql://localhost:3306/oozie&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;oozie.service.JPAService.jdbc.username&lt;/name&gt;&lt;value&gt;oozie&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;oozie.service.JPAService.jdbc.password&lt;/name&gt;&lt;value&gt;oozie&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>这里直接把hadoop的jar添加到脚本中，不拷贝到libext下面
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ vi bin/ooziedb.sh
</span><span class='line'>OOZIECPPATH=""
</span><span class='line'>if [ ! -z ${HADOOP_HOME} ] ; then
</span><span class='line'>  OOZIECPPATH="${OOZIECPPATH}:$($HADOOP_HOME/bin/hadoop classpath)"
</span><span class='line'>fi
</span><span class='line'>
</span><span class='line'>照着写就行了，不必考虑sql文件的存在与否
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/ooziedb.sh create -sqlfile oozie.sql -run
</span><span class='line'>  setting CATALINA_OPTS="$CATALINA_OPTS -Xmx1024m"
</span><span class='line'>
</span><span class='line'>Validate DB Connection
</span><span class='line'>DONE
</span><span class='line'>DB schema does not exist
</span><span class='line'>Check OOZIE_SYS table does not exist
</span><span class='line'>DONE
</span><span class='line'>Create SQL schema
</span><span class='line'>DONE
</span><span class='line'>Create OOZIE_SYS table
</span><span class='line'>DONE
</span><span class='line'>
</span><span class='line'>Oozie DB has been created for Oozie version '4.2.0'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>The SQL commands have been written to: oozie.sql</span></code></pre></td></tr></table></div></figure>


<ol>
<li>启动服务</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>由于war中没有hadoop的jar，所以这里也需要把它们添加到tomcat
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ $HADOOP_HOME/bin/hadoop classpath | sed 's/:/,/g'
</span><span class='line'>/home/hadoop/hadoop-2.7.1/etc/hadoop,/home/hadoop/hadoop-2.7.1/share/hadoop/common/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/common/*,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/*,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/*,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/*,/home/hadoop/hadoop-2.7.1/contrib/capacity-scheduler/*.jar
</span><span class='line'>
</span><span class='line'>处理下把*改成*.jar
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ vi oozie-server/conf/catalina.properties 
</span><span class='line'>common.loader=${catalina.base}/lib,${catalina.base}/lib/*.jar,${catalina.home}/lib,${catalina.home}/lib/*.jar,/home/hadoop/hadoop-2.7.1/etc/hadoop,/home/hadoop/hadoop-2.7.1/share/hadoop/common/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/common/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/*.jar,/home/hadoop/hadoop-2.7.1/contrib/capacity-scheduler/*.jar
</span><span class='line'>
</span><span class='line'># 前台运行 bin/oozied.sh run
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/oozied.sh start
</span><span class='line'>
</span><span class='line'>http://localhost:11000/</span></code></pre></td></tr></table></div></figure>


<ol>
<li>测试</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 oozie-4.2.0]$ vi bin/oozie
</span><span class='line'>OOZIECPPATH=""
</span><span class='line'>if [ ! -z ${HADOOP_HOME} ] ; then
</span><span class='line'>  OOZIECPPATH="${OOZIECPPATH}:$($HADOOP_HOME/bin/hadoop classpath)"
</span><span class='line'>fi
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/oozie admin -oozie http://localhost:11000/oozie -status
</span><span class='line'>System mode: NORMAL</span></code></pre></td></tr></table></div></figure>


<ol>
<li>跑个helloworld</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 oozie-4.2.0]$ tar zxvf oozie-sharelib-4.2.0.tar.gz 
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ ~/hadoop-2.7.1/bin/hadoop fs -rmr share
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ ~/hadoop-2.7.1/bin/hadoop fs -put share share
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ tar zxvf oozie-examples.tar.gz 
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ ~/hadoop-2.7.1/bin/hadoop fs -put examples examples
</span><span class='line'>
</span><span class='line'>修改share后重启下oozie，sharelib在应用中会缓冲，中间上传程序不能识别，会报`Could not locate Oozie sharelib`的错。
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ vi examples/apps/map-reduce/job.properties 
</span><span class='line'>nameNode=hdfs://hadoop-master2:9000
</span><span class='line'>jobTracker=hadoop-master2:8032
</span><span class='line'>queueName=default
</span><span class='line'>examplesRoot=examples
</span><span class='line'>
</span><span class='line'>oozie.wf.application.path=${nameNode}/user/${user.name}/${examplesRoot}/apps/map-reduce/workflow.xml
</span><span class='line'>outputDir=map-reduce
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/oozie job -oozie http://localhost:11000/oozie -config examples/apps/map-reduce/job.properties -run
</span><span class='line'>Error: E0501 : E0501: Could not perform authorization operation, User: hadoop is not allowed to impersonate hadoop
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.7.1]$ vi etc/hadoop/core-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ for h in `cat /etc/hosts | grep slaver | awk '{print $2}' ` ; do rsync -vaz hadoop-2.7.1 $h:~/ --exclude=logs ; done
</span><span class='line'>
</span><span class='line'>同步重启集群
</span><span class='line'>
</span><span class='line'>注：增加以上配置后，无需重启集群，可以直接用hadoop管理员账号重新加载这两个属性值，命令为：
</span><span class='line'>    hdfs dfsadmin -refreshSuperUserGroupsConfiguration
</span><span class='line'>    yarn rmadmin -refreshSuperUserGroupsConfiguration
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 oozie-4.2.0]$ bin/oozie job -oozie http://localhost:11000/oozie -config examples/apps/map-reduce/job.properties -run
</span><span class='line'>job: 0000000-150908082015741-oozie-hado-W
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.7.1]$ bin/hadoop fs -cat /user/hadoop/examples/output-data/map-reduce/part-00000
</span><span class='line'>
</span><span class='line'>尽管能看到结果了，但是不算任务执行成功。任务是有报错的`JA006: Call From cu2/192.168.0.214 to hadoop-master2:10020 failed on connection exception`
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.7.1]$ sbin/mr-jobhistory-daemon.sh start historyserver
</span><span class='line'>
</span><span class='line'>在运行一次就ok了。</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="https://oozie.apache.org/docs/4.2.0/DG_QuickStart.html">https://oozie.apache.org/docs/4.2.0/DG_QuickStart.html</a></li>
<li><a href="http://ju.outofmemory.cn/entry/65688">http://ju.outofmemory.cn/entry/65688</a></li>
<li><a href="http://stackoverflow.com/questions/30926357/oozie-on-yarn-oozie-is-not-allowed-to-impersonate-hadoop">http://stackoverflow.com/questions/30926357/oozie-on-yarn-oozie-is-not-allowed-to-impersonate-hadoop</a></li>
<li><a href="http://oozie.apache.org/docs/4.0.0/DG_QuickStart.html#Oozie_Share_Lib_Installation">http://oozie.apache.org/docs/4.0.0/DG_QuickStart.html#Oozie_Share_Lib_Installation</a></li>
<li><a href="https://oozie.apache.org/docs/4.2.0/DG_Examples.html">https://oozie.apache.org/docs/4.2.0/DG_Examples.html</a></li>
<li><p><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html">http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></p></li>
<li><p><a href="http://blog.csdn.net/wngn123/article/details/41380013">http://blog.csdn.net/wngn123/article/details/41380013</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装http代理服务器squid]]></title>
    <link href="http://winseliu.com/blog/2015/09/06/squid-http-proxy-server-install/"/>
    <updated>2015-09-06T23:22:50+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/06/squid-http-proxy-server-install</id>
    <content type="html"><![CDATA[<h2>环境说明</h2>

<ul>
<li>squid-3.3.14.tar.gz</li>
<li>centos6.6</li>
</ul>


<h2>安装</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install gcc gcc-c++
</span><span class='line'>cd squid-3.3.14
</span><span class='line'>./configure
</span><span class='line'>make
</span><span class='line'>make install
</span><span class='line'>
</span><span class='line'>cd /usr/local/squid
</span><span class='line'>#不修改会有权限的问题
</span><span class='line'>chmod 777 var/logs
</span><span class='line'>sbin/squid 
</span><span class='line'>sbin/squid -k shutdown</span></code></pre></td></tr></table></div></figure>


<p>或者：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum -y install squid
</span><span class='line'>chkconfig squid on</span></code></pre></td></tr></table></div></figure>


<p>改下squid.conf的配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># And finally deny all other access to this proxy
</span><span class='line'>#http_access deny all
</span><span class='line'>http_access allow all</span></code></pre></td></tr></table></div></figure>


<h2>使用</h2>

<p>在浏览器中设置Http代理。端口为3128</p>

<h2>参考</h2>

<ul>
<li><a href="ftp://ftp.cuhk.edu.hk/pub/packages/info-systems/www/squid/">ftp://ftp.cuhk.edu.hk/pub/packages/info-systems/www/squid/</a></li>
<li><a href="http://www.educity.cn/linux/517165.html">http://www.educity.cn/linux/517165.html</a></li>
<li><a href="http://www.ajaxstu.com/Proxyfuwuqi/283731.html">http://www.ajaxstu.com/Proxyfuwuqi/283731.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_537b9caa010185xo.html">http://blog.sina.com.cn/s/blog_537b9caa010185xo.html</a></li>
<li><a href="http://blog.163.com/sword_111/blog/static/6658941620114163458435/">http://blog.163.com/sword_111/blog/static/6658941620114163458435/</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-install-squid-proxy-on-centos-6">https://www.digitalocean.com/community/tutorials/how-to-install-squid-proxy-on-centos-6</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
