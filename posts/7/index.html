
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="从apache下载的tar.gz的hadoop-1.1.0包中本来就包括了src的源码。可以方便我们查看源码调试。 题外话： 从github上下载了最新的hadoop-common的源码，发现hadoop-2.0已经是使用maven管理代码了。 在eclipse中新建java project， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winse.github.io/posts/7">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="http://cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-43198550-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winse.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/15/compile-hadoop-source-and-modify-jsp/">编译hadoop的jsp源码</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-15T23:21:00+08:00" pubdate data-updated="true">Fri 2013-03-15 23:21</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>从apache下载的tar.gz的hadoop-1.1.0包中本来就包括了src的源码。可以方便我们查看源码调试。</p>

<p><del>题外话： 从github上下载了最新的hadoop-common的源码，发现hadoop-2.0已经是使用maven管理代码了。</del></p>

<p>在eclipse中新建java project，去掉<strong>Use Default location</strong>的复选框的勾，项目目录为hadoop-1.1.0程序所在的位置。然后点击finish即可。</p>

<p><img src="http://dl.iteye.com/upload/attachment/0081/7334/643c83b4-e123-362e-bc40-d801805584f4.png" alt="" /></p>

<p>完成后，项目下面的lib包，以及Source Folder源码包都已经正确的配置好了。如下图。</p>

<p><img src="http://dl.iteye.com/upload/attachment/0081/7344/64575adf-3ee5-3a83-a184-bcff4f9df4d8.png" alt="" /></p>

<p>编译hadoop的源码，需要用到sed，sh的linux shell命令（根据网上的资料）。安装好了cygwin，把c:\cygwin\bin加入到PATH环境变量。然后直接使用eclipse ant（eclipse自带）编译。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Winseliu@WINSE ~
</span><span class='line'>$ cygcheck -c cygwin
</span><span class='line'>Cygwin Package Information
</span><span class='line'>Package              Version        Status
</span><span class='line'>cygwin               1.7.17-1       OK
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://dl.iteye.com/upload/attachment/0081/7351/e1b2d853-fcaf-3ccc-8663-8f579c67755f.png" alt="" /></p>

<p>由于linux和windows的换行符的不同（同事周帅哥在导数据也遇到这样的问题），直接编译会失败。</p>

<p><img src="http://dl.iteye.com/upload/attachment/0081/7353/29b31fa1-7f02-3979-b72d-fc3019f355dd.png" alt="" /></p>

<p>需要对src/saveVersion.sh的shell文件进行修改：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-  user=`whoami`
</span><span class='line'>+  user=`whoami | tr -d '\r'` </span></code></pre></td></tr></table></div></figure>


<p>然后再编译一次就ok了！</p>

<hr />

<p>经过上面步骤已经可以正确的编译hadoop-core的源码了。</p>

<p>在监控集群的时刻，我们一般都在自己常用的windows系统上面通过50030和50070来了解集群的情况。但是如果没有域名服务器，那，我们就不得不修改hosts文件。在出现访问失败的情况下，我们可以使用ip地址替换URL中对应的hostname来访问，但是比较麻烦。</p>

<p>如果在服务器响应请求的时刻，解析生成html的时刻就已经是ip地址那就最好不过了！
其实，直接看看jsp的源码，修改起来不算太难。把jsp里面的hostname转换为IP地址即可。</p>

<p><img src="http://dl.iteye.com/upload/attachment/0081/7361/951ae5f2-9dc3-31cd-aef3-657608a93e00.png" alt="" /></p>

<p>把上图的hostname通过InetAddress获取转换为IpAddress地址。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-    String namenodeHost = jspHelper.nameNodeAddr.getHostName();
</span><span class='line'>+    String namenodeHost = jspHelper.nameNodeAddr.getAddress().getHostAddress();
</span><span class='line'>
</span><span class='line'>-              InetAddress.getByName(namenodeHost).getCanonicalHostName() + ":" +
</span><span class='line'>+              InetAddress.getByName(namenodeHost).getHostAddress() + ":" +
</span></code></pre></td></tr></table></div></figure>


<p>全部修改完成后，再次运行hadoop-1.1.0 build.xml的ant命令，会调用自定义的jsp-compile把jsp转换成java类保存到build/src目录下面。然后javac再编译build/src目录下的源码。</p>

<p><img src="http://dl.iteye.com/upload/attachment/0081/7370/421dc6d3-4a8a-340a-8bca-705369c0a057.png" alt="" /></p>

<p>如果你只想编译这些jsp，把javac中的srcdir的目录只保留build.src应该就可以咯。</p>

<p>我是直接把build/src作为Source Folder，然后把这个Source Folder下的编译文件放置的特定的目录，然后覆盖原来jar里面的class即可！</p>

<p><img src="http://dl.iteye.com/upload/attachment/0081/7396/7b3ccd33-936a-30ce-8082-d82f34d768bf.png" alt="" /></p>

<h2>参考：</h2>

<ul>
<li><a href="http://wenku.baidu.com/view/c1ad44323968011ca3009199.html">Hadoop源代码eclipse编译教程</a></li>
</ul>


<hr />

<p><a href="http://winse.iteye.com/blog/1830311">【原文地址】</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/02/quickly-build-a-second-hadoop-cluster/">快速搭建第二个hadoop分布式集群环境</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-02T00:06:00+08:00" pubdate data-updated="true">Sat 2013-03-02 00:06</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>万事开头难，第一次搭建集群环境确实是比较难，比较苦恼。但，也不是说第二次搭建集群环境就会容易。</p>

<p>一般，第一次操作我们都会在测试环境中进行，当我们要搭建正式的环境时，是否还要像第一次那样搭建环境呢？
这里提供一种稍稍便捷一点的配置方式来搭建集群，<strong>所有的操作</strong>都在<strong>namenode</strong>上面进行！</p>

<p>192.168.3.100 h100为测试环境的namenode。</p>

<p>将要搭建的环境包括3台机器，已经全部安装好redhat的操作系统：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>192.168.80.81 h81 #namenode
</span><span class='line'>192.168.80.82 h82 #datanode1
</span><span class='line'>192.168.80.83 h83 #datanode2</span></code></pre></td></tr></table></div></figure>


<p>使用SecureCRT工具，root用户登录到新环境namenode。步骤参考，有些步骤需要输入密码(<strong>可以通过expect来模拟</strong>)，不能一次性全部执行。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 生成root用户的密钥对
</span><span class='line'>ssh-keygen 
</span><span class='line'>
</span><span class='line'>## 建立到100机器的无密钥登录
</span><span class='line'>ssh-copy-id -i .ssh/id_rsa.pub hadoop@192.168.3.100
</span><span class='line'>
</span><span class='line'>## 拷贝JDK，将加入hadoop用户的环境变量
</span><span class='line'>mkdir -p /opt/java
</span><span class='line'>scp -r hadoop@192.168.3.100:/opt/java/jdk1.6.0_29 /opt/java
</span><span class='line'>
</span><span class='line'>## 把集群的IP和机器名对应加入hosts文件
</span><span class='line'>vi /etc/hosts
</span><span class='line'>
</span><span class='line'># 192.168.80.81 h81
</span><span class='line'># 192.168.80.82 h82
</span><span class='line'># 192.168.80.83 h83
</span><span class='line'>
</span><span class='line'>## 定义常量
</span><span class='line'>namenode='h81'
</span><span class='line'>hosts=`cat /etc/hosts | grep 192.168 | awk '{print $2}'`
</span><span class='line'>
</span><span class='line'>## 修改时间，~~可以日期和时间一起修改的~~
</span><span class='line'>DATE='2013-03-01'
</span><span class='line'>TIME='10:30:00'
</span><span class='line'>
</span><span class='line'>for host in $hosts
</span><span class='line'>do
</span><span class='line'>  ssh $host date -s $DATE
</span><span class='line'>  ssh $host date -s $TIME
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>## 建立namenode到datanodes的无密钥访问，这里需要输入对应datanode的root用户的密码
</span><span class='line'>for host in $hosts
</span><span class='line'>do
</span><span class='line'>  ssh-copy-id -i .ssh/id_rsa.pub $host
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>#### 
</span><span class='line'>for host in $hosts
</span><span class='line'>do
</span><span class='line'>  ## 在集群所有节点上创建hadoop用户，会提示很多次输入密码。可以通过修改/etc/shadow替换密码输入的步骤
</span><span class='line'>  ssh $host useradd hadoop
</span><span class='line'>  ssh $host passwd hadoop
</span><span class='line'>
</span><span class='line'>  ## 拷贝jdk到datanodes
</span><span class='line'>  if [ $host != $namenode ]
</span><span class='line'>  then
</span><span class='line'>      scp /etc/hosts $host:/etc/hosts
</span><span class='line'>      ssh $host mkdir -p /opt/java
</span><span class='line'>      scp -r /opt/java/jdk1.6.0_29 $host:/opt/java 2&gt;&1 &gt; jdk.scp.$host.log & 
</span><span class='line'>  fi
</span><span class='line'>
</span><span class='line'>  ## 修改集群的hostname主机名称
</span><span class='line'>  ssh $host hostname $host
</span><span class='line'>  ssh $host cat /etc/sysconfig/network | sed s/localhost.localdomain/$host/g &gt; /tmp/network && cat /tmp/network &gt; /etc/sysconfig/network
</span><span class='line'>
</span><span class='line'>  ## 创建数据目录，并把权限分配给hadoop
</span><span class='line'>  ssh $host mkdir /opt/cloud
</span><span class='line'>  ssh $host chown hadoop /opt/cloud
</span><span class='line'>
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>## ！切换到hadoop用户
</span><span class='line'>su - hadoop
</span><span class='line'>
</span><span class='line'>## 生成hadoop用户的密钥对
</span><span class='line'>ssh-keygen
</span><span class='line'>
</span><span class='line'>## 在hadoop用户的终端定义变量（root的终端变量获取不到的）
</span><span class='line'>namenode='h81'
</span><span class='line'>hosts=`cat /etc/hosts | grep 192.168 | awk '{print $2}'`
</span><span class='line'>
</span><span class='line'>## 使namenode的hadoop用户无密钥登录到集群各个机器
</span><span class='line'>for host in $hosts
</span><span class='line'>do
</span><span class='line'>  ssh-copy-id -i .ssh/id_rsa.pub $host
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>## 更新hadoop用户的环境变量，
</span><span class='line'>vi .bashrc
</span><span class='line'>
</span><span class='line'># export JAVA_HOME=/opt/java/jdk1.6.0_29
</span><span class='line'># PATH=$JAVA_HOME/bin:/usr/sbin:$PATH
</span><span class='line'># export PATH
</span><span class='line'>
</span><span class='line'>## 修改datanodes的环境环境变量，同时为集群创建必要的目录
</span><span class='line'>for host in $hosts
</span><span class='line'>do
</span><span class='line'>  if [ $host != $namenode ]
</span><span class='line'>  then
</span><span class='line'>      scp .bashrc $host:~/.bashrc
</span><span class='line'>  fi
</span><span class='line'>
</span><span class='line'>  ssh $host source .bashrc
</span><span class='line'>  ssh $host mkdir -p /home/hadoop/cloud/zookeeper
</span><span class='line'>  ssh $host mkdir -p /home/hadoop/pids/katta/pids
</span><span class='line'>  ssh $host mkdir -p /home/hadoop/pids/hadoop/pids 
</span><span class='line'>
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>## 建立namenode下的hadoop用户到192.168.3.100的无密钥访问
</span><span class='line'>ssh-copy-id -i .ssh/id_rsa.pub 192.168.3.100
</span><span class='line'>
</span><span class='line'>## 从100上拷贝集群程序
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/lucene ~/
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/sqoop-1.4.1 ~/
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/zookeeper-3.3.5 ~/
</span><span class='line'>
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/hadoop-1.0.0 ~/
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/hbase-0.92.1 ~/
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/katta-core-0.6.4 ~/
</span><span class='line'>rsync -vaz --delete  --exclude=logs --exclude=log  192.168.3.100:~/lucene-shared-lib ~/
</span><span class='line'>
</span><span class='line'>## 查找配置文件中与测试环境有关的信息
</span><span class='line'>[hadoop@h81 ~]$ find */conf | while read conf; do if grep -E 'h100|192.168.3.100' $conf &gt; /dev/null; then echo $conf;fi;done
</span><span class='line'>hadoop-1.0.0/conf/mapred-site.xml
</span><span class='line'>hadoop-1.0.0/conf/core-site.xml
</span><span class='line'>hadoop-1.0.0/conf/masters
</span><span class='line'>hbase-0.92.1/conf/hbase-site.xml
</span><span class='line'>katta-core-0.6.4/conf/katta.zk.properties
</span><span class='line'>katta-core-0.6.4/conf/masters
</span><span class='line'>lucene/conf/config-env.sh
</span><span class='line'>[hadoop@h81 ~]$ 
</span><span class='line'>
</span><span class='line'>## 替换为新的nameode的hostname
</span><span class='line'>find */conf | while read conf; do if grep -E 'h100|192.168.3.100' $conf &gt; /dev/null; then  cat $conf | sed s/h100/h81/g &gt; /tmp/conf && cat /tmp/conf &gt; $conf ;fi;done
</span><span class='line'>
</span><span class='line'>## 修改其他配置
</span><span class='line'>vi hadoop-1.0.0/conf/slaves
</span><span class='line'>vi hbase-0.92.1/conf/regionservers
</span><span class='line'>vi katta-core-0.6.4/conf/nodes
</span><span class='line'>
</span><span class='line'>## 确认是否还有原有集群的余孽！
</span><span class='line'>find */conf | while read conf; do if grep -E 'h10' $conf &gt; /dev/null; then echo $conf;fi;done
</span><span class='line'>
</span><span class='line'>## 拷贝集群程序到datanodes
</span><span class='line'>for host in $hosts
</span><span class='line'>do
</span><span class='line'>  if [ $host != $namenode ]
</span><span class='line'>  then
</span><span class='line'>      rsync -vaz --delete  --exclude=logs --exclude=log  ~/hadoop-1.0.0 $host:~/ &
</span><span class='line'>      rsync -vaz --delete  --exclude=logs --exclude=log  ~/hbase-0.92.1 $host:~/ &
</span><span class='line'>      rsync -vaz --delete  --exclude=logs --exclude=log  ~/katta-core-0.6.4 $host:~/ &
</span><span class='line'>      rsync -vaz --delete  --exclude=logs --exclude=log  ~/lucene-shared-lib $host:~/ &
</span><span class='line'>  fi
</span><span class='line'>done</span></code></pre></td></tr></table></div></figure>


<p><strong>如果你觉得sed修改麻烦，要备份，在写回！其实有<code>sed -i</code>（&ndash;in-place）参数提供了直接写入的功能。</strong></p>

<p>在批处理文件内容替换时，使用到了临时文件，当然也可以先把文件备份后，再写入新文件中，如下面的方式。
但，先备份再写入新文件 有个缺陷就是原始文件的权限会丢失！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh $host \
</span><span class='line'>mv /etc/sysconfig/network /etc/sysconfig/network.back && \ 
</span><span class='line'>cat /etc/sysconfig/network.back | sed s/localhost.localdomain/$host/g &gt; /etc/sysconfig/network</span></code></pre></td></tr></table></div></figure>


<p>最后你懂的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> hadoop-1.0.0/bin/hadoop namenode -format
</span><span class='line'> hadoop-1.0.0/bin/start-all.sh</span></code></pre></td></tr></table></div></figure>


<p>通过for，scp， ssh， sed， awk，rsync，vi， find，ssh-copy-id， mkdir等命令仅在namenode上完成集群的部署工作。</p>

<p>仅新增节点，又不想修改namenode配置文件！可以用下面的方法启动新节点：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@h101 ~]$ hadoop-1.0.0/bin/hadoop-daemon.sh start datanode
</span><span class='line'>
</span><span class='line'>starting datanode, logging to /home/hadoop/hadoop-1.0.0/libexec/../logs/hadoop-hadoop-datanode-h101.out
</span><span class='line'>
</span><span class='line'>[hadoop@h101 ~]$ hadoop-1.0.0/bin/hadoop-daemon.sh start tasktracker
</span><span class='line'>
</span><span class='line'>starting tasktracker, logging to /home/hadoop/hadoop-1.0.0/libexec/../logs/hadoop-hadoop-tasktracker-h101.out</span></code></pre></td></tr></table></div></figure>


<hr />

<p><a href="http://winse.iteye.com/blog/1820209">【原文地址】</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/02/22/hadoop-cluster-increases-nodes/">Hadoop集群增加节点</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-02-22T22:14:00+08:00" pubdate data-updated="true">Fri 2013-02-22 22:14</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>hadoop的集群的优势，其中之一就是可以灵活的增加数据节点，简简单单的实现扩容！
<del>新增个别节点还是可以通过这种方式来运行的，如果是初始化整个集群，一台一台的操作就很纠结了!</del></p>

<h2>操作步骤</h2>

<ol>
<li>最好安装统一的操作系统。安装的时刻把防火墙关了！</li>
<li><p>在新节点使用root用户，修改系统的一些参数</p>

<ul>
<li><p>修改时间</p>

<pre><code class="``">  date -s 12:00:00
</code></pre></li>
<li><p>设置IP地址</p>

<pre><code class="``">  vi /etc/sysconfig/network-scripts/ifcfg-eth0
  service network restart
</code></pre></li>
<li><p>修改host</p>

<pre><code class="``">  vi /etc/sysconfig/network
  ## 设置完以后不能立即见效，可以先使用hostname命令生效
  hostname datanode-00003
</code></pre></li>
<li><p>新增用户hadoop</p>

<pre><code class="``">  useradd hadoop
  passwd hadoop
</code></pre></li>
<li><p>修改<code>/etc/hosts</code></p></li>
</ul>
</li>
<li><p>namenode配置文件中添加新datanode</p>

<p> <strong>切换到namenode节点机器</strong></p>

<ul>
<li>如果没有域名解析服务，这里需要用<strong>root用户</strong>来修改namenode的<code>/etc/hosts</code>文件，添加新节点的hostname和ip的对应。</li>
<li><p>拷贝jdk到新节点（最好不要使用系统自带的版本） 。</p>

<pre><code class="``">  scp -r /opt/java/jdk1.6.0_29 datanode-00003:/opt/java
</code></pre></li>
</ul>


<p> <strong>然后，从root用户切换到hadoop用户</strong></p>

<ul>
<li>修改HADOOP_HOME/conf/slaves文件，添加新节点的hostname（为了以后start/stop <strong>统一管理</strong>hadoop）</li>
<li><p>namenode无密钥登录datanode，执行（为了以后start/stop <strong>统一管理</strong>hadoop）</p>

<pre><code class="``">  ssh-copy-id -i .ssh/id-rsa.pub datanode-00003
  #然后输入新节点hadoop用户的密码即可。
</code></pre></li>
<li><p>拷贝hadoop程序到新节点。</p>

<pre><code class="``">  rsync -vaz --delete --exclude=logs --exclude=log hadoop-1.0.0 datanode-00003:~/
</code></pre></li>
</ul>
</li>
<li><p>使用hadoop用户登录到新节点datanode-00003。</p>

<ul>
<li><p>修改环境变量。</p>

<pre><code class="``">  cd
  vi .bashrc
  ## 添加JAVA_HOME/bin到PATH路径
  # export JAVA_HOME=/opt/java/jdk1.6.0_29
  # export PATH=$JAVA_HOME/bin:$PATH

  source .bashrc
</code></pre></li>
<li><p>创建必要的目录（把hadoop的进程的<strong>pids文件保存的自定义的目录</strong>下，如果放置在tmp下，一段时间过后会被清除）。</p>

<pre><code class="``">  mkdir /opt/cloud
  mkdir /home/hadoop/pids/hadoop/pids
</code></pre></li>
</ul>
</li>
<li><p>启动新节点，加入到集群</p>

<p> <del>有很多文章说使用hadoop-daemon.sh来启动：</del></p>

<pre><code class="` ">   $HADOOP/bin/hadoop-daemon.sh start datanode 
   $HADOOP/hadoop-daemon.sh start tasktracker
</code></pre>

<p> 其实，大可不必，使用<strong>hadoop登录到namenode</strong>，在namenode上执行start-all.sh即可：</p>

<pre><code class="`"> bin/start-all.sh
</code></pre>

<p> 启动节点的时刻，会检查是否已经启动，<strong>只会启动</strong>未启动的服务。</p></li>
<li><p>如果希望节点的数据平均一点，可以执行：</p>

<pre><code class="`"> bin/start-balancer.sh
</code></pre></li>
</ol>


<h2>参考资料：</h2>

<ol>
<li><a href="http://kerry.blog.51cto.com/172631/517921">shell脚本自动修改IP信息</a></li>
<li><a href="http://a280606790.iteye.com/blog/867532">http://a280606790.iteye.com/blog/867532</a></li>
<li><a href="http://eclecl1314-163-com.iteye.com/blog/987732">http://eclecl1314-163-com.iteye.com/blog/987732</a></li>
<li><a href="http://running.iteye.com/blog/906585">http://running.iteye.com/blog/906585</a></li>
</ol>


<hr />

<p><a href="http://winse.iteye.com/blog/1812689">【原文地址】</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/11/25/hbase-script-bug-in-cygwin/">hbase-0.94启动脚本在cygwin环境的BUG</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-11-25T19:17:00+08:00" pubdate data-updated="true">Sun 2012-11-25 19:17</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>该Bug的问题本质，其实是不同系统classpath的分隔符不同。</p>

<h2>问题原由：</h2>

<p>搞了一天，简单的本地默认的hbase的环境搭不起，郁闷！</p>

<p>最后，原来是hbase脚本的bug！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Winseliu@WINSE ~/hbase-0.94.2
</span><span class='line'>$ bin/hbase classpath
</span><span class='line'>C:\cygwin\home\Winseliu\hbase-0.94.2\conf;C:\Java\jdk1.7.0_02\lib\tools.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\;C:\cygwin\home\Winseliu\hbase-0.94.2\hbase-0.94.2.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\hbase-0.94.2-tests.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\activation-1.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\asm-3.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\avro-1.5.3.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\avro-ipc-1.5.3.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-beanutils-1.7.0.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-beanutils-core-1.8.0.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-cli-1.2.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-codec-1.4.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-collections-3.2.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-configuration-1.6.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-digester-1.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-el-1.0.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-httpclient-3.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-io-2.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-lang-2.5.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-logging-1.1.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-math-2.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\commons-net-1.4.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\core-3.1.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\guava-11.0.2.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\hadoop-core-1.0.3.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\high-scale-lib-1.1.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\httpclient-4.1.2.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\httpcore-4.1.3.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jackson-core-asl-1.8.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jackson-jaxrs-1.8.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jackson-mapper-asl-1.8.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jackson-xc-1.8.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jamon-runtime-2.3.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jasper-compiler-5.5.23.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jasper-runtime-5.5.23.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jaxb-api-2.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jaxb-impl-2.2.3-1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jersey-core-1.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jersey-json-1.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jersey-server-1.8.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jettison-1.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jetty-6.1.26.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jetty-util-6.1.26.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jruby-complete-1.6.5.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jsp-2.1-6.1.14.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jsp-api-2.1-6.1.14.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\jsr305-1.3.9.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\junit-4.10-HBASE-1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\libthrift-0.8.0.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\log4j-1.2.16.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\metrics-core-2.1.2.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\netty-3.2.4.Final.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\protobuf-java-2.4.0a.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\servlet-api-2.5-6.1.14.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\slf4j-api-1.4.3.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\slf4j-log4j12-1.4.3.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\snappy-java-1.0.3.2.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\stax-api-1.0.1.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\velocity-1.7.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\xmlenc-0.52.jar;C:\cygwin\home\Winseliu\hbase-0.94.2\lib\zookeeper-3.4.3.jar:
</span></code></pre></td></tr></table></div></figure>


<p>环境变量<strong>最后应该是一个“;”而现在是“:”</strong></p>

<h2>解决问题</h2>

<p>修改如下(其实就是<strong>把cygwin路径转换的代码位置移动</strong>了一下)：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Winseliu@WINSE ~/hbase-0.94.2/bin
</span><span class='line'>$ diff -urN hbase-old hbase
</span><span class='line'>--- hbase-old   2012-10-08 04:04:16.000000000 +0800
</span><span class='line'>+++ hbase       2012-11-25 19:08:06.408506700 +0800
</span><span class='line'>@@ -199,13 +199,6 @@
</span><span class='line'>   HBASE_LOGFILE='hbase.log'
</span><span class='line'> fi
</span><span class='line'>
</span><span class='line'>-# cygwin path translation
</span><span class='line'>-if $cygwin; then
</span><span class='line'>-  CLASSPATH=`cygpath -p -w "$CLASSPATH"`
</span><span class='line'>-  HBASE_HOME=`cygpath -d "$HBASE_HOME"`
</span><span class='line'>-  HBASE_LOG_DIR=`cygpath -d "$HBASE_LOG_DIR"`
</span><span class='line'>-fi
</span><span class='line'>-
</span><span class='line'> function append_path() {
</span><span class='line'>   if [ -z "$1" ]; then
</span><span class='line'>     echo $2
</span><span class='line'>@@ -227,6 +220,13 @@
</span><span class='line'>   CLASSPATH=$(append_path "${CLASSPATH}" `${HADOOP_IN_PATH} classpath 2&gt;/dev/null`)
</span><span class='line'> fi
</span><span class='line'>
</span><span class='line'>+# cygwin path translation
</span><span class='line'>+if $cygwin; then
</span><span class='line'>+  CLASSPATH=`cygpath -p -w "$CLASSPATH"`
</span><span class='line'>+  HBASE_HOME=`cygpath -d "$HBASE_HOME"`
</span><span class='line'>+  HBASE_LOG_DIR=`cygpath -d "$HBASE_LOG_DIR"`
</span><span class='line'>+fi
</span><span class='line'>+
</span><span class='line'> if [ -d "${HBASE_HOME}/build/native" -o -d "${HBASE_HOME}/lib/native" ]; then
</span><span class='line'>   if [ -z $JAVA_PLATFORM ]; then
</span><span class='line'>     JAVA_PLATFORM=`CLASSPATH=${CLASSPATH} ${JAVA} org.apache.hadoop.util.PlatformName | sed -e "s/ /_/g"`
</span></code></pre></td></tr></table></div></figure>


<p>或者修改下<code>append_path</code>方法也可以。</p>

<hr />

<p><a href="http://winseclone.iteye.com/blog/1734818">【原文地址】</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/11/25/windows-install-pseudo-distributed-hadoop1/">Windows配置hadoop1的伪分布式环境</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-11-25T00:00:00+08:00" pubdate data-updated="true">Sun 2012-11-25 00:00</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>由于Hadoop的部分操作需要用到Linux的shell命令，所以在Windows下安装，需要安装一个Linux的运行时环境。然后，需要配置无密钥通信协议。配置完后，需要配置Hadoop的xml文件。</p>

<h1>安装Cygwin</h1>

<p><a href="http://cygwin.com/install.html">http://cygwin.com/install.html</a></p>

<h2>Cygwin中配置sshd</h2>

<p><a href="http://docs.oracle.com/cd/E24628_01/install.121/e22624/preinstall_req_cygwin_ssh.htm#CBHIAFGI">http://docs.oracle.com/cd/E24628_01/install.121/e22624/preinstall_req_cygwin_ssh.htm#CBHIAFGI</a></p>

<h2>伪分布式配置</h2>

<p>配置文档路径： hadoop-1.1.0/docs/single_node_setup.html</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bin/hadoop namenode -format
</span><span class='line'>
</span><span class='line'>bin/start-all.sh
</span><span class='line'>bin/stop-all.sh
</span><span class='line'>
</span><span class='line'>http://localhost:50030
</span><span class='line'>http://localhost:50070</span></code></pre></td></tr></table></div></figure>


<h2>遇到的问题及解决：</h2>

<p>在真正运行的时刻会遇到几个问题:</p>

<p>1、设置的路径并非使用cygwin linux的路径。</p>

<p>hadoop.tmp.dir在/tmp目录下面，理论上应该在C:\cygwin\tmp，但实际的路径确实C:\tmp</p>

<p>路径不同意，我们就设置自己的目录就可以了</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> &lt;property&gt;
</span><span class='line'>     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>     &lt;value&gt;/cygwin/home/Winseliu/cloud&lt;/value&gt;
</span><span class='line'> &lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<p>2、启动datanode和jobtracker，以及tasktacker时会有路径权限的问题</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2012-11-25 13:53:05,031 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:Winseliu cause:java.io.IOException: Failed to set permissions of path: C:\cygwin\home\Winseliu\hadoop-1.1.0\logs\history to 0755
</span><span class='line'>2012-11-25 13:53:05,032 FATAL org.apache.hadoop.mapred.JobTracker: java.io.IOException: Failed to set permissions of path: C:\cygwin\home\Winseliu\hadoop-1.1.0\logs\history to 0755
</span><span class='line'>        at org.apache.hadoop.fs.FileUtil.checkReturnValue(FileUtil.java:689)
</span><span class='line'>        at org.apache.hadoop.fs.FileUtil.setPermission(FileUtil.java:670)
</span><span class='line'>        at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:509)
</span><span class='line'>        at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:344)
</span><span class='line'>        at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:189)
</span><span class='line'>        at org.apache.hadoop.mapred.JobHistory.init(JobHistory.java:510)
</span><span class='line'>...
</span><span class='line'>...
</span><span class='line'>2012-11-25 13:53:04,389 INFO org.apache.hadoop.mapred.TaskTracker: Good mapred local directories are: /cygwin/home/Winseliu/cloud/mapred/local
</span><span class='line'>2012-11-25 13:53:04,396 ERROR org.apache.hadoop.mapred.TaskTracker: Can not start task tracker because java.io.IOException: Failed to set permissions of path: \cygwin\home\Winseliu\cloud\mapred\local\taskTracker to 0755
</span><span class='line'>        at org.apache.hadoop.fs.FileUtil.checkReturnValue(FileUtil.java:689)
</span><span class='line'>        at org.apache.hadoop.fs.FileUtil.setPermission(FileUtil.java:670)
</span></code></pre></td></tr></table></div></figure>


<p>权限问题，直接修改FileUtils的checkReturnValue()方法，替换hadoop-core-1.1.0.jar中的FileUtils.class文件</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>private static void checkReturnValue(boolean rv, File p, 
</span><span class='line'>                                 FsPermission permission
</span><span class='line'>                                 ) throws IOException {
</span><span class='line'>if (!rv) {
</span><span class='line'>  // FIXME
</span><span class='line'>      try {
</span><span class='line'>          throw new IOException("Failed to set permissions of path: " + p
</span><span class='line'>                  + " to " + String.format("%04o", permission.toShort()));
</span><span class='line'>      } catch (Exception e) {
</span><span class='line'>          e.printStackTrace();
</span><span class='line'>      }
</span><span class='line'>}
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>3、使用jps查不全真正执行的java进程，不知道那个进程启动或未启动</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Winseliu@WINSE ~/hadoop-1.1.0
</span><span class='line'>$ jps
</span><span class='line'>6364 NameNode
</span><span class='line'>7168 JobTracker
</span><span class='line'>2692 Jps
</span><span class='line'>
</span><span class='line'>Winseliu@WINSE ~/hadoop-1.1.0
</span><span class='line'>$ ps aux | grep java
</span><span class='line'>     7880       1    5544       7028  ?       1001 13:20:40 /cygdrive/c/Java/jdk1.7.0_02/bin/java
</span><span class='line'>     5968       1    7500       4592  ?       1001 13:20:36 /cygdrive/c/Java/jdk1.7.0_02/bin/java
</span><span class='line'>     5784       1     484       6364  pty0    1001 13:20:31 /cygdrive/c/Java/jdk1.7.0_02/bin/java
</span><span class='line'>     6732       1     484       7168  pty0    1001 13:20:38 /cygdrive/c/Java/jdk1.7.0_02/bin/java
</span><span class='line'>     7976       1    5716       5628  ?       1001 13:20:34 /cygdrive/c/Java/jdk1.7.0_02/bin/java
</span><span class='line'>     4492       0       0       4492  pty0    1001   Jan  1 /cygdrive/c/Java/jdk1.7.0_02/bin/java
</span></code></pre></td></tr></table></div></figure>


<p>直接再执行一次start-all.sh，如果会提示让你先stop就说明该进程已经启动了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Winseliu@WINSE ~
</span><span class='line'>$ cd hadoop-1.1.0/
</span><span class='line'>
</span><span class='line'>Winseliu@WINSE ~/hadoop-1.1.0
</span><span class='line'>$ bin/start-all.sh
</span><span class='line'>starting namenode, logging to /home/Winseliu/hadoop-1.1.0/libexec/../logs/hadoop-Winseliu-namenode-WINSE.out
</span><span class='line'>localhost: starting datanode, logging to /home/Winseliu/hadoop-1.1.0/libexec/../logs/hadoop-Winseliu-datanode-WINSE.out
</span><span class='line'>localhost: starting secondarynamenode, logging to /home/Winseliu/hadoop-1.1.0/libexec/../logs/hadoop-Winseliu-secondarynamenode-WINSE.out
</span><span class='line'>starting jobtracker, logging to /home/Winseliu/hadoop-1.1.0/libexec/../logs/hadoop-Winseliu-jobtracker-WINSE.out
</span><span class='line'>localhost: starting tasktracker, logging to /home/Winseliu/hadoop-1.1.0/libexec/../logs/hadoop-Winseliu-tasktracker-WINSE.out
</span><span class='line'>
</span><span class='line'>Winseliu@WINSE ~/hadoop-1.1.0
</span><span class='line'>$ bin/start-all.sh
</span><span class='line'>namenode running as process 2648\. Stop it first.
</span><span class='line'>localhost: datanode running as process 3512\. Stop it first.
</span><span class='line'>localhost: secondarynamenode running as process 2468\. Stop it first.
</span><span class='line'>jobtracker running as process 2388\. Stop it first.
</span><span class='line'>localhost: tasktracker running as process 860\. Stop it first.
</span><span class='line'>
</span><span class='line'>Winseliu@WINSE ~/hadoop-1.1.0
</span><span class='line'>$
</span></code></pre></td></tr></table></div></figure>


<hr />

<p><a href="http://winseclone.iteye.com/blog/1734737">【原文地址】</a></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/8">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/6">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://file.bmob.cn/M00/03/DE/wKhkA1PMkwyAH4pHAAHJu9ZKfYc646.png"><i class="fa fa-weixin">winseliu</i></a></p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/07/29/hadoop2-use-shortcircuit-local-reading/">Hadoop2 Use ShortCircuit Local Reading</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/29/safely-remove-datanode/">Hadoop安全的关闭datanode节点</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/21/build-openjdk/">Win编译32位openjdk</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/07/18/install-ganglia-on-redhat/">Install Ganglia on Redhat5+</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/21/upgrade-hive/">Upgrade Hive: 0.12.0 to 0.13.1</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (17) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (10) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (3) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (41)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'winseliu';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
