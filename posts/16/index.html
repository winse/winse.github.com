
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="官网配置资料 http://spark.apache.org/docs/latest/running-on-yarn.html
http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup
http &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winseliu.com/posts/16">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="http://cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winseliu.com" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
  <li><a href="https://yunpan.cn/cuYhpFBPgQYgT" >Books[5aee]</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/25/spark-sql-executors-dynamic-on-yarn/">SparkSQL-on-YARN的Executors池(动态)配置</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-25T07:14:53+00:00" pubdate data-updated="true">Fri 2016-03-25 07:14</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>官网配置资料</h2>

<ul>
<li><a href="http://spark.apache.org/docs/latest/running-on-yarn.html">http://spark.apache.org/docs/latest/running-on-yarn.html</a></li>
<li><a href="http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup">http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup</a></li>
<li><a href="http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation">http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation</a></li>
</ul>


<h2>实战</h2>

<h4>修改YARN配置，添加spark-yarn-shuffle.jar，同步配置和jar到nodemanager节点并重启。</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ vi etc/hadoop/yarn-site.xml 
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>&lt;value&gt;mapreduce_shuffle,spark_shuffle&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ cp ~/spark-1.6.0-bin-2.6.3/lib/spark-1.6.0-yarn-shuffle.jar share/hadoop/yarn/
</span><span class='line'>
</span><span class='line'>for h in `cat etc/hadoop/slaves` ; do rsync -az share $h:~/hadoop-2.6.3/ ; done 
</span><span class='line'>for h in `cat etc/hadoop/slaves` ; do rsync -az etc $h:~/hadoop-2.6.3/ ; done 
</span><span class='line'>
</span><span class='line'>rsync -vaz etc hadoop-master2:~/hadoop-2.6.3/
</span><span class='line'>rsync -vaz share hadoop-master2:~/hadoop-2.6.3/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-yarn.sh 
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-yarn.sh </span></code></pre></td></tr></table></div></figure>


<h4>原来已经部署了Hive-1.2.1（和spark-1.6.0的hive是匹配的），直接把hive-site.xml做一个软链到spark/conf下面：</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ cd conf/
</span><span class='line'>[hadoop@hadoop-master1 conf]$ ln -s ~/hive/conf/hive-site.xml 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ ll conf/hive-site.xml 
</span><span class='line'>lrwxrwxrwx. 1 hadoop hadoop 36 3月  25 11:30 conf/hive-site.xml -&gt; /home/hadoop/hive/conf/hive-site.xml</span></code></pre></td></tr></table></div></figure>


<p>注意：如果原来配置了tez，把hive-site.xml的 <strong>hive.execution.engine</strong> 配置注释掉。或者启动的时刻换引擎： <code>bin/spark-sql --master yarn-client --hiveconf hive.execution.engine=mr</code></p>

<h4>修改spark配置</h4>

<p>spark-defaults.conf</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 conf]$ cat spark-defaults.conf 
</span><span class='line'>spark.yarn.jar    hdfs:///spark/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar
</span><span class='line'>
</span><span class='line'>spark.dynamicAllocation.enabled    true
</span><span class='line'>spark.shuffle.service.enabled      true
</span><span class='line'>spark.dynamicAllocation.executorIdleTimeout    600s
</span><span class='line'>spark.dynamicAllocation.minExecutors    160
</span><span class='line'>spark.dynamicAllocation.maxExecutors    1800
</span><span class='line'>spark.dynamicAllocation.schedulerBacklogTimeout   5s
</span><span class='line'>
</span><span class='line'>spark.driver.maxResultSize   0
</span><span class='line'>
</span><span class='line'>spark.eventLog.enabled  true
</span><span class='line'>spark.eventLog.compress  true
</span><span class='line'>spark.eventLog.dir    hdfs:///spark-eventlogs
</span><span class='line'>spark.yarn.historyServer.address hadoop-master2:18080
</span><span class='line'>
</span><span class='line'>spark.serializer        org.apache.spark.serializer.KryoSerializer
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>spark.yarn.jar 配置后，spark启动后直接使用该文件作为executor的main-jar，不需要每次都上传一次spark.jar（每次都搞一下180M也不少资源了）</li>
<li>enabled 启用动态两个都配置必须设置为true</li>
<li>executorIdleTimeout 关闭不用executors需要等待的时间</li>
<li>schedulerBacklogTimeout 增加积压的任务时间来判断是否增加executors</li>
<li>minExecutors 至少存活的executors个数</li>
</ul>


<p>spark-env.sh环境变量</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 conf]$ cat spark-env.sh 
</span><span class='line'>SPARK_CLASSPATH=/home/hadoop/hive/lib/mysql-connector-java-5.1.21-bin.jar:$SPARK_CLASSPATH
</span><span class='line'>HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop
</span><span class='line'>SPARK_DRIVER_MEMORY=30g
</span><span class='line'>SPARK_PID_DIR=/home/hadoop/tmp/pids</span></code></pre></td></tr></table></div></figure>


<h4>启动</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 spark-1.6.0-bin-2.6.3]$ sbin/start-thriftserver.sh --master yarn-client
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 spark-1.6.0-bin-2.6.3]$ sbin/start-history-server.sh hdfs:///spark-eventlogs
</span><span class='line'>
</span><span class='line'># 不包括hadoop jars的情况下，自己编写脚本把hadoop的依赖包加入classpath
</span><span class='line'>[hadoop@hadoop-master2 spark-1.3.1-bin-hadoop2.6.3-without-hive]$ cat start-historyserver.sh 
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>bin=`dirname $0`
</span><span class='line'>cd $bin
</span><span class='line'>
</span><span class='line'>source $HADOOP_HOME/libexec/hadoop-config.sh
</span><span class='line'>
</span><span class='line'>export SPARK_PID_DIR=/home/hadoop/tmp/pids
</span><span class='line'>export SPARK_CLASSPATH=`hadoop classpath`
</span><span class='line'>
</span><span class='line'>export SPARK_PID_DIR=/home/hadoop/tmp/pids
</span><span class='line'>
</span><span class='line'># http://spark.apache.org/docs/latest/monitoring.html#viewing-after-the-fact
</span><span class='line'>export SPARK_HISTORY_OPTS="-Dspark.history.fs.update.interval=30s -Dspark.history.fs.cleaner.enabled=true -Dspark.history.fs.logDirectory=hdfs:///spark-eventlogs"
</span><span class='line'>sbin/start-history-server.sh 
</span></code></pre></td></tr></table></div></figure>


<p>收工。</p>

<p>整个过程就是：添加spark-shuffle到yarn，然后配置spark参数，最后就是重启任务（yarn/hiveserver）。</p>

<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/17/hadoop-memory-opts-and-args/">Hadoop内存环境变量和参数</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-17T06:09:26+00:00" pubdate data-updated="true">Thu 2016-03-17 06:09</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>问题：</h2>

<p><a href="https://www.zhihu.com/question/25498407">https://www.zhihu.com/question/25498407</a></p>

<p>问题是hadoop内存的配置，涉及两个方面：</p>

<ul>
<li>namenode/datanode/resourcemanager/nodemanager的HEAPSIZE环境变量</li>
<li>在配置文件/Configuration中影响MR运行的变量</li>
</ul>


<p>尽管搞hadoop有好一阵子了，对这些变量有个大概的了解，但没有真正的去弄懂他们的区别。乘着这个机会好好的整整（其实就是下载源码然后全文查找<sup>V</sup>^）。</p>

<h2>HEAPSIZE环境变量</h2>

<p>hadoop-env.sh配置文件hdfs和yarn脚本都会加载。hdfs是一脉相承使用 <strong>HADOOP_HEAPSIZE</strong> ，而yarn使用新的环境变量 <strong>YARN_HEAPSIZE</strong> 。</p>

<p>hadoop/hdfs/yarn命令最终会把HEAPSIZE的参数转换了 <strong>JAVA_HEAP_MAX</strong>，把它作为启动参数传递给Java。</p>

<ul>
<li>hadoop</li>
</ul>


<p>hadoop命令是把 <code>HADOOP_HEAPSIZE</code> 转换为 <code>JAVA_HEAP_MAX</code> ，调用路径：</p>

<p><code>hadoop -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>JAVA_HEAP_MAX=-Xmx1000m 
</span><span class='line'>
</span><span class='line'># check envvars which might override default args
</span><span class='line'>if [ "$HADOOP_HEAPSIZE" != "" ]; then
</span><span class='line'>  #echo "run with heapsize $HADOOP_HEAPSIZE"
</span><span class='line'>  JAVA_HEAP_MAX="-Xmx""$HADOOP_HEAPSIZE""m"
</span><span class='line'>  #echo $JAVA_HEAP_MAX
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<ul>
<li>hdfs</li>
</ul>


<p>hdfs其实就是从hadoop脚本里面分离出来的。调用路径：</p>

<p><code>hdfs -&gt; hdfs-config.sh -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<ul>
<li>yarn</li>
</ul>


<p>yarn也调用了hadoop-env.sh，但是设置内存的参数变成了 <strong>YARN_HEAPSIZE</strong> 。调用路径：</p>

<p><code>yarn -&gt; yarn-config.sh -&gt; hadoop-config.sh -&gt; hadoop-env.sh</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>JAVA_HEAP_MAX=-Xmx1000m 
</span><span class='line'>
</span><span class='line'># For setting YARN specific HEAP sizes please use this
</span><span class='line'># Parameter and set appropriately
</span><span class='line'># YARN_HEAPSIZE=1000
</span><span class='line'>
</span><span class='line'># check envvars which might override default args
</span><span class='line'>if [ "$YARN_HEAPSIZE" != "" ]; then
</span><span class='line'>  JAVA_HEAP_MAX="-Xmx""$YARN_HEAPSIZE""m"
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<ul>
<li>实例：</li>
</ul>


<p>配置hadoop参数的时刻，一般都是配置 <strong>hadoop-env.sh</strong> 如：<code>export HADOOP_HEAPSIZE=16000</code> 。查看相关进程命令有：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_resourcemanager -Xmx1000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_timelineserver -Xmx1000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_nodemanager -Xmx1000m 
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_journalnode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_namenode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_journalnode -Xmx16000m
</span><span class='line'>/usr/local/jdk1.7.0_17/bin/java -Dproc_datanode -Xmx16000m</span></code></pre></td></tr></table></div></figure>


<p>与hdfs有关的内存都修改成功了。而与yarn的还是默认的1g(堆)内存。</p>

<h2>MR配置文件参数</h2>

<p>分成两组，一种是直接设置数字(mb结束的属性)，一种是配置java虚拟机变量的-Xmx。</p>

<pre><code>* yarn.app.mapreduce.am.resource.mb、mapreduce.map.memory.mb、mapreduce.reduce.memory.mb
    用于调度计算内存，是不是还能分配任务（计算额度）
* yarn.app.mapreduce.am.command-opts、mapreduce.map.java.opts、mapreduce.reduce.java.opts
    程序实际启动使用的参数
</code></pre>

<p>一个是控制中枢，一个是实实在在的限制。</p>

<ul>
<li>官网文档的介绍：</li>
</ul>


<blockquote><ul>
<li>mapreduce.map.memory.mb 1024    The amount of memory to request from the scheduler for each map task.</li>
<li>mapreduce.reduce.memory.mb  1024    The amount of memory to request from the scheduler for each reduce task.</li>
<li>mapred.child.java.opts  -Xmx200m    Java opts for the task processes.</li>
</ul>
</blockquote>

<ul>
<li><p>下面用实践来验证效果：</p>

<ul>
<li>先搞一个很大大只有一个block的文件，把程序运行时间拖长一点</li>
<li>修改opts参数，查看效果</li>
<li>修改mb参数，查看效果</li>
</ul>
</li>
<li><p>实践一</p></li>
</ul>


<p>mapreduce.map.memory.mb设置为1000，而mapreduce.map.java.opts设置为1200m。程序照样跑的很欢！！</p>

<p>同时从map的 YarnChild 进程看出起实际作用的是 mapreduce.map.java.opts 参数。memory.mb用来计算节点是否有足够的内存来跑任务，以及用来计算整个集群的可用内存等。而java.opts则是用来限制真正任务的堆内存用量。</p>

<p><strong>注意</strong> ： 这里仅仅是用来测试，正式环境java.opts的内存应该小于memory.mb！！具体配置参考：<a href="http://blog.javachen.com/2015/06/05/yarn-memory-and-cpu-configuration.html">yarn-memory-and-cpu-configuration</a></p>

<p><img src="/images/blogs/hadoop-opts/yarn-opts-mb.jpg" alt="" /></p>

<ul>
<li>实践二</li>
</ul>


<p>map.memory.mb设置太大，导致调度失败！</p>

<p><img src="/images/blogs/hadoop-opts/yarn-mb-1.jpg" alt="" /></p>

<ul>
<li>实践三</li>
</ul>


<p>尽管实际才用不大于1.2G的内存，但是由于mapreduce.map.memory.mb设置为8G，整个集群显示已用内存18G（2 * 8g + 1 * 2g）。登录实际运行任务的机器，实际内存其实不多。</p>

<p><img src="/images/blogs/hadoop-opts/yarn-mb-2.jpg" alt="" />
<img src="/images/blogs/hadoop-opts/yarn-mb-3.jpg" alt="" /></p>

<p>reduce和am（appmaster）的参数类似。</p>

<p><img src="/images/blogs/hadoop-opts/yarn-appmaster-mb-1.jpg" alt="" />
<img src="/images/blogs/hadoop-opts/yarn-appmaster-mb-2.jpg" alt="" /></p>

<h2>mapred.child.java.opts参数</h2>

<p>这是一个过时的属性，当然你设置也能起效果(没有设置mapreduce.map.java.opts/mapreduce.reduce.java.opts)。相当于把MR的java.opts都设置了。</p>

<p><img src="/images/blogs/hadoop-opts/mapred-opts.jpg" alt="" /></p>

<p>获取map/reduce的opts中间会取 <strong>mapred.child.java.opts</strong> 的值。</p>

<p><img src="/images/blogs/hadoop-opts/mapred-opts-2.jpg" alt="" /></p>

<h2>admin-opts</h2>

<p>查找源码后，其实opts被分成两部分：admin和user。admin的写在前面，user在后面。admin设置的opts可以覆盖user设置的。应该是方便用于设置默认值吧。</p>

<h2>实例</h2>

<p>同时在一台很牛掰的机器上跑程序（分了yarn.nodemanager.resource.memory-mb 26G内存），但是总是只能一次跑一个任务，但还剩很多内存(20G)没有用啊！！初步怀疑是调度算法的问题。</p>

<p>查看了调度的日志，初始化的时刻会输出 <strong>scheduler.capacity.LeafQueue</strong> 的日志，打印了集群控制的一些参数。然后 同时找到一篇<a href="http://stackoverflow.com/questions/33465300/why-does-yarn-job-not-transition-to-running-state">http://stackoverflow.com/questions/33465300/why-does-yarn-job-not-transition-to-running-state</a> 说是调整 <strong>yarn.scheduler.capacity.maximum-am-resource-percent</strong> ，是用于控制appmaster最多可用的资源。</p>

<p>appmaster的默认内存是： <strong>yarn.app.mapreduce.am.resource.mb  1536</strong>（client设置有效）， <strong>yarn.scheduler.capacity.maximum-am-resource-percent 0.1</strong>。</p>

<p>跑第二job的时刻，第二个appmaster调度的时刻没有足够的内存（26G * 0.1 - 1.536 > 1.536），所以就跑不了两个job。</p>

<h2>CLIENT_OPTS</h2>

<p>一般 HADOOP 集群都会配套 HIVE，hive直接用 sql 来查询数据比mapreduce简单很多。启动hive是直接用 hadoop jar 来启动的。相对于一个客户端程序。控制hive内存的就是 HADOOP_CLIENT_OPTS 环境变量中的 -Xmx 。</p>

<p>所以要调整 hive 内存的使用，可以通过调整 HADOOP_CLIENT_OPTS 来控制。（当然理解这些环境变量，你就可以随心随欲的改）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hive]$ sh -x bin/hiveserver2 
</span><span class='line'>...
</span><span class='line'>++ exec /home/hadoop/hadoop/bin/hadoop jar /home/hadoop/hive/lib/hive-service-1.2.1.jar org.apache.hive.service.server.HiveServer2
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ grep -3  "HADOOP_CLIENT_OPTS" ~/hadoop/etc/hadoop/hadoop-env.sh
</span><span class='line'>export HADOOP_PORTMAP_OPTS="-Xmx512m $HADOOP_PORTMAP_OPTS"
</span><span class='line'>
</span><span class='line'># The following applies to multiple commands (fs, dfs, fsck, distcp etc)
</span><span class='line'>export HADOOP_CLIENT_OPTS="-Xmx128m $HADOOP_CLIENT_OPTS"
</span><span class='line'>#HADOOP_JAVA_PLATFORM_OPTS="-XX:-UsePerfData $HADOOP_JAVA_PLATFORM_OPTS"
</span><span class='line'>
</span><span class='line'># On secure datanodes, user to run the datanode as after dropping privileges.
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ jinfo 10249
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>VM Flags:
</span><span class='line'>
</span><span class='line'>-Xmx256m -Djava.net.preferIPv4Stack=true -Dhadoop.log.dir=/home/hadoop/hadoop-2.6.3/logs -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/hadoop/hadoop-2.6.3 -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,console -Djava.library.path=/home/hadoop/hadoop-2.6.3/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx128m -Dhadoop.security.logger=INFO,NullAppender
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ jmap -heap 10249
</span><span class='line'>...
</span><span class='line'>Heap Configuration:
</span><span class='line'>   MinHeapFreeRatio = 40
</span><span class='line'>   MaxHeapFreeRatio = 70
</span><span class='line'>   MaxHeapSize      = 134217728 (128.0MB)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/11/install-and-config-openvpn/">安装配置OpenVPN</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2016-03-11T01:46:49+00:00" pubdate data-updated="true">Fri 2016-03-11 01:46</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>由于测试环境搭建不在同一个网络，平时查看hadoop集群状态、提交任务都可以通过hadoop-master的外网来操作。但是要读写kafka，需要直接连通所有的节点，全部映射端口太麻烦。一开始想到了VLAN(虚拟局域网），远远超出能力范围。最后通过搭架VPN来实现与测试环境的透明访问。</p>

<h2>使用集成版本</h2>

<p>参考 <a href="https://linux.cn/article-4733-1.html">https://linux.cn/article-4733-1.html</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># download https://openvpn.net/index.php/access-server/download-openvpn-as-sw.html
</span><span class='line'>
</span><span class='line'># 安装
</span><span class='line'>[root@cu2 ~]# rpm -ivh openvpn-as-2.0.25-CentOS6.x86_64.rpm 
</span><span class='line'>Preparing...                ########################################### [100%]
</span><span class='line'>   1:openvpn-as             ########################################### [100%]
</span><span class='line'>The Access Server has been successfully installed in /usr/local/openvpn_as
</span><span class='line'>Configuration log file has been written to /usr/local/openvpn_as/init.log
</span><span class='line'>Please enter "passwd openvpn" to set the initial
</span><span class='line'>administrative password, then login as "openvpn" to continue
</span><span class='line'>configuration here: https://192.168.0.214:943/admin
</span><span class='line'>To reconfigure manually, use the /usr/local/openvpn_as/bin/ovpn-init tool.
</span><span class='line'>
</span><span class='line'>Access Server web UIs are available here:
</span><span class='line'>Admin  UI: https://192.168.0.214:943/admin
</span><span class='line'>Client UI: https://192.168.0.214:943/
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# passwd openvpn
</span><span class='line'>
</span><span class='line'>然后通过web admin进行配置。如主机的信息、hostname以及监听绑定的IP</span></code></pre></td></tr></table></div></figure>


<p>配置好以后，本地通过网页下载client程序安装。连接配置后：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>C:\Users\winse&gt;tracert  cu3
</span><span class='line'>
</span><span class='line'>通过最多 30 个跃点跟踪
</span><span class='line'>到 cu3 [192.168.0.148] 的路由:
</span><span class='line'>
</span><span class='line'>  1     2 ms     2 ms     2 ms  172.27.232.1
</span><span class='line'>  2     2 ms     2 ms     2 ms  cu3 [192.168.0.148]
</span><span class='line'>
</span><span class='line'>跟踪完成。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>C:\Users\winse&gt;route print
</span><span class='line'>===========================================================================
</span><span class='line'>IPv4 路由表
</span><span class='line'>===========================================================================
</span><span class='line'>活动路由:
</span><span class='line'>网络目标        网络掩码          网关       接口   跃点数
</span><span class='line'>          0.0.0.0          0.0.0.0      192.168.1.1    192.168.1.102     20
</span><span class='line'>          0.0.0.0        128.0.0.0     172.27.232.1     172.27.232.2     20
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p><a href="http://designmylife.blog.163.com/blog/static/2067142542013527101659960/">http://designmylife.blog.163.com/blog/static/2067142542013527101659960/</a></p>

<p>路由匹配按最大(最亲)方式匹配。上面路由会先匹配mask为 <code>128.0.0.0</code> 的路由。最终把所有的流量经由VPN出去。</p>

<p>通过 <strong>Access Server</strong> 安装简单，配置通过网页来弄，和网上资料的都匹配不上，还有用户数量的限制，囧。</p>

<h2>编译源码安装</h2>

<ul>
<li>服务端安装配置</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 openvpn-2.3.10]# yum install libpam* (centos7是pam*)
</span><span class='line'>[root@cu2 openvpn-2.3.10]# yum install pam-devel.x86_64
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring lzo-2.06.tar.gz...
</span><span class='line'>  100%     569 KB     569 KB/sec    00:00:01       0 Errors  
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# tar zxvf lzo-2.06.tar.gz 
</span><span class='line'>[root@cu2 ~]# cd lzo-2.06
</span><span class='line'>[root@cu2 lzo-2.06]# ./configure 
</span><span class='line'>[root@cu2 lzo-2.06]# make &&  make install
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# ./configure --prefix=/usr/local/openvpn 
</span><span class='line'>[root@cu2 openvpn-2.3.10]# make && make install
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# /usr/local/openvpn/sbin/openvpn --version
</span><span class='line'>OpenVPN 2.3.10 x86_64-unknown-linux-gnu [SSL (OpenSSL)] [EPOLL] [MH] [IPv6] built on Mar  9 2016
</span><span class='line'>
</span><span class='line'>https://github.com/OpenVPN/easy-rsa/releases
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa  help
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa init-pki
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]#  ./easyrsa build-ca
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa gen-req openvpn nopass
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa sign client openvpn
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa gen-req eshore-cu nopass
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# ./easyrsa sign server eshore-cu
</span><span class='line'>
</span><span class='line'>commonName随便取，但是不能重！
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# tree pki/
</span><span class='line'>pki/
</span><span class='line'>├── ca.crt
</span><span class='line'>├── certs_by_serial
</span><span class='line'>│   ├── 01.pem
</span><span class='line'>│   └── 02.pem
</span><span class='line'>├── index.txt
</span><span class='line'>├── index.txt.attr
</span><span class='line'>├── index.txt.attr.old
</span><span class='line'>├── index.txt.old
</span><span class='line'>├── issued
</span><span class='line'>│   ├── eshore-cu.crt
</span><span class='line'>│   └── openvpn.crt
</span><span class='line'>├── private
</span><span class='line'>│   ├── ca.key
</span><span class='line'>│   ├── eshore-cu.key
</span><span class='line'>│   └── openvpn.key
</span><span class='line'>├── reqs
</span><span class='line'>│   ├── eshore-cu.req
</span><span class='line'>│   └── openvpn.req
</span><span class='line'>├── serial
</span><span class='line'>└── serial.old
</span><span class='line'>
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]#  ./easyrsa gen-dh
</span><span class='line'>[root@cu2 EasyRSA-3.0.1]# cd pki
</span><span class='line'>[root@cu2 pki]# cp ca.crt dh.pem issued/eshore-cu.crt private/eshore-cu.key /etc/openvpn/ 
</span><span class='line'>
</span><span class='line'>[root@cu2 openvpn-2.3.10]# cp sample/sample-config-files/server.conf /etc/openvpn/
</span><span class='line'>
</span><span class='line'>  proto tcp
</span><span class='line'>  cert eshore-cu.crt
</span><span class='line'>  key eshore-cu.key 
</span><span class='line'>  dh dh.pem
</span><span class='line'>  # 在客户端额外添加这条路由到VPN
</span><span class='line'>  push "route 192.168.0.0 255.255.255.0"
</span><span class='line'>  # 和AS一样，会添加0.0.0.0到VPN的路由。所有请求默认走VPN https://www.digitalocean.com/community/tutorials/how-to-setup-and-configure-an-openvpn-server-on-centos-7
</span><span class='line'>  ;push "redirect-gateway def1 bypass-dhcp"
</span><span class='line'>  # 内网特定的域名解析地址
</span><span class='line'>  ;push "dhcp-option DNS 10.16.6.88"
</span><span class='line'>  #Enable multiple client to connect with same key
</span><span class='line'>  duplicate-cn
</span><span class='line'>  user nobody
</span><span class='line'>  group nobody
</span><span class='line'>
</span><span class='line'>[root@cu2 pki]# cd /etc/openvpn/
</span><span class='line'>[root@cu2 openvpn]# /usr/local/openvpn/sbin/openvpn --config /etc/openvpn/server.conf --启动完后Ctrl+C
</span><span class='line'>[root@cu2 openvpn]# /usr/local/openvpn/sbin/openvpn --daemon --config server.conf </span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装客户端：</li>
</ul>


<p><a href="https://openvpn.net/index.php/open-source/downloads.html">https://openvpn.net/index.php/open-source/downloads.html</a> 下载安装 <strong>对应</strong> 的版本，<strong> 客户端的版本最好最好与服务端一致！！</strong> 不同版本默认配置不同。</p>

<p>拷贝sample-config/client.ovpn和服务端的ca.crt、openvpn.crt、openvpn.key到config目录下面。</p>

<p>修改client.ovpn:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proto tcp
</span><span class='line'>remote webcu2 1194
</span><span class='line'>cert openvpn.crt
</span><span class='line'>key openvpn.key</span></code></pre></td></tr></table></div></figure>


<p>然后启动 <strong>OpenVPN GUI</strong> ，右键connect就行了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ route print
</span><span class='line'>...
</span><span class='line'>IPv4 路由表
</span><span class='line'>===========================================================================
</span><span class='line'>活动路由:
</span><span class='line'>网络目标        网络掩码          网关       接口   跃点数
</span><span class='line'>          0.0.0.0          0.0.0.0      192.168.1.1    192.168.1.102     20
</span><span class='line'>         10.8.0.1  255.255.255.255         10.8.0.5         10.8.0.6     20
</span><span class='line'>         10.8.0.4  255.255.255.252            在链路上          10.8.0.6    276
</span><span class='line'>         10.8.0.6  255.255.255.255            在链路上          10.8.0.6    276
</span><span class='line'>         10.8.0.7  255.255.255.255            在链路上          10.8.0.6    276
</span><span class='line'>      192.168.0.0    255.255.255.0         10.8.0.5         10.8.0.6     20
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h2>问题</h2>

<ul>
<li>连接到VPN服务端的机器是没有问题，但是不能访问该机器的应用（端口不同）</li>
</ul>


<p>被防火墙限制了，在服务端把10.8.0.0/24加入到防火墙允许。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -A INPUT -s 10.8.0.0/24 -j ACCEPT  # 反正能访问OpenVPN的端口即可</span></code></pre></td></tr></table></div></figure>


<ul>
<li>不能访问服务端其他机器</li>
</ul>


<p>在iptables上增加转发</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE</span></code></pre></td></tr></table></div></figure>


<p>centos7 firewall:(注：在centos7上面一样可以用上面的iptables命令！！ <a href="https://www.centos.org/forums/viewtopic.php?t=53819">https://www.centos.org/forums/viewtopic.php?t=53819</a>)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ firewall-cmd --permanent --add-masquerade 
</span><span class='line'>cat zones/public.xml
</span><span class='line'>$ firewall-cmd --permanent --direct --add-rule ipv4 nat POSTROUTING 0 -o eth0 -j MASQUERADE 
</span><span class='line'>查看写入的内容： cat /etc/firewalld/direct.xml
</span><span class='line'>$ firewall-cmd --reload
</span><span class='line'>https://www.server-world.info/en/note?os=CentOS_7&p=firewalld&f=2
</span><span class='line'>http://www.mjhall.org/centos7-firewalld-nat-router/
</span><span class='line'>https://www.centos.org/forums/viewtopic.php?t=53819
</span><span class='line'>
</span><span class='line'>#如果防火墙默认是reject，需要增加
</span><span class='line'># #开放主机IP firewall-cmd --permanent --zone=trusted --add-source=192.168.2.0/24
</span><span class='line'>[root@bigdata-dev ~]# firewall-cmd --zone=public --add-port=1194/tcp --permanent
</span><span class='line'>success
</span><span class='line'>[root@bigdata-dev ~]# firewall-cmd --reload
</span><span class='line'>success</span></code></pre></td></tr></table></div></figure>


<p>centos7 iptables:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install iptables-services -y
</span><span class='line'>systemctl mask firewalld
</span><span class='line'>systemctl enable iptables
</span><span class='line'>systemctl stop firewalld
</span><span class='line'>systemctl start iptables
</span><span class='line'>iptables --flush</span></code></pre></td></tr></table></div></figure>


<ul>
<li>centos7 firewall <a href="http://www.centoscn.com/CentOS/Intermediate/2016/0602/7348.html">http://www.centoscn.com/CentOS/Intermediate/2016/0602/7348.html</a></li>
</ul>


<p>查看iptables规则：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iptables -nL -t nat</span></code></pre></td></tr></table></div></figure>


<p>测试下:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ping cu3
</span><span class='line'>
</span><span class='line'>正在 Ping cu3 [192.168.0.148] 具有 32 字节的数据:
</span><span class='line'>来自 192.168.0.148 的回复: 字节=32 时间=5ms TTL=63
</span><span class='line'>来自 192.168.0.148 的回复: 字节=32 时间=5ms TTL=63</span></code></pre></td></tr></table></div></figure>


<p>其他（参数，未实践，记录下来）</p>

<blockquote><p>必须在服务器端的内网网关上将到10.8.0.0/24网段的路由指向到openvpn服务器，不然从服务器端内网其他机器根本找不到去往10.8.0.0/24网段的路由。这里又分两种情况，一种是服务端有内网网关设备的（按如上说法即可）；一种是服务端内网没有网关设备，即服务器通过交换机相连，相互通讯靠广播的情况。我的就是这种情况。需要在想访问的server上增加到10.8.0.0/24的路由，如下</p>

<p>route add -net 10.8.0.0/24 gw 192.168.1.211    #1.211为openvpn服务器的内网IP</p>

<p>Make sure that you&rsquo;ve enabled IP and TUN/TAP forwarding on the OpenVPN server machine.
确定开启了转发功能，然后在openvpn服务器Iptables添加如下两条规则</p>

<p>iptables -A FORWARD -i tun0 -s 10.8.0.0/24 -j ACCEPT    #简单说，允许数据从客户端到后端server
iptables -A FORWARD -i em2 -d 10.8.0.0/24 -j ACCEPT    #允许数据从后端server到客户端</p></blockquote>

<h2>参考</h2>

<ul>
<li><a href="https://openvpn.net/index.php/open-source/documentation/howto.html">https://openvpn.net/index.php/open-source/documentation/howto.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html">http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html</a></li>
<li><a href="http://www.linuxquestions.org/questions/linux-networking-3/openvpn-conencts-but-can%27t-ping-servers-on-the-other-network-660610/">http://www.linuxquestions.org/questions/linux-networking-3/openvpn-conencts-but-can%27t-ping-servers-on-the-other-network-660610/</a></li>
<li><a href="http://www.ilanni.com/?p=9877">http://www.ilanni.com/?p=9877</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html">http://blog.sina.com.cn/s/blog_86fbdd650101a0ax.html</a></li>
<li><a href="http://kaifly.blog.51cto.com/3209616/1367591">http://kaifly.blog.51cto.com/3209616/1367591</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/07/rsync-vs-scp/">Rsync与scp优势</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-07T09:05:45+00:00" pubdate data-updated="true">Mon 2016-03-07 09:05</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>今天在做flume写kafka数据时，数据从其他目录cp拷贝过来，flume采集程序报错 <strong>程序采集的时刻文件发生了改变</strong>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>07 Mar 2016 16:46:05,535 ERROR [pool-3-thread-1] (org.apache.flume.source.SpoolDirectorySource$SpoolDirectoryRunnable.run:256)  - FATAL: Spool Directory source s1: { spoolDir: /home/hadoop/flume/data/ }: Uncaught exception in SpoolDirectorySource thread. Restart or reconfigure Flume to continue processing.
</span><span class='line'>java.lang.IllegalStateException: File has changed size since being read: /home/hadoop/flume/data/hbase-hadoop-master-cu2.log
</span><span class='line'>        at org.apache.flume.client.avro.ReliableSpoolingFileEventReader.retireCurrentFile(ReliableSpoolingFileEventReader.java:326)
</span><span class='line'>        at org.apache.flume.client.avro.ReliableSpoolingFileEventReader.readEvents(ReliableSpoolingFileEventReader.java:259)</span></code></pre></td></tr></table></div></figure>


<p>联想到scp和rsync，好像rsync是有重命名这样的步骤的。网上也有很多对比这个两个工具的资料。</p>

<ul>
<li><a href="http://stackoverflow.com/questions/20244585/how-does-scp-differ-from-rsync">http://stackoverflow.com/questions/20244585/how-does-scp-differ-from-rsync</a></li>
<li><p><a href="http://superuser.com/questions/193952/why-is-rsync-avz-faster-than-scp-r">http://superuser.com/questions/193952/why-is-rsync-avz-faster-than-scp-r</a></p></li>
<li><p>rsync可以增量复制，并且只复制内容不同的部分</p></li>
<li>rsync可以压缩，通过有断点续传 <code>-P</code></li>
<li>rsync有各种参数： exclude等</li>
<li>SCP也可以增加压缩参数： <code>scp -C -o 'CompressionLevel 9' -o 'IPQoS throughput'  -c arcfour machine:file .</code></li>
<li>rsync会先写临时文件，复制完成后再重命名！</li>
</ul>


<p>这里只关注最后一点，对于按照名称来采集的程序非常关键！下面使用inotify监控目录的操作，在进行scp和rsync时发生的操作：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 test]$ scp -r source target/
</span><span class='line'>[hadoop@cu2 test]$ rm target/source/1234
</span><span class='line'>[hadoop@cu2 test]$ rsync -vaz source target/
</span><span class='line'>sending incremental file list
</span><span class='line'>source/
</span><span class='line'>source/1234
</span><span class='line'>
</span><span class='line'>sent 141 bytes  received 35 bytes  352.00 bytes/sec
</span><span class='line'>total size is 34  speedup is 0.19</span></code></pre></td></tr></table></div></figure>


<p>对应的inotify的输出为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 test]$ inotifywait -m target/source/ # yum install -y inotify*
</span><span class='line'>Setting up watches.
</span><span class='line'>Watches established.
</span><span class='line'>target/source/ CREATE 1234
</span><span class='line'>target/source/ OPEN 1234
</span><span class='line'>target/source/ MODIFY 1234
</span><span class='line'>target/source/ CLOSE_WRITE,CLOSE 1234
</span><span class='line'>
</span><span class='line'>target/source/ DELETE 1234
</span><span class='line'>
</span><span class='line'>target/source/ ATTRIB,ISDIR 
</span><span class='line'>target/source/ CREATE .1234.ARUg56
</span><span class='line'>target/source/ OPEN .1234.ARUg56
</span><span class='line'>target/source/ ATTRIB .1234.ARUg56
</span><span class='line'>target/source/ MODIFY .1234.ARUg56
</span><span class='line'>target/source/ CLOSE_WRITE,CLOSE .1234.ARUg56
</span><span class='line'>target/source/ ATTRIB .1234.ARUg56
</span><span class='line'>target/source/ MOVED_FROM .1234.ARUg56
</span><span class='line'>target/source/ MOVED_TO 1234
</span></code></pre></td></tr></table></div></figure>


<p>rsync会先写把内容复制到一个临时文件，复制完成后，再重命名为正式的名称。</p>

<p><strong>在生产环境尽量使用rsync来进行文件(夹)的复制/同步操作，即快键有安全。</strong></p>

<p>当然还有奇葩的快速删除海量文件夹的方式也用的是rsync：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rsync --delete-before -d /data/blank/ /var/spool/clientmqueue/ 
</span><span class='line'>
</span><span class='line'>rsync --delete-before -a -H -v --progress --stats /tmp/test/ log/</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://logo32.iteye.com/blog/1564727">http://logo32.iteye.com/blog/1564727</a></li>
<li><a href="http://www.ha97.com/4107.html">http://www.ha97.com/4107.html</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/25/ganglia-web-ui-views/">Ganglia页自定义视图</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-02-25T12:29:11+00:00" pubdate data-updated="true">Thu 2016-02-25 12:29</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>官网自带的页面指标太拥挤，同一个组各指标的顺序不能指定(默认好像是按名称排序的)不便于观察。通过页面的Views页签可以查看自定的图标。</p>

<p>在conf文件夹(由conf_default.php中views_dir指定)下面建立文件名以 <strong>view</strong> 开头的json文件。通过Views还可以聚合多个指标，在一个图中查看整体的变化趋势。配置聚合视图前可以先在 <strong>Aggregate Graphs</strong> 弄出来先瞧一瞧。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# cd /var/www/html/ganglia/
</span><span class='line'># 查看view放置的位置
</span><span class='line'>[root@cu2 ganglia]# grep views_dir conf_default.php 
</span><span class='line'>$conf['views_dir'] = $conf['gweb_confdir'] . '/conf';
</span><span class='line'>
</span><span class='line'># view配置目录
</span><span class='line'>[root@cu2 conf]$ ll
</span><span class='line'>......
</span><span class='line'>-rw-rw-r-- 1 apache apache    58 Oct  2 04:38 view_default.json
</span><span class='line'>-rw-r--r-- 1 root   root    2344 Feb 25 20:12 view_qbevery.json
</span><span class='line'>-rw-r--r-- 1 root   root     241 Feb 25 18:59 view_qb.json
</span><span class='line'>
</span><span class='line'>[root@cu2 conf]# cat view_qb.json 
</span><span class='line'>{
</span><span class='line'>"default_size" : "xlarge",
</span><span class='line'>"view_name": "qb",
</span><span class='line'>"items": [
</span><span class='line'>{
</span><span class='line'>"aggregate_graph": "true",
</span><span class='line'>"graph_type": "stack", 
</span><span class='line'>"host_regex":  [ { "regex" : "cu2" } ], 
</span><span class='line'>"metric_regex": [ { "regex":  "qb_.*" } ],
</span><span class='line'>"title": "qb"
</span><span class='line'>}
</span><span class='line'>],
</span><span class='line'>"view_type": "standard"
</span><span class='line'>}
</span><span class='line'>[root@cu2 conf]# cat view_qbevery.json 
</span><span class='line'>{
</span><span class='line'>"default_size" : "medium",
</span><span class='line'>"view_name": "qbevery",
</span><span class='line'>"items": [
</span><span class='line'>{ "hostname":"cu2","metric":"qb_520k_53d_9.82_120807"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_500k_98d_7.81_116763"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_400k_91d_7.67_116762"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_350k_42d_9.08_120802"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_350k_83d_7.40_116761"},
</span><span class='line'>{ "hostname":"cu2","metric":"qb_300k_78d_7.12_116760"}
</span><span class='line'>],
</span><span class='line'>"view_type": "standard"
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="https://github.com/ganglia/ganglia-web/wiki#Views">https://github.com/ganglia/ganglia-web/wiki#Views</a></li>
<li><a href="https://gist.github.com/mnikhil-git/4708591">https://gist.github.com/mnikhil-git/4708591</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/17">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/15">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2016/04/23/hadoop-guide-catalog/">[整理] Hadoop入门</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/03/28/hive-on-spark/">Hive on Spark</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/08/24/manual-install-supervisor/">Supervisor安装配置</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/10/16/spark-build-and-configuration/">编译/搭建Spark环境</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/08/25/step-by-step-found-java-oom-error/">查找逐步定位Java程序OOM的异常实践</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/29/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/26/start-redis/">[读读书]Redis入门指南</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/17/jekyll-edit-link-in-web-page/">Jekyll页面添加编辑按钮</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/09/20/docker-manual-make-connect-each-other/">两台主机的docker通过route互联互通</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/09/19/os-install-via-usb/">使用U盘安装Centos7</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/09/18/redmine-deploy-and-install-plugins/">Redmine部署以及插件安装</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/09/17/docker-compose-hello/">Docker Compose入门</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/09/02/zookeeper-acl/">Zookeeper ACL</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/08/30/jenkins-build-via-shell/">命令行调用Jenkins2.63打包</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/08/22/vagrant-create-your-own-box/">Vagrant创建自定义的BOX</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/08/13/kubeadm-install-k8s-on-centos7-with-resources/">Kubeadm部署k8s(资源已有)</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/bigdata/'>bigdata</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (13) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/flume/'>flume</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (44) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jenkins/'>jenkins</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kubeadm/'>kubeadm</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (53) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/vagrant/'>vagrant</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/zookeeper/'>zookeeper</a> (1) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (188)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Softs, I&#8217;m using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253461959'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1253461959%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  

<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"winseliu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->










</body>
</html>
