
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="Set 1
2
3
4
5
6
7
8
9
10
Set&lt;BlockedInfo&gt; diffs = new HashSet&lt;&gt;();
diffs.addAll(oldBlockedList);
diffs.addAll(newBlockedList);
Iterator& &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winseliu.com/posts/16">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="http://cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winseliu.com" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
  <li><a href="https://yunpan.cn/cuYhpFBPgQYgT" >Books[5aee]</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/19/hole/">坑</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2016-01-19T08:53:29+00:00" pubdate data-updated="true">Tue 2016-01-19 08:53</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Set</h2>

<p><img src="/images/blogs/hole-set-add-diff.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Set&lt;BlockedInfo&gt; diffs = new HashSet&lt;&gt;();
</span><span class='line'>diffs.addAll(oldBlockedList);
</span><span class='line'>diffs.addAll(newBlockedList);
</span><span class='line'>Iterator&lt;BlockedInfo&gt; iterator = diffs.iterator();
</span><span class='line'>while (iterator.hasNext()) {
</span><span class='line'>  BlockedInfo i = iterator.next();
</span><span class='line'>  if (oldBlockedList.contains(i) && newBlockedList.contains(i)) {
</span><span class='line'>      iterator.remove();
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>第二段代码希望找出前后两个list的差别，即XOR的效果。但是。。。为什么呢？想一想。</p>

<p>用guava库一行代码搞定：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Sets.difference(Sets.union(oldBlockedList, newBlockedList), Sets.intersection(oldBlockedList, newBlockedList))</span></code></pre></td></tr></table></div></figure>


<h2>hive建表</h2>

<p>由于fs.defaultFS和hive.metastore.warehouse.dir对不上，建表后不能删除。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;hdfs://zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;hdfs://zfcluster:8020/hive/warehousedir&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<p>删除表报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; drop table es_t_house_monitor2;
</span><span class='line'>FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:java.lang.IllegalArgumentException: Wrong FS: hdfs://zfcluster:8020/hive/warehousedir/es_t_house_monitor2, expected: hdfs://zfcluster)</span></code></pre></td></tr></table></div></figure>


<p>建错了，只能先改！然后把hive.metastore.warehouse.dir和fs.defaultFS调成一致。</p>

<p>修改hive持久化（数据库）的表sds，找到location是该路径的改掉。然后就可以drop表了。</p>

<h2>nginx rewrite中大括号</h2>

<p>由于大括号用于一段规则的结束开始，所以直接在rewrite写 {} 是报错的。需要把包括{}大括号的规则用双引号括起来。</p>

<p>注: 对花括号( { 和 } )来说, 他们既能用在重定向的正则表达式里，也是用在配置文件里分割代码块, 为了避免冲突, 正则表达式里带花括号的话，应该用双引号（或者单引号）包围。</p>

<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/12/tez-ui-config-and-run/">配置TEZ-UI</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-12T12:28:35+00:00" pubdate data-updated="true">Tue 2016-01-12 12:28</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>tez-ui很早就出来了，荒废了很多时间。今天才把它配置出来，效果挺不错的，和spark-web差不多。</p>

<p>记录了在hive-1.2.1上配置tez-0.7.0过程，配置运行hadoop2.6.3-timeline以及为tez添加tez-ui特性的步骤。</p>

<h2>编译tez-0.7.0</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ mvn package -Dhadoop.version=2.6.3 -DskipTests
</span><span class='line'>
</span><span class='line'>[INFO] Reactor Summary:
</span><span class='line'>[INFO] 
</span><span class='line'>[INFO] tez ................................................ SUCCESS [  0.831 s]
</span><span class='line'>[INFO] tez-api ............................................ SUCCESS [  6.580 s]
</span><span class='line'>[INFO] tez-common ......................................... SUCCESS [  0.124 s]
</span><span class='line'>[INFO] tez-runtime-internals .............................. SUCCESS [  0.676 s]
</span><span class='line'>[INFO] tez-runtime-library ................................ SUCCESS [  1.378 s]
</span><span class='line'>[INFO] tez-mapreduce ...................................... SUCCESS [  0.989 s]
</span><span class='line'>[INFO] tez-examples ....................................... SUCCESS [  0.105 s]
</span><span class='line'>[INFO] tez-dag ............................................ SUCCESS [  2.391 s]
</span><span class='line'>[INFO] tez-tests .......................................... SUCCESS [  0.187 s]
</span><span class='line'>[INFO] tez-ui ............................................. SUCCESS [02:23 min]
</span><span class='line'>[INFO] tez-plugins ........................................ SUCCESS [  0.017 s]
</span><span class='line'>[INFO] tez-yarn-timeline-history .......................... SUCCESS [  0.595 s]
</span><span class='line'>[INFO] tez-yarn-timeline-history-with-acls ................ SUCCESS [  0.316 s]
</span><span class='line'>[INFO] tez-mbeans-resource-calculator ..................... SUCCESS [  0.189 s]
</span><span class='line'>[INFO] tez-tools .......................................... SUCCESS [  0.017 s]
</span><span class='line'>[INFO] tez-dist ........................................... SUCCESS [ 16.554 s]
</span><span class='line'>[INFO] Tez ................................................ SUCCESS [  0.015 s]
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] BUILD SUCCESS
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] Total time: 02:55 min
</span><span class='line'>[INFO] Finished at: 2016-01-12T19:08:50+08:00
</span><span class='line'>[INFO] Final Memory: 63M/756M
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span></code></pre></td></tr></table></div></figure>


<h2>tez嵌入到hive</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 上传tez程序到hdfs
</span><span class='line'>[hadoop@cu2 ~]$ cd sources/apache-tez-0.7.0-src/tez-dist/target/
</span><span class='line'>[hadoop@cu2 target]$ hadoop fs -mkdir -p /apps/tez-0.7.0
</span><span class='line'>[hadoop@cu2 target]$ hadoop fs -put tez-0.7.0.tar.gz /apps/tez-0.7.0/
</span><span class='line'>
</span><span class='line'>// TEZ_CONF_DIR = HADOOP_CONF_DIR
</span><span class='line'>[hadoop@cu2 ~]$ cd hadoop-2.6.3/etc/hadoop/
</span><span class='line'>[hadoop@cu2 hadoop]$ vi tez-site.xml
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>&lt;value&gt;${fs.defaultFS}/apps/tez-0.7.0/tez-0.7.0.tar.gz&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>// 本地tez jars加入HADOOP_CLASSPATH
</span><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ cd tez-dist/target/
</span><span class='line'>archive-tmp/              maven-archiver/           tez-0.7.0/                tez-0.7.0-minimal.tar.gz  tez-0.7.0.tar.gz          tez-dist-0.7.0-tests.jar  
</span><span class='line'>[hadoop@cu2 apache-tez-0.7.0-src]$ cd tez-dist/target/
</span><span class='line'>[hadoop@cu2 target]$ mv tez-0.7.0 ~/
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ vi apache-hive-1.2.1-bin/conf/hive-env.sh
</span><span class='line'>
</span><span class='line'>// 多个jline版本 http://stackoverflow.com/questions/28997441/hive-startup-error-terminal-initialization-failed-falling-back-to-unsupporte
</span><span class='line'>export HADOOP_USER_CLASSPATH_FIRST=true
</span><span class='line'>export TEZ_HOME=/home/hadoop/tez-0.7.0
</span><span class='line'>export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/*:$TEZ_HOME/lib/*
</span><span class='line'>
</span><span class='line'>// http://stackoverflow.com/questions/26988388/hive-0-14-0-not-starting [/tmp/hive on HDFS should be writable. Current permissions are: rwxrwxr-x]
</span><span class='line'>// hive.metastore.warehouse.dir  hive.exec.scratchdir
</span><span class='line'>[hadoop@cu2 hive]$ rm -rf /tmp/hive
</span><span class='line'>[hadoop@cu2 hive]$ hadoop fs -rmr /tmp/hive
</span><span class='line'>// 或者修改权限 hadoop fs -chmod 777 /tmp/hive</span></code></pre></td></tr></table></div></figure>


<h2>启用/使用tez</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop]$ cat ~/hive/conf/hive-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hive.execution.engine&lt;/name&gt;
</span><span class='line'>&lt;value&gt;tez&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hive]$ bin/hive
</span><span class='line'>...
</span><span class='line'>hive&gt; select count(*) from t_ods_access_log2;
</span><span class='line'>Query ID = hadoop_20160112200359_f8be3d1c-9adc-42c0-abb9-2643dfef2cc7
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Status: Running (Executing on YARN cluster with App id application_1452600034599_0001)
</span><span class='line'>
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>        VERTICES      STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>Map 1 ..........   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>Reducer 2 ......   SUCCEEDED      1          1        0        0       0       0
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 20.83 s    
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>OK
</span><span class='line'>67
</span><span class='line'>Time taken: 27.823 seconds, Fetched: 1 row(s)
</span></code></pre></td></tr></table></div></figure>


<h2>部署/启动hadoop-timeline</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 hadoop]$ vi etc/hadoop/yarn-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.hostname&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;hadoop-master2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.timeline-service.http-cross-origin.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;yarn.resourcemanager.system-metrics-publisher.enabled&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ for h in hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/yarn-daemon.sh start timelineserver
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/stop-all.sh
</span><span class='line'>[hadoop@cu2 hadoop]$ sbin/start-all.sh
</span></code></pre></td></tr></table></div></figure>


<h2>部署tez-ui</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 放置tez-ui
</span><span class='line'>[hadoop@cu2 target]$ cd ../../tez-ui/
</span><span class='line'>[hadoop@cu2 tez-ui]$ cd target/
</span><span class='line'>[hadoop@cu2 target]$ ll
</span><span class='line'>total 1476
</span><span class='line'>drwxrwxr-x 3 hadoop hadoop    4096 Jan 12 19:08 classes
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop    4096 Jan 12 19:08 maven-archiver
</span><span class='line'>drwxrwxr-x 8 hadoop hadoop    4096 Jan 12 19:08 tez-ui-0.7.0
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop    3058 Jan 12 19:08 tez-ui-0.7.0-tests.jar
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop 1491321 Jan 12 19:08 tez-ui-0.7.0.war
</span><span class='line'>[hadoop@cu2 target]$ mv tez-ui-0.7.0 ~/
</span><span class='line'>
</span><span class='line'>// 部署tez-ui
</span><span class='line'>[hadoop@cu2 ~]$ cd apache-tomcat-7.0.67/conf/
</span><span class='line'>修改端口为9999
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ vi conf/server.xml 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ cd conf/Catalina/localhost/
</span><span class='line'>[hadoop@cu2 localhost]$ vi tez-ui.xml
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 apache-tomcat-7.0.67]$ bin/startup.sh 
</span><span class='line'>
</span><span class='line'>// tez添加tez-ui功能
</span><span class='line'>[hadoop@cu2 hive]$ vi ~/hadoop-2.6.3/etc/hadoop/tez-site.xml 
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>&lt;value&gt;${fs.defaultFS}/apps/tez-0.7.0/tez-0.7.0.tar.gz&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.history.logging.service.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;tez.tez-ui.history-url.base&lt;/name&gt;
</span><span class='line'>&lt;value&gt;http://hadoop-master2:9999/tez-ui/&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span></code></pre></td></tr></table></div></figure>


<p>再运行一遍hive，查询一两个SQL。</p>

<p>最终效果：</p>

<p><img src="/images/blogs/tez-ui.png" alt="" /></p>

<h2>参考</h2>

<ul>
<li><a href="http://tez.apache.org/install.html">http://tez.apache.org/install.html</a></li>
<li><a href="http://tez.apache.org/tez-ui.html">http://tez.apache.org/tez-ui.html</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html">http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/">Hadoop安装与升级-(4)HA升级</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-07T15:04:27+00:00" pubdate data-updated="true">Thu 2016-01-07 15:04</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>官网的文档[HDFSHighAvailabilityWithQJM.html]和[HdfsRollingUpgrade.html]（Note that rolling upgrade is supported only from Hadoop-2.4.0 onwards.）很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<ol>
<li>关闭所有的namenode，部署新版本的hadoop</li>
<li>启动所有的journalnode，是所有！！升级namenode的同时，也会升级所有journalnode！！</li>
<li>使用-upgrade选项启动一台namenode。启动的这台namenode会直接进入active状态，升级本地的元数据，同时会升级shared edit log（也就是journalnode的数据）</li>
<li>使用-bootstrapStandby启动其他namenode，同步更新。不能使用-upgrade选项！（我也没试，不知道试了是啥效果）</li>
</ol>


<h2>关闭集群，部署新版本的hadoop</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/08 09:10:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/08 09:10:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping zkfc
</span><span class='line'>hadoop-master2: stopping zkfc
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ~/hadoop-2.6.3
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ ll
</span><span class='line'>total 52
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 bin
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop    32 Jan  8 06:05 etc -&gt; /home/hadoop/hadoop-2.2.0/ha-etc
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 include
</span><span class='line'>drwxr-xr-x 3 hadoop hadoop  4096 Dec 18 01:52 lib
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 libexec
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 15429 Dec 18 01:52 LICENSE.txt
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop  4096 Jan  8 03:37 logs
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   101 Dec 18 01:52 NOTICE.txt
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  1366 Dec 18 01:52 README.txt
</span><span class='line'>drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 sbin
</span><span class='line'>drwxr-xr-x 3 hadoop hadoop  4096 Jan  7 08:00 share
</span><span class='line'>
</span><span class='line'>#// 同步
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs ~/hadoop-2.6.3 $h:~/ ; done</span></code></pre></td></tr></table></div></figure>


<h2>启动所有Journalnode</h2>

<p>2.6和2.2用的是一份配置！etc通过软链接到2.2的ha-etc配置。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/hadoop-daemons.sh --hostnames "hadoop-master1" --script /home/hadoop/hadoop-2.2.0/bin/hdfs start journalnode
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
</span><span class='line'>31047 JournalNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>31097 Jps</span></code></pre></td></tr></table></div></figure>


<h2>升级一台namenode</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ bin/hdfs namenode -upgrade
</span><span class='line'>...
</span><span class='line'>16/01/08 09:13:54 INFO namenode.NameNode: createNameNode [-upgrade]
</span><span class='line'>...
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSImage: Starting upgrade of local storage directories.
</span><span class='line'>   old LV = -47; old CTime = 0.
</span><span class='line'>   new LV = -60; new CTime = 1452244437060
</span><span class='line'>16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>16/01/08 09:13:57 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>官网文档上说，除了升级了namenode的本地元数据外，sharededitlog也被升级了的。</p>

<p>查看journalnode的日志，确实journalnode也升级了：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-journalnode-hadoop-master1.log 
</span><span class='line'>...
</span><span class='line'>2016-01-08 09:13:57,070 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Starting upgrade of edits directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,072 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Starting upgrade of edits directory: .
</span><span class='line'>   old LV = -47; old CTime = 0.
</span><span class='line'>   new LV = -60; new CTime = 1452244437060
</span><span class='line'>2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/journal/zfcluster
</span><span class='line'>2016-01-08 09:13:57,222 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastWriterEpoch from 2 to 3 for client /172.17.0.1
</span><span class='line'>2016-01-08 09:16:57,731 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 3 to 4 for client /172.17.0.1
</span><span class='line'>2016-01-08 09:16:57,735 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/data/journal/zfcluster)
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>升级的namenode是前台运行的，不要关闭这个进程。接下来把另一台namenode同步一下。</p>

<h2>同步另一台namenode</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>...
</span><span class='line'>=====================================================
</span><span class='line'>About to bootstrap Standby ID nn2 from:
</span><span class='line'>           Nameservice ID: zfcluster
</span><span class='line'>        Other Namenode ID: nn1
</span><span class='line'>  Other NN's HTTP address: http://hadoop-master1:50070
</span><span class='line'>  Other NN's IPC  address: hadoop-master1/172.17.0.1:8020
</span><span class='line'>             Namespace ID: 639021326
</span><span class='line'>            Block pool ID: BP-1695500896-172.17.0.1-1452152050513
</span><span class='line'>               Cluster ID: CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
</span><span class='line'>           Layout version: -60
</span><span class='line'>       isUpgradeFinalized: false
</span><span class='line'>=====================================================
</span><span class='line'>16/01/08 09:15:19 INFO ha.BootstrapStandby: The active NameNode is in Upgrade. Prepare the upgrade for the standby NameNode as well.
</span><span class='line'>16/01/08 09:15:19 INFO common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 5008@hadoop-master2
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Opening connection to http://hadoop-master1:50070/imagetransfer?getimage=1&txid=1126&storageInfo=-60:639021326:1452244437060:CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
</span><span class='line'>16/01/08 09:15:21 INFO namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001126 size 977 bytes.
</span><span class='line'>16/01/08 09:15:21 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h2>重新启动集群</h2>

<p>ctrl+c关闭hadoop-master1 upgrade的namenode。启动整个集群。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</span><span class='line'>16/01/08 09:16:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: journalnode running as process 31047. Stop it first.
</span><span class='line'>16/01/08 09:16:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
</span><span class='line'>31047 JournalNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>31596 DFSZKFailoverController
</span><span class='line'>31655 Jps
</span><span class='line'>31294 NameNode
</span></code></pre></td></tr></table></div></figure>


<h2>后记：Journalnode重置</h2>

<p>在HA和non-HA环境来回的切换，最后启动HA时master起不来，执行bootstrapStandby也不行。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-01-08 06:15:36,746 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [172.17.0.1:8485]. Skipping.
</span><span class='line'>org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 1/1. 1 exceptions thrown:
</span><span class='line'>172.17.0.1:8485: Asked for firstTxId 1022 which is in the middle of file /data/journal/zfcluster/current/edits_0000000000000001021-0000000000000001022
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FileJournalManager.getRemoteEditLogs(FileJournalManager.java:198)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:640)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:181)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:203)
</span><span class='line'>        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:17453)
</span><span class='line'>        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>关闭集群，启动journalnode，跳转到没有问题的namenode机器，执行initializeSharedEdits命令。然后在有问题的namenode上重新初始化！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh</span></code></pre></td></tr></table></div></figure>


<p>后话（谨慎，没有试验过，猜想而已）： 其实上面HA升级的步骤，如果upgrade时没用启动journalnode，导致了问题的话，把journalnode重置应该也是可以的。</p>

<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/">Hadoop安装与升级-(3)HA配置</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-07T15:04:27+00:00" pubdate data-updated="true">Thu 2016-01-07 15:04</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>官网的文档[HDFSHighAvailabilityWithQJM.html]很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<h2>配置</h2>

<p>hadoop-master1和hadoop-master2之间无密钥登录（failover要用到）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-keygen
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master2
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master1</span></code></pre></td></tr></table></div></figure>


<p>配置文件修改：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/core-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hdfs://zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/tmp&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/hdfs-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span><span class='line'>&lt;value&gt; &lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.nameservices&lt;/name&gt;
</span><span class='line'>&lt;value&gt;zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.namenodes.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;nn1,nn2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;qjournal://hadoop-master1:8485/zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.client.failover.proxy.provider.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/journal&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
</span><span class='line'>&lt;value&gt;sshfence&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
</span><span class='line'>&lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>启动</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ..
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.2.0 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>#// 此时可以启动datanode，通过50070端口看namenode的状态
</span><span class='line'>
</span><span class='line'>#// Automatic failover，zkfc和namenode没有启动顺序的问题！
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs zkfc -formatZK
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs haadmin -failover nn1 nn2
</span><span class='line'>
</span><span class='line'>#// 测试failover，把一个active的namenode直接kill掉，看看另一个是否变成active！
</span><span class='line'>
</span><span class='line'># 重启
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/07 10:57:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/07 10:58:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: no zkfc to stop
</span><span class='line'>hadoop-master1: no zkfc to stop
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>16/01/07 10:59:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>16/01/07 10:59:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ jps
</span><span class='line'>15241 DFSZKFailoverController
</span><span class='line'>14882 NameNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>18715 Jps
</span><span class='line'>15076 JournalNode</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html</a></li>
<li><a href="http://www.xlgps.com/article/40993.html">http://www.xlgps.com/article/40993.html</a></li>
<li><a href="http://hbase.apache.org/book.html#basic.prerequisites">http://hbase.apache.org/book.html#basic.prerequisites</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/">Hadoop安装与升级-(2)2.2升级到2.6</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-07T14:04:27+00:00" pubdate data-updated="true">Thu 2016-01-07 14:04</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>升级的命令很简单，但是不要瞎整！升级就一个命令就搞定了！</p>

<h2>部署2.6.3</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.6.3.tar.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.6.3/share/
</span><span class='line'>[hadoop@hadoop-master1 share]$ rm -rf doc/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ rm -rf lib/native/*
</span><span class='line'>
</span><span class='line'>#// 拷贝四个配置文件到hadoop-2.6.3
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ cd etc/hadoop/
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/*-site.xml ./
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/slaves ./
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cd 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span></code></pre></td></tr></table></div></figure>


<h2>升级（最佳方式）</h2>

<p>直接使用upgrade选项启动dfs即可。（secondarynamenode不要单独操作来升级，反正就是执行upgrade启动dfs就好了）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade
</span><span class='line'>
</span><span class='line'>// 2.2和2.6都没有这个命令
</span><span class='line'>// hadoop dfsadmin -upgradeProgress status
</span><span class='line'>hadoop dfsadmin -finalizeUpgrade
</span></code></pre></td></tr></table></div></figure>


<p>参考[Hadoop: The Definitive Guide/Chapter 10. Administering Hadoop/Maintenance/Upgrades]</p>

<h2>瞎整1</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先停集群
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</span></code></pre></td></tr></table></div></figure>


<p>直接在原来的2.2基础上启动，datanode启动没问题，但是namenode报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-namenode-hadoop-master1.log 
</span><span class='line'>...
</span><span class='line'>2016-01-07 08:05:23,582 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
</span><span class='line'>java.io.IOException: 
</span><span class='line'>File system image contains an old layout version -47.
</span><span class='line'>An upgrade to version -60 is required.
</span><span class='line'>Please restart NameNode with the "-rollingUpgrade started" option if a rolling upgrade is already started; or restart NameNode with the "-upgrade" option to start a new upgrade.
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:232)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:764)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:748)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
</span><span class='line'>2016-01-07 08:05:23,583 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
</span><span class='line'>2016-01-07 08:05:23,585 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
</span><span class='line'>/************************************************************
</span><span class='line'>SHUTDOWN_MSG: Shutting down NameNode at hadoop-master1/172.17.0.1
</span><span class='line'>************************************************************/</span></code></pre></td></tr></table></div></figure>


<p>重新启动，使用upgrade选项启动：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade</span></code></pre></td></tr></table></div></figure>


<p>或者还原到2.2：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># **所有**slaver节点的VERSION改回47
</span><span class='line'>[hadoop@hadoop-slaver3 ~]$ vi /data/tmp/dfs/data/current/VERSION 
</span><span class='line'>...
</span><span class='line'>layoutVersion=-47
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh -rollback
</span></code></pre></td></tr></table></div></figure>


<h2>原理</h2>

<p>升级的时刻，首先备份原来的数据到previous目录下，升级后的放置到current目录下。namenode这样没啥大问题，但是datanode也是这样结构current和previous，那相当有问题，那数据量不是翻倍了？</p>

<p>查看数据后，发现一个名字的文件current和previous里面使用的是一个inode。也就是说用的是硬链接，数据只有一份！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop fs -put *.txt /
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver3 ~]$ cd /data/tmp/dfs/data/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ test current/finalized/subdir0/subdir0/blk_1073741825 -ef previous/finalized/blk_1073741825
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ echo $?
</span><span class='line'>0
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i current/finalized/subdir0/subdir0/blk_1073741825 
</span><span class='line'>142510 current/finalized/subdir0/subdir0/blk_1073741825
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i previous/finalized/blk_1073741825
</span><span class='line'>142510 previous/finalized/blk_1073741825
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/17">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/15">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2016/04/23/hadoop-guide-catalog/">[整理] Hadoop入门</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/03/28/hive-on-spark/">Hive on Spark</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/08/24/manual-install-supervisor/">Supervisor安装配置</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/10/16/spark-build-and-configuration/">编译/搭建Spark环境</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/08/25/step-by-step-found-java-oom-error/">查找逐步定位Java程序OOM的异常实践</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/29/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/26/start-redis/">[读读书]Redis入门指南</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/17/jekyll-edit-link-in-web-page/">Jekyll页面添加编辑按钮</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/08/09/java-bytecode-security/">保护/加密JAVA代码</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/08/05/nfs-on-centos7/">Nfs on Centos7</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/08/05/encfs-secure-filesystem/">Encfs加密文件系统</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/">Kubeadm部署kubernetes</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/07/16/consistent-hashing/">[转]一致性Hash</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/07/15/togo-another-rpmbuild-tool/">togo简单的RPM打包工具</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/07/08/casperjs-crawler/">爬虫之CasperJS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/06/04/wechat-images-export/">导出微信照片</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/bigdata/'>bigdata</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (10) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/flume/'>flume</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (43) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kubeadm/'>kubeadm</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (51) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/zookeeper/'>zookeeper</a> (1) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (180)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Softs, I&#8217;m using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253461959'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1253461959%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  

<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"winseliu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->










</body>
</html>
