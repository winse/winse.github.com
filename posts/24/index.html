
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="最好的就是集群的所有的datanode的节点的硬件配置一样！当然系统时间也的一致，hosts等等这些。机器配置一样时可以使用脚本进行批量处理，给维护带来很大的便利性。 今天收到运维的信息，说集群的一台机器硬盘爆了！上到环境查看df -h发现硬盘配置和其他datanode的不同！但是hadoop &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winseliu.com/posts/24">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="http://cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winseliu.com" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
  <li><a href="https://yunpan.cn/cuYhpFBPgQYgT" >Books[5aee]</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/02/hadoop-datanode-config-should-equals/">Hadoop的datanode数据节点软/硬件配置应该一致</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-02T22:21:12+08:00" pubdate data-updated="true">Sat 2014-08-02 22:21</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最好的就是集群的所有的datanode的节点的<strong>硬件配置一样</strong>！当然系统时间也的一致，hosts等等这些。机器配置一样时可以使用脚本进行批量处理，给维护带来很大的便利性。</p>

<p>今天收到运维的信息，说集群的一台机器硬盘爆了！上到环境查看<code>df -h</code>发现硬盘配置和其他datanode的不同！但是hadoop hdfs-site.xml的<code>dfs.datanode.data.dir</code>却是一样的！</p>

<p>经验： dir的配置应该是一个系统设备对应一个路径，而不是一个系统目录对应dir的一个路径！</p>

<h2>问题现象以及根源</h2>

<p>问题机器A的磁盘情况：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-slaver8 ~]$ df -h
</span><span class='line'>文件系统              容量  已用  可用 已用%% 挂载点
</span><span class='line'>/dev/sda3             2.7T  2.5T   53G  98% /
</span><span class='line'>tmpfs                  32G  260K   32G   1% /dev/shm
</span><span class='line'>/dev/sda1              97M   32M   61M  35% /boot
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver8 /]$ ll
</span><span class='line'>总用量 170
</span><span class='line'>dr-xr-xr-x.   2 root   root    4096 2月  12 19:39 bin
</span><span class='line'>dr-xr-xr-x.   5 root   root    1024 2月  13 02:40 boot
</span><span class='line'>drwxr-xr-x.   2 root   root    4096 2月  23 2012 cgroup
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data1
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data10
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data11
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data12
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data13
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data14
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data15
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data2
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data3
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data4
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data5
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data6
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data7
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data8
</span><span class='line'>drwxr-xr-x.   3 hadoop hadoop  4096 6月  30 10:36 data9</span></code></pre></td></tr></table></div></figure>


<p>再看集群其他机器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-slaver1 ~]$ df -h
</span><span class='line'>文件系统              容量  已用  可用 已用%% 挂载点
</span><span class='line'>/dev/sda3             2.7T   32G  2.5T   2% /
</span><span class='line'>tmpfs                  32G   88K   32G   1% /dev/shm
</span><span class='line'>/dev/sda1              97M   32M   61M  35% /boot
</span><span class='line'>/dev/sdb1             1.8T  495G  1.3T  29% /data1
</span><span class='line'>/dev/sdb2             1.8T  485G  1.3T  28% /data2
</span><span class='line'>/dev/sdb3             1.8T  492G  1.3T  29% /data3
</span><span class='line'>/dev/sdb4             1.8T  488G  1.3T  28% /data4
</span><span class='line'>/dev/sdb5             1.8T  486G  1.3T  28% /data5
</span><span class='line'>/dev/sdb6             1.8T  480G  1.3T  28% /data6
</span><span class='line'>/dev/sdb7             1.8T  479G  1.3T  28% /data7
</span><span class='line'>/dev/sdb8             1.8T  474G  1.3T  28% /data8
</span><span class='line'>/dev/sdb9             1.8T  480G  1.3T  28% /data9
</span><span class='line'>/dev/sdb10            1.8T  478G  1.3T  28% /data10
</span><span class='line'>/dev/sdb11            1.8T  475G  1.3T  28% /data11
</span><span class='line'>/dev/sdb12            1.8T  489G  1.3T  29% /data12
</span><span class='line'>/dev/sdb13            1.8T  475G  1.3T  28% /data13
</span><span class='line'>/dev/sdb14            1.8T  476G  1.3T  28% /data14
</span><span class='line'>/dev/sdb15            1.8T  469G  1.3T  27% /data15</span></code></pre></td></tr></table></div></figure>


<p>出问题机器没有挂存储，仅仅是建立了对应的目录结构，并不是把目录挂载到单独的存储设备上。</p>

<p>同时查看50070的前面的信息，hadoop把每个逗号分隔后的路径默认都做一个磁盘设备来计算！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Node               Address             ..Admin State CC    Used  NU    RU(%) R(%)      Blocks Block  Pool Used Block Pool Used (%)
</span><span class='line'>hadoop-slaver1    192.168.32.21:50010 2   In Service  26.86   7.05    1.37    18.44   26.25       68.66   264844  7.05    26.25   
</span><span class='line'>hadoop-slaver8    192.168.32.28:50010 1   In Service  37.94   2.46    34.71   0.77    6.48        2.03    29637   2.46    6.48    </span></code></pre></td></tr></table></div></figure>


<p>配置容量是所有配置的路径所在盘容量的<strong>累加</strong>。总的剩余空间（余量）也是各个dir配置路径的剩余空间<strong>累加</strong>的！这样很容易出现问题！
最好的就是集群的所有的datanode的节点的<strong>硬件配置一样</strong>！当然系统时间也的一致，hosts等等这些。</p>

<h2>问题处理</h2>

<p>首先得把问题解决啊：</p>

<ul>
<li>把<code>dfs.datanode.data.dir</code>路径个数调整为磁盘个数！</li>
<li>修改该datanode的hdfs-site的配置，添加<code>dfs.datanode.du.reserved</code>，留给系统的空间设置为400多G。</li>
<li>冗余份数也没有必要3份，浪费空间。如果两台机器同时出现问题，还是同一份数据，那只能说是天意！你可以去趟澳门赌一圈了！</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data1/hadoop/data&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.datanode.du.reserved&lt;/name&gt;
</span><span class='line'>&lt;value&gt;437438953472&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<p>设置了reserved保留空间后，再看LIVE页面slaver8的容量变少了且正好等于(盘的容量2.7T-430G~=2.26T 计算容量的hdfs源码在<code>FsVolumeImpl.getCapacity()</code>)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hadoop-slaver8   192.168.32.28:50010 1   In Service  2.26    2.23    0.00    0.03    98.66</span></code></pre></td></tr></table></div></figure>


<p>datanode和blockpool的平衡处理，可以参考<a href="http://hadoop-master1:50070/dfsnodelist.jsp?whatNodes=LIVE">Live Datanodes</a>的容量和进行！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ hdfs balancer -help
</span><span class='line'>Usage: java Balancer
</span><span class='line'>        [-policy &lt;policy&gt;]      the balancing policy: datanode or blockpool
</span><span class='line'>        [-threshold &lt;threshold&gt;]        Percentage of disk capacity
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver8 ~]$ hadoop-2.2.0/bin/hdfs getconf -confkey dfs.datanode.du.reserved
</span><span class='line'>137438953472</span></code></pre></td></tr></table></div></figure>


<p>删除一些没用的备份数据。配置好以后，重启当前slaver8节点，并进行数据平衡（如果觉得麻烦，直接丢掉原来的一个目录下的数据也行，可能更快！均衡器运行的太慢！！）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-slaver8 ~]$  ~/hadoop-2.2.0/sbin/hadoop-daemon.sh stop datanode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver8 ~]$  for i in 6 7 8 9 10 11 12 13 14 15; do  cd /data$i/hadoop/data/current/BP-1414312971-192.168.32.11-1392479369615/current/finalized;  find . -type f -exec mv {} /data1/hadoop/data/current/BP-1414312971-192.168.32.11-1392479369615/current/finalized/{} \;; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver8 ~]$  ~/hadoop-2.2.0/sbin/hadoop-daemon.sh start datanode
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ hdfs dfsadmin -setBalancerBandwidth 10485760
</span><span class='line'>[hadoop@hadoop-master1 ~]$ hdfs balancer -threshold 60
</span></code></pre></td></tr></table></div></figure>


<p>查看datanode的日志，由于移动数据，有些blk的id一样，会清理一些数据。对于均衡器程序的阀值越小集群越平衡！默认是10（%），会移动很多的数据（准备看下均衡器的源码，了解各个参数以及运行的逻辑）！</p>

<h2>参考</h2>

<ul>
<li><a href="http://blog.csdn.net/lingzihan1215/article/details/8700532">hadoop的datanode多磁盘空间处理</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2014-07-30T00:25:39+08:00" pubdate data-updated="true">Wed 2014-07-30 00:25</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>网上查了很多资料说的很复杂，要叉叉叉叉叉！其实hadoop2已经集成了hadoop-snappy，只要安装snappy即可。但是也没有一些文章说的只要编译snappy然后放到lib/native路径下即可，还需要重新编译libhadoop的library包。</p>

<p>查找hadoop-snappy的源码的时刻，在C代码里面定义了<code>HADOOP_SNAPPY_LIBRARY</code>，然后理着这个思路去查找，发现在CMakeFile文件中也定义了对应的变量，然后再查找pom.xml的native profile中定义了snappy.prefix的属性。最后就有了下面的步骤。</p>

<ul>
<li>2016-1 更新编译2.6.3</li>
</ul>


<h2>centos6编译2.6.3命令</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-- linux已经自带了libsnappy.so.1文件，用于编译。如果系统没有libsnappy.so.1，需要把编译好的so拷贝到$HADOOP_HOME/lib/native目录下（方便拷贝到其他机器）。
</span><span class='line'>-- 
</span><span class='line'>-- https://www.rpmfind.net/linux/rpm2html/search.php?query=snappy&submit=Search+...&system=&arch= 
</span><span class='line'>-- 去看这里看下系统版本有哪些snappy版本，然后再下载相应的snappy版本编译
</span><span class='line'>-- http://google.github.io/snappy/
</span><span class='line'>-- 
</span><span class='line'>[root@cu2 ~]# yum install -y libtool*
</span><span class='line'>[root@cu2 ~]# exit
</span><span class='line'>logout
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 snappy-1.1.3]$ ./autogen.sh 
</span><span class='line'>[hadoop@cu2 snappy-1.1.3]$ 
</span><span class='line'>[hadoop@cu2 snappy-1.1.3]$ ./configure --prefix=/home/hadoop/snappy
</span><span class='line'>[hadoop@cu2 snappy-1.1.3]$ make 
</span><span class='line'>[hadoop@cu2 snappy-1.1.3]$ make install
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3-src]$ mvn package -Pdist -Pnative -Dtar -Dmaven.javadoc.skip=true -DskipTests -Dsnappy.prefix=/home/hadoop/snappy -Drequire.snappy=true 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ tar zxvf sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3.tar.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ cd hadoop-2.6.3
</span><span class='line'>[hadoop@cu2 hadoop-2.6.3]$ bin/hadoop checknative
</span><span class='line'>16/01/09 19:25:46 WARN bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version
</span><span class='line'>16/01/09 19:25:46 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
</span><span class='line'>Native library checking:
</span><span class='line'>hadoop:  true /home/hadoop/hadoop-2.6.3/lib/native/libhadoop.so.1.0.0
</span><span class='line'>zlib:    true /lib64/libz.so.1
</span><span class='line'>snappy:  true /usr/lib64/libsnappy.so.1
</span><span class='line'>lz4:     true revision:99
</span><span class='line'>bzip2:   false 
</span><span class='line'>openssl: false Cannot load libcrypto.so (libcrypto.so: cannot open shared object file: No such file or directory)!
</span><span class='line'>
</span><span class='line'>[hadoop@cu2 ~]$ for h in hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span></code></pre></td></tr></table></div></figure>


<h2>正文部分</h2>

<p>1) build snappy</p>

<p>编译Snappy，并把lib拷贝/同步到hadoop的native目录下。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar zxf snappy-1.1.1.tar.gz 
</span><span class='line'>cd snappy-1.1.1
</span><span class='line'>./configure --prefix=/home/hadoop/snappy
</span><span class='line'>make
</span><span class='line'>make install
</span><span class='line'>
</span><span class='line'>cd snappy
</span><span class='line'>cd lib/
</span><span class='line'># 拷贝到hadoop/lib目录下
</span><span class='line'>rysnc -vaz * ~/hadoop-2.2.0/lib/native/</span></code></pre></td></tr></table></div></figure>


<p>2) rebuild hadoop common project</p>

<p>重新编译hadoop的lib，覆盖原来的文件。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 hadoop-common]$ mvn package -Dmaven.javadoc.skip=true -DskipTests -Dsnappy.prefix=/home/hadoop/snappy -Drequire.snappy=true -Pnative 
</span><span class='line'>
</span><span class='line'>[hadoop@master1 hadoop-common]$ cd ~/hadoop-2.2.0-src/hadoop-common-project/hadoop-common/
</span><span class='line'>[hadoop@master1 hadoop-common]$ cd target/native/target/usr/local/lib/
</span><span class='line'>[hadoop@master1 lib]$ ll
</span><span class='line'>total 1252
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop 820824 Jul 30 00:18 libhadoop.a
</span><span class='line'>lrwxrwxrwx. 1 hadoop hadoop     18 Jul 30 00:18 libhadoop.so -&gt; libhadoop.so.1.0.0
</span><span class='line'>-rwxrwxr-x. 1 hadoop hadoop 455542 Jul 30 00:18 libhadoop.so.1.0.0
</span><span class='line'>[hadoop@master1 lib]$ rsync -vaz * ~/hadoop-2.2.0/lib/native/
</span><span class='line'>sending incremental file list
</span><span class='line'>libhadoop.a
</span><span class='line'>libhadoop.so.1.0.0
</span><span class='line'>
</span><span class='line'>sent 409348 bytes  received 53 bytes  818802.00 bytes/sec
</span><span class='line'>total size is 1276384  speedup is 3.12
</span><span class='line'>[hadoop@master1 lib]$ </span></code></pre></td></tr></table></div></figure>


<p>3) check</p>

<p>检查程序snappy是否已经配置成功</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 ~]$ hadoop checknative -a
</span><span class='line'>14/07/30 00:22:14 WARN bzip2.Bzip2Factory: Failed to load/initialize native-bzip2 library system-native, will use pure-Java version
</span><span class='line'>14/07/30 00:22:14 INFO zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
</span><span class='line'>Native library checking:
</span><span class='line'>hadoop: true /home/hadoop/hadoop-2.2.0/lib/native/libhadoop.so.1.0.0
</span><span class='line'>zlib:   true /lib64/libz.so.1
</span><span class='line'>snappy: true /home/hadoop/hadoop-2.2.0/lib/native/libsnappy.so.1
</span><span class='line'>lz4:    true revision:43
</span><span class='line'>bzip2:  false 
</span><span class='line'>14/07/30 00:22:14 INFO util.ExitUtil: Exiting with status 1
</span><span class='line'>[hadoop@master1 ~]$ </span></code></pre></td></tr></table></div></figure>


<p>4) 跑一个压缩程序</p>

<p>先参考网上的，直接用hbase的带的测试类运行（前提：需要在hbase-env.sh中配置HADOOP_HOME，这样hbase才能找到hadoop下的lib本地库）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 ~]$ hbase-0.98.3-hadoop2/bin/hbase org.apache.hadoop.hbase.util.CompressionTest file:///tmp/abc.snappy snappy
</span><span class='line'>2014-07-30 08:50:42,617 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
</span><span class='line'>SLF4J: Class path contains multiple SLF4J bindings.
</span><span class='line'>SLF4J: Found binding in [jar:file:/home/hadoop/hbase-0.98.3-hadoop2/lib/slf4j-log4j12-1.6.4.jar!/org/slf4j/impl/StaticLoggerBinder.class]
</span><span class='line'>SLF4J: Found binding in [jar:file:/home/hadoop/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
</span><span class='line'>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
</span><span class='line'>2014-07-30 08:50:44,515 INFO  [main] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
</span><span class='line'>2014-07-30 08:50:44,522 INFO  [main] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
</span><span class='line'>2014-07-30 08:50:45,388 INFO  [main] compress.CodecPool: Got brand-new compressor [.snappy]
</span><span class='line'>2014-07-30 08:50:45,408 INFO  [main] compress.CodecPool: Got brand-new compressor [.snappy]
</span><span class='line'>2014-07-30 08:50:45,430 ERROR [main] hbase.KeyValue: Unexpected getShortMidpointKey result, fakeKey:testkey, firstKeyInBlock:testkey
</span><span class='line'>2014-07-30 08:50:47,088 INFO  [main] compress.CodecPool: Got brand-new decompressor [.snappy]
</span><span class='line'>SUCCESS
</span><span class='line'>[hadoop@master1 ~]$ </span></code></pre></td></tr></table></div></figure>


<p>看到最后的<strong>SUCCESS</strong>就说明安装配置成功了！</p>

<p>接下来自己写程序测试压缩/解压缩，首先编写java类：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import java.io.FileInputStream;
</span><span class='line'>import java.io.FileNotFoundException;
</span><span class='line'>import java.io.FileOutputStream;
</span><span class='line'>import java.io.IOException;
</span><span class='line'>
</span><span class='line'>import org.apache.commons.lang.StringUtils;
</span><span class='line'>import org.apache.hadoop.conf.Configuration;
</span><span class='line'>import org.apache.hadoop.io.compress.CompressionCodec;
</span><span class='line'>import org.apache.hadoop.io.compress.CompressionInputStream;
</span><span class='line'>import org.apache.hadoop.io.compress.CompressionOutputStream;
</span><span class='line'>import org.apache.hadoop.io.compress.SnappyCodec;
</span><span class='line'>import org.apache.hadoop.util.ReflectionUtils;
</span><span class='line'>import org.apache.zookeeper.common.IOUtils;
</span><span class='line'>
</span><span class='line'>public class SnappyCompressTest {
</span><span class='line'>
</span><span class='line'>        public static void main(String[] args) throws FileNotFoundException, IOException {
</span><span class='line'>                try {
</span><span class='line'>                        execute(args);
</span><span class='line'>                } catch (Exception e) {
</span><span class='line'>                        System.out.println("Usage: $0 read|write file[.snappy]");
</span><span class='line'>                }
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>        private static void execute(String[] args) throws FileNotFoundException, IOException {
</span><span class='line'>                String op = args[0];
</span><span class='line'>                String file = args[1];
</span><span class='line'>                String snappyFile = file + ".snappy";
</span><span class='line'>
</span><span class='line'>                Class&lt;? extends CompressionCodec&gt; clazz = SnappyCodec.class;
</span><span class='line'>                CompressionCodec codec = ReflectionUtils.newInstance(clazz, new Configuration());
</span><span class='line'>
</span><span class='line'>                if (StringUtils.equalsIgnoreCase(op, "read")) {
</span><span class='line'>                        FileInputStream fin = new FileInputStream(snappyFile);
</span><span class='line'>                        CompressionInputStream in = codec.createInputStream(fin);
</span><span class='line'>                        FileOutputStream fout = new FileOutputStream(file);
</span><span class='line'>                        IOUtils.copyBytes(in, fout, 4096, true);
</span><span class='line'>                } else {
</span><span class='line'>                        FileInputStream fin = new FileInputStream(file);
</span><span class='line'>                        CompressionOutputStream out = codec.createOutputStream(new FileOutputStream(snappyFile));
</span><span class='line'>                        IOUtils.copyBytes(fin, out, 4096, true);
</span><span class='line'>                }
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>编译运行，测试读写功能。使用hadoop命令可以简化很多工作，把当前路径加入到<code>HADOOP_CLASSPATH</code>。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 test]$ javac -cp `hadoop classpath` SnappyCompressTest.java 
</span><span class='line'>[hadoop@master1 test]$ export HADOOP_CLASSPATH=$PWD
</span><span class='line'>[hadoop@master1 test]$ hadoop SnappyCompressTest 
</span><span class='line'>Usage: $0 read|write file[.snappy]
</span><span class='line'>[hadoop@master1 test]$ hadoop SnappyCompressTest write test.txt 
</span><span class='line'>[hadoop@master1 test]$ ll
</span><span class='line'>total 16
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop 1991 Jul 30 09:27 SnappyCompressTest.class
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop 1586 Jul 30 09:23 SnappyCompressTest.java
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop   12 Jul 30 09:23 test.txt
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop   22 Jul 30 09:28 test.txt.snappy
</span><span class='line'>[hadoop@master1 test]$ rm test.txt
</span><span class='line'>[hadoop@master1 test]$ hadoop SnappyCompressTest read test.txt 
</span><span class='line'>[hadoop@master1 test]$ ll
</span><span class='line'>total 16
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop 1991 Jul 30 09:27 SnappyCompressTest.class
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop 1586 Jul 30 09:23 SnappyCompressTest.java
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop   12 Jul 30 09:28 test.txt
</span><span class='line'>-rw-rw-r--. 1 hadoop hadoop   22 Jul 30 09:28 test.txt.snappy
</span><span class='line'>[hadoop@master1 test]$ cat test.txt
</span><span class='line'>abc
</span><span class='line'>abc
</span><span class='line'>abc</span></code></pre></td></tr></table></div></figure>


<p>5) hbase中添加压缩</p>

<p>把所有library，以及hbase的配置同步其他所有从节点。对hbase的表使用Snappy压缩。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hbase(main):001:0&gt; create 'st1', 'f1'
</span><span class='line'>hbase(main):005:0&gt; alter 'st1', {NAME=&gt;'f1', COMPRESSION=&gt;'snappy'}
</span><span class='line'>Updating all regions with the new schema...
</span><span class='line'>0/1 regions updated.
</span><span class='line'>1/1 regions updated.
</span><span class='line'>Done.
</span><span class='line'>0 row(s) in 2.7880 seconds
</span><span class='line'>
</span><span class='line'>hbase(main):010:0&gt; create 'sst1','f1'
</span><span class='line'>0 row(s) in 0.5730 seconds
</span><span class='line'>
</span><span class='line'>=&gt; Hbase::Table - sst1
</span><span class='line'>hbase(main):011:0&gt; flush 'sst1'
</span><span class='line'>0 row(s) in 2.5380 seconds
</span><span class='line'>
</span><span class='line'>hbase(main):012:0&gt; flush 'st1'
</span><span class='line'>0 row(s) in 7.5470 seconds</span></code></pre></td></tr></table></div></figure>


<p>对于hbase来说，使用压缩消耗还是挺大的。插入10w数据中间进行compaction时停顿比较久。最后flush写数据的时间也长了很多！
下面是文件写入后的文件大小对比（由于是进行简单的测试，写入的数据重复比较多。具体比例没有参考价值）：</p>

<p><img src="http://file.bmob.cn/M00/05/5A/wKhkA1PYz9CAB-TdAAEWX8LGpUo149.png" alt="" /></p>

<p>6) 正式环境下解压snappy文件</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>import java.io.FileOutputStream;
</span><span class='line'>import java.io.IOException;
</span><span class='line'>import java.io.InputStream;
</span><span class='line'>
</span><span class='line'>import org.apache.hadoop.conf.Configuration;
</span><span class='line'>import org.apache.hadoop.fs.FileSystem;
</span><span class='line'>import org.apache.hadoop.fs.Path;
</span><span class='line'>import org.apache.hadoop.io.compress.CompressionCodec;
</span><span class='line'>import org.apache.hadoop.io.compress.CompressionInputStream;
</span><span class='line'>import org.apache.hadoop.io.compress.SnappyCodec;
</span><span class='line'>import org.apache.hadoop.util.ReflectionUtils;
</span><span class='line'>import org.apache.zookeeper.common.IOUtils;
</span><span class='line'>
</span><span class='line'>public class DecompressTest {
</span><span class='line'>  public static void main(String[] args) throws IOException {
</span><span class='line'>
</span><span class='line'>      Configuration conf = new Configuration();
</span><span class='line'>      Path path = new Path(args[0]);
</span><span class='line'>      FileSystem fs = path.getFileSystem(conf);
</span><span class='line'>
</span><span class='line'>      Class&lt;? extends CompressionCodec&gt; clazz = SnappyCodec.class;
</span><span class='line'>      CompressionCodec codec = ReflectionUtils.newInstance(clazz, new Configuration());
</span><span class='line'>
</span><span class='line'>      InputStream fin = fs.open(path);
</span><span class='line'>      CompressionInputStream in = codec.createInputStream(fin);
</span><span class='line'>
</span><span class='line'>      IOUtils.copyBytes(in, System.out, 4096, true);
</span><span class='line'>
</span><span class='line'>      fin.close();
</span><span class='line'>
</span><span class='line'>      System.out.println("SUCCESS");
</span><span class='line'>
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>// build & run
</span><span class='line'>
</span><span class='line'>&gt;DecompressTest.java 
</span><span class='line'>vi DecompressTest.java 
</span><span class='line'>javac -cp `hadoop classpath`  DecompressTest.java 
</span><span class='line'>export HADOOP_CLASSPATH=.
</span><span class='line'># snappyfile on hdfs
</span><span class='line'>hadoop DecompressTest /user/hive/t_ods_access_log2/month=201408/day=20140828/hour=2014082808/t_ods_access_log2-2014082808.our.snappy.1409187524328
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/29/hadoop2-use-shortcircuit-local-reading/">Hadoop2 ShortCircuit Local Reading</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2014-07-29T20:11:58+08:00" pubdate data-updated="true">Tue 2014-07-29 20:11</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>hadoop一直以来认为是本地读写文件的，但是其实也是通过TCP端口去获取数据，只是都在同一台机器。在hivetuning调优hive的文档中看到了ShortCircuit的HDFS配置属性，查看了ShortCircuit的来由，真正的实现了本地读取文件。蒙查查表示看的不是很明白，最终大致就是通过linux的<strong>文件描述符</strong>来实现功能同时保证文件的权限。</p>

<p>由于仅在自己的机器上面配置来查询hbase的数据，性能方面提升感觉不是很明显。等以后整到正式环境再对比对比。</p>

<ul>
<li>2016-1 添加测试方法数据是否通过short-circuit读取</li>
</ul>


<p>配置如下。</p>

<p>1 修改hdfs-site.xml</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;/home/hadoop/data/sockets/dn_socket&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<p>注意：socket路径的权限控制的比较严格。dn_socket<strong>所有的父路径</strong>要么仅有当前启动用户的写权限，要么仅root可写。</p>

<p><img src="http://file.bmob.cn/M00/05/52/wKhkA1PXfbKANLOrAADWJQ5taVs391.png" alt="" /></p>

<p>2 修改hbase的配置，并添加HADOOP_HOME（hbase查找hadoop-native）</p>

<p><img src="http://file.bmob.cn/M00/05/52/wKhkA1PXhRKAZDs6AAChrEauBoU738.png" alt="" /></p>

<p>hbase的脚本找到hadoop命令后，会把hadoop的java.library.path配置加入到hbase的启动脚本中。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// 更好的方式是Hbase直接共享HADOOP_CONF_DIR
</span><span class='line'>[hadoop@master1 ~]$ tail -15 hbase-0.98.3-hadoop2/conf/hbase-site.xml 
</span><span class='line'>    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;/home/hadoop/data/hbase&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;/home/hadoop/data/sockets/dn_socket&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>// IBM部署是直接把一系列的bigdata的环境变量写到一个FILE，然后加入到/etc/profile.d/FILE。
</span><span class='line'>[hadoop@master1 ~]$ cat hbase-0.98.3-hadoop2/conf/hbase-env.sh
</span><span class='line'>...
</span><span class='line'>export HADOOP_HOME=/home/hadoop/hadoop-2.2.0
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>3 同步到其他节点，然后重启hdfs,hbase</p>

<h2>测试</h2>

<ul>
<li><a href="https://www.zybuluo.com/jewes/note/37713">https://www.zybuluo.com/jewes/note/37713</a></li>
</ul>


<p>在datanode读取该机器上的block（fsck命令可以查看文件的块在哪些机器）。通过查看日志，或者通过HdfsDataInputStream.getReadStatistics().getTotalShortCircuitBytesRead()来获取从ShortCircuit读取数据量。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu3 ~]$ ~/hadoop-2.6.3/bin/hdfs fsck /spark-assembly-1.6.0-hadoop2.6.3.jar -files -blocks -locations</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://vdisk.weibo.com/s/z_44nz36hNM3Z">hive-tuning</a></li>
<li><a href="http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/">How Improved Short-Circuit Local Reads Bring Better Performance and Security to Hadoop</a></li>
<li><a href="http://hbase.apache.org/book/perf.hdfs.html">HDFS&ndash;Apache HBase Performance Tuning</a></li>
<li><a href="http://archive.cloudera.com/cdh4/cdh/4/hadoop/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">HDFS Short-Circuit Local Reads</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/29/safely-remove-datanode/">Hadoop安全的关闭datanode节点</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-29T15:08:41+08:00" pubdate data-updated="true">Tue 2014-07-29 15:08</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>hadoop默认就有冗余（dfs.replication）的机制，所以一般情况下，一台机器挂了也没所谓。集群会自动的进行复制均衡处理。</p>

<p>作为测试，如果dfs.replication设置为1的情况下，怎么安全的把datanode节点服务关闭呢？例如说，刚刚开始搭建环境是把namenode、datanode放在一台机器上，后面增加了机器如何把datanode分离出来呢？</p>

<p>借助于<strong>dfs.hosts.exclude</strong>即可完成顺序的完成此项任务。</p>

<p>修改hdfs-site.xml配置。我操作的时刻仅修改了master1上的hdfs-site.xml。把<strong>master1</strong>值写入到对应的文件中。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 hadoop]$ cat hdfs-site.xml 
</span><span class='line'>...
</span><span class='line'>&lt;property&gt;
</span><span class='line'>        &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;
</span><span class='line'>        &lt;value&gt;/home/hadoop/hadoop-2.2.0/etc/hadoop/exclude&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>[hadoop@master1 hadoop]$ cat /home/hadoop/hadoop-2.2.0/etc/hadoop/exclude
</span><span class='line'>master1
</span></code></pre></td></tr></table></div></figure>


<p>修改完成后，刷新节点即可(完全没有必要重启集dfs)。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hadoop dfsadmin -refreshNodes</span></code></pre></td></tr></table></div></figure>


<p>可以通过<code>dfsadmin -report</code>或者网页查看master1已经变成<em>Decommission In Progress</em>了。</p>

<p><img src="http://file.bmob.cn/M00/05/4C/wKhkA1PXUMOAVvvWAAED6CN-3Rg187.png" alt="" /></p>

<p>注：</p>

<p>问题一： 在新建节点是slaver1的防火墙没关闭，由于master1已经被exclude，而slaver1不能提供服务，上传文件时报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 hadoop]$ hadoop fs -put slaves  /
</span><span class='line'>14/07/29 15:18:21 WARN hdfs.DFSClient: DataStreamer Exception
</span><span class='line'>org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /slaves._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 2 datanode(s) running and no node(s) are excluded in this operation.
</span><span class='line'>        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1384)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2477)</span></code></pre></td></tr></table></div></figure>


<p>关闭防火墙一样再次上传，还是报同样的错误。此时，也可以通过刷新节点<code>hadoop dfsadmin -refreshNodes</code>来解决。</p>

<p>问题二： 设置备份数量</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 hadoop]$ hadoop fs -setrep 3 /slaves 
</span><span class='line'>Replication 3 set: /slaves</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>问题三： 新增节点</p>

<p>拷贝程序到新增节点，然后启动</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 ~]$ tar zc hadoop-2.2.0 --exclude=logs | ssh slaver2 'cat | tar zx'
</span><span class='line'>
</span><span class='line'>[hadoop@slaver2 ~]$ cd hadoop-2.2.0/
</span><span class='line'>[hadoop@slaver2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start datanode</span></code></pre></td></tr></table></div></figure>


<p>也可以修改master上的slavers文件再<code>sbin/start-dfs.sh</code>启动。</p>

<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/27/start-redis/">[读读书]Redis入门指南</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-27T01:20:44+08:00" pubdate data-updated="true">Sun 2014-07-27 01:20</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>《Redis入门指南》的基本使用笔记，<a href="/blog/categories/redis/">jemalloc/tcmalloc功能和redis3集群的安装参考</a>。</p>

<h2>第一章 简介</h2>

<ul>
<li>讲了redis的产生的缘由</li>
<li>Salvtore Sanfilippo/Pieter Noordhuis被招到VMware专门负责redis</li>
<li>redis的源码可以从github下载编译。</li>
</ul>


<p>redis相比keyvalue，提供了更加丰富的值类型：字符串/散列/列表/集合/有序集合，数据提供多种持久化(RDB/AOF)的方式。</p>

<p>在一台普通的笔记本电脑上，Redis可以在一秒内读写超过十万个键值。</p>

<p>功能丰富，提供TTL，可以做(阻塞)队列、缓冲系统、发布/订阅消息模式。redis是单线程模型，相比memcached的多线程，可以启动多个redis实例。</p>

<h2>第二章 准备</h2>

<p>默认的生产环境使用linux，windows操作系统下也有对应的版本但是版本比较旧。
在linux下，下载完成后直接<code>make</code>就可以使用src目录下生成的命令了，<code>make install</code>会把命令拷贝到/usr/local/bin目录下。同时有介绍iOS和Windows下怎么安装redis。</p>

<h3>启动Redis2.8.3</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>src/redis-server # default port 6379
</span><span class='line'>src/redis-server --port 6380</span></code></pre></td></tr></table></div></figure>


<p>初始化脚本启动Redis</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/sh
</span><span class='line'>#
</span><span class='line'># Simple Redis init.d script conceived to work on linux systems
</span><span class='line'># as it does use of the /proc filesystem.
</span><span class='line'>
</span><span class='line'>REDISPORT=6379
</span><span class='line'>EXEC=/usr/local/bin/redis-server
</span><span class='line'>CLIEXEC=/usr/local/bin/redis-cli
</span><span class='line'>
</span><span class='line'>PIDFILE=/var/run/redis_${REDISPORT}.pid
</span><span class='line'>CONF=/etc/redis/${REDISPORT}.conf
</span><span class='line'>
</span><span class='line'>case "$1" in
</span><span class='line'>start)
</span><span class='line'>  if [ -f $PIDFILE ]
</span><span class='line'>  then
</span><span class='line'>      echo "$PIDFILE exists, process is already running or crashed"
</span><span class='line'>  else
</span><span class='line'>      echo "Starting Redis server..."
</span><span class='line'>      $EXEC $CONF
</span><span class='line'>  fi
</span><span class='line'>  ::
</span><span class='line'>stop)
</span><span class='line'>  if [ ! -f $PIDFILE ]
</span><span class='line'>  then
</span><span class='line'>      echo "$PIDFILE does not exists, process is not running"
</span><span class='line'>  else
</span><span class='line'>      PID=$(cat $PIDFILE)
</span><span class='line'>      echo "Stopping..."
</span><span class='line'>      $CLIEXEC -p $REDISPORT shutdown
</span><span class='line'>      while [ -x /proc/$PID ]
</span><span class='line'>      do 
</span><span class='line'>          echo "Waiting for Redis to shutdown..."
</span><span class='line'>          sleep 1
</span><span class='line'>      done
</span><span class='line'>      echo "Redis stopped"
</span><span class='line'>  fi
</span><span class='line'>  ::
</span><span class='line'>*)
</span><span class='line'>  echo "Please use start or stop as first argument"
</span><span class='line'>  ::
</span><span class='line'>esac</span></code></pre></td></tr></table></div></figure>


<h3>停止Redis</h3>

<p>不要直接强制终止程序(<code>kill -9</code>)。使用redis提供的shutdown来停，会等所有操作都flush到磁盘后再关闭。保证数据不会丢失。
当然也可以使用SIGTERM信号来处理，使用<code>kill PID</code>命令，Redis妥善的处理与发送shutdown命令效果一样。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>src/redis-cli shutdown</span></code></pre></td></tr></table></div></figure>


<h3>命令行客户端(cli Command-Line-Interface)</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>redis-cli -h IP -p PORT
</span><span class='line'>
</span><span class='line'>[hadoop@master1 src]$ ./redis-cli PING
</span><span class='line'>PONG
</span><span class='line'>
</span><span class='line'>[hadoop@master1 src]$ ./redis-cli
</span><span class='line'>127.0.0.1:6379&gt; PING
</span><span class='line'>PONG
</span><span class='line'>127.0.0.1:6379&gt; echo hi
</span><span class='line'>"hi"</span></code></pre></td></tr></table></div></figure>


<p>各种返回值</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; errorcommand
</span><span class='line'>(error) ERR unknown command 'errorcommand'
</span><span class='line'>127.0.0.1:6379&gt; incr foo
</span><span class='line'>(integer) 1
</span><span class='line'>127.0.0.1:6379&gt; get foo
</span><span class='line'>"1"
</span><span class='line'>127.0.0.1:6379&gt; get noexists
</span><span class='line'>(nil)
</span><span class='line'>127.0.0.1:6379&gt; keys *
</span><span class='line'>1) "foo"</span></code></pre></td></tr></table></div></figure>


<h3>配置</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>redis-server CONFPATH --loglevel warning</span></code></pre></td></tr></table></div></figure>


<p>也可以通过客户端设置值</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; config set loglevel warning
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; config get loglevel
</span><span class='line'>1) "loglevel"
</span><span class='line'>2) "warning"</span></code></pre></td></tr></table></div></figure>


<h3>多数据库</h3>

<p>默认启动的程序启用了16个库（0-15，<code>databases 16</code>），客户端与Redis建立连接后，会自动选择0号数据库，不过可以通过SELECT命令更换数据库:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; select 1
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379[1]&gt; get foo
</span><span class='line'>(nil)
</span><span class='line'>127.0.0.1:6379[1]&gt; set foo 1
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379[1]&gt; get foo
</span><span class='line'>"1"</span></code></pre></td></tr></table></div></figure>


<p>redis不支持为每个数据库设置不同的访问密码，一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库并不是完全的隔离，比如flushall命令可以清空Redis实例中所有的数据库中的数据。所以这些数据库更像是一个命名空间，而不是适合存储不同应用的数据。</p>

<p>但是可以使用0号数据库存储A应用的生产数据而使用1号数据库存储A应用的测试数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis非常轻量级，一个空Redis实例占用内存只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。</p>

<h2>第三章 入门</h2>

<h3>热身</h3>

<p>获取符合规则的键名（glob风格 ?/*/\X/[]） : <code>KEYS pattern</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379[1]&gt; KEYS *
</span><span class='line'>1) "foq"
</span><span class='line'>2) "foo"
</span><span class='line'>3) "fop"
</span><span class='line'>127.0.0.1:6379[1]&gt; keys fo[a-p]
</span><span class='line'>1) "foo"
</span><span class='line'>2) "fop"
</span><span class='line'>
</span><span class='line'>127.0.0.1:6379[1]&gt; exists foa
</span><span class='line'>(integer) 0 #不存在
</span><span class='line'>127.0.0.1:6379[1]&gt; exists foo
</span><span class='line'>(integer) 1 #存在
</span><span class='line'>
</span><span class='line'>127.0.0.1:6379[1]&gt; del foo
</span><span class='line'>(integer) 1
</span><span class='line'>127.0.0.1:6379[1]&gt; del foa
</span><span class='line'>(integer) 0
</span><span class='line'>127.0.0.1:6379[1]&gt; keys *
</span><span class='line'>1) "fop"</span></code></pre></td></tr></table></div></figure>


<p>keys会遍历Redis中的所有键，当数量比较多是会影响性能，不建议在生产环境使用。</p>

<p>del可以删除多个键值，返回值为删除的个数。del命令的参数不支持通配符，但可以通过linux的实现批量删除<code>redis-cli DEL $(redis-cli KEYS "user:*")</code>（有长度限制）来达到效果，效果比xargs效果更好。</p>

<p>获取keyvalue值的类型</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; set foo 1
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; lpush foo 1
</span><span class='line'>(error) WRONGTYPE Operation against a key holding the wrong kind of value
</span><span class='line'>127.0.0.1:6379&gt; lpush foa 1
</span><span class='line'>(integer) 1
</span><span class='line'>127.0.0.1:6379&gt; type foo
</span><span class='line'>string
</span><span class='line'>127.0.0.1:6379&gt; type foa
</span><span class='line'>list</span></code></pre></td></tr></table></div></figure>


<h3>字符串类型</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>set key value
</span><span class='line'>get key
</span><span class='line'>
</span><span class='line'>incr key # 对应的值需为数值
</span><span class='line'>
</span><span class='line'>set foo 1
</span><span class='line'>incr foo
</span><span class='line'>set foo b
</span><span class='line'>incr foo
</span><span class='line'># (error) ERR value is not an integer or out of range
</span><span class='line'>
</span><span class='line'># 增加指定的整数
</span><span class='line'>
</span><span class='line'>incrby key increment
</span><span class='line'>decr key 
</span><span class='line'>decr key decrement
</span><span class='line'>increbyfloat key increment
</span><span class='line'>
</span><span class='line'>append key value
</span><span class='line'>strlen key # 字节数，和java字符串的length不同
</span><span class='line'>
</span><span class='line'>mget key [key ...]
</span><span class='line'>mset key value [key value ...]
</span><span class='line'>
</span><span class='line'>getbit key offset
</span><span class='line'>setbit key offset value
</span><span class='line'>bitcount key [start] [end]
</span><span class='line'>bitop operation destkey key [key ...] # AND OR XOR NOT
</span><span class='line'>
</span><span class='line'>set foo1 bar
</span><span class='line'>set foo2 aar
</span><span class='line'>BITOP OR res foo1 foo2 # 位操作命令可以非常紧凑地存储布尔值
</span><span class='line'>GET res</span></code></pre></td></tr></table></div></figure>


<h3>散列值</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hset key field value
</span><span class='line'>hget key field
</span><span class='line'>hmset key field value [field value ...]
</span><span class='line'>hmget key field [field ...]
</span><span class='line'>hgetall key
</span><span class='line'>
</span><span class='line'>hexists key field
</span><span class='line'>hsetnx key field value # 当字段不存在时赋值 if not exists
</span><span class='line'>
</span><span class='line'>hincrby key field increment
</span><span class='line'>
</span><span class='line'>hdel key field [field ...]
</span><span class='line'>
</span><span class='line'>hkeys key # 仅key
</span><span class='line'>hvals key # 仅value
</span><span class='line'>hlen key  # 字段数量</span></code></pre></td></tr></table></div></figure>


<h3>列表</h3>

<p>双端队列型列表</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>lpush key value [value ...]
</span><span class='line'>rpush key value [value ...]
</span><span class='line'>lpop key
</span><span class='line'>rpop key
</span><span class='line'>llen key
</span><span class='line'>lrange key start stop # 可以使用负索引，从0开始，包括最右边的元素
</span><span class='line'>
</span><span class='line'>lrem key count value 
</span><span class='line'># 删除列表中前count个值为value的元素，返回的是实际删除的元素个数。
</span><span class='line'># count为负数是从右边开始删除
</span><span class='line'># count为0时删除所有值为value的元素
</span><span class='line'>
</span><span class='line'># 获得/设置指定索引的元素值
</span><span class='line'>
</span><span class='line'>lindex key index # index为负数是从右边开始
</span><span class='line'>lset key index value
</span><span class='line'>
</span><span class='line'>ltrim key start end # 只保留列表指定的片段
</span><span class='line'>linsert key BEFORE/AFTER pivotvalue value
</span><span class='line'>
</span><span class='line'>poplpush source destination # 将元素从给一个列表转到另一个列表</span></code></pre></td></tr></table></div></figure>


<h3>集合类型</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sadd key member [member ...]
</span><span class='line'>srem key member [member ...]
</span><span class='line'>smembers key # 获取集合中的元素
</span><span class='line'>sismember key member # 判断元素是否在集合中
</span><span class='line'>
</span><span class='line'>sdiff key [key ...] # 差集 A-B
</span><span class='line'>sinter key [key ...] # A ∩ B
</span><span class='line'>sunion key [key ...] # A ∪ B
</span><span class='line'>
</span><span class='line'>scard key # 获取集合中元素个数
</span><span class='line'>
</span><span class='line'>sdiffstore destination key [key ...]
</span><span class='line'>sinterstore destination key [key ...]
</span><span class='line'>sunionstore destination key [key ...]
</span><span class='line'>
</span><span class='line'>srandmember key [count] 
</span><span class='line'># 随机获取集合中的元素，count参数来一次性获取多个元素
</span><span class='line'># count为负数时，会随机从集合里获得|count|个的元素，这里元素有可能相同。
</span><span class='line'>
</span><span class='line'>spop key # 从集合中随机弹出一个元素</span></code></pre></td></tr></table></div></figure>


<h3>有序集合</h3>

<p>列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现和“新鲜事”或“日志”这样很少访问中间元素的应用。有序集合类型是使用散列和跳跃表（Skip list）实现的，所以即使读取位于中间的数据也很快（时间复杂度是O(log(N))）。列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数）。有序集合要比列表类型更耗费内存。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>zadd key score member [score member ...]
</span><span class='line'># 如果该元素已经存在则会用新的分数替换原有的分数。zadd命令的返回值是新加入到集合中的元素个数（不包含之前已经存在的元素）。
</span><span class='line'># 其中+inf和-inf分别表示正无穷和负无穷
</span><span class='line'>
</span><span class='line'>zscore key member
</span><span class='line'>
</span><span class='line'>zrange key start stop [withscores] # 获取排名在某个范围的元素列表
</span><span class='line'>zrevrange key start stop [withscores] 
</span><span class='line'># 负数代表从后向前查找（-1表示最后一个元素），O(logn+m)
</span><span class='line'>
</span><span class='line'>zrangebyscore key min max [withscores] [limit offset  count]
</span><span class='line'>
</span><span class='line'># 命令按照元素分数从小到大的顺序返回分数的min和max之间（包含min和max）的元素。
</span><span class='line'># 如果希望分数范围不包含端点值，可以在分数前加上"("符号。例如，希望返回80分到100分的数据，可以含80分，但不包含100分。则稍微修改一下上面的命令即可：
</span><span class='line'>zrangebyscore scoreboard 80 (100
</span><span class='line'>zrangebyscore scoreboard (80 +inf
</span><span class='line'># 本命令中LIMIT offset count与SQL中的用法基本相同。获取分数低于或等于100的前3个人
</span><span class='line'>zrevrangebyscore scoreboard 100 0 limit 0 3
</span><span class='line'>
</span><span class='line'>zincrby key increment memeber # 增加某个元素的分数
</span><span class='line'>
</span><span class='line'>zcard key # 获取集合中元素的数量
</span><span class='line'>zcount key min max # 获得指定分数范围内的元素个数
</span><span class='line'>zrem key member [memeber ...] # 删除一个或多个元素，返回成功删除的元素数量
</span><span class='line'>
</span><span class='line'># 按照排名范围删除元素, 并返回删除的元素数量
</span><span class='line'>zremrangebyrank key start stop
</span><span class='line'># 按照分数范围删除元素
</span><span class='line'>zremrangebyscore key min max
</span><span class='line'>
</span><span class='line'>zrank key member
</span><span class='line'>zrevrank key memeber
</span><span class='line'>
</span><span class='line'>zinterstore destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [aggregate sum|min|max]
</span><span class='line'>zunionstore ...
</span></code></pre></td></tr></table></div></figure>


<h2>第四章 进阶</h2>

<h3>事务</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>multi
</span><span class='line'>sadd "user:1:following" 2
</span><span class='line'>sadd "user:2:followers" 1
</span><span class='line'>exec</span></code></pre></td></tr></table></div></figure>


<p>脚本语法有错，命令不能执行。但是当数据类型等逻辑运行错误时，事务里面的命令会被redis接受并执行。</p>

<p>如果事务里的一条命令出现错误，事务里的其他命令依然会继续执行（包括出错到最后的命令）。对应的返回值会返回错误信息。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; multi
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; set key 1
</span><span class='line'>QUEUED
</span><span class='line'>127.0.0.1:6379&gt; sadd key 2
</span><span class='line'>QUEUED
</span><span class='line'>127.0.0.1:6379&gt; set key 3
</span><span class='line'>QUEUED
</span><span class='line'>127.0.0.1:6379&gt; exec
</span><span class='line'>1) OK
</span><span class='line'>2) (error) WRONGTYPE Operation against a key holding the wrong kind of value
</span><span class='line'>3) OK
</span><span class='line'>127.0.0.1:6379&gt; get key
</span><span class='line'>"3"</span></code></pre></td></tr></table></div></figure>


<p>redis的事务没有回滚的功能，出现错误事务时必须自己负责收拾剩下的摊子（将数据库复原事务执行前的状态等）。不过由于redis不支持回滚功能，也使得redis在事务上可以保持简洁和快速。其中语法错误完全可以再开发时找出并解决。另外如果能够很好的规划数据库（保证键名规范等）的使用，是不会出现命令与数据类型不匹配这样的错误的。</p>

<p><strong>watch命令</strong></p>

<p>在一个事务中只有当所有命令都依次执行完后才能得到每个结果的返回值。可是有些情况下需要先获得一条命令的返回值，然后再根据这个值执行下一条命令。
如increment的操作，在增加1的是时刻没法保证数据还是原来的数据。为了解决这个问题，可以在GET获取值后保证该键值不会被其他客户端修改，知道函数执行完成后才允许其他客户端修改该键值，这样也可以防止竞态条件。watch命令可以监控一个或多个键，一旦其中一个键被修改（或删除），之后的事务就不会被执行。监控一直持续到exec命令。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; watch key
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; set key 2
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; multi
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; set key 3
</span><span class='line'>QUEUED
</span><span class='line'>127.0.0.1:6379&gt; exec
</span><span class='line'>(nil)
</span><span class='line'>127.0.0.1:6379&gt; get key
</span><span class='line'>"2"</span></code></pre></td></tr></table></div></figure>


<p>执行exec命令会取消对所有键的监控，如果不想执行事务中的命令也可以使用unwatch命令来取消监控。</p>

<h3>生存时间TTL</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>expire key seconds
</span><span class='line'>
</span><span class='line'>ttl key
</span><span class='line'>
</span><span class='line'>127.0.0.1:6379&gt; get key
</span><span class='line'>"2"
</span><span class='line'>127.0.0.1:6379&gt; ttl key
</span><span class='line'>(integer) -1
</span><span class='line'>127.0.0.1:6379&gt; expire key 10
</span><span class='line'>(integer) 1
</span><span class='line'>127.0.0.1:6379&gt; ttl key
</span><span class='line'>(integer) 6
</span><span class='line'>127.0.0.1:6379&gt; ttl key
</span><span class='line'>(integer) 1
</span><span class='line'>127.0.0.1:6379&gt; ttl key
</span><span class='line'>(integer) -2
</span><span class='line'>
</span><span class='line'>pexpire milliseconds #时间的单位为毫秒
</span><span class='line'>expireat UTC
</span><span class='line'>pexpireat 毫秒（UTC*1000）</span></code></pre></td></tr></table></div></figure>


<p>除了persist命令之外，使用set和getset命令为键赋值也会同时清除键的生存时间。使用expire命令会重新设置键的生存时间。其他对键值进行操作的命令（如incr、lpush、hset、zrem）均不会影响键的生存时间。</p>

<p>提示： 如果使用watch命令监测一个拥有生存时间的键，该键时间到期自动删除并不会被watch命令认为该键被改变。</p>

<h3>缓冲</h3>

<p>expire + maxmemory maxmemory-policy(LRU)</p>

<h3>排序</h3>

<p>可以使用multi, zintestore, zrange, del, exec来实现，但太麻烦！<a href="https://gist.github.com/winse/30f9db38a4c41aaf5f9d">实际操作日志</a>。</p>

<p>sort命令，可用于集合、列表类型和有序集合类型</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sort key [ALPHA] [BY PREFIXKYE:*-&gt;property] [DESC] [LIMIT offset count] 
</span><span class='line'>
</span><span class='line'>127.0.0.1:6379&gt; lpush mylist 7 1 3 9 0
</span><span class='line'>(integer) 5
</span><span class='line'>127.0.0.1:6379&gt; sort mylist
</span><span class='line'>1) "0"
</span><span class='line'>2) "1"
</span><span class='line'>3) "3"
</span><span class='line'>4) "7"
</span><span class='line'>5) "9"</span></code></pre></td></tr></table></div></figure>


<p>针对有序集合排序时会忽略元素的分数，只针对元素自身的值进行排序。
集合类型中所有元素是无序的，但经常被用于存储对象的ID，很多情况下都是整数。所以redis多这种情况进行了特殊的优化，元素的顺序是有序的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; sadd myset 5 2 6 1 8 1 9 0
</span><span class='line'>(integer) 7
</span><span class='line'>127.0.0.1:6379&gt; smembers myset
</span><span class='line'>1) "0"
</span><span class='line'>2) "1"
</span><span class='line'>3) "2"
</span><span class='line'>4) "5"
</span><span class='line'>5) "6"
</span><span class='line'>6) "8"
</span><span class='line'>7) "9"</span></code></pre></td></tr></table></div></figure>


<p>除了直接对元素排序排序外，还可以通过BY操作来获取关联值来进行排序。BY参数的语法为“BY参考键”，其中参考键可以使字符串类型或者是散列类型键的某个字段（表示为键名->字段名）。如果提供了BY参数，sort命令将不再依据元素自身的值进行排序，而是对每个元素使用元素的值替换参考键中的第一个<code>*</code>并获取取值，然后依据该值对元素排序。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sort tag:ruby:posts BY post:*-&gt;time desc
</span><span class='line'>sort sortbylist BY itemsore:* desc</span></code></pre></td></tr></table></div></figure>


<p>当参考键不包括<code>*</code>时（即常量键名，与元素值无关）。SORT命令将不会执行排序操作，因为redis认为这种情况没有意义（因为所有要比较的值都一样）。没有执行排序操作，在不需要排序但需要借组sort命令获得与元素相关联的数据时，常量键名是很有用的！</p>

<p>如果几个元素的参考键值相同，则SORT命令会在比较元素本身的值来决定元素的顺序。
当某个元素的参考键不存在时，会默认参考键的值为0。
参考键虽然支持散列类型，但是<code>*</code>只能在<code>-&gt;</code>符号前面（即键名部分）才有用，在<code>-&gt;</code>后（即字段名部分）会被当成字段名本身名本身而不会作为占位符被元素的值替换，即常量键名。但是实际运行时会发现一个有趣的结果。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sort sortbylist BY somekey-&gt;somefield:* </span></code></pre></td></tr></table></div></figure>


<p>上面提到了当参考键名是常量键名时SORT命令将不会执行排序操作，然而上例中却是进行了排序，而且只是对元素本身进行排序。这是因为Redis判断参考键名是不是常量键名的方式是判断参考键名中是否包含<code>*</code>，而<code>somekey-&gt;somefield:*</code>中包含<code>*</code>所以不是常量键名。所以在排序的时刻Redis对每个元素都会读取键somekey中的<code>somefield:*</code>字段（<code>*</code>不会被替换）。无论能否获得其值，每个元素的参考键值是相同的，所以redis被按照元素本身的大小排序。</p>

<p>GET参考不影响排序，它的作用是使SORT命令的返回结果不在是元素自身的值。而是GET参数中指定的键值。GET参数的规则和BY参数一样，GET参数也支持字符串类型和散列类型的值，并使用<code>*</code>作为占位符。要实现在排序后直接返回ID对应的违章标题，可以这样写：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; lpush tag:ruby:posts 1 2 3
</span><span class='line'>(integer) 3
</span><span class='line'>127.0.0.1:6379&gt; hmset post:1 time 140801 name HelloWorld
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; hmset post:2 time 140802 name HelloWorld2
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; hmset post:3 time 140803 name HelloWorld3
</span><span class='line'>OK
</span><span class='line'>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc
</span><span class='line'>1) "3"
</span><span class='line'>2) "2"
</span><span class='line'>3) "1"
</span><span class='line'>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time DESC GET post:*-&gt;name
</span><span class='line'>1) "HelloWorld3"
</span><span class='line'>2) "HelloWorld2"
</span><span class='line'>3) "HelloWorld"</span></code></pre></td></tr></table></div></figure>


<p>一个sort命令中可以有多个GET参数（而BY参数只能有一个），所以还可以这样用：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc GET post:*-&gt;name GET post:*-&gt;time
</span><span class='line'>1) "HelloWorld3"
</span><span class='line'>2) "140803"
</span><span class='line'>3) "HelloWorld2"
</span><span class='line'>4) "140802"
</span><span class='line'>5) "HelloWorld"
</span><span class='line'>6) "140801"</span></code></pre></td></tr></table></div></figure>


<p>如果还需要返回文章ID，可以使用<code>GET #</code>获得，也就是返回元素本身的值。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc GET post:*-&gt;name GET post:*-&gt;time GET #
</span><span class='line'>1) "HelloWorld3"
</span><span class='line'>2) "140803"
</span><span class='line'>3) "3"
</span><span class='line'>4) "HelloWorld2"
</span><span class='line'>5) "140802"
</span><span class='line'>6) "2"
</span><span class='line'>7) "HelloWorld"
</span><span class='line'>8) "140801"
</span><span class='line'>9) "1"</span></code></pre></td></tr></table></div></figure>


<p>默认情况下SORT会直接返回排序结果，如果希望保存排序结果，可以使用STORE参数。保存后的键的类型为列表类型，如果键已经存在则会覆盖它，加上STORE参数后的SORT命令的返回值的结果的个数。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc GET post:*-&gt;name GET post:*-&gt;time GET # STORE tag.ruby.posts.sort
</span><span class='line'>(integer) 9
</span><span class='line'>127.0.0.1:6379&gt; lrange tag.ruby.posts.sort 0 -1
</span><span class='line'>1) "HelloWorld3"
</span><span class='line'>2) "140803"
</span><span class='line'>3) "3"
</span><span class='line'>4) "HelloWorld2"
</span><span class='line'>5) "140802"
</span><span class='line'>6) "2"
</span><span class='line'>7) "HelloWorld"
</span><span class='line'>8) "140801"
</span><span class='line'>9) "1"</span></code></pre></td></tr></table></div></figure>


<p>SORT命令的时间复杂度是O(n+mlogm)，其中n表示要排序的列表（集合或有序集合）中的元素个数，m表示要返回的元素个数。当n较大时SORT命令的性能相对较低，并且redis在排序前会建立一个长度为n的容器来存储排序的元素（当键类型为有序集合且参考键为常量键名时容器大小为m而不是n），虽然是一个临时的过程，但如果同时进行较多的大数据量排序操作则会严重影响性能。</p>

<h3>消息通知</h3>

<p>producer/consumer，松耦合，易于扩展，而且可以分布在不同的服务器中！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>BLPOP key [key ...] timeout
</span><span class='line'>BRPOP key [key ...] timeoutseconds
</span><span class='line'># 超时时间设置为0时，表示不限制等待的时间，即如果没有新元素加入列表就会永远阻塞下去。</span></code></pre></td></tr></table></div></figure>


<p>BRPOP可以同时接收多个键，同时检测多个键，如果所有键都没有元素则阻塞，其中有一个键有元素则会从该键中弹出元素。如果存在键都有元素则从左到右的顺序取第一个键中的一个元素。借此特性可以实现优先级的队列任务。</p>

<p>publish/subscribe模式，发布/订阅模式同样可以实现进程间的消息传递。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PUBLISH channel.1 hi
</span><span class='line'>SUBSCRIBE channel.1</span></code></pre></td></tr></table></div></figure>


<p>执行SUBSCRIBE命令后，客户端会进入订阅状态，处于此状态下客户端不能使用SUBSCRIBE/UNSUBSCRIBE/PSUBSCRIBE（支持glob风格通配符格式）/PUNSUBSCRIBE这4个属于发布/订阅模式的命令之外的命令，否则会报错。</p>

<p>消息类型： subscribe/message/unsubscribe</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>psubscribe channel.?*</span></code></pre></td></tr></table></div></figure>


<h3>管道pipelining</h3>

<p>在执行多个命令时每条命令都需要等待上一条命令执行完才能执行，即使命令不需要上一条命令的执行结果。通过管道可以一次性发送多条命令并在执行完后一次性将结果返回，当一组命令中每条命令都不依赖与之前命令的执行结果就可以将这一组命令一起通过管道发出。管道通过减少客户端与redis的通信次数来实现降低往返时延。（</p>

<h3>节省空间</h3>

<ul>
<li>精简键名和键值 <code>VIP&lt;-very.important.person</code></li>
<li>内部编码优化（存储和效率的取舍）</li>
</ul>


<p>如果想查看一个键的内部编码方式可以使用<code>OBJECT ENCODING foo</code></p>

<h2>第五章 实践</h2>

<ul>
<li>php用户登录，忘记密码邮件发送队列</li>
<li>ruby自动完成</li>
<li>python在线好友</li>
<li>nodejs的IP段地址查询</li>
</ul>


<h2>第六章 脚本</h2>

<p>代码块多次请求，以及事务竞态等问题，需要用到WATCH，多次请求在网络传输上浪费很多时间。redis的脚本类似于数据库的function，在服务端执行。这种方式不仅代码简单、没有竞态条件（redis的命令都是原子的），而且减少了通过网络发送和接收命令的传输开销。</p>

<p>从2.6开始，允许开发者使用Lua语言编写脚本传到redis中执行。在Lua脚本中可以调用大部分的redis命令。减少网络传输时延，原子操作，复用（发送的脚本永久存储在redis中，其他客户端可以复用）。</p>

<p><strong>访问频率</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>localtimes=redis.call('incr', KEYS[1])
</span><span class='line'>if times==1 then
</span><span class='line'>redis.call('expire', KEYS[1], ARGV[1])
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>if times&gt;tonumber(ARGV[2]) then
</span><span class='line'>return 0
</span><span class='line'>end
</span><span class='line'>
</span><span class='line'>return 1
</span><span class='line'># redis-cli --eval ratelimiting.lua rate.limiting:127.0.0.1 , 10 3 逗号前的是键，后面的是参数</span></code></pre></td></tr></table></div></figure>


<h3>lua语法（和shell脚本有点像，更简洁）</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>本地变量 local x=10
</span><span class='line'>注释 --xxx
</span><span class='line'>多行注释 --[[xxxx]]
</span><span class='line'>赋值 local a,b=1,2 # a=1, b=2
</span><span class='line'>   local a={1,2,3}
</span><span class='line'>   a[1]=5
</span><span class='line'>数字操作符的操作数如果是字符串会自动转成数字
</span><span class='line'>tonumber
</span><span class='line'>tostring
</span><span class='line'>只要操作数不是nil或者false，逻辑操作符就认为操作数为真，否则为假！
</span><span class='line'>用..来实现字符串连接
</span><span class='line'>取长度 print(#"hello") -- 5
</span></code></pre></td></tr></table></div></figure>


<h3>使用脚本</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>EVAL script numkeys key [key ...] arg [arg ...]
</span><span class='line'>
</span><span class='line'>redis&gt; eval "return redis.call('SET', KEYS[1], ARGV[1])" 1 foo bar
</span><span class='line'>
</span><span class='line'>EVALSHA sha1 numkeys key [key ...] arg [arg ...]</span></code></pre></td></tr></table></div></figure>


<p>同时获取多个散列类型键的键值</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>local result={}
</span><span class='line'>for i,v in ipairs(KEYS) do
</span><span class='line'>result[i]=redis.call("HGETALL", v)
</span><span class='line'>end
</span><span class='line'>return result</span></code></pre></td></tr></table></div></figure>


<p>获取并删除有序集合中分数最小的元素</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>local element=redis.call("ZRANGE", KEY[1], 0, 0)[1]
</span><span class='line'>if element the
</span><span class='line'>redis.call('ZREM', KEYS[1], element)
</span><span class='line'>end
</span><span class='line'>return element</span></code></pre></td></tr></table></div></figure>


<p>处理JSON</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>local sum=0
</span><span class='line'>local users=redis.call('mget', unpack(KEYS))
</span><span class='line'>for _,user in ipairs(users) do 
</span><span class='line'>local courses=cjson.decode(user).course
</span><span class='line'>for _,score in pairs(courses) do
</span><span class='line'>sum=sum+score
</span><span class='line'>end
</span><span class='line'>end
</span><span class='line'>return sum</span></code></pre></td></tr></table></div></figure>


<p>redis脚本禁用使用lua标准库中与文件或系统调用相关的函数，在脚本中只允许对redis的数据进行处理。并且redis还通过禁用脚本的全局变量的方式保证每个脚本都是相对隔离的们不会互相干扰。
使用沙盒不仅是为了保证服务器的安全性，而且还确保了脚本的执行结果值和脚本本身和执行时传递的参数有关，不依赖外界条件（如系统时间、系统中某个文件的内存。。）。这是因为在执行复制和AOF持久化操作时记录的是脚本的内容而不是脚本调用的命令，所以必须保证在脚本内容和参数一样的前提下脚本的执行进行特殊的处理。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>script load 'return 1'
</span><span class='line'>script exists sha1
</span><span class='line'>script flush #清空脚本缓冲
</span><span class='line'>
</span><span class='line'>script kill
</span><span class='line'>script nosave</span></code></pre></td></tr></table></div></figure>


<p>为了限制某个脚本执行时间过长导致redis无法提供服务（如死循环），redis提供了lua-time-limit参数限制脚本的最长运行时间，默认5s。</p>

<h2>第七章 管理</h2>

<ul>
<li>持久化 rdb/AOF</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>save 900 1
</span><span class='line'>save 300 10
</span><span class='line'>save 60 10000
</span><span class='line'>SAVE
</span><span class='line'>BGSAVE
</span><span class='line'>appendonly yes
</span><span class='line'>appendfilename appendonly.aof
</span><span class='line'>auto-aof-rewrite-percentage 100
</span><span class='line'>auto-aof-rewrite-min-size 64mb
</span><span class='line'>BGREWRITEAOF
</span><span class='line'>#appendfsync always
</span><span class='line'>appendfsync everysec
</span><span class='line'>#appendfsync no</span></code></pre></td></tr></table></div></figure>


<ul>
<li>复制</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>redis-server --port 6380 --slaveof 127.0.0.1 6379
</span><span class='line'>SLAVEOF 127.0.0.1 6379
</span><span class='line'>SLAVEOF NO ONE</span></code></pre></td></tr></table></div></figure>


<ul>
<li>读写分离</li>
<li>耗时日志查询</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SLOWLOG GET # slowlog-log-slower-than slowlog-max-len
</span><span class='line'>MONITOR</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/25">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/23">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2016/04/23/hadoop-guide-catalog/">[整理] Hadoop入门</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/03/28/hive-on-spark/">Hive on Spark</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/08/24/manual-install-supervisor/">Supervisor安装配置</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/10/16/spark-build-and-configuration/">编译/搭建Spark环境</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/08/25/step-by-step-found-java-oom-error/">查找逐步定位Java程序OOM的异常实践</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/27/start-redis/">[读读书]Redis入门指南</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/18/jekyll-edit-link-in-web-page/">Jekyll页面添加编辑按钮</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/02/25/k8s-docker-multinode/">K8s集群部署</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/02/08/k8s-minikube-on-windows/">K8s Minikube on Windows</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/02/06/docker-http-proxy-and-save-reload/">Docker代理配置以及导入导出</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks/">使用Privoxy把shadowsocks转换为Http代理</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/27/vnc-server-on-centos7/">在Centos7上安装VNC Server</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/25/develop-environment-prepare/">[整理] 环境准备工具集</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/21/jarsperreports-pdf-chinese/">jarsperreports生成PDF中文问题</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/20/nginx-https-with-tomcat-http/">Nginx Https With Tomcat Http</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/bigdata/'>bigdata</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/flume/'>flume</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (42) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (10) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (44) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/zookeeper/'>zookeeper</a> (1) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (163)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Softs, I&#8217;m using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253461959'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1253461959%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  

<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"winseliu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->










</body>
</html>
