
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="容器中的应用数据得保存下来，使用local/hostPath可以临时用用，还是得有一个共享的存储。 https://kubernetes.io/zh/docs/concepts/storage/volumes/#volume-types
https://kubernetes.io/zh/docs/ &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winse.github.io/posts/3">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/libs/jquery.toc.min.js" type="text/javascript"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->

<script src="/javascripts/generate-toc.js" type="text/javascript"></script>


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winse.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2022/04/14/k8s-nfs/">k8s共享存储使用NFS</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2022-04-14T01:23:14+08:00" pubdate data-updated="true">Thu 2022-04-14 01:23</time>
		
        
		
      </p>
    
  </header>


  <div class="entry-content"><p>容器中的应用数据得保存下来，使用local/hostPath可以临时用用，还是得有一个共享的存储。</p>

<ul>
<li><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/#volume-types">https://kubernetes.io/zh/docs/concepts/storage/volumes/#volume-types</a></li>
<li><a href="https://kubernetes.io/zh/docs/concepts/storage/_print/#types-of-persistent-volumes">https://kubernetes.io/zh/docs/concepts/storage/_print/#types-of-persistent-volumes</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner">https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath">https://kubernetes.io/docs/concepts/storage/volumes/#hostpath</a></li>
<li><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/#local">https://kubernetes.io/zh/docs/concepts/storage/volumes/#local</a></li>
<li><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/#cephfs">https://kubernetes.io/zh/docs/concepts/storage/volumes/#cephfs</a></li>
</ul>


<p>先使用最简单的NFS分区/卷。</p>

<ul>
<li><a href="http://www.lishuai.fun/2021/08/12/k8s-nfs-pv">http://www.lishuai.fun/2021/08/12/k8s-nfs-pv</a></li>
</ul>


<h2>安装NFS server on aws ec2</h2>

<ul>
<li><a href="https://segmentfault.com/a/1190000024512057">https://segmentfault.com/a/1190000024512057</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#所有node节点安装nfs客户端
</span><span class='line'>#yum -y install nfs-utils
</span><span class='line'>#systemctl start nfs && systemctl enable nfs
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo yum install nfs-utils 
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>amzn2-core                                                                                                                     | 3.7 kB  00:00:00     
</span><span class='line'>Package 1:nfs-utils-1.3.0-0.54.amzn2.0.2.x86_64 already installed and latest version
</span><span class='line'>Nothing to do
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo mkdir /backup
</span><span class='line'>[ec2-user@k8s ~]$ sudo chmod -R 755 /backup
</span><span class='line'>[ec2-user@k8s ~]$ sudo chown nfsnobody:nfsnobody /backup
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo vi /etc/exports
</span><span class='line'>[ec2-user@k8s ~]$ cat /etc/exports    
</span><span class='line'>/backup 192.168.191.0/24(rw,sync,no_root_squash,no_all_squash)
</span><span class='line'>
</span><span class='line'># /k8s-fs *(rw,sync,no_root_squash,no_all_squash)
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo service nfs-server restart 
</span><span class='line'>Redirecting to /bin/systemctl restart nfs-server.service
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>[ec2-user@k8s ~]$ sudo exportfs
</span><span class='line'>/backup         192.168.191.0/24
</span><span class='line'>[ec2-user@k8s ~]$ sudo exportfs -arv 
</span><span class='line'>exporting 192.168.191.0/24:/backup
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ rpcinfo -p localhost
</span><span class='line'>   program vers proto   port  service
</span><span class='line'>    100000    4   tcp    111  portmapper
</span><span class='line'>    100000    3   tcp    111  portmapper
</span><span class='line'>    100000    2   tcp    111  portmapper
</span><span class='line'>    100000    4   udp    111  portmapper
</span><span class='line'>    100000    3   udp    111  portmapper
</span><span class='line'>    100000    2   udp    111  portmapper
</span><span class='line'>    100024    1   udp  56847  status
</span><span class='line'>    100024    1   tcp  60971  status
</span><span class='line'>    100005    1   udp  20048  mountd
</span><span class='line'>    100005    1   tcp  20048  mountd
</span><span class='line'>    100005    2   udp  20048  mountd
</span><span class='line'>    100005    2   tcp  20048  mountd
</span><span class='line'>    100005    3   udp  20048  mountd
</span><span class='line'>    100005    3   tcp  20048  mountd
</span><span class='line'>    100003    3   tcp   2049  nfs
</span><span class='line'>    100003    4   tcp   2049  nfs
</span><span class='line'>    100227    3   tcp   2049  nfs_acl
</span><span class='line'>    100003    3   udp   2049  nfs
</span><span class='line'>    100227    3   udp   2049  nfs_acl
</span><span class='line'>    100021    1   udp  47545  nlockmgr
</span><span class='line'>    100021    3   udp  47545  nlockmgr
</span><span class='line'>    100021    4   udp  47545  nlockmgr
</span><span class='line'>    100021    1   tcp  40703  nlockmgr
</span><span class='line'>    100021    3   tcp  40703  nlockmgr
</span><span class='line'>    100021    4   tcp  40703  nlockmgr
</span><span class='line'>[ec2-user@k8s ~]$ showmount -e 192.168.191.131
</span><span class='line'>Export list for 192.168.191.131:
</span><span class='line'>/backup 192.168.191.0/24
</span></code></pre></td></tr></table></div></figure>


<p>也可以通过docker来启动nfs server：</p>

<ul>
<li><a href="https://blog.ruanbekker.com/blog/2020/09/20/setup-a-nfs-server-with-docker/">https://blog.ruanbekker.com/blog/2020/09/20/setup-a-nfs-server-with-docker/</a></li>
<li><a href="https://westzq1.github.io/k8s/2019/06/28/nfs-server-on-K8S.html">https://westzq1.github.io/k8s/2019/06/28/nfs-server-on-K8S.html</a></li>
<li><a href="https://github.com/kubernetes/examples/blob/master/staging/volumes/nfs/nfs-server-deployment.yaml">https://github.com/kubernetes/examples/blob/master/staging/volumes/nfs/nfs-server-deployment.yaml</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ sudo mkdir -p /data/kubernetes-volumes
</span><span class='line'>[ec2-user@k8s ~]$ docker run --privileged -itd --name nfs -p 2049:2049 -e SHARED_DIRECTORY=/data -v /data/kubernetes-volumes:/data itsthenetwork/nfs-server-alpine:12 
</span><span class='line'>f84b70dcca6bd5abb275fbee50fd161d8befdd709ce6523b3a514f04b7af8677
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ docker logs f84b70dcca6bd5abb2 
</span><span class='line'>Writing SHARED_DIRECTORY to /etc/exports file
</span><span class='line'>The PERMITTED environment variable is unset or null, defaulting to '*'.
</span><span class='line'>This means any client can mount.
</span><span class='line'>The READ_ONLY environment variable is unset or null, defaulting to 'rw'.
</span><span class='line'>Clients have read/write access.
</span><span class='line'>The SYNC environment variable is unset or null, defaulting to 'async' mode.
</span><span class='line'>Writes will not be immediately written to disk.
</span><span class='line'>Displaying /etc/exports contents:
</span><span class='line'>/data *(rw,fsid=0,async,no_subtree_check,no_auth_nlm,insecure,no_root_squash)
</span><span class='line'>
</span><span class='line'>Starting rpcbind...
</span><span class='line'>Displaying rpcbind status...
</span><span class='line'>   program version netid     address                service    owner
</span><span class='line'>    100000    4    tcp6      ::.0.111               -          superuser
</span><span class='line'>    100000    3    tcp6      ::.0.111               -          superuser
</span><span class='line'>    100000    4    udp6      ::.0.111               -          superuser
</span><span class='line'>    100000    3    udp6      ::.0.111               -          superuser
</span><span class='line'>    100000    4    tcp       0.0.0.0.0.111          -          superuser
</span><span class='line'>    100000    3    tcp       0.0.0.0.0.111          -          superuser
</span><span class='line'>    100000    2    tcp       0.0.0.0.0.111          -          superuser
</span><span class='line'>    100000    4    udp       0.0.0.0.0.111          -          superuser
</span><span class='line'>    100000    3    udp       0.0.0.0.0.111          -          superuser
</span><span class='line'>    100000    2    udp       0.0.0.0.0.111          -          superuser
</span><span class='line'>    100000    4    local     /var/run/rpcbind.sock  -          superuser
</span><span class='line'>    100000    3    local     /var/run/rpcbind.sock  -          superuser
</span><span class='line'>Starting NFS in the background...
</span><span class='line'>rpc.nfsd: knfsd is currently down
</span><span class='line'>rpc.nfsd: Writing version string to kernel: -2 -3 +4 +4.1 +4.2
</span><span class='line'>rpc.nfsd: Created AF_INET TCP socket.
</span><span class='line'>rpc.nfsd: Created AF_INET6 TCP socket.
</span><span class='line'>Exporting File System...
</span><span class='line'>exporting *:/data
</span><span class='line'>/data           &lt;world&gt;
</span><span class='line'>Starting Mountd in the background...These
</span><span class='line'>Startup successful.
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo mount -v -o vers=4,loud 127.0.0.1:/ nfsmnt
</span><span class='line'>mount.nfs: timeout set for Thu Apr 14 08:26:48 2022
</span><span class='line'>mount.nfs: trying text-based options 'vers=4.1,addr=127.0.0.1,clientaddr=127.0.0.1'
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ df -h | grep nfsmnt
</span><span class='line'>127.0.0.1:/      25G  9.8G   16G  39% /home/ec2-user/nfsmnt
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ touch nfsmnt/$(hostname).txt
</span><span class='line'>[ec2-user@k8s ~]$ ls -l nfsmnt/
</span><span class='line'>total 0
</span><span class='line'>-rw-rw-r-- 1 ec2-user ec2-user 0 Apr 14 08:25 k8s.txt
</span><span class='line'>[ec2-user@k8s ~]$ ls -l /data/kubernetes-volumes/
</span><span class='line'>total 0
</span><span class='line'>-rw-rw-r-- 1 ec2-user ec2-user 0 Apr 14 08:25 k8s.txt
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>
</span><span class='line'># vi /etc/fstab
</span><span class='line'># 192.168.0.4:/   /mnt   nfs4    _netdev,auto  0  0
</span><span class='line'>
</span><span class='line'>### pod
</span><span class='line'># kubectl create -f nfs-server.yml
</span><span class='line'>apiVersion: extensions/v1beta1
</span><span class='line'>kind: Deployment
</span><span class='line'>metadata:
</span><span class='line'>  name: nfs-server
</span><span class='line'>spec:
</span><span class='line'>  replicas: 1           # &lt;- no more replicas
</span><span class='line'>  template:
</span><span class='line'>    metadata:
</span><span class='line'>      labels:
</span><span class='line'>        app: nfs-server
</span><span class='line'>    spec:
</span><span class='line'>      nodeSelector:     # &lt;- use selector to fix nfs-server on k8s2.zhangqiaoc.com
</span><span class='line'>        kubernetes.io/hostname: k8s2.zhangqiaoc.com
</span><span class='line'>      containers:
</span><span class='line'>      - name: nfs-server
</span><span class='line'>        image: itsthenetwork/nfs-server-alpine:latest
</span><span class='line'>        volumeMounts:
</span><span class='line'>        - name: nfs-storage
</span><span class='line'>          mountPath: /nfsshare
</span><span class='line'>        env:
</span><span class='line'>        - name: SHARED_DIRECTORY
</span><span class='line'>          value: "/nfsshare"
</span><span class='line'>        ports:
</span><span class='line'>        - name: nfs  
</span><span class='line'>          containerPort: 2049   # &lt;- export port
</span><span class='line'>        securityContext:
</span><span class='line'>          privileged: true      # &lt;- privileged mode is mandentory.
</span><span class='line'>      volumes:
</span><span class='line'>      - name: nfs-storage  
</span><span class='line'>        hostPath:               # &lt;- the folder on the host machine.
</span><span class='line'>          path: /root/fileshare
</span><span class='line'># kubectl expose deployment nfs-server --type=ClusterIP
</span><span class='line'># kubectl get svc
</span><span class='line'>
</span><span class='line'># yum install -y nfs-utils
</span><span class='line'># mkdir /root/nfsmnt
</span><span class='line'># mount -v 10.101.117.226:/ /root/nfsmnt
</span></code></pre></td></tr></table></div></figure>


<p>client</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 所有work节点安装 nfs-utils rpcbind
</span><span class='line'>[ec2-user@worker1 ~]$ sudo yum install nfs-utils 
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>amzn2-core                                                                                                                                        | 3.7 kB  00:00:00     
</span><span class='line'>Package 1:nfs-utils-1.3.0-0.54.amzn2.0.2.x86_64 already installed and latest version
</span><span class='line'>Nothing to do
</span><span class='line'>
</span><span class='line'>[ec2-user@worker1 ~]$ sudo systemctl status nfs
</span><span class='line'>● nfs-server.service - NFS server and services
</span><span class='line'>   Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; disabled; vendor preset: disabled)
</span><span class='line'>   Active: inactive (dead)
</span><span class='line'>[ec2-user@worker1 ~]$ sudo systemctl status rpcbind
</span><span class='line'>● rpcbind.service - RPC bind service
</span><span class='line'>   Loaded: loaded (/usr/lib/systemd/system/rpcbind.service; enabled; vendor preset: enabled)
</span><span class='line'>   Active: active (running) since Wed 2022-04-13 20:44:34 CST; 1h 51min ago
</span><span class='line'>  Process: 6979 ExecStart=/sbin/rpcbind -w $RPCBIND_ARGS (code=exited, status=0/SUCCESS)
</span><span class='line'> Main PID: 7025 (rpcbind)
</span><span class='line'>    Tasks: 1
</span><span class='line'>   Memory: 2.1M
</span><span class='line'>   CGroup: /system.slice/rpcbind.service
</span><span class='line'>           └─7025 /sbin/rpcbind -w
</span><span class='line'>
</span><span class='line'>Apr 13 20:44:34 worker1 systemd[1]: Starting RPC bind service...
</span><span class='line'>Apr 13 20:44:34 worker1 systemd[1]: Started RPC bind service.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@worker1 ~]$ sudo mkdir -p /data
</span><span class='line'>[ec2-user@worker1 ~]$ sudo chmod 777 /data 
</span><span class='line'>[ec2-user@worker1 ~]$ sudo mount -t nfs 192.168.191.131:/backup /data
</span><span class='line'>[ec2-user@worker1 ~]$ df -h | grep 192.168.191.131
</span><span class='line'>192.168.191.131:/backup   25G  9.6G   16G  39% /data
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># vi /etc/fstab
</span><span class='line'># 172.17.30.22:/backup /data nfs defaults 0 0
</span></code></pre></td></tr></table></div></figure>


<h2>k8s中使用NFS</h2>

<ul>
<li><a href="http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/">http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/</a></li>
</ul>


<h3>容器直接挂载NFS</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ cat nginx-1.yml 
</span><span class='line'>apiVersion: apps/v1
</span><span class='line'>kind: Deployment
</span><span class='line'>metadata:
</span><span class='line'>  name: nginx-deployment
</span><span class='line'>  labels:
</span><span class='line'>    app: nginx
</span><span class='line'>spec:
</span><span class='line'>  replicas: 3
</span><span class='line'>  selector:
</span><span class='line'>    matchLabels:
</span><span class='line'>      app: nginx
</span><span class='line'>  template:
</span><span class='line'>    metadata:
</span><span class='line'>      labels:
</span><span class='line'>        app: nginx
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - name: nginx
</span><span class='line'>        image: nginx:1.14.2
</span><span class='line'>        ports:
</span><span class='line'>        - containerPort: 80
</span><span class='line'>        volumeMounts:
</span><span class='line'>        - name: data
</span><span class='line'>          mountPath: /usr/share/nginx/html
</span><span class='line'>      volumes:
</span><span class='line'>      - name: data
</span><span class='line'>        nfs:
</span><span class='line'>          path: /backup
</span><span class='line'>          server: 192.168.191.131
</span><span class='line'>        
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f nginx-1.yml
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get all 
</span><span class='line'>NAME                                   READY   STATUS    RESTARTS   AGE
</span><span class='line'>pod/nginx-deployment-67dcb957c-g2h8x   1/1     Running   0          2m50s
</span><span class='line'>pod/nginx-deployment-67dcb957c-gfv28   1/1     Running   0          2m50s
</span><span class='line'>pod/nginx-deployment-67dcb957c-rqwjs   1/1     Running   0          2m50s
</span><span class='line'>
</span><span class='line'>NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
</span><span class='line'>service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   27d
</span><span class='line'>
</span><span class='line'>NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
</span><span class='line'>deployment.apps/nginx-deployment   3/3     3            3           2m50s
</span><span class='line'>
</span><span class='line'>NAME                                         DESIRED   CURRENT   READY   AGE
</span><span class='line'>replicaset.apps/nginx-deployment-67dcb957c   3         3         3       2m50s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl exec -ti pod/nginx-deployment-67dcb957c-g2h8x -- bash 
</span><span class='line'>root@nginx-deployment-67dcb957c-g2h8x:/# echo $(hostname) &gt;/usr/share/nginx/html/1.txt
</span><span class='line'>
</span><span class='line'>root@nginx-deployment-67dcb957c-g2h8x:/# mount | grep 192
</span><span class='line'>192.168.191.131:/backup on /usr/share/nginx/html type nfs4 (rw,relatime,vers=4.1,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.191.132,local_lock=none,addr=192.168.191.131)
</span><span class='line'>root@nginx-deployment-67dcb957c-g2h8x:/# 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 服务端查看文件内容
</span><span class='line'>[ec2-user@k8s ~]$ cat /backup/1.txt 
</span><span class='line'>nginx-deployment-67dcb957c-g2h8x
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl delete -f nginx-1.yml 
</span><span class='line'>deployment.apps "nginx-deployment" deleted
</span></code></pre></td></tr></table></div></figure>


<h3>pvc</h3>

<ul>
<li><a href="https://segmentfault.com/a/1190000040785500">https://segmentfault.com/a/1190000040785500</a></li>
<li><a href="http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/#%E5%88%9B%E5%BB%BA%E7%B1%BB%E5%9E%8B%E4%B8%BAnfs%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E5%8D%B7">http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/#%E5%88%9B%E5%BB%BA%E7%B1%BB%E5%9E%8B%E4%B8%BAnfs%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E5%8D%B7</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ vi pv-nfs.yaml 
</span><span class='line'>[ec2-user@k8s ~]$ cat pv-nfs.yaml 
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: PersistentVolume
</span><span class='line'>metadata:
</span><span class='line'>  name: pv-nfs
</span><span class='line'>spec:
</span><span class='line'>  capacity:
</span><span class='line'>    storage: 10Gi
</span><span class='line'>  accessModes:
</span><span class='line'>    - ReadWriteMany 
</span><span class='line'>  nfs:
</span><span class='line'>    path: /backup
</span><span class='line'>    server: 192.168.191.131
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f pv-nfs.yaml 
</span><span class='line'>persistentvolume/pv-nfs created
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pv 
</span><span class='line'>NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
</span><span class='line'>pv-nfs   10Gi       RWX            Retain           Available                                   5s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ vi pvc-nfs.yaml 
</span><span class='line'>[ec2-user@k8s ~]$ cat pvc-nfs.yaml 
</span><span class='line'>kind: PersistentVolumeClaim
</span><span class='line'>apiVersion: v1
</span><span class='line'>metadata:
</span><span class='line'>  name: pvc-nfs
</span><span class='line'>spec:
</span><span class='line'>  accessModes:
</span><span class='line'>    - ReadWriteMany
</span><span class='line'>  resources:
</span><span class='line'>    requests:
</span><span class='line'>      storage: 10Gi
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f pvc-nfs.yaml 
</span><span class='line'>persistentvolumeclaim/pvc-nfs created
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pvc
</span><span class='line'>NAME      STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
</span><span class='line'>pvc-nfs   Bound    pv-nfs   10Gi       RWX                           7s
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pv 
</span><span class='line'>NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS   REASON   AGE
</span><span class='line'>pv-nfs   10Gi       RWX            Retain           Bound    default/pvc-nfs                           79s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ vi dp-pvc.yaml
</span><span class='line'>[ec2-user@k8s ~]$ cat dp-pvc.yaml 
</span><span class='line'>apiVersion: apps/v1
</span><span class='line'>kind: Deployment
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  labels:
</span><span class='line'>    app: busybox
</span><span class='line'>spec:
</span><span class='line'>  replicas: 1
</span><span class='line'>  selector:
</span><span class='line'>    matchLabels:
</span><span class='line'>      app: busybox
</span><span class='line'>  template:
</span><span class='line'>    metadata:
</span><span class='line'>      labels:
</span><span class='line'>        app: busybox
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - name: busybox
</span><span class='line'>        image: busybox
</span><span class='line'>        command: ['sh', '-c', 'echo "Hello, Kubernetes!" && sleep 3600']
</span><span class='line'>        volumeMounts:
</span><span class='line'>        - name: data
</span><span class='line'>          mountPath: /data
</span><span class='line'>      volumes:
</span><span class='line'>      - name: data
</span><span class='line'>        persistentVolumeClaim:
</span><span class='line'>          claimName: pvc-nfs
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f dp-pvc.yaml 
</span><span class='line'>deployment.apps/busybox created
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get all 
</span><span class='line'>NAME                           READY   STATUS    RESTARTS   AGE
</span><span class='line'>pod/busybox-6b99c495c9-qnvlp   1/1     Running   0          47s
</span><span class='line'>
</span><span class='line'>NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
</span><span class='line'>service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   27d
</span><span class='line'>
</span><span class='line'>NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
</span><span class='line'>deployment.apps/busybox   1/1     1            1           47s
</span><span class='line'>
</span><span class='line'>NAME                                 DESIRED   CURRENT   READY   AGE
</span><span class='line'>replicaset.apps/busybox-6b99c495c9   1         1         1       47s
</span><span class='line'>
</span><span class='line'># 查看NFS中原来的数据
</span><span class='line'>[ec2-user@k8s ~]$ kubectl exec -ti busybox-6b99c495c9-qnvlp -- cat /data/1.txt 
</span><span class='line'>nginx-deployment-67dcb957c-g2h8x
</span></code></pre></td></tr></table></div></figure>


<p>测一下subPathExpr：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl delete -f dp-pvc.yaml 
</span><span class='line'>deployment.apps "busybox" deleted
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>[ec2-user@k8s ~]$ vi dp-pvc.yaml 
</span><span class='line'>[ec2-user@k8s ~]$ cat dp-pvc.yaml 
</span><span class='line'>apiVersion: apps/v1
</span><span class='line'>kind: Deployment
</span><span class='line'>metadata:
</span><span class='line'>  name: busybox
</span><span class='line'>  labels:
</span><span class='line'>    app: busybox
</span><span class='line'>spec:
</span><span class='line'>  replicas: 1
</span><span class='line'>  selector:
</span><span class='line'>    matchLabels:
</span><span class='line'>      app: busybox
</span><span class='line'>  template:
</span><span class='line'>    metadata:
</span><span class='line'>      labels:
</span><span class='line'>        app: busybox
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - name: busybox
</span><span class='line'>        image: busybox
</span><span class='line'>        command: ['sh', '-c', 'echo "Hello, Kubernetes!" && sleep 3600']
</span><span class='line'>        env:
</span><span class='line'>        - name: POD_NAME
</span><span class='line'>          valueFrom:
</span><span class='line'>            fieldRef:
</span><span class='line'>              apiVersion: v1
</span><span class='line'>              fieldPath: metadata.name
</span><span class='line'>        volumeMounts:
</span><span class='line'>        - name: data
</span><span class='line'>          mountPath: /data
</span><span class='line'>          subPathExpr: $(POD_NAME)
</span><span class='line'>      volumes:
</span><span class='line'>      - name: data
</span><span class='line'>        persistentVolumeClaim:
</span><span class='line'>          claimName: pvc-nfs
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f dp-pvc.yaml 
</span><span class='line'>deployment.apps/busybox created
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get all 
</span><span class='line'>NAME                           READY   STATUS    RESTARTS   AGE
</span><span class='line'>pod/busybox-5497486bf5-csr6q   1/1     Running   0          7s
</span><span class='line'>
</span><span class='line'>NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
</span><span class='line'>service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   27d
</span><span class='line'>
</span><span class='line'>NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
</span><span class='line'>deployment.apps/busybox   1/1     1            1           7s
</span><span class='line'>
</span><span class='line'>NAME                                 DESIRED   CURRENT   READY   AGE
</span><span class='line'>replicaset.apps/busybox-5497486bf5   1         1         1       7s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl exec -ti pod/busybox-5497486bf5-csr6q -- sh 
</span><span class='line'>/ # ls /data
</span><span class='line'>/ # echo $(hostname) &gt; /data/pvc.txt
</span><span class='line'>/ # exit
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 查看服务端目录下数据
</span><span class='line'>[ec2-user@k8s ~]$ ll /backup/
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 33 Apr 14 00:37 1.txt
</span><span class='line'>drwxr-xr-x 2 root root 21 Apr 14 00:51 busybox-5497486bf5-csr6q
</span><span class='line'>[ec2-user@k8s ~]$ cat /backup/busybox-5497486bf5-csr6q/pvc.txt   
</span><span class='line'>busybox-5497486bf5-csr6q
</span></code></pre></td></tr></table></div></figure>


<p>把replicas改成2，再试试：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f dp-pvc.yaml 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods
</span><span class='line'>NAME                       READY   STATUS    RESTARTS   AGE
</span><span class='line'>busybox-5497486bf5-fkzls   1/1     Running   0          3m8s
</span><span class='line'>busybox-5497486bf5-rv7k7   1/1     Running   0          3m8s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl exec busybox-5497486bf5-fkzls -- sh -c 'echo $(hostname) &gt;/data/$(hostname).txt'
</span><span class='line'>[ec2-user@k8s ~]$ kubectl exec busybox-5497486bf5-rv7k7 -- sh -c 'echo $(hostname) &gt;/data/$(hostname).txt'                        
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 查看服务端目录结构
</span><span class='line'>[ec2-user@k8s ~]$ ll -R /backup/
</span><span class='line'>/backup/:
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 33 Apr 14 00:37 1.txt
</span><span class='line'>drwxr-xr-x 2 root root 21 Apr 14 00:51 busybox-5497486bf5-csr6q
</span><span class='line'>drwxr-xr-x 2 root root 42 Apr 14 01:20 busybox-5497486bf5-fkzls
</span><span class='line'>drwxr-xr-x 2 root root 42 Apr 14 01:20 busybox-5497486bf5-rv7k7
</span><span class='line'>
</span><span class='line'>/backup/busybox-5497486bf5-csr6q:
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 25 Apr 14 00:51 pvc.txt
</span><span class='line'>
</span><span class='line'>/backup/busybox-5497486bf5-fkzls:
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 25 Apr 14 01:20 busybox-5497486bf5-fkzls.txt
</span><span class='line'>
</span><span class='line'>/backup/busybox-5497486bf5-rv7k7:
</span><span class='line'>total 4
</span><span class='line'>-rw-r--r-- 1 root root 25 Apr 14 01:20 busybox-5497486bf5-rv7k7.txt
</span><span class='line'>[ec2-user@k8s ~]$ 
</span></code></pre></td></tr></table></div></figure>


<h3>NFS Subdir External Provisioner</h3>

<ul>
<li><a href="http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/#NFS-Subdir-External-Provisioner">http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/#NFS-Subdir-External-Provisioner</a></li>
<li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#nfs">https://kubernetes.io/docs/concepts/storage/storage-classes/#nfs</a></li>
<li><a href="https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner">https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner</a></li>
</ul>


<p>NFS subdir external provisioner 使用现有的的NFS 服务器来支持通过 Persistent Volume Claims 动态供应 Kubernetes Persistent Volumes。持久卷默认被配置为${namespace}-${pvcName}-${pvName}，使用这个必须已经拥有 NFS 服务器。</p>

<ul>
<li><a href="http://dockone.io/article/2598">http://dockone.io/article/2598</a> External NFS驱动的工作原理</li>
</ul>


<blockquote><p>K8S的外部NFS驱动，可以按照其工作方式（是作为NFS server还是NFS client）分为两类：</p>

<p>1.nfs-client:</p>

<p>也就是我们接下来演示的这一类，它通过K8S的内置的NFS驱动挂载远端的NFS服务器到本地目录；然后将自身作为storage provider，关联storage class。当用户创建对应的PVC来申请PV时，该provider就将PVC的要求与自身的属性比较，一旦满足就在本地挂载好的NFS目录中创建PV所属的子目录，为Pod提供动态的存储服务。</p>

<p>2.nfs:
与nfs-client不同，该驱动并不使用k8s的NFS驱动来挂载远端的NFS到本地再分配，而是直接将本地文件映射到容器内部，然后在容器内使用ganesha.nfsd来对外提供NFS服务；在每次创建PV的时候，直接在本地的NFS根目录中创建对应文件夹，并export出该子目录。</p>

<p>接下来我们来操作一个nfs-client驱动的例子，先对其有个直观的认识！</p>

<p>External NFS驱动的部署实例</p>

<p>这里，我们将nfs-client驱动做一个deployment部署到K8S集群中，然后对外提供存储服务。</p>

<p>1.部署nfs-client-provisioner</p>

<p>环境变量的PROVISIONER_NAME、NFS服务器地址、NFS对外提供服务的路径信息等需要设置好；部署所使用的yaml文件关键代码如下所示：</p>

<p>2.创建Storage Class</p>

<p>storage class的定义，需要注意的是：provisioner属性要等于驱动所传入的环境变量PROVISIONER_NAME的值。否则，驱动不知道知道如何绑定storage class。</p>

<p>3.创建PVC</p>

<p>这里指定了其对应的storage-class的名字为wise2c-nfs-storage，如下：</p>

<p>4.创建pod</p>

<p>指定该pod使用我们刚刚创建的PVC：henry-claim：</p>

<p>完成之后，如果attach到pod中执行一些文件的读写操作，就可以确定pod的/mnt已经使用了NFS的存储服务了。</p></blockquote>

<ul>
<li><a href="https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner#without-helm">https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner#without-helm</a></li>
</ul>


<p>官方文档中的脚本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Set the subject of the RBAC objects to the current namespace where the provisioner is being deployed
</span><span class='line'>$ NS=$(kubectl config get-contexts|grep -e "^\*" |awk '{print $5}')
</span><span class='line'>$ NAMESPACE=${NS:-default}
</span><span class='line'>$ sed -i'' "s/namespace:.*/namespace: $NAMESPACE/g" ./deploy/rbac.yaml ./deploy/deployment.yaml
</span><span class='line'>$ kubectl create -f deploy/rbac.yaml</span></code></pre></td></tr></table></div></figure>


<p>操作步骤：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/
</span><span class='line'>[ec2-user@k8s ~]$ cd nfs-subdir-external-provisioner/
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ NS=$(kubectl config get-contexts|grep -e "^\*" |awk '{print $5}')
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ NAMESPACE=${NS:-default}
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ sed -i'' "s/namespace:.*/namespace: $NAMESPACE/g" ./deploy/rbac.yaml ./deploy/deployment.yaml
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ kubectl create -f deploy/rbac.yaml
</span><span class='line'>serviceaccount/nfs-client-provisioner created
</span><span class='line'>clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created
</span><span class='line'>clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created
</span><span class='line'>role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
</span><span class='line'>rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>$ vi deploy/deployment.yaml
</span><span class='line'>
</span><span class='line'>            - name: NFS_SERVER
</span><span class='line'>              value: 192.168.191.131
</span><span class='line'>            - name: NFS_PATH
</span><span class='line'>              value: /backup
</span><span class='line'>      volumes:
</span><span class='line'>        - name: nfs-client-root
</span><span class='line'>          nfs:
</span><span class='line'>            server: 192.168.191.131
</span><span class='line'>            path: /backup
</span><span class='line'>
</span><span class='line'>$ vi deploy/class.yaml
</span><span class='line'>
</span><span class='line'>parameters:
</span><span class='line'>  archiveOnDelete: "false"
</span><span class='line'>#Specifies a template for creating a directory path via PVC metadata's such as labels, annotations, name or namespace. To specify metadata use ${.PVC.&lt;metadata&gt;}. Example: If folder should be named like &lt;pvc-namespace&gt;-&lt;pvc-name&gt;, use ${.PVC.namespace}-${.PVC.name} as pathPattern.
</span><span class='line'>#  pathPattern: "${.PVC.namespace}/${.PVC.annotations.nfs.io/storage-path}" # waits for nfs.io/storage-path annotation, if not specified will accept as empty string.
</span><span class='line'>#  onDelete: delete
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 先把镜像拉下来 k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ kubectl apply -f deploy/deployment.yaml 
</span><span class='line'>deployment.apps/nfs-client-provisioner created
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ kubectl apply -f deploy/class.yaml 
</span><span class='line'>storageclass.storage.k8s.io/nfs-client created
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>测试：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># PVC内容
</span><span class='line'># https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/blob/master/deploy/test-claim.yaml
</span><span class='line'>kind: PersistentVolumeClaim
</span><span class='line'>apiVersion: v1
</span><span class='line'>metadata:
</span><span class='line'>  name: test-claim
</span><span class='line'>spec:
</span><span class='line'>  storageClassName: nfs-client
</span><span class='line'>  accessModes:
</span><span class='line'>    - ReadWriteMany
</span><span class='line'>  resources:
</span><span class='line'>    requests:
</span><span class='line'>      storage: 1Mi
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ kubectl create -f deploy/test-claim.yaml -f deploy/test-pod.yaml
</span><span class='line'>persistentvolumeclaim/test-claim created
</span><span class='line'>pod/test-pod created
</span><span class='line'>
</span><span class='line'># kubectl delete -f deploy/test-pod.yaml -f deploy/test-claim.yaml
</span></code></pre></td></tr></table></div></figure>


<p><code>test pod</code> 在共享文件系统下写了一个 <code>touch /mnt/SUCCESS</code> 文件：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s nfs-subdir-external-provisioner]$ ll /backup/default-test-claim-pvc-9857153a-6c2b-42d7-b464-aa5fc2acbf90/
</span><span class='line'>total 0
</span><span class='line'>-rw-r--r-- 1 root root 0 Apr 14 02:14 SUCCESS
</span></code></pre></td></tr></table></div></figure>


<h3>NFS Ganesha server and external provisioner</h3>

<ul>
<li><a href="https://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner">https://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner</a></li>
<li><a href="http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/#nfs-ganesha-server-and-external-provisioner">http://www.lishuai.fun/2021/08/12/k8s-nfs-pv/#nfs-ganesha-server-and-external-provisioner</a></li>
</ul>


<p>就是直接在k8s集群中装一个NFS server。感觉没有直接在系统安装NFS管理方便，先搁置了。</p>

<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2022/04/11/xiaomi-r4a-install-padavan/">Xiaomi R4a Install Padavan</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2022-04-11T21:19:31+08:00" pubdate data-updated="true">Mon 2022-04-11 21:19</time>
		
        
		
      </p>
    
  </header>


  <div class="entry-content"><p>最近换了个小米的路由，想着登录ssh，能在路由上跑一些小的定时任务。但是无奈，绑定不通过，那就直接刷机了。</p>

<p>一开始是按照csdn上的文章刷opewrt的，但是都不成功，最后换成 老毛子Padavan 了。</p>

<h2>参考</h2>

<ul>
<li><a href="https://blog.csdn.net/qq_43206901/article/details/119106511">小米路由器R4A(千兆版)固件刷opewrt、刷官方固件</a></li>
<li><a href="https://www.0412.cyou/type/xiaomi.html">小米路由4A千兆版安装openwrt教程（R4A）</a></li>
</ul>


<h2>步骤描述</h2>

<h3>获取root权限</h3>

<p>使用 <code>WSL Ubuntu</code> 进行访问，python3已经安装了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@LAPTOP-I9ECVAQ4:OpenWRTInvasion-master$ python3 --version
</span><span class='line'>Python 3.8.5
</span><span class='line'>
</span><span class='line'># https://github.com/acecilia/OpenWRTInvasion
</span><span class='line'>winse@LAPTOP-I9ECVAQ4:OpenWRTInvasion-master$ ls
</span><span class='line'>Dockerfile  readme                                     requirements.txt  set_english.py
</span><span class='line'>extras      README.md                                  script.sh         speedtest_urls_template.xml
</span><span class='line'>firmwares   remote_command_execution_vulnerability.py  script_tools      tcp_file_server.py
</span><span class='line'>
</span><span class='line'>winse@LAPTOP-I9ECVAQ4:OpenWRTInvasion-master$ sudo apt install python3-pip
</span><span class='line'>
</span><span class='line'>winse@LAPTOP-I9ECVAQ4:OpenWRTInvasion-master$ pip3 install -r requirements.txt
</span><span class='line'>Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from -r requirements.txt (line 1)) (2.22.0)
</span><span class='line'>
</span><span class='line'># stok获取：登录web访问后，浏览器的地址上就有stok的参数。
</span><span class='line'># 详情可查看参考的文章
</span><span class='line'>winse@LAPTOP-I9ECVAQ4:OpenWRTInvasion-master$ python3 remote_command_execution_vulnerability.py
</span><span class='line'>Router IP address [press enter for using the default 'miwifi.com']:
</span><span class='line'>Enter router admin password: __xxx__
</span><span class='line'>There two options to provide the files needed for invasion:
</span><span class='line'>   1. Use a local TCP file server runing on random port to provide files in local directory `script_tools`.
</span><span class='line'>   2. Download needed files from remote github repository. (choose this option only if github is accessable inside router device.)
</span><span class='line'>Which option do you prefer? (default: 1)
</span><span class='line'>****************
</span><span class='line'>router_ip_address: miwifi.com
</span><span class='line'>stok: __xxx__
</span><span class='line'>file provider: local file server
</span><span class='line'>****************
</span><span class='line'>start uploading config file...
</span><span class='line'>start exec command...
</span><span class='line'>local file server is runing on 0.0.0.0:1135. root='script_tools'
</span><span class='line'>local file server is getting 'busybox-mipsel' for 192.168.31.1.
</span><span class='line'>local file server is getting 'dropbearStaticMipsel.tar.bz2' for 192.168.31.1.
</span><span class='line'>done! Now you can connect to the router using several options: (user: root, password: root)
</span><span class='line'>* telnet miwifi.com
</span><span class='line'>* ssh -oKexAlgorithms=+diffie-hellman-group1-sha1 -c 3des-cbc -o UserKnownHostsFile=/dev/null root@miwifi.com
</span><span class='line'>* ftp: using a program like cyberduck
</span><span class='line'>
</span><span class='line'>winse@LAPTOP-I9ECVAQ4:OpenWRTInvasion-master$ ssh -oKexAlgorithms=+diffie-hellman-group1-sha1 -c 3des-cbc -o UserKnownHostsFile=/dev/null root@miwifi.com
</span><span class='line'>The authenticity of host 'miwifi.com (192.168.31.1)' can't be established.
</span><span class='line'>RSA key fingerprint is SHA256:AT91yqVuqPnmOO5wmke6V0Hl67GKXdkb48W/FU3WfEM.
</span><span class='line'>Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
</span><span class='line'>Warning: Permanently added 'miwifi.com,192.168.31.1' (RSA) to the list of known hosts.
</span><span class='line'>root@miwifi.com's password:
</span><span class='line'>
</span><span class='line'>BusyBox v1.19.4 (2021-09-30 03:16:53 UTC) built-in shell (ash)
</span><span class='line'>Enter 'help' for a list of built-in commands.
</span><span class='line'>
</span><span class='line'> -----------------------------------------------------
</span><span class='line'>       Welcome to XiaoQiang!
</span><span class='line'> -----------------------------------------------------
</span><span class='line'>  $$$$$$\  $$$$$$$\  $$$$$$$$\      $$\      $$\        $$$$$$\  $$\   $$\
</span><span class='line'> $$  __$$\ $$  __$$\ $$  _____|     $$ |     $$ |      $$  __$$\ $$ | $$  |
</span><span class='line'> $$ /  $$ |$$ |  $$ |$$ |           $$ |     $$ |      $$ /  $$ |$$ |$$  /
</span><span class='line'> $$$$$$$$ |$$$$$$$  |$$$$$\         $$ |     $$ |      $$ |  $$ |$$$$$  /
</span><span class='line'> $$  __$$ |$$  __$$&lt; $$  __|        $$ |     $$ |      $$ |  $$ |$$  $$&lt;
</span><span class='line'> $$ |  $$ |$$ |  $$ |$$ |           $$ |     $$ |      $$ |  $$ |$$ |\$$\
</span><span class='line'> $$ |  $$ |$$ |  $$ |$$$$$$$$\       $$$$$$$$$  |       $$$$$$  |$$ | \$$\
</span><span class='line'> \__|  \__|\__|  \__|\________|      \_________/        \______/ \__|  \__|
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>root@XiaoQiang:~# 
</span></code></pre></td></tr></table></div></figure>


<h3>安装breed</h3>

<p>用WinSCP登入路由，使用 <code>ftp协议</code> ，ip地址 <code>miwifi.com</code> ，账号 <code>root</code>，把 <code>breed-mt7621-pbr-m1.bin</code> 文件上传到tmp文件夹内，之后执行如下命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@XiaoQiang:~# cd /tmp
</span><span class='line'>root@XiaoQiang:/tmp# ls breed-mt7621-pbr-*
</span><span class='line'>breed-mt7621-pbr-m1.bin
</span><span class='line'>
</span><span class='line'>root@XiaoQiang:/tmp# mtd -r write breed-mt7621-pbr-m1.bin Bootloader
</span><span class='line'>Unlocking Bootloader ...
</span><span class='line'>
</span><span class='line'>Writing from breed-mt7621-pbr-m1.bin to Bootloader ...
</span><span class='line'>Rebooting ...
</span></code></pre></td></tr></table></div></figure>


<p>接上网线，再等一阵子（1,2分钟），然后访问 <code>http://192.168.1.1/</code> 。</p>

<h3>刷padavan</h3>

<p>下载r4a版本的padavan: <code>https://opt.cn2qq.com/padavan/</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MI-R4A_3.4.3.9-099.trx</span></code></pre></td></tr></table></div></figure>


<p>访问 <code>192.168.1.1</code> ，备份eeprom和固件（重要），然后勾选固件，然后将小米4A的trx固件文件进行上传，然后完成固件更新流程。</p>

<p>更新过程请不要切断路由电源！更新完成后, 页面并不会自动刷新, 自己尝试能否进入路由配置页面。。</p>

<p>刷完后，这里需要多等待一点时间，耐心一点。</p>

<h3>访问</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>http://192.168.123.1/
</span><span class='line'>admin/admin
</span><span class='line'>
</span><span class='line'>在 [系统管理 - 服务] 页签开启ssh公钥登录。
</span><span class='line'>
</span><span class='line'>[MI-R4A /home/root]# uname -a
</span><span class='line'>Linux MI-R4A 3.4.113 #3 SMP Sun Apr 3 14:26:03 CST 2022 mips GNU/Linux
</span><span class='line'>[MI-R4A /home/root]# uname -r
</span><span class='line'>3.4.113
</span><span class='line'>[MI-R4A /home/root]# uname -m
</span><span class='line'>mips
</span><span class='line'>
</span><span class='line'>#CPU/Memory information
</span><span class='line'>$ cat /proc/cpuinfo
</span><span class='line'>
</span><span class='line'>#Version
</span><span class='line'>$ cat /proc/version
</span><span class='line'>
</span><span class='line'>#SCSI/Sata devices
</span><span class='line'>$ cat /proc/scsi/scsi
</span><span class='line'>
</span><span class='line'>#Partitions
</span><span class='line'>$ cat /proc/partitions
</span><span class='line'>
</span><span class='line'>#安装 okpg , 进入 Shell 后，在根目录安装，输入如下：
</span><span class='line'>[MI-R4A /home/root]# opkg.sh
</span><span class='line'>
</span><span class='line'># 升级：
</span><span class='line'>[MI-R4A /home/root]# opkg update
</span><span class='line'>Downloading http://bin.entware.net/mipselsf-k3.4/Packages.gz
</span><span class='line'>Updated list of available packages in /opt/var/opkg-lists/entware
</span><span class='line'>
</span><span class='line'>[MI-R4A /home/root]# opkg install jq
</span><span class='line'>Installing jq (1.6-2) to root...
</span><span class='line'>Downloading http://bin.entware.net/mipselsf-k3.4/jq_1.6-2_mipsel-3.4.ipk
</span><span class='line'>Configuring jq.
</span><span class='line'>
</span><span class='line'># opkg list
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2022/04/06/minikube-guide/">Minikube Guide</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2022-04-06T08:00:07+08:00" pubdate data-updated="true">Wed 2022-04-06 08:00</time>
		
        
		
      </p>
    
  </header>


  <div class="entry-content"><p>正如其名，minikube快速的安装一个k8s的集群，方便新手和应用开发人员调试等。</p>

<p>注：如果资源足够的话，搭建一个kubeadm的集群来的好一些。</p>

<h2>官网文档</h2>

<ul>
<li><a href="https://minikube.sigs.k8s.io/docs/start/">https://minikube.sigs.k8s.io/docs/start/</a></li>
</ul>


<h2>下载</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 墙外下载
</span><span class='line'>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
</span><span class='line'>
</span><span class='line'># 上传
</span><span class='line'>[ec2-user@amazonlinux ~]$ rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring minikube-linux-amd64...
</span><span class='line'>  100%   70948 KB    35474 KB/sec    00:00:02       0 Errors  
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo install minikube-linux-amd64 /usr/local/bin/minikube
</span></code></pre></td></tr></table></div></figure>


<h2>安装docker</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ sudo amazon-linux-extras install docker
</span><span class='line'>Installing docker
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>Cleaning repos: amzn2-core amzn2extra-docker
</span><span class='line'>12 metadata files removed
</span><span class='line'>4 sqlite files removed
</span><span class='line'>0 metadata files removed
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>amzn2-core                                                                                                                                        | 3.7 kB  00:00:00     
</span><span class='line'>amzn2extra-docker                                                                                                                                 | 3.0 kB  00:00:00     
</span><span class='line'>(1/5): amzn2-core/2/x86_64/group_gz                                                                                                               | 2.5 kB  00:00:01     
</span><span class='line'>(2/5): amzn2-core/2/x86_64/updateinfo                                                                                                             | 452 kB  00:00:01     
</span><span class='line'>(3/5): amzn2extra-docker/2/x86_64/updateinfo                                                                                                      | 5.9 kB  00:00:00     
</span><span class='line'>(4/5): amzn2extra-docker/2/x86_64/primary_db                                                                                                      |  86 kB  00:00:01     
</span><span class='line'>(5/5): amzn2-core/2/x86_64/primary_db                                                                                                             |  60 MB  00:00:04     
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package docker.x86_64 0:20.10.7-5.amzn2 will be installed
</span><span class='line'>--&gt; Processing Dependency: runc &gt;= 1.0.0 for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libcgroup &gt;= 0.40.rc1-5.15 for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Processing Dependency: containerd &gt;= 1.3.2 for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Processing Dependency: pigz for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package containerd.x86_64 0:1.4.6-8.amzn2 will be installed
</span><span class='line'>---&gt; Package libcgroup.x86_64 0:0.41-21.amzn2 will be installed
</span><span class='line'>---&gt; Package pigz.x86_64 0:2.3.4-1.amzn2.0.1 will be installed
</span><span class='line'>---&gt; Package runc.x86_64 0:1.0.0-2.amzn2 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>=========================================================================================================================================================================
</span><span class='line'> Package                               Arch                              Version                                      Repository                                    Size
</span><span class='line'>=========================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> docker                                x86_64                            20.10.7-5.amzn2                              amzn2extra-docker                             42 M
</span><span class='line'>Installing for dependencies:
</span><span class='line'> containerd                            x86_64                            1.4.6-8.amzn2                                amzn2extra-docker                             24 M
</span><span class='line'> libcgroup                             x86_64                            0.41-21.amzn2                                amzn2-core                                    66 k
</span><span class='line'> pigz                                  x86_64                            2.3.4-1.amzn2.0.1                            amzn2-core                                    81 k
</span><span class='line'> runc                                  x86_64                            1.0.0-2.amzn2                                amzn2extra-docker                            3.3 M
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>=========================================================================================================================================================================
</span><span class='line'>Install  1 Package (+4 Dependent packages)
</span><span class='line'>
</span><span class='line'>Total download size: 69 M
</span><span class='line'>Installed size: 285 M
</span><span class='line'>Is this ok [y/d/N]: t
</span><span class='line'>Is this ok [y/d/N]: y
</span><span class='line'>Downloading packages:
</span><span class='line'>(1/5): libcgroup-0.41-21.amzn2.x86_64.rpm                                                                                                         |  66 kB  00:00:01     
</span><span class='line'>(2/5): pigz-2.3.4-1.amzn2.0.1.x86_64.rpm                                                                                                          |  81 kB  00:00:01     
</span><span class='line'>(3/5): docker-20.10.7-5.amzn2.x86_64.rpm                                                                                                          |  42 MB  00:00:07     
</span><span class='line'>(4/5): runc-1.0.0-2.amzn2.x86_64.rpm                                                                                                              | 3.3 MB  00:00:00     
</span><span class='line'>(5/5): containerd-1.4.6-8.amzn2.x86_64.rpm                                                                                                        |  24 MB  00:00:12     
</span><span class='line'>-------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class='line'>Total                                                                                                                                    5.5 MB/s |  69 MB  00:00:12     
</span><span class='line'>Running transaction check
</span><span class='line'>Running transaction test
</span><span class='line'>Transaction test succeeded
</span><span class='line'>Running transaction
</span><span class='line'>  Installing : runc-1.0.0-2.amzn2.x86_64                                                                                                                             1/5 
</span><span class='line'>  Installing : containerd-1.4.6-8.amzn2.x86_64                                                                                                                       2/5 
</span><span class='line'>  Installing : libcgroup-0.41-21.amzn2.x86_64                                                                                                                        3/5 
</span><span class='line'>  Installing : pigz-2.3.4-1.amzn2.0.1.x86_64                                                                                                                         4/5 
</span><span class='line'>  Installing : docker-20.10.7-5.amzn2.x86_64                                                                                                                         5/5 
</span><span class='line'>  Verifying  : docker-20.10.7-5.amzn2.x86_64                                                                                                                         1/5 
</span><span class='line'>  Verifying  : containerd-1.4.6-8.amzn2.x86_64                                                                                                                       2/5 
</span><span class='line'>  Verifying  : runc-1.0.0-2.amzn2.x86_64                                                                                                                             3/5 
</span><span class='line'>  Verifying  : pigz-2.3.4-1.amzn2.0.1.x86_64                                                                                                                         4/5 
</span><span class='line'>  Verifying  : libcgroup-0.41-21.amzn2.x86_64                                                                                                                        5/5 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  docker.x86_64 0:20.10.7-5.amzn2                                                                                                                                        
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  containerd.x86_64 0:1.4.6-8.amzn2           libcgroup.x86_64 0:0.41-21.amzn2           pigz.x86_64 0:2.3.4-1.amzn2.0.1           runc.x86_64 0:1.0.0-2.amzn2          
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>  0  ansible2                 available    \
</span><span class='line'>        [ =2.4.2  =2.4.6  =2.8  =stable ]
</span><span class='line'>  2  httpd_modules            available    [ =1.0  =stable ]
</span><span class='line'>  3  memcached1.5             available    \
</span><span class='line'>        [ =1.5.1  =1.5.16  =1.5.17 ]
</span><span class='line'>  5  postgresql9.6            available    \
</span><span class='line'>        [ =9.6.6  =9.6.8  =stable ]
</span><span class='line'>  6  postgresql10             available    [ =10  =stable ]
</span><span class='line'>  9  R3.4                     available    [ =3.4.3  =stable ]
</span><span class='line'> 10  rust1                    available    \
</span><span class='line'>        [ =1.22.1  =1.26.0  =1.26.1  =1.27.2  =1.31.0  =1.38.0
</span><span class='line'>          =stable ]
</span><span class='line'> 11  vim                      available    [ =8.0  =stable ]
</span><span class='line'> 18  libreoffice              available    \
</span><span class='line'>        [ =5.0.6.2_15  =5.3.6.1  =stable ]
</span><span class='line'> 19  gimp                     available    [ =2.8.22 ]
</span><span class='line'> 20  docker=latest            enabled      \
</span><span class='line'>        [ =17.12.1  =18.03.1  =18.06.1  =18.09.9  =stable ]
</span><span class='line'> 21  mate-desktop1.x          available    \
</span><span class='line'>        [ =1.19.0  =1.20.0  =stable ]
</span><span class='line'> 22  GraphicsMagick1.3        available    \
</span><span class='line'>        [ =1.3.29  =1.3.32  =1.3.34  =stable ]
</span><span class='line'> 23  tomcat8.5                available    \
</span><span class='line'>        [ =8.5.31  =8.5.32  =8.5.38  =8.5.40  =8.5.42  =8.5.50
</span><span class='line'>          =stable ]
</span><span class='line'> 24  epel                     available    [ =7.11  =stable ]
</span><span class='line'> 25  testing                  available    [ =1.0  =stable ]
</span><span class='line'> 26  ecs                      available    [ =stable ]
</span><span class='line'> 27  corretto8                available    \
</span><span class='line'>        [ =1.8.0_192  =1.8.0_202  =1.8.0_212  =1.8.0_222  =1.8.0_232
</span><span class='line'>          =1.8.0_242  =stable ]
</span><span class='line'> 28  firecracker              available    [ =0.11  =stable ]
</span><span class='line'> 29  golang1.11               available    \
</span><span class='line'>        [ =1.11.3  =1.11.11  =1.11.13  =stable ]
</span><span class='line'> 30  squid4                   available    [ =4  =stable ]
</span><span class='line'> 32  lustre2.10               available    \
</span><span class='line'>        [ =2.10.5  =2.10.8  =stable ]
</span><span class='line'> 33  java-openjdk11           available    [ =11  =stable ]
</span><span class='line'> 34  lynis                    available    [ =stable ]
</span><span class='line'> 35  kernel-ng                available    [ =stable ]
</span><span class='line'> 36  BCC                      available    [ =0.x  =stable ]
</span><span class='line'> 37  mono                     available    [ =5.x  =stable ]
</span><span class='line'> 38  nginx1                   available    [ =stable ]
</span><span class='line'> 39  ruby2.6                  available    [ =2.6  =stable ]
</span><span class='line'> 40  mock                     available    [ =stable ]
</span><span class='line'> 41  postgresql11             available    [ =11  =stable ]
</span><span class='line'> 42  php7.4                   available    [ =stable ]
</span><span class='line'> 43  livepatch                available    [ =stable ]
</span><span class='line'> 44  python3.8                available    [ =stable ]
</span><span class='line'> 45  haproxy2                 available    [ =stable ]
</span><span class='line'> 46  collectd                 available    [ =stable ]
</span><span class='line'> 47  aws-nitro-enclaves-cli   available    [ =stable ]
</span><span class='line'> 48  R4                       available    [ =stable ]
</span><span class='line'> 49  kernel-5.4               available    [ =stable ]
</span><span class='line'> 50  selinux-ng               available    [ =stable ]
</span><span class='line'> 51  php8.0                   available    [ =stable ]
</span><span class='line'> 52  tomcat9                  available    [ =stable ]
</span><span class='line'> 53  unbound1.13              available    [ =stable ]
</span><span class='line'> 54  mariadb10.5              available    [ =stable ]
</span><span class='line'> 55  kernel-5.10              available    [ =stable ]
</span><span class='line'> 56  redis6                   available    [ =stable ]
</span><span class='line'> 57  ruby3.0                  available    [ =stable ]
</span><span class='line'> 58  postgresql12             available    [ =stable ]
</span><span class='line'> 59  postgresql13             available    [ =stable ]
</span><span class='line'> 60  mock2                    available    [ =stable ]
</span><span class='line'> 61  dnsmasq2.85              available    [ =stable ]
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo service docker start
</span><span class='line'>Redirecting to /bin/systemctl start docker.service
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo systemctl enable docker
</span><span class='line'>Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo usermod -a -G docker ec2-user
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ exit
</span><span class='line'>logout
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker info 
</span><span class='line'>Client:
</span><span class='line'> Context:    default
</span><span class='line'> Debug Mode: false
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Containers: 0
</span><span class='line'>  Running: 0
</span><span class='line'>  Paused: 0
</span><span class='line'>  Stopped: 0
</span><span class='line'> Images: 0
</span><span class='line'> Server Version: 20.10.7
</span><span class='line'> Storage Driver: overlay2
</span><span class='line'>  Backing Filesystem: xfs
</span><span class='line'>  Supports d_type: true
</span><span class='line'>  Native Overlay Diff: true
</span><span class='line'>  userxattr: false
</span><span class='line'> Logging Driver: json-file
</span><span class='line'> Cgroup Driver: cgroupfs
</span><span class='line'> Cgroup Version: 1
</span><span class='line'> Plugins:
</span><span class='line'>  Volume: local
</span><span class='line'>  Network: bridge host ipvlan macvlan null overlay
</span><span class='line'>  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
</span><span class='line'> Swarm: inactive
</span><span class='line'> Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc
</span><span class='line'> Default Runtime: runc
</span><span class='line'> Init Binary: docker-init
</span><span class='line'> containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d
</span><span class='line'> runc version: 84113eef6fc27af1b01b3181f31bbaf708715301
</span><span class='line'> init version: de40ad0
</span><span class='line'> Security Options:
</span><span class='line'>  seccomp
</span><span class='line'>   Profile: default
</span><span class='line'> Kernel Version: 4.14.268-205.500.amzn2.x86_64
</span><span class='line'> Operating System: Amazon Linux 2
</span><span class='line'> OSType: linux
</span><span class='line'> Architecture: x86_64
</span><span class='line'> CPUs: 2
</span><span class='line'> Total Memory: 3.828GiB
</span><span class='line'> Name: amazonlinux.onprem
</span><span class='line'> ID: MXVZ:LQK7:BVKI:WECH:XNBN:QJUK:IXYU:FADA:4EYI:JOHA:VS3R:LNLX
</span><span class='line'> Docker Root Dir: /var/lib/docker
</span><span class='line'> Debug Mode: false
</span><span class='line'> Registry: https://index.docker.io/v1/
</span><span class='line'> Labels:
</span><span class='line'> Experimental: false
</span><span class='line'> Insecure Registries:
</span><span class='line'>  127.0.0.0/8
</span><span class='line'> Live Restore Enabled: false
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker info
</span><span class='line'>Client:
</span><span class='line'> Context:    default
</span><span class='line'> Debug Mode: false
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Containers: 0
</span><span class='line'>  Running: 0
</span><span class='line'>  Paused: 0
</span><span class='line'>  Stopped: 0
</span><span class='line'> Images: 0
</span><span class='line'> Server Version: 20.10.7
</span><span class='line'> Storage Driver: overlay2
</span><span class='line'>  Backing Filesystem: xfs
</span><span class='line'>  Supports d_type: true
</span><span class='line'>  Native Overlay Diff: true
</span><span class='line'>  userxattr: false
</span><span class='line'> Logging Driver: json-file
</span><span class='line'> Cgroup Driver: cgroupfs
</span><span class='line'> Cgroup Version: 1
</span><span class='line'> Plugins:
</span><span class='line'>  Volume: local
</span><span class='line'>  Network: bridge host ipvlan macvlan null overlay
</span><span class='line'>  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
</span><span class='line'> Swarm: inactive
</span><span class='line'> Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux
</span><span class='line'> Default Runtime: runc
</span><span class='line'> Init Binary: docker-init
</span><span class='line'> containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d
</span><span class='line'> runc version: 84113eef6fc27af1b01b3181f31bbaf708715301
</span><span class='line'> init version: de40ad0
</span><span class='line'> Security Options:
</span><span class='line'>  seccomp
</span><span class='line'>   Profile: default
</span><span class='line'> Kernel Version: 4.14.268-205.500.amzn2.x86_64
</span><span class='line'> Operating System: Amazon Linux 2
</span><span class='line'> OSType: linux
</span><span class='line'> Architecture: x86_64
</span><span class='line'> CPUs: 2
</span><span class='line'> Total Memory: 3.828GiB
</span><span class='line'> Name: amazonlinux.onprem
</span><span class='line'> ID: MXVZ:LQK7:BVKI:WECH:XNBN:QJUK:IXYU:FADA:4EYI:JOHA:VS3R:LNLX
</span><span class='line'> Docker Root Dir: /var/lib/docker
</span><span class='line'> Debug Mode: false
</span><span class='line'> Registry: https://index.docker.io/v1/
</span><span class='line'> Labels:
</span><span class='line'> Experimental: false
</span><span class='line'> Insecure Registries:
</span><span class='line'>  127.0.0.0/8
</span><span class='line'> Live Restore Enabled: false
</span></code></pre></td></tr></table></div></figure>


<h2>启动minikube</h2>

<ul>
<li><a href="https://minikube.sigs.k8s.io/docs/start/">https://minikube.sigs.k8s.io/docs/start/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ minikube start
</span><span class='line'>* minikube v1.25.2 on Amazon 2
</span><span class='line'>* Automatically selected the docker driver. Other choices: none, ssh
</span><span class='line'>* Starting control plane node minikube in cluster minikube
</span><span class='line'>* Pulling base image ...
</span><span class='line'>* Downloading Kubernetes v1.23.3 preload ...
</span><span class='line'>    &gt; preloaded-images-k8s-v17-v1...: 505.68 MiB / 505.68 MiB  100.00% 14.20 Mi
</span><span class='line'>    &gt; index.docker.io/kicbase/sta...: 379.06 MiB / 379.06 MiB  100.00% 2.11 MiB
</span><span class='line'>! minikube was unable to download gcr.io/k8s-minikube/kicbase:v0.0.30, but successfully downloaded docker.io/kicbase/stable:v0.0.30 as a fallback image
</span><span class='line'>* Creating docker container (CPUs=2, Memory=2200MB) ...
</span><span class='line'>! This container is having trouble accessing https://k8s.gcr.io
</span><span class='line'>* To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
</span><span class='line'>* Preparing Kubernetes v1.23.3 on Docker 20.10.12 ...
</span><span class='line'>  - kubelet.housekeeping-interval=5m
</span><span class='line'>  - Generating certificates and keys ...
</span><span class='line'>  - Booting up control plane ...
</span><span class='line'>  - Configuring RBAC rules ...
</span><span class='line'>* Verifying Kubernetes components...
</span><span class='line'>  - Using image gcr.io/k8s-minikube/storage-provisioner:v5
</span><span class='line'>* Enabled addons: default-storageclass, storage-provisioner
</span><span class='line'>* kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
</span><span class='line'>* Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
</span></code></pre></td></tr></table></div></figure>


<p>Interact with your cluster</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ minikube kubectl -- get pods -A 
</span><span class='line'>    &gt; kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
</span><span class='line'>    &gt; kubectl: 44.43 MiB / 44.43 MiB [-------------] 100.00% 17.41 MiB p/s 2.8s
</span><span class='line'>NAMESPACE     NAME                               READY   STATUS    RESTARTS       AGE
</span><span class='line'>kube-system   coredns-64897985d-cm6h7            1/1     Running   0              2m3s
</span><span class='line'>kube-system   etcd-minikube                      1/1     Running   0              2m15s
</span><span class='line'>kube-system   kube-apiserver-minikube            1/1     Running   0              2m15s
</span><span class='line'>kube-system   kube-controller-manager-minikube   1/1     Running   0              2m15s
</span><span class='line'>kube-system   kube-proxy-s2sf4                   1/1     Running   0              2m3s
</span><span class='line'>kube-system   kube-scheduler-minikube            1/1     Running   0              2m15s
</span><span class='line'>kube-system   storage-provisioner                1/1     Running   1 (101s ago)   2m14s
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ alias kubectl="minikube kubectl --"
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get pods -A 
</span><span class='line'>NAMESPACE     NAME                               READY   STATUS    RESTARTS        AGE
</span><span class='line'>kube-system   coredns-64897985d-cm6h7            1/1     Running   0               5m5s
</span><span class='line'>kube-system   etcd-minikube                      1/1     Running   0               5m17s
</span><span class='line'>kube-system   kube-apiserver-minikube            1/1     Running   0               5m17s
</span><span class='line'>kube-system   kube-controller-manager-minikube   1/1     Running   0               5m17s
</span><span class='line'>kube-system   kube-proxy-s2sf4                   1/1     Running   0               5m5s
</span><span class='line'>kube-system   kube-scheduler-minikube            1/1     Running   0               5m17s
</span><span class='line'>kube-system   storage-provisioner                1/1     Running   1 (4m43s ago)   5m16s
</span><span class='line'>
</span><span class='line'># 查看配置
</span><span class='line'>[ec2-user@amazonlinux ~]$ cat .kube/config 
</span><span class='line'>apiVersion: v1
</span><span class='line'>clusters:
</span><span class='line'>- cluster:
</span><span class='line'>    certificate-authority: /home/ec2-user/.minikube/ca.crt
</span><span class='line'>    extensions:
</span><span class='line'>    - extension:
</span><span class='line'>        last-update: Sun, 03 Apr 2022 16:43:46 UTC
</span><span class='line'>        provider: minikube.sigs.k8s.io
</span><span class='line'>        version: v1.25.2
</span><span class='line'>      name: cluster_info
</span><span class='line'>    server: https://192.168.49.2:8443
</span><span class='line'>  name: minikube
</span><span class='line'>contexts:
</span><span class='line'>- context:
</span><span class='line'>    cluster: minikube
</span><span class='line'>    extensions:
</span><span class='line'>    - extension:
</span><span class='line'>        last-update: Sun, 03 Apr 2022 16:43:46 UTC
</span><span class='line'>        provider: minikube.sigs.k8s.io
</span><span class='line'>        version: v1.25.2
</span><span class='line'>      name: context_info
</span><span class='line'>    namespace: default
</span><span class='line'>    user: minikube
</span><span class='line'>  name: minikube
</span><span class='line'>current-context: minikube
</span><span class='line'>kind: Config
</span><span class='line'>preferences: {}
</span><span class='line'>users:
</span><span class='line'>- name: minikube
</span><span class='line'>  user:
</span><span class='line'>    client-certificate: /home/ec2-user/.minikube/profiles/minikube/client.crt
</span><span class='line'>    client-key: /home/ec2-user/.minikube/profiles/minikube/client.key
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span></code></pre></td></tr></table></div></figure>


<p>或者做一个软连接的kubectl：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://minikube.sigs.k8s.io/docs/handbook/kubectl/
</span><span class='line'># https://kubernetes.io/docs/tasks/tools/included/optional-kubectl-configs-bash-linux/
</span><span class='line'># https://minikube.sigs.k8s.io/docs/handbook/kubectl/
</span><span class='line'>
</span><span class='line'>ln -s $(which minikube) /usr/local/bin/kubectl
</span></code></pre></td></tr></table></div></figure>


<h3>对系统做了些什么？</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ docker images 
</span><span class='line'>REPOSITORY       TAG       IMAGE ID       CREATED       SIZE
</span><span class='line'>kicbase/stable   v0.0.30   1312ccd2422d   7 weeks ago   1.14GB
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker ps 
</span><span class='line'>CONTAINER ID   IMAGE                    COMMAND                  CREATED         STATUS         PORTS                                                                                                                                  NAMES
</span><span class='line'>19887e6799fb   kicbase/stable:v0.0.30   "/usr/local/bin/entr…"   7 minutes ago   Up 7 minutes   127.0.0.1:49157-&gt;22/tcp, 127.0.0.1:49156-&gt;2376/tcp, 127.0.0.1:49155-&gt;5000/tcp, 127.0.0.1:49154-&gt;8443/tcp, 127.0.0.1:49153-&gt;32443/tcp   minikube
</span><span class='line'>
</span><span class='line'># 进到容器内查看
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker exec -ti 19887e6799fb bash 
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube ssh
</span><span class='line'>docker@minikube:~$ sudo su -
</span><span class='line'>root@minikube:/# 
</span><span class='line'>root@minikube:/# docker ps -a 
</span><span class='line'>CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS                     PORTS     NAMES
</span><span class='line'>317a4dc12504   6e38f40d628d           "/storage-provisioner"   7 minutes ago   Up 7 minutes                         k8s_storage-provisioner_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_1
</span><span class='line'>e0876840ef56   a4ca41631cc7           "/coredns -conf /etc…"   7 minutes ago   Up 7 minutes                         k8s_coredns_coredns-64897985d-cm6h7_kube-system_0bbdb9ae-d64a-4d74-8b38-ba5bd66af499_0
</span><span class='line'>485899a5fe0c   9b7cc9982109           "/usr/local/bin/kube…"   7 minutes ago   Up 7 minutes                         k8s_kube-proxy_kube-proxy-s2sf4_kube-system_2e24cec7-d9b3-430e-8869-b9af785588de_0
</span><span class='line'>0faab30374f5   k8s.gcr.io/pause:3.6   "/pause"                 7 minutes ago   Up 7 minutes                         k8s_POD_coredns-64897985d-cm6h7_kube-system_0bbdb9ae-d64a-4d74-8b38-ba5bd66af499_0
</span><span class='line'>ae99f0b5b873   k8s.gcr.io/pause:3.6   "/pause"                 7 minutes ago   Up 7 minutes                         k8s_POD_kube-proxy-s2sf4_kube-system_2e24cec7-d9b3-430e-8869-b9af785588de_0
</span><span class='line'>fdeeb06fda78   6e38f40d628d           "/storage-provisioner"   7 minutes ago   Exited (1) 7 minutes ago             k8s_storage-provisioner_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_0
</span><span class='line'>f83e36d2d77e   k8s.gcr.io/pause:3.6   "/pause"                 7 minutes ago   Up 7 minutes                         k8s_POD_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_0
</span><span class='line'>df73834cbaf8   b07520cd7ab7           "kube-controller-man…"   8 minutes ago   Up 8 minutes                         k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_b965983ec05322d0973594a01d5e8245_0
</span><span class='line'>49ad661cee86   25f8c7f3da61           "etcd --advertise-cl…"   8 minutes ago   Up 8 minutes                         k8s_etcd_etcd-minikube_kube-system_9d3d310935e5fabe942511eec3e2cd0c_0
</span><span class='line'>2c28a97b3875   99a3486be4f2           "kube-scheduler --au…"   8 minutes ago   Up 8 minutes                         k8s_kube-scheduler_kube-scheduler-minikube_kube-system_be132fe5c6572cb34d93f5e05ce2a540_0
</span><span class='line'>72aca4e710b6   f40be0088a83           "kube-apiserver --ad…"   8 minutes ago   Up 8 minutes                         k8s_kube-apiserver_kube-apiserver-minikube_kube-system_cd6e47233d36a9715b0ab9632f871843_0
</span><span class='line'>97c6ecde381c   k8s.gcr.io/pause:3.6   "/pause"                 8 minutes ago   Up 8 minutes                         k8s_POD_kube-scheduler-minikube_kube-system_be132fe5c6572cb34d93f5e05ce2a540_0
</span><span class='line'>9140211bc570   k8s.gcr.io/pause:3.6   "/pause"                 8 minutes ago   Up 8 minutes                         k8s_POD_kube-controller-manager-minikube_kube-system_b965983ec05322d0973594a01d5e8245_0
</span><span class='line'>b27ec09ec789   k8s.gcr.io/pause:3.6   "/pause"                 8 minutes ago   Up 8 minutes                         k8s_POD_kube-apiserver-minikube_kube-system_cd6e47233d36a9715b0ab9632f871843_0
</span><span class='line'>0aef74ead92e   k8s.gcr.io/pause:3.6   "/pause"                 8 minutes ago   Up 8 minutes                         k8s_POD_etcd-minikube_kube-system_9d3d310935e5fabe942511eec3e2cd0c_0
</span><span class='line'>
</span><span class='line'>root@minikube:/# docker images 
</span><span class='line'>REPOSITORY                                TAG       IMAGE ID       CREATED         SIZE
</span><span class='line'>k8s.gcr.io/kube-apiserver                 v1.23.3   f40be0088a83   2 months ago    135MB
</span><span class='line'>k8s.gcr.io/kube-proxy                     v1.23.3   9b7cc9982109   2 months ago    112MB
</span><span class='line'>k8s.gcr.io/kube-scheduler                 v1.23.3   99a3486be4f2   2 months ago    53.5MB
</span><span class='line'>k8s.gcr.io/kube-controller-manager        v1.23.3   b07520cd7ab7   2 months ago    125MB
</span><span class='line'>k8s.gcr.io/etcd                           3.5.1-0   25f8c7f3da61   5 months ago    293MB
</span><span class='line'>k8s.gcr.io/coredns/coredns                v1.8.6    a4ca41631cc7   5 months ago    46.8MB
</span><span class='line'>k8s.gcr.io/pause                          3.6       6270bb605e12   7 months ago    683kB
</span><span class='line'>kubernetesui/dashboard                    v2.3.1    e1482a24335a   9 months ago    220MB
</span><span class='line'>kubernetesui/metrics-scraper              v1.0.7    7801cfc6d5c0   9 months ago    34.4MB
</span><span class='line'>gcr.io/k8s-minikube/storage-provisioner   v5        6e38f40d628d   12 months ago   31.5MB
</span></code></pre></td></tr></table></div></figure>


<p>更便捷的管理minikube docker：</p>

<ul>
<li><a href="https://minikube.sigs.k8s.io/docs/handbook/pushing/">https://minikube.sigs.k8s.io/docs/handbook/pushing/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://minikube.sigs.k8s.io/docs/handbook/pushing/#1-pushing-directly-to-the-in-cluster-docker-daemon-docker-env
</span><span class='line'>[ec2-user@amazonlinux ~]$ eval $(minikube docker-env)
</span><span class='line'># 原理就是设置了环境变量，docker连上了远程服务：export DOCKER_HOST="tcp://192.168.49.2:2376"
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker ps
</span><span class='line'>CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
</span><span class='line'>344dc0e8c1e6   7801cfc6d5c0           "/metrics-sidecar"       13 minutes ago   Up 13 minutes             k8s_dashboard-metrics-scraper_dashboard-metrics-scraper-58549894f-mzhg2_kubernetes-dashboard_4d6591df-2ee1-46b1-b44c-46ef748a3cd8_0
</span><span class='line'>276a2b6b591f   e1482a24335a           "/dashboard --insecu…"   13 minutes ago   Up 13 minutes             k8s_kubernetes-dashboard_kubernetes-dashboard-ccd587f44-w22lx_kubernetes-dashboard_eb06974d-a4e6-459a-b135-b2426696a75f_0
</span><span class='line'>739f9fdc02bf   k8s.gcr.io/pause:3.6   "/pause"                 13 minutes ago   Up 13 minutes             k8s_POD_dashboard-metrics-scraper-58549894f-mzhg2_kubernetes-dashboard_4d6591df-2ee1-46b1-b44c-46ef748a3cd8_0
</span><span class='line'>9b9d38bdb6d7   k8s.gcr.io/pause:3.6   "/pause"                 13 minutes ago   Up 13 minutes             k8s_POD_kubernetes-dashboard-ccd587f44-w22lx_kubernetes-dashboard_eb06974d-a4e6-459a-b135-b2426696a75f_0
</span><span class='line'>8fd387311710   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_hello-minikube-74c6b47596-gfxrl_default_689891ce-a761-46a6-aa16-fb33dd037c45_0
</span><span class='line'>317a4dc12504   6e38f40d628d           "/storage-provisioner"   8 hours ago      Up 8 hours                k8s_storage-provisioner_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_1
</span><span class='line'>e0876840ef56   a4ca41631cc7           "/coredns -conf /etc…"   8 hours ago      Up 8 hours                k8s_coredns_coredns-64897985d-cm6h7_kube-system_0bbdb9ae-d64a-4d74-8b38-ba5bd66af499_0
</span><span class='line'>485899a5fe0c   9b7cc9982109           "/usr/local/bin/kube…"   8 hours ago      Up 8 hours                k8s_kube-proxy_kube-proxy-s2sf4_kube-system_2e24cec7-d9b3-430e-8869-b9af785588de_0
</span><span class='line'>0faab30374f5   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_coredns-64897985d-cm6h7_kube-system_0bbdb9ae-d64a-4d74-8b38-ba5bd66af499_0
</span><span class='line'>ae99f0b5b873   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_kube-proxy-s2sf4_kube-system_2e24cec7-d9b3-430e-8869-b9af785588de_0
</span><span class='line'>f83e36d2d77e   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_0
</span><span class='line'>df73834cbaf8   b07520cd7ab7           "kube-controller-man…"   8 hours ago      Up 8 hours                k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_b965983ec05322d0973594a01d5e8245_0
</span><span class='line'>49ad661cee86   25f8c7f3da61           "etcd --advertise-cl…"   8 hours ago      Up 8 hours                k8s_etcd_etcd-minikube_kube-system_9d3d310935e5fabe942511eec3e2cd0c_0
</span><span class='line'>2c28a97b3875   99a3486be4f2           "kube-scheduler --au…"   8 hours ago      Up 8 hours                k8s_kube-scheduler_kube-scheduler-minikube_kube-system_be132fe5c6572cb34d93f5e05ce2a540_0
</span><span class='line'>72aca4e710b6   f40be0088a83           "kube-apiserver --ad…"   8 hours ago      Up 8 hours                k8s_kube-apiserver_kube-apiserver-minikube_kube-system_cd6e47233d36a9715b0ab9632f871843_0
</span><span class='line'>97c6ecde381c   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_kube-scheduler-minikube_kube-system_be132fe5c6572cb34d93f5e05ce2a540_0
</span><span class='line'>9140211bc570   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_kube-controller-manager-minikube_kube-system_b965983ec05322d0973594a01d5e8245_0
</span><span class='line'>b27ec09ec789   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_kube-apiserver-minikube_kube-system_cd6e47233d36a9715b0ab9632f871843_0
</span><span class='line'>0aef74ead92e   k8s.gcr.io/pause:3.6   "/pause"                 8 hours ago      Up 8 hours                k8s_POD_etcd-minikube_kube-system_9d3d310935e5fabe942511eec3e2cd0c_0
</span></code></pre></td></tr></table></div></figure>


<p>管理：</p>

<ul>
<li><a href="https://minikube.sigs.k8s.io/docs/handbook/pushing/#2-push-images-using-cache-command">https://minikube.sigs.k8s.io/docs/handbook/pushing/#2-push-images-using-cache-command</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>minikube cache add alpine:latest
</span><span class='line'>minikube cache reload
</span><span class='line'>minikube cache list
</span><span class='line'>minikube cache delete &lt;image name&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>dashboard</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ minikube dashboard
</span><span class='line'>* Enabling dashboard ...
</span><span class='line'>  - Using image kubernetesui/metrics-scraper:v1.0.7
</span><span class='line'>  - Using image kubernetesui/dashboard:v2.3.1
</span><span class='line'>* Verifying dashboard health ...
</span><span class='line'>* Launching proxy ...
</span><span class='line'>* Verifying proxy health ...
</span><span class='line'>* Opening http://127.0.0.1:37163/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ in your default browser...
</span><span class='line'>  http://127.0.0.1:37163/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo netstat -anp | grep 37163 | grep LISTEN
</span><span class='line'>tcp        0      0 127.0.0.1:37163         0.0.0.0:*               LISTEN      71016/kubectl       
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ ps aux|grep 71016
</span><span class='line'>ec2-user   71016  0.0  0.9 750808 38932 pts/2    Sl+  00:59   0:00 /home/ec2-user/.minikube/cache/linux/amd64/v1.23.3/kubectl --cluster minikube --context minikube proxy --port 0
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 再获取访问地址
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube dashboard --url
</span><span class='line'>* Verifying dashboard health ...
</span><span class='line'>* Launching proxy ...
</span><span class='line'>* Verifying proxy health ...
</span><span class='line'>http://127.0.0.1:43247/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/
</span></code></pre></td></tr></table></div></figure>


<h2>hello world</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ eval $(minikube docker-env)
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker load -i echoserver.tar.gz 
</span><span class='line'>6cc9890d69b6: Loading layer [==================================================&gt;]  61.68MB/61.68MB
</span><span class='line'>5f70bf18a086: Loading layer [==================================================&gt;]  1.024kB/1.024kB
</span><span class='line'>e105cd217163: Loading layer [==================================================&gt;]  8.704kB/8.704kB
</span><span class='line'>9f9b8efa9a34: Loading layer [==================================================&gt;]  83.34MB/83.34MB
</span><span class='line'>4cc84b7b3aba: Loading layer [==================================================&gt;]  3.072kB/3.072kB
</span><span class='line'>e2615e4925e2: Loading layer [==================================================&gt;]  3.072kB/3.072kB
</span><span class='line'>1787713d6d5d: Loading layer [==================================================&gt;]   5.12kB/5.12kB
</span><span class='line'>67639a8a7916: Loading layer [==================================================&gt;]  2.048kB/2.048kB
</span><span class='line'>Loaded image: k8s.gcr.io/echoserver:1.4
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker images 
</span><span class='line'>REPOSITORY                                TAG       IMAGE ID       CREATED         SIZE
</span><span class='line'>k8s.gcr.io/kube-apiserver                 v1.23.3   f40be0088a83   2 months ago    135MB
</span><span class='line'>k8s.gcr.io/kube-scheduler                 v1.23.3   99a3486be4f2   2 months ago    53.5MB
</span><span class='line'>k8s.gcr.io/kube-proxy                     v1.23.3   9b7cc9982109   2 months ago    112MB
</span><span class='line'>k8s.gcr.io/kube-controller-manager        v1.23.3   b07520cd7ab7   2 months ago    125MB
</span><span class='line'>k8s.gcr.io/etcd                           3.5.1-0   25f8c7f3da61   5 months ago    293MB
</span><span class='line'>k8s.gcr.io/coredns/coredns                v1.8.6    a4ca41631cc7   6 months ago    46.8MB
</span><span class='line'>k8s.gcr.io/pause                          3.6       6270bb605e12   7 months ago    683kB
</span><span class='line'>kubernetesui/dashboard                    v2.3.1    e1482a24335a   10 months ago   220MB
</span><span class='line'>kubernetesui/metrics-scraper              v1.0.7    7801cfc6d5c0   10 months ago   34.4MB
</span><span class='line'>gcr.io/k8s-minikube/storage-provisioner   v5        6e38f40d628d   12 months ago   31.5MB
</span><span class='line'>k8s.gcr.io/echoserver                     1.4       a90209bb39e3   5 years ago     140MB
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.4
</span><span class='line'># kubectl expose deployment hello-minikube --type=NodePort --port=8080
</span><span class='line'>
</span><span class='line'># kubectl --help
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get svc 
</span><span class='line'>NAME             TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
</span><span class='line'>hello-minikube   NodePort    10.98.195.3   &lt;none&gt;        8080:32754/TCP   7h
</span><span class='line'>kubernetes       ClusterIP   10.96.0.1     &lt;none&gt;        443/TCP          12d
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get services hello-minikube
</span><span class='line'>NAME             TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
</span><span class='line'>hello-minikube   NodePort   10.98.195.3   &lt;none&gt;        8080:32754/TCP   7h59m
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># kubectl port-forward service/hello-minikube 7080:8080
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl port-forward --address 0.0.0.0 service/hello-minikube 7080:8080
</span><span class='line'>Forwarding from 0.0.0.0:7080 -&gt; 8080
</span><span class='line'>Handling connection for 7080
</span><span class='line'>Handling connection for 7080
</span><span class='line'>
</span><span class='line'>浏览器访问 http://192.168.191.133:7080/
</span></code></pre></td></tr></table></div></figure>


<h2>load balancer</h2>

<ul>
<li><a href="https://minikube.sigs.k8s.io/docs/start/#loadbalancer-deployments">https://minikube.sigs.k8s.io/docs/start/#loadbalancer-deployments</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ kubectl create deployment balanced --image=k8s.gcr.io/echoserver:1.4  
</span><span class='line'>deployment.apps/balanced created
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl expose deployment balanced --type=LoadBalancer --port=8080
</span><span class='line'>service/balanced exposed
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube tunnel
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get services balanced
</span><span class='line'>NAME       TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE
</span><span class='line'>balanced   LoadBalancer   10.100.193.49   10.100.193.49   8080:30406/TCP   13s
</span><span class='line'>[ec2-user@amazonlinux ~]$ curl 10.100.193.49:8080
</span><span class='line'>CLIENT VALUES:
</span><span class='line'>client_address=172.17.0.1
</span><span class='line'>command=GET
</span><span class='line'>real path=/
</span><span class='line'>query=nil
</span><span class='line'>request_version=1.1
</span><span class='line'>request_uri=http://10.100.193.49:8080/
</span><span class='line'>
</span><span class='line'>SERVER VALUES:
</span><span class='line'>server_version=nginx: 1.10.0 - lua: 10001
</span><span class='line'>
</span><span class='line'>HEADERS RECEIVED:
</span><span class='line'>accept=*/*
</span><span class='line'>host=10.100.193.49:8080
</span><span class='line'>user-agent=curl/7.79.1
</span><span class='line'>BODY:
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span></code></pre></td></tr></table></div></figure>


<h2>清理</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ minikube pause
</span><span class='line'>* Pausing node minikube ... 
</span><span class='line'>* Paused 18 containers in: kube-system, kubernetes-dashboard, storage-gluster, istio-operator
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube unpause
</span><span class='line'>* Unpausing node minikube ... 
</span><span class='line'>* Unpaused 18 containers in: kube-system, kubernetes-dashboard, storage-gluster, istio-operator
</span><span class='line'>
</span><span class='line'>###!!!!
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube config set memory 16384
</span><span class='line'>! These changes will take effect upon a minikube delete and then a minikube start
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube config unset memory
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker ps 
</span><span class='line'>CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS     NAMES
</span><span class='line'>01cf3a66eb7c   a90209bb39e3           "nginx -g 'daemon of…"   6 minutes ago    Up 6 minutes              k8s_echoserver_balanced-5b98d98bf8-t464f_default_c6b70ff1-d799-4633-bf13-e481052a5da1_0
</span><span class='line'>6a23b4b82131   k8s.gcr.io/pause:3.6   "/pause"                 6 minutes ago    Up 6 minutes              k8s_POD_balanced-5b98d98bf8-t464f_default_c6b70ff1-d799-4633-bf13-e481052a5da1_0
</span><span class='line'>b5817aab4b25   a90209bb39e3           "nginx -g 'daemon of…"   17 minutes ago   Up 17 minutes             k8s_echoserver_hello-minikube-7bc9d7884c-m4r4s_default_cef90979-1c63-4497-acb0-d13847c5a60b_0
</span><span class='line'>9d5677d088c6   k8s.gcr.io/pause:3.6   "/pause"                 17 minutes ago   Up 17 minutes             k8s_POD_hello-minikube-7bc9d7884c-m4r4s_default_cef90979-1c63-4497-acb0-d13847c5a60b_0
</span><span class='line'>c13da70206de   e1482a24335a           "/dashboard --insecu…"   50 minutes ago   Up 50 minutes             k8s_kubernetes-dashboard_kubernetes-dashboard-ccd587f44-w22lx_kubernetes-dashboard_eb06974d-a4e6-459a-b135-b2426696a75f_4
</span><span class='line'>0cead3ead613   6e38f40d628d           "/storage-provisioner"   50 minutes ago   Up 50 minutes             k8s_storage-provisioner_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_5
</span><span class='line'>3a1c19a7a51f   7801cfc6d5c0           "/metrics-sidecar"       51 minutes ago   Up 51 minutes             k8s_dashboard-metrics-scraper_dashboard-metrics-scraper-58549894f-mzhg2_kubernetes-dashboard_4d6591df-2ee1-46b1-b44c-46ef748a3cd8_2
</span><span class='line'>0c48d4f778de   a4ca41631cc7           "/coredns -conf /etc…"   51 minutes ago   Up 51 minutes             k8s_coredns_coredns-64897985d-cm6h7_kube-system_0bbdb9ae-d64a-4d74-8b38-ba5bd66af499_2
</span><span class='line'>ac2ee5d973c6   9b7cc9982109           "/usr/local/bin/kube…"   51 minutes ago   Up 51 minutes             k8s_kube-proxy_kube-proxy-s2sf4_kube-system_2e24cec7-d9b3-430e-8869-b9af785588de_2
</span><span class='line'>dc17216220bb   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_kubernetes-dashboard-ccd587f44-w22lx_kubernetes-dashboard_eb06974d-a4e6-459a-b135-b2426696a75f_2
</span><span class='line'>9d7f883afb88   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_storage-provisioner_kube-system_c4ea2d31-2c3e-4672-9479-719b0082ac5c_2
</span><span class='line'>d28d9a0a91b1   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_coredns-64897985d-cm6h7_kube-system_0bbdb9ae-d64a-4d74-8b38-ba5bd66af499_2
</span><span class='line'>7e7a16e16d03   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_kube-proxy-s2sf4_kube-system_2e24cec7-d9b3-430e-8869-b9af785588de_2
</span><span class='line'>ace45942773c   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_dashboard-metrics-scraper-58549894f-mzhg2_kubernetes-dashboard_4d6591df-2ee1-46b1-b44c-46ef748a3cd8_2
</span><span class='line'>8f00f611d713   f40be0088a83           "kube-apiserver --ad…"   51 minutes ago   Up 51 minutes             k8s_kube-apiserver_kube-apiserver-minikube_kube-system_cd6e47233d36a9715b0ab9632f871843_2
</span><span class='line'>79f528bbd4d1   99a3486be4f2           "kube-scheduler --au…"   51 minutes ago   Up 51 minutes             k8s_kube-scheduler_kube-scheduler-minikube_kube-system_be132fe5c6572cb34d93f5e05ce2a540_2
</span><span class='line'>75ce75e37ceb   b07520cd7ab7           "kube-controller-man…"   51 minutes ago   Up 51 minutes             k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_b965983ec05322d0973594a01d5e8245_2
</span><span class='line'>50c302912f4a   25f8c7f3da61           "etcd --advertise-cl…"   51 minutes ago   Up 51 minutes             k8s_etcd_etcd-minikube_kube-system_9d3d310935e5fabe942511eec3e2cd0c_2
</span><span class='line'>0b1c094b5824   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_kube-controller-manager-minikube_kube-system_b965983ec05322d0973594a01d5e8245_2
</span><span class='line'>7b6d52353935   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_kube-scheduler-minikube_kube-system_be132fe5c6572cb34d93f5e05ce2a540_2
</span><span class='line'>64ba4b4c1a84   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_etcd-minikube_kube-system_9d3d310935e5fabe942511eec3e2cd0c_2
</span><span class='line'>92f05324a447   k8s.gcr.io/pause:3.6   "/pause"                 51 minutes ago   Up 51 minutes             k8s_POD_kube-apiserver-minikube_kube-system_cd6e47233d36a9715b0ab9632f871843_2
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube addons list
</span><span class='line'>|-----------------------------|----------|--------------|--------------------------------|
</span><span class='line'>|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |
</span><span class='line'>|-----------------------------|----------|--------------|--------------------------------|
</span><span class='line'>| ambassador                  | minikube | disabled     | third-party (ambassador)       |
</span><span class='line'>| auto-pause                  | minikube | disabled     | google                         |
</span><span class='line'>| csi-hostpath-driver         | minikube | disabled     | kubernetes                     |
</span><span class='line'>| dashboard                   | minikube | enabled ✅   | kubernetes                     |
</span><span class='line'>| default-storageclass        | minikube | enabled ✅   | kubernetes                     |
</span><span class='line'>| efk                         | minikube | disabled     | third-party (elastic)          |
</span><span class='line'>| freshpod                    | minikube | disabled     | google                         |
</span><span class='line'>| gcp-auth                    | minikube | disabled     | google                         |
</span><span class='line'>| gvisor                      | minikube | disabled     | google                         |
</span><span class='line'>| helm-tiller                 | minikube | disabled     | third-party (helm)             |
</span><span class='line'>| ingress                     | minikube | disabled     | unknown (third-party)          |
</span><span class='line'>| ingress-dns                 | minikube | disabled     | google                         |
</span><span class='line'>| istio                       | minikube | disabled     | third-party (istio)            |
</span><span class='line'>| istio-provisioner           | minikube | disabled     | third-party (istio)            |
</span><span class='line'>| kong                        | minikube | disabled     | third-party (Kong HQ)          |
</span><span class='line'>| kubevirt                    | minikube | disabled     | third-party (kubevirt)         |
</span><span class='line'>| logviewer                   | minikube | disabled     | unknown (third-party)          |
</span><span class='line'>| metallb                     | minikube | disabled     | third-party (metallb)          |
</span><span class='line'>| metrics-server              | minikube | disabled     | kubernetes                     |
</span><span class='line'>| nvidia-driver-installer     | minikube | disabled     | google                         |
</span><span class='line'>| nvidia-gpu-device-plugin    | minikube | disabled     | third-party (nvidia)           |
</span><span class='line'>| olm                         | minikube | disabled     | third-party (operator          |
</span><span class='line'>|                             |          |              | framework)                     |
</span><span class='line'>| pod-security-policy         | minikube | disabled     | unknown (third-party)          |
</span><span class='line'>| portainer                   | minikube | disabled     | portainer.io                   |
</span><span class='line'>| registry                    | minikube | disabled     | google                         |
</span><span class='line'>| registry-aliases            | minikube | disabled     | unknown (third-party)          |
</span><span class='line'>| registry-creds              | minikube | disabled     | third-party (upmc enterprises) |
</span><span class='line'>| storage-provisioner         | minikube | enabled ✅   | google                         |
</span><span class='line'>| storage-provisioner-gluster | minikube | disabled     | unknown (third-party)          |
</span><span class='line'>| volumesnapshots             | minikube | disabled     | kubernetes                     |
</span><span class='line'>|-----------------------------|----------|--------------|--------------------------------|
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ minikube delete --all
</span><span class='line'>* Deleting "minikube" in docker ...
</span><span class='line'>* Removing /home/ec2-user/.minikube/machines/minikube ...
</span><span class='line'>* Removed all traces of the "minikube" cluster.
</span><span class='line'>* Successfully deleted all profiles
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#Create a second cluster running an older Kubernetes release:
</span><span class='line'># minikube start -p aged --kubernetes-version=v1.16.1
</span></code></pre></td></tr></table></div></figure>


<h2>k3d</h2>

<ul>
<li><a href="https://k3d.io/v5.4.1/">https://k3d.io/v5.4.1/</a>
k3d is a lightweight wrapper to run k3s (Rancher Lab’s minimal Kubernetes distribution) in docker.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash
</span><span class='line'>Preparing to install k3d into /usr/local/bin
</span><span class='line'>k3d installed into /usr/local/bin/k3d
</span><span class='line'>Run 'k3d --help' to see what you can do with it.
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ k3d cluster create mycluster
</span><span class='line'>INFO[0000] Prep: Network                                
</span><span class='line'>INFO[0000] Created network 'k3d-mycluster'              
</span><span class='line'>INFO[0000] Created image volume k3d-mycluster-images    
</span><span class='line'>INFO[0000] Starting new tools node...                   
</span><span class='line'>INFO[0001] Creating node 'k3d-mycluster-server-0'       
</span><span class='line'>INFO[0003] Pulling image 'ghcr.io/k3d-io/k3d-tools:5.4.1' 
</span><span class='line'>INFO[0007] Pulling image 'docker.io/rancher/k3s:v1.22.7-k3s1' 
</span><span class='line'>INFO[0009] Starting Node 'k3d-mycluster-tools'          
</span><span class='line'>INFO[0084] Creating LoadBalancer 'k3d-mycluster-serverlb' 
</span><span class='line'>INFO[0087] Pulling image 'ghcr.io/k3d-io/k3d-proxy:5.4.1' 
</span><span class='line'>INFO[0098] Using the k3d-tools node to gather environment information 
</span><span class='line'>INFO[0098] HostIP: using network gateway 172.18.0.1 address 
</span><span class='line'>INFO[0098] Starting cluster 'mycluster'                 
</span><span class='line'>INFO[0098] Starting servers...                          
</span><span class='line'>INFO[0098] Starting Node 'k3d-mycluster-server-0'       
</span><span class='line'>INFO[0104] All agents already running.                  
</span><span class='line'>INFO[0104] Starting helpers...                          
</span><span class='line'>INFO[0104] Starting Node 'k3d-mycluster-serverlb'       
</span><span class='line'>INFO[0111] Injecting records for hostAliases (incl. host.k3d.internal) and for 2 network members into CoreDNS configmap... 
</span><span class='line'>INFO[0114] Cluster 'mycluster' created successfully!    
</span><span class='line'>INFO[0114] You can now use it like this:                
</span><span class='line'>kubectl cluster-info
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker ps 
</span><span class='line'>CONTAINER ID   IMAGE                            COMMAND                  CREATED         STATUS         PORTS                             NAMES
</span><span class='line'>5d57c1328e66   ghcr.io/k3d-io/k3d-proxy:5.4.1   "/bin/sh -c nginx-pr…"   6 minutes ago   Up 6 minutes   80/tcp, 0.0.0.0:41489-&gt;6443/tcp   k3d-mycluster-serverlb
</span><span class='line'>add7ac133348   rancher/k3s:v1.22.7-k3s1         "/bin/k3s server --t…"   6 minutes ago   Up 6 minutes                                     k3d-mycluster-server-0
</span><span class='line'>
</span><span class='line'># 注意：上面的kubectl是minikue的，需要下载
</span><span class='line'>[ec2-user@amazonlinux ~]$ curl -LO https://dl.k8s.io/release/v1.23.0/bin/linux/amd64/kubectl
</span><span class='line'>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
</span><span class='line'>                                 Dload  Upload   Total   Spent    Left  Speed
</span><span class='line'>100   154  100   154    0     0    230      0 --:--:-- --:--:-- --:--:--   230
</span><span class='line'>100 44.4M  100 44.4M    0     0  1989k      0  0:00:22  0:00:22 --:--:-- 2256k
</span><span class='line'>[ec2-user@amazonlinux ~]$ ll
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo cp kubectl /usr/local/bin/
</span><span class='line'>[ec2-user@amazonlinux ~]$ which kubectl
</span><span class='line'>/usr/local/bin/kubectl
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get nodes
</span><span class='line'>NAME                     STATUS   ROLES                  AGE   VERSION
</span><span class='line'>k3d-mycluster-server-0   Ready    control-plane,master   47m   v1.22.7+k3s1
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get pods -A 
</span><span class='line'>NAMESPACE     NAME                                      READY   STATUS      RESTARTS      AGE
</span><span class='line'>kube-system   local-path-provisioner-84bb864455-s8t7f   1/1     Running     0             45m
</span><span class='line'>kube-system   coredns-96cc4f57d-vvmrx                   1/1     Running     0             45m
</span><span class='line'>kube-system   helm-install-traefik-crd--1-ghv9f         0/1     Completed   0             45m
</span><span class='line'>kube-system   helm-install-traefik--1-s4ktb             0/1     Completed   1             45m
</span><span class='line'>kube-system   svclb-traefik-9jt5d                       2/2     Running     1 (44m ago)   44m
</span><span class='line'>kube-system   metrics-server-ff9dbcb6c-72mwc            1/1     Running     0             45m
</span><span class='line'>kube-system   traefik-56c4b88c4b-f454f                  1/1     Running     0             44m
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ k3d cluster list 
</span><span class='line'>NAME        SERVERS   AGENTS   LOADBALANCER
</span><span class='line'>mycluster   1/1       0/0      true
</span><span class='line'>[ec2-user@amazonlinux ~]$ k3d node create worker1 --cluster mycluster
</span><span class='line'>INFO[0000] Adding 1 node(s) to the runtime local cluster 'mycluster'... 
</span><span class='line'>INFO[0000] Using the k3d-tools node to gather environment information 
</span><span class='line'>INFO[0000] Starting new tools node...                   
</span><span class='line'>INFO[0000] Starting Node 'k3d-mycluster-tools'          
</span><span class='line'>INFO[0001] HostIP: using network gateway 172.18.0.1 address 
</span><span class='line'>INFO[0001] Starting Node 'k3d-worker1-0'                
</span><span class='line'>INFO[0009] Successfully created 1 node(s)!              
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get nodes
</span><span class='line'>NAME                     STATUS     ROLES                  AGE   VERSION
</span><span class='line'>k3d-mycluster-server-0   Ready      control-plane,master   50m   v1.22.7+k3s1
</span><span class='line'>k3d-worker1-0            NotReady   &lt;none&gt;                 7s    v1.22.7+k3s1
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get nodes                          
</span><span class='line'>NAME                     STATUS   ROLES                  AGE   VERSION
</span><span class='line'>k3d-mycluster-server-0   Ready    control-plane,master   50m   v1.22.7+k3s1
</span><span class='line'>k3d-worker1-0            Ready    &lt;none&gt;                 24s   v1.22.7+k3s1
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://k3d.io/v5.4.1/usage/exposing_services/">https://k3d.io/v5.4.1/usage/exposing_services/</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ cat .vimrc 
</span><span class='line'>set paste
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ cat thatfile.yaml 
</span><span class='line'>apiVersion: networking.k8s.io/v1
</span><span class='line'>kind: Ingress
</span><span class='line'>metadata:
</span><span class='line'>  name: nginx
</span><span class='line'>  annotations:
</span><span class='line'>    ingress.kubernetes.io/ssl-redirect: "false"
</span><span class='line'>spec:
</span><span class='line'>  rules:
</span><span class='line'>  - http:
</span><span class='line'>      paths:
</span><span class='line'>      - path: /
</span><span class='line'>        pathType: Prefix
</span><span class='line'>        backend:
</span><span class='line'>          service:
</span><span class='line'>            name: nginx
</span><span class='line'>            port:
</span><span class='line'>              number: 80
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ export KUBECONFIG="$(k3d kubeconfig write mycluster)"  
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl create deployment nginx --image=nginx
</span><span class='line'>deployment.apps/nginx created
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl create service clusterip nginx --tcp=80:80
</span><span class='line'>service/nginx created
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl apply -f thatfile.yaml
</span><span class='line'>ingress.networking.k8s.io/nginx created
</span></code></pre></td></tr></table></div></figure>


<p>查看结果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get all -A -o wide
</span><span class='line'>NAMESPACE     NAME                                          READY   STATUS      RESTARTS      AGE     IP          NODE                     NOMINATED NODE   READINESS GATES
</span><span class='line'>kube-system   pod/local-path-provisioner-84bb864455-s8t7f   1/1     Running     0             64m     10.42.0.5   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/coredns-96cc4f57d-vvmrx                   1/1     Running     0             64m     10.42.0.6   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/helm-install-traefik-crd--1-ghv9f         0/1     Completed   0             64m     10.42.0.4   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/helm-install-traefik--1-s4ktb             0/1     Completed   1             64m     10.42.0.3   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/svclb-traefik-9jt5d                       2/2     Running     1 (63m ago)   63m     10.42.0.7   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/metrics-server-ff9dbcb6c-72mwc            1/1     Running     0             64m     10.42.0.2   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/traefik-56c4b88c4b-f454f                  1/1     Running     0             63m     10.42.0.8   k3d-mycluster-server-0   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   pod/svclb-traefik-dvvrp                       2/2     Running     1 (13m ago)   14m     10.42.1.2   k3d-worker1-0            &lt;none&gt;           &lt;none&gt;
</span><span class='line'>default       pod/nginx-6799fc88d8-vgc9x                    1/1     Running     0             4m34s   10.42.1.3   k3d-worker1-0            &lt;none&gt;           &lt;none&gt;
</span><span class='line'>
</span><span class='line'>NAMESPACE     NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP             PORT(S)                      AGE     SELECTOR
</span><span class='line'>default       service/kubernetes       ClusterIP      10.43.0.1       &lt;none&gt;                  443/TCP                      64m     &lt;none&gt;
</span><span class='line'>kube-system   service/kube-dns         ClusterIP      10.43.0.10      &lt;none&gt;                  53/UDP,53/TCP,9153/TCP       64m     k8s-app=kube-dns
</span><span class='line'>kube-system   service/metrics-server   ClusterIP      10.43.88.129    &lt;none&gt;                  443/TCP                      64m     k8s-app=metrics-server
</span><span class='line'>kube-system   service/traefik          LoadBalancer   10.43.4.2       172.18.0.2,172.18.0.4   80:32037/TCP,443:30484/TCP   63m     app.kubernetes.io/instance=traefik,app.kubernetes.io/name=traefik
</span><span class='line'>default       service/nginx            ClusterIP      10.43.206.223   &lt;none&gt;                  80/TCP                       4m30s   app=nginx
</span><span class='line'>
</span><span class='line'>NAMESPACE     NAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS               IMAGES                                                SELECTOR
</span><span class='line'>kube-system   daemonset.apps/svclb-traefik   2         2         2       2            2           &lt;none&gt;          63m   lb-port-80,lb-port-443   rancher/klipper-lb:v0.3.4,rancher/klipper-lb:v0.3.4   app=svclb-traefik
</span><span class='line'>
</span><span class='line'>NAMESPACE     NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS               IMAGES                                   SELECTOR
</span><span class='line'>kube-system   deployment.apps/local-path-provisioner   1/1     1            1           64m     local-path-provisioner   rancher/local-path-provisioner:v0.0.21   app=local-path-provisioner
</span><span class='line'>kube-system   deployment.apps/coredns                  1/1     1            1           64m     coredns                  rancher/mirrored-coredns-coredns:1.8.6   k8s-app=kube-dns
</span><span class='line'>kube-system   deployment.apps/metrics-server           1/1     1            1           64m     metrics-server           rancher/mirrored-metrics-server:v0.5.2   k8s-app=metrics-server
</span><span class='line'>kube-system   deployment.apps/traefik                  1/1     1            1           63m     traefik                  rancher/mirrored-library-traefik:2.6.1   app.kubernetes.io/instance=traefik,app.kubernetes.io/name=traefik
</span><span class='line'>default       deployment.apps/nginx                    1/1     1            1           4m34s   nginx                    nginx                                    app=nginx
</span><span class='line'>
</span><span class='line'>NAMESPACE     NAME                                                DESIRED   CURRENT   READY   AGE     CONTAINERS               IMAGES                                   SELECTOR
</span><span class='line'>kube-system   replicaset.apps/local-path-provisioner-84bb864455   1         1         1       64m     local-path-provisioner   rancher/local-path-provisioner:v0.0.21   app=local-path-provisioner,pod-template-hash=84bb864455
</span><span class='line'>kube-system   replicaset.apps/coredns-96cc4f57d                   1         1         1       64m     coredns                  rancher/mirrored-coredns-coredns:1.8.6   k8s-app=kube-dns,pod-template-hash=96cc4f57d
</span><span class='line'>kube-system   replicaset.apps/metrics-server-ff9dbcb6c            1         1         1       64m     metrics-server           rancher/mirrored-metrics-server:v0.5.2   k8s-app=metrics-server,pod-template-hash=ff9dbcb6c
</span><span class='line'>kube-system   replicaset.apps/traefik-56c4b88c4b                  1         1         1       63m     traefik                  rancher/mirrored-library-traefik:2.6.1   app.kubernetes.io/instance=traefik,app.kubernetes.io/name=traefik,pod-template-hash=56c4b88c4b
</span><span class='line'>default       replicaset.apps/nginx-6799fc88d8                    1         1         1       4m34s   nginx                    nginx                                    app=nginx,pod-template-hash=6799fc88d8
</span><span class='line'>
</span><span class='line'>NAMESPACE     NAME                                 COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES                                      SELECTOR
</span><span class='line'>kube-system   job.batch/helm-install-traefik-crd   1/1           52s        64m   helm         rancher/klipper-helm:v0.6.6-build20211022   controller-uid=1d4ac20d-0436-4d54-9d8b-e37fe7c46e6e
</span><span class='line'>kube-system   job.batch/helm-install-traefik       1/1           53s        64m   helm         rancher/klipper-helm:v0.6.6-build20211022   controller-uid=b51475a5-3fac-4b96-b218-7dd7a094512b
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ kubectl get ingress 
</span><span class='line'>NAME    CLASS    HOSTS   ADDRESS                 PORTS   AGE
</span><span class='line'>nginx   &lt;none&gt;   *       172.18.0.2,172.18.0.4   80      3m18s
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ curl 172.18.0.2
</span><span class='line'>&lt;!DOCTYPE html&gt;
</span><span class='line'>&lt;html&gt;
</span><span class='line'>&lt;head&gt;
</span><span class='line'>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span><span class='line'>&lt;style&gt;
</span><span class='line'>html { color-scheme: light dark; }
</span><span class='line'>body { width: 35em; margin: 0 auto;
</span><span class='line'>font-family: Tahoma, Verdana, Arial, sans-serif; }
</span><span class='line'>&lt;/style&gt;
</span><span class='line'>&lt;/head&gt;
</span><span class='line'>&lt;body&gt;
</span><span class='line'>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span><span class='line'>&lt;p&gt;If you see this page, the nginx web server is successfully installed and
</span><span class='line'>working. Further configuration is required.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;For online documentation and support please refer to
</span><span class='line'>&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
</span><span class='line'>Commercial support is available at
</span><span class='line'>&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
</span><span class='line'>&lt;/body&gt;
</span><span class='line'>&lt;/html&gt;
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2022/03/26/k8s-ingress/">K8s Ingress</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2022-03-26T13:59:16+08:00" pubdate data-updated="true">Sat 2022-03-26 13:59</time>
		
        
		
      </p>
    
  </header>


  <div class="entry-content"><p>Ingress是一个集中的集群应用网关，自动化的k8s反向代理组件（功能类比nginx）。</p>

<p>Ingress涉及到LoadBalancer，Ingress Controller, Ingress config等相关概念。controller从LoadBalancer/NodePort把当前的服务发布出去，同时监听Ingress config实时的修改当前Ingress配置(实时更新nginx.conf配置文件，并重载)</p>

<p>这里仅从helloworld入门实践操作进行。</p>

<h2>入门指南</h2>

<h3>参考</h3>

<ul>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/#quick-start">https://kubernetes.github.io/ingress-nginx/deploy/#quick-start</a></li>
<li><p><a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress/">https://kubernetes.io/zh/docs/concepts/services-networking/ingress/</a></p></li>
<li><p><a href="https://docs.jdcloud.com/cn/jcs-for-kubernetes/deploy-k8s-ingress-nginx">https://docs.jdcloud.com/cn/jcs-for-kubernetes/deploy-k8s-ingress-nginx</a></p></li>
<li><a href="https://jimmysong.io/kubernetes-handbook/concepts/ingress.html">https://jimmysong.io/kubernetes-handbook/concepts/ingress.html</a></li>
</ul>


<p>版本兼容性：
* <a href="https://github.com/kubernetes/ingress-nginx/#support-versions-table">https://github.com/kubernetes/ingress-nginx/#support-versions-table</a></p>

<h3>下载镜像</h3>

<p>镜像在gcr上面，先远程下载回来：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.2/deploy/static/provider/cloud/deploy.yaml 
</span><span class='line'>[ec2-user@k8s ~]$ vi ingress-nginx-controller-v1.1.2.yaml
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ grep image: ingress-nginx-controller-v1.1.2.yaml | sed 's/image: //' | sort -u | xargs echo 
</span><span class='line'>k8s.gcr.io/ingress-nginx/controller:v1.1.2@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660
</span><span class='line'>
</span><span class='line'>[root@izt4nhcmmx33bjwcsdmf8oz ~]# docker pull k8s.gcr.io/ingress-nginx/controller:v1.1.2@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c 
</span><span class='line'>k8s.gcr.io/ingress-nginx/controller@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c: Pulling from ingress-nginx/controller
</span><span class='line'>a0d0a0d46f8b: Pull complete 
</span><span class='line'>3aae86482564: Pull complete 
</span><span class='line'>c0d03781abb3: Pull complete 
</span><span class='line'>0297e2ef8f7f: Pull complete 
</span><span class='line'>866a68ce3c13: Pull complete 
</span><span class='line'>1c2a7ca65b54: Pull complete 
</span><span class='line'>41fd2de30e46: Pull complete 
</span><span class='line'>637f10464e4d: Pull complete 
</span><span class='line'>998064a16da4: Pull complete 
</span><span class='line'>e63d23220e8c: Pull complete 
</span><span class='line'>8128610547fb: Pull complete 
</span><span class='line'>ae07a1a7f038: Pull complete 
</span><span class='line'>ceb23c4cb607: Pull complete 
</span><span class='line'>Digest: sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c
</span><span class='line'>Status: Downloaded newer image for k8s.gcr.io/ingress-nginx/controller@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c
</span><span class='line'>k8s.gcr.io/ingress-nginx/controller:v1.1.2@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c
</span><span class='line'>
</span><span class='line'>[root@izt4nhcmmx33bjwcsdmf8oz ~]# docker pull k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660 
</span><span class='line'>k8s.gcr.io/ingress-nginx/kube-webhook-certgen@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660: Pulling from ingress-nginx/kube-webhook-certgen
</span><span class='line'>ec52731e9273: Pull complete 
</span><span class='line'>b90aa28117d4: Pull complete 
</span><span class='line'>Digest: sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660
</span><span class='line'>Status: Downloaded newer image for k8s.gcr.io/ingress-nginx/kube-webhook-certgen@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660
</span><span class='line'>k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660
</span><span class='line'>
</span><span class='line'>[root@izt4nhcmmx33bjwcsdmf8oz ~]# docker save k8s.gcr.io/ingress-nginx/controller:v1.1.2@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660 -o ingress-nginx-v1.1.2.tar
</span><span class='line'>[root@izt4nhcmmx33bjwcsdmf8oz ~]# gzip ingress-nginx-v1.1.2.tar 
</span><span class='line'>
</span><span class='line'>[root@izt4nhcmmx33bjwcsdmf8oz ~]# ll -h ingress-nginx-v1.1.2.tar.gz 
</span><span class='line'>-rw------- 1 root root 116M Mar 24 23:49 ingress-nginx-v1.1.2.tar.gz
</span></code></pre></td></tr></table></div></figure>


<p>本地Linux服务器加载镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ docker load -i k8s.gcr.io-ingress-nginx-v1.1.2.tar.gz 
</span><span class='line'>c0d270ab7e0d: Loading layer [==================================================&gt;]  3.697MB/3.697MB
</span><span class='line'>ce7a3c1169b6: Loading layer [==================================================&gt;]  45.38MB/45.38MB
</span><span class='line'>e2eb06d8af82: Loading layer [==================================================&gt;]  5.865MB/5.865MB
</span><span class='line'>ab1476f3fdd9: Loading layer [==================================================&gt;]  120.9MB/120.9MB
</span><span class='line'>ad20729656ef: Loading layer [==================================================&gt;]  4.096kB/4.096kB
</span><span class='line'>0d5022138006: Loading layer [==================================================&gt;]  38.09MB/38.09MB
</span><span class='line'>8f757e3fe5e4: Loading layer [==================================================&gt;]  21.42MB/21.42MB
</span><span class='line'>d2bc6b915bc9: Loading layer [==================================================&gt;]  4.019MB/4.019MB
</span><span class='line'>bbeb6784ed45: Loading layer [==================================================&gt;]  313.9kB/313.9kB
</span><span class='line'>0c411e83ee78: Loading layer [==================================================&gt;]  6.141MB/6.141MB
</span><span class='line'>9c2d86dc137f: Loading layer [==================================================&gt;]  38.45MB/38.45MB
</span><span class='line'>7797e5b3a760: Loading layer [==================================================&gt;]  2.754MB/2.754MB
</span><span class='line'>98ef19df5514: Loading layer [==================================================&gt;]  4.096kB/4.096kB
</span><span class='line'>4cde87c7ecaf: Loading layer [==================================================&gt;]  51.75MB/51.75MB
</span><span class='line'>11536690d74a: Loading layer [==================================================&gt;]  3.584kB/3.584kB
</span><span class='line'>Loaded image ID: sha256:c41e9fcadf5a291120de706b7dfa1af598b9f2ed5138b6dcb9f79a68aad0ef4c
</span><span class='line'>Loaded image ID: sha256:7e5c1cecb086f36c6ef4b319a60853020820997f3600c3687e8ba6139e83674d
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ cat k8s.gcr.io-ingress-nginx-v1.1.2.tar.gz | ssh worker1 docker load 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>docker tag 7e5c1cecb086 k8s.gcr.io/ingress-nginx/controller:v1.1.2
</span><span class='line'>docker tag c41e9fcadf5a k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>注：由于配置中用了sha码，下载后tag不同，把image最后的 @sha256:xxx 删掉
</span><span class='line'>vi ingress-nginx-controller-v1.1.2.yaml
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<h3>创建服务</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f ingress-nginx-controller-v1.1.2.yaml
</span><span class='line'>namespace/ingress-nginx created
</span><span class='line'>serviceaccount/ingress-nginx created
</span><span class='line'>serviceaccount/ingress-nginx-admission created
</span><span class='line'>role.rbac.authorization.k8s.io/ingress-nginx created
</span><span class='line'>role.rbac.authorization.k8s.io/ingress-nginx-admission created
</span><span class='line'>clusterrole.rbac.authorization.k8s.io/ingress-nginx created
</span><span class='line'>clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created
</span><span class='line'>rolebinding.rbac.authorization.k8s.io/ingress-nginx created
</span><span class='line'>rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
</span><span class='line'>clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created
</span><span class='line'>clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
</span><span class='line'>configmap/ingress-nginx-controller created
</span><span class='line'>service/ingress-nginx-controller created
</span><span class='line'>service/ingress-nginx-controller-admission created
</span><span class='line'>deployment.apps/ingress-nginx-controller created
</span><span class='line'>job.batch/ingress-nginx-admission-create created
</span><span class='line'>job.batch/ingress-nginx-admission-patch created
</span><span class='line'>ingressclass.networking.k8s.io/nginx created
</span><span class='line'>validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl wait --namespace ingress-nginx \
</span><span class='line'>   --for=condition=ready pod \
</span><span class='line'>   --selector=app.kubernetes.io/component=controller \
</span><span class='line'>   --timeout=120s
</span><span class='line'>pod/ingress-nginx-controller-755447bb4d-rnxvl condition met
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># 状态参考：
</span><span class='line'># https://kubernetes.io/zh/docs/tasks/access-application-cluster/ingress-minikube/
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods --namespace=ingress-nginx
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get all -n ingress-nginx
</span><span class='line'>NAME                                            READY   STATUS      RESTARTS   AGE
</span><span class='line'>pod/ingress-nginx-admission-create-hbt9d        0/1     Completed   0          2m51s
</span><span class='line'>pod/ingress-nginx-admission-patch-j8qfh         0/1     Completed   1          2m51s
</span><span class='line'>pod/ingress-nginx-controller-755447bb4d-rnxvl   1/1     Running     0          2m51s
</span><span class='line'>
</span><span class='line'>NAME                                         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
</span><span class='line'>service/ingress-nginx-controller             LoadBalancer   10.104.8.155    &lt;pending&gt;     80:31031/TCP,443:31845/TCP   2m51s
</span><span class='line'>service/ingress-nginx-controller-admission   ClusterIP      10.108.67.255   &lt;none&gt;        443/TCP                      2m51s
</span><span class='line'>
</span><span class='line'>NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE
</span><span class='line'>deployment.apps/ingress-nginx-controller   1/1     1            1           2m51s
</span><span class='line'>
</span><span class='line'>NAME                                                  DESIRED   CURRENT   READY   AGE
</span><span class='line'>replicaset.apps/ingress-nginx-controller-755447bb4d   1         1         1       2m51s
</span><span class='line'>
</span><span class='line'>NAME                                       COMPLETIONS   DURATION   AGE
</span><span class='line'>job.batch/ingress-nginx-admission-create   1/1           3s         2m51s
</span><span class='line'>job.batch/ingress-nginx-admission-patch    1/1           3s         2m51s
</span></code></pre></td></tr></table></div></figure>


<p>看到 ingress-nginx-controller 服务的 <code>EXTERNAL-IP</code> 为 <code>&lt;pending&gt;</code> ，由于本地搭建并没有配备负载均衡器，所以没有手段，获取不到对外的IP。</p>

<h3>本地测试</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl create deployment demo --image=httpd --port=80
</span><span class='line'>deployment.apps/demo created
</span><span class='line'>[ec2-user@k8s ~]$ kubectl expose deployment demo
</span><span class='line'>service/demo exposed
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl create ingress demo-localhost --class=nginx \
</span><span class='line'>   --rule=demo.localdev.me/*=demo:80
</span><span class='line'>ingress.networking.k8s.io/demo-localhost created
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl port-forward --namespace=ingress-nginx service/ingress-nginx-controller 8080:80
</span><span class='line'>Forwarding from 127.0.0.1:8080 -&gt; 80
</span><span class='line'>Forwarding from [::1]:8080 -&gt; 80
</span><span class='line'>Handling connection for 8080
</span><span class='line'>Handling connection for 8080
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ curl http://demo.localdev.me:8080/
</span><span class='line'>&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;
</span></code></pre></td></tr></table></div></figure>


<p>clean</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl delete deployment demo 
</span><span class='line'>kubectl delete service demo 
</span><span class='line'>kubectl delete ingress demo</span></code></pre></td></tr></table></div></figure>


<h2>集成（发布）</h2>

<h3>cloud</h3>

<ul>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/#aws">https://kubernetes.github.io/ingress-nginx/deploy/#aws</a></li>
</ul>


<p>配置云厂商的负载均衡器。</p>

<h3>baremetal: nodeport</h3>

<p>适用于部署在裸机服务器上的 Kubernetes 集群，以及使用通用 Linux 发行版手动安装 Kubernetes 的 [原始] 虚拟机</p>

<p>为了快速测试，您可以使用 NodePort。这应该适用于几乎每个集群，但它通常会使用 30000-32767 范围内的端口。</p>

<ul>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters">https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters</a></li>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#over-a-nodeport-service">https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#over-a-nodeport-service</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.2/deploy/static/provider/baremetal/deploy.yaml
</span></code></pre></td></tr></table></div></figure>


<p>注：也可以通过修改配置使用80，443等端口，但不推荐。</p>

<h3>baremetal: hostNetwork</h3>

<p>ingress nginx controller的pod网络直接使用主机网络，这个比Service Nodeport稍微灵活一点，可以自己选择/管理端口。</p>

<h3>A pure software solution: MetalLB</h3>

<ul>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#a-pure-software-solution-metallb">https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#a-pure-software-solution-metallb</a></li>
<li><a href="https://metallb.universe.tf/concepts/">https://metallb.universe.tf/concepts/</a></li>
</ul>


<p>It has two features that work together to provide this service: address allocation, and external announcement.</p>

<p>After MetalLB has assigned an external IP address to a service, it needs to make the network beyond the cluster aware that the IP “lives” in the cluster. MetalLB uses standard routing protocols to achieve this: ARP, NDP, or BGP.</p>

<h4>安装</h4>

<ul>
<li><a href="https://metallb.universe.tf/installation/">https://metallb.universe.tf/installation/</a></li>
</ul>


<p>需要kube-proxy配置arp为true。得与局域网进行广播通信，所以需要开启arp功能（标准路由协议）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl edit configmap -n kube-system kube-proxy
</span><span class='line'>
</span><span class='line'>apiVersion: kubeproxy.config.k8s.io/v1alpha1
</span><span class='line'>kind: KubeProxyConfiguration
</span><span class='line'>mode: "ipvs"
</span><span class='line'>ipvs:
</span><span class='line'>  strictARP: true</span></code></pre></td></tr></table></div></figure>


<p>或者批处理一步到位</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># see what changes would be made, returns nonzero returncode if different
</span><span class='line'>kubectl get configmap kube-proxy -n kube-system -o yaml | \
</span><span class='line'>sed -e "s/strictARP: false/strictARP: true/" | \
</span><span class='line'>kubectl diff -f - -n kube-system
</span><span class='line'>
</span><span class='line'># actually apply the changes, returns nonzero returncode on errors only
</span><span class='line'>kubectl get configmap kube-proxy -n kube-system -o yaml | \
</span><span class='line'>sed -e "s/strictARP: false/strictARP: true/" | \
</span><span class='line'>kubectl apply -f - -n kube-system
</span></code></pre></td></tr></table></div></figure>


<p>安装</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.12.1/manifests/namespace.yaml
</span><span class='line'>kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.12.1/manifests/metallb.yaml
</span></code></pre></td></tr></table></div></figure>


<p>下载镜像慢一点，需要稍微多等等。再查看状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl get all -n metallb-system
</span><span class='line'>NAME                             READY   STATUS    RESTARTS   AGE
</span><span class='line'>pod/controller-57fd9c5bb-kc5zt   1/1     Running   0          5m55s
</span><span class='line'>pod/speaker-8pg4v                1/1     Running   0          5m55s
</span><span class='line'>pod/speaker-95bs8                1/1     Running   0          5m55s
</span><span class='line'>
</span><span class='line'>NAME                     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
</span><span class='line'>daemonset.apps/speaker   2         2         2       2            2           kubernetes.io/os=linux   5m55s
</span><span class='line'>
</span><span class='line'>NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
</span><span class='line'>deployment.apps/controller   1/1     1            1           5m55s
</span><span class='line'>
</span><span class='line'>NAME                                   DESIRED   CURRENT   READY   AGE
</span><span class='line'>replicaset.apps/controller-57fd9c5bb   1         1         1       5m55s
</span></code></pre></td></tr></table></div></figure>


<h4>配置地址</h4>

<ul>
<li><p><a href="https://metallb.universe.tf/configuration/#layer-2-configuration">https://metallb.universe.tf/configuration/#layer-2-configuration</a></p></li>
<li><p><a href="https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#a-pure-software-solution-metallb">https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#a-pure-software-solution-metallb</a></p></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 查看主机ip，避开这些节点IP的区间
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get node -o wide
</span><span class='line'>NAME      STATUS   ROLES                  AGE   VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME
</span><span class='line'>k8s       Ready    control-plane,master   10d   v1.23.5   192.168.191.131   &lt;none&gt;        Amazon Linux 2   4.14.268-205.500.amzn2.x86_64   docker://20.10.7
</span><span class='line'>worker1   Ready    &lt;none&gt;                 10d   v1.23.5   192.168.191.132   &lt;none&gt;        Amazon Linux 2   4.14.268-205.500.amzn2.x86_64   docker://20.10.7
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ cat metallb-config.yml
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: ConfigMap
</span><span class='line'>metadata:
</span><span class='line'>  namespace: metallb-system
</span><span class='line'>  name: config
</span><span class='line'>data:
</span><span class='line'>  config: |
</span><span class='line'>    address-pools:
</span><span class='line'>    - name: default
</span><span class='line'>      protocol: layer2
</span><span class='line'>      addresses:
</span><span class='line'>      - 192.168.191.200-192.168.191.220
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f metallb-config.yml 
</span><span class='line'>configmap/config created
</span></code></pre></td></tr></table></div></figure>


<p>然后，再回过头重新安装一遍nginx-ingress：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl get pods --namespace=ingress-nginx
</span><span class='line'>NAME                                        READY   STATUS      RESTARTS   AGE
</span><span class='line'>ingress-nginx-admission-create-b9hkn        0/1     Completed   0          17s
</span><span class='line'>ingress-nginx-admission-patch-xmnbr         0/1     Completed   1          17s
</span><span class='line'>ingress-nginx-controller-755447bb4d-lfrwk   0/1     Running     0          17s
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods --namespace=ingress-nginx
</span><span class='line'>NAME                                        READY   STATUS      RESTARTS   AGE
</span><span class='line'>ingress-nginx-admission-create-b9hkn        0/1     Completed   0          25s
</span><span class='line'>ingress-nginx-admission-patch-xmnbr         0/1     Completed   1          25s
</span><span class='line'>ingress-nginx-controller-755447bb4d-lfrwk   1/1     Running     0          25s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl -n ingress-nginx get svc
</span><span class='line'>NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
</span><span class='line'>ingress-nginx-controller             LoadBalancer   10.107.221.243   192.168.191.200   80:31443/TCP,443:30099/TCP   57s
</span><span class='line'>ingress-nginx-controller-admission   ClusterIP      10.105.12.185    &lt;none&gt;            443/TCP                      57s
</span></code></pre></td></tr></table></div></figure>


<p>这次 EXTERNAL-IP 的ip就有值了，上面配置的ip段里面一个ip。</p>

<h3>在线/集成测试</h3>

<ul>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/#online-testing">https://kubernetes.github.io/ingress-nginx/deploy/#online-testing</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl get service ingress-nginx-controller --namespace=ingress-nginx
</span><span class='line'>NAME                       TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
</span><span class='line'>ingress-nginx-controller   LoadBalancer   10.107.221.243   192.168.191.200   80:31443/TCP,443:30099/TCP   4m
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl create deployment demo --image=httpd --port=80
</span><span class='line'>deployment.apps/demo created
</span><span class='line'>[ec2-user@k8s ~]$ kubectl expose deployment demo
</span><span class='line'>service/demo exposed
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl create ingress demo --class=nginx \
</span><span class='line'>   --rule="www.demo.io/*=demo:80"
</span><span class='line'>ingress.networking.k8s.io/demo created
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get ingress 
</span><span class='line'>NAME   CLASS   HOSTS         ADDRESS   PORTS   AGE
</span><span class='line'>demo   nginx   www.demo.io             80      42s
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get ingress 
</span><span class='line'>NAME   CLASS   HOSTS         ADDRESS           PORTS   AGE
</span><span class='line'>demo   nginx   www.demo.io   192.168.191.200   80      27m
</span></code></pre></td></tr></table></div></figure>


<p>在本地windows机器的 <code>C:/Windows/System32/drivers/etc/hosts</code> 增加 <code>192.168.191.200 www.demo.io</code> ，然后浏览器访问 <code>http://www.demo.io/</code> ，顺利的话就能在浏览器看到：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>It works!</span></code></pre></td></tr></table></div></figure>


<h3>后记</h3>

<h4>理一下网络调用，其实就是nginx的方式：</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl logs --tail=2 pod/demo-764c97f6fd-q5xts
</span><span class='line'>10.244.2.79 - - [28/Mar/2022:09:52:36 +0000] "GET / HTTP/1.1" 200 45
</span><span class='line'>10.244.2.79 - - [28/Mar/2022:09:52:36 +0000] "GET /favicon.ico HTTP/1.1" 404 196
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods -n ingress-nginx -o wide 
</span><span class='line'>NAME                                        READY   STATUS      RESTARTS   AGE    IP            NODE      NOMINATED NODE   READINESS GATES
</span><span class='line'>ingress-nginx-admission-create-b9hkn        0/1     Completed   0          157m   10.244.2.78   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>ingress-nginx-admission-patch-xmnbr         0/1     Completed   1          157m   10.244.2.77   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>ingress-nginx-controller-755447bb4d-lfrwk   1/1     Running     0          157m   10.244.2.79   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>
</span><span class='line'># 192.168.191.1是vmware虚拟网卡的地址
</span><span class='line'>[ec2-user@k8s ~]$ kubectl logs --tail=2 pod/ingress-nginx-controller-755447bb4d-lfrwk -n ingress-nginx 
</span><span class='line'>192.168.191.1 - - [28/Mar/2022:09:52:36 +0000] "GET / HTTP/1.1" 200 45 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.82 Safari/537.36" 566 0.000 [default-demo-80] [] 10.244.2.80:80 45 0.000 200 6d52ef8349eb3101c31c3cc6377b982b
</span><span class='line'>192.168.191.1 - - [28/Mar/2022:09:52:36 +0000] "GET /favicon.ico HTTP/1.1" 404 196 "http://www.demo.io/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.82 Safari/537.36" 506 0.001 [default-demo-80] [] 10.244.2.80:80 196 0.000 404 fefe172a57273977cdcd1455bcf322ac
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>## web
</span><span class='line'>Request URL: http://www.demo.io/
</span><span class='line'>Request Method: GET
</span><span class='line'>Status Code: 200 OK
</span><span class='line'>Remote Address: 192.168.191.200:80
</span><span class='line'>Referrer Policy: strict-origin-when-cross-origin
</span></code></pre></td></tr></table></div></figure>


<h4>看看metallb的日志，ip是怎么分配的</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># https://metallb.universe.tf/concepts/layer2/
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods -n metallb-system -o wide
</span><span class='line'>NAME                         READY   STATUS    RESTARTS   AGE     IP                NODE      NOMINATED NODE   READINESS GATES
</span><span class='line'>controller-57fd9c5bb-kc5zt   1/1     Running   0          3h34m   10.244.2.76       worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>speaker-8pg4v                1/1     Running   0          3h34m   192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>speaker-95bs8                1/1     Running   0          3h34m   192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl logs pod/controller-57fd9c5bb-kc5zt -n metallb-system
</span><span class='line'>{"caller":"level.go:63","event":"ipAllocated","ip":["192.168.191.200"],"level":"info","msg":"IP address assigned by controller","service":"ingress-nginx/ingress-nginx-controller","ts":"2022-03-28T07:16:22.675599527Z"}
</span><span class='line'>{"caller":"level.go:63","event":"serviceUpdated","level":"info","msg":"updated service object","service":"ingress-nginx/ingress-nginx-controller","ts":"2022-03-28T07:1
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl logs speaker-8pg4v -n metallb-system 
</span><span class='line'>{"caller":"level.go:63","event":"serviceAnnounced","ips":["192.168.191.200"],"level":"info","msg":"service has IP, announcing","pool":"default","protocol":"layer2","service":"ingress-nginx/ingress-nginx-controller","ts":"2022-03-28T07:16:42.775467559Z"}
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ ping 192.168.191.200
</span><span class='line'>PING 192.168.191.200 (192.168.191.200) 56(84) bytes of data.
</span><span class='line'>^C
</span><span class='line'>--- 192.168.191.200 ping statistics ---
</span><span class='line'>3 packets transmitted, 0 received, 100% packet loss, time 2055ms
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ arp 
</span><span class='line'>Address                  HWtype  HWaddress           Flags Mask            Iface
</span><span class='line'>192.168.191.200          ether   00:0c:29:d5:4f:0f   C                     eth0
</span><span class='line'>
</span><span class='line'># worker1节点的MAC
</span><span class='line'>[ec2-user@worker1 ~]$ ip a | grep -i -C 10 '00:0c:29:d5:4f:0f' 
</span><span class='line'>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
</span><span class='line'>    link/ether 00:0c:29:d5:4f:0f brd ff:ff:ff:ff:ff:ff
</span><span class='line'>    inet 192.168.191.132/24 brd 192.168.191.255 scope global dynamic eth0
</span><span class='line'>       valid_lft 1714sec preferred_lft 1714sec
</span><span class='line'>
</span><span class='line'># In layer 2 mode, all traffic for a service IP goes to one node. From there, kube-proxy spreads the traffic to all the service’s pods.
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods -A -o wide | grep 192.168.191.132
</span><span class='line'>kube-system            kube-flannel-ds-q4qkt                        1/1     Running     8 (2d10h ago)   11d     192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-proxy-pd77m                             1/1     Running     6 (3d2h ago)    11d     192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>metallb-system         speaker-8pg4v                                1/1     Running     0               5h31m   192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>例子：</h2>

<ul>
<li><a href="https://kubernetes.github.io/ingress-nginx/deploy/#local-testing">https://kubernetes.github.io/ingress-nginx/deploy/#local-testing</a></li>
<li><a href="https://kubernetes.io/zh/docs/tasks/access-application-cluster/ingress-minikube/">https://kubernetes.io/zh/docs/tasks/access-application-cluster/ingress-minikube/</a></li>
</ul>


<h2>验证</h2>

<ul>
<li><a href="https://www.qikqiak.com/post/visually-explained-k8s-service/">图解 Kubernetes Service</a></li>
<li><a href="https://www.qikqiak.com/post/visually-explained-k8s-ingress/">图解 Kubernetes Ingress</a></li>
</ul>


<p>文中说loadbalancer是通过了nodeport（会创建nodeport），还是有点诧异的。验证一番，果真如此！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl get service ingress-nginx-controller --namespace=ingress-nginx
</span><span class='line'>NAME                       TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
</span><span class='line'>ingress-nginx-controller   LoadBalancer   10.107.221.243   192.168.191.200   80:31443/TCP,443:30099/TCP   34m
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl describe service ingress-nginx-controller --namespace=ingress-nginx
</span><span class='line'>Name:                     ingress-nginx-controller
</span><span class='line'>Namespace:                ingress-nginx
</span><span class='line'>Labels:                   app.kubernetes.io/component=controller
</span><span class='line'>                          app.kubernetes.io/instance=ingress-nginx
</span><span class='line'>                          app.kubernetes.io/managed-by=Helm
</span><span class='line'>                          app.kubernetes.io/name=ingress-nginx
</span><span class='line'>                          app.kubernetes.io/part-of=ingress-nginx
</span><span class='line'>                          app.kubernetes.io/version=1.1.2
</span><span class='line'>                          helm.sh/chart=ingress-nginx-4.0.18
</span><span class='line'>Annotations:              &lt;none&gt;
</span><span class='line'>Selector:                 app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx
</span><span class='line'>Type:                     LoadBalancer
</span><span class='line'>IP Family Policy:         SingleStack
</span><span class='line'>IP Families:              IPv4
</span><span class='line'>IP:                       10.107.221.243
</span><span class='line'>IPs:                      10.107.221.243
</span><span class='line'>LoadBalancer Ingress:     192.168.191.200
</span><span class='line'>Port:                     http  80/TCP
</span><span class='line'>TargetPort:               http/TCP
</span><span class='line'>NodePort:                 http  31443/TCP
</span><span class='line'>Endpoints:                10.244.2.79:80
</span><span class='line'>Port:                     https  443/TCP
</span><span class='line'>TargetPort:               https/TCP
</span><span class='line'>NodePort:                 https  30099/TCP
</span><span class='line'>Endpoints:                10.244.2.79:443
</span><span class='line'>Session Affinity:         None
</span><span class='line'>External Traffic Policy:  Local
</span><span class='line'>HealthCheck NodePort:     31942
</span><span class='line'>Events:
</span><span class='line'>  Type    Reason        Age   From                Message
</span><span class='line'>  ----    ------        ----  ----                -------
</span><span class='line'>  Normal  IPAllocated   38m   metallb-controller  Assigned IP ["192.168.191.200"]
</span><span class='line'>  Normal  nodeAssigned  38m   metallb-speaker     announcing from node "worker1"
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ netstat -anp | grep 31443 
</span><span class='line'>(No info could be read for "-p": geteuid()=1002 but you should be root.)
</span><span class='line'>tcp        0      0 0.0.0.0:31443           0.0.0.0:*               LISTEN      -       
</span><span class='line'>
</span><span class='line'>[ec2-user@worker1 ~]$ netstat -anp | grep 31443
</span><span class='line'>(No info could be read for "-p": geteuid()=1002 but you should be root.)
</span><span class='line'>tcp        0      0 0.0.0.0:31443           0.0.0.0:*               LISTEN      -                   
</span></code></pre></td></tr></table></div></figure>


<h2>其他参考</h2>

<ul>
<li><a href="https://blog.51cto.com/tansong/4850092">多种方式访问AWS EKS的 Kubernetes Dashboard 下篇</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 创建证书
</span><span class='line'>openssl genrsa 2048 &gt; k8s-dashboard-private.key
</span><span class='line'>openssl req -new -x509 -nodes -sha1 -days 3650 -extensions v3_ca -key k8s-dashboard-private.key &gt; k8s-dashboard.crt
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://segmentfault.com/a/1190000019908991">k8s ingress原理及ingress-nginx部署测试</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2022/03/18/k8s-guide-use-kubeadm/">k8s-v1.23.5安装指南 - 使用kubeadm</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2022-03-18T11:58:48+08:00" pubdate data-updated="true">Fri 2022-03-18 11:58</time>
		
        
		
      </p>
    
  </header>


  <div class="entry-content"><p>注[2022-03-25]：如果后面需要用AWS，用Amazon的操作系统会便利一点。aws的命令这些都自带了。</p>

<p>本文是在 Amazon Linux 2 系统上安装部署的，和centos7.3基本相似。</p>

<p>和k8s软件依赖需要访问google的，已经在前面一篇文章中下载好，本文中会直接使用。依赖的软件可以在百度网盘下载：</p>

<pre><code>链接：https://pan.baidu.com/s/1P3ABqKGt1JhNkg-9yB22yQ 
提取码：k7af
</code></pre>

<h2>安装 amazon-linux-2 操作系统</h2>

<ul>
<li><a href="https://docs.amazonaws.cn/AWSEC2/latest/UserGuide/amazon-linux-2-virtual-machine.html#amazon-linux-2-virtual-machine-download">步骤 2：下载 Amazon Linux 2 VM 映像</a></li>
<li>下载 <a href="https://cdn.amazonlinux.com/os-images/2.0.20220218.3/">https://cdn.amazonlinux.com/os-images/2.0.20220218.3/</a></li>
</ul>


<p>这里下载vmware使用的镜像 <code>amzn2-vmware_esx-2.0.20220218.3-x86_64.xfs.gpt.ova</code> 和初始化配置 <code>Seed.iso</code> 。</p>

<p>这里简单说下，其实ova已经是可以直接用的，文档中讲的很多内容是辅助系统定制初始化的。user-data用于创建用户和修改文件内容，meta-data配置主机名和网络ip设置。为了本地开发测试，我们直接用默认提供 <code>Seed.iso</code> 即可，登录使用 <code>ec2-user:amazon</code> 。</p>

<p>然后双击 ova 文件，就可以导入创建一个虚拟机出来了。</p>

<ul>
<li>修改网络适配器为NAT模式；</li>
<li>添加CD/DVD设备，选择 <code>Seed.iso</code> ISO映射文件；</li>
<li>开机登录系统后，打开sshd的密码登录。</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo ifup eth0
</span><span class='line'>$ ip a
</span><span class='line'>
</span><span class='line'>$ sudo vi /etc/ssh/sshd_config
</span><span class='line'>#PasswordAuthentication no
</span><span class='line'>
</span><span class='line'>$ sudo service sshd reload 
</span></code></pre></td></tr></table></div></figure>


<h2>安装docker</h2>

<p>k8s需要容器运行时软件，我们先安装好docker。</p>

<ul>
<li><a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#docker">https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#docker</a></li>
</ul>


<p>aws linux 2有它自己的docker源，使用docker官网文档的方式依赖有些找不到。直接按照aws官方文档中提供的方式安装。</p>

<h3>坑</h3>

<p>一开始是按照docker官网在centos的方式安装的，但yum repo的变量不对上，改了releasever后，然后依赖的版本找不到。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://docs.docker.com/engine/install/centos/
</span><span class='line'>[ec2-user@amazonlinux ~]$ cat /etc/issue
</span><span class='line'>\S
</span><span class='line'>Kernel \r on an \m
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ yum-debug-dump
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>Output written to: /home/ec2-user/yum_debug_dump-amazonlinux.onprem-2022-03-17_02:16:37.txt.gz
</span><span class='line'>[ec2-user@amazonlinux ~]$ less /home/ec2-user/yum_debug_dump-amazonlinux.onprem-2022-03-17_02:16:37.txt.gz
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span><span class='line'>
</span><span class='line'>$releasever的值,这个表示当前系统的发行版本，可以通过rpm -qi centos-release命令查看，结果如下：
</span><span class='line'>$basearch是我们的系统硬件架构(CPU指令集),使用命令arch得到
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo sed -i 's/$releasever/7/g' /etc/yum.repos.d/docker-ce.repo 
</span><span class='line'>
</span><span class='line'>## 缺少依赖
</span></code></pre></td></tr></table></div></figure>


<h3>正式安装docker</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo yum update -y
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo amazon-linux-extras install docker
</span><span class='line'>Installing docker
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>Cleaning repos: amzn2-core amzn2extra-docker
</span><span class='line'>12 metadata files removed
</span><span class='line'>4 sqlite files removed
</span><span class='line'>0 metadata files removed
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>amzn2-core                                                                                                                                        | 3.7 kB  00:00:00     
</span><span class='line'>amzn2extra-docker                                                                                                                                 | 3.0 kB  00:00:00     
</span><span class='line'>(1/5): amzn2-core/2/x86_64/group_gz                                                                                                               | 2.5 kB  00:00:00     
</span><span class='line'>(2/5): amzn2extra-docker/2/x86_64/updateinfo                                                                                                      | 5.9 kB  00:00:00     
</span><span class='line'>(3/5): amzn2-core/2/x86_64/updateinfo                                                                                                             | 452 kB  00:00:01     
</span><span class='line'>(4/5): amzn2extra-docker/2/x86_64/primary_db                                                                                                      |  86 kB  00:00:00     
</span><span class='line'>(5/5): amzn2-core/2/x86_64/primary_db                                                                                                             |  60 MB  00:01:42     
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package docker.x86_64 0:20.10.7-5.amzn2 will be installed
</span><span class='line'>--&gt; Processing Dependency: runc &gt;= 1.0.0 for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libcgroup &gt;= 0.40.rc1-5.15 for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Processing Dependency: containerd &gt;= 1.3.2 for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Processing Dependency: pigz for package: docker-20.10.7-5.amzn2.x86_64
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package containerd.x86_64 0:1.4.6-8.amzn2 will be installed
</span><span class='line'>---&gt; Package libcgroup.x86_64 0:0.41-21.amzn2 will be installed
</span><span class='line'>---&gt; Package pigz.x86_64 0:2.3.4-1.amzn2.0.1 will be installed
</span><span class='line'>---&gt; Package runc.x86_64 0:1.0.0-2.amzn2 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>=========================================================================================================================================================================
</span><span class='line'> Package                               Arch                              Version                                      Repository                                    Size
</span><span class='line'>=========================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> docker                                x86_64                            20.10.7-5.amzn2                              amzn2extra-docker                             42 M
</span><span class='line'>Installing for dependencies:
</span><span class='line'> containerd                            x86_64                            1.4.6-8.amzn2                                amzn2extra-docker                             24 M
</span><span class='line'> libcgroup                             x86_64                            0.41-21.amzn2                                amzn2-core                                    66 k
</span><span class='line'> pigz                                  x86_64                            2.3.4-1.amzn2.0.1                            amzn2-core                                    81 k
</span><span class='line'> runc                                  x86_64                            1.0.0-2.amzn2                                amzn2extra-docker                            3.3 M
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>=========================================================================================================================================================================
</span><span class='line'>Install  1 Package (+4 Dependent packages)
</span><span class='line'>
</span><span class='line'>Total download size: 69 M
</span><span class='line'>Installed size: 285 M
</span><span class='line'>Is this ok [y/d/N]: y
</span><span class='line'>Downloading packages:
</span><span class='line'>(1/5): pigz-2.3.4-1.amzn2.0.1.x86_64.rpm                                                                                                          |  81 kB  00:00:00     
</span><span class='line'>(2/5): libcgroup-0.41-21.amzn2.x86_64.rpm                                                                                                         |  66 kB  00:00:00     
</span><span class='line'>(3/5): containerd-1.4.6-8.amzn2.x86_64.rpm                                                                                                        |  24 MB  00:01:14     
</span><span class='line'>(4/5): runc-1.0.0-2.amzn2.x86_64.rpm                                                                                                              | 3.3 MB  00:00:10     
</span><span class='line'>(5/5): docker-20.10.7-5.amzn2.x86_64.rpm                                                                                                          |  42 MB  00:01:50     
</span><span class='line'>-------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class='line'>Total                                                                                                                                    641 kB/s |  69 MB  00:01:50     
</span><span class='line'>Running transaction check
</span><span class='line'>Running transaction test
</span><span class='line'>Transaction test succeeded
</span><span class='line'>Running transaction
</span><span class='line'>  Installing : runc-1.0.0-2.amzn2.x86_64                                                                                                                             1/5 
</span><span class='line'>  Installing : containerd-1.4.6-8.amzn2.x86_64                                                                                                                       2/5 
</span><span class='line'>  Installing : libcgroup-0.41-21.amzn2.x86_64                                                                                                                        3/5 
</span><span class='line'>  Installing : pigz-2.3.4-1.amzn2.0.1.x86_64                                                                                                                         4/5 
</span><span class='line'>  Installing : docker-20.10.7-5.amzn2.x86_64                                                                                                                         5/5 
</span><span class='line'>  Verifying  : docker-20.10.7-5.amzn2.x86_64                                                                                                                         1/5 
</span><span class='line'>  Verifying  : containerd-1.4.6-8.amzn2.x86_64                                                                                                                       2/5 
</span><span class='line'>  Verifying  : runc-1.0.0-2.amzn2.x86_64                                                                                                                             3/5 
</span><span class='line'>  Verifying  : pigz-2.3.4-1.amzn2.0.1.x86_64                                                                                                                         4/5 
</span><span class='line'>  Verifying  : libcgroup-0.41-21.amzn2.x86_64                                                                                                                        5/5 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  docker.x86_64 0:20.10.7-5.amzn2                                                                                                                                        
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  containerd.x86_64 0:1.4.6-8.amzn2           libcgroup.x86_64 0:0.41-21.amzn2           pigz.x86_64 0:2.3.4-1.amzn2.0.1           runc.x86_64 0:1.0.0-2.amzn2          
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>  0  ansible2                 available    \
</span><span class='line'>        [ =2.4.2  =2.4.6  =2.8  =stable ]
</span><span class='line'>  2  httpd_modules            available    [ =1.0  =stable ]
</span><span class='line'>  3  memcached1.5             available    \
</span><span class='line'>        [ =1.5.1  =1.5.16  =1.5.17 ]
</span><span class='line'>  5  postgresql9.6            available    \
</span><span class='line'>        [ =9.6.6  =9.6.8  =stable ]
</span><span class='line'>  6  postgresql10             available    [ =10  =stable ]
</span><span class='line'>  9  R3.4                     available    [ =3.4.3  =stable ]
</span><span class='line'> 10  rust1                    available    \
</span><span class='line'>        [ =1.22.1  =1.26.0  =1.26.1  =1.27.2  =1.31.0  =1.38.0
</span><span class='line'>          =stable ]
</span><span class='line'> 11  vim                      available    [ =8.0  =stable ]
</span><span class='line'> 18  libreoffice              available    \
</span><span class='line'>        [ =5.0.6.2_15  =5.3.6.1  =stable ]
</span><span class='line'> 19  gimp                     available    [ =2.8.22 ]
</span><span class='line'> 20  docker=latest            enabled      \
</span><span class='line'>        [ =17.12.1  =18.03.1  =18.06.1  =18.09.9  =stable ]
</span><span class='line'> 21  mate-desktop1.x          available    \
</span><span class='line'>        [ =1.19.0  =1.20.0  =stable ]
</span><span class='line'> 22  GraphicsMagick1.3        available    \
</span><span class='line'>        [ =1.3.29  =1.3.32  =1.3.34  =stable ]
</span><span class='line'> 23  tomcat8.5                available    \
</span><span class='line'>        [ =8.5.31  =8.5.32  =8.5.38  =8.5.40  =8.5.42  =8.5.50
</span><span class='line'>          =stable ]
</span><span class='line'> 24  epel                     available    [ =7.11  =stable ]
</span><span class='line'> 25  testing                  available    [ =1.0  =stable ]
</span><span class='line'> 26  ecs                      available    [ =stable ]
</span><span class='line'> 27  corretto8                available    \
</span><span class='line'>        [ =1.8.0_192  =1.8.0_202  =1.8.0_212  =1.8.0_222  =1.8.0_232
</span><span class='line'>          =1.8.0_242  =stable ]
</span><span class='line'> 28  firecracker              available    [ =0.11  =stable ]
</span><span class='line'> 29  golang1.11               available    \
</span><span class='line'>        [ =1.11.3  =1.11.11  =1.11.13  =stable ]
</span><span class='line'> 30  squid4                   available    [ =4  =stable ]
</span><span class='line'> 32  lustre2.10               available    \
</span><span class='line'>        [ =2.10.5  =2.10.8  =stable ]
</span><span class='line'> 33  java-openjdk11           available    [ =11  =stable ]
</span><span class='line'> 34  lynis                    available    [ =stable ]
</span><span class='line'> 35  kernel-ng                available    [ =stable ]
</span><span class='line'> 36  BCC                      available    [ =0.x  =stable ]
</span><span class='line'> 37  mono                     available    [ =5.x  =stable ]
</span><span class='line'> 38  nginx1                   available    [ =stable ]
</span><span class='line'> 39  ruby2.6                  available    [ =2.6  =stable ]
</span><span class='line'> 40  mock                     available    [ =stable ]
</span><span class='line'> 41  postgresql11             available    [ =11  =stable ]
</span><span class='line'> 42  php7.4                   available    [ =stable ]
</span><span class='line'> 43  livepatch                available    [ =stable ]
</span><span class='line'> 44  python3.8                available    [ =stable ]
</span><span class='line'> 45  haproxy2                 available    [ =stable ]
</span><span class='line'> 46  collectd                 available    [ =stable ]
</span><span class='line'> 47  aws-nitro-enclaves-cli   available    [ =stable ]
</span><span class='line'> 48  R4                       available    [ =stable ]
</span><span class='line'> 49  kernel-5.4               available    [ =stable ]
</span><span class='line'> 50  selinux-ng               available    [ =stable ]
</span><span class='line'> 51  php8.0                   available    [ =stable ]
</span><span class='line'> 52  tomcat9                  available    [ =stable ]
</span><span class='line'> 53  unbound1.13              available    [ =stable ]
</span><span class='line'> 54  mariadb10.5              available    [ =stable ]
</span><span class='line'> 55  kernel-5.10              available    [ =stable ]
</span><span class='line'> 56  redis6                   available    [ =stable ]
</span><span class='line'> 57  ruby3.0                  available    [ =stable ]
</span><span class='line'> 58  postgresql12             available    [ =stable ]
</span><span class='line'> 59  postgresql13             available    [ =stable ]
</span><span class='line'> 60  mock2                    available    [ =stable ]
</span><span class='line'> 61  dnsmasq2.85              available    [ =stable ]
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo service docker start
</span><span class='line'>Redirecting to /bin/systemctl start docker.service
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo systemctl enable docker
</span><span class='line'>Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo usermod -a -G docker ec2-user
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker info
</span><span class='line'>Client:
</span><span class='line'> Context:    default
</span><span class='line'> Debug Mode: false
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'>ERROR: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.24/info": dial unix /var/run/docker.sock: connect: permission denied
</span><span class='line'>errors pretty printing info
</span><span class='line'>[ec2-user@amazonlinux ~]$ exit
</span><span class='line'>退出后再次连接：
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker info 
</span><span class='line'>Client:
</span><span class='line'> Context:    default
</span><span class='line'> Debug Mode: false
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Containers: 0
</span><span class='line'>  Running: 0
</span><span class='line'>  Paused: 0
</span><span class='line'>  Stopped: 0
</span><span class='line'> Images: 0
</span><span class='line'> Server Version: 20.10.7
</span><span class='line'> Storage Driver: overlay2
</span><span class='line'>  Backing Filesystem: xfs
</span><span class='line'>  Supports d_type: true
</span><span class='line'>  Native Overlay Diff: true
</span><span class='line'>  userxattr: false
</span><span class='line'> Logging Driver: json-file
</span><span class='line'> Cgroup Driver: cgroupfs
</span><span class='line'> Cgroup Version: 1
</span><span class='line'> Plugins:
</span><span class='line'>  Volume: local
</span><span class='line'>  Network: bridge host ipvlan macvlan null overlay
</span><span class='line'>  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
</span><span class='line'> Swarm: inactive
</span><span class='line'> Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc
</span><span class='line'> Default Runtime: runc
</span><span class='line'> Init Binary: docker-init
</span><span class='line'> containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d
</span><span class='line'> runc version: 84113eef6fc27af1b01b3181f31bbaf708715301
</span><span class='line'> init version: de40ad0
</span><span class='line'> Security Options:
</span><span class='line'>  seccomp
</span><span class='line'>   Profile: default
</span><span class='line'> Kernel Version: 4.14.268-205.500.amzn2.x86_64
</span><span class='line'> Operating System: Amazon Linux 2
</span><span class='line'> OSType: linux
</span><span class='line'> Architecture: x86_64
</span><span class='line'> CPUs: 2
</span><span class='line'> Total Memory: 3.828GiB
</span><span class='line'> Name: amazonlinux.onprem
</span><span class='line'> ID: GENW:47BV:UJR2:247P:CPFE:PHSO:RA6Z:H4RK:HYEE:LXN3:XDIZ:SI6Q
</span><span class='line'> Docker Root Dir: /var/lib/docker
</span><span class='line'> Debug Mode: false
</span><span class='line'> Registry: https://index.docker.io/v1/
</span><span class='line'> Labels:
</span><span class='line'> Experimental: false
</span><span class='line'> Insecure Registries:
</span><span class='line'>  127.0.0.0/8
</span><span class='line'> Live Restore Enabled: false
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo yum install telnet -y
</span></code></pre></td></tr></table></div></figure>


<h2>准备工作</h2>

<p>可以先了解一些基本概念
* <a href="https://www.jianshu.com/p/7bc34ff88d9d">Kubernetes in Action 笔记 —— 部署第一个应用</a></p>

<ul>
<li><a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#%E5%87%86%E5%A4%87%E5%BC%80%E5%A7%8B">准备开始</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 确保每个节点上 MAC 地址和 product_uuid 的唯一性
</span><span class='line'>[ec2-user@amazonlinux ~]$ ip link
</span><span class='line'>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
</span><span class='line'>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span><span class='line'>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
</span><span class='line'>    link/ether 00:0c:29:a4:a6:fc brd ff:ff:ff:ff:ff:ff
</span><span class='line'>[ec2-user@amazonlinux ~]$ ifconfig -a
</span><span class='line'>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
</span><span class='line'>        inet 192.168.191.131  netmask 255.255.255.0  broadcast 192.168.191.255
</span><span class='line'>        inet6 fe80::20c:29ff:fea4:a6fc  prefixlen 64  scopeid 0x20&lt;link&gt;
</span><span class='line'>        ether 00:0c:29:a4:a6:fc  txqueuelen 1000  (Ethernet)
</span><span class='line'>        RX packets 1737  bytes 288390 (281.6 KiB)
</span><span class='line'>        RX errors 0  dropped 0  overruns 0  frame 0
</span><span class='line'>        TX packets 1704  bytes 139101 (135.8 KiB)
</span><span class='line'>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span><span class='line'>
</span><span class='line'>lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
</span><span class='line'>        inet 127.0.0.1  netmask 255.0.0.0
</span><span class='line'>        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;
</span><span class='line'>        loop  txqueuelen 1000  (Local Loopback)
</span><span class='line'>        RX packets 625  bytes 57768 (56.4 KiB)
</span><span class='line'>        RX errors 0  dropped 0  overruns 0  frame 0
</span><span class='line'>        TX packets 625  bytes 57768 (56.4 KiB)
</span><span class='line'>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo cat /sys/class/dmi/id/product_uuid
</span><span class='line'>564DD81E-DEBE-B06D-CF35-D7E3DDA4A6FC
</span><span class='line'>
</span><span class='line'>## 检查网络适配器
</span><span class='line'># 只有一个网卡，跳过
</span><span class='line'>
</span><span class='line'>## 允许 iptables 检查桥接流量
</span><span class='line'>[ec2-user@amazonlinux ~]$ lsmod | grep br_netfilter
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo modprobe br_netfilter
</span><span class='line'>[ec2-user@amazonlinux ~]$ lsmod | grep br_netfilter 
</span><span class='line'>br_netfilter           24576  0
</span><span class='line'>bridge                172032  1 br_netfilter
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span><span class='line'>br_netfilter
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span><span class='line'>net.bridge.bridge-nf-call-ip6tables = 1
</span><span class='line'>net.bridge.bridge-nf-call-iptables = 1
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo sysctl --system
</span><span class='line'>* Applying /etc/sysctl.d/00-defaults.conf ...
</span><span class='line'>kernel.printk = 8 4 1 7
</span><span class='line'>kernel.panic = 30
</span><span class='line'>net.ipv4.neigh.default.gc_thresh1 = 0
</span><span class='line'>net.ipv6.neigh.default.gc_thresh1 = 0
</span><span class='line'>net.ipv4.neigh.default.gc_thresh2 = 15360
</span><span class='line'>net.ipv6.neigh.default.gc_thresh2 = 15360
</span><span class='line'>net.ipv4.neigh.default.gc_thresh3 = 16384
</span><span class='line'>net.ipv6.neigh.default.gc_thresh3 = 16384
</span><span class='line'>* Applying /usr/lib/sysctl.d/00-system.conf ...
</span><span class='line'>net.bridge.bridge-nf-call-ip6tables = 0
</span><span class='line'>net.bridge.bridge-nf-call-iptables = 0
</span><span class='line'>net.bridge.bridge-nf-call-arptables = 0
</span><span class='line'>* Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
</span><span class='line'>kernel.yama.ptrace_scope = 0
</span><span class='line'>* Applying /usr/lib/sysctl.d/50-default.conf ...
</span><span class='line'>kernel.sysrq = 16
</span><span class='line'>kernel.core_uses_pid = 1
</span><span class='line'>kernel.kptr_restrict = 1
</span><span class='line'>net.ipv4.conf.default.rp_filter = 1
</span><span class='line'>net.ipv4.conf.all.rp_filter = 1
</span><span class='line'>net.ipv4.conf.default.accept_source_route = 0
</span><span class='line'>net.ipv4.conf.all.accept_source_route = 0
</span><span class='line'>net.ipv4.conf.default.promote_secondaries = 1
</span><span class='line'>net.ipv4.conf.all.promote_secondaries = 1
</span><span class='line'>fs.protected_hardlinks = 1
</span><span class='line'>fs.protected_symlinks = 1
</span><span class='line'>* Applying /etc/sysctl.d/99-amazon.conf ...
</span><span class='line'>kernel.sched_autogroup_enabled = 0
</span><span class='line'>* Applying /etc/sysctl.d/99-sysctl.conf ...
</span><span class='line'>* Applying /etc/sysctl.d/k8s.conf ...
</span><span class='line'>net.bridge.bridge-nf-call-ip6tables = 1
</span><span class='line'>net.bridge.bridge-nf-call-iptables = 1
</span><span class='line'>* Applying /etc/sysctl.conf ...
</span><span class='line'>
</span><span class='line'>## SELINUX
</span><span class='line'>sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 
</span><span class='line'>setenforce 0
</span><span class='line'>
</span><span class='line'>## Docker
</span><span class='line'>cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json
</span><span class='line'>{
</span><span class='line'>  "exec-opts": ["native.cgroupdriver=systemd"],
</span><span class='line'>  "log-driver": "json-file",
</span><span class='line'>  "log-opts": {
</span><span class='line'>    "max-size": "100m"
</span><span class='line'>  },
</span><span class='line'>  "storage-driver": "overlay2"
</span><span class='line'>}
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'>sudo systemctl enable docker
</span><span class='line'>sudo systemctl daemon-reload
</span><span class='line'>sudo systemctl restart docker
</span></code></pre></td></tr></table></div></figure>


<p>修改时区</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo rm -rf /etc/localtime 
</span><span class='line'>sudo ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime </span></code></pre></td></tr></table></div></figure>


<h2>主节点安装kubeadm并加载docker镜像</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 修改主机名
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo hostnamectl --static set-hostname k8s 
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo hostname k8s 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ rz
</span><span class='line'>rz waiting to receive.
</span><span class='line'>Starting zmodem transfer.  Press Ctrl+C to cancel.
</span><span class='line'>Transferring ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64.rpm...
</span><span class='line'>  100%    9253 KB    9253 KB/sec    00:00:01       0 Errors  
</span><span class='line'>Transferring d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64.rpm...
</span><span class='line'>  100%   21041 KB    21041 KB/sec    00:00:01       0 Errors  
</span><span class='line'>Transferring 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64.rpm...
</span><span class='line'>  100%    7228 KB    7228 KB/sec    00:00:01       0 Errors  
</span><span class='line'>Transferring db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64.rpm...
</span><span class='line'>  100%   19030 KB    19030 KB/sec    00:00:01       0 Errors  
</span><span class='line'>Transferring 96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64.rpm...
</span><span class='line'>  100%    9689 KB    9689 KB/sec    00:00:01       0 Errors  
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo yum install -y *.rpm
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>Examining 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64.rpm: cri-tools-1.23.0-0.x86_64
</span><span class='line'>Marking 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64.rpm to be installed
</span><span class='line'>Examining 96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64.rpm: kubectl-1.23.5-0.x86_64
</span><span class='line'>Marking 96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64.rpm to be installed
</span><span class='line'>Examining ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64.rpm: kubeadm-1.23.5-0.x86_64
</span><span class='line'>Marking ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64.rpm to be installed
</span><span class='line'>Examining d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64.rpm: kubelet-1.23.5-0.x86_64
</span><span class='line'>Marking d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64.rpm to be installed
</span><span class='line'>Examining db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64.rpm: kubernetes-cni-0.8.7-0.x86_64
</span><span class='line'>Marking db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64.rpm to be installed
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package cri-tools.x86_64 0:1.23.0-0 will be installed
</span><span class='line'>---&gt; Package kubeadm.x86_64 0:1.23.5-0 will be installed
</span><span class='line'>---&gt; Package kubectl.x86_64 0:1.23.5-0 will be installed
</span><span class='line'>---&gt; Package kubelet.x86_64 0:1.23.5-0 will be installed
</span><span class='line'>--&gt; Processing Dependency: conntrack for package: kubelet-1.23.5-0.x86_64
</span><span class='line'>--&gt; Processing Dependency: ebtables for package: kubelet-1.23.5-0.x86_64
</span><span class='line'>--&gt; Processing Dependency: socat for package: kubelet-1.23.5-0.x86_64
</span><span class='line'>---&gt; Package kubernetes-cni.x86_64 0:0.8.7-0 will be installed
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package conntrack-tools.x86_64 0:1.4.4-5.amzn2.2 will be installed
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>---&gt; Package ebtables.x86_64 0:2.0.10-16.amzn2.0.1 will be installed
</span><span class='line'>---&gt; Package socat.x86_64 0:1.7.3.2-2.amzn2.0.1 will be installed
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package libnetfilter_cthelper.x86_64 0:1.0.0-10.amzn2.1 will be installed
</span><span class='line'>---&gt; Package libnetfilter_cttimeout.x86_64 0:1.0.0-6.amzn2.1 will be installed
</span><span class='line'>---&gt; Package libnetfilter_queue.x86_64 0:1.0.2-2.amzn2.0.2 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>======================================================================================================================================================
</span><span class='line'> Package                Arch   Version             Repository                                                                                    Size
</span><span class='line'>======================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> cri-tools              x86_64 1.23.0-0            /4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64   34 M
</span><span class='line'> kubeadm                x86_64 1.23.5-0            /ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64     43 M
</span><span class='line'> kubectl                x86_64 1.23.5-0            /96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64     44 M
</span><span class='line'> kubelet                x86_64 1.23.5-0            /d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64    119 M
</span><span class='line'> kubernetes-cni         x86_64 0.8.7-0             /db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64
</span><span class='line'>                                                                                                                                                 55 M
</span><span class='line'>Installing for dependencies:
</span><span class='line'> conntrack-tools        x86_64 1.4.4-5.amzn2.2     amzn2-core                                                                                   186 k
</span><span class='line'> ebtables               x86_64 2.0.10-16.amzn2.0.1 amzn2-core                                                                                   122 k
</span><span class='line'> libnetfilter_cthelper  x86_64 1.0.0-10.amzn2.1    amzn2-core                                                                                    18 k
</span><span class='line'> libnetfilter_cttimeout x86_64 1.0.0-6.amzn2.1     amzn2-core                                                                                    18 k
</span><span class='line'> libnetfilter_queue     x86_64 1.0.2-2.amzn2.0.2   amzn2-core                                                                                    24 k
</span><span class='line'> socat                  x86_64 1.7.3.2-2.amzn2.0.1 amzn2-core                                                                                   291 k
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>======================================================================================================================================================
</span><span class='line'>Install  5 Packages (+6 Dependent packages)
</span><span class='line'>
</span><span class='line'>Total size: 296 M
</span><span class='line'>Total download size: 658 k
</span><span class='line'>Installed size: 298 M
</span><span class='line'>Downloading packages:
</span><span class='line'>(1/6): ebtables-2.0.10-16.amzn2.0.1.x86_64.rpm                                                                                 | 122 kB  00:00:10     
</span><span class='line'>(2/6): libnetfilter_cthelper-1.0.0-10.amzn2.1.x86_64.rpm                                                                       |  18 kB  00:00:00     
</span><span class='line'>(3/6): conntrack-tools-1.4.4-5.amzn2.2.x86_64.rpm                                                                              | 186 kB  00:00:10     
</span><span class='line'>(4/6): libnetfilter_cttimeout-1.0.0-6.amzn2.1.x86_64.rpm                                                                       |  18 kB  00:00:00     
</span><span class='line'>(5/6): libnetfilter_queue-1.0.2-2.amzn2.0.2.x86_64.rpm                                                                         |  24 kB  00:00:00     
</span><span class='line'>(6/6): socat-1.7.3.2-2.amzn2.0.1.x86_64.rpm                                                                                    | 291 kB  00:00:00     
</span><span class='line'>------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class='line'>Total                                                                                                                  45 kB/s | 658 kB  00:00:14     
</span><span class='line'>Running transaction check
</span><span class='line'>Running transaction test
</span><span class='line'>Transaction test succeeded
</span><span class='line'>Running transaction
</span><span class='line'>  Installing : libnetfilter_cthelper-1.0.0-10.amzn2.1.x86_64                                                                                     1/11 
</span><span class='line'>  Installing : libnetfilter_cttimeout-1.0.0-6.amzn2.1.x86_64                                                                                     2/11 
</span><span class='line'>  Installing : libnetfilter_queue-1.0.2-2.amzn2.0.2.x86_64                                                                                       3/11 
</span><span class='line'>  Installing : conntrack-tools-1.4.4-5.amzn2.2.x86_64                                                                                            4/11 
</span><span class='line'>  Installing : ebtables-2.0.10-16.amzn2.0.1.x86_64                                                                                               5/11 
</span><span class='line'>  Installing : cri-tools-1.23.0-0.x86_64                                                                                                         6/11 
</span><span class='line'>  Installing : socat-1.7.3.2-2.amzn2.0.1.x86_64                                                                                                  7/11 
</span><span class='line'>  Installing : kubelet-1.23.5-0.x86_64                                                                                                           8/11 
</span><span class='line'>  Installing : kubernetes-cni-0.8.7-0.x86_64                                                                                                     9/11 
</span><span class='line'>  Installing : kubectl-1.23.5-0.x86_64                                                                                                          10/11 
</span><span class='line'>  Installing : kubeadm-1.23.5-0.x86_64                                                                                                          11/11 
</span><span class='line'>  Verifying  : kubernetes-cni-0.8.7-0.x86_64                                                                                                     1/11 
</span><span class='line'>  Verifying  : kubectl-1.23.5-0.x86_64                                                                                                           2/11 
</span><span class='line'>  Verifying  : socat-1.7.3.2-2.amzn2.0.1.x86_64                                                                                                  3/11 
</span><span class='line'>  Verifying  : cri-tools-1.23.0-0.x86_64                                                                                                         4/11 
</span><span class='line'>  Verifying  : ebtables-2.0.10-16.amzn2.0.1.x86_64                                                                                               5/11 
</span><span class='line'>  Verifying  : libnetfilter_queue-1.0.2-2.amzn2.0.2.x86_64                                                                                       6/11 
</span><span class='line'>  Verifying  : conntrack-tools-1.4.4-5.amzn2.2.x86_64                                                                                            7/11 
</span><span class='line'>  Verifying  : libnetfilter_cttimeout-1.0.0-6.amzn2.1.x86_64                                                                                     8/11 
</span><span class='line'>  Verifying  : kubeadm-1.23.5-0.x86_64                                                                                                           9/11 
</span><span class='line'>  Verifying  : kubelet-1.23.5-0.x86_64                                                                                                          10/11 
</span><span class='line'>  Verifying  : libnetfilter_cthelper-1.0.0-10.amzn2.1.x86_64                                                                                    11/11 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  cri-tools.x86_64 0:1.23.0-0   kubeadm.x86_64 0:1.23.5-0   kubectl.x86_64 0:1.23.5-0   kubelet.x86_64 0:1.23.5-0   kubernetes-cni.x86_64 0:0.8.7-0  
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  conntrack-tools.x86_64 0:1.4.4-5.amzn2.2          ebtables.x86_64 0:2.0.10-16.amzn2.0.1           libnetfilter_cthelper.x86_64 0:1.0.0-10.amzn2.1  
</span><span class='line'>  libnetfilter_cttimeout.x86_64 0:1.0.0-6.amzn2.1   libnetfilter_queue.x86_64 0:1.0.2-2.amzn2.0.2   socat.x86_64 0:1.7.3.2-2.amzn2.0.1               
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ sudo yum install ebtables ethtool             
</span></code></pre></td></tr></table></div></figure>


<p>加载docker镜像：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ docker load -i k8s.tar.gz 
</span><span class='line'>194a408e97d8: Loading layer [==================================================&gt;]  68.57MB/68.57MB
</span><span class='line'>2b8347a02bc5: Loading layer [==================================================&gt;]  1.509MB/1.509MB
</span><span class='line'>618b3e11ccba: Loading layer [==================================================&gt;]  44.17MB/44.17MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-proxy:v1.23.5
</span><span class='line'>5b1fa8e3e100: Loading layer [==================================================&gt;]  3.697MB/3.697MB
</span><span class='line'>83e216f0eb98: Loading layer [==================================================&gt;]  1.509MB/1.509MB
</span><span class='line'>a70573edad24: Loading layer [==================================================&gt;]  121.1MB/121.1MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-controller-manager:v1.23.5
</span><span class='line'>46576c5a6a97: Loading layer [==================================================&gt;]  49.63MB/49.63MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-scheduler:v1.23.5
</span><span class='line'>6d75f23be3dd: Loading layer [==================================================&gt;]  3.697MB/3.697MB
</span><span class='line'>b6e8c573c18d: Loading layer [==================================================&gt;]  2.257MB/2.257MB
</span><span class='line'>d80003ff5706: Loading layer [==================================================&gt;]    267MB/267MB
</span><span class='line'>664dd6f2834b: Loading layer [==================================================&gt;]  2.137MB/2.137MB
</span><span class='line'>62ae031121b1: Loading layer [==================================================&gt;]  18.86MB/18.86MB
</span><span class='line'>Loaded image: k8s.gcr.io/etcd:3.5.1-0
</span><span class='line'>256bc5c338a6: Loading layer [==================================================&gt;]  336.4kB/336.4kB
</span><span class='line'>80e4a2390030: Loading layer [==================================================&gt;]  46.62MB/46.62MB
</span><span class='line'>Loaded image: k8s.gcr.io/coredns/coredns:v1.8.6
</span><span class='line'>1021ef88c797: Loading layer [==================================================&gt;]  684.5kB/684.5kB
</span><span class='line'>Loaded image: k8s.gcr.io/pause:3.6
</span><span class='line'>50098fdfecae: Loading layer [==================================================&gt;]  131.3MB/131.3MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-apiserver:v1.23.5
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ docker images 
</span><span class='line'>REPOSITORY                           TAG       IMAGE ID       CREATED        SIZE
</span><span class='line'>k8s.gcr.io/kube-apiserver            v1.23.5   3fc1d62d6587   15 hours ago   135MB
</span><span class='line'>k8s.gcr.io/kube-proxy                v1.23.5   3c53fa8541f9   15 hours ago   112MB
</span><span class='line'>k8s.gcr.io/kube-controller-manager   v1.23.5   b0c9e5e4dbb1   15 hours ago   125MB
</span><span class='line'>k8s.gcr.io/kube-scheduler            v1.23.5   884d49d6d8c9   15 hours ago   53.5MB
</span><span class='line'>k8s.gcr.io/etcd                      3.5.1-0   25f8c7f3da61   4 months ago   293MB
</span><span class='line'>k8s.gcr.io/coredns/coredns           v1.8.6    a4ca41631cc7   5 months ago   46.8MB
</span><span class='line'>k8s.gcr.io/pause                     3.6       6270bb605e12   6 months ago   683kB
</span><span class='line'>[ec2-user@k8s ~]$ 
</span></code></pre></td></tr></table></div></figure>


<h2>主节点(控制平面control-plane node)启动服务</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ sudo su - 
</span><span class='line'>
</span><span class='line'>[root@k8s ~]# kubeadm init 
</span><span class='line'>[init] Using Kubernetes version: v1.23.5
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>        [WARNING FileExisting-tc]: tc not found in system path
</span><span class='line'>        [WARNING Hostname]: hostname "k8s" could not be reached
</span><span class='line'>        [WARNING Hostname]: hostname "k8s": lookup k8s on 192.168.191.2:53: no such host
</span><span class='line'>        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
</span><span class='line'>[preflight] Pulling images required for setting up a Kubernetes cluster
</span><span class='line'>[preflight] This might take a minute or two, depending on the speed of your internet connection
</span><span class='line'>[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
</span><span class='line'>[certs] Using certificateDir folder "/etc/kubernetes/pki"
</span><span class='line'>[certs] Generating "ca" certificate and key
</span><span class='line'>[certs] Generating "apiserver" certificate and key
</span><span class='line'>[certs] apiserver serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.191.131]
</span><span class='line'>[certs] Generating "apiserver-kubelet-client" certificate and key
</span><span class='line'>[certs] Generating "front-proxy-ca" certificate and key
</span><span class='line'>[certs] Generating "front-proxy-client" certificate and key
</span><span class='line'>[certs] Generating "etcd/ca" certificate and key
</span><span class='line'>[certs] Generating "etcd/server" certificate and key
</span><span class='line'>[certs] etcd/server serving cert is signed for DNS names [k8s localhost] and IPs [192.168.191.131 127.0.0.1 ::1]
</span><span class='line'>[certs] Generating "etcd/peer" certificate and key
</span><span class='line'>[certs] etcd/peer serving cert is signed for DNS names [k8s localhost] and IPs [192.168.191.131 127.0.0.1 ::1]
</span><span class='line'>[certs] Generating "etcd/healthcheck-client" certificate and key
</span><span class='line'>[certs] Generating "apiserver-etcd-client" certificate and key
</span><span class='line'>[certs] Generating "sa" key and public key
</span><span class='line'>[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
</span><span class='line'>[kubeconfig] Writing "admin.conf" kubeconfig file
</span><span class='line'>[kubeconfig] Writing "kubelet.conf" kubeconfig file
</span><span class='line'>[kubeconfig] Writing "controller-manager.conf" kubeconfig file
</span><span class='line'>[kubeconfig] Writing "scheduler.conf" kubeconfig file
</span><span class='line'>[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
</span><span class='line'>[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
</span><span class='line'>[kubelet-start] Starting the kubelet
</span><span class='line'>[control-plane] Using manifest folder "/etc/kubernetes/manifests"
</span><span class='line'>[control-plane] Creating static Pod manifest for "kube-apiserver"
</span><span class='line'>[control-plane] Creating static Pod manifest for "kube-controller-manager"
</span><span class='line'>[control-plane] Creating static Pod manifest for "kube-scheduler"
</span><span class='line'>[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
</span><span class='line'>[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
</span><span class='line'>[kubelet-check] Initial timeout of 40s passed.
</span><span class='line'>[apiclient] All control plane components are healthy after 87.001525 seconds
</span><span class='line'>[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
</span><span class='line'>[kubelet] Creating a ConfigMap "kubelet-config-1.23" in namespace kube-system with the configuration for the kubelets in the cluster
</span><span class='line'>NOTE: The "kubelet-config-1.23" naming of the kubelet ConfigMap is deprecated. Once the UnversionedKubeletConfigMap feature gate graduates to Beta the default name will become just "kubelet-config". Kubeadm upgrade will handle this transition transparently.
</span><span class='line'>[upload-certs] Skipping phase. Please see --upload-certs
</span><span class='line'>[mark-control-plane] Marking the node k8s as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
</span><span class='line'>[mark-control-plane] Marking the node k8s as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
</span><span class='line'>[bootstrap-token] Using token: sj6fff.bpak7gkd3hnyzcm5
</span><span class='line'>[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
</span><span class='line'>[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
</span><span class='line'>[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
</span><span class='line'>[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
</span><span class='line'>[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
</span><span class='line'>[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
</span><span class='line'>[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
</span><span class='line'>[addons] Applied essential addon: CoreDNS
</span><span class='line'>[addons] Applied essential addon: kube-proxy
</span><span class='line'>
</span><span class='line'>Your Kubernetes control-plane has initialized successfully!
</span><span class='line'>
</span><span class='line'>To start using your cluster, you need to run the following as a regular user:
</span><span class='line'>
</span><span class='line'>  mkdir -p $HOME/.kube
</span><span class='line'>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>  sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>Alternatively, if you are the root user, you can run:
</span><span class='line'>
</span><span class='line'>  export KUBECONFIG=/etc/kubernetes/admin.conf
</span><span class='line'>
</span><span class='line'>You should now deploy a pod network to the cluster.
</span><span class='line'>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
</span><span class='line'>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span><span class='line'>
</span><span class='line'>Then you can join any number of worker nodes by running the following on each as root:
</span><span class='line'>
</span><span class='line'>kubeadm join 192.168.191.131:6443 --token sj6fff.bpak7gkd3hnyzcm5 \
</span><span class='line'>        --discovery-token-ca-cert-hash sha256:8e15649afc0771e80cce7f1dfdbb0933f4fdbd45ea1f9e03be1f3b78449a6d3c 
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<p>普通用户配置kubectl：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ mkdir -p $HOME/.kube
</span><span class='line'>[ec2-user@k8s ~]$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span><span class='line'>[ec2-user@k8s ~]$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ which kubectl
</span><span class='line'>/usr/bin/kubectl
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>[ec2-user@k8s ~]$ kubectl cluster-info
</span><span class='line'>Kubernetes control plane is running at https://192.168.191.131:6443
</span><span class='line'>CoreDNS is running at https://192.168.191.131:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
</span><span class='line'>
</span><span class='line'>To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get nodes -o wide
</span><span class='line'>NAME   STATUS     ROLES                  AGE   VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME
</span><span class='line'>k8s    NotReady   control-plane,master   14m   v1.23.5   192.168.191.131   &lt;none&gt;        Amazon Linux 2   4.14.268-205.500.amzn2.x86_64   docker://20.10.7
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods --all-namespaces -o wide
</span><span class='line'>NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE   IP                NODE     NOMINATED NODE   READINESS GATES
</span><span class='line'>kube-system   coredns-64897985d-pcxpd       0/1     Pending   0          14m   &lt;none&gt;            &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   coredns-64897985d-pfsj6       0/1     Pending   0          14m   &lt;none&gt;            &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   etcd-k8s                      1/1     Running   0          14m   192.168.191.131   k8s      &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-apiserver-k8s            1/1     Running   0          14m   192.168.191.131   k8s      &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-controller-manager-k8s   1/1     Running   0          14m   192.168.191.131   k8s      &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-proxy-qj6lw              1/1     Running   0          14m   192.168.191.131   k8s      &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-scheduler-k8s            1/1     Running   0          14m   192.168.191.131   k8s      &lt;none&gt;           &lt;none&gt;
</span><span class='line'>[ec2-user@k8s ~]$ 
</span></code></pre></td></tr></table></div></figure>


<p>如果希望主节点（控制平面节点control-plane node)上也调度 Pod， 例如用于开发的单机 Kubernetes 集群，请运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@k8s ~]# export KUBECONFIG=/etc/kubernetes/admin.conf
</span><span class='line'>[root@k8s ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
</span><span class='line'>node/k8s untainted
</span><span class='line'>[root@k8s ~]# 
</span></code></pre></td></tr></table></div></figure>


<h2>加入工作节点(nodes)</h2>

<p>先把docker安装好，以及系统基础配置，参考上面的步骤。然后安装kubeadm，以及加载gcr的docker镜像。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@amazonlinux ~]$ ll
</span><span class='line'>total 285480
</span><span class='line'>-rw-r--r-- 1 ec2-user ec2-user   7401938 Mar 17 15:22 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 ec2-user ec2-user   9921646 Mar 17 15:22 96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 ec2-user ec2-user   9475514 Mar 17 15:22 ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 ec2-user ec2-user  21546750 Mar 17 15:22 d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 ec2-user ec2-user  19487362 Mar 17 15:22 db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 ec2-user ec2-user 224482960 Mar 17 15:22 k8s.tar.gz
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo yum install *.rpm 
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>Examining 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64.rpm: cri-tools-1.23.0-0.x86_64
</span><span class='line'>Marking 4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64.rpm to be installed
</span><span class='line'>Examining 96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64.rpm: kubectl-1.23.5-0.x86_64
</span><span class='line'>Marking 96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64.rpm to be installed
</span><span class='line'>Examining ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64.rpm: kubeadm-1.23.5-0.x86_64
</span><span class='line'>Marking ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64.rpm to be installed
</span><span class='line'>Examining d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64.rpm: kubelet-1.23.5-0.x86_64
</span><span class='line'>Marking d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64.rpm to be installed
</span><span class='line'>Examining db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64.rpm: kubernetes-cni-0.8.7-0.x86_64
</span><span class='line'>Marking db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64.rpm to be installed
</span><span class='line'>Resolving Dependencies
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package cri-tools.x86_64 0:1.23.0-0 will be installed
</span><span class='line'>---&gt; Package kubeadm.x86_64 0:1.23.5-0 will be installed
</span><span class='line'>---&gt; Package kubectl.x86_64 0:1.23.5-0 will be installed
</span><span class='line'>---&gt; Package kubelet.x86_64 0:1.23.5-0 will be installed
</span><span class='line'>--&gt; Processing Dependency: conntrack for package: kubelet-1.23.5-0.x86_64
</span><span class='line'>amzn2-core                                                                                                                                  | 3.7 kB  00:00:00     
</span><span class='line'>--&gt; Processing Dependency: ebtables for package: kubelet-1.23.5-0.x86_64
</span><span class='line'>--&gt; Processing Dependency: socat for package: kubelet-1.23.5-0.x86_64
</span><span class='line'>---&gt; Package kubernetes-cni.x86_64 0:0.8.7-0 will be installed
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package conntrack-tools.x86_64 0:1.4.4-5.amzn2.2 will be installed
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>--&gt; Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-5.amzn2.2.x86_64
</span><span class='line'>---&gt; Package ebtables.x86_64 0:2.0.10-16.amzn2.0.1 will be installed
</span><span class='line'>---&gt; Package socat.x86_64 0:1.7.3.2-2.amzn2.0.1 will be installed
</span><span class='line'>--&gt; Running transaction check
</span><span class='line'>---&gt; Package libnetfilter_cthelper.x86_64 0:1.0.0-10.amzn2.1 will be installed
</span><span class='line'>---&gt; Package libnetfilter_cttimeout.x86_64 0:1.0.0-6.amzn2.1 will be installed
</span><span class='line'>---&gt; Package libnetfilter_queue.x86_64 0:1.0.2-2.amzn2.0.2 will be installed
</span><span class='line'>--&gt; Finished Dependency Resolution
</span><span class='line'>
</span><span class='line'>Dependencies Resolved
</span><span class='line'>
</span><span class='line'>===================================================================================================================================================================
</span><span class='line'> Package                  Arch     Version                 Repository                                                                                         Size
</span><span class='line'>===================================================================================================================================================================
</span><span class='line'>Installing:
</span><span class='line'> cri-tools                x86_64   1.23.0-0                /4d300a7655f56307d35f127d99dc192b6aa4997f322234e754f16aaa60fd8906-cri-tools-1.23.0-0.x86_64        34 M
</span><span class='line'> kubeadm                  x86_64   1.23.5-0                /ab0e12925be5251baf5dd3b31493663d46e4a7b458c7a5b6b717f4ae87a81bd4-kubeadm-1.23.5-0.x86_64          43 M
</span><span class='line'> kubectl                  x86_64   1.23.5-0                /96b208380314a19ded917eaf125ed748f5e2b28a3cc8707a10a76a9f5b61c0df-kubectl-1.23.5-0.x86_64          44 M
</span><span class='line'> kubelet                  x86_64   1.23.5-0                /d39aa6eb38a6a8326b7e88c622107327dfd02ac8aaae32eceb856643a2ad9981-kubelet-1.23.5-0.x86_64         119 M
</span><span class='line'> kubernetes-cni           x86_64   0.8.7-0                 /db7cb5cb0b3f6875f54d10f02e625573988e3e91fd4fc5eef0b1876bb18604ad-kubernetes-cni-0.8.7-0.x86_64    55 M
</span><span class='line'>Installing for dependencies:
</span><span class='line'> conntrack-tools          x86_64   1.4.4-5.amzn2.2         amzn2-core                                                                                        186 k
</span><span class='line'> ebtables                 x86_64   2.0.10-16.amzn2.0.1     amzn2-core                                                                                        122 k
</span><span class='line'> libnetfilter_cthelper    x86_64   1.0.0-10.amzn2.1        amzn2-core                                                                                         18 k
</span><span class='line'> libnetfilter_cttimeout   x86_64   1.0.0-6.amzn2.1         amzn2-core                                                                                         18 k
</span><span class='line'> libnetfilter_queue       x86_64   1.0.2-2.amzn2.0.2       amzn2-core                                                                                         24 k
</span><span class='line'> socat                    x86_64   1.7.3.2-2.amzn2.0.1     amzn2-core                                                                                        291 k
</span><span class='line'>
</span><span class='line'>Transaction Summary
</span><span class='line'>===================================================================================================================================================================
</span><span class='line'>Install  5 Packages (+6 Dependent packages)
</span><span class='line'>
</span><span class='line'>Total size: 296 M
</span><span class='line'>Total download size: 658 k
</span><span class='line'>Installed size: 298 M
</span><span class='line'>Is this ok [y/d/N]: y
</span><span class='line'>Downloading packages:
</span><span class='line'>(1/6): ebtables-2.0.10-16.amzn2.0.1.x86_64.rpm                                                                                              | 122 kB  00:00:00     
</span><span class='line'>(2/6): libnetfilter_cthelper-1.0.0-10.amzn2.1.x86_64.rpm                                                                                    |  18 kB  00:00:00     
</span><span class='line'>(3/6): libnetfilter_cttimeout-1.0.0-6.amzn2.1.x86_64.rpm                                                                                    |  18 kB  00:00:00     
</span><span class='line'>(4/6): conntrack-tools-1.4.4-5.amzn2.2.x86_64.rpm                                                                                           | 186 kB  00:00:00     
</span><span class='line'>(5/6): libnetfilter_queue-1.0.2-2.amzn2.0.2.x86_64.rpm                                                                                      |  24 kB  00:00:00     
</span><span class='line'>(6/6): socat-1.7.3.2-2.amzn2.0.1.x86_64.rpm                                                                                                 | 291 kB  00:00:00     
</span><span class='line'>-------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class='line'>Total                                                                                                                              1.0 MB/s | 658 kB  00:00:00     
</span><span class='line'>Running transaction check
</span><span class='line'>Running transaction test
</span><span class='line'>Transaction test succeeded
</span><span class='line'>Running transaction
</span><span class='line'>  Installing : libnetfilter_cthelper-1.0.0-10.amzn2.1.x86_64                                                                                                  1/11 
</span><span class='line'>  Installing : libnetfilter_cttimeout-1.0.0-6.amzn2.1.x86_64                                                                                                  2/11 
</span><span class='line'>  Installing : libnetfilter_queue-1.0.2-2.amzn2.0.2.x86_64                                                                                                    3/11 
</span><span class='line'>  Installing : conntrack-tools-1.4.4-5.amzn2.2.x86_64                                                                                                         4/11 
</span><span class='line'>  Installing : ebtables-2.0.10-16.amzn2.0.1.x86_64                                                                                                            5/11 
</span><span class='line'>  Installing : cri-tools-1.23.0-0.x86_64                                                                                                                      6/11 
</span><span class='line'>  Installing : socat-1.7.3.2-2.amzn2.0.1.x86_64                                                                                                               7/11 
</span><span class='line'>  Installing : kubelet-1.23.5-0.x86_64                                                                                                                        8/11 
</span><span class='line'>  Installing : kubernetes-cni-0.8.7-0.x86_64                                                                                                                  9/11 
</span><span class='line'>  Installing : kubectl-1.23.5-0.x86_64                                                                                                                       10/11 
</span><span class='line'>  Installing : kubeadm-1.23.5-0.x86_64                                                                                                                       11/11 
</span><span class='line'>  Verifying  : kubernetes-cni-0.8.7-0.x86_64                                                                                                                  1/11 
</span><span class='line'>  Verifying  : kubectl-1.23.5-0.x86_64                                                                                                                        2/11 
</span><span class='line'>  Verifying  : socat-1.7.3.2-2.amzn2.0.1.x86_64                                                                                                               3/11 
</span><span class='line'>  Verifying  : cri-tools-1.23.0-0.x86_64                                                                                                                      4/11 
</span><span class='line'>  Verifying  : ebtables-2.0.10-16.amzn2.0.1.x86_64                                                                                                            5/11 
</span><span class='line'>  Verifying  : libnetfilter_queue-1.0.2-2.amzn2.0.2.x86_64                                                                                                    6/11 
</span><span class='line'>  Verifying  : conntrack-tools-1.4.4-5.amzn2.2.x86_64                                                                                                         7/11 
</span><span class='line'>  Verifying  : libnetfilter_cttimeout-1.0.0-6.amzn2.1.x86_64                                                                                                  8/11 
</span><span class='line'>  Verifying  : kubeadm-1.23.5-0.x86_64                                                                                                                        9/11 
</span><span class='line'>  Verifying  : kubelet-1.23.5-0.x86_64                                                                                                                       10/11 
</span><span class='line'>  Verifying  : libnetfilter_cthelper-1.0.0-10.amzn2.1.x86_64                                                                                                 11/11 
</span><span class='line'>
</span><span class='line'>Installed:
</span><span class='line'>  cri-tools.x86_64 0:1.23.0-0     kubeadm.x86_64 0:1.23.5-0     kubectl.x86_64 0:1.23.5-0     kubelet.x86_64 0:1.23.5-0     kubernetes-cni.x86_64 0:0.8.7-0    
</span><span class='line'>
</span><span class='line'>Dependency Installed:
</span><span class='line'>  conntrack-tools.x86_64 0:1.4.4-5.amzn2.2              ebtables.x86_64 0:2.0.10-16.amzn2.0.1               libnetfilter_cthelper.x86_64 0:1.0.0-10.amzn2.1      
</span><span class='line'>  libnetfilter_cttimeout.x86_64 0:1.0.0-6.amzn2.1       libnetfilter_queue.x86_64 0:1.0.2-2.amzn2.0.2       socat.x86_64 0:1.7.3.2-2.amzn2.0.1                   
</span><span class='line'>
</span><span class='line'>Complete!
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo yum install ebtables ethtool  
</span><span class='line'>Loaded plugins: langpacks, priorities, update-motd
</span><span class='line'>Package ebtables-2.0.10-16.amzn2.0.1.x86_64 already installed and latest version
</span><span class='line'>Package 2:ethtool-4.8-10.amzn2.x86_64 already installed and latest version
</span><span class='line'>Nothing to do
</span></code></pre></td></tr></table></div></figure>


<p>加载docker镜像</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker load -i k8s.tar.gz 
</span><span class='line'>194a408e97d8: Loading layer [==================================================&gt;]  68.57MB/68.57MB
</span><span class='line'>2b8347a02bc5: Loading layer [==================================================&gt;]  1.509MB/1.509MB
</span><span class='line'>618b3e11ccba: Loading layer [==================================================&gt;]  44.17MB/44.17MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-proxy:v1.23.5
</span><span class='line'>5b1fa8e3e100: Loading layer [==================================================&gt;]  3.697MB/3.697MB
</span><span class='line'>83e216f0eb98: Loading layer [==================================================&gt;]  1.509MB/1.509MB
</span><span class='line'>a70573edad24: Loading layer [==================================================&gt;]  121.1MB/121.1MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-controller-manager:v1.23.5
</span><span class='line'>46576c5a6a97: Loading layer [==================================================&gt;]  49.63MB/49.63MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-scheduler:v1.23.5
</span><span class='line'>6d75f23be3dd: Loading layer [==================================================&gt;]  3.697MB/3.697MB
</span><span class='line'>b6e8c573c18d: Loading layer [==================================================&gt;]  2.257MB/2.257MB
</span><span class='line'>d80003ff5706: Loading layer [==================================================&gt;]    267MB/267MB
</span><span class='line'>664dd6f2834b: Loading layer [==================================================&gt;]  2.137MB/2.137MB
</span><span class='line'>62ae031121b1: Loading layer [==================================================&gt;]  18.86MB/18.86MB
</span><span class='line'>Loaded image: k8s.gcr.io/etcd:3.5.1-0
</span><span class='line'>256bc5c338a6: Loading layer [==================================================&gt;]  336.4kB/336.4kB
</span><span class='line'>80e4a2390030: Loading layer [==================================================&gt;]  46.62MB/46.62MB
</span><span class='line'>Loaded image: k8s.gcr.io/coredns/coredns:v1.8.6
</span><span class='line'>1021ef88c797: Loading layer [==================================================&gt;]  684.5kB/684.5kB
</span><span class='line'>Loaded image: k8s.gcr.io/pause:3.6
</span><span class='line'>50098fdfecae: Loading layer [==================================================&gt;]  131.3MB/131.3MB
</span><span class='line'>Loaded image: k8s.gcr.io/kube-apiserver:v1.23.5
</span><span class='line'>
</span><span class='line'>[ec2-user@amazonlinux ~]$ docker images 
</span><span class='line'>REPOSITORY                           TAG       IMAGE ID       CREATED        SIZE
</span><span class='line'>k8s.gcr.io/kube-apiserver            v1.23.5   3fc1d62d6587   15 hours ago   135MB
</span><span class='line'>k8s.gcr.io/kube-proxy                v1.23.5   3c53fa8541f9   15 hours ago   112MB
</span><span class='line'>k8s.gcr.io/kube-controller-manager   v1.23.5   b0c9e5e4dbb1   15 hours ago   125MB
</span><span class='line'>k8s.gcr.io/kube-scheduler            v1.23.5   884d49d6d8c9   15 hours ago   53.5MB
</span><span class='line'>k8s.gcr.io/etcd                      3.5.1-0   25f8c7f3da61   4 months ago   293MB
</span><span class='line'>k8s.gcr.io/coredns/coredns           v1.8.6    a4ca41631cc7   5 months ago   46.8MB
</span><span class='line'>k8s.gcr.io/pause                     3.6       6270bb605e12   6 months ago   683kB
</span><span class='line'>[ec2-user@amazonlinux ~]$ 
</span></code></pre></td></tr></table></div></figure>


<p>中间出了个小插曲，一开始没有改主机名，导致加入节点的时刻用的是默认的，这样看起来不清晰，后面改了名称后就不认了。得重新弄一遍。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 加入节点
</span><span class='line'>[ec2-user@amazonlinux ~]$ sudo su -
</span><span class='line'>[root@amazonlinux ~]# kubeadm join 192.168.191.131:6443 --token sj6fff.bpak7gkd3hnyzcm5 \
</span><span class='line'>         --discovery-token-ca-cert-hash sha256:8e15649afc0771e80cce7f1dfdbb0933f4fdbd45ea1f9e03be1f3b78449a6d3c 
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>        [WARNING FileExisting-tc]: tc not found in system path
</span><span class='line'>        [WARNING Hostname]: hostname "amazonlinux.onprem" could not be reached
</span><span class='line'>        [WARNING Hostname]: hostname "amazonlinux.onprem": lookup amazonlinux.onprem on 192.168.191.2:53: no such host
</span><span class='line'>        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
</span><span class='line'>[preflight] Reading configuration from the cluster...
</span><span class='line'>[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
</span><span class='line'>[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
</span><span class='line'>[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
</span><span class='line'>[kubelet-start] Starting the kubelet
</span><span class='line'>[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
</span><span class='line'>
</span><span class='line'>This node has joined the cluster:
</span><span class='line'>* Certificate signing request was sent to apiserver and a response was received.
</span><span class='line'>* The Kubelet was informed of the new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
</span><span class='line'>
</span><span class='line'>[root@amazonlinux ~]# 
</span><span class='line'>
</span><span class='line'>## 改下主机名称：
</span><span class='line'>[root@amazonlinux ~]# hostnamectl --static set-hostname worker1
</span><span class='line'>[root@amazonlinux ~]# hostname worker1
</span><span class='line'>[root@amazonlinux ~]# exit
</span><span class='line'>
</span><span class='line'>## 改了一下名，重启后不行了，重新加入
</span><span class='line'>[ec2-user@worker1 ~]$ sudo su - 
</span><span class='line'>Last login: Thu Mar 17 15:24:32 CST 2022 on pts/0
</span><span class='line'>
</span><span class='line'>[root@worker1 ~]# kubeadm join 192.168.191.131:6443 --token sj6fff.bpak7gkd3hnyzcm5 \
</span><span class='line'>          --discovery-token-ca-cert-hash sha256:8e15649afc0771e80cce7f1dfdbb0933f4fdbd45ea1f9e03be1f3b78449a6d3c 
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>        [WARNING FileExisting-tc]: tc not found in system path
</span><span class='line'>        [WARNING Hostname]: hostname "worker1" could not be reached
</span><span class='line'>        [WARNING Hostname]: hostname "worker1": lookup worker1 on 192.168.191.2:53: no such host
</span><span class='line'>        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
</span><span class='line'>error execution phase preflight: [preflight] Some fatal errors occurred:
</span><span class='line'>        [ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists
</span><span class='line'>        [ERROR Port-10250]: Port 10250 is in use
</span><span class='line'>        [ERROR FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists
</span><span class='line'>[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
</span><span class='line'>To see the stack trace of this error execute with --v=5 or higher
</span><span class='line'>
</span><span class='line'>## 直接重新加入不行，需要先重置再加入
</span><span class='line'>[root@worker1 ~]# kubeadm reset 
</span><span class='line'>[reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.
</span><span class='line'>[reset] Are you sure you want to proceed? [y/N]: y
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>W0317 17:42:03.050519    6887 removeetcdmember.go:80] [reset] No kubeadm config, using etcd pod spec to get data directory
</span><span class='line'>[reset] No etcd config found. Assuming external etcd
</span><span class='line'>[reset] Please, manually reset etcd to prevent further issues
</span><span class='line'>[reset] Stopping the kubelet service
</span><span class='line'>[reset] Unmounting mounted directories in "/var/lib/kubelet"
</span><span class='line'>[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
</span><span class='line'>[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]
</span><span class='line'>[reset] Deleting contents of stateful directories: [/var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni]
</span><span class='line'>
</span><span class='line'>The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d
</span><span class='line'>
</span><span class='line'>The reset process does not reset or clean up iptables rules or IPVS tables.
</span><span class='line'>If you wish to reset iptables, you must do so manually by using the "iptables" command.
</span><span class='line'>
</span><span class='line'>If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
</span><span class='line'>to reset your system's IPVS tables.
</span><span class='line'>
</span><span class='line'>The reset process does not clean your kubeconfig files and you must remove them manually.
</span><span class='line'>Please, check the contents of the $HOME/.kube/config file.
</span><span class='line'>
</span><span class='line'>[root@worker1 ~]# kubeadm join 192.168.191.131:6443 --token sj6fff.bpak7gkd3hnyzcm5 \
</span><span class='line'>         --discovery-token-ca-cert-hash sha256:8e15649afc0771e80cce7f1dfdbb0933f4fdbd45ea1f9e03be1f3b78449a6d3c 
</span><span class='line'>[preflight] Running pre-flight checks
</span><span class='line'>        [WARNING FileExisting-tc]: tc not found in system path
</span><span class='line'>        [WARNING Hostname]: hostname "worker1" could not be reached
</span><span class='line'>        [WARNING Hostname]: hostname "worker1": lookup worker1 on 192.168.191.2:53: no such host
</span><span class='line'>        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
</span><span class='line'>[preflight] Reading configuration from the cluster...
</span><span class='line'>[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
</span><span class='line'>[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
</span><span class='line'>[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
</span><span class='line'>[kubelet-start] Starting the kubelet
</span><span class='line'>[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
</span><span class='line'>
</span><span class='line'>This node has joined the cluster:
</span><span class='line'>* Certificate signing request was sent to apiserver and a response was received.
</span><span class='line'>* The Kubelet was informed of the new secure connection details.
</span><span class='line'>
</span><span class='line'>Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
</span></code></pre></td></tr></table></div></figure>


<p>加入节点后，查看状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl get nodes 
</span><span class='line'>NAME      STATUS     ROLES                  AGE    VERSION
</span><span class='line'>k8s       Ready      control-plane,master   166m   v1.23.5
</span><span class='line'>worker1   NotReady   &lt;none&gt;                 30s    v1.23.5
</span></code></pre></td></tr></table></div></figure>


<h2>安装网络</h2>

<ul>
<li><a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model">https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model</a></li>
<li><a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/addons/">https://kubernetes.io/zh/docs/concepts/cluster-administration/addons/</a></li>
<li><a href="https://github.com/flannel-io/flannel#deploying-flannel-manually">https://github.com/flannel-io/flannel#deploying-flannel-manually</a></li>
</ul>


<p>github上的资源好像也不能下载了，打开后复制内容到新建的文件中。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># For Kubernetes v1.17+ kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
</span><span class='line'>[ec2-user@k8s ~]$ vi kube-flannel.yml 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f kube-flannel.yml
</span></code></pre></td></tr></table></div></figure>


<p>由于初始化 <code>kubeadm init</code> 时没有添加网络参数，导致这里flannel网络插件一直处于 CrashLoopBackOff 状态，查看日志提示没有分配 cidr 报错查日志</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://cloud-atlas.readthedocs.io/zh_CN/latest/kubernetes/debug/k8s_crashloopbackoff.html
</span><span class='line'># 查看日志
</span><span class='line'>[ec2-user@k8s ~]$ kubectl describe -n kube-system pod kube-flannel-ds-sbx86 
</span><span class='line'>  Warning  BackOff    2m5s (x69 over 16m)  kubelet            Back-off restarting failed container
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl logs -n kube-system kube-flannel-ds-sbx86 
</span><span class='line'>E0317 09:19:27.915383       1 main.go:317] Error registering network: failed to acquire lease: node "k8s" pod cidr not assigned
</span><span class='line'>W0317 09:19:27.915664       1 reflector.go:436] github.com/flannel-io/flannel/subnet/kube/kube.go:379: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: context canceled") has prevented the request from succeeding
</span><span class='line'>
</span><span class='line'>可以再通过docker查看flannel日志
</span><span class='line'>[root@test4 profile]# docker ps -l
</span><span class='line'>[root@test4 profile]# docker logs f7be3ebe77fd 
</span><span class='line'>
</span><span class='line'>## https://www.talkwithtrend.com/Article/251751
</span><span class='line'># kube-controller-manager 没有给新加入的节点分配 IP 段，init 的时候没有指定 IP 段
</span><span class='line'># 加最后两行，和 kube-flannel.yml 中的 net-conf.json/Network 对应：
</span><span class='line'>[ec2-user@k8s ~]$ sudo vi /etc/kubernetes/manifests/kube-controller-manager.yaml 
</span><span class='line'>  - command:
</span><span class='line'>    - kube-controller-manager
</span><span class='line'>    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
</span><span class='line'>    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
</span><span class='line'>    - --bind-address=127.0.0.1
</span><span class='line'>    - --client-ca-file=/etc/kubernetes/pki/ca.crt
</span><span class='line'>    - --cluster-name=kubernetes
</span><span class='line'>    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
</span><span class='line'>    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
</span><span class='line'>    - --controllers=*,bootstrapsigner,tokencleaner
</span><span class='line'>    - --kubeconfig=/etc/kubernetes/controller-manager.conf
</span><span class='line'>    - --leader-elect=true
</span><span class='line'>    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
</span><span class='line'>    - --root-ca-file=/etc/kubernetes/pki/ca.crt
</span><span class='line'>    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
</span><span class='line'>    - --use-service-account-credentials=true
</span><span class='line'>    - --allocate-node-cidrs=true
</span><span class='line'>    - --cluster-cidr=10.244.0.0/16
</span><span class='line'>
</span><span class='line'># 重启服务
</span><span class='line'>## https://stackoverflow.com/questions/51375940/kubernetes-master-node-is-down-after-restarting-host-machine
</span><span class='line'>[ec2-user@k8s ~]$ sudo systemctl restart kubelet  
</span><span class='line'>
</span><span class='line'># 重新部署
</span><span class='line'># 然后删除flannel容器，重新部署
</span><span class='line'>[ec2-user@k8s ~]$ kubectl delete -f kube-flannel.yml 
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f kube-flannel.yml
</span></code></pre></td></tr></table></div></figure>


<p>注：还有可以临时编辑节点的配置 手动分配podCIDR。这里不做具体描述，参考： <a href="http://www.hyhblog.cn/2021/02/21/k8s-flannel-pod-cidr-not-assigned/">http://www.hyhblog.cn/2021/02/21/k8s-flannel-pod-cidr-not-assigned/</a> 。</p>

<p>再次查看pod状态，网络组件安装好后，dns组件也跑起来了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl get pods --all-namespaces -o wide 
</span><span class='line'>NAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE     IP                NODE      NOMINATED NODE   READINESS GATES
</span><span class='line'>kube-system   coredns-64897985d-4d5rx       1/1     Running   0          2m30s   10.244.0.3        k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   coredns-64897985d-m9p9q       1/1     Running   0          2m30s   10.244.0.2        k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   etcd-k8s                      1/1     Running   0          166m    192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-apiserver-k8s            1/1     Running   0          166m    192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-controller-manager-k8s   1/1     Running   0          12m     192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-flannel-ds-q4qkt         1/1     Running   0          60s     192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-flannel-ds-ttcwt         1/1     Running   0          6m1s    192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-proxy-pd77m              1/1     Running   0          60s     192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-proxy-qj6lw              1/1     Running   0          166m    192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system   kube-scheduler-k8s            1/1     Running   0          166m    192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>安装dashboard</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://github.com/kubernetes/dashboard#kubernetes-dashboard
</span><span class='line'># kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f dashboard-v2.5.1.yml 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods -A -o wide
</span><span class='line'>NAMESPACE              NAME                                         READY   STATUS    RESTARTS   AGE     IP                NODE      NOMINATED NODE   READINESS GATES
</span><span class='line'>kube-system            coredns-64897985d-4d5rx                      1/1     Running   0          36m     10.244.0.3        k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            coredns-64897985d-m9p9q                      1/1     Running   0          36m     10.244.0.2        k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            etcd-k8s                                     1/1     Running   0          3h20m   192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-apiserver-k8s                           1/1     Running   0          3h19m   192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-controller-manager-k8s                  1/1     Running   0          46m     192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-flannel-ds-q4qkt                        1/1     Running   0          34m     192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-flannel-ds-ttcwt                        1/1     Running   0          39m     192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-proxy-pd77m                             1/1     Running   0          34m     192.168.191.132   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-proxy-qj6lw                             1/1     Running   0          3h20m   192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kube-system            kube-scheduler-k8s                           1/1     Running   0          3h20m   192.168.191.131   k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kubernetes-dashboard   dashboard-metrics-scraper-799d786dbf-q87wv   1/1     Running   0          59s     10.244.2.3        worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>kubernetes-dashboard   kubernetes-dashboard-fb8648fd9-vprpt         1/1     Running   0          59s     10.244.2.2        worker1   &lt;none&gt;           &lt;none&gt;
</span></code></pre></td></tr></table></div></figure>


<p>安装还是很便捷和容易的，访问搞起来比较麻烦，由于是在虚拟机里面部署，kubectl命令也都在虚拟机操作，用 <code>kubectl proxy</code> 访问dashboard，如果不是localhost或者https的话不给访问的。</p>

<p>尝试了绑定网卡ip，但是由于不是https，还是不能访问dashboard：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl proxy --address='0.0.0.0' --accept-hosts='.*'
</span><span class='line'>Starting to serve on [::]:8001
</span></code></pre></td></tr></table></div></figure>


<p>访问dashboard方法一：kubectl proxy 加上 ssh的locally port forward，把本地的8001的请求转发到 远程服务器的localhost:8001。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://github.com/kubernetes/dashboard#access
</span><span class='line'>[ec2-user@k8s ~]$ kubectl proxy 
</span><span class='line'>Starting to serve on 127.0.0.1:8001
</span></code></pre></td></tr></table></div></figure>


<p>在SecureCRT的ssh会话的配置 Session Options 的 Connection - Port Forwarding 增加 Local Port Forwarding 的端口转发。在Local和Remote的Port输入框中都填入8001即可。</p>

<p>重新连接，这样我们访问 <code>http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login</code> 就能访问到dashboard页面了。</p>

<p>方法二：后面直接通过查看dashboard服务的ip，通过 ssh的socks5代理 来访问 使用内部地址的dashboard。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl -n kubernetes-dashboard get service kubernetes-dashboard
</span><span class='line'>NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
</span><span class='line'>kubernetes-dashboard   ClusterIP   10.101.193.109   &lt;none&gt;        443/TCP   6h38m
</span><span class='line'>
</span><span class='line'>## 通过服务ip访问（Locally Port Forwarding - socks5方式代理）：
</span><span class='line'>https://10.101.193.109/#/login
</span><span class='line'>https://10.101.193.109/#/pod?namespace=kube-system
</span></code></pre></td></tr></table></div></figure>


<p>方法三：或者网上说的使用端口转发：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://kubernetes.io/zh/docs/tasks/access-application-cluster/port-forward-access-application-cluster/
</span><span class='line'>kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8080:443 --address='0.0.0.0'
</span></code></pre></td></tr></table></div></figure>


<p>能访问了，接下来就是获取token进行登录。同样有两种方式，第一种暴力设置跳过登录，第二种方式从系统中获取/创建一个token来登录。</p>

<p>登录方法一：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## https://www.cnblogs.com/tylerzhou/p/11117956.html
</span><span class='line'># 在1.10.1里面默认不再显然skip按钮,其实dashboard安装有很多坑,如果有读者按照以上设置仍然不能正常成功登陆,但是仍然想要体验dashboard,可以开启默认关闭的skip按钮,这样就可以进入到dashboard管理界面了.
</span><span class='line'>      containers:
</span><span class='line'>      - args:
</span><span class='line'>        - --auto-generate-certificates
</span><span class='line'>        - --enable-skip-login            # &lt;-- add this line
</span><span class='line'>        image: k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1
</span></code></pre></td></tr></table></div></figure>


<p>改了配置后记得重新加载。</p>

<p>方法二：另一种方式是从系统获取token，然后填到界面上然后登录。访问dashboard：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/46664104/how-to-sign-in-kubernetes-dashboard">https://stackoverflow.com/questions/46664104/how-to-sign-in-kubernetes-dashboard</a></li>
<li><a href="https://jimmysong.io/kubernetes-handbook/guide/auth-with-kubeconfig-or-token.html">https://jimmysong.io/kubernetes-handbook/guide/auth-with-kubeconfig-or-token.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl -n kube-system get secret
</span><span class='line'># 这些secrets中的大部分都可以用来访问dashboard的,只有不同的账户权限不同,很多账户被限制不能进行操作.
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl -n kube-system describe secret deployment-controller-token
</span><span class='line'>
</span><span class='line'># 使用一条命令来显示token
</span><span class='line'>[ec2-user@k8s ~]$ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | awk '/^deployment-controller-token-/{print $1}') | awk '$1=="token:"{print $2}'
</span><span class='line'>eyJhbGciOiJSUzI1NiIsImtpZCI6IjQzNllWOFFBYU5qaXdtUmdLelJQSDU5T2FVbGVpREJFZTlMQU12MXFhN1UifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tejVwbWQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNTcwNWJiMzYtMTMyNi00MGY5LWI3ZWUtNzE3ZTAyMTM1NzA2Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.Av-RwOQGdEyZn56xmH_siz-7yU07OrhLhfiPqfJRaNJ5DL8wEDIZkxgNMzHrrthTsOJl7Tky3ABo5z3c_4xjgADGSqKqP0rvWtaLSHZFZR16c5S2c08aHdSH7KIAdoCy0muMiKHRw67QRf7zo5bPUyqfCyPY2vcB-pxqYnrTTAw71f34rgIPA-LACc5LIQwv8DT5O-KE1TopYF7lX5hXZIHOGP3sYpmbR7yIzO3MDNRUIfiZutYiQnHwXRQGBwHu1iUVk8Lu69gnqggkjp2cXa4d2ZUpCxrpeLGGdjPv6JPZEFLDhLbiBLF04b7IOdFQO4bH6BbXBNs9e0AGPbvp4Q
</span><span class='line'>[ec2-user@k8s ~]$ 
</span></code></pre></td></tr></table></div></figure>


<p>方法三：当然，也可以创建一个dashboard的拥有完整权限的token：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ kubectl create serviceaccount cluster-admin-dashboard-sa -n kube-system
</span><span class='line'>
</span><span class='line'>$ kubectl create clusterrolebinding cluster-admin-dashboard-sa \
</span><span class='line'>  --clusterrole=cluster-admin \
</span><span class='line'>  --serviceaccount=kube-system:cluster-admin-dashboard-sa -n kube-system
</span><span class='line'>
</span><span class='line'>And then, you can use the token of just created cluster admin service account.
</span><span class='line'>$ kubectl get secret | grep cluster-admin-dashboard-sa
</span><span class='line'>cluster-admin-dashboard-sa-token-6xm8l   kubernetes.io/service-account-token   3         18m
</span><span class='line'>$ kubectl describe secret cluster-admin-dashboard-sa-token-6xm8l
</span><span class='line'>
</span><span class='line'># Parse the token
</span><span class='line'>$ TOKEN=$(kubectl describe secret -n kube-system $(kubectl get secret -n kube-system | awk '/^cluster-admin-dashboard-sa-token-/{print $1}') | awk '$1=="token:"{print $2}')
</span><span class='line'>$ echo $TOKEN
</span><span class='line'>
</span><span class='line'>## -OR-
</span><span class='line'>[ec2-user@k8s ~]$ kubectl describe secret cluster-admin-dashboard-sa
</span><span class='line'>## -OR-
</span><span class='line'>[ec2-user@k8s ~]$ kubectl describe secret -n kube-system | grep deployment -A 12
</span></code></pre></td></tr></table></div></figure>


<p>如果使用token登录，一段事件没有操作就会有超时的困扰，可以修改token-ttl配置。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>##--&gt; Unauthorized (401): You have been logged out because your token has expired.
</span><span class='line'>
</span><span class='line'>## https://blog.csdn.net/otoyix/article/details/118758736
</span><span class='line'># 增加一行参数 token-ttl=68400
</span><span class='line'>  containers:
</span><span class='line'>    - name: kubernetes-dashboard
</span><span class='line'>      image: 'kubernetesui/dashboard:v2.0.0-rc5'
</span><span class='line'>      args:
</span><span class='line'>        - '--auto-generate-certificates'
</span><span class='line'>        - '--namespace=kubernetes-dashboard'
</span><span class='line'>        - '--token-ttl=68400'    -- 增加了此行
</span></code></pre></td></tr></table></div></figure>


<h2>安装metrics-server</h2>

<p>如果没有安装metrics-server，在dashboard中不能看到cpu/内存使用情况图形，kubectl top的命令也获取不到数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl top nodes
</span><span class='line'>error: Metrics API not available
</span><span class='line'>[ec2-user@k8s ~]$ kubectl top pods -A
</span><span class='line'>error: Metrics API not available
</span></code></pre></td></tr></table></div></figure>


<p>安装metrics-server会有镜像下载和证书的问题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 每台主机都导入一下该镜像
</span><span class='line'>[ec2-user@k8s ~]$ docker load -i metrics-server-v0.6.1.tar.gz 
</span><span class='line'>3dc34f14eb83: Loading layer [==================================================&gt;]  66.43MB/66.43MB
</span><span class='line'>Loaded image: k8s.gcr.io/metrics-server/metrics-server:v0.6.1
</span><span class='line'>
</span><span class='line'># kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
</span><span class='line'>[ec2-user@k8s ~]$ vi metrics-server.yml
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f metrics-server.yml 
</span></code></pre></td></tr></table></div></figure>


<p>还是启动不起来，由于metrics-server需要连服务端，证书不对，为了先跑起来，先忽略安全证书。在containers参数最后加上 <code>--kubelet-insecure-tls</code> ，然后删除后重新创建一次。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## [k8s metrics-server 轻量化监控](https://www.jianshu.com/p/5fe108d70310)
</span><span class='line'>## https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#cannot-use-the-metrics-server-securely-in-a-kubeadm-cluster
</span><span class='line'>
</span><span class='line'>## 证书 https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/#kubelet-serving-certs
</span><span class='line'>
</span><span class='line'>## https://github.com/kubernetes-sigs/metrics-server/blob/master/FAQ.md#how-to-run-metrics-server-securely
</span><span class='line'>## https://github.com/kubernetes-sigs/metrics-server/issues/196
</span><span class='line'>## https://cloud.tencent.com/developer/article/1819955
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - args:
</span><span class='line'>        - --cert-dir=/tmp
</span><span class='line'>        - --secure-port=4443
</span><span class='line'>        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
</span><span class='line'>        - --kubelet-use-node-status-port
</span><span class='line'>        - --metric-resolution=15s
</span><span class='line'>        - --kubelet-insecure-tls
</span><span class='line'>        image: k8s.gcr.io/metrics-server/metrics-server:v0.6.1
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl delete -f metrics-server.yml 
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f metrics-server.yml 
</span></code></pre></td></tr></table></div></figure>


<p>等一小会，再次查看top命令。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl top nodes 
</span><span class='line'>NAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
</span><span class='line'>k8s       91m          4%     913Mi           23%       
</span><span class='line'>worker1   38m          1%     431Mi           11%       
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>[ec2-user@k8s ~]$ kubectl top pods -n kube-system
</span><span class='line'>NAME                              CPU(cores)   MEMORY(bytes)   
</span><span class='line'>coredns-64897985d-4d5rx           1m           12Mi            
</span><span class='line'>coredns-64897985d-m9p9q           1m           12Mi            
</span><span class='line'>etcd-k8s                          11m          60Mi            
</span><span class='line'>kube-apiserver-k8s                32m          312Mi           
</span><span class='line'>kube-controller-manager-k8s       13m          46Mi            
</span><span class='line'>kube-flannel-ds-q4qkt             2m           11Mi            
</span><span class='line'>kube-flannel-ds-ttcwt             2m           11Mi            
</span><span class='line'>kube-proxy-pd77m                  7m           16Mi            
</span><span class='line'>kube-proxy-qj6lw                  2m           16Mi            
</span><span class='line'>kube-scheduler-k8s                3m           17Mi            
</span><span class='line'>metrics-server-7cf8b65d65-trtcj   33m          11Mi            
</span><span class='line'>[ec2-user@k8s ~]$ 
</span></code></pre></td></tr></table></div></figure>


<p>同时dashboard web界面就能看到cpu/内存的性能图形了。</p>

<h2>Hello world</h2>

<p>编写一个配置，然后运行一个实例，看看两台机器上的pod网络是否互通。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## docker run -it public.ecr.aws/amazonlinux/amazonlinux /bin/bash
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ cat replicaset.yml 
</span><span class='line'>apiVersion: apps/v1
</span><span class='line'>kind: ReplicaSet
</span><span class='line'>metadata:
</span><span class='line'>  name: hello-world
</span><span class='line'>spec:
</span><span class='line'>  replicas: 2
</span><span class='line'>  selector:
</span><span class='line'>    matchLabels:
</span><span class='line'>      app: hello-world
</span><span class='line'>  template:
</span><span class='line'>    metadata:
</span><span class='line'>      labels:
</span><span class='line'>        app: hello-world
</span><span class='line'>    spec:
</span><span class='line'>      containers:
</span><span class='line'>      - name: hello-world
</span><span class='line'>        image: amazonlinux:2
</span><span class='line'>        command: ["/bin/sh"]
</span><span class='line'>        args: ["-c", "while true; do echo hello; sleep 10;done"]
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f replicaset.yml  
</span><span class='line'>replicaset.apps/hello-world created
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl get pods -o wide
</span><span class='line'>NAME                READY   STATUS    RESTARTS   AGE   IP            NODE      NOMINATED NODE   READINESS GATES
</span><span class='line'>hello-world-d2tss   1/1     Running   0          8s    10.244.0.7    k8s       &lt;none&gt;           &lt;none&gt;
</span><span class='line'>hello-world-h9jxq   1/1     Running   0          8s    10.244.2.12   worker1   &lt;none&gt;           &lt;none&gt;
</span><span class='line'>[ec2-user@k8s ~]$ 
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl exec -ti hello-world-d2tss bash 
</span><span class='line'>kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
</span><span class='line'>bash-4.2# cat /etc/hosts 
</span><span class='line'>
</span><span class='line'>bash-4.2# yum install -y iputils net-tools 
</span><span class='line'>
</span><span class='line'>bash-4.2# ping hello-world-h9jxq           
</span><span class='line'>ping: hello-world-h9jxq: Name or service not known
</span><span class='line'>服务service才有域名。后面试一下服务的，来ping域名，测试下dns。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>bash-4.2# ping 10.244.0.7 
</span><span class='line'>PING 10.244.0.7 (10.244.0.7) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.244.0.7: icmp_seq=1 ttl=255 time=0.012 ms
</span><span class='line'>64 bytes from 10.244.0.7: icmp_seq=2 ttl=255 time=0.021 ms
</span><span class='line'>^C
</span><span class='line'>--- 10.244.0.7 ping statistics ---
</span><span class='line'>2 packets transmitted, 2 received, 0% packet loss, time 1007ms
</span><span class='line'>rtt min/avg/max/mdev = 0.012/0.016/0.021/0.006 ms
</span><span class='line'>
</span><span class='line'>bash-4.2# ping 10.244.2.12
</span><span class='line'>PING 10.244.2.12 (10.244.2.12) 56(84) bytes of data.
</span><span class='line'>64 bytes from 10.244.2.12: icmp_seq=1 ttl=253 time=0.508 ms
</span><span class='line'>64 bytes from 10.244.2.12: icmp_seq=2 ttl=253 time=0.425 ms
</span><span class='line'>^C
</span><span class='line'>--- 10.244.2.12 ping statistics ---
</span><span class='line'>2 packets transmitted, 2 received, 0% packet loss, time 1027ms
</span><span class='line'>rtt min/avg/max/mdev = 0.425/0.466/0.508/0.046 ms
</span></code></pre></td></tr></table></div></figure>


<h2>Service domain</h2>

<p>配置启动容器和服务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ cat pg-db.yml 
</span><span class='line'>---
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Pod
</span><span class='line'>metadata:
</span><span class='line'>  name: db-op-1 
</span><span class='line'>  labels:
</span><span class='line'>    name: postgres
</span><span class='line'>spec:
</span><span class='line'>  hostname: db-op-1
</span><span class='line'>  containers:
</span><span class='line'>  - name: postgres
</span><span class='line'>    image: postgis/postgis:9.6-2.5
</span><span class='line'>    imagePullPolicy: IfNotPresent
</span><span class='line'>---
</span><span class='line'>apiVersion: v1
</span><span class='line'>kind: Service
</span><span class='line'>metadata:
</span><span class='line'>  name: db-op-1
</span><span class='line'>spec:
</span><span class='line'>  ports:
</span><span class='line'>  - protocol: TCP
</span><span class='line'>    port: 5432
</span><span class='line'>  selector:
</span><span class='line'>    name: postgres
</span><span class='line'>
</span><span class='line'>[ec2-user@k8s ~]$ kubectl apply -f pg-db.yml 
</span></code></pre></td></tr></table></div></figure>


<p>在默认的namespace中再启动一个postgis的容器，用来测试访问域名：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@k8s ~]$ kubectl run busybox --image=postgis/postgis:9.6-2.5 -ti --restart=Never --rm  --command -- sh                
</span><span class='line'>If you don't see a command prompt, try pressing enter.
</span><span class='line'>
</span><span class='line'># apt update ; apt-get install net-tools iproute2 iputils-ping -y
</span><span class='line'>
</span><span class='line'># cat /etc/resolv.conf
</span><span class='line'>nameserver 10.96.0.10
</span><span class='line'>search default.svc.cluster.local svc.cluster.local cluster.local localdomain
</span><span class='line'>options ndots:5
</span><span class='line'>
</span><span class='line'># ping db-op-1
</span><span class='line'>PING db-op-1.default.svc.cluster.local (10.107.190.149) 56(84) bytes of data.
</span><span class='line'>
</span><span class='line'># psql -h db-op-1 -U postgres
</span><span class='line'>Password for user postgres: 
</span><span class='line'>psql (9.6.24)
</span><span class='line'>Type "help" for help.
</span><span class='line'>
</span><span class='line'>postgres=# \q
</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2023/11/18/reinstall-redmine-on-respberry2/">Reinstall Redmine on Respberry2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2023/03/25/reinstall-raspberry2/">重新折腾raspberry2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2023/03/25/mirror-request/">请求复制/镜像</a>
			</li>
		
			<li class="post">
				<a href="/blog/2022/07/24/xinchuang-install-postgres/">信创环境迁移浅析-以Postgres为例</a>
			</li>
		
			<li class="post">
				<a href="/blog/2021/12/08/recommand-blogs/">认真的博客</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/10/30/windows-run-ubuntu/">Windows Run Ubuntu</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/09/18/redmine-deploy-and-install-plugins/">Redmine部署以及插件安装</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/09/13/review-linux-101-hacks/">【linux 101 Hacks】读后感</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2023/11/18/reinstall-redmine-on-respberry2/">Reinstall Redmine on Respberry2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/04/09/dingtalk-with-openai/">钉钉群机器人对接ChatGPT</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/26/clash-on-raspberry4/">树莓派4安装Clash</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/25/reinstall-raspberry2/">重新折腾raspberry2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/25/mirror-request/">请求复制/镜像</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/18/wechat-on-openai/">微信对接OpenAI</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/02/01/git-reset-hard/">记git Reset &#8211;hard</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/02/01/register-openai/">注册OpenAI</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/0/'>0</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/bigdata/'>bigdata</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/clash/'>clash</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/deprecated/'>deprecated</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/devops/'>devops</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (16) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/es/'>es</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/flume/'>flume</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/good-series-1/'>good-series-1</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (44) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (13) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jenkins/'>jenkins</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jeykll/'>jeykll</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k2/'>k2</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (15) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kubeadm/'>kubeadm</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/logstash/'>logstash</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/map/'>map</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nfs/'>nfs</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/openai/'>openai</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/openeuler/'>openeuler</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/openvpn/'>openvpn</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/r4a/'>r4a</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/raspberry/'>raspberry</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (18) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redmine/'>redmine</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/respberry2/'>respberry2</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (13) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/staf/'>staf</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (71) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/vagrant/'>vagrant</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/vnc/'>vnc</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/wsl/'>wsl</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/zookeeper/'>zookeeper</a> (1) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (236)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
<!--
  <h1>Softs, I&#8217;m using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
&#8211;>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2023 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">document.write(unescape("%3Cspan id='cnzz_stat_icon_1253103971'%3E%3C/span%3E%3Cscript src='https://s19.cnzz.com/z_stat.php%3Fid%3D1253103971%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>

<script>

var time=location.pathname.substring(6).substring(0,11);
var eName=location.pathname.substring(17);
var gitalk = new Gitalk({
  clientID: 'c14f68eac6330d15d984',
  clientSecret: '73b7c1fffa98e299ff0cdd332821201933858e6e',
  repo: 'winse.github.com',
  owner: 'winse',
  admin: ['winse'],
  id: eName,
  labels: ['Gitalk', time],
  body: "http://winse.github.io" + location.pathname,
  createIssueManually: true,
  
  // facebook-like distraction free mode
  distractionFreeMode: false
})

gitalk.render('gitalk-container')

</script>



<script>
/*
$.ajax({
  type: "POST",
  url: "http://log.winseliu.com:20000",
  data: JSON.stringify({
    title: document.title,
    location: JSON.stringify(location),
    referrer: document.referrer,
    userAgent: navigator.userAgent
  }),
  contentType: "application/json; charset=utf-8",
  dataType: "json"
});
*/
</script>











</body>
</html>
