
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="官网的文档[HDFSHighAvailabilityWithQJM.html]很详细，但是没有一个整体的案例。这里整理下操作记录下来。 配置 hadoop-master1和hadoop-master2之间无密钥登录（failover要用到）： 1
2
3
[hadoop@hadoop- &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winseliu.com/posts/20">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="http://cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winseliu.com" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/">Hadoop安装与升级-(3)HA配置</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-07T23:04:27+08:00" pubdate data-updated="true">Thu 2016-01-07 23:04</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>官网的文档[HDFSHighAvailabilityWithQJM.html]很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<h2>配置</h2>

<p>hadoop-master1和hadoop-master2之间无密钥登录（failover要用到）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-keygen
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master2
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master1</span></code></pre></td></tr></table></div></figure>


<p>配置文件修改：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/core-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hdfs://zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/tmp&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/hdfs-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span><span class='line'>&lt;value&gt; &lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.nameservices&lt;/name&gt;
</span><span class='line'>&lt;value&gt;zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.namenodes.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;nn1,nn2&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:8020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn1&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.http-address.zfcluster.nn2&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master2:50070&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;qjournal://hadoop-master1:8485/zfcluster&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.client.failover.proxy.provider.zfcluster&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/journal&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
</span><span class='line'>&lt;value&gt;sshfence&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
</span><span class='line'>&lt;value&gt;true&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<h2>启动</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ..
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.2.0 $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits
</span><span class='line'>
</span><span class='line'>#// 此时可以启动datanode，通过50070端口看namenode的状态
</span><span class='line'>
</span><span class='line'>#// Automatic failover，zkfc和namenode没有启动顺序的问题！
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs zkfc -formatZK
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs haadmin -failover nn1 nn2
</span><span class='line'>
</span><span class='line'>#// 测试failover，把一个active的namenode直接kill掉，看看另一个是否变成active！
</span><span class='line'>
</span><span class='line'># 重启
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>16/01/07 10:57:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master1: stopping namenode
</span><span class='line'>hadoop-master2: stopping namenode
</span><span class='line'>hadoop-slaver1: stopping datanode
</span><span class='line'>hadoop-slaver2: stopping datanode
</span><span class='line'>hadoop-slaver3: stopping datanode
</span><span class='line'>Stopping journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: stopping journalnode
</span><span class='line'>16/01/07 10:58:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: no zkfc to stop
</span><span class='line'>hadoop-master1: no zkfc to stop
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>16/01/07 10:59:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting namenodes on [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master1.out
</span><span class='line'>hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
</span><span class='line'>hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
</span><span class='line'>hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
</span><span class='line'>Starting journal nodes [hadoop-master1]
</span><span class='line'>hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-journalnode-hadoop-master1.out
</span><span class='line'>16/01/07 10:59:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
</span><span class='line'>Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
</span><span class='line'>hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master2.out
</span><span class='line'>hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master1.out
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ jps
</span><span class='line'>15241 DFSZKFailoverController
</span><span class='line'>14882 NameNode
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>18715 Jps
</span><span class='line'>15076 JournalNode</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html</a></li>
<li><a href="http://www.xlgps.com/article/40993.html">http://www.xlgps.com/article/40993.html</a></li>
<li><a href="http://hbase.apache.org/book.html#basic.prerequisites">http://hbase.apache.org/book.html#basic.prerequisites</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/">Hadoop安装与升级-(2)2.2升级到2.6</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-07T22:04:27+08:00" pubdate data-updated="true">Thu 2016-01-07 22:04</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>升级的命令很简单，但是不要瞎整！升级就一个命令就搞定了！</p>

<h2>部署2.6.3</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.6.3.tar.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.6.3/share/
</span><span class='line'>[hadoop@hadoop-master1 share]$ rm -rf doc/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ rm -rf lib/native/*
</span><span class='line'>
</span><span class='line'>#// 拷贝四个配置文件到hadoop-2.6.3
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ cd etc/hadoop/
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/*-site.xml ./
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/slaves ./
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ cd 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.6.3 $h:~/ ; done
</span></code></pre></td></tr></table></div></figure>


<h2>升级（最佳方式）</h2>

<p>直接使用upgrade选项启动dfs即可。（secondarynamenode不要单独操作来升级，反正就是执行upgrade启动dfs就好了）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade
</span><span class='line'>
</span><span class='line'>// 2.2和2.6都没有这个命令
</span><span class='line'>// hadoop dfsadmin -upgradeProgress status
</span><span class='line'>hadoop dfsadmin -finalizeUpgrade
</span></code></pre></td></tr></table></div></figure>


<p>参考[Hadoop: The Definitive Guide/Chapter 10. Administering Hadoop/Maintenance/Upgrades]</p>

<h2>瞎整1</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 先停集群
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</span></code></pre></td></tr></table></div></figure>


<p>直接在原来的2.2基础上启动，datanode启动没问题，但是namenode报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-namenode-hadoop-master1.log 
</span><span class='line'>...
</span><span class='line'>2016-01-07 08:05:23,582 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
</span><span class='line'>java.io.IOException: 
</span><span class='line'>File system image contains an old layout version -47.
</span><span class='line'>An upgrade to version -60 is required.
</span><span class='line'>Please restart NameNode with the "-rollingUpgrade started" option if a rolling upgrade is already started; or restart NameNode with the "-upgrade" option to start a new upgrade.
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:232)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:764)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:748)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
</span><span class='line'>        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
</span><span class='line'>2016-01-07 08:05:23,583 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
</span><span class='line'>2016-01-07 08:05:23,585 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
</span><span class='line'>/************************************************************
</span><span class='line'>SHUTDOWN_MSG: Shutting down NameNode at hadoop-master1/172.17.0.1
</span><span class='line'>************************************************************/</span></code></pre></td></tr></table></div></figure>


<p>重新启动，使用upgrade选项启动：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade</span></code></pre></td></tr></table></div></figure>


<p>或者还原到2.2：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># **所有**slaver节点的VERSION改回47
</span><span class='line'>[hadoop@hadoop-slaver3 ~]$ vi /data/tmp/dfs/data/current/VERSION 
</span><span class='line'>...
</span><span class='line'>layoutVersion=-47
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh -rollback
</span></code></pre></td></tr></table></div></figure>


<h2>原理</h2>

<p>升级的时刻，首先备份原来的数据到previous目录下，升级后的放置到current目录下。namenode这样没啥大问题，但是datanode也是这样结构current和previous，那相当有问题，那数据量不是翻倍了？</p>

<p>查看数据后，发现一个名字的文件current和previous里面使用的是一个inode。也就是说用的是<strong>硬链接</strong>，数据只有一份！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop fs -put *.txt /
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver3 ~]$ cd /data/tmp/dfs/data/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ test current/finalized/subdir0/subdir0/blk_1073741825 -ef previous/finalized/blk_1073741825
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ echo $?
</span><span class='line'>0
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i current/finalized/subdir0/subdir0/blk_1073741825 
</span><span class='line'>142510 current/finalized/subdir0/subdir0/blk_1073741825
</span><span class='line'>[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i previous/finalized/blk_1073741825
</span><span class='line'>142510 previous/finalized/blk_1073741825
</span></code></pre></td></tr></table></div></figure>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/">Hadoop安装与升级-Docker中安装(1)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-01-07T21:04:27+08:00" pubdate data-updated="true">Thu 2016-01-07 21:04</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>其实部署一个hadoop集群不难，按照步骤一步步的操作： 无密钥登录，防火墙(以及selinux)，JDK，配置，启动(包括format)。</p>

<h2>集群机器准备</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# docker -v
</span><span class='line'>Docker version 1.6.2, build 7c8fca2/1.6.2
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker images
</span><span class='line'>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
</span><span class='line'>centos              centos6             62068de82c82        4 months ago        250.7 MB
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-master1 -h hadoop-master1 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>c975b0e41429a3c214e86552f2a9f599ba8ee7487e8fbdc25fd59d29adacca4f
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-master2 -h hadoop-master2 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>fac1d2ee4a05ab8457f4bd6756622ac8236f64423544150d355f9e3091764d8f
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-slaver1 -h hadoop-slaver1 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>cc8734f2a0963a030b994f69be697308a13e511557eaefc7d4aca7e300950ded
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-slaver2 -h hadoop-slaver2 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>7e4b5410a7cb8585436775f15609708b309a5b83930da74d6571533251c26355
</span><span class='line'>[root@cu2 ~]# docker run -d --name hadoop-slaver3 -h hadoop-slaver3 centos:centos6 /usr/sbin/sshd -D
</span><span class='line'>26018b256403d956b4272b6bda09a58d1fc6938591d18f9892ba72782c41880b
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker ps -a
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND               CREATED              STATUS              PORTS               NAMES
</span><span class='line'>26018b256403        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver3      
</span><span class='line'>7e4b5410a7cb        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver2      
</span><span class='line'>cc8734f2a096        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver1      
</span><span class='line'>fac1d2ee4a05        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-master2      
</span><span class='line'>c975b0e41429        centos:centos6      "/usr/sbin/sshd -D"   8 minutes ago        Up 8 minutes                            hadoop-master1      
</span><span class='line'>
</span><span class='line'>[root@cu2 ~]# docker ps | grep hadoop | awk '{print $1}' | xargs -I{} docker inspect -f ' ' {}
</span><span class='line'>172.17.0.6 hadoop-slaver3
</span><span class='line'>172.17.0.5 hadoop-slaver2
</span><span class='line'>172.17.0.4 hadoop-slaver1
</span><span class='line'>172.17.0.3 hadoop-master2
</span><span class='line'>172.17.0.2 hadoop-master1</span></code></pre></td></tr></table></div></figure>


<p>重启docker后，可以直接通过名称启动即可：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# service docker start
</span><span class='line'>Starting docker:                                           [  OK  ]
</span><span class='line'>[root@cu2 ~]# docker start hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3
</span><span class='line'>hadoop-master1
</span><span class='line'>hadoop-master2
</span><span class='line'>hadoop-slaver1
</span><span class='line'>hadoop-slaver2
</span><span class='line'>hadoop-slaver3</span></code></pre></td></tr></table></div></figure>


<p>重启后，hosts文件会被重置！最好就是测试好之前不要重启docker！（长期用docker集群实例，还是指定DNS!!）</p>

<h2>机器配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@cu2 ~]# ssh root@172.17.0.2
</span><span class='line'>root@172.17.0.2's password: 
</span><span class='line'>Last login: Thu Jan  7 06:17:11 2016 from 172.17.42.1
</span><span class='line'>[root@hadoop-master1 ~]# 
</span><span class='line'>[root@hadoop-master1 ~]# vi /etc/hosts
</span><span class='line'>127.0.0.1       localhost
</span><span class='line'>::1     localhost ip6-localhost ip6-loopback
</span><span class='line'>fe00::0 ip6-localnet
</span><span class='line'>ff00::0 ip6-mcastprefix
</span><span class='line'>ff02::1 ip6-allnodes
</span><span class='line'>ff02::2 ip6-allrouters
</span><span class='line'>
</span><span class='line'>172.17.0.6 hadoop-slaver3
</span><span class='line'>172.17.0.5 hadoop-slaver2
</span><span class='line'>172.17.0.4 hadoop-slaver1
</span><span class='line'>172.17.0.3 hadoop-master2
</span><span class='line'>172.17.0.2 hadoop-master1
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 ~]# ssh-keygen
</span><span class='line'>[root@hadoop-master1 ~]# 
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-master1
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-master2
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver1
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver2
</span><span class='line'>[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver3
</span><span class='line'>
</span><span class='line'># 拷贝hosts
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp /etc/hosts $h:/etc/ ; done
</span><span class='line'>
</span><span class='line'># 安装需要的软件
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h "yum install man rsync curl wget tar" ; done
</span><span class='line'>
</span><span class='line'># 创建用户
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h useradd hadoop ; done
</span><span class='line'>
</span><span class='line'>#// 把要设置的密码拷贝一下，接下来直接右键（CRT）粘贴弄5次就可以了。如果是几十几百台机器可以使用expect来实现
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h passwd hadoop ; done
</span><span class='line'>New password: hadoop
</span><span class='line'>BAD PASSWORD: it is based on a dictionary word
</span><span class='line'>BAD PASSWORD: is too simple
</span><span class='line'>Retype new password: hadoop
</span><span class='line'>Changing password for user hadoop.
</span><span class='line'>passwd: all authentication tokens updated successfully.
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'># 建立数据目录，赋权给hadoop用户
</span><span class='line'>[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h "mkdir /data; chown hadoop:hadoop /data" ; done
</span><span class='line'>
</span><span class='line'>[root@hadoop-master1 ~]# su - hadoop
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-keygen 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-master1
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-master2
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver1
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver2
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver3
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ ll
</span><span class='line'>total 139036
</span><span class='line'>drwxr-xr-x 9 hadoop hadoop      4096 Oct  7  2013 hadoop-2.2.0
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 142362384 Jan  7 07:14 jdk-7u60-linux-x64.gz
</span><span class='line'>drwxr-xr-x 8 hadoop hadoop      4096 Jan  7 07:11 zookeeper-3.4.6
</span><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf jdk-7u60-linux-x64.gz 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.2.0.tar.gz 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ tar zxvf zookeeper-3.4.6.tar.gz 
</span><span class='line'>
</span><span class='line'># 清理生产上无用的数据
</span><span class='line'>[hadoop@hadoop-master1 ~]$ rm hadoop-2.2.0.tar.gz zookeeper-3.4.6.tar.gz jdk-7u60-linux-x64.gz 
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd zookeeper-3.4.6/
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ rm -rf docs/ src/
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ cd ../hadoop-2.2.0/
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd share/
</span><span class='line'>[hadoop@hadoop-master1 share]$ rm -rf doc/</span></code></pre></td></tr></table></div></figure>


<h2>程序配置与启动</h2>

<ul>
<li>java</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ cd
</span><span class='line'>[hadoop@hadoop-master1 ~]$ vi .bashrc 
</span><span class='line'>...
</span><span class='line'>JAVA_HOME=~/jdk1.7.0_60
</span><span class='line'>PATH=$JAVA_HOME/bin:$PATH
</span><span class='line'>
</span><span class='line'>export JAVA_HOME PATH</span></code></pre></td></tr></table></div></figure>


<p>退出shell再登录，或者source .bashrc！</p>

<ul>
<li>zookeeper</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ cd zookeeper-3.4.6/conf
</span><span class='line'>[hadoop@hadoop-master1 conf]$ cp zoo_sample.cfg zoo.cfg
</span><span class='line'>[hadoop@hadoop-master1 conf]$ vi zoo.cfg 
</span><span class='line'>...
</span><span class='line'>dataDir=/data/zookeeper
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ mkdir /data/zookeeper
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd ~/zookeeper-3.4.6/
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ bin/zkServer.sh start
</span><span class='line'>JMX enabled by default
</span><span class='line'>Using config: /home/hadoop/zookeeper-3.4.6/bin/../conf/zoo.cfg
</span><span class='line'>Starting zookeeper ... STARTED
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ 
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ jps
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>265 Jps
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 zookeeper-3.4.6]$ less zookeeper.out </span></code></pre></td></tr></table></div></figure>


<ul>
<li>hadoop</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 ~]$ cd ~/hadoop-2.2.0/etc/hadoop/
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ rm *.cmd
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi hadoop-env.sh 
</span><span class='line'># 修改java_home和hadoop_pid，以及yarn_pid
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi core-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;fs.defaultFS&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hdfs://hadoop-master1:9000&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span><span class='line'>&lt;value&gt;/data/tmp&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi hdfs-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.replication&lt;/name&gt;
</span><span class='line'>&lt;value&gt;1&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span><span class='line'>&lt;value&gt; &lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi mapred-site.xml
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
</span><span class='line'>&lt;value&gt;yarn&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:10020&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:19888&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop]$ vi yarn-site.xml 
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
</span><span class='line'>&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8032&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8030&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8031&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8033&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>
</span><span class='line'>&lt;property&gt;
</span><span class='line'>&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
</span><span class='line'>&lt;value&gt;hadoop-master1:8080&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<p>启动Hadoop</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop version
</span><span class='line'>Hadoop 2.2.0
</span><span class='line'>Subversion https://svn.apache.org/repos/asf/hadoop/common -r 1529768
</span><span class='line'>Compiled by hortonmu on 2013-10-07T06:28Z
</span><span class='line'>Compiled with protoc 2.5.0
</span><span class='line'>From source with checksum 79e53ce7994d1628b240f09af91e1af4
</span><span class='line'>This command was run using /home/hadoop/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop namenode -format
</span><span class='line'>
</span><span class='line'># 默认自带的libhadoop有点问题，start-dfs.sh通过hdfs getconf -namenodes输出信息导致执行错误
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ rm lib/native/libh*
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd 
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r jdk1.7.0_60 $h:~/ ; done
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r hadoop-2.2.0 $h:~/ ; done
</span><span class='line'>[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r .bashrc $h:~/ ; done
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</span><span class='line'>[hadoop@hadoop-master1 hadoop-2.2.0]$ jps
</span><span class='line'>244 QuorumPeerMain
</span><span class='line'>3995 NameNode
</span><span class='line'>4187 Jps</span></code></pre></td></tr></table></div></figure>


<p>通过CRT的Port Forwarding的dynamic socket5，浏览器配置socket5代理就可以通过50070端口查看hadoop hdfs集群的状态了。</p>

<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/12/13/postgresql-start-guide/">Postgresql入门</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-12-13T23:19:55+08:00" pubdate data-updated="true">Sun 2015-12-13 23:19</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>简单介绍下软件的安装，配置。同时实践下从mysql迁移到postgres。</p>

<h2>安装配置</h2>

<p>这里直接使用rpm包来安装。如果是centos6.6以下版本的系统需要更新openssl。</p>

<p>使用YUM安装看<a href="https://wiki.postgresql.org/wiki/YUM_Installation">https://wiki.postgresql.org/wiki/YUM_Installation</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@hadoop-master1 postgres]# ll
</span><span class='line'>total 20708
</span><span class='line'>-rw-r--r-- 1 root root  1593932 Dec 11 10:02 openssl-1.0.1e-42.el6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  1085208 Dec 11 09:12 postgresql94-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root   541376 Dec 11 09:12 postgresql94-contrib-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  1600736 Dec 11 09:12 postgresql94-devel-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root 11485008 Dec 11 09:13 postgresql94-docs-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root   198968 Dec 11 09:12 postgresql94-libs-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root    60688 Dec 11 09:12 postgresql94-plperl-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root    68884 Dec 11 09:12 postgresql94-plpython-9.4.5-1PGDG.rhel6.x86_64.rpm
</span><span class='line'>-rw-r--r-- 1 root root  4556880 Dec 11 09:11 postgresql94-server-9.4.5-1PGDG.rhel6.x86_64.rpm</span></code></pre></td></tr></table></div></figure>


<ul>
<li>安装命令：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># yum install -y openssl-1.0.1e-42.el6.x86_64.rpm 
</span><span class='line'>
</span><span class='line'># useradd postgres
</span><span class='line'># rpm -i postgresql94-*</span></code></pre></td></tr></table></div></figure>


<ul>
<li>配置环境变量、初始化数据库、启动数据库：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># su - postgres
</span><span class='line'>$ vi .bash_profile
</span><span class='line'>
</span><span class='line'>export PGDATA=/var/lib/pgsql/9.4/data
</span><span class='line'>PG_HOME=/usr/pgsql-9.4
</span><span class='line'>PATH=$PG_HOME/bin:$PATH
</span><span class='line'>export PATH
</span><span class='line'>
</span><span class='line'>$ initdb
</span><span class='line'>
</span><span class='line'>$ vi $PGDATA/pg_hba.conf
</span><span class='line'>  host    all             all              192.168.0.0/16          md5
</span><span class='line'>
</span><span class='line'>$ vi /var/lib/pgsql/9.4/data/postgresql.conf
</span><span class='line'>  listen_addresses = '*'
</span><span class='line'>
</span><span class='line'># 切回root
</span><span class='line'>
</span><span class='line'># service postgresql-9.4 start
</span><span class='line'># chkconfig postgresql-9.4 on --level 2345</span></code></pre></td></tr></table></div></figure>


<p>pg_hba.conf用来控制什么用于可以被远程访问。而postgresql.conf修改的监听的地址，默认是localhost改成*后就可以所有地址都可以访问了。</p>

<ul>
<li>建立库，创建数据库用户</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-bash-4.1$ psql 
</span><span class='line'>
</span><span class='line'> create user dpi;
</span><span class='line'> create database dpi owner dpi;
</span><span class='line'> alter user dpi with password 'XXXX';</span></code></pre></td></tr></table></div></figure>


<p>建表：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE TABLE t_dta_illegalweb (
</span><span class='line'>...
</span><span class='line'>  day varchar(10) DEFAULT NULL,
</span><span class='line'>...
</span><span class='line'>);
</span><span class='line'>
</span><span class='line'>create or replace function t_dta_illegalweb_insert_trigger()
</span><span class='line'>returns trigger as $$
</span><span class='line'>begin
</span><span class='line'>  return null;
</span><span class='line'>end; 
</span><span class='line'>$$ language plpgsql;
</span><span class='line'>
</span><span class='line'>CREATE TRIGGER trigger_t_dta_illegalweb_insert
</span><span class='line'>    BEFORE INSERT ON t_dta_illegalweb
</span><span class='line'>    FOR EACH ROW EXECUTE PROCEDURE t_dta_illegalweb_insert_trigger();
</span></code></pre></td></tr></table></div></figure>


<p>后面会使用分区表，先把触发器都建好。把框框搭好，后面修改就行了。</p>

<h2>数据迁移</h2>

<ol>
<li>postgres创建表：</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151211 (check(day = '2015-12-11')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151210 (check(day = '2015-12-10')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151209 (check(day = '2015-12-09')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151208 (check(day = '2015-12-08')) INHERITS (t_dta_illegalweb);
</span><span class='line'>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151207 (check(day = '2015-12-07')) INHERITS (t_dta_illegalweb);</span></code></pre></td></tr></table></div></figure>


<ol>
<li>mysql导出数据：</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>select * from t_dta_illegalweb where day='2015-12-09' into outfile '/tmp/etl/t_dta_illegalweb20151209.sql'  fields terminated by '|';
</span><span class='line'>select * from t_dta_illegalweb where day='2015-12-08' into outfile '/tmp/etl/t_dta_illegalweb20151208.sql'  fields terminated by '|';
</span><span class='line'>select * from t_dta_illegalweb where day='2015-12-07' into outfile '/tmp/etl/t_dta_illegalweb20151207.sql'  fields terminated by '|';</span></code></pre></td></tr></table></div></figure>


<p>数据在mysql服务器的/tmp/etl目录下面。如果mysql和postgres不在同一台机，需要把这些文件拷贝到postgres的服务器。</p>

<ol>
<li>导入数据到postgres:</li>
</ol>


<p>用psql登录dpi，然后执行copy命令把数据导入到对应的表。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>\copy  t_dta_illegalweb20151209 from  '/tmp/etl/t_dta_illegalweb20151209.sql' using delimiters '|' ;
</span><span class='line'>\copy  t_dta_illegalweb20151208 from  '/tmp/etl/t_dta_illegalweb20151208.sql' using delimiters '|' ;
</span><span class='line'>\copy  t_dta_illegalweb20151207 from  '/tmp/etl/t_dta_illegalweb20151207.sql' using delimiters '|' ;</span></code></pre></td></tr></table></div></figure>


<h2>程序修改</h2>

<p>程序修改是一件头痛的事情，虽然大部分都是SQL，但是MYSQL的比较宽泛，很多语句都兼容不报错也能出来想要的结果。但是这些语句在postgres下面执行是会报错的。比如说，select count(*)对所有数据count的时刻不能加order by（提示要groupby）；再比如，mysql遇到字符串字段和数字比较会统一转换成数字比较，等等这些在postgres中都需要在SQL中显示的转换的。</p>

<p>那么postgres的类型转换怎么实现呢？两种形式cast(X as TYPE) 或者 X::TYPE。</p>

<p>由于程序是用hibernate来做数据库访问的，会遇到如下的问题</p>

<ul>
<li>如果用hql的话CAST函数hibernate首先会进行转换。（转换类型与hibernate对象的类型不匹配）</li>
<li>而用X::TYPE会把:TYPE作为一个name parameter。</li>
<li>不用hql用sql的话，要自己做对象转换，这是我们不愿意去做的事情（不然用hibernate干嘛）</li>
</ul>


<p>各种尝试过后，修改PostgreSQLDialect来实现，添加一个自定义的hibernate函数，把字符串转成bigint即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import java.sql.Types;
</span><span class='line'>
</span><span class='line'>import org.hibernate.Hibernate;
</span><span class='line'>import org.hibernate.dialect.function.SQLFunctionTemplate;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>public class PostgreSQLDialect extends org.hibernate.dialect.PostgreSQLDialect {
</span><span class='line'>  
</span><span class='line'>  public PostgreSQLDialect() {
</span><span class='line'>      super();
</span><span class='line'>      registerFunction( "bigint", new SQLFunctionTemplate(Hibernate.BIG_INTEGER, "cast(?1 as bigint)") );
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>使用如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>StringBuilder hql = new StringBuilder("from IllegalWebInfo where 1=1 ");
</span><span class='line'>List&lt;Object&gt; params = new ArrayList&lt;&gt;();
</span><span class='line'>
</span><span class='line'>String domain = queryBean.getDomain();
</span><span class='line'>if (StringUtils.isNotBlank(domain)) {
</span><span class='line'>  hql.append(" and ").append("domain=?");
</span><span class='line'>  params.add(domain.toLowerCase());
</span><span class='line'>}
</span><span class='line'>String houseId = queryBean.getHouseId();
</span><span class='line'>if (StringUtils.isNotBlank(houseId)) {
</span><span class='line'>  hql.append(" and ").append("houseId=?");
</span><span class='line'>  params.add(houseId);
</span><span class='line'>}
</span><span class='line'>String day = queryBean.getDay();
</span><span class='line'>if (StringUtils.isNotBlank(day)) {
</span><span class='line'>  hql.append(" and ").append("day=?");
</span><span class='line'>  params.add(day);
</span><span class='line'>}
</span><span class='line'>int threshold = queryBean.getThreshold();
</span><span class='line'>if(threshold &gt; 0){
</span><span class='line'>  hql.append(" and ").append("bigint(visitsCount) &gt;= ?");
</span><span class='line'>  params.add(BigInteger.valueOf(threshold)); // 注意这里的类型转换，把int装成bigint
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>Object[] paramArray = params.toArray();
</span><span class='line'>String detailHQL = hql.toString(); // + " order by bigint(visitsCount) desc ";
</span><span class='line'>List&lt;ActiveResourcesDomainInfo&gt; hist = activeResourcesDomainDao.findPageable(detailHQL, currentPage, pageSize, paramArray);
</span><span class='line'>
</span><span class='line'>String countHQL = "select count(*) " + hql;
</span><span class='line'>long count = (long) illegalWebDao.findByHql(countHQL, paramArray).iterator().next();</span></code></pre></td></tr></table></div></figure>


<h2>定时任务，创建和更新触发器函数</h2>

<p>函数：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>create or replace function create_partition_table_everyday (t TEXT) returns timestamp as $$
</span><span class='line'>declare 
</span><span class='line'>  i int;
</span><span class='line'>  cnt int;
</span><span class='line'>  stmt text;
</span><span class='line'>  select_stmt text;
</span><span class='line'>  day date;
</span><span class='line'>  isInherit BOOLEAN;
</span><span class='line'>begin
</span><span class='line'>
</span><span class='line'>  day := now() + interval '-1 day';
</span><span class='line'>  stmt := 'CREATE TABLE IF NOT EXISTS ' || t || to_char(day, 'YYYYMMDD') || '(check(day = ''' || to_char(day, 'YYYY-MM-DD') || ''')) INHERITS (' || t || ')';
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>
</span><span class='line'>  day := now() + interval '-183 day';
</span><span class='line'>  stmt := 'DROP TABLE IF EXISTS ' || t || to_char(day, 'YYYYMMDD');
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>
</span><span class='line'>    -- try-catch
</span><span class='line'>BEGIN
</span><span class='line'>  day := now() + interval '-32 day';
</span><span class='line'>  stmt := 'ALTER TABLE IF EXISTS ' || t || to_char(day, 'YYYYMMDD') || ' NO INHERIT ' || t;
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>EXCEPTION WHEN OTHERS THEN
</span><span class='line'>  RAISE INFO '[WARN] % %', SQLERRM, SQLSTATE;
</span><span class='line'>END;
</span><span class='line'>
</span><span class='line'>  i := 0;
</span><span class='line'>  cnt := 6; -- 用于生成触发器分发最近几天的insert功能
</span><span class='line'>
</span><span class='line'>  day := now() + interval '-1 day';
</span><span class='line'>  stmt :=         ' create or replace function ' || t || '_insert_trigger() returns trigger as $' || '$ ';
</span><span class='line'>  stmt := stmt || ' begin ';
</span><span class='line'>  stmt := stmt || ' if (new.day = ''' || to_char(day, 'YYYY-MM-DD') || ''') then INSERT INTO ' || t || to_char(day, 'YYYYMMDD') || ' VALUES (new.*); ';
</span><span class='line'>  while i &lt; cnt 
</span><span class='line'>  loop
</span><span class='line'>      day := day + interval '-1 day';
</span><span class='line'>      stmt := stmt || ' elsif (new.day = ''' || to_char(day, 'YYYY-MM-DD') || ''') then INSERT INTO ' || t || to_char(day, 'YYYYMMDD') || ' VALUES (new.*); ';
</span><span class='line'>
</span><span class='line'>      i := i + 1;
</span><span class='line'>  end loop;
</span><span class='line'>  stmt := stmt || ' else raise exception ''DATE out of range. Fix the ' || t || '_insert_trigger() func!!''; ';
</span><span class='line'>  stmt := stmt || ' end if; ';
</span><span class='line'>  stmt := stmt || ' return null; ';
</span><span class='line'>  stmt := stmt || ' end;  ';
</span><span class='line'>  stmt := stmt || ' $' || '$ language plpgsql; ';
</span><span class='line'>  RAISE INFO '[DEBUG] %', stmt;
</span><span class='line'>  EXECUTE stmt;
</span><span class='line'>
</span><span class='line'>  return now();
</span><span class='line'>end;
</span><span class='line'>$$ language plpgsql;
</span></code></pre></td></tr></table></div></figure>


<p>脚本：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>vi update_dta_postgres.sh
</span><span class='line'>
</span><span class='line'>#!/bin/sh
</span><span class='line'>
</span><span class='line'>source ~/.bash_profile
</span><span class='line'>
</span><span class='line'>psql -d dpi -c "select create_partition_table_everyday('t_dta_illegalweb')"
</span><span class='line'>psql -d dpi -c "select create_partition_table_everyday('t_dta_activeresources_domain')"
</span><span class='line'>psql -d dpi -c "select create_partition_table_everyday('t_dta_activeresources_ip')"
</span><span class='line'>
</span><span class='line'>$ 
</span><span class='line'>chmod +x update_dta_postgres.sh 
</span><span class='line'>crontab -e
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>10 0 * * * sh ~/scripts/update_dta_postgres.sh &gt;~/scripts/update_dta_postgres.log 2&gt;&1</span></code></pre></td></tr></table></div></figure>


<h2>参考</h2>

<ul>
<li><a href="http://stackoverflow.com/questions/22648597/linux-centos-yum-error-package-requires-libcrypto-so-10openssl-1-0-1-ec64bi">http://stackoverflow.com/questions/22648597/linux-centos-yum-error-package-requires-libcrypto-so-10openssl-1-0-1-ec64bi</a></li>
<li><a href="http://twpug.net/docs/postgresql-doc-8.0-zh_TW/functions-comparison.html">http://twpug.net/docs/postgresql-doc-8.0-zh_TW/functions-comparison.html</a></li>
<li><a href="http://stackoverflow.com/questions/7690329/check-if-table-inherits-from-other-table-in-postgresql">http://stackoverflow.com/questions/7690329/check-if-table-inherits-from-other-table-in-postgresql</a></li>
<li><a href="http://www.jaredlog.com/?p=137">http://www.jaredlog.com/?p=137</a></li>
<li><a href="http://www.anicehumble.com/2011/08/postgresql-catch-exception-rocks.html">http://www.anicehumble.com/2011/08/postgresql-catch-exception-rocks.html</a></li>
<li><a href="http://stackoverflow.com/questions/4877637/postgresql-exception-handling">http://stackoverflow.com/questions/4877637/postgresql-exception-handling</a></li>
</ul>


<p>&ndash;END</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/11/22/gfw-ladder/">搭梯笔记</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2015-11-22T20:51:35+08:00" pubdate data-updated="true">Sun 2015-11-22 20:51</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>准备一个SSH账号</h2>

<ul>
<li><a href="http://www.99ssh.net/">http://www.99ssh.net/</a> 更改为 <a href="http://99ss.in/">http://99ss.in/</a></li>
</ul>


<p>2017年1月25日11:20:55 -
现在都换成Shadowsocks了，下载 <a href="http://www.tomato8.net/help/newsshow.php?cid=17&amp;id=22">Shadowsocks使用教程合集及相关客户端下载</a> 然后配置地址就行了。多配几个地址开启 <strong>高可用</strong> 完美。</p>

<p>2017年6月19日09:50:22 - 域名经常改啊，也苦了人家了，搭梯人不易。<a href="http://www.moonss.club">http://www.moonss.club</a> 咨询QQ：58277266</p>

<h2>SSH -N -D 或者MyEnTunnel</h2>

<ul>
<li><code>ssh -N -D [PORT] [USER@IP]</code></li>
<li><a href="http://www.99ssh.net/help/newsshow.php?cid=19&amp;id=21">http://www.99ssh.net/help/newsshow.php?cid=19&amp;id=21</a></li>
</ul>


<p>使用MyEnTunel的话，设置程序为【启动软件时自动连接】，同时把程序的快捷方式加到【C:\Users\winse\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup\】目录下。</p>

<h2>Chrome + SwitchyOmega + gfwlist</h2>

<ul>
<li><a href="https://github.com/FelisCatus/SwitchyOmega/releases">https://github.com/FelisCatus/SwitchyOmega/releases</a> SwitchySharp升级版本</li>
<li><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a></li>
</ul>


<p>可以做到智能代理功能，gfwlist的才会走代理。加速访问国内网站，同时减少不必要的流量。</p>

<h2>Firefox + FoxyProxy + gfwlist</h2>

<ul>
<li><a href="http://mozilla.com.cn/thread-230260-1-1.html">http://mozilla.com.cn/thread-230260-1-1.html</a></li>
<li><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a></li>
</ul>


<p>Chrome的版本速度快一点。配置好后，等待一段时间就智能的适配了，firefox的等的时间略长。</p>

<p>&ndash;END</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/21">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/19">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2016/04/23/hadoop-guide-catalog/">[整理] Hadoop入门</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/03/28/hive-on-spark/">Hive on Spark</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/08/24/manual-install-supervisor/">Supervisor安装配置</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/10/16/spark-build-and-configuration/">编译/搭建Spark环境</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/08/25/step-by-step-found-java-oom-error/">查找逐步定位Java程序OOM的异常实践</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/27/start-redis/">[读读书]Redis入门指南</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/18/jekyll-edit-link-in-web-page/">Jekyll页面添加编辑按钮</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/11/16/sphinx-generate-docs/">使用Sphinx生成/管理文档</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/11/04/teamviewer-vpn-on-windows/">使用TeamviewerVPN访问公司内网</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/10/30/windows-run-ubuntu/">Windows Run Ubuntu</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/10/28/application-run-do-double-click-on-centos7/">在Cenots7双击运行程序</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/10/28/flamegraph-display-how-disk-be-used/">使用Flamegraph查看磁盘使用情况</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/10/08/docker-network-via-macvlan/">Docker多主机网络配置 - Macvlan</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/10/07/docker-network-via-pipework/">Docker多主机网络配置 - Pipework</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/10/06/staf-start-guide/">STAF Start Guide</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/bigdata/'>bigdata</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (15) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/flume/'>flume</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (44) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jenkins/'>jenkins</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kubeadm/'>kubeadm</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/staf/'>staf</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (59) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/vagrant/'>vagrant</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/zookeeper/'>zookeeper</a> (1) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (197)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Softs, I&#8217;m using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253461959'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1253461959%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  









</body>
</html>
