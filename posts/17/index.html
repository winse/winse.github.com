
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="win编译32位openjdk7u60: ## 编译jdk7u60过程中的注意点: 0. 先看目录下的README-builds.html，不要太认真看个大概就行
1. 下载最新的Microsoft DirectX SDK，安装时路径不要带括号
2. 安装procps代替free.exe( &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winseliu.com/posts/17">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="http://cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winseliu.com" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
  <li><a href="https://yunpan.cn/cuYhpFBPgQYgT" >Books[5aee]</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/21/build-openjdk/">Win编译32位openjdk</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-21T14:23:57+08:00" pubdate data-updated="true">Mon 2014-07-21 14:23</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>win编译32位openjdk7u60:</p>

<div><script src='https://gist.github.com/3e6b42012dfb228a5b02.js?file=OpenJDK-Build-README.md'></script>
<noscript><pre><code>## 编译jdk7u60过程中的注意点: 

0. 先看目录下的README-builds.html，不要太认真看个大概就行
1. 下载最新的Microsoft DirectX SDK，安装时路径不要带括号
2. 安装procps代替free.exe(检查可用内存是会用到，没有应该也可以就是多个警告而已)
3. cygwin-make的版本问题，使用3.81 [snapshot](http://farm6.staticflickr.com/5486/14325549816_da7343282b_o.png)
4. VS2010的cl命令显示的信息一直是中文的话，需要修改源码跳过版本号的检查 [snapshot](http://farm3.staticflickr.com/2928/14162188587_7874083086_o.png)
5. 语言问题，导致编译corba失败！而后面有需要用到这个工程！ [snapshot](http://farm3.staticflickr.com/2936/14347140552_0f29391905_o.png)
6. PATH顺序问题，link.exe和find.exe [snapshot](http://farm6.staticflickr.com/5483/14347108132_9abdac5ae8_o.png)
7. 编译时间有点长！ [snapshot](http://farm4.staticflickr.com/3867/14162097680_40d5f69561_o.png) [java-version](http://farm4.staticflickr.com/3881/14162098450_7e86bd5b0b_o.png)
8. 默认的make不带调试信息的，需要用`make fastdebug_build`。

## 步骤：

1、 下载

可以的话，通过cygwin的setup.exe安装mercurial也行。

* hg: &lt;http://tortoisehg.bitbucket.org/download/index.html&gt;
* source: http://hg.openjdk.java.net/jdk7u/jdk7u60/

```
cd E:
cd git/
mkdir openjdk
cd openjdk/

HG_HOME=/cygdrive/c/Program\ Files/TortoiseHg/
PATH=$PATH:$HG_HOME

hg clone http://hg.openjdk.java.net/jdk7u/jdk7u60/
cd jdk7u60/
ls
./get_source.sh
```

2、 安装依赖软件

* jdk1.7.0_02/apache-ant-1.9.0
* Visual Studio2010
* Cygwin
  * 按照README-builds.html#cygwin，能找的必须安装，找不到的随意。
  * 安装procps，包括了free.exe。
  * 安装binutils，包括了ar.exe。
  * 替换[make.exe](http://www.cmake.org/files/cygwin/make.exe), 添加[cygintl-3.dll](http://www.opendll.com/dll/c/__32-cygintl-3.dll.zip)。
* 下载解压[freetype](http://jaist.dl.sourceforge.net/project/gnuwin32/freetype/2.3.5-1/freetype-2.3.5-1-bin.zip) 
  * 把bin目录下的freetype6.dll文件拷贝到../lib/freetype.dll
  * 添加[zlib1.dll](http://75.duote.org/win_dll/zlib1.zip) 也可以下载[安装版本](http://jaist.dl.sourceforge.net/project/gnuwin32/freetype/2.3.5-1/)包括了zlib1.dll
  * [snapshot](http://farm4.staticflickr.com/3922/14162193337_65d281fc73_o.png)
* 下载安装[Microsoft DirectX](http://download.microsoft.com/download/F/1/7/F178BCE4-FA19-428F-BB60-F3DEE1130BFA/DXSDK_Feb10.exe)
  * 安装路径不要带括号 

3、 配置环境

* 切换为英文语言环境，当你重新启动看到的是【Welcome】的时刻说明你修改成功了！重启后记得make clean再进行后面的操作！
 * Windows7安装更新，添加英文语言包
* 环境变量的所有路径最好是/ 而不是\，不能带双引号（否则中间编译的时刻会遇到问题）[snapshot](http://farm4.staticflickr.com/3862/14162030769_8766efa9a5_o.png)
* PATH路径顺序的问题，cygwin/bin放在vs的后面，但需要放在windows的前面。link.exe和find.exe的问题

如果是在X64机器上编译，需要加ARCH_DATA_MODEL的参数。参见【README-builds.html#creating】

## 参考：

* 【膜拜】[openjdk windows 编译](http://blog.csdn.net/instruder/article/details/8834117)
* 【有点老，不过注意事项还是相同的】 [自己动手编译Windows版的OpenJDK 7](http://icyfenix.iteye.com/blog/1097344) 
* 【linux下安装】&lt;http://khotyn.iteye.com/blog/1225348&gt;
* 【cl版本问题，以及make程序问题】&lt;http://www.myexception.cn/program/779678.html&gt;
* 【emitPermissionCheck问题】&lt;http://mail.openjdk.java.net/pipermail/jdk6-dev/2013-November/003104.html&gt; &lt;http://comments.gmane.org/gmane.comp.java.openjdk.jdk6.devel/976&gt;</code></pre></noscript></div>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/07/18/install-ganglia-on-redhat/">Install Ganglia on Redhat5+</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2014-07-18T14:53:44+08:00" pubdate data-updated="true">Fri 2014-07-18 14:53</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>对使用C写的复杂的程序安装心里有阴影，还有本来可以上网的话，使用yum安装会省很多的事情。
但是没办法，环境是这样，正式环境没有提供网络环境，搭建的本地yum环境也不知道行不行。</p>

<p>上次在自己电脑的虚拟机上面成功安装过ganglia，但apache、rrdtool依赖使用yum安装的，安装过程比较揪心。把ganglia安装到正式环境就不了了之的。
上个星期生产环境出现了用户查询数据久久不能返回的问题，由于查询程序写的比较差的缘故。但同时也给自己敲了警钟，都不知道集群机器运行情况，终究是大隐患；安装后监测集群同时为以后程序的调优工作带来便利。</p>

<p>总结下，原来安装ganglia就仅是按照网络的步骤一步步的弄，同时各个程序的版本又有可能不一致，每一步都胆战心惊！没有重点重心，以至于浪费了很多的事情。
分步骤有条不紊的操作就可以踏实多了，安装ganglia主要涉及三个核心部分(安装程序包<a href="http://yunpan.cn/QCFUiuyAWSyZI">下载</a>（提取码：0ec4）)：</p>

<p>纯手工安装Ganglia(rrdtool也是手工安装)，本次安装全部使用源码包安装，有部分lib有重复编译。</p>

<ul>
<li>rrdtool</li>
<li>gmetad / gmond</li>
<li>apache / web</li>
<li>集群子节点部署</li>
<li>配置hadoop metrics监控hadoop集群</li>
</ul>


<p>按照顺序一个个的安装就可以了，无需为一个个依赖的版本不一致问题而忧心。不考虑版本的问题时，可以更好的单个参考网络上的实践。</p>

<h2>安装rrdtool</h2>

<p>推荐按照<a href="http://oss.oetiker.ch/rrdtool/doc/rrdbuild.en.html#IBUILDING_DEPENDENCIES">官网教程</a>步骤操作，非常的详细。（如果可以上网，推荐用yum安装，方便简单。其实我们也不是c程序员，也不是要成为rrdtool的开发者，能用会用就好！！）
教程中 <strong>环境变量必须得设置</strong> ！这个很重点！</p>

<p>下面是安装rrdtool过程中用到的软件，列出的顺序即为安装的次序：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-44 rrdbuild]$ ll -tr | grep -v 'tar'
</span><span class='line'>总计 24132
</span><span class='line'>drwxrwxrwx  6   1000          1000    4096 07-17 12:12 pkg-config-0.23
</span><span class='line'>drwxr-xr-x 11 hadoop            80    4096 07-17 12:28 zlib-1.2.3
</span><span class='line'>drwxr-xr-x  7   1004 avahi-autoipd    4096 07-17 12:29 libpng-1.2.18
</span><span class='line'>drwxr-xr-x  8   1000 users            4096 07-17 12:31 freetype-2.3.5
</span><span class='line'>drwxrwxrwx 15  50138 vcsa            12288 07-17 16:37 libxml2-2.6.32
</span><span class='line'>drwxrwxrwx 15   1488 users            4096 07-17 16:53 fontconfig-2.4.2
</span><span class='line'>drwxrwxrwx  4 sjyw   sjyw             4096 07-17 16:56 pixman-0.10.0
</span><span class='line'>drwxrwsrwx  8   1000 ftp              4096 07-17 16:59 cairo-1.6.4
</span><span class='line'>drwxrwxrwx 12 sjyw   sjyw             4096 07-17 17:01 glib-2.15.4
</span><span class='line'>drwxrwxrwx  9 sjyw   sjyw             4096 07-17 17:16 pango-1.21.1
</span><span class='line'>drwxr-xr-x 11   1003          1001    4096 07-17 17:36 rrdtool-1.4.8</span></code></pre></td></tr></table></div></figure>


<p>具体操作的步骤（原来包括操作步骤，发现太累赘了重新调整了一下）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 下面几个环境变量是基础！
</span><span class='line'>BUILD_DIR=/home/ganglia/rrdbuild
</span><span class='line'>INSTALL_DIR=/opt/rrdtool-1.4.8
</span><span class='line'>
</span><span class='line'>export PKG_CONFIG_PATH=${INSTALL_DIR}/lib/pkgconfig
</span><span class='line'>export PATH=$INSTALL_DIR/bin:$PATH
</span><span class='line'>
</span><span class='line'>export LDFLAGS="-Wl,--rpath -Wl,${INSTALL_DIR}/lib" 
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf pkg-config-0.23.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd pkg-config-0.23
</span><span class='line'>[root@umcc97-44 pkg-config-0.23]# ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC"
</span><span class='line'>[root@umcc97-44 pkg-config-0.23]# make && make install
</span><span class='line'>
</span><span class='line'># 这个环境变量也很重要
</span><span class='line'>[root@umcc97-44 pkg-config-0.23]# export PKG_CONFIG=$INSTALL_DIR/bin/pkg-config
</span><span class='line'>[root@umcc97-44 pkg-config-0.23]# cd ..
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf zlib-1.2.3.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd zlib-1.2.3
</span><span class='line'># 修改了下官网的命令; 64位问题 recompile with -fPIC
</span><span class='line'>[root@umcc97-44 zlib-1.2.3]# CFLAGS="-O3 -fPIC" ./configure
</span><span class='line'>[root@umcc97-44 zlib-1.2.3]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf libpng-1.2.18.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd libpng-1.2.18
</span><span class='line'>[root@umcc97-44 zlib-1.2.3]# cd ../libpng-1.2.18
</span><span class='line'>[root@umcc97-44 libpng-1.2.18]# env CFLAGS="-O3 -fPIC" ./configure --prefix=$INSTALL_DIR
</span><span class='line'>[root@umcc97-44 libpng-1.2.18]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 libpng-1.2.18]# cd ..
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf freetype-2.3.5.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd freetype-2.3.5
</span><span class='line'>[root@umcc97-44 freetype-2.3.5]# ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC"
</span><span class='line'>[root@umcc97-44 freetype-2.3.5]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf libxml2-2.6.32.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd libxml2-2.6.32
</span><span class='line'>[root@umcc97-44 libxml2-2.6.32]#  ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC"
</span><span class='line'>[root@umcc97-44 libxml2-2.6.32]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 libxml2-2.6.32]# cd ..
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf fontconfig-2.4.2.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd fontconfig-2.4.2
</span><span class='line'>[root@umcc97-44 fontconfig-2.4.2]# ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC" --with-freetype-config=$INSTALL_DIR/bin/freetype-config
</span><span class='line'>[root@umcc97-44 fontconfig-2.4.2]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 fontconfig-2.4.2]# cd ..
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd pixman-0.10.0
</span><span class='line'>[root@umcc97-44 pixman-0.10.0]# ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC"
</span><span class='line'>[root@umcc97-44 pixman-0.10.0]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 pixman-0.10.0]# cd ../cairo-1.6.4
</span><span class='line'>[root@umcc97-44 cairo-1.6.4]# ./configure --prefix=$INSTALL_DIR \
</span><span class='line'>&gt;     --enable-xlib=no \
</span><span class='line'>&gt;     --enable-xlib-render=no \
</span><span class='line'>&gt;     --enable-win32=no \
</span><span class='line'>&gt;     CFLAGS="-O3 -fPIC"
</span><span class='line'>[root@umcc97-44 cairo-1.6.4]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 cairo-1.6.4]# cd ..
</span><span class='line'>[root@umcc97-44 rrdbuild]# tar zxvf glib-2.15.4.tar.gz 
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd glib-2.15.4
</span><span class='line'>[root@umcc97-44 glib-2.15.4]# ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC"
</span><span class='line'>[root@umcc97-44 glib-2.15.4]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 rrdbuild]# bunzip2 -c pango-1.21.1.tar.bz2 | tar xf -
</span><span class='line'>[root@umcc97-44 rrdbuild]# ll
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd pango-1.21.1
</span><span class='line'>[root@umcc97-44 pango-1.21.1]# ./configure --prefix=$INSTALL_DIR CFLAGS="-O3 -fPIC" --without-x
</span><span class='line'>[root@umcc97-44 pango-1.21.1]# export PATH=$INSTALL_DIR/bin:$PATH
</span><span class='line'>[root@umcc97-44 pango-1.21.1]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 rrdbuild]# cd rrdtool-1.4.8/
</span><span class='line'>[root@umcc97-44 rrdtool-1.4.8]#  ./configure --prefix=$INSTALL_DIR --disable-tcl --disable-python
</span><span class='line'>[root@umcc97-44 rrdtool-1.4.8]# make clean
</span><span class='line'>[root@umcc97-44 rrdtool-1.4.8]# make 
</span><span class='line'>[root@umcc97-44 rrdtool-1.4.8]# make install
</span><span class='line'>   
</span><span class='line'>## 安装完后，搞个例子玩玩   
</span><span class='line'>[root@umcc97-44 rrdtool-1.4.8]# cd /opt/rrdtool-1.4.8/share/rrdtool/examples/
</span><span class='line'>[root@umcc97-44 examples]# ll
</span><span class='line'>[root@umcc97-44 examples]# ./4charts.pl 
</span><span class='line'>This script has created 4charts.png in the current directory
</span><span class='line'>This demonstrates the use of the TIME and % RPN operators
</span><span class='line'># 运行完后，会在当前目录生成不同尺寸的png的图片
</span><span class='line'> 
</span><span class='line'>[hadoop@umcc97-44 ~]$ /opt/rrdtool-1.4.8/bin/rrdtool -v
</span><span class='line'>RRDtool 1.4.8  Copyright 1997-2013 by Tobias Oetiker &lt;tobi@oetiker.ch&gt;
</span><span class='line'>               Compiled Jul 17 2014 17:37:58
</span><span class='line'>
</span><span class='line'>Usage: rrdtool [options] command command_options
</span><span class='line'>Valid commands: create, update, updatev, graph, graphv,  dump, restore,
</span><span class='line'>      last, lastupdate, first, info, fetch, tune,
</span><span class='line'>      resize, xport, flushcached
</span><span class='line'>
</span><span class='line'>RRDtool is distributed under the Terms of the GNU General
</span><span class='line'>Public License Version 2. (www.gnu.org/copyleft/gpl.html)
</span><span class='line'>
</span><span class='line'>For more information read the RRD manpages</span></code></pre></td></tr></table></div></figure>


<p>到这里rrd安装好。期间，遇到zlib的CFLAGS变量设置的问题，以及终端断了必须重新设置<strong>环境变量</strong>两个大点的问题！其他如果按照官网的顺序安装基本顺顺利利了。</p>

<p>同时认识到了pkg，其实类似于java的jar嘛，依赖包不一定非要安装在系统的默认位置，自己管理也是一种简单易行的方式。接下来安装gmetad/gmond也使用这样方式，为后面部署gmond带来便利：所有依赖的包都放在一个目录下嘛！
接下来ganglia程序。</p>

<h2>gmetad安装</h2>

<p>需要用到的软件包：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./gangliabuild/ganglia-web-3.5.12
</span><span class='line'>./gangliabuild/apr-1.5.1
</span><span class='line'>./gangliabuild/apr-util-1.5.3
</span><span class='line'>./gangliabuild/confuse-2.7
</span><span class='line'>./gangliabuild/expat-2.0.1
</span><span class='line'>./gangliabuild/ganglia-3.6.0</span></code></pre></td></tr></table></div></figure>


<p>整个安装过程，除了make的时刻rrd的库找不到的问题（通过 LD_LIBRARY_PATH 解决），其他都可以很顺利的安装。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 把下载来的tar全部解压
</span><span class='line'>[root@umcc97-44 gangliabuild]# find . -name "*.tar.gz" -exec tar zxvf {} \;
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 gangliabuild]# cd expat-2.0.1
</span><span class='line'>[root@umcc97-44 expat-2.0.1]# INSTALL_DIR=/opt/ganglia
</span><span class='line'>[root@umcc97-44 expat-2.0.1]# ./configure --prefix=$INSTALL_DIR 
</span><span class='line'>[root@umcc97-44 expat-2.0.1]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 expat-2.0.1]# cd ../apr-1.5.1
</span><span class='line'>[root@umcc97-44 apr-1.5.1]# ./configure --prefix=$INSTALL_DIR 
</span><span class='line'>[root@umcc97-44 apr-1.5.1]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 apr-1.5.1]# cd ../apr-util-1.5.3
</span><span class='line'>[root@umcc97-44 apr-util-1.5.3]# ./configure --with-apr=/opt/ganglia --with-expat=/opt/ganglia --prefix=$INSTALL_DIR 
</span><span class='line'>[root@umcc97-44 apr-util-1.5.3]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 apr-util-1.5.3]# cd ../confuse-2.7
</span><span class='line'>[root@umcc97-44 confuse-2.7]# ./configure CFLAGS=-fPIC --disable-nls --prefix=$INSTALL_DIR 
</span><span class='line'>[root@umcc97-44 confuse-2.7]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 confuse-2.7]# cd ../ganglia-3.6.0
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# export LDFLAGS="-Wl,--rpath -Wl,${INSTALL_DIR}/lib" 
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# export PKG_CONFIG_PATH=${INSTALL_DIR}/lib/pkgconfig
</span><span class='line'># 注意sysconfdir，运行程序配置所在的目录
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# ./configure --prefix=$INSTALL_DIR --with-librrd=/opt/rrdtool-1.4.8 --with-libexpat=/opt/ganglia --with-libconfuse=/opt/ganglia --with-libpcre=no  --with-gmetad --enable-gexec --enable-status -sysconfdir=/etc/ganglia
</span><span class='line'>...
</span><span class='line'>Welcome to..
</span><span class='line'>     ______                  ___
</span><span class='line'>    / ____/___ _____  ____ _/ (_)___ _
</span><span class='line'>   / / __/ __ `/ __ \/ __ `/ / / __ `/
</span><span class='line'>  / /_/ / /_/ / / / / /_/ / / / /_/ /
</span><span class='line'>  \____/\__,_/_/ /_/\__, /_/_/\__,_/
</span><span class='line'>                   /____/
</span><span class='line'>
</span><span class='line'>Copyright (c) 2005 University of California, Berkeley
</span><span class='line'>
</span><span class='line'>Version: 3.6.0
</span><span class='line'>Library: Release 3.6.0 0:0:0
</span><span class='line'>
</span><span class='line'>Type "make" to compile.
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# 
</span><span class='line'># 设置rrd的LIB路径
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# export LD_LIBRARY_PATH=/opt/rrdtool-1.4.8/lib
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# make
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# make install</span></code></pre></td></tr></table></div></figure>


<p>接下来是配置gmetad</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@umcc97-44 ganglia-3.6.0]#  cd gmetad
</span><span class='line'>[root@umcc97-44 gmetad]# cp gmetad.init /etc/init.d/gmetad
</span><span class='line'>[root@umcc97-44 gmetad]# chkconfig gmetad on
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 gmetad]# chkconfig --list gmetad
</span><span class='line'>gmetad            0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 gmetad]# mkdir -p /var/lib/ganglia/rrds
</span><span class='line'>[root@umcc97-44 gmetad]# chown nobody:nobody /var/lib/ganglia/rrds
</span><span class='line'>[root@umcc97-44 gmetad]# 
</span><span class='line'># 没有启动起来，程序的路径不对
</span><span class='line'>[root@umcc97-44 gmetad]# service gmetad start
</span><span class='line'>Starting GANGLIA gmetad: 
</span><span class='line'>[root@umcc97-44 gmetad]# 
</span><span class='line'>[root@umcc97-44 gmetad]# ln -s /opt/ganglia/sbin/gmetad /usr/sbin/gmetad
</span><span class='line'>[root@umcc97-44 gmetad]# service gmetad start
</span><span class='line'>Starting GANGLIA gmetad: [  OK  ]
</span><span class='line'>
</span><span class='line'># 配置
</span><span class='line'>[root@umcc97-44 gmetad]# cp gmetad.conf /etc/ganglia/gmetad.conf
</span><span class='line'>[root@umcc97-44 gmetad]# vi /etc/ganglia/gmetad.conf 
</span><span class='line'> datasource "hadoop" localhost
</span><span class='line'> rrd_rootdir "/var/lib/ganglia/rrds"
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 gmetad]# service gmetad restart
</span><span class='line'>Shutting down GANGLIA gmetad: [  OK  ]
</span><span class='line'>Starting GANGLIA gmetad: [  OK  ]
</span><span class='line'>
</span><span class='line'># 测试下
</span><span class='line'>[root@umcc97-44 gmetad]# telnet localhost 8651</span></code></pre></td></tr></table></div></figure>


<h2>gmond安装（Update 2016-1-23 17:42:07 其实上面的步骤已经安装好了gmond）</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@umcc97-44 gmetad]# pwd
</span><span class='line'>/home/ganglia/gangliabuild/ganglia-3.6.0/gmetad
</span><span class='line'>[root@umcc97-44 gmetad]# cd ..
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# ./configure --prefix=$INSTALL_DIR  --with-libpcre=no
</span><span class='line'>...
</span><span class='line'>Welcome to..
</span><span class='line'>     ______                  ___
</span><span class='line'>    / ____/___ _____  ____ _/ (_)___ _
</span><span class='line'>   / / __/ __ `/ __ \/ __ `/ / / __ `/
</span><span class='line'>  / /_/ / /_/ / / / / /_/ / / / /_/ /
</span><span class='line'>  \____/\__,_/_/ /_/\__, /_/_/\__,_/
</span><span class='line'>                   /____/
</span><span class='line'>
</span><span class='line'>Copyright (c) 2005 University of California, Berkeley
</span><span class='line'>
</span><span class='line'>Version: 3.6.0
</span><span class='line'>Library: Release 3.6.0 0:0:0
</span><span class='line'>
</span><span class='line'>Type "make" to compile.
</span><span class='line'>
</span><span class='line'># 尽管检查通过了，但是make会报错
</span><span class='line'># 需要指定lib包位置
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# ./configure --prefix=$INSTALL_DIR  --with-libpcre=no  --with-libexpat=/opt/ganglia --with-libconfuse=/opt/ganglia -sysconfdir=/etc/ganglia
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# cd gmond/
</span><span class='line'>[root@umcc97-44 gmond]# ./gmond -t &gt; /etc/ganglia/gmond.conf
</span><span class='line'>
</span><span class='line'># 和gmetad一样，需要把路径把程序做个软连接
</span><span class='line'>[root@umcc97-44 gmond]# cat gmond.init
</span><span class='line'>  #!/bin/sh
</span><span class='line'>  #
</span><span class='line'>  # chkconfig: 2345 70 40
</span><span class='line'>  # description: gmond startup script
</span><span class='line'>  #
</span><span class='line'>  GMOND=/usr/sbin/gmond
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>[root@umcc97-44 gmond]# ln -s /opt/ganglia/sbin/gmond /usr/sbin/gmond
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 gmond]# cp gmond.init /etc/init.d/gmond
</span><span class='line'>[root@umcc97-44 gmond]# chkconfig --add gmond
</span><span class='line'>[root@umcc97-44 gmond]# chkconfig --list gmond
</span><span class='line'>gmond             0:off   1:off   2:on    3:on    4:on    5:on    6:off
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# vi /etc/ganglia/gmond.conf 
</span><span class='line'> cluster-name
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# service gmond start
</span><span class='line'>Starting GANGLIA gmond: [  OK  ]
</span><span class='line'>
</span><span class='line'># 测试下
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# telnet localhost 8649</span></code></pre></td></tr></table></div></figure>


<p>查看运行情况：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@umcc97-44 ganglia-3.6.0]# ldconfig -v
</span><span class='line'>[root@umcc97-44 ganglia-3.6.0]# /opt/ganglia/bin/gstat -a</span></code></pre></td></tr></table></div></figure>


<h2>安装apache和php环境</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@umcc97-44 webbuild]# tar zxvf httpd-2.4.9.tar.gz 
</span><span class='line'>[root@umcc97-44 webbuild]# cd httpd-2.4.9
</span><span class='line'>[root@umcc97-44 httpd-2.4.9]# ./configure -with-enable-so -sysconfdir=/etc/httpd
</span><span class='line'>...
</span><span class='line'>checking for APR... no
</span><span class='line'>configure: error: APR not found.  Please read the documentation.
</span><span class='line'>
</span><span class='line'># 前面安装ganglia时也安装过APR但是安装的目录指定的，混用不是很好。查看官方安装2.4的安装文档，可以直接把apr放到srclib下，编译时会同时编译这些依赖
</span><span class='line'>[root@umcc97-44 httpd-2.4.9]# cd srclib/
</span><span class='line'>[root@umcc97-44 srclib]# cp -r /home/ganglia/gangliabuild/apr-1.5.1 ./
</span><span class='line'>[root@umcc97-44 srclib]# cp -r /home/ganglia/gangliabuild/apr-util-1.5.3 ./
</span><span class='line'>[root@umcc97-44 srclib]# mv apr-1.5.1 apr
</span><span class='line'>[root@umcc97-44 srclib]# mv apr-util-1.5.3 apr-util
</span><span class='line'>[root@umcc97-44 srclib]# ll
</span><span class='line'>[root@umcc97-44 srclib]# cd ..
</span><span class='line'>[root@umcc97-44 httpd-2.4.9]#  cd ../
</span><span class='line'>[root@umcc97-44 webbuild]# tar zxvf pcre-8.35.tar.gz 
</span><span class='line'># 正则表达式的包，这里安装默认位置
</span><span class='line'>[root@umcc97-44 webbuild]# cd pcre-8.35
</span><span class='line'>[root@umcc97-44 pcre-8.35]# ./configure 
</span><span class='line'>[root@umcc97-44 pcre-8.35]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 pcre-8.35]# cd ../httpd-2.4.9
</span><span class='line'>[root@umcc97-44 httpd-2.4.9]# ./configure --with-included-apr -with-enable-so -sysconfdir=/etc/httpd
</span><span class='line'>[root@umcc97-44 httpd-2.4.9]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 httpd-2.4.9]# cd /usr/local/apache2/
</span><span class='line'>[root@umcc97-44 apache2]# cd /etc/httpd
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 httpd]# cd /home/ganglia/webbuild/
</span><span class='line'>[root@umcc97-44 webbuild]# tar zxvf php-5.5.14\ \(2\).tar.gz 
</span><span class='line'>[root@umcc97-44 webbuild]# cd php-5.5.14
</span><span class='line'># 用了安装rrd时的libxml
</span><span class='line'>[root@umcc97-44 php-5.5.14]# ./configure -with-apxs2=/usr/local/apache2/bin/apxs --with-libxml-dir=/opt/rrdtool-1.4.8/ -sysconfdir=/etc -with-config-file-path=/etc -with-config-file-scan-dir=/usr/etc/php.d -with-zlib
</span><span class='line'>[root@umcc97-44 php-5.5.14]# make && make install
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 php-5.5.14]#  
</span><span class='line'>[root@umcc97-44 php-5.5.14]#  vi /etc/httpd/httpd.conf
</span><span class='line'>
</span><span class='line'>  LoadModule php5_module        modules/libphp5.so #这个安装php后自动加上了
</span><span class='line'>
</span><span class='line'>  DocumentRoot "/var/www/html"
</span><span class='line'>  &lt;Directory "/var/www/html"&gt;
</span><span class='line'>
</span><span class='line'>  AddType application/x-httpd-php .php
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 php-5.5.14]# /usr/local/apache2/bin/apachectl start
</span><span class='line'>AH00526: Syntax error on line 215 of /etc/httpd/httpd.conf:
</span><span class='line'>DocumentRoot must be a directory
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 php-5.5.14]# mkdir -p /var/www/html
</span><span class='line'>[root@umcc97-44 php-5.5.14]# /usr/local/apache2/bin/apachectl start
</span><span class='line'>AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.18.97.44. Set the 'ServerName' directive globally to suppress this message
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 php-5.5.14]#  vi /etc/httpd/httpd.conf
</span><span class='line'>  ServerName
</span><span class='line'>[root@umcc97-44 php-5.5.14]#/usr/local/apache2/bin/apachectl start
</span><span class='line'>httpd (pid 31416) already running
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 php-5.5.14]# cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd
</span><span class='line'>[root@umcc97-44 php-5.5.14]# chkconfig --add httpd
</span><span class='line'>service httpd does not support chkconfig
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ~]# cat /etc/init.d/httpd 
</span><span class='line'> #chkconfig: 2345 10 90
</span><span class='line'> #description: Activates/Deactivates Apache Web Server
</span><span class='line'> 
</span><span class='line'>[root@umcc97-44 ~]# service httpd start
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ~]# cd /var/www/html/
</span><span class='line'>[root@umcc97-44 ~]# vi index.php
</span><span class='line'># http://umcc97-44 浏览器查看下结果
</span><span class='line'>
</span><span class='line'># /usr/local/apache2/bin/apachectl -k stop
</span><span class='line'>[root@umcc97-44 ganglia-web]# service httpd -k stop   
</span><span class='line'># 等apache结束
</span><span class='line'>[root@umcc97-44 ganglia-web]# tail -f /usr/local/apache2/logs/error_log </span></code></pre></td></tr></table></div></figure>


<p>部署ganglia-web：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@umcc97-44 ~]# cd /home/ganglia/gangliabuild/ganglia-web-3.5.12
</span><span class='line'>[root@umcc97-44 ganglia-web-3.5.12]# ls
</span><span class='line'>[root@umcc97-44 ganglia-web-3.5.12]# make install
</span><span class='line'>rsync --exclude "rpmbuild" --exclude "*.gz" --exclude "Makefile" --exclude "*debian*" --exclude "ganglia-web-3.5.12" --exclude ".git*" --exclude "*.in" --exclude "*~" --exclude "#*#" --exclude "ganglia-web.spec" --exclude "apache.conf" -a . ganglia-web-3.5.12
</span><span class='line'>mkdir -p //var/lib/ganglia-web/dwoo/compiled && \
</span><span class='line'>  mkdir -p //var/lib/ganglia-web/dwoo/cache && \
</span><span class='line'>  mkdir -p //var/lib/ganglia-web && \
</span><span class='line'>  rsync -a ganglia-web-3.5.12/conf //var/lib/ganglia-web && \
</span><span class='line'>  mkdir -p //usr/share/ganglia-webfrontend && \
</span><span class='line'>  rsync --exclude "conf" -a ganglia-web-3.5.12/* //usr/share/ganglia-webfrontend && \
</span><span class='line'>  chown -R root:root //var/lib/ganglia-web
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ganglia-web-3.5.12]# mv /usr/share/ganglia-webfrontend /var/www/html/ganglia
</span><span class='line'>[root@umcc97-44 ganglia-web-3.5.12]# cd /var/www/html/ganglia/    
</span><span class='line'>
</span><span class='line'># 修改配置，在安装完gmetad后有新建/var/lib/ganglia/rrds其实和conf中的配置是一致的
</span><span class='line'>[root@umcc97-44 ganglia]# cp conf_default.php conf.php    
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 ganglia]# cd /var/lib/ganglia-web/
</span><span class='line'>[root@umcc97-44 ganglia-web]# cd dwoo/
</span><span class='line'>[root@umcc97-44 dwoo]# ll
</span><span class='line'>total 8
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jul 17 21:34 cache
</span><span class='line'>drwxr-xr-x 2 root root 4096 Jul 17 21:34 compiled
</span><span class='line'>[root@umcc97-44 dwoo]# chmod 777 *    
</span><span class='line'># http://umcc97-44/ganglia</span></code></pre></td></tr></table></div></figure>


<p>部署gmond到其他集群节点</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>[root@umcc97-44 opt]# cat /etc/init.d/gmond 
</span><span class='line'>  #!/bin/sh
</span><span class='line'>  #
</span><span class='line'>  # chkconfig: 2345 70 40
</span><span class='line'>  # description: gmond startup script
</span><span class='line'>  #
</span><span class='line'>  GMOND=/usr/sbin/gmond   
</span><span class='line'>
</span><span class='line'>[root@umcc97-44 opt]# vi /etc/ganglia/gmetad.conf     
</span><span class='line'> data_source
</span><span class='line'> # 重启gmetad
</span><span class='line'>
</span><span class='line'># 部署其他节点
</span><span class='line'>[root@umcc97-44 opt]# ssh-copy-id -i ~/.ssh/id_rsa.pub umcc97-144
</span><span class='line'>[root@umcc97-44 opt]# scp /etc/init.d/gmond umcc97-144:/etc/init.d/
</span><span class='line'>[root@umcc97-44 opt]# ssh umcc97-144 'mkdir /etc/ganglia' 
</span><span class='line'>[root@umcc97-44 opt]# scp /etc/ganglia/gmond.conf  umcc97-144:/etc/ganglia/
</span><span class='line'>[root@umcc97-44 opt]# rsync -vaz ganglia umcc97-144:/opt/
</span><span class='line'>[root@umcc97-44 opt]# ssh umcc97-144
</span><span class='line'>Last login: Tue Jun 10 12:08:47 2014
</span><span class='line'>
</span><span class='line'>[root@umcc97-144 ~]# ln -s /opt/ganglia/sbin/gmond /usr/sbin/gmond
</span><span class='line'>[root@umcc97-144 ~]# chkconfig --add gmond
</span><span class='line'>[root@umcc97-144 ~]# service gmond start
</span><span class='line'>Starting GANGLIA gmond: [  OK  ]
</span></code></pre></td></tr></table></div></figure>


<h2>Hadoop/Hbase Metrics配置</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-44 ~]$ cat hadoop-2.2.0/etc/hadoop/hadoop-metrics*
</span><span class='line'>#
</span><span class='line'>#   Licensed to the Apache Software Foundation (ASF) under one or more
</span><span class='line'>#   contributor license agreements.  See the NOTICE file distributed with
</span><span class='line'>#   this work for additional information regarding copyright ownership.
</span><span class='line'>#   The ASF licenses this file to You under the Apache License, Version 2.0
</span><span class='line'>#   (the "License"); you may not use this file except in compliance with
</span><span class='line'>#   the License.  You may obtain a copy of the License at
</span><span class='line'>#
</span><span class='line'>#       http://www.apache.org/licenses/LICENSE-2.0
</span><span class='line'>#
</span><span class='line'>#   Unless required by applicable law or agreed to in writing, software
</span><span class='line'>#   distributed under the License is distributed on an "AS IS" BASIS,
</span><span class='line'>#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span><span class='line'>#   See the License for the specific language governing permissions and
</span><span class='line'>#   limitations under the License.
</span><span class='line'>#
</span><span class='line'>
</span><span class='line'># syntax: [prefix].[source|sink].[instance].[options]
</span><span class='line'># See javadoc of package-info.java for org.apache.hadoop.metrics2 for details
</span><span class='line'>
</span><span class='line'># @changed
</span><span class='line'>#*.sink.file.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># default sampling period, in seconds
</span><span class='line'>#*.period=10
</span><span class='line'>
</span><span class='line'># The namenode-metrics.out will contain metrics from all context
</span><span class='line'>#namenode.sink.file.filename=namenode-metrics.out
</span><span class='line'># Specifying a special sampling period for namenode:
</span><span class='line'>#namenode.sink.*.period=8
</span><span class='line'>
</span><span class='line'>#datanode.sink.file.filename=datanode-metrics.out
</span><span class='line'>
</span><span class='line'># the following example split metrics of different
</span><span class='line'># context to different sinks (in this case files)
</span><span class='line'>#jobtracker.sink.file_jvm.context=jvm
</span><span class='line'>#jobtracker.sink.file_jvm.filename=jobtracker-jvm-metrics.out
</span><span class='line'>#jobtracker.sink.file_mapred.context=mapred
</span><span class='line'>#jobtracker.sink.file_mapred.filename=jobtracker-mapred-metrics.out
</span><span class='line'>
</span><span class='line'>#tasktracker.sink.file.filename=tasktracker-metrics.out
</span><span class='line'>
</span><span class='line'>#maptask.sink.file.filename=maptask-metrics.out
</span><span class='line'>
</span><span class='line'>#reducetask.sink.file.filename=reducetask-metrics.out
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31
</span><span class='line'>*.sink.ganglia.period=10
</span><span class='line'>
</span><span class='line'>*.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapUsedM=both
</span><span class='line'>*.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm.metrics.memHeapUsedM=40
</span><span class='line'>
</span><span class='line'>namenode.sink.ganglia.servers=umcc97-44:8649
</span><span class='line'>resourcemanager.sink.ganglia.servers=umcc97-44:8649
</span><span class='line'>
</span><span class='line'>datanode.sink.ganglia.servers=umcc97-44:8649
</span><span class='line'>nodemanager.sink.ganglia.servers=umcc97-44:8649
</span><span class='line'>
</span><span class='line'>maptask.sink.ganglia.servers=umcc97-44:8649
</span><span class='line'>reducetask.sink.ganglia.servers=umcc97-44:8649
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Configuration of the "dfs" context for null
</span><span class='line'>dfs.class=org.apache.hadoop.metrics.spi.NullContext
</span><span class='line'>
</span><span class='line'># Configuration of the "dfs" context for file
</span><span class='line'>#dfs.class=org.apache.hadoop.metrics.file.FileContext
</span><span class='line'>#dfs.period=10
</span><span class='line'>#dfs.fileName=/tmp/dfsmetrics.log
</span><span class='line'>
</span><span class='line'># Configuration of the "dfs" context for ganglia
</span><span class='line'># Pick one: Ganglia 3.0 (former) or Ganglia 3.1 (latter)
</span><span class='line'># dfs.class=org.apache.hadoop.metrics.ganglia.GangliaContext
</span><span class='line'># dfs.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
</span><span class='line'># dfs.period=10
</span><span class='line'># dfs.servers=localhost:8649
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Configuration of the "mapred" context for null
</span><span class='line'>mapred.class=org.apache.hadoop.metrics.spi.NullContext
</span><span class='line'>
</span><span class='line'># Configuration of the "mapred" context for file
</span><span class='line'>#mapred.class=org.apache.hadoop.metrics.file.FileContext
</span><span class='line'>#mapred.period=10
</span><span class='line'>#mapred.fileName=/tmp/mrmetrics.log
</span><span class='line'>
</span><span class='line'># Configuration of the "mapred" context for ganglia
</span><span class='line'># Pick one: Ganglia 3.0 (former) or Ganglia 3.1 (latter)
</span><span class='line'># mapred.class=org.apache.hadoop.metrics.ganglia.GangliaContext
</span><span class='line'># mapred.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
</span><span class='line'># mapred.period=10
</span><span class='line'># mapred.servers=localhost:8649
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Configuration of the "jvm" context for null
</span><span class='line'>#jvm.class=org.apache.hadoop.metrics.spi.NullContext
</span><span class='line'>
</span><span class='line'># Configuration of the "jvm" context for file
</span><span class='line'>#jvm.class=org.apache.hadoop.metrics.file.FileContext
</span><span class='line'>#jvm.period=10
</span><span class='line'>#jvm.fileName=/tmp/jvmmetrics.log
</span><span class='line'>
</span><span class='line'># Configuration of the "jvm" context for ganglia
</span><span class='line'># jvm.class=org.apache.hadoop.metrics.ganglia.GangliaContext
</span><span class='line'># jvm.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
</span><span class='line'># jvm.period=10
</span><span class='line'># jvm.servers=localhost:8649
</span><span class='line'>
</span><span class='line'># Configuration of the "rpc" context for null
</span><span class='line'>rpc.class=org.apache.hadoop.metrics.spi.NullContext
</span><span class='line'>
</span><span class='line'># Configuration of the "rpc" context for file
</span><span class='line'>#rpc.class=org.apache.hadoop.metrics.file.FileContext
</span><span class='line'>#rpc.period=10
</span><span class='line'>#rpc.fileName=/tmp/rpcmetrics.log
</span><span class='line'>
</span><span class='line'># Configuration of the "rpc" context for ganglia
</span><span class='line'># rpc.class=org.apache.hadoop.metrics.ganglia.GangliaContext
</span><span class='line'># rpc.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
</span><span class='line'># rpc.period=10
</span><span class='line'># rpc.servers=localhost:8649
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Configuration of the "ugi" context for null
</span><span class='line'>ugi.class=org.apache.hadoop.metrics.spi.NullContext
</span><span class='line'>
</span><span class='line'># Configuration of the "ugi" context for file
</span><span class='line'>#ugi.class=org.apache.hadoop.metrics.file.FileContext
</span><span class='line'>#ugi.period=10
</span><span class='line'>#ugi.fileName=/tmp/ugimetrics.log
</span><span class='line'>
</span><span class='line'># Configuration of the "ugi" context for ganglia
</span><span class='line'># ugi.class=org.apache.hadoop.metrics.ganglia.GangliaContext
</span><span class='line'># ugi.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
</span><span class='line'># ugi.period=10
</span><span class='line'># ugi.servers=localhost:8649
</span><span class='line'>
</span><span class='line'>[hadoop@umcc97-44 ~]$ cat hbase-0.98.3-hadoop2/conf/hadoop-metrics2-hbase.properties 
</span><span class='line'># syntax: [prefix].[source|sink].[instance].[options]
</span><span class='line'># See javadoc of package-info.java for org.apache.hadoop.metrics2 for details
</span><span class='line'>
</span><span class='line'>#*.sink.file*.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># default sampling period
</span><span class='line'>#*.period=10
</span><span class='line'>
</span><span class='line'># Below are some examples of sinks that could be used
</span><span class='line'># to monitor different hbase daemons.
</span><span class='line'>
</span><span class='line'># hbase.sink.file-all.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># hbase.sink.file-all.filename=all.metrics
</span><span class='line'>
</span><span class='line'># hbase.sink.file0.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># hbase.sink.file0.context=hmaster
</span><span class='line'># hbase.sink.file0.filename=master.metrics
</span><span class='line'>
</span><span class='line'># hbase.sink.file1.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># hbase.sink.file1.context=thrift-one
</span><span class='line'># hbase.sink.file1.filename=thrift-one.metrics
</span><span class='line'>
</span><span class='line'># hbase.sink.file2.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># hbase.sink.file2.context=thrift-two
</span><span class='line'># hbase.sink.file2.filename=thrift-one.metrics
</span><span class='line'>
</span><span class='line'># hbase.sink.file3.class=org.apache.hadoop.metrics2.sink.FileSink
</span><span class='line'># hbase.sink.file3.context=rest
</span><span class='line'># hbase.sink.file3.filename=rest.metrics
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31
</span><span class='line'>*.sink.ganglia.period=10
</span><span class='line'>
</span><span class='line'>hbase.sink.ganglia.period=10
</span><span class='line'>hbase.sink.ganglia.servers=umcc97-44:8649
</span></code></pre></td></tr></table></div></figure>


<p>然后properties配置同步到集群的从节点（datanode/regionserver），重启集群。等一会儿就能在ganglia-web界面看到多了很多很多的指标量。</p>

<h2>参考</h2>

<h3>ganglia</h3>

<ul>
<li><p><a href="http://www.huomo.cn/os/article-19aac.html">http://www.huomo.cn/os/article-19aac.html</a></p></li>
<li><p><a href="http://oss.oetiker.ch/rrdtool/doc/rrdbuild.en.html#IBUILDING_DEPENDENCIES">RRDTool安装</a></p></li>
<li><a href="http://www.cnblogs.com/qq78292959/archive/2012/05/30/2526761.html">CFLAGS=&ldquo;-O3 -fPIC&#8221;为64位编译参数</a></li>
<li><a href="http://www.codesky.net/article/201107/174186.html">pkgconfig作用处理包依赖</a></li>
<li><a href="http://blog.chinaunix.net/uid-23916356-id-3290237.html">gmetad和gmond安装以及配置</a></li>
<li><a href="http://wenku.baidu.com/link?url=RH4EhSP3U_dp4I7goEVA_DFkb0DrgZ3uWw_mSt2hhaRb6mQJLtWxaa75RrwETwtY5e8BvOCI_p9RNrmXn_qbEexTE-PGlgtf6f5T3cGglKq">gmond节点拷贝安装</a></li>
<li><a href="http://blog.chinaunix.net/uid-11121450-id-3147002.html">http://blog.chinaunix.net/uid-11121450-id-3147002.html</a></li>
<li><a href="http://blog.chinaunix.net/uid-23916356-id-3290237.html">http://blog.chinaunix.net/uid-23916356-id-3290237.html</a></li>
<li><a href="http://wenku.baidu.com/link?url=qY7vCTyodgSCsoIg6c2UiHXWv0nEGkS9nd0DbQERxFGEaTvgvi7FMQTKv5Sn1L9H8CX5_gDgAbJJ5jaQh3KhZED7PoB2Bgr2I6mS-vDc1LS">虚拟机操作从零开始弄, 搭了个本地源, 配置</a></li>
<li><a href="http://www.linuxidc.com/Linux/2014-01/95804p2.htm">Hadoop/Hbase metrics2配置</a></li>
<li><a href="https://github.com/cbuchner1/CudaMiner/issues/23">https://github.com/cbuchner1/CudaMiner/issues/23</a></li>
<li><a href="http://bbs.csdn.net/topics/390546319">http://bbs.csdn.net/topics/390546319</a> LIBRARY_PATH是编译时使用的，LD_LIBRARY_PATH是运行时使用的。</li>
</ul>


<h3>apache web</h3>

<ul>
<li><a href="http://blog.sina.com.cn/s/blog_70121e200100lq0h.html">apache程序安装</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_5d15305b0101ceft.html">apache服务安装配置</a></li>
<li><a href="http://www.cnblogs.com/yuboyue/archive/2011/07/18/2109875.html">apache关闭服务</a></li>
<li><a href="http://www.soadmin.com/zonghe/operating-system/1008085.htm">目录权限处理</a></li>
<li><a href="http://blog.163.com/figo_2007@126/blog/static/2318076520111149413935/">http://blog.163.com/figo_2007@126/blog/static/2318076520111149413935/</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_70121e200100lq0h.html">http://blog.sina.com.cn/s/blog_70121e200100lq0h.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_815611fb0101cxnl.html">http://blog.sina.com.cn/s/blog_815611fb0101cxnl.html</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/21/upgrade-hive/">Upgrade Hive: 0.12.0 to 0.13.1</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-21T02:34:59+08:00" pubdate data-updated="true">Sat 2014-06-21 02:34</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>由于hive-0.12.0的FileSystem使用不当导致内存溢出问题，最终考虑升级hive。升级的过程没想象中的那么可怕，步骤很简单：对源数据库执行升级脚本，拷贝原hive-0.12.0的配置和jar，然后把添加jar重启hiverserver2即可。记录了升级到0.13，添加tez，调试hive。</p>

<h2>修改环境变量</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>HIVE_HOME=/home/hadoop/apache-hive-0.13.1-bin
</span><span class='line'>PATH=$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH</span></code></pre></td></tr></table></div></figure>


<p>如果要使用hwi，需要自己下载原来编译生成war。（默认的bin.tar.gz里面不包括）</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@Lenovo-PC ~/git/hive/hwi
</span><span class='line'>$ mvn package war:war</span></code></pre></td></tr></table></div></figure>


<p>配置的时刻注意下<code>hive.hwi.war.file</code>是相对于<strong>HIVE_HOME</strong>的位置<code>lib/hive-hwi-0.13.1.war</code>。同时需要把<code>$JDK/lib/tools.jar</code>加入到classpath。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/home/eshore/jdk1.7.0_60/lib/tools.jar
</span><span class='line'>
</span><span class='line'>$CD/bin/hive --service hwi</span></code></pre></td></tr></table></div></figure>


<h2>升级metadata</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@ismp0 ~]$ cd apache-hive-0.13.1-bin/scripts/metastore/upgrade/mysql/
</span><span class='line'>
</span><span class='line'>[hadoop@ismp0 mysql]$ mysql -uXXX -hXXX -pXXX
</span><span class='line'>mysql&gt; use hive
</span><span class='line'>Reading table information for completion of table and column names
</span><span class='line'>You can turn off this feature to get a quicker startup with -A
</span><span class='line'>
</span><span class='line'>Database changed
</span><span class='line'>mysql&gt; source upgrade-0.12.0-to-0.13.0.mysql.sql
</span><span class='line'>+--------------------------------------------------+
</span><span class='line'>|                                                  |
</span><span class='line'>+--------------------------------------------------+
</span><span class='line'>| Upgrading MetaStore schema from 0.12.0 to 0.13.0 |
</span><span class='line'>+--------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>+-----------------------------------------------------------------------+
</span><span class='line'>|                                                                       |
</span><span class='line'>+-----------------------------------------------------------------------+
</span><span class='line'>| &lt; HIVE-5700 enforce single date format for partition column storage &gt; |
</span><span class='line'>+-----------------------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.22 sec)
</span><span class='line'>Rows matched: 0  Changed: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>+--------------------------------------------+
</span><span class='line'>|                                            |
</span><span class='line'>+--------------------------------------------+
</span><span class='line'>| &lt; HIVE-6386: Add owner filed to database &gt; |
</span><span class='line'>+--------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.33 sec)
</span><span class='line'>Records: 1  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.16 sec)
</span><span class='line'>Records: 1  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------------+
</span><span class='line'>|                                                                                             |
</span><span class='line'>+---------------------------------------------------------------------------------------------+
</span><span class='line'>| &lt;HIVE-6458 Add schema upgrade scripts for metastore changes related to permanent functions&gt; |
</span><span class='line'>+---------------------------------------------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.06 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.06 sec)
</span><span class='line'>
</span><span class='line'>+----------------------------------------------------------------------------------+
</span><span class='line'>|                                                                                  |
</span><span class='line'>+----------------------------------------------------------------------------------+
</span><span class='line'>| &lt;HIVE-6757 Remove deprecated parquet classes from outside of org.apache package&gt; |
</span><span class='line'>+----------------------------------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.04 sec)
</span><span class='line'>Rows matched: 0  Changed: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>Rows matched: 0  Changed: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.01 sec)
</span><span class='line'>Rows matched: 0  Changed: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.07 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.12 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.07 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.06 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.05 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.06 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.15 sec)
</span><span class='line'>Records: 0  Duplicates: 0  Warnings: 0
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.06 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.05 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.07 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 0 rows affected (0.06 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.05 sec)
</span><span class='line'>
</span><span class='line'>Query OK, 1 row affected (0.07 sec)
</span><span class='line'>Rows matched: 1  Changed: 1  Warnings: 0
</span><span class='line'>
</span><span class='line'>+-----------------------------------------------------------+
</span><span class='line'>|                                                           |
</span><span class='line'>+-----------------------------------------------------------+
</span><span class='line'>| Finished upgrading MetaStore schema from 0.12.0 to 0.13.0 |
</span><span class='line'>+-----------------------------------------------------------+
</span><span class='line'>1 row in set, 1 warning (0.00 sec)
</span><span class='line'>
</span><span class='line'>mysql&gt; 
</span><span class='line'>mysql&gt; 
</span><span class='line'>mysql&gt; exit
</span><span class='line'>Bye
</span><span class='line'>
</span><span class='line'>[hadoop@ismp0 ~]$ vi .bash_profile
</span><span class='line'>[hadoop@ismp0 ~]$ source .bash_profile
</span><span class='line'>[hadoop@ismp0 ~]$ cd apache-hive-0.13.1-bin
</span><span class='line'>[hadoop@ismp0 apache-hive-0.13.1-bin]$ cd conf/
</span><span class='line'>[hadoop@ismp0 conf]$ cp ~/hive-0.12.0/conf/hive-site.xml ./
</span><span class='line'>[hadoop@ismp0 conf]$ cd ..
</span><span class='line'>[hadoop@ismp0 apache-hive-0.13.1-bin]$ cp ~/hive-0.12.0/lib/mysql-connector-java-5.1.21-bin.jar lib/
</span><span class='line'>[hadoop@ismp0 apache-hive-0.13.1-bin]$ hive
</span><span class='line'>[hadoop@ismp0 apache-hive-0.13.1-bin]$ hive
</span><span class='line'>
</span><span class='line'>hive&gt;  select count(*) from t_ods_idc_isp_log2 where day=20140624;
</span><span class='line'>Total jobs = 1
</span><span class='line'>Launching Job 1 out of 1
</span><span class='line'>Number of reduce tasks determined at compile time: 1
</span><span class='line'>In order to change the average load for a reducer (in bytes):
</span><span class='line'>  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;
</span><span class='line'>In order to limit the maximum number of reducers:
</span><span class='line'>  set hive.exec.reducers.max=&lt;number&gt;
</span><span class='line'>In order to set a constant number of reducers:
</span><span class='line'>  set mapreduce.job.reduces=&lt;number&gt;
</span><span class='line'>Starting Job = job_1403006477300_3403, Tracking URL = http://umcc97-79:8088/proxy/application_1403006477300_3403/
</span><span class='line'>Kill Command = /home/hadoop/hadoop-2.2.0/bin/hadoop job  -kill job_1403006477300_3403
</span><span class='line'>Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
</span><span class='line'>2014-06-24 17:19:07,618 Stage-1 map = 0%,  reduce = 0%
</span><span class='line'>2014-06-24 17:19:15,283 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 2.37 sec
</span><span class='line'>2014-06-24 17:19:16,360 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.49 sec
</span><span class='line'>2014-06-24 17:19:22,749 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.99 sec
</span><span class='line'>MapReduce Total cumulative CPU time: 7 seconds 990 msec
</span><span class='line'>Ended Job = job_1403006477300_3403
</span><span class='line'>MapReduce Jobs Launched: 
</span><span class='line'>Job 0: Map: 2  Reduce: 1   Cumulative CPU: 7.99 sec   HDFS Read: 19785618 HDFS Write: 6 SUCCESS
</span><span class='line'>Total MapReduce CPU Time Spent: 7 seconds 990 msec
</span><span class='line'>OK
</span><span class='line'>77625
</span><span class='line'>Time taken: 36.387 seconds, Fetched: 1 row(s)
</span><span class='line'>hive&gt; 
</span><span class='line'>
</span><span class='line'>[hadoop@ismp0 apache-hive-0.13.1-bin]$ nohup bin/hiveserver2 &
</span><span class='line'>
</span><span class='line'>$# 测试hive-jdbc
</span><span class='line'>[hadoop@ismp0 apache-hive-0.13.1-bin]$ bin/beeline 
</span><span class='line'>Beeline version 0.13.1 by Apache Hive
</span><span class='line'>beeline&gt; !connect jdbc:hive2://10.18.97.22:10000/
</span><span class='line'>scan complete in 7ms
</span><span class='line'>Connecting to jdbc:hive2://10.18.97.22:10000/
</span><span class='line'>Enter username for jdbc:hive2://10.18.97.22:10000/: hadoop
</span><span class='line'>Enter password for jdbc:hive2://10.18.97.22:10000/: 
</span><span class='line'>Connected to: Apache Hive (version 0.13.1)
</span><span class='line'>Driver: Hive JDBC (version 0.13.1)
</span><span class='line'>Transaction isolation: TRANSACTION_REPEATABLE_READ
</span><span class='line'>0: jdbc:hive2://10.18.97.22:10000/&gt; show tables;
</span><span class='line'>+-------------------------+
</span><span class='line'>|        tab_name         |
</span><span class='line'>+-------------------------+
</span><span class='line'>...
</span><span class='line'>| test_123                |
</span><span class='line'>+-------------------------+
</span><span class='line'>10 rows selected (2.547 seconds)
</span><span class='line'>0: jdbc:hive2://10.18.97.22:10000/&gt;  select count(*) from t_ods_idc_isp_log2 where day=20140624;
</span><span class='line'>+--------+
</span><span class='line'>|  _c0   |
</span><span class='line'>+--------+
</span><span class='line'>| 77625  |
</span><span class='line'>+--------+
</span><span class='line'>1 row selected (37.463 seconds)
</span><span class='line'>0: jdbc:hive2://10.18.97.22:10000/&gt; 
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>上一篇tez的安装使用中由于hive的缘故进行了回退，现在升级到hive-0.13后，也在hive上试下tez的功能：</p>

<ul>
<li>本地添加tez依赖，设置环境变量</li>
<li>MR添加tez依赖，添加tez-site.xml</li>
<li>切换到tez的engine</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$# 已上传到HDFS
</span><span class='line'>$ hadoop fs -mkdir /apps
</span><span class='line'>$ hadoop fs -put tez-0.4.0-incubating /apps/
</span><span class='line'>$ hadoop fs -ls /apps
</span><span class='line'>Found 1 items
</span><span class='line'>drwxr-xr-x   - hadoop supergroup          0 2014-09-09 16:19 /apps/tez-0.4.0-incubating
</span><span class='line'>
</span><span class='line'>$ cat etc/hadoop/tez-site.xml 
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>    &lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;${fs.default.name}/apps/tez-0.4.0-incubating,${fs.default.name}/apps/tez-0.4.0-incubating/lib/&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>$ export HADOOP_CLASSPATH=${TEZ_HOME}/*:${TEZ_HOME}/lib/*:$HADOOP_CLASSPATH
</span><span class='line'>$ apache-hive-0.13.1-bin/bin/hive
</span><span class='line'>hive&gt; set hive.execution.engine=tez;
</span><span class='line'>hive&gt; select count(*) from t_ods_idc_isp_log2 ;
</span><span class='line'>Time taken: 24.926 seconds, Fetched: 1 row(s)
</span><span class='line'>
</span><span class='line'>hive&gt; set hive.execution.engine=mr;                              
</span><span class='line'>hive&gt; select count(*) from t_ods_idc_isp_log2 where day=20140720;
</span><span class='line'>Time taken: 40.585 seconds, Fetched: 1 row(s)
</span><span class='line'>
</span><span class='line'>// 添加TEZ的jar到CLASSPATH
</span><span class='line'>$# @hive-env.sh
</span><span class='line'> # export TEZ_HOME=/home/hadoop/tez-0.4.0-incubating
</span><span class='line'> # export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$TEZ_HOME/*:$TEZ_HOME/lib/*
</span><span class='line'>$ last_hour=2014090915
</span><span class='line'>$ hive --hiveconf hive.execution.engine=tez -e "select houseId, count(*) 
</span><span class='line'>from 
</span><span class='line'>(
</span><span class='line'>select houseId
</span><span class='line'>from t_house_monitor2
</span><span class='line'>where hour=$last_hour
</span><span class='line'>group by from_unixtime(cast(accesstime as bigint), 'yyyyMMdd'),houseId,IP,port,domain,serviceType,illegalType,currentState,usr,icpError,regerror,regDomain,use_type,real_useType
</span><span class='line'>) hs
</span><span class='line'>group by houseId"</span></code></pre></td></tr></table></div></figure>


<p>简单从时间上看，还是有效果的。</p>

<p><img src="http://file.bmob.cn/M00/04/A2/wKhkA1PSPSeAb1wWAAER_4gjIug339.png" alt="" /></p>

<h2>调试Hive</h2>

<p>也很简单，hive脚本已经默认集成了这个功能，设置下DEBUG环境变量即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@master1 ~]$ less apache-hive-0.13.1-bin/bin/ext/debug.sh
</span><span class='line'>[hadoop@master1 bin]$ less hive
</span><span class='line'>
</span><span class='line'>$# 脚本最终会把调试的参数` -agentlib:jdwp=transport=dt_socket,server=y,address=8000,suspend=y`加入到HADOOP_CLIENT_OPTS中，最后合并到HADOOP_OPTS传递给java程序。
</span><span class='line'>
</span><span class='line'>[hadoop@master1 bin]$ DEBUG=true hive
</span><span class='line'>Listening for transport dt_socket at address: 8000</span></code></pre></td></tr></table></div></figure>


<p>然后通过eclipse的远程调试即可一步步的查看整个过程。下面断点处为记录解析功能：</p>

<p><img src="http://file.bmob.cn/M00/0A/D4/wKhkA1QEASyAM9VEAAHQS7gZJlo672.png" alt="" /></p>

<h2>编译源码导入eclipse</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git clone https://github.com/apache/hive.git
</span><span class='line'>
</span><span class='line'>winse@Lenovo-PC /cygdrive/e/git/hive
</span><span class='line'>$ git checkout branch-0.13
</span><span class='line'>
</span><span class='line'>E:\git\hive&gt;mvn clean package eclipse:eclipse -DskipTests -Dmaven.test.skip=true -Phadoop-2</span></code></pre></td></tr></table></div></figure>


<h2>注意点</h2>

<ul>
<li>除了分区，hive表数据路径下不能包括其他文件夹</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hive&gt; create database test location '/user/hive/warehouse_temp/' ;
</span><span class='line'>
</span><span class='line'>hive&gt; create table t_ods_ddos as select * from default.t_ods_ddos limit 0;
</span><span class='line'>
</span><span class='line'>hive&gt; select * from t_ods_ddos;
</span><span class='line'>OK
</span><span class='line'>Time taken: 0.176 seconds
</span><span class='line'>
</span><span class='line'>[hadoop@umcc97-44 ~]$ hadoop fs -mkdir /user/hive/warehouse_temp/t_ods_ddos/abc
</span><span class='line'>
</span><span class='line'>hive&gt; select * from t_ods_ddos;
</span><span class='line'>OK
</span><span class='line'>Failed with exception java.io.IOException:java.io.IOException: Not a file: hdfs://umcc97-44:9000/user/hive/warehouse_temp/t_ods_ddos/abc
</span><span class='line'>Time taken: 0.167 seconds</span></code></pre></td></tr></table></div></figure>



</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/18/hadoop-tez-firststep/">Tez编译及使用</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-18T04:22:58+08:00" pubdate data-updated="true">Wed 2014-06-18 04:22</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>初步了解</h2>

<p>hadoop2自带的mapreduce任务中间只能传递一次，也即一个任务只能聚合一次（然后就的写入磁盘）。tez项目是对原有yarn架构的一个拓展，使用DAG（无环有向图）实现MRR的任务框架。</p>

<p><img src="http://farm6.staticflickr.com/5571/14256993179_4990fc86d5_o.png" alt="" /></p>

<p>上图中，左边的MR任务完成一个步骤后，需要进行 <strong>数据存储</strong> 后再执行另一个任务来进行第二个 <strong>reduce</strong> ； 而tez则可以在reduce后继续执行reduce，减少了中间过程的IO以及mapreduce的启动时间。</p>

<h2>环境整合</h2>

<ul>
<li><a href="http://tez.incubator.apache.org/install.html">Install/Deploy</a></li>
<li>hadoop-2.2.0（umcc97-44：hdfs， umcc97-79：yarn）</li>
<li>windows下使用Cygwin编译</li>
</ul>


<h3>下载编译tez</h3>

<p>首先下载<a href="http://apache.fayea.com/apache-mirror/incubator/tez/tez-0.4.0-incubating/">tez-0.4.0-incubating.tar.gz</a>，同时还需要<a href="http://code.google.com/p/protobuf">protoc</a>的程序支持（可以参考<a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html">Hadoop源码编译</a>）。
解压后，使用mvn编译。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big
</span><span class='line'>$ tar zxvf tez-0.4.0-incubating.tar.gz
</span><span class='line'>
</span><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big
</span><span class='line'>$ cd tez-0.4.0-incubating/
</span><span class='line'>
</span><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big/tez-0.4.0-incubating
</span><span class='line'>$ mvn install -DskipTests -Dmaven.javadoc.skip
</span><span class='line'>...
</span><span class='line'>[INFO] Reactor Summary:
</span><span class='line'>[INFO]
</span><span class='line'>[INFO] tez ............................................... SUCCESS [1.518s]
</span><span class='line'>[INFO] tez-api ........................................... SUCCESS [8.890s]
</span><span class='line'>[INFO] tez-common ........................................ SUCCESS [0.725s]
</span><span class='line'>[INFO] tez-runtime-internals ............................. SUCCESS [2.529s]
</span><span class='line'>[INFO] tez-runtime-library ............................... SUCCESS [5.100s]
</span><span class='line'>[INFO] tez-mapreduce ..................................... SUCCESS [3.666s]
</span><span class='line'>[INFO] tez-mapreduce-examples ............................ SUCCESS [2.692s]
</span><span class='line'>[INFO] tez-dag ........................................... SUCCESS [13.943s]
</span><span class='line'>[INFO] tez-tests ......................................... SUCCESS [1.691s]
</span><span class='line'>[INFO] tez-dist .......................................... SUCCESS [14.370s]
</span><span class='line'>[INFO] Tez ............................................... SUCCESS [0.245s]
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] BUILD SUCCESS
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span><span class='line'>[INFO] Total time: 55.791s
</span><span class='line'>[INFO] Finished at: Tue Jun 17 17:33:45 CST 2014
</span><span class='line'>[INFO] Final Memory: 35M/151M
</span><span class='line'>[INFO] ------------------------------------------------------------------------
</span></code></pre></td></tr></table></div></figure>


<h3>上传tez程序的jars到HDFS</h3>

<p>为了简单我直接把tez jars上传到开发环境的集群上面去测试了。放到本地集群环境应该也类似。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big/tez-0.4.0-incubating
</span><span class='line'>$ cd tez-dist/
</span><span class='line'>
</span><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big/tez-0.4.0-incubating/tez-dist
</span><span class='line'>$ cd target/
</span><span class='line'>
</span><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big/tez-0.4.0-incubating/tez-dist/target
</span><span class='line'>$ export HADOOP_USER_NAME=hadoop
</span><span class='line'>
</span><span class='line'>Administrator@winseliu /cygdrive/e/local/libs/big/tez-0.4.0-incubating/tez-dist/target
</span><span class='line'>$ hadoop dfs -put tez-0.4.0-incubating/tez-0.4.0-incubating/ hdfs://umcc97-44:9000/apps/ 
</span></code></pre></td></tr></table></div></figure>


<h3>配置集群环境</h3>

<p>首先看下原来集群的classpath路径，路径中已经包括了 <code>etc/hadoop</code> 目录，所以这里我直接把 <code>tez-site.xml</code> 放到该目录下。同时把tez-lib复制到 <code>share/hadoop/tez</code> 目录下，并添加到 <code>HADOOP_CLASSPATH</code> 环境变量。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-79 hadoop]$ hadoop classpath
</span><span class='line'>/home/hadoop/hadoop-2.2.0/etc/hadoop:/home/hadoop/hadoop-2.2.0/share/hadoop/common/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/common/*:/home/hadoop/hadoop-2.2.0/share/hadoop/hdfs:/home/hadoop/hadoop-2.2.0/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/hdfs/*:/home/hadoop/hadoop-2.2.0/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/yarn/*:/home/hadoop/hadoop-2.2.0/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/mapreduce/*:/home/hadoop/hadoop-2.2.0/contrib/capacity-scheduler/*.jar
</span><span class='line'>
</span><span class='line'># 用于map/reduce
</span><span class='line'>[hadoop@umcc97-79 hadoop]$ cat tez-site.xml 
</span><span class='line'>&lt;?xml version="1.0"?&gt;
</span><span class='line'>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
</span><span class='line'>
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;tez.lib.uris&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;${fs.default.name}/apps/tez-0.4.0-incubating,${fs.default.name}/apps/tez-0.4.0-incubating/lib/&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span><span class='line'>&lt;/configuration&gt;
</span><span class='line'>
</span><span class='line'>[hadoop@umcc97-79 hadoop]$ cd ~/hadoop-2.2.0/share/hadoop/tez/
</span><span class='line'>[hadoop@umcc97-79 tez]$ ll
</span><span class='line'>total 9616
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  303139 Jun 17 17:33 avro-1.7.4.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   41123 Jun 17 17:33 commons-cli-1.2.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  610259 Jun 17 17:33 commons-collections4-4.0.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 1648200 Jun 17 17:33 guava-11.0.2.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  710492 Jun 17 17:33 guice-3.0.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  656365 Jun 17 17:33 hadoop-mapreduce-client-common-2.2.0.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 1455001 Jun 17 17:33 hadoop-mapreduce-client-core-2.2.0.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   21537 Jun 17 17:33 hadoop-mapreduce-client-shuffle-2.2.0.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   81743 Jun 17 17:33 jettison-1.3.4.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  533455 Jun 17 17:33 protobuf-java-2.5.0.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  995968 Jun 17 17:33 snappy-java-1.0.4.1.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  749917 Jun 17 17:33 tez-api-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   34049 Jun 17 17:33 tez-common-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  970987 Jun 17 17:33 tez-dag-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  246409 Jun 17 17:33 tez-mapreduce-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  199934 Jun 17 17:33 tez-mapreduce-examples-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  114692 Jun 17 17:33 tez-runtime-internals-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  352177 Jun 17 17:33 tez-runtime-library-0.4.0-incubating.jar
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop    6845 Jun 17 17:33 tez-tests-0.4.0-incubating.jar
</span><span class='line'>
</span><span class='line'># MR配置，用于client任务提交
</span><span class='line'>[hadoop@umcc97-79 hadoop]$ grep HADOOP_CLASSPATH hadoop-env.sh
</span><span class='line'>export HADOOP_CLASSPATH=${HADOOP_HOME}/share/hadoop/tez/*:${HADOOP_HOME}/share/hadoop/tez/lib/*:$HADOOP_CLASSPATH
</span><span class='line'>
</span><span class='line'>[hadoop@umcc97-79 hadoop]$ sed -n 19,23p mapred-site.xml
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>&lt;property&gt;
</span><span class='line'>  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
</span><span class='line'>  &lt;value&gt;yarn-tez&lt;/value&gt;
</span><span class='line'>&lt;/property&gt;
</span></code></pre></td></tr></table></div></figure>


<h3>同步，重启yarn</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>for h in `cat hadoop-2.2.0/etc/hadoop/slaves ` ; do 
</span><span class='line'>  rsync -vaz --exclude=logs --exclude=pid --exclude=tmp  hadoop-2.2.0 $h:~/ ; 
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'># 同步到secondnamenode
</span><span class='line'>rsync -vaz --exclude=logs --exclude=pid --exclude=tmp  hadoop-2.2.0 umcc97-44:~/</span></code></pre></td></tr></table></div></figure>


<h3>测试</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-79 ~]$ hadoop classpath
</span><span class='line'>/home/hadoop/hadoop-2.2.0/etc/hadoop:/home/hadoop/hadoop-2.2.0/share/hadoop/common/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/common/*:/home/hadoop/hadoop-2.2.0/share/hadoop/hdfs:/home/hadoop/hadoop-2.2.0/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/hdfs/*:/home/hadoop/hadoop-2.2.0/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/yarn/*:/home/hadoop/hadoop-2.2.0/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop-2.2.0/share/hadoop/mapreduce/*:/home/hadoop/hadoop-2.2.0/share/hadoop/tez/*:/home/hadoop/hadoop-2.2.0/share/hadoop/tez/lib/*:/home/hadoop/hadoop-2.2.0/contrib/capacity-scheduler/*.jar
</span><span class='line'>
</span><span class='line'>[hadoop@umcc97-79 ~]$ cd hadoop-2.2.0/share/hadoop/mapreduce/
</span><span class='line'>[hadoop@umcc97-79 mapreduce]$ hadoop jar hadoop-mapreduce-client-jobclient-2.2.0-tests.jar sleep -mt 1 -rt 1 -m 1 -r 1
</span><span class='line'>
</span><span class='line'>cd hadoop-2.2.0/share/hadoop/tez/
</span><span class='line'>
</span><span class='line'>hadoop fs -put ~/hadoop-2.2.0/logs/yarn-hadoop-resourcemanager-umcc97-79.* /hello/in
</span><span class='line'>hadoop fs -rmr /hello/out
</span><span class='line'>hadoop jar tez-mapreduce-examples-0.4.0-incubating.jar orderedwordcount  /hello/in /hello/out
</span></code></pre></td></tr></table></div></figure>


<h3>回滚，使用时临时修改环境变量即可</h3>

<p>使用了tez后，导致hive-0.12.0不能运行。由于其他同事需要用hive，得把配置全部修改回去。【升级hive请查看<a href="/blog/2014/06/21/upgrade-hive/">hive-0.13中使用tez</a>】</p>

<p>在配置文件中配置为yarn，要使用tez在 <strong>提交任务</strong> 时指定配置参数即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export HADOOP_CLASSPATH=${HADOOP_HOME}/share/hadoop/tez/*:${HADOOP_HOME}/share/hadoop/tez/lib/*:$HADOOP_CLASSPATH
</span><span class='line'>hadoop jar hadoop-2.2.0/share/hadoop/tez/tez-mapreduce-examples-0.4.0-incubating.jar orderedwordcount \
</span><span class='line'>  -Dmapreduce.framework.name=yarn-tez  /hello/in /hello/out</span></code></pre></td></tr></table></div></figure>


<p>org.apache.tez.mapreduce.examples.OrderedWordCount不仅计算出了结果，同时按个数大小进行了排序。</p>

<p>问题： tez的任务的history还不知道怎么弄的，启动historyserver没作用？</p>

<p>0.6版本已经有ui了。</p>

<h3>持续更新</h3>

<p>本来想编译好tez-0.6就往hive-0.13上面放，没想到遇到钉子了！！hive-0.13不支持！！</p>

<p>在编译tez并想集成到hive，先下载hive的源码，看看pom.xml中使用的是到底是什么版本的tez，再编译tez不迟！！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>apache-hive-1.1.0-src.tar.gz/pom.xml
</span><span class='line'>    &lt;tez.version&gt;0.5.2&lt;/tez.version&gt;</span></code></pre></td></tr></table></div></figure>


<p>tez-0.6在hadoop-2.2基础上编译：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\opt\bigdata\apache-tez-0.6.0-src&gt;mvn  package -Dhadoop.version=2.2.0 -DskipTests -Dmaven.javadoc.skip=true -DskipATS
</span><span class='line'>
</span><span class='line'>vi tez-dist/pom.xml
</span><span class='line'>&lt;profile&gt;
</span><span class='line'>      &lt;id&gt;hadoop26&lt;/id&gt;
</span><span class='line'>      &lt;activation&gt;
</span><span class='line'>        &lt;activeByDefault&gt;false&lt;/activeByDefault&gt;
</span><span class='line'>      &lt;/activation&gt;</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/22/remote-debug-hadoop2/">远程调试hadoop2以及错误处理方法</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-22T06:47:48+08:00" pubdate data-updated="true">Tue 2014-04-22 06:47</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>了解程序运行过程，除了一行行代码的扫射源代码。更快捷的方式是运行调试源码，通过F6/F7来一步步的带领我们熟悉程序。针对特定细节具体数据，打个断点调试则是水到渠成的方式。</p>

<h2>Java远程调试</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> * JDK 1.3 or earlier -Xnoagent -Djava.compiler=NONE -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=6006
</span><span class='line'> * JDK 1.4(linux ok) -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=6006
</span><span class='line'> * newer JDK(win7 & jdk7) -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=6006</span></code></pre></td></tr></table></div></figure>


<h2>同一操作系统任务提交</h2>

<p>windows提交到windows，linux提交到linux，可以直接通过命令行添加参数调试wordcount任务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>E:\local\dotfile&gt;hdfs dfs -rmr /out # native-lib放在非path路径下，cmd脚本中有对其进行处理
</span><span class='line'>
</span><span class='line'>E:\local\dotfile&gt;hadoop org.apache.hadoop.examples.WordCount  "-Dmapreduce.map.java.opts=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8090 -Djava.library.path=E:\local\libs\big\hadoop-2.2.0\lib\native -Dmapreduce.reduce.java.opts=-Djava.library.path=E:\local\libs\big\hadoop-2.2.0\lib\native"  /in /out</span></code></pre></td></tr></table></div></figure>


<p><strong>suspend设置为y，会等待客户端连接再运行</strong>。在eclipse中在WordCount$TokenizerMapper#map打个断点，然后再使用<code>Remote Java Application</code>就可以调试程序了。</p>

<h2>Hadoop集群环境下调试任务</h2>

<p>hadoop有很多的程序，同样有对应的环境变量选项来进行设置！</p>

<ul>
<li>主程序-调试Job提交

<ul>
<li><code>set HADOOP_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8090"</code></li>
<li>可以在配置文件中进行设置。需要注意可能会覆盖已经设置的该参数的值。</li>
</ul>
</li>
<li>Nodemanager调试

<ul>
<li><code>set HADOOP_NODEMANAGER_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8092"</code></li>
<li>(linux下需要定义在文件中)<code>YARN_NODEMANAGER_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8092"</code></li>
</ul>
</li>
<li>ResourceManager调试

<ul>
<li>HADOOP_RESOURCEMANAGER_OPTS</li>
<li><code>export YARN_RESOURCEMANAGER_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8091"</code></li>
</ul>
</li>
</ul>


<p>Linux上的设置略有不同，通过SSH再调用的进程(如NodeManager)需要把其OPTS写到命令行脚本文件中！！
linux需要远程调试NodeManager的话，需要写到etc/hadoop/yarn-env.sh文件中！不然，nodemanger不生效（通过ssh去执行的）！</p>

<h3>其他调试技巧</h3>

<p>调试测试集群环境，比本地windows开发环境复杂点。毕竟本地windows的就一个主一个从。而把<strong>任务放到分布式集群</strong>上时，例如调试分布式缓存的！
那么就需要一些小技巧来获取任务运行所在的机器！下面的步骤中有具体操作命令。</p>

<h3>任务配置及运行</h3>

<p>eclipse下windows提交job到linux的补丁，查阅<a href="https://issues.apache.org/jira/browse/MAPREDUCE-5655">[MAPREDUCE-5655]</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 配置
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>      &lt;name&gt;mapred.remote.os&lt;/name&gt;
</span><span class='line'>      &lt;value&gt;Linux&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>      &lt;name&gt;mapreduce.job.jar&lt;/name&gt;
</span><span class='line'>      &lt;value&gt;dta-analyser-all.jar&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>      &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt;
</span><span class='line'>      &lt;value&gt;-Xmx1024m -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=18090&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>      &lt;name&gt;mapred.task.timeout&lt;/name&gt;
</span><span class='line'>      &lt;value&gt;1800000&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>
</span><span class='line'># 代码，map/reduce数都设置为1 
</span><span class='line'>job.setNumReduceTasks(1);
</span><span class='line'>job.getConfiguration().setInt(MRJobConfig.NUM_MAPS, 1);
</span></code></pre></td></tr></table></div></figure>


<p></p>

<ul>
<li>调试的时刻把超时时间设置的久一点，否则：</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> Got exception: java.net.SocketTimeoutException: Call From winseliu/127.0.0.1 to winse.com:2850 failed on socket timeout exception: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch :</span></code></pre></td></tr></table></div></figure>


<ul>
<li>调试main方法参数设置</li>
</ul>


<p>调试main（转瞬即逝的把suspend设置为true！），map的调试选项的语句写在配置文件里面</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export HADOOP_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8073"
</span><span class='line'>
</span><span class='line'>Administrator@winseliu ~/hadoop
</span><span class='line'>$ sh -x bin/hadoop org.apache.hadoop.examples.WordCount /in /out </span></code></pre></td></tr></table></div></figure>


<h3>遍历所有子节点，查找节点运行map程序的信息</h3>

<p>map调试的端口配置为18090，根据这个选项来查找程序运行的机器。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-44 ~]$ for h in `cat hadoop-2.2.0/etc/hadoop/slaves` ; do ssh $h 'ps aux|grep java | grep 18090'; echo $h;  done
</span><span class='line'>hadoop    8667  0.0  0.0  63888  1268 ?        Ss   18:21   0:00 bash -c ps aux|grep java | grep 18090
</span><span class='line'>umcc97-142
</span><span class='line'>hadoop   12686  0.0  0.0  63868  1260 ?        Ss   18:21   0:00 bash -c ps aux|grep java | grep 18090
</span><span class='line'>umcc97-143
</span><span class='line'>hadoop   23516  0.0  0.0  63856  1108 ?        Ss   18:11   0:00 /bin/bash -c /home/java/jdk1.7.0_45/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx256m -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=18090 -Djava.io.tmpdir=/home/hadoop/hadoop-2.2.0/tmp/nm-local-dir/usercache/hadoop/appcache/application_1397006359464_1605/container_1397006359464_1605_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1605/container_1397006359464_1605_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 10.18.97.143 57576 attempt_1397006359464_1605_m_000000_0 2 1&gt;/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1605/container_1397006359464_1605_01_000002/stdout 2&gt;/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1605/container_1397006359464_1605_01_000002/stderr 
</span><span class='line'>hadoop   23522  0.0  0.0 605136 15728 ?        Sl   18:11   0:00 /home/java/jdk1.7.0_45/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx256m -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=18090 -Djava.io.tmpdir=/home/hadoop/hadoop-2.2.0/tmp/nm-local-dir/usercache/hadoop/appcache/application_1397006359464_1605/container_1397006359464_1605_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1605/container_1397006359464_1605_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 10.18.97.143 57576 attempt_1397006359464_1605_m_000000_0 2
</span><span class='line'>hadoop   23665  0.0  0.0  63856  1264 ?        Ss   18:21   0:00 bash -c ps aux|grep java | grep 18090
</span><span class='line'>umcc97-144</span></code></pre></td></tr></table></div></figure>


<p>仅打印运行map的节点名称</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-44 ~]$ for h in `cat hadoop-2.2.0/etc/hadoop/slaves` ; do ssh $h 'if ps aux|grep -v grep | grep java | grep 18090 | grep -v bash 2&gt;&1 1&gt;/dev/null ; then echo `hostname`; fi'; done
</span><span class='line'>umcc97-142
</span><span class='line'>[hadoop@umcc97-44 ~]$ </span></code></pre></td></tr></table></div></figure>


<p>后面的操作就和普通的java程序调试步骤一样了。不再赘述。</p>

<h2>任务运行过程中的数据</h2>

<h4>辅助运行的两个bash程序</h4>

<p>运行的第一个程序（000001）为AppMaster，第二程序（000002）才是我们提交job的map任务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-143 ~]$ cd hadoop-2.2.0/tmp/nm-local-dir/nmPrivate
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ ls -Rl
</span><span class='line'>.:
</span><span class='line'>total 12
</span><span class='line'>drwxrwxr-x 4 hadoop hadoop 4096 Apr 21 18:34 application_1397006359464_1606
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop    6 Apr 21 18:34 container_1397006359464_1606_01_000001.pid
</span><span class='line'>-rw-rw-r-- 1 hadoop hadoop    6 Apr 21 18:34 container_1397006359464_1606_01_000002.pid
</span><span class='line'>
</span><span class='line'>./application_1397006359464_1606:
</span><span class='line'>total 8
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop 4096 Apr 21 18:34 container_1397006359464_1606_01_000001
</span><span class='line'>drwxrwxr-x 2 hadoop hadoop 4096 Apr 21 18:34 container_1397006359464_1606_01_000002
</span><span class='line'>
</span><span class='line'>./application_1397006359464_1606/container_1397006359464_1606_01_000001:
</span><span class='line'>total 8
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop   95 Apr 21 18:34 container_1397006359464_1606_01_000001.tokens
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 3121 Apr 21 18:34 launch_container.sh
</span><span class='line'>
</span><span class='line'>./application_1397006359464_1606/container_1397006359464_1606_01_000002:
</span><span class='line'>total 8
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  129 Apr 21 18:34 container_1397006359464_1606_01_000002.tokens
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop 3532 Apr 21 18:34 launch_container.sh
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ 
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ jps
</span><span class='line'>4692 NodeManager
</span><span class='line'>4173 DataNode
</span><span class='line'>13497 YarnChild
</span><span class='line'>7538 HRegionServer
</span><span class='line'>13376 MRAppMaster
</span><span class='line'>13574 Jps
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ cat *.pid
</span><span class='line'>13366
</span><span class='line'>13491
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ ps aux | grep 13366
</span><span class='line'>hadoop   13366  0.0  0.0  63868  1088 ?        Ss   18:34   0:00 /bin/bash -c /home/java/jdk1.7.0_45/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1606/container_1397006359464_1606_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1&gt;/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1606/container_1397006359464_1606_01_000001/stdout 2&gt;/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1606/container_1397006359464_1606_01_000001/stderr 
</span><span class='line'>hadoop   13594  0.0  0.0  61204   760 pts/2    S+   18:36   0:00 grep 13366
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ ps aux | grep 13491
</span><span class='line'>hadoop   13491  0.0  0.0  63868  1100 ?        Ss   18:34   0:00 /bin/bash -c /home/java/jdk1.7.0_45/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx256m -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=18090 -Djava.io.tmpdir=/home/hadoop/hadoop-2.2.0/tmp/nm-local-dir/usercache/hadoop/appcache/application_1397006359464_1606/container_1397006359464_1606_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1606/container_1397006359464_1606_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA org.apache.hadoop.mapred.YarnChild 10.18.97.143 52046 attempt_1397006359464_1606_m_000000_0 2 1&gt;/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1606/container_1397006359464_1606_01_000002/stdout 2&gt;/home/hadoop/hadoop-2.2.0/logs/userlogs/application_1397006359464_1606/container_1397006359464_1606_01_000002/stderr 
</span><span class='line'>hadoop   13599  0.0  0.0  61204   760 pts/2    S+   18:37   0:00 grep 13491
</span><span class='line'>[hadoop@umcc97-143 nmPrivate]$ </span></code></pre></td></tr></table></div></figure>


<h4>程序运行本地缓存数据</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@umcc97-143 container_1397006359464_1606_01_000002]$ ls -l
</span><span class='line'>total 28
</span><span class='line'>-rw-r--r-- 1 hadoop hadoop  129 Apr 21 18:34 container_tokens
</span><span class='line'>-rwx------ 1 hadoop hadoop  516 Apr 21 18:34 default_container_executor.sh
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop   65 Apr 21 18:34 filter.io -&gt; /home/hadoop/hadoop-2.2.0/tmp/nm-local-dir/filecache/10/filter.io
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop  120 Apr 21 18:34 job.jar -&gt; /home/hadoop/hadoop-2.2.0/tmp/nm-local-dir/usercache/hadoop/appcache/application_1397006359464_1606/filecache/10/job.jar
</span><span class='line'>lrwxrwxrwx 1 hadoop hadoop  120 Apr 21 18:34 job.xml -&gt; /home/hadoop/hadoop-2.2.0/tmp/nm-local-dir/usercache/hadoop/appcache/application_1397006359464_1606/filecache/13/job.xml
</span><span class='line'>-rwx------ 1 hadoop hadoop 3532 Apr 21 18:34 launch_container.sh
</span><span class='line'>drwx--x--- 2 hadoop hadoop 4096 Apr 21 18:34 tmp
</span><span class='line'>[hadoop@umcc97-143 container_1397006359464_1606_01_000002]$ </span></code></pre></td></tr></table></div></figure>


<h2>处理问题方法</h2>

<ul>
<li>打印DEBUG日志：<code>export HADOOP_ROOT_LOGGER=DEBUG,console</code>

<ul>
<li>日志文件放置在nodemanager节点的logs/userlogs目录下。</li>
</ul>
</li>
<li>打印DEBUG日志也搞不定时，可以在源码里面sysout信息然后把<strong>class覆盖</strong>，来进行定位配置的问题。</li>
<li>如果不清楚shell的执行过程，可以通过<code>sh -x [CMD]</code>，或者在脚本文件的操作前加上<code>set -x</code>。相当于windows-batch的<code>echo on</code>功能。</li>
</ul>


<h2>参考</h2>

<ul>
<li><a href="http://stackoverflow.com/questions/975271/remote-debugging-a-java-application">remote debugger opts</a></li>
</ul>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/18">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/16">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2016/03/28/hive-on-spark/">Hive on Spark</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/">安装配置Ganglia(2)</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/">Hadoop安装与升级-(3)HA配置</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/">Hadoop安装与升级-Docker中安装(1)</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/03/08/vmware-build-hadoop2-dot-6/">VMware-Centos6 Build hadoop-2.6</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/10/16/spark-build-and-configuration/">编译/搭建Spark环境</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/09/30/docker-ssh-on-centos/">配置ssh登录docker-centos</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/09/17/windows-hadoop2-test-your-mapreduce-feature/">在windows开发测试mapreduce几种方式</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/08/25/step-by-step-found-java-oom-error/">查找逐步定位Java程序OOM的异常实践</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/27/start-redis/">[读读书]Redis入门指南</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/18/jekyll-edit-link-in-web-page/">Jekyll页面添加编辑按钮</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/04/15/alluxio-quickstart2/">Alluxio入门大全2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/13/hiveserver2-ui-and-upgrade-hive2-dot-0-0/">Hiveserver2 Ui and Upgrade hive2.0.0</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/11/spark-on-yarn-memory-allocate/">Spark-on-yarn内存分配</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/08/snappy-centos5-on-hive-on-spark/">Hive-on-spark Snappy on Centos5</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/08/puppet-install/">puppet4.4.1入门安装</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/08/dbcp-parameters/">DBCP参数在Hive JDBC上的实践</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/04/rpm-build-your-package/">RPM打包</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/03/29/parquet-simple-view/">Parquet学习</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (40) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (15) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (33) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (123)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Softs, I&#8217;m using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1253461959'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/z_stat.php%3Fid%3D1253461959%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'winseliu';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
