
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>AIGC Setup on Win11 WSL2 - Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="看 Yi官方文档，一开始摸不着头脑，不知道从哪里入手。 网上找了一些资料，查到了苏洋的博客，先把环境搭建起来。 基于 Docker 的深度学习环境：Windows
使用 Docker 快速上手 Stability AI 的 SDXL 1.0 正式版-Linux 为了在 Windows11 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winse.github.io/blog/2024/01/15/aigc-setup-on-windows-wsl-2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/libs/jquery.toc.min.js" type="text/javascript"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->

<script src="/javascripts/generate-toc.js" type="text/javascript"></script>


  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D3G1YVNBK4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-D3G1YVNBK4');
</script>

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停都是风景, 熙熙攘攘都向最好, 忙忙碌碌都为明朝, 何畏之.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winse.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives/">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
  <li><a href="/tool/">Tools</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">AIGC Setup on Win11 WSL2</h1>
    
    
      <p class="meta">
        








  


<time datetime="2024-01-15T01:25:22+08:00" pubdate data-updated="true">Mon 2024-01-15 01:25</time>
		
        
		
      </p>
    
  </header>



<div class="toc-icon">
	<svg viewBox="0 0 20 20" enable-background="new 0 0 20 20" xml:space="preserve" style="width: 20px;">
		<g>
			<path fill-rule="evenodd" clip-rule="evenodd" d="M2,15c-1.1,0-2,0.9-2,2c0,1.1,0.9,2,2,2s2-0.9,2-2C4,15.9,3.1,15,2,15z M2,8
				c-1.1,0-2,0.9-2,2c0,1.1,0.9,2,2,2s2-0.9,2-2C4,8.9,3.1,8,2,8z M7,4h12c0.55,0,1-0.45,1-1c0-0.55-0.45-1-1-1H7C6.45,2,6,2.45,6,3
				C6,3.55,6.45,4,7,4z M2,1C0.9,1,0,1.9,0,3c0,1.1,0.9,2,2,2s2-0.9,2-2C4,1.9,3.1,1,2,1z M19,9H7c-0.55,0-1,0.45-1,1
				c0,0.55,0.45,1,1,1h12c0.55,0,1-0.45,1-1C20,9.45,19.55,9,19,9z M19,16H7c-0.55,0-1,0.45-1,1c0,0.55,0.45,1,1,1h12
				c0.55,0,1-0.45,1-1C20,16.45,19.55,16,19,16z"></path>
		</g>
	</svg>
</div>
<div class="entry-content"><p>看 <a href="https://github.com/01-ai/Yi">Yi</a>官方文档，一开始摸不着头脑，不知道从哪里入手。 网上找了一些资料，查到了苏洋的博客，先把环境搭建起来。</p>

<ul>
<li><a href="https://soulteary.com/2023/07/29/docker-based-deep-learning-environment-under-windows.html">基于 Docker 的深度学习环境：Windows</a></li>
<li><a href="https://soulteary.com/2023/07/29/get-started-with-stability-ai-sdxl-1-0-release-using-docker.html">使用 Docker 快速上手 Stability AI 的 SDXL 1.0 正式版-Linux</a></li>
</ul>


<p>为了在 Windows11 机器方便使用GPU，以及开源很多工程都提供docker入门，但WSL2慢，考虑本地已经搞了一个WSL1了会不会冲突，同时虚拟机里面也安装不了WSL2，VMWare桌面虚拟机的话直接使用GPU没有很好的方式等等，纠结了一天，最终还是选了安装 WSL2+Docker Desktop。</p>

<p>跟着文章，你将会了解Windows+WLS2+Docker怎么跑GPU模型，以及在国内怎么下载模型文件。</p>

<h2>使用WSL2</h2>

<p>在 启用或关闭Windows功能 中选择 虚拟机平台。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wsl --update
</span><span class='line'>wsl --set-default-version 2</span></code></pre></td></tr></table></div></figure>


<p>然后在微软商店Microsoft Store里面安装 <strong>Ubuntu-20.04</strong> （版本选20或者22）的系统（通过应用商店的话就规避了可能安装同一个的Linux的问题：已经安装 在应用商店的按钮不是[获取]是[打开]）。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:~$ cat /etc/os-release
</span><span class='line'>NAME="Ubuntu"
</span><span class='line'>VERSION="20.04.6 LTS (Focal Fossa)"
</span><span class='line'>ID=ubuntu
</span><span class='line'>ID_LIKE=debian
</span><span class='line'>PRETTY_NAME="Ubuntu 20.04.6 LTS"
</span><span class='line'>VERSION_ID="20.04"
</span><span class='line'>HOME_URL="https://www.ubuntu.com/"
</span><span class='line'>SUPPORT_URL="https://help.ubuntu.com/"
</span><span class='line'>BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
</span><span class='line'>PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
</span><span class='line'>VERSION_CODENAME=focal
</span><span class='line'>UBUNTU_CODENAME=focal
</span><span class='line'>
</span><span class='line'>winse@DESKTOP-BR4MG38:~$ uname -a
</span><span class='line'>Linux DESKTOP-BR4MG38 5.15.133.1-microsoft-standard-WSL2 #1 SMP Thu Oct 5 21:02:42 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux</span></code></pre></td></tr></table></div></figure>


<p>对比WSL1，WSL2的 <code>ip a</code> ，WSL2还是干净很多，把宿主机的一些信息合并到linux里面了（如：hosts）。</p>

<h2>Docker Desktop + WSL2</h2>

<ul>
<li><p><a href="https://docs.docker.com/desktop/install/windows-install/">https://docs.docker.com/desktop/install/windows-install/</a></p></li>
<li><p>微软的安装内容讲的差不多，增加了使用vscode的内容
<a href="https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers#develop-in-remote-containers-using-vs-code">https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers#develop-in-remote-containers-using-vs-code</a></p></li>
</ul>


<p>通过exe安装，安装过程中选择使用WSL2，装好后wsl显示多出了两个linux。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>C:\Users\P15&gt;wsl -l -v
</span><span class='line'>  NAME                   STATE           VERSION
</span><span class='line'>* Ubuntu                 Stopped         1
</span><span class='line'>  Ubuntu-20.04           Running         2
</span><span class='line'>  docker-desktop-data    Running         2
</span><span class='line'>  docker-desktop         Running         2</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:~$ su -
</span><span class='line'>root@DESKTOP-BR4MG38:~# echo "winse ALL=(ALL:ALL) NOPASSWD: ALL" &gt;&gt;/etc/sudoers
</span><span class='line'>
</span><span class='line'>root@DESKTOP-BR4MG38:~# sed -i.bak -e 's|archive.ubuntu.com/ubuntu/|mirrors.aliyun.com/ubuntu/|' -e 's|security.ubuntu.com/ubuntu/|mirrors.aliyun.com/ubuntu/|' /etc/apt/sources.list
</span></code></pre></td></tr></table></div></figure>


<p>在 WSL-Ubuntu 里面可以直接用 Win11 的程序，直接查看docker的信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:~$ docker version
</span><span class='line'>Client: Docker Engine - Community
</span><span class='line'> Cloud integration: v1.0.35+desktop.5
</span><span class='line'> Version:           24.0.7
</span><span class='line'> API version:       1.43
</span><span class='line'> Go version:        go1.20.10
</span><span class='line'> Git commit:        afdd53b
</span><span class='line'> Built:             Thu Oct 26 09:08:17 2023
</span><span class='line'> OS/Arch:           linux/amd64
</span><span class='line'> Context:           default
</span><span class='line'>
</span><span class='line'>Server: Docker Desktop
</span><span class='line'> Engine:
</span><span class='line'>  Version:          24.0.7
</span><span class='line'>  API version:      1.43 (minimum version 1.12)
</span><span class='line'>  Go version:       go1.20.10
</span><span class='line'>  Git commit:       311b9ff
</span><span class='line'>  Built:            Thu Oct 26 09:08:02 2023
</span><span class='line'>  OS/Arch:          linux/amd64
</span><span class='line'>  Experimental:     false
</span><span class='line'> containerd:
</span><span class='line'>  Version:          1.6.25
</span><span class='line'>  GitCommit:        d8f198a4ed8892c764191ef7b3b06d8a2eeb5c7f
</span><span class='line'> runc:
</span><span class='line'>  Version:          1.1.10
</span><span class='line'>  GitCommit:        v1.1.10-0-g18a0cb0
</span><span class='line'> docker-init:
</span><span class='line'>  Version:          0.19.0
</span><span class='line'>  GitCommit:        de40ad0
</span><span class='line'>  
</span><span class='line'>winse@DESKTOP-BR4MG38:~$ which docker
</span><span class='line'>/usr/bin/docker
</span><span class='line'>winse@DESKTOP-BR4MG38:~$ ll  /usr/bin/docker
</span><span class='line'>lrwxrwxrwx 1 root root 48 Jan 13 11:03 /usr/bin/docker -&gt; /mnt/wsl/docker-desktop/cli-tools/usr/bin/docker*
</span></code></pre></td></tr></table></div></figure>


<p>其实用的就是windows的docker</p>

<p><img src="/images/blogs/ai/wsl2-docker-cli.png" alt="" /></p>

<p>镜像加速</p>

<p><img src="/images/blogs/ai/docker-mirror.png" alt="" /></p>

<p>保存会重启docker，再查看docker的信息，确认Registry Mirrors：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:~$ docker info
</span><span class='line'>Client: Docker Engine - Community
</span><span class='line'> Version:    24.0.7
</span><span class='line'> Context:    default
</span><span class='line'> Debug Mode: false
</span><span class='line'> Plugins:
</span><span class='line'>  buildx: Docker Buildx (Docker Inc.)
</span><span class='line'>    Version:  v0.12.0-desktop.2
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-buildx
</span><span class='line'>  compose: Docker Compose (Docker Inc.)
</span><span class='line'>    Version:  v2.23.3-desktop.2
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-compose
</span><span class='line'>  dev: Docker Dev Environments (Docker Inc.)
</span><span class='line'>    Version:  v0.1.0
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-dev
</span><span class='line'>  extension: Manages Docker extensions (Docker Inc.)
</span><span class='line'>    Version:  v0.2.21
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-extension
</span><span class='line'>  feedback: Provide feedback, right in your terminal! (Docker Inc.)
</span><span class='line'>    Version:  0.1
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-feedback
</span><span class='line'>  init: Creates Docker-related starter files for your project (Docker Inc.)
</span><span class='line'>    Version:  v0.1.0-beta.10
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-init
</span><span class='line'>  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc.)
</span><span class='line'>    Version:  0.6.0
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-sbom
</span><span class='line'>  scan: Docker Scan (Docker Inc.)
</span><span class='line'>    Version:  v0.26.0
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-scan
</span><span class='line'>  scout: Docker Scout (Docker Inc.)
</span><span class='line'>    Version:  v1.2.0
</span><span class='line'>    Path:     /usr/local/lib/docker/cli-plugins/docker-scout
</span><span class='line'>
</span><span class='line'>Server:
</span><span class='line'> Containers: 1
</span><span class='line'>  Running: 1
</span><span class='line'>  Paused: 0
</span><span class='line'>  Stopped: 0
</span><span class='line'> Images: 5
</span><span class='line'> Server Version: 24.0.7
</span><span class='line'> Storage Driver: overlay2
</span><span class='line'>  Backing Filesystem: extfs
</span><span class='line'>  Supports d_type: true
</span><span class='line'>  Using metacopy: false
</span><span class='line'>  Native Overlay Diff: true
</span><span class='line'>  userxattr: false
</span><span class='line'> Logging Driver: json-file
</span><span class='line'> Cgroup Driver: cgroupfs
</span><span class='line'> Cgroup Version: 1
</span><span class='line'> Plugins:
</span><span class='line'>  Volume: local
</span><span class='line'>  Network: bridge host ipvlan macvlan null overlay
</span><span class='line'>  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
</span><span class='line'> Swarm: inactive
</span><span class='line'> Runtimes: io.containerd.runc.v2 runc
</span><span class='line'> Default Runtime: runc
</span><span class='line'> Init Binary: docker-init
</span><span class='line'> containerd version: d8f198a4ed8892c764191ef7b3b06d8a2eeb5c7f
</span><span class='line'> runc version: v1.1.10-0-g18a0cb0
</span><span class='line'> init version: de40ad0
</span><span class='line'> Security Options:
</span><span class='line'>  seccomp
</span><span class='line'>   Profile: unconfined
</span><span class='line'> Kernel Version: 5.15.133.1-microsoft-standard-WSL2
</span><span class='line'> Operating System: Docker Desktop
</span><span class='line'> OSType: linux
</span><span class='line'> Architecture: x86_64
</span><span class='line'> CPUs: 16
</span><span class='line'> Total Memory: 31.26GiB
</span><span class='line'> Name: docker-desktop
</span><span class='line'> ID: 340fee1c-e22a-485c-a973-f0e26d7535c9
</span><span class='line'> Docker Root Dir: /var/lib/docker
</span><span class='line'> Debug Mode: false
</span><span class='line'> HTTP Proxy: http.docker.internal:3128
</span><span class='line'> HTTPS Proxy: http.docker.internal:3128
</span><span class='line'> No Proxy: hubproxy.docker.internal
</span><span class='line'> Experimental: false
</span><span class='line'> Insecure Registries:
</span><span class='line'>  hubproxy.docker.internal:5555
</span><span class='line'>  127.0.0.0/8
</span><span class='line'> Registry Mirrors:
</span><span class='line'>  https://us69kjun.mirror.aliyuncs.com/
</span><span class='line'>  https://docker.mirrors.ustc.edu.cn/
</span><span class='line'>  https://hub-mirror.c.163.com/
</span><span class='line'>  https://mirror.baidubce.com/
</span><span class='line'> Live Restore Enabled: false
</span><span class='line'>
</span><span class='line'>WARNING: No blkio throttle.read_bps_device support
</span><span class='line'>WARNING: No blkio throttle.write_bps_device support
</span><span class='line'>WARNING: No blkio throttle.read_iops_device support
</span><span class='line'>WARNING: No blkio throttle.write_iops_device support
</span><span class='line'>WARNING: daemon is not using the default seccomp profile</span></code></pre></td></tr></table></div></figure>


<h2>GPU</h2>

<h3>Driver</h3>

<p>根据Win11机器的显卡安装最新版本驱动（不要在WSL中安装任何Linux版的Nvidia驱动！）</p>

<p><a href="https://www.nvidia.com/Download/index.aspx">https://www.nvidia.com/Download/index.aspx</a></p>

<p>输入nvidia-smi，查验是否安装成功。WSL2里面啥都不用做，在WSL2命令行直接就能查看nvidia-smi。</p>

<p>启动docker也能一样查看</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:stable-diffusion-taiyi$ docker run -it --rm --gpus all ubuntu nvidia-smi
</span></code></pre></td></tr></table></div></figure>


<p>其实这个启动的container也是一个WSL2。注意：WSL中不需要安装任何Linux版的Nvidia驱动！</p>

<p>验证 WLS2中Docker跑起来的容器 是否能够正常调用GPU：</p>

<ul>
<li><a href="https://soulteary.com/2023/07/29/docker-based-deep-learning-environment-under-windows.html">https://soulteary.com/2023/07/29/docker-based-deep-learning-environment-under-windows.html</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:~$ docker pull nvcr.io/nvidia/pytorch:23.07-py3
</span><span class='line'>23.07-py3: Pulling from nvidia/pytorch
</span><span class='line'>3153aa388d02: Pulling fs layer
</span><span class='line'>...
</span><span class='line'>ee3f0ae6e80f: Pull complete
</span><span class='line'>d4528227b5b8: Pull complete
</span><span class='line'>Digest: sha256:c53e8702a4ccb3f55235226dab29ef5d931a2a6d4d003ab47ca2e7e670f7922b
</span><span class='line'>Status: Downloaded newer image for nvcr.io/nvidia/pytorch:23.07-py3
</span><span class='line'>nvcr.io/nvidia/pytorch:23.07-py3
</span><span class='line'>
</span><span class='line'>What's Next?
</span><span class='line'>  1. Sign in to your Docker account → docker login
</span><span class='line'>  2. View a summary of image vulnerabilities and recommendations → docker scout quickview nvcr.io/nvidia/pytorch:23.07-py3
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>winse@DESKTOP-BR4MG38:~$ docker run -it --gpus=all --rm nvcr.io/nvidia/pytorch:23.07-py3 nvidia-smi
</span><span class='line'>
</span><span class='line'>=============
</span><span class='line'>== PyTorch ==
</span><span class='line'>=============
</span><span class='line'>
</span><span class='line'>NVIDIA Release 23.07 (build 63867923)
</span><span class='line'>PyTorch Version 2.1.0a0+b5021ba
</span><span class='line'>
</span><span class='line'>Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
</span><span class='line'>
</span><span class='line'>Copyright (c) 2014-2023 Facebook Inc.
</span><span class='line'>Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
</span><span class='line'>Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
</span><span class='line'>Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
</span><span class='line'>Copyright (c) 2011-2013 NYU                      (Clement Farabet)
</span><span class='line'>Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
</span><span class='line'>Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
</span><span class='line'>Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
</span><span class='line'>Copyright (c) 2015      Google Inc.
</span><span class='line'>Copyright (c) 2015      Yangqing Jia
</span><span class='line'>Copyright (c) 2013-2016 The Caffe contributors
</span><span class='line'>All rights reserved.
</span><span class='line'>
</span><span class='line'>Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
</span><span class='line'>
</span><span class='line'>This container image and its contents are governed by the NVIDIA Deep Learning Container License.
</span><span class='line'>By pulling and using the container, you accept the terms and conditions of this license:
</span><span class='line'>https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
</span><span class='line'>
</span><span class='line'>NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be
</span><span class='line'>   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:
</span><span class='line'>   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...
</span><span class='line'>
</span><span class='line'>Sat Jan 13 14:01:37 2024
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| NVIDIA-SMI 535.146.01             Driver Version: 537.99       CUDA Version: 12.2     |
</span><span class='line'>|-----------------------------------------+----------------------+----------------------+
</span><span class='line'>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
</span><span class='line'>| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
</span><span class='line'>|                                         |                      |               MIG M. |
</span><span class='line'>|=========================================+======================+======================|
</span><span class='line'>|   0  Quadro T2000                   On  | 00000000:01:00.0  On |                  N/A |
</span><span class='line'>| N/A   43C    P8               6W /  60W |    856MiB /  4096MiB |      9%      Default |
</span><span class='line'>|                                         |                      |                  N/A |
</span><span class='line'>+-----------------------------------------+----------------------+----------------------+
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| Processes:                                                                            |
</span><span class='line'>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
</span><span class='line'>|        ID   ID                                                             Usage      |
</span><span class='line'>|=======================================================================================|
</span><span class='line'>|    0   N/A  N/A        27      G   /Xwayland                                 N/A      |
</span><span class='line'>|    0   N/A  N/A        41      G   /Xwayland                                 N/A      |
</span><span class='line'>|    0   N/A  N/A        42      G   /Xwayland                                 N/A      |
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>winse@DESKTOP-BR4MG38:~$ docker run --rm --gpus all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark
</span><span class='line'>Unable to find image 'nvcr.io/nvidia/k8s/cuda-sample:nbody' locally
</span><span class='line'>nbody: Pulling from nvidia/k8s/cuda-sample
</span><span class='line'>22c5ef60a68e: Pull complete
</span><span class='line'>1939e4248814: Pull complete
</span><span class='line'>548afb82c856: Pull complete
</span><span class='line'>a424d45fd86f: Pull complete
</span><span class='line'>207b64ab7ce6: Pull complete
</span><span class='line'>f65423f1b49b: Pull complete
</span><span class='line'>2b60900a3ea5: Pull complete
</span><span class='line'>e9bff09d04df: Pull complete
</span><span class='line'>edc14edf1b04: Pull complete
</span><span class='line'>1f37f461c076: Pull complete
</span><span class='line'>9026fb14bf88: Pull complete
</span><span class='line'>Digest: sha256:59261e419d6d48a772aad5bb213f9f1588fcdb042b115ceb7166c89a51f03363
</span><span class='line'>Status: Downloaded newer image for nvcr.io/nvidia/k8s/cuda-sample:nbody
</span><span class='line'>Run "nbody -benchmark [-numbodies=&lt;numBodies&gt;]" to measure performance.
</span><span class='line'>        -fullscreen       (run n-body simulation in fullscreen mode)
</span><span class='line'>        -fp64             (use double precision floating point values for simulation)
</span><span class='line'>        -hostmem          (stores simulation data in host memory)
</span><span class='line'>        -benchmark        (run benchmark to measure performance)
</span><span class='line'>        -numbodies=&lt;N&gt;    (number of bodies (&gt;= 1) to run in simulation)
</span><span class='line'>        -device=&lt;d&gt;       (where d=0,1,2.... for the CUDA device to use)
</span><span class='line'>        -numdevices=&lt;i&gt;   (where i=(number of CUDA devices &gt; 0) to use for simulation)
</span><span class='line'>        -compare          (compares simulation results running once on the default GPU and once on the CPU)
</span><span class='line'>        -cpu              (run n-body simulation on the CPU)
</span><span class='line'>        -tipsy=&lt;file.bin&gt; (load a tipsy model file for simulation)
</span><span class='line'>
</span><span class='line'>NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</span><span class='line'>
</span><span class='line'>&gt; Windowed mode
</span><span class='line'>&gt; Simulation data stored in video memory
</span><span class='line'>&gt; Single precision floating point simulation
</span><span class='line'>&gt; 1 Devices used for simulation
</span><span class='line'>GPU Device 0: "Turing" with compute capability 7.5
</span><span class='line'>
</span><span class='line'>&gt; Compute 7.5 CUDA device: [Quadro T2000]
</span><span class='line'>16384 bodies, total time for 10 iterations: 64.071 ms
</span><span class='line'>= 41.897 billion interactions per second
</span><span class='line'>= 837.937 single-precision GFLOP/s at 20 flops per interaction
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#再跑一遍
</span><span class='line'>winse@DESKTOP-BR4MG38:~$ docker run --rm --gpus all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark
</span><span class='line'>Run "nbody -benchmark [-numbodies=&lt;numBodies&gt;]" to measure performance.
</span><span class='line'>        -fullscreen       (run n-body simulation in fullscreen mode)
</span><span class='line'>        -fp64             (use double precision floating point values for simulation)
</span><span class='line'>        -hostmem          (stores simulation data in host memory)
</span><span class='line'>        -benchmark        (run benchmark to measure performance)
</span><span class='line'>        -numbodies=&lt;N&gt;    (number of bodies (&gt;= 1) to run in simulation)
</span><span class='line'>        -device=&lt;d&gt;       (where d=0,1,2.... for the CUDA device to use)
</span><span class='line'>        -numdevices=&lt;i&gt;   (where i=(number of CUDA devices &gt; 0) to use for simulation)
</span><span class='line'>        -compare          (compares simulation results running once on the default GPU and once on the CPU)
</span><span class='line'>        -cpu              (run n-body simulation on the CPU)
</span><span class='line'>        -tipsy=&lt;file.bin&gt; (load a tipsy model file for simulation)
</span><span class='line'>
</span><span class='line'>NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</span><span class='line'>
</span><span class='line'>&gt; Windowed mode
</span><span class='line'>&gt; Simulation data stored in video memory
</span><span class='line'>&gt; Single precision floating point simulation
</span><span class='line'>&gt; 1 Devices used for simulation
</span><span class='line'>GPU Device 0: "Turing" with compute capability 7.5
</span><span class='line'>
</span><span class='line'>&gt; Compute 7.5 CUDA device: [Quadro T2000]
</span><span class='line'>16384 bodies, total time for 10 iterations: 23.398 ms
</span><span class='line'>= 114.724 billion interactions per second
</span><span class='line'>= 2294.490 single-precision GFLOP/s at 20 flops per interaction
</span></code></pre></td></tr></table></div></figure>


<h3>WSL2 cuda-toolkit</h3>

<p>开发环境/运行环境
* <a href="https://zhuanlan.zhihu.com/p/555151725">https://zhuanlan.zhihu.com/p/555151725</a>
* <a href="https://docs.nvidia.com/cuda/wsl-user-guide/index.html#cuda-support-for-WSL2">https://docs.nvidia.com/cuda/wsl-user-guide/index.html#cuda-support-for-WSL2</a>
* <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=WSL-Ubuntu&amp;target_version=2.0&amp;target_type=deb_network">https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=WSL-Ubuntu&amp;target_version=2.0&amp;target_type=deb_network</a></p>

<p><img src="/images/blogs/ai/wsl2-cuda.png" alt="" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
</span><span class='line'>sudo dpkg -i cuda-keyring_1.1-1_all.deb
</span><span class='line'>sudo apt-get update
</span><span class='line'>sudo apt-get -y install cuda-toolkit-12-3</span></code></pre></td></tr></table></div></figure>


<p>运行安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>(demo_env) winse@DESKTOP-BR4MG38:ai$ wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
</span><span class='line'>--2024-01-14 23:53:22--  https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
</span><span class='line'>Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144, 72.21.80.5, 72.21.80.6, ...
</span><span class='line'>Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.
</span><span class='line'>HTTP request sent, awaiting response... 301 Moved Permanently
</span><span class='line'>Location: https://developer.download.nvidia.cn/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb [following]
</span><span class='line'>--2024-01-14 23:53:23--  https://developer.download.nvidia.cn/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
</span><span class='line'>Resolving developer.download.nvidia.cn (developer.download.nvidia.cn)... 59.36.216.26, 59.36.216.27, 175.4.58.180, ...
</span><span class='line'>Connecting to developer.download.nvidia.cn (developer.download.nvidia.cn)|59.36.216.26|:443... connected.
</span><span class='line'>HTTP request sent, awaiting response... 200 OK
</span><span class='line'>Length: 4328 (4.2K) [application/x-deb]
</span><span class='line'>Saving to: ‘cuda-keyring_1.1-1_all.deb’
</span><span class='line'>
</span><span class='line'>cuda-keyring_1.1-1_all.deb      100%[====================================================&gt;]   4.23K  --.-KB/s    in 0s
</span><span class='line'>
</span><span class='line'>2024-01-14 23:53:23 (1.61 GB/s) - ‘cuda-keyring_1.1-1_all.deb’ saved [4328/4328]
</span><span class='line'>
</span><span class='line'>(demo_env) winse@DESKTOP-BR4MG38:ai$
</span><span class='line'>(demo_env) winse@DESKTOP-BR4MG38:ai$ sudo dpkg -i cuda-keyring_1.1-1_all.deb
</span><span class='line'>(demo_env) winse@DESKTOP-BR4MG38:ai$ sudo apt-get update
</span><span class='line'>(demo_env) winse@DESKTOP-BR4MG38:ai$ sudo apt-get -y install cuda-toolkit-12-3
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:~$ vi .bashrc
</span><span class='line'>
</span><span class='line'>export PATH=/usr/local/cuda/bin:$PATH
</span></code></pre></td></tr></table></div></figure>


<p>新打开一个shell：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:~$ nvcc -V
</span><span class='line'>nvcc: NVIDIA (R) Cuda compiler driver
</span><span class='line'>Copyright (c) 2005-2023 NVIDIA Corporation
</span><span class='line'>Built on Wed_Nov_22_10:17:15_PST_2023
</span><span class='line'>Cuda compilation tools, release 12.3, V12.3.107
</span><span class='line'>Build cuda_12.3.r12.3/compiler.33567101_0</span></code></pre></td></tr></table></div></figure>


<h3>cuDNN</h3>

<p><a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></p>

<p>NVIDIA CUDA® Deep Neural Network library 支持神经网络的推理。</p>

<p>注册下载对应CUDA的版本 <a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p>

<p>注意：如果不在WSL2-Ubuntu中直接使用cuDNN，后续通过容器直接拉取包含cuDNN的容器，就可以省略这一部分。</p>

<p><a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux-deb">https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux-deb</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#sudo dpkg -i cudnn-local-repo-ubuntu2004-8.9.6.50_1.0-1_amd64.deb
</span><span class='line'>#sudo dpkg -r cudnn-local-repo-ubuntu2004-8.9.6.50
</span><span class='line'>#sudo rm /etc/apt/sources.list.d/cudnn-local-ubuntu2004-8.9.6.50.list
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ sudo dpkg -i cudnn-local-repo-ubuntu2004-8.9.7.29_1.0-1_amd64.deb
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ sudo cp /var/cudnn-local-repo-ubuntu2004-8.9.7.29/cudnn-local-30472A84-keyring.gpg /usr/share/keyrings/
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ sudo apt install zlib1g
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ sudo apt update
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ apt search libcudnn8
</span><span class='line'>Sorting... Done
</span><span class='line'>Full Text Search... Done
</span><span class='line'>libcudnn8/unknown 8.9.7.29-1+cuda12.2 amd64
</span><span class='line'>  cuDNN runtime libraries
</span><span class='line'>
</span><span class='line'>libcudnn8-dev/unknown 8.9.7.29-1+cuda12.2 amd64
</span><span class='line'>  cuDNN development libraries and headers
</span><span class='line'>
</span><span class='line'>libcudnn8-samples/unknown 8.9.7.29-1+cuda12.2 amd64
</span><span class='line'>  cuDNN samples
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ sudo apt install libcudnn8 libcudnn8-dev libcudnn8-samples
</span></code></pre></td></tr></table></div></figure>


<p>校验是否安装成功</p>

<p><a href="https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#verify">https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#verify</a></p>

<p>运行报错参考 <a href="https://forums.developer.nvidia.com/t/freeimage-is-not-set-up-correctly-please-ensure-freeimae-is-set-up-correctly/66950">https://forums.developer.nvidia.com/t/freeimage-is-not-set-up-correctly-please-ensure-freeimae-is-set-up-correctly/66950</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ cp -r /usr/src/cudnn_samples_v8 ./
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:i$ cd cudnn_samples_v8/mnistCUDNN/
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:mnistCUDNN$
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:mnistCUDNN$ sudo apt-get install libfreeimage3 libfreeimage-dev
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:mnistCUDNN$ make clean && make
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:mnistCUDNN$ ./mnistCUDNN
</span><span class='line'>Executing: mnistCUDNN
</span><span class='line'>cudnnGetVersion() : 8907 , CUDNN_VERSION from cudnn.h : 8907 (8.9.7)
</span><span class='line'>Host compiler version : GCC 9.4.0
</span><span class='line'>
</span><span class='line'>There are 1 CUDA capable devices on your machine :
</span><span class='line'>device 0 : sms 16  Capabilities 7.5, SmClock 1785.0 Mhz, MemSize (Mb) 4095, MemClock 6001.0 Mhz, Ecc=0, boardGroupID=0
</span><span class='line'>Using device 0
</span><span class='line'>
</span><span class='line'>Testing single precision
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>Result of classification: 1 3 5
</span><span class='line'>
</span><span class='line'>Test passed!
</span><span class='line'>
</span><span class='line'>Testing half precision (math in single precision)
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>Result of classification: 1 3 5
</span><span class='line'>
</span><span class='line'>Test passed!
</span></code></pre></td></tr></table></div></figure>


<h3>nvidia-container-toolkit???</h3>

<p>Docker Desktop + WSL2不用安装 nvidia-container-toolkit ???</p>

<h2>WSL2 Python - conda</h2>

<p>下载安装conda</p>

<ul>
<li><a href="https://blog.csdn.net/weixin_44029053/article/details/119480776">https://blog.csdn.net/weixin_44029053/article/details/119480776</a></li>
</ul>


<h3>下载miniconda</h3>

<p><a href="https://docs.conda.io/projects/miniconda/en/latest/">https://docs.conda.io/projects/miniconda/en/latest/</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir -p ~/miniconda3
</span><span class='line'>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
</span><span class='line'>bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
</span><span class='line'>rm -rf ~/miniconda3/miniconda.sh
</span><span class='line'>
</span><span class='line'>~/miniconda3/bin/conda init bash</span></code></pre></td></tr></table></div></figure>


<p>运行脚本安装：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>winse@DESKTOP-BR4MG38:ai$ mkdir miniconda3
</span><span class='line'>winse@DESKTOP-BR4MG38:ai$ cd miniconda3/
</span><span class='line'>winse@DESKTOP-BR4MG38:miniconda3$
</span><span class='line'>
</span><span class='line'>winse@DESKTOP-BR4MG38:miniconda3$ bash miniconda.sh -b -u -p ~/miniconda3
</span><span class='line'>PREFIX=/home/winse/miniconda3
</span><span class='line'>Unpacking payload ...
</span><span class='line'>
</span><span class='line'>Installing base environment...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Downloading and Extracting Packages:
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Downloading and Extracting Packages:
</span><span class='line'>
</span><span class='line'>Preparing transaction: done
</span><span class='line'>Executing transaction: done
</span><span class='line'>installation finished.
</span><span class='line'>
</span><span class='line'>winse@DESKTOP-BR4MG38:miniconda3$ ~/miniconda3/bin/conda init bash
</span><span class='line'>no change     /home/winse/miniconda3/condabin/conda
</span><span class='line'>no change     /home/winse/miniconda3/bin/conda
</span><span class='line'>no change     /home/winse/miniconda3/bin/conda-env
</span><span class='line'>no change     /home/winse/miniconda3/bin/activate
</span><span class='line'>no change     /home/winse/miniconda3/bin/deactivate
</span><span class='line'>no change     /home/winse/miniconda3/etc/profile.d/conda.sh
</span><span class='line'>no change     /home/winse/miniconda3/etc/fish/conf.d/conda.fish
</span><span class='line'>no change     /home/winse/miniconda3/shell/condabin/Conda.psm1
</span><span class='line'>no change     /home/winse/miniconda3/shell/condabin/conda-hook.ps1
</span><span class='line'>no change     /home/winse/miniconda3/lib/python3.11/site-packages/xontrib/conda.xsh
</span><span class='line'>no change     /home/winse/miniconda3/etc/profile.d/conda.csh
</span><span class='line'>modified      /home/winse/.bashrc
</span><span class='line'>
</span><span class='line'>==&gt; For changes to take effect, close and re-open your current shell. &lt;==
</span></code></pre></td></tr></table></div></figure>


<h3>添加源：</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
</span><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
</span><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
</span><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
</span><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
</span><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/
</span><span class='line'>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
</span><span class='line'>conda config --set show_channel_urls yes 
</span><span class='line'>
</span><span class='line'>conda config --show channels
</span><span class='line'>#conda config --remove-key channels
</span></code></pre></td></tr></table></div></figure>


<h3>运行测试GPU</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>conda create -n demo_env python=3.8
</span><span class='line'>conda activate demo_env
</span><span class='line'>conda install pytorch==1.6.0 cudatoolkit=10.1 torchaudio=0.6.0 -c pytorch
</span><span class='line'>
</span><span class='line'>#conda list
</span><span class='line'>#conda deactivate
</span><span class='line'>
</span><span class='line'>#conda env list
</span><span class='line'>#conda remove -n demo_env --all
</span><span class='line'>#conda env remove --name old_name
</span></code></pre></td></tr></table></div></figure>


<p>验证是否安装成功
在我们到demo_env环境下，打开Python，输入以下语句：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(demo_env) winse@DESKTOP-BR4MG38:ai$ python
</span><span class='line'>Python 3.8.18 | packaged by conda-forge | (default, Dec 23 2023, 17:21:28)
</span><span class='line'>[GCC 12.3.0] on linux
</span><span class='line'>Type "help", "copyright", "credits" or "license" for more information.
</span><span class='line'>&gt;&gt;&gt; import torch
</span><span class='line'>&gt;&gt;&gt; x = torch.rand(5,3)
</span><span class='line'>&gt;&gt;&gt; print(x)
</span><span class='line'>tensor([[0.4343, 0.3966, 0.1862],
</span><span class='line'>        [0.1502, 0.0788, 0.7713],
</span><span class='line'>        [0.3505, 0.7065, 0.9952],
</span><span class='line'>        [0.6420, 0.2574, 0.7550],
</span><span class='line'>        [0.8292, 0.7714, 0.9014]])
</span><span class='line'>&gt;&gt;&gt; print(torch.cuda.is_available())
</span><span class='line'>True
</span></code></pre></td></tr></table></div></figure>


<h2>模型下载</h2>

<p><strong>非常重要，不然时间都浪费等待下载上了。模型动辄几G，稍微大一点的就几十G，是需要慎重和反复探索。</strong></p>

<p>一开始用代理和GIT下载的，又慢又浪费时间又浪费空间。放着下了一晚，早起起来磁盘空间不够 o(╥﹏╥)o 。</p>

<p><img src="/images/blogs/ai/git-down-ai-models.png" alt="" /></p>

<p>参考 <a href="https://soulteary.com/2024/01/09/summary-of-reliable-download-solutions-for-ai-models.html">https://soulteary.com/2024/01/09/summary-of-reliable-download-solutions-for-ai-models.html</a></p>

<h3>国内的modelscope下载</h3>

<p>modelscope它还结合了aliyun提供了一定时长的免费环境，在本地折腾折腾后再上去跑跑。这里只通过它去下载模型（下载的方式是没有.git的文件，少占一半多的磁盘空间）。</p>

<ul>
<li><a href="https://modelscope.cn/docs/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E8%BD%BD">https://modelscope.cn/docs/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E8%BD%BD</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:ai$ conda activate demo
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ pip install modelscope
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ python -c "from modelscope.hub.snapshot_download import snapshot_download;snapshot_download('damo/nlp_xlmr_named-entity-recognition_viet-ecommerce-title', cache_dir='./')"
</span><span class='line'>2024-01-14 16:52:36,017 - modelscope - INFO - PyTorch version 1.11.0+cu113 Found.
</span><span class='line'>2024-01-14 16:52:36,018 - modelscope - INFO - Loading ast index from /home/winse/.cache/modelscope/ast_indexer
</span><span class='line'>2024-01-14 16:52:36,050 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 85336421feb1dc1ec9dde85ceee20f42 and a total number of 953 components indexed
</span><span class='line'>2024-01-14 16:52:36,757 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.19k/1.19k [00:00&lt;00:00, 12.3MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238/238 [00:00&lt;00:00, 1.97MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238/238 [00:00&lt;00:00, 1.81MB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 1.04G/1.04G [00:36&lt;00:00, 30.1MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.68k/2.68k [00:00&lt;00:00, 18.2MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.68k/2.68k [00:00&lt;00:00, 27.7MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.83M/4.83M [00:00&lt;00:00, 7.97MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:00&lt;00:00, 1.58MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8.68M/8.68M [00:00&lt;00:00, 11.3MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 470/470 [00:00&lt;00:00, 4.53MB/s]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ python -c "from modelscope.hub.snapshot_download import snapshot_download;snapshot_download('Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1', cache_dir='./')"
</span><span class='line'>2024-01-15 08:19:52,588 - modelscope - INFO - PyTorch version 1.11.0+cu113 Found.
</span><span class='line'>2024-01-15 08:19:52,589 - modelscope - INFO - Loading ast index from /home/winse/.cache/modelscope/ast_indexer
</span><span class='line'>2024-01-15 08:19:52,741 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 85336421feb1dc1ec9dde85ceee20f42 and a total number of 953 components indexed
</span><span class='line'>2024-01-15 08:19:53,874 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 257k/257k [00:00&lt;00:00, 1.48MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 600/600 [00:00&lt;00:00, 488kB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████████| 793/793 [00:00&lt;00:00, 1.35MB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████████| 884/884 [00:00&lt;00:00, 1.47MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████| 4.56k/4.56k [00:00&lt;00:00, 220kB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 146/146 [00:00&lt;00:00, 251kB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████▉| 3.20G/3.20G [01:29&lt;00:00, 38.5MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 319M/319M [00:39&lt;00:00, 8.39MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 571k/571k [00:00&lt;00:00, 2.35MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 583k/583k [00:00&lt;00:00, 2.16MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 571k/571k [00:00&lt;00:00, 2.10MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 539/539 [00:00&lt;00:00, 924kB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████| 196k/196k [00:00&lt;00:00, 998kB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 226k/226k [00:00&lt;00:00, 1.24MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 342/342 [00:00&lt;00:00, 617kB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 390M/390M [00:30&lt;00:00, 13.5MB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████▉| 1.13G/1.13G [00:41&lt;00:00, 29.3MB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████| 8.90k/8.90k [00:00&lt;00:00, 3.09MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 298/298 [00:00&lt;00:00, 482kB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 186/186 [00:00&lt;00:00, 304kB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████▉| 3.89G/3.89G [02:12&lt;00:00, 31.6MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 477k/477k [00:00&lt;00:00, 2.02MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 477k/477k [00:00&lt;00:00, 1.72MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 198k/198k [00:00&lt;00:00, 1.01MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████| 212k/212k [00:00&lt;00:00, 1.10MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████| 555/555 [00:00&lt;00:00, 933kB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████| 107k/107k [00:00&lt;00:00, 782kB/s]
</span></code></pre></td></tr></table></div></figure>


<p>对比一下git和直接下载空间的占用，时间就更加不用说了。</p>

<p><img src="/images/blogs/ai/download-vs.png" alt="" /></p>

<h3>modelscope</h3>

<p>把整个流程跑一下，跑个简单的例子：</p>

<p>环境安装
<a href="https://modelscope.cn/docs/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85">https://modelscope.cn/docs/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85</a></p>

<p>运行时依赖</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</span><span class='line'>#pip config set global.index-url https://mirrors.cloud.aliyuncs.com/pypi/simple 
</span><span class='line'>#pip config set install.trusted-host mirrors.cloud.aliyuncs.com
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ pip3 install torch==1.11.0 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
</span><span class='line'>
</span><span class='line'>$ pip install transformers sentencepiece pyvi
</span></code></pre></td></tr></table></div></figure>


<p>测试模型：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>https://modelscope.cn/models/damo/nlp_xlmr_named-entity-recognition_viet-ecommerce-title/summary
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ python
</span><span class='line'>Python 3.8.18 | packaged by conda-forge | (default, Dec 23 2023, 17:21:28)
</span><span class='line'>[GCC 12.3.0] on linux
</span><span class='line'>Type "help", "copyright", "credits" or "license" for more information.
</span><span class='line'>&gt;&gt;&gt; from modelscope.pipelines import pipeline
</span><span class='line'>2024-01-15 01:22:20,476 - modelscope - INFO - PyTorch version 1.11.0+cu113 Found.
</span><span class='line'>2024-01-15 01:22:20,478 - modelscope - INFO - Loading ast index from /home/winse/.cache/modelscope/ast_indexer
</span><span class='line'>2024-01-15 01:22:20,498 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 85336421feb1dc1ec9dde85ceee20f42 and a total number of 953 components indexed
</span><span class='line'>&gt;&gt;&gt; from modelscope.utils.constant import Tasks
</span><span class='line'>&gt;&gt;&gt; ner_pipeline = pipeline(Tasks.named_entity_recognition, 'damo/nlp_xlmr_named-entity-recognition_viet-ecommerce-title', model_revision='v1.0.1')
</span><span class='line'>2024-01-15 01:22:28,618 - modelscope - INFO - initiate model from damo/nlp_xlmr_named-entity-recognition_viet-ecommerce-title
</span><span class='line'>2024-01-15 01:22:28,620 - modelscope - INFO - initiate model from location damo/nlp_xlmr_named-entity-recognition_viet-ecommerce-title.
</span><span class='line'>2024-01-15 01:22:28,630 - modelscope - INFO - initialize model from damo/nlp_xlmr_named-entity-recognition_viet-ecommerce-title
</span><span class='line'>2024-01-15 01:22:30,945 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing
</span><span class='line'>2024-01-15 01:22:34,599 - modelscope - INFO - All model checkpoint weights were used when initializing ModelForTokenClassificationWithCRF.
</span><span class='line'>
</span><span class='line'>2024-01-15 01:22:34,599 - modelscope - INFO - All the weights of ModelForTokenClassificationWithCRF were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use ModelForTokenClassificationWithCRF for predictions without further training.
</span><span class='line'>&gt;&gt;&gt; result = ner_pipeline('Nón vành dễ thương cho bé gái')
</span><span class='line'>&gt;&gt;&gt; print(result)
</span><span class='line'>{'output': [{'type': 'product', 'start': 0, 'end': 8, 'prob': 0.98140895, 'span': 'Nón vành'}, {'type': 'style', 'start': 9, 'end': 18, 'prob': 0.99752563, 'span': 'dễ thương'}, {'type': 'consumer_group', 'start': 23, 'end': 29, 'prob': 0.99895895, 'span': 'bé gái'}]}
</span><span class='line'>&gt;&gt;&gt;
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<h3>TODO</h3>

<ul>
<li>huggingface</li>
</ul>


<p>国外的，后续用到了再补</p>

<ul>
<li>downloader（跳过）</li>
</ul>


<p>当然，如果进场要用到各种工具的特定版本来下载依赖，用一个docker镜像来作为下载器，也是不错的方法</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#Python轻量环境
</span><span class='line'>docker pull python:3.10-slim
</span><span class='line'>
</span><span class='line'>@1
</span><span class='line'>#将本地目录挂载到容器里，一会作为模型下载目录使用
</span><span class='line'>docker run --rm -it -v `pwd`:/models python:3.10-slim bash
</span><span class='line'>
</span><span class='line'>sed -i 's/snapshot.debian.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.list.d/debian.sources
</span><span class='line'>pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</span><span class='line'>
</span><span class='line'>cd /models
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>@2
</span><span class='line'>#创建一个持续运行的 Python 容器
</span><span class='line'>docker run -d --name=downloader -v `pwd`:/models python:3.10-slim tail -f /etc/hosts
</span><span class='line'>#使用命令进入容器进行配置和下载模型
</span><span class='line'>docker exec -it downloader bash
</span></code></pre></td></tr></table></div></figure>


<h2>太乙模型</h2>

<h3>[尝试/试错]</h3>

<p>开始是参照 <a href="https://soulteary.com/2022/12/09/use-docker-to-quickly-get-started-with-the-chinese-stable-diffusion-model-taiyi.html">使用 Docker 来快速上手中文 Stable Diffusion 模型：太乙</a> 文章里面说的蛮简单的，想着我这个WSL2+GPU应该也是可以的。</p>

<p>开始的时刻还是git clone的，等到怕了，几个小时还不一定成功，后面才改成下载的方式！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#git clone https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1
</span><span class='line'>winse@DESKTOP-BR4MG38:/mnt/i/ai/stable-diffusion-taiyi$ git clone https://www.modelscope.cn/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1.git
</span><span class='line'>Cloning into 'Taiyi-Stable-Diffusion-1B-Chinese-v0.1'...
</span><span class='line'>remote: Enumerating objects: 85, done.
</span><span class='line'>remote: Counting objects: 100% (6/6), done.
</span><span class='line'>remote: Compressing objects: 100% (6/6), done.
</span><span class='line'>remote: Total 85 (delta 2), reused 0 (delta 0), pack-reused 79
</span><span class='line'>Unpacking objects: 100% (85/85), 3.61 GiB | 1.98 MiB/s, done.
</span><span class='line'>Filtering content: 100% (5/5), 8.92 GiB | 1.71 MiB/s, done.
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#镜像也下载了好几次 才pull下来
</span><span class='line'>winse@DESKTOP-BR4MG38:/mnt/i/ai$ docker pull soulteary/stable-diffusion:taiyi-0.1
</span><span class='line'>taiyi-0.1: Pulling from soulteary/stable-diffusion
</span><span class='line'>a404e5416296: Pull complete
</span><span class='line'>af6d12d8d61a: Pull complete
</span><span class='line'>bc57d500b85c: Pull complete
</span><span class='line'>fcd60060414d: Pull complete
</span><span class='line'>65b27d733eb0: Pull complete
</span><span class='line'>266c4315d44f: Pull complete
</span><span class='line'>7ed4190451a3: Pull complete
</span><span class='line'>975671c72e25: Pull complete
</span><span class='line'>213ba1e17e15: Pull complete
</span><span class='line'>37bbbc68318a: Pull complete
</span><span class='line'>80438d07027f: Pull complete
</span><span class='line'>74c79bc62d3a: Pull complete
</span><span class='line'>f8054e9907fb: Pull complete
</span><span class='line'>dc8d44bb4941: Pull complete
</span><span class='line'>625444b7a83c: Pull complete
</span><span class='line'>0b90667ff465: Pull complete
</span><span class='line'>67d73c5193e1: Pull complete
</span><span class='line'>Digest: sha256:69cc4b5fc890dd7ccffff9dbfc2eb2262a0a727574b8beeeafe621f9ef135d16
</span><span class='line'>Status: Downloaded newer image for soulteary/stable-diffusion:taiyi-0.1
</span><span class='line'>docker.io/soulteary/stable-diffusion:taiyi-0.1
</span><span class='line'>
</span><span class='line'>What's Next?
</span><span class='line'>  View a summary of image vulnerabilities and recommendations → docker scout quickview soulteary/stable-diffusion:taiyi-0.1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#这也是得在纯Linux机器上的Docker才行的
</span><span class='line'>#wget https://github.com/soulteary/docker-stable-diffusion-taiyi/blob/main/docker-compose.yml
</span><span class='line'>#我这就直接运行
</span><span class='line'>winse@DESKTOP-BR4MG38:stable-diffusion-taiyi$ docker run --gpus all --rm -it -v $(pwd)/Taiyi-Stable-Diffusion-1B-Chinese-v0.1:/stable-diffusion-webui/models/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 -p 7860:7860 soulteary/stable-diffusion:taiyi-0.1
</span><span class='line'>
</span><span class='line'>#Windows cmd
</span><span class='line'>#docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 --rm -it -v C:/docker-sdxl/stabilityai/:/app/stabilityai -p 7860:7860 soulteary/sdxl:runtime
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>运行起来后访问 <a href="http://localhost:7860/">http://localhost:7860/</a> ，输入 小船，河流，星空，星星，山峦，油画 查看Win11的任务管理器，GPU是打满了的，但生成的图片是全黑，啥都没有！</p>

<h3>WSL-Ubuntu部署</h3>

<p>试了很多次都不行，最后还是回到原点，不能偷懒，先把效果跑出来：</p>

<ul>
<li><a href="https://modelscope.cn/models/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/summary#%E4%BD%BF%E7%94%A8-usage">https://modelscope.cn/models/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/summary#%E4%BD%BF%E7%94%A8-usage</a></li>
</ul>


<h4>安装依赖（通过代理）</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#https://stackoverflow.com/questions/37776228/pycharm-python-opencv-and-cv2-install-error
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:~$ pip3 install opencv-python
</span><span class='line'>
</span><span class='line'>$ pip install diffusers
</span><span class='line'>
</span><span class='line'>##pip install accelerate
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:~$ unset all_proxy && unset ALL_PROXY
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:~$ pip install pysocks
</span><span class='line'>
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:~$ export ALL_PROXY=socks5://172.22.240.1:23333 HTTPS_PROXY=socks5://172.22.240.1:23333 HTTP_PROXY=socks5://172.22.240.1:23333
</span><span class='line'>(demo) winse@DESKTOP-BR4MG38:~$ pip install git+https://github.com/huggingface/accelerate  
</span></code></pre></td></tr></table></div></figure>


<h4>测试（跑了一个小时，-_-||）（此时还没安装cuDNN）：</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ python
</span><span class='line'>Python 3.8.18 | packaged by conda-forge | (default, Dec 23 2023, 17:21:28)
</span><span class='line'>[GCC 12.3.0] on linux
</span><span class='line'>Type "help", "copyright", "credits" or "license" for more information.
</span><span class='line'>&gt;&gt;&gt; from modelscope.utils.constant import Tasks
</span><span class='line'>2024-01-15 10:07:41,619 - modelscope - INFO - PyTorch version 1.11.0+cu113 Found.
</span><span class='line'>2024-01-15 10:07:41,630 - modelscope - INFO - Loading ast index from /home/winse/.cache/modelscope/ast_indexer
</span><span class='line'>2024-01-15 10:07:41,751 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 85336421feb1dc1ec9dde85ceee20f42 and a total number of 953 components indexed
</span><span class='line'>&gt;&gt;&gt; from modelscope.pipelines import pipeline
</span><span class='line'>&gt;&gt;&gt; import cv2
</span><span class='line'>&gt;&gt;&gt; pipe = pipeline(task=Tasks.text_to_image_synthesis, model='Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1', model_revision='v1.0.0')
</span><span class='line'>Loading pipeline components...:   0%|                                                          | 0/7 [00:00&lt;?, ?it/s]
</span><span class='line'>/home/winse/miniconda3/envs/demo/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: 
</span><span class='line'>FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
</span><span class='line'>  warnings.warn(
</span><span class='line'>Loading pipeline components...:  57%|████████████████████████████▌                     | 4/7 [00:32&lt;00:23,  7.83s/it]
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
</span><span class='line'>Loading pipeline components...: 100%|██████████████████████████████████████████████████| 7/7 [03:23&lt;00:00, 29.02s/it]
</span><span class='line'>&gt;&gt;&gt; prompt = '飞流直下三千尺，油画'
</span><span class='line'>&gt;&gt;&gt; output = pipe({'text': prompt})
</span><span class='line'>/home/winse/miniconda3/envs/demo/lib/python3.8/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:889: FutureWarning: `callback_steps` is deprecated and will be removed in version 1.0.0. Passing `callback_steps` as an input argument to `__call__` is deprecated, consider using `callback_on_step_end`
</span><span class='line'>  deprecate(
</span><span class='line'>We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
</span><span class='line'>You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (2), or the `sep_token_id` (None), and your input is not padded.
</span><span class='line'>100%|██████████████████████████████████████████████████████████████████████████████| 50/50 [1:03:11&lt;00:00, 75.83s/it]
</span><span class='line'>&gt;&gt;&gt; cv2.imwrite('result.png', output['output_imgs'][0])
</span><span class='line'>True
</span><span class='line'>&gt;&gt;&gt;</span></code></pre></td></tr></table></div></figure>


<p><img src="/images/blogs/ai/taiyi-result.png" alt="" /></p>

<h4>再测个快的</h4>

<p>有 cuDNN 加持确实快，10分钟就跑出来了！没安装之前时间估计是三个小时的！！！</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; import torch
</span><span class='line'>&gt;&gt;&gt; from diffusers import StableDiffusionPipeline
</span><span class='line'>&gt;&gt;&gt; torch.backends.cudnn.benchmark = True
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt; pipe = StableDiffusionPipeline.from_pretrained("Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1", torch_dtype=torch.float16)
</span><span class='line'>Loading pipeline components...:  57%|████████████████████████████▌                     | 4/7 [00:05&lt;00:03,  1.32s/it]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
</span><span class='line'>Loading pipeline components...: 100%|██████████████████████████████████████████████████| 7/7 [00:32&lt;00:00,  4.58s/it]
</span><span class='line'>&gt;&gt;&gt; pipe.to('cuda')
</span><span class='line'>StableDiffusionPipeline {
</span><span class='line'>  "_class_name": "StableDiffusionPipeline",
</span><span class='line'>  "_diffusers_version": "0.25.0",
</span><span class='line'>  "_name_or_path": "Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1",
</span><span class='line'>  "feature_extractor": [
</span><span class='line'>    "transformers",
</span><span class='line'>    "CLIPFeatureExtractor"
</span><span class='line'>  ],
</span><span class='line'>  "image_encoder": [
</span><span class='line'>    null,
</span><span class='line'>    null
</span><span class='line'>  ],
</span><span class='line'>  "requires_safety_checker": true,
</span><span class='line'>  "safety_checker": [
</span><span class='line'>    "stable_diffusion",
</span><span class='line'>    "StableDiffusionSafetyChecker"
</span><span class='line'>  ],
</span><span class='line'>  "scheduler": [
</span><span class='line'>    "diffusers",
</span><span class='line'>    "PNDMScheduler"
</span><span class='line'>  ],
</span><span class='line'>  "text_encoder": [
</span><span class='line'>    "transformers",
</span><span class='line'>    "BertModel"
</span><span class='line'>  ],
</span><span class='line'>  "tokenizer": [
</span><span class='line'>    "transformers",
</span><span class='line'>    "BertTokenizer"
</span><span class='line'>  ],
</span><span class='line'>  "unet": [
</span><span class='line'>    "diffusers",
</span><span class='line'>    "UNet2DConditionModel"
</span><span class='line'>  ],
</span><span class='line'>  "vae": [
</span><span class='line'>    "diffusers",
</span><span class='line'>    "AutoencoderKL"
</span><span class='line'>  ]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>&gt;&gt;&gt;
</span><span class='line'>&gt;&gt;&gt; prompt = '飞流直下三千尺，油画'
</span><span class='line'>&gt;&gt;&gt; image = pipe(prompt, guidance_scale=7.5).images[0]
</span><span class='line'>100%|████████████████████████████████████████████████████████████████████████████████| 50/50 [09:32&lt;00:00, 11.45s/it]
</span><span class='line'>&gt;&gt;&gt; image.save("飞流.png")
</span><span class='line'>&gt;&gt;&gt;
</span></code></pre></td></tr></table></div></figure>


<p><img src="/images/blogs/ai/taiyi-cudnn-result.png" alt="" /></p>

<h2>改一下conda的名字</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(demo) winse@DESKTOP-BR4MG38:ai$ conda deactivate
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:ai$ conda rename -n demo modelscope
</span><span class='line'>Source:      /home/winse/miniconda3/envs/demo
</span><span class='line'>Destination: /home/winse/miniconda3/envs/modelscope
</span><span class='line'>Packages: 22
</span><span class='line'>Files: 33924
</span><span class='line'>
</span><span class='line'>Downloading and Extracting Packages:
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Downloading and Extracting Packages:
</span><span class='line'>
</span><span class='line'>Preparing transaction: done
</span><span class='line'>Verifying transaction: done
</span><span class='line'>Executing transaction: done
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:ai$ conda env list
</span><span class='line'># conda environments:
</span><span class='line'>#
</span><span class='line'>base                  *  /home/winse/miniconda3
</span><span class='line'>modelscope               /home/winse/miniconda3/envs/modelscope
</span></code></pre></td></tr></table></div></figure>


<h2>模型下载脚本</h2>

<p>比如下载：<a href="https://modelscope.cn/models/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1/summary">https://modelscope.cn/models/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1/summary</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tail -16 ~/.bashrc
</span><span class='line'>
</span><span class='line'>function modelscope_download() {
</span><span class='line'>model=$1
</span><span class='line'>
</span><span class='line'>conda activate modelscope
</span><span class='line'>
</span><span class='line'>#pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</span><span class='line'>#pip install modelscope
</span><span class='line'>
</span><span class='line'>python -c "from modelscope.hub.snapshot_download import snapshot_download;snapshot_download('$model', cache_dir='./')"
</span><span class='line'>
</span><span class='line'>conda deactivate
</span><span class='line'>
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>$ source ~/.bashrc
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:ai$ modelscope_download "Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1"
</span><span class='line'>2024-01-15 15:17:13,613 - modelscope - INFO - PyTorch version 1.11.0+cu113 Found.
</span><span class='line'>2024-01-15 15:17:13,614 - modelscope - INFO - Loading ast index from /home/winse/.cache/modelscope/ast_indexer
</span><span class='line'>2024-01-15 15:17:13,637 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 85336421feb1dc1ec9dde85ceee20f42 and a total number of 953 components indexed
</span><span class='line'>2024-01-15 15:17:16,879 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 2.31M/2.31M [00:00&lt;00:00, 6.01MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 612/612 [00:00&lt;00:00, 436kB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 547/547 [00:00&lt;00:00, 804kB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 743/743 [00:00&lt;00:00, 1.25MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 4.46k/4.46k [00:00&lt;00:00, 244kB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 139/139 [00:00&lt;00:00, 231kB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████▉| 3.20G/3.20G [02:36&lt;00:00, 22.0MB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 319M/319M [00:39&lt;00:00, 8.40MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 2.11M/2.11M [00:00&lt;00:00, 4.05MB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 512k/512k [00:00&lt;00:00, 1.28MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [00:00&lt;00:00, 845kB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 342/342 [00:00&lt;00:00, 521kB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████▉| 1.13G/1.13G [01:22&lt;00:00, 14.8MB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 469M/469M [00:12&lt;00:00, 39.0MB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5.00/5.00 [00:00&lt;00:00, 6.02kB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 7.97k/7.97k [00:00&lt;00:00, 7.06MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [00:00&lt;00:00, 441kB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 389/389 [00:00&lt;00:00, 348kB/s]
</span><span class='line'>Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████▉| 11.3G/11.3G [04:07&lt;00:00, 49.0MB/s]
</span><span class='line'>Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 697/697 [00:00&lt;00:00, 950kB/s]
</span><span class='line'>Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 939k/939k [00:00&lt;00:00, 2.50MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 2.87M/2.87M [00:00&lt;00:00, 5.79MB/s]
</span><span class='line'>Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 3.44M/3.44M [00:00&lt;00:00, 6.17MB/s]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#tree -L 2
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:ai$ tree -L 1 Fengshenbang/
</span><span class='line'>Fengshenbang/
</span><span class='line'>├── Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1
</span><span class='line'>└── Taiyi-Stable-Diffusion-1B-Chinese-v0.1
</span><span class='line'>
</span><span class='line'>2 directories, 0 files
</span></code></pre></td></tr></table></div></figure>


<p>再跑一个中英文的模型试试</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:ai$ conda activate modelscope
</span><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:ai$
</span><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:ai$ python
</span><span class='line'>Python 3.8.18 | packaged by conda-forge | (default, Dec 23 2023, 17:21:28)
</span><span class='line'>[GCC 12.3.0] on linux
</span><span class='line'>Type "help", "copyright", "credits" or "license" for more information.
</span><span class='line'>&gt;&gt;&gt; from diffusers import StableDiffusionPipeline
</span><span class='line'>&gt;&gt;&gt; pipe = StableDiffusionPipeline.from_pretrained("Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1").to("cuda")
</span><span class='line'>Loading pipeline components...:  43%|█████████████████████████████████▊                                             | 3/7 [00:17&lt;00:21,  5.46s/it]/home/winse/miniconda3/envs/modelscope/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
</span><span class='line'>  warnings.warn(
</span><span class='line'>Loading pipeline components...:  86%|███████████████████████████████████████████████████████████████████▋           | 6/7 [00:17&lt;00:01,  1.90s/it]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
</span><span class='line'>`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
</span><span class='line'>Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████████| 7/7 [00:27&lt;00:00,  3.87s/it]
</span><span class='line'>&gt;&gt;&gt;
</span><span class='line'>&gt;&gt;&gt; prompt = '小桥流水人家，Van Gogh style'
</span><span class='line'>&gt;&gt;&gt; image = pipe(prompt, guidance_scale=10).images[0]
</span><span class='line'>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [14:19&lt;00:00, 17.19s/it]
</span><span class='line'>&gt;&gt;&gt; image.save("小桥.png")
</span><span class='line'>&gt;&gt;&gt;</span></code></pre></td></tr></table></div></figure>


<p><img src="/images/blogs/ai/taiyi-zh-en-result.png" alt="" /></p>

<h2>太乙webui - 亦步亦趋</h2>

<p>这里记录了安装的详细过程，比较繁琐，如果直接安装可以跳到[太乙webui - 纯净版]。</p>

<ul>
<li><a href="https://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/README.md">https://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/README.md</a></li>
<li><a href="https://github.com/soulteary/docker-stable-diffusion-taiyi/blob/main/docker/Dockerfile">https://github.com/soulteary/docker-stable-diffusion-taiyi/blob/main/docker/Dockerfile</a></li>
<li><a href="https://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/webui.sh">https://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/webui.sh</a></li>
</ul>


<p>选一个跟我现在用的环境一样的版本和系统：<a href="https://hub.docker.com/r/nvidia/cuda/tags">https://hub.docker.com/r/nvidia/cuda/tags</a></p>

<p>镜像的描述：CUDA and cuDNN images from gitlab.com/nvidia/cuda</p>

<h3>试错</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:ai$ docker pull nvidia/cuda:12.3.1-devel-ubuntu20.04
</span><span class='line'>12.3.1-devel-ubuntu20.04: Pulling from nvidia/cuda
</span><span class='line'>12.3.1-devel-ubuntu20.04: Pulling from nvidia/cuda
</span><span class='line'>25ad149ed3cf: Pull complete
</span><span class='line'>ba7b66a9df40: Pull complete
</span><span class='line'>520797292d92: Pull complete
</span><span class='line'>c5f2ffd06d8b: Pull complete
</span><span class='line'>1698c67699a3: Pull complete
</span><span class='line'>16dd7c0d35aa: Pull complete
</span><span class='line'>568cac1e538c: Pull complete
</span><span class='line'>6252d19a7f1d: Pull complete
</span><span class='line'>f573e2686be4: Pull complete
</span><span class='line'>0074e75104ac: Pull complete
</span><span class='line'>df35fae9e247: Pull complete
</span><span class='line'>Digest: sha256:befbdfddbb52727f9ce8d0c574cac0f631c606b1e6f0e523f3a0777fe2720c99
</span><span class='line'>Status: Downloaded newer image for nvidia/cuda:12.3.1-devel-ubuntu20.04
</span><span class='line'>docker.io/nvidia/cuda:12.3.1-devel-ubuntu20.04
</span><span class='line'>
</span><span class='line'>What's Next?
</span><span class='line'>  1. Sign in to your Docker account → docker login
</span><span class='line'>  2. View a summary of image vulnerabilities and recommendations → docker scout quickview nvidia/cuda:12.3.1-devel-ubuntu20.04
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:ai$ docker run --rm --gpus all --ipc host --ulimit memlock=-1 --ulimit stack=67108864 -it -v /mnt/i/ai:/app/stabilityai -p 7860:7860 docker.io/nvidia/cuda:12.3.1-devel-ubuntu20.04
</span><span class='line'>docker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running hook #0: error running hook: exit status 1, stdout: , stderr: Auto-detected mode as 'legacy'
</span><span class='line'>nvidia-container-cli: requirement error: unsatisfied condition: cuda&gt;=12.3, please update your driver to a newer version, or use an earlier cuda container: unknown.
</span></code></pre></td></tr></table></div></figure>


<h3>重新下载镜像并配置</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:ai$ nvidia-smi
</span><span class='line'>Mon Jan 15 17:04:18 2024
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| NVIDIA-SMI 535.146.01             Driver Version: 537.99       CUDA Version: 12.2     |
</span><span class='line'>|-----------------------------------------+----------------------+----------------------+
</span><span class='line'>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
</span><span class='line'>| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
</span><span class='line'>|                                         |                      |               MIG M. |
</span><span class='line'>|=========================================+======================+======================|
</span><span class='line'>|   0  Quadro T2000                   On  | 00000000:01:00.0  On |                  N/A |
</span><span class='line'>| N/A   46C    P8               6W /  60W |    589MiB /  4096MiB |      7%      Default |
</span><span class='line'>|                                         |                      |                  N/A |
</span><span class='line'>+-----------------------------------------+----------------------+----------------------+
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| Processes:                                                                            |
</span><span class='line'>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
</span><span class='line'>|        ID   ID                                                             Usage      |
</span><span class='line'>|=======================================================================================|
</span><span class='line'>|    0   N/A  N/A        39      G   /Xwayland                                 N/A      |
</span><span class='line'>|    0   N/A  N/A        42      G   /Xwayland                                 N/A      |
</span><span class='line'>|    0   N/A  N/A        44      G   /Xwayland                                 N/A      |
</span><span class='line'>+---------------------------------------------------------------------------------------+</span></code></pre></td></tr></table></div></figure>


<p>版本不能高于本地CUDA，重新下载镜像：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:ai$ docker pull nvidia/cuda:12.2.2-devel-ubuntu20.04
</span><span class='line'>12.2.2-devel-ubuntu20.04: Pulling from nvidia/cuda
</span><span class='line'>12.2.2-devel-ubuntu20.04: Pulling from nvidia/cuda
</span><span class='line'>96d54c3075c9: Pull complete
</span><span class='line'>db26cf78ae4f: Pull complete
</span><span class='line'>5adc7ab504d3: Pull complete
</span><span class='line'>e4f230263527: Pull complete
</span><span class='line'>95e3f492d47e: Pull complete
</span><span class='line'>35dd1979297e: Pull complete
</span><span class='line'>39a2c88664b3: Pull complete
</span><span class='line'>d8f6b6cd09da: Pull complete
</span><span class='line'>fe19bbed4a4a: Pull complete
</span><span class='line'>469ef7e9efe0: Pull complete
</span><span class='line'>e30c6425f419: Pull complete
</span><span class='line'>Digest: sha256:b7074ef6f9aa30c27fe747f3a7e10402ec442f001290718c73e0972d1ee61342
</span><span class='line'>Status: Downloaded newer image for nvidia/cuda:12.2.2-devel-ubuntu20.04
</span><span class='line'>docker.io/nvidia/cuda:12.2.2-devel-ubuntu20.04
</span><span class='line'>
</span><span class='line'>What's Next?
</span><span class='line'>  1. Sign in to your Docker account → docker login
</span><span class='line'>  2. View a summary of image vulnerabilities and recommendations → docker scout quickview nvidia/cuda:12.2.2-devel-ubuntu20.04
</span></code></pre></td></tr></table></div></figure>


<h3>运行容器实例</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(modelscope) winse@DESKTOP-BR4MG38:P15$ docker run --rm --gpus all --ipc host --ulimit memlock=-1 --ulimit stack=67108864 -it -v /mnt/i/ai:/app/stabilityai -p 7860:7860 docker.io/nvidia/cuda:12.2.2-devel-ubuntu20.04
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>==========
</span><span class='line'>== CUDA ==
</span><span class='line'>==========
</span><span class='line'>
</span><span class='line'>CUDA Version 12.2.2
</span><span class='line'>
</span><span class='line'>Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
</span><span class='line'>
</span><span class='line'>This container image and its contents are governed by the NVIDIA Deep Learning Container License.
</span><span class='line'>By pulling and using the container, you accept the terms and conditions of this license:
</span><span class='line'>https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
</span><span class='line'>
</span><span class='line'>A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# nvidia-smi 
</span><span class='line'>Mon Jan 15 13:25:43 2024       
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| NVIDIA-SMI 535.146.01             Driver Version: 537.99       CUDA Version: 12.2     |
</span><span class='line'>|-----------------------------------------+----------------------+----------------------+
</span><span class='line'>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
</span><span class='line'>| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
</span><span class='line'>|                                         |                      |               MIG M. |
</span><span class='line'>|=========================================+======================+======================|
</span><span class='line'>|   0  Quadro T2000                   On  | 00000000:01:00.0  On |                  N/A |
</span><span class='line'>| N/A   43C    P8               3W /  60W |    620MiB /  4096MiB |      2%      Default |
</span><span class='line'>|                                         |                      |                  N/A |
</span><span class='line'>+-----------------------------------------+----------------------+----------------------+
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| Processes:                                                                            |
</span><span class='line'>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
</span><span class='line'>|        ID   ID                                                             Usage      |
</span><span class='line'>|=======================================================================================|
</span><span class='line'>|  No running processes found                                                           |
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>root@41af85cb0007:/# docker ps -a 
</span><span class='line'>bash: docker: command not found
</span><span class='line'>root@41af85cb0007:/# python -V 
</span><span class='line'>bash: python: command not found
</span></code></pre></td></tr></table></div></figure>


<p>尽管用的是WSL 2 based engine，但是不是Windows管理的。</p>

<h3>配值webui</h3>

<p>[解决被官方忽视的 AI 容器应用问题] <a href="https://soulteary.com/2022/12/09/use-docker-to-quickly-get-started-with-the-chinese-stable-diffusion-model-taiyi.html">https://soulteary.com/2022/12/09/use-docker-to-quickly-get-started-with-the-chinese-stable-diffusion-model-taiyi.html</a>
<a href="https://github.com/soulteary/docker-stable-diffusion-taiyi/blob/main/docker/Dockerfile">https://github.com/soulteary/docker-stable-diffusion-taiyi/blob/main/docker/Dockerfile</a>
是对官方的依赖安装的拆解。可以参考，还是不建议这么搞，如果能促成源头修正那就是另一种说法了。</p>

<p>由于他的镜像我也跑不起来，所以直接按照官方来安装，参考借鉴他遇到解决过的问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
<span class='line-number'>296</span>
<span class='line-number'>297</span>
<span class='line-number'>298</span>
<span class='line-number'>299</span>
<span class='line-number'>300</span>
<span class='line-number'>301</span>
<span class='line-number'>302</span>
<span class='line-number'>303</span>
<span class='line-number'>304</span>
<span class='line-number'>305</span>
<span class='line-number'>306</span>
<span class='line-number'>307</span>
<span class='line-number'>308</span>
<span class='line-number'>309</span>
<span class='line-number'>310</span>
<span class='line-number'>311</span>
<span class='line-number'>312</span>
<span class='line-number'>313</span>
<span class='line-number'>314</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@41af85cb0007:/# sed -i.bak -e 's|archive.ubuntu.com/ubuntu/|mirrors.tuna.tsinghua.edu.cn/ubuntu/|' -e 's|security.ubuntu.com/ubuntu/|mirrors.tuna.tsinghua.edu.cn/ubuntu/|' /etc/apt/sources.list
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# apt update 
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# apt install -y git wget curl iputils-ping iproute2 traceroute
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# bash Miniconda3-latest-Linux-x86_64.sh -b
</span><span class='line'>PREFIX=/root/miniconda3
</span><span class='line'>Unpacking payload ...
</span><span class='line'>                                                                                                                                                                                                           
</span><span class='line'>Installing base environment...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Downloading and Extracting Packages:
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Downloading and Extracting Packages:
</span><span class='line'>
</span><span class='line'>Preparing transaction: done
</span><span class='line'>Executing transaction: done
</span><span class='line'>installation finished.
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# /root/miniconda3/bin/conda init bash 
</span><span class='line'>no change     /root/miniconda3/condabin/conda
</span><span class='line'>no change     /root/miniconda3/bin/conda
</span><span class='line'>no change     /root/miniconda3/bin/conda-env
</span><span class='line'>no change     /root/miniconda3/bin/activate
</span><span class='line'>no change     /root/miniconda3/bin/deactivate
</span><span class='line'>no change     /root/miniconda3/etc/profile.d/conda.sh
</span><span class='line'>no change     /root/miniconda3/etc/fish/conf.d/conda.fish
</span><span class='line'>no change     /root/miniconda3/shell/condabin/Conda.psm1
</span><span class='line'>no change     /root/miniconda3/shell/condabin/conda-hook.ps1
</span><span class='line'>no change     /root/miniconda3/lib/python3.11/site-packages/xontrib/conda.xsh
</span><span class='line'>no change     /root/miniconda3/etc/profile.d/conda.csh
</span><span class='line'>modified      /root/.bashrc
</span><span class='line'>
</span><span class='line'>==&gt; For changes to take effect, close and re-open your current shell. &lt;==
</span><span class='line'>
</span><span class='line'>root@41af85cb0007:/# source ~/.bashrc
</span><span class='line'>(base) root@41af85cb0007:/# 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#https://github.com/IDEA-CCNL/stable-diffusion-webui/zipball/master/
</span><span class='line'>#https://github.com/IDEA-CCNL/stable-diffusion-webui/tarball/master/
</span><span class='line'>#https://docs.github.com/en/repositories/working-with-files/using-files/downloading-source-code-archives#source-code-archive-urls
</span><span class='line'>(base) root@41af85cb0007:/opt# wget -c https://github.com/IDEA-CCNL/stable-diffusion-webui/archive/refs/heads/master.tar.gz -O stable-diffusion-webui.tgz
</span><span class='line'>
</span><span class='line'>(base) root@41af85cb0007:/opt# tar zxf stable-diffusion-webui.tgz 
</span><span class='line'>(base) root@41af85cb0007:/opt# mv stable-diffusion-webui-master stable-diffusion-webui
</span><span class='line'>(base) root@41af85cb0007:/opt# cd stable-diffusion-webui
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#@@ 反正走代理，没必要
</span><span class='line'>#(webui) root@41af85cb0007:/opt/stable-diffusion-webui# pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</span><span class='line'>#Writing to /root/.config/pip/pip.conf
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/4345
</span><span class='line'>#https://stackoverflow.com/questions/75099182/stable-diffusion-error-couldnt-install-torch-no-matching-distribution-found
</span><span class='line'>#ERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python &gt;=3.7,&lt;3.10; 1.6.3 Requires-Python &gt;=3.7,&lt;3.10; 1.7.0 Requires-Python &gt;=3.7,&lt;3.10; 1.7.1 Requires-Python &gt;=3.7,&lt;3.10
</span><span class='line'>(base) root@41af85cb0007:/opt/stable-diffusion-webui# conda create -n py39 python=3.9
</span><span class='line'>(base) root@41af85cb0007:/opt/stable-diffusion-webui# conda activate py39
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# 
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#@@ 用到github，得socks代理一下，@@先去掉代理不然又解析不了@@
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# unset all_proxy && unset ALL_PROXY && unset https_proxy && unset HTTPS_PROXY
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# pip install pysocks
</span><span class='line'>Collecting pysocks
</span><span class='line'>  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(&lt;pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fca218ae370&gt;, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl
</span><span class='line'>  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)
</span><span class='line'>Installing collected packages: pysocks
</span><span class='line'>Successfully installed pysocks-1.7.1
</span><span class='line'>WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#?? ImportError: libGL.so.1: cannot open shared object file: No such file or directory
</span><span class='line'>
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# apt-get install ffmpeg libsm6 libxext6  -y
</span><span class='line'>...
</span><span class='line'>Setting up tzdata (2023c-0ubuntu0.20.04.2) ...
</span><span class='line'>debconf: unable to initialize frontend: Dialog
</span><span class='line'>debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)
</span><span class='line'>debconf: falling back to frontend: Readline
</span><span class='line'>Configuring tzdata
</span><span class='line'>------------------
</span><span class='line'>
</span><span class='line'>Please select the geographic area in which you live. Subsequent configuration questions will narrow this down by presenting a list of cities, representing the time zones in which they are located.
</span><span class='line'>
</span><span class='line'>  1. Africa  2. America  3. Antarctica  4. Australia  5. Arctic  6. Asia  7. Atlantic  8. Europe  9. Indian  10. Pacific  11. SystemV  12. US  13. Etc
</span><span class='line'>Geographic area: 6
</span><span class='line'>
</span><span class='line'>Please select the city or region corresponding to your time zone.
</span><span class='line'>
</span><span class='line'>  1. Aden      9. Baghdad   17. Chita       25. Dushanbe     33. Irkutsk    41. Kashgar       49. Macau         57. Omsk        65. Rangoon        73. Taipei    81. Ujung_Pandang  89. Yekaterinburg
</span><span class='line'>  2. Almaty    10. Bahrain  18. Choibalsan  26. Famagusta    34. Istanbul   42. Kathmandu     50. Magadan       58. Oral        66. Riyadh         74. Tashkent  82. Ulaanbaatar    90. Yerevan
</span><span class='line'>  3. Amman     11. Baku     19. Chongqing   27. Gaza         35. Jakarta    43. Khandyga      51. Makassar      59. Phnom_Penh  67. Sakhalin       75. Tbilisi   83. Urumqi
</span><span class='line'>  4. Anadyr    12. Bangkok  20. Colombo     28. Harbin       36. Jayapura   44. Kolkata       52. Manila        60. Pontianak   68. Samarkand      76. Tehran    84. Ust-Nera
</span><span class='line'>  5. Aqtau     13. Barnaul  21. Damascus    29. Hebron       37. Jerusalem  45. Krasnoyarsk   53. Muscat        61. Pyongyang   69. Seoul          77. Tel_Aviv  85. Vientiane
</span><span class='line'>  6. Aqtobe    14. Beirut   22. Dhaka       30. Ho_Chi_Minh  38. Kabul      46. Kuala_Lumpur  54. Nicosia       62. Qatar       70. Shanghai       78. Thimphu   86. Vladivostok
</span><span class='line'>  7. Ashgabat  15. Bishkek  23. Dili        31. Hong_Kong    39. Kamchatka  47. Kuching       55. Novokuznetsk  63. Qostanay    71. Singapore      79. Tokyo     87. Yakutsk
</span><span class='line'>  8. Atyrau    16. Brunei   24. Dubai       32. Hovd         40. Karachi    48. Kuwait        56. Novosibirsk   64. Qyzylorda   72. Srednekolymsk  80. Tomsk     88. Yangon
</span><span class='line'>Time zone: 70
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>Current default time zone: 'Asia/Shanghai'
</span><span class='line'>Local time is now:      Tue Jan 16 02:00:49 CST 2024.
</span><span class='line'>Universal Time is now:  Mon Jan 15 18:00:49 UTC 2024.
</span><span class='line'>Run 'dpkg-reconfigure tzdata' if you wish to change it.
</span><span class='line'>
</span><span class='line'>Setting up libxcb-present0:amd64 (1.14-2) ...
</span><span class='line'>Setting up libglib2.0-data (2.64.6-1~ubuntu20.04.6) ...
</span><span class='line'>Setting up libslang2:amd64 (2.3.2-4) ...
</span><span class='line'>....
</span><span class='line'>Setting up libavdevice58:amd64 (7:4.2.7-0ubuntu0.1) ...
</span><span class='line'>Setting up ffmpeg (7:4.2.7-0ubuntu0.1) ...
</span><span class='line'>Processing triggers for libc-bin (2.31-0ubuntu9.12) ...
</span><span class='line'>/sbin/ldconfig.real: /lib/x86_64-linux-gnu/libcudadebugger.so.1 is not a symbolic link
</span><span class='line'>
</span><span class='line'>/sbin/ldconfig.real: /lib/x86_64-linux-gnu/libcuda.so.1 is not a symbolic link
</span><span class='line'>
</span><span class='line'>Processing triggers for libgdk-pixbuf2.0-0:amd64 (2.40.0+dfsg-3ubuntu0.4) ...
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#@@ 改改改：1 可以root跑，2 直接用当前项目，下载没带.git， 3 使用conda管理环境
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# diff -u webui.sh.back  webui.sh
</span><span class='line'>--- webui.sh.back       2024-01-16 02:10:15.775277218 +0800
</span><span class='line'>+++ webui.sh    2024-01-16 02:41:22.748823781 +0800
</span><span class='line'>@@ -64,23 +64,23 @@
</span><span class='line'> if [[ $(id -u) -eq 0 ]]
</span><span class='line'> then
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    printf "\e[1m\e[31mERROR: This script must not be launched as root, aborting...\e[0m"
</span><span class='line'>-    printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    exit 1
</span><span class='line'>+#    printf "\e[1m\e[31mERROR: This script must not be launched as root, aborting...\e[0m"
</span><span class='line'>+#    printf "\n%s\n" "${delimiter}"
</span><span class='line'>+#    exit 1
</span><span class='line'> else
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'>     printf "Running on \e[1m\e[32m%s\e[0m user" "$(whoami)"
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'> fi
</span><span class='line'> 
</span><span class='line'>-if [[ -d .git ]]
</span><span class='line'>-then
</span><span class='line'>+#if [[ -d .git ]]
</span><span class='line'>+#then
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'>     printf "Repo already cloned, using it as install directory"
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'>     install_dir="${PWD}/../"
</span><span class='line'>     clone_dir="${PWD##*/}"
</span><span class='line'>-fi
</span><span class='line'>+#fi
</span><span class='line'>
</span><span class='line'> # Check prerequisites
</span><span class='line'> for preq in "${GIT}" "${python_cmd}"
</span><span class='line'>@@ -120,19 +120,20 @@
</span><span class='line'> cd "${install_dir}"/"${clone_dir}"/ || { printf "\e[1m\e[31mERROR: Can't cd to %s/%s/, aborting...\e[0m" "${install_dir}" "${clone_dir}"; exit 1; }
</span><span class='line'> if [[ ! -d "${venv_dir}" ]]
</span><span class='line'> then
</span><span class='line'>-    "${python_cmd}" -m venv "${venv_dir}"
</span><span class='line'>+#    "${python_cmd}" -m venv "${venv_dir}"
</span><span class='line'>+    mkdir -p "${venv_dir}"
</span><span class='line'>     first_launch=1
</span><span class='line'> fi
</span><span class='line'> # shellcheck source=/dev/null
</span><span class='line'>-if [[ -f "${venv_dir}"/bin/activate ]]
</span><span class='line'>-then
</span><span class='line'>-    source "${venv_dir}"/bin/activate
</span><span class='line'>-else
</span><span class='line'>-    printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    printf "\e[1m\e[31mERROR: Cannot activate python venv, aborting...\e[0m"
</span><span class='line'>-    printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    exit 1
</span><span class='line'>-fi
</span><span class='line'>+#if [[ -f "${venv_dir}"/bin/activate ]]
</span><span class='line'>+#then
</span><span class='line'>+#    source "${venv_dir}"/bin/activate
</span><span class='line'>+#else
</span><span class='line'>+#    printf "\n%s\n" "${delimiter}"
</span><span class='line'>+#    printf "\e[1m\e[31mERROR: Cannot activate python venv, aborting...\e[0m"
</span><span class='line'>+#    printf "\n%s\n" "${delimiter}"
</span><span class='line'>+#    exit 1
</span><span class='line'>+#fi
</span><span class='line'>
</span><span class='line'> printf "\n%s\n" "${delimiter}"
</span><span class='line'> printf "Launching launch.py..."
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# export HTTPS_PROXY=socks5://172.22.240.1:23333
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# bash webui.sh
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Install script for stable-diffusion + Web UI
</span><span class='line'>Tested on Debian 11 (Bullseye)
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Repo already cloned, using it as install directory
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Launching launch.py...
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Python 3.9.18 (main, Sep 11 2023, 13:41:44) 
</span><span class='line'>[GCC 11.2.0]
</span><span class='line'>Commit hash: &lt;none&gt;
</span><span class='line'>Installing torch and torchvision
</span><span class='line'>Installing gfpgan
</span><span class='line'>Installing clip
</span><span class='line'>Cloning Stable Diffusion into repositories/stable-diffusion...
</span><span class='line'>Cloning Taming Transformers into repositories/taming-transformers...
</span><span class='line'>Cloning K-diffusion into repositories/k-diffusion...
</span><span class='line'>Cloning CodeFormer into repositories/CodeFormer...
</span><span class='line'>Cloning BLIP into repositories/BLIP...
</span><span class='line'>Installing requirements for CodeFormer
</span><span class='line'>Installing requirements for Web UI
</span><span class='line'>repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/feature_extractor/preprocessor_config.json | File missing.
</span><span class='line'>repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 does not exist or file is missing. (1)Do you want to redownload the Taiyi model? Or (2)move your downloaded Taiyi model path? 1/2: 2
</span><span class='line'>
</span><span class='line'>Detection failed, please reconfirm that the model has been moved to: repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1
</span><span class='line'>Please move the Taiyi model to: repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1. Completed? y: y
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>???
</span><span class='line'>  File "/root/miniconda3/envs/py39/lib/python3.9/site-packages/httpx/_transports/default.py", line 275, in __init__
</span><span class='line'>    self._pool = httpcore.AsyncConnectionPool(
</span><span class='line'>TypeError: __init__() got an unexpected keyword argument 'socket_options'
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13236
</span><span class='line'>
</span><span class='line'>#pip install -U httpcore
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# pip3 install httpx==0.24.1
</span><span class='line'>
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# unset all_proxy && unset ALL_PROXY && unset https_proxy && unset HTTPS_PROXY && unset http_proxy && unset HTTP_PROXY
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# bash webui.sh
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>???
</span><span class='line'>ImportError: cannot import name '_compare_version' from 'torchmetrics.utilities.imports' (/root/miniconda3/envs/py39/lib/python3.9/site-packages/torchmetrics/utilities/imports.py)    
</span><span class='line'>
</span><span class='line'>#https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/11648
</span><span class='line'>#conda list torchmetrics
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# conda install --force-reinstall torchmetrics==0.11.4
</span><span class='line'>
</span><span class='line'>pip install torchmetrics==0.11.4 torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>???
</span><span class='line'>
</span><span class='line'>export COMMANDLINE_ARGS="--lowvram --precision full --no-half --skip-torch-cuda-test"
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>???
</span><span class='line'>RuntimeError: Cannot add middleware after an application has started
</span><span class='line'>
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# pip install fastapi==0.90.1
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>@@终于启动了
</span><span class='line'>(py39) root@41af85cb0007:/opt/stable-diffusion-webui# bash webui.sh
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Install script for stable-diffusion + Web UI
</span><span class='line'>Tested on Debian 11 (Bullseye)
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Repo already cloned, using it as install directory
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Create and activate python venv
</span><span class='line'>################################################################
</span><span class='line'>
</span><span class='line'>################################################################
</span><span class='line'>Launching launch.py...
</span><span class='line'>################################################################
</span><span class='line'>Python 3.9.18 (main, Sep 11 2023, 13:41:44)
</span><span class='line'>[GCC 11.2.0]
</span><span class='line'>Commit hash: &lt;none&gt;
</span><span class='line'>Installing requirements for Web UI
</span><span class='line'>Obtaining file:///opt/stable-diffusion-webui
</span><span class='line'>ERROR: file:///opt/stable-diffusion-webui does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.
</span><span class='line'>Launching Web UI with arguments: --lowvram --precision full --no-half --ckpt /opt/stable-diffusion-webui/repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/Taiyi-Stable-Diffusion-1B-Chinese-v0.1.ckpt --listen --port 12345
</span><span class='line'>LatentDiffusion: Running in eps-prediction mode
</span><span class='line'>DiffusionWrapper has 859.52 M params.
</span><span class='line'>making attention of type 'vanilla' with 512 in_channels
</span><span class='line'>Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
</span><span class='line'>making attention of type 'vanilla' with 512 in_channels
</span><span class='line'>Loading weights [e2e75020] from /opt/stable-diffusion-webui/repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/Taiyi-Stable-Diffusion-1B-Chinese-v0.1.ckpt
</span><span class='line'>Applying cross attention optimization (Doggettx).
</span><span class='line'>Model loaded.
</span><span class='line'>Loaded a total of 0 textual inversion embeddings.
</span><span class='line'>Embeddings:
</span><span class='line'>Running on local URL:  http://0.0.0.0:12345
</span><span class='line'>
</span><span class='line'>To create a public link, set `share=True` in `launch()`.
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>启动镜像的时刻忘了挂数据U盘了，直接全部拷贝到容器里面：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) root@41af85cb0007:/opt/stable-diffusion-webui/repositories# mkdir Taiyi-Stable-Diffusion-1B-Chinese-v0.1 
</span><span class='line'>
</span><span class='line'>#(base) winse@DESKTOP-BR4MG38:Taiyi-Stable-Diffusion-1B-Chinese-v0.1$ tar tf 1.tar * 
</span><span class='line'>#(base) winse@DESKTOP-BR4MG38:Taiyi-Stable-Diffusion-1B-Chinese-v0.1$ docker cp 1.tar 41af85cb0007:/opt/stable-diffusion-webui/repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/
</span><span class='line'>
</span><span class='line'>(base) root@41af85cb0007:/opt/stable-diffusion-webui/repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1# tar xf 1.tar 
</span><span class='line'>(base) root@41af85cb0007:/opt/stable-diffusion-webui/repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1# rm -rf 1.tar 
</span><span class='line'>(base) root@41af85cb0007:/opt/stable-diffusion-webui/repositories/Taiyi-Stable-Diffusion-1B-Chinese-v0.1# ll
</span><span class='line'>total 4084196
</span><span class='line'>drwxr-xr-x 9 root  root        4096 Jan 15 17:57 ./
</span><span class='line'>drwxrwxr-x 9 root  root        4096 Jan 15 17:42 ../
</span><span class='line'>-rwxrwxrwx 1 webui webui 4182159787 Jan 15 00:26 Taiyi-Stable-Diffusion-1B-Chinese-v0.1.ckpt*
</span><span class='line'>-rwxrwxrwx 1 webui webui        146 Jan 15 00:19 configuration.json*
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 feature_extractor/
</span><span class='line'>-rwxrwxrwx 1 webui webui        539 Jan 15 00:22 model_index.json*
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 safety_checker/
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 scheduler/
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 text_encoder/
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 tokenizer/
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 unet/
</span><span class='line'>drwxrwxrwx 2 webui webui       4096 Jan 15 17:50 vae/
</span></code></pre></td></tr></table></div></figure>


<h2>太乙webui - 纯净版</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:P15$ cat /etc/os-release 
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:P15$ cat /etc/issue
</span><span class='line'>Ubuntu 20.04.6 LTS \n \l
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:P15$ nvidia-smi
</span><span class='line'>Tue Jan 16 07:09:11 2024       
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| NVIDIA-SMI 535.146.01             Driver Version: 537.99       CUDA Version: 12.2     |
</span><span class='line'>|-----------------------------------------+----------------------+----------------------+
</span><span class='line'>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
</span><span class='line'>| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
</span><span class='line'>|                                         |                      |               MIG M. |
</span><span class='line'>|=========================================+======================+======================|
</span><span class='line'>|   0  Quadro T2000                   On  | 00000000:01:00.0  On |                  N/A |
</span><span class='line'>| N/A   50C    P8               4W /  60W |    537MiB /  4096MiB |      1%      Default |
</span><span class='line'>|                                         |                      |                  N/A |
</span><span class='line'>+-----------------------------------------+----------------------+----------------------+
</span><span class='line'>
</span><span class='line'>+---------------------------------------------------------------------------------------+
</span><span class='line'>| Processes:                                                                            |
</span><span class='line'>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
</span><span class='line'>|        ID   ID                                                             Usage      |
</span><span class='line'>|=======================================================================================|
</span><span class='line'>|    0   N/A  N/A        32      G   /Xwayland                                 N/A      |
</span><span class='line'>|    0   N/A  N/A        39      G   /Xwayland                                 N/A      |
</span><span class='line'>|    0   N/A  N/A        41      G   /Xwayland                                 N/A      |
</span><span class='line'>+---------------------------------------------------------------------------------------+</span></code></pre></td></tr></table></div></figure>


<p>选一个跟我现在用的环境一样的版本和系统：<a href="https://hub.docker.com/r/nvidia/cuda/tags">https://hub.docker.com/r/nvidia/cuda/tags</a> CUDA and cuDNN images from gitlab.com/nvidia/cuda</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(base) winse@DESKTOP-BR4MG38:P15$ docker pull nvidia/cuda:12.2.2-devel-ubuntu20.04
</span><span class='line'>
</span><span class='line'>(base) winse@DESKTOP-BR4MG38:P15$ docker run --gpus all --ipc host --ulimit memlock=-1 --ulimit stack=67108864 -it -v /mnt/i/ai:/app/stabilityai -p 7860:7860 docker.io/nvidia/cuda:12.2.2-devel-ubuntu20.04
</span><span class='line'>
</span><span class='line'>root@c65a73d918b1:/# sed -i.bak -e 's|archive.ubuntu.com/ubuntu/|mirrors.tuna.tsinghua.edu.cn/ubuntu/|' -e 's|security.ubuntu.com/ubuntu/|mirrors.tuna.tsinghua.edu.cn/ubuntu/|' /etc/apt/sources.list
</span><span class='line'>root@c65a73d918b1:/# apt update 
</span><span class='line'>
</span><span class='line'>root@c65a73d918b1:/# apt install -y git wget vim
</span><span class='line'>
</span><span class='line'>root@c65a73d918b1:/# cd 
</span><span class='line'>root@c65a73d918b1:~# wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
</span><span class='line'>root@c65a73d918b1:~# bash Miniconda3-latest-Linux-x86_64.sh -b -u                
</span><span class='line'>root@c65a73d918b1:~# ~/miniconda3/bin/conda init bash
</span><span class='line'>root@c65a73d918b1:~# source ~/.bashrc
</span><span class='line'>(base) root@c65a73d918b1:~# 
</span><span class='line'>
</span><span class='line'>(base) root@c65a73d918b1:~# wget -c https://github.com/IDEA-CCNL/stable-diffusion-webui/archive/refs/heads/master.tar.gz -O - | tar zxf - 
</span><span class='line'>(base) root@c65a73d918b1:~# mv stable-diffusion-webui-master stable-diffusion-webui        
</span><span class='line'>
</span><span class='line'>(base) root@c65a73d918b1:~# cd stable-diffusion-webui
</span><span class='line'>(base) root@c65a73d918b1:~/stable-diffusion-webui# conda create -n py3.10 python=3.10
</span><span class='line'>(base) root@c65a73d918b1:~/stable-diffusion-webui# conda activate py3.10
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# mkdir .git 
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# diff -u webui.sh.back  webui.sh 
</span><span class='line'>--- webui.sh.back       2024-01-15 23:39:24.271256229 +0000
</span><span class='line'>+++ webui.sh    2024-01-15 23:42:17.070404354 +0000
</span><span class='line'>@@ -64,9 +64,6 @@
</span><span class='line'> if [[ $(id -u) -eq 0 ]]
</span><span class='line'> then
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    printf "\e[1m\e[31mERROR: This script must not be launched as root, aborting...\e[0m"
</span><span class='line'>-    printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    exit 1
</span><span class='line'> else
</span><span class='line'>     printf "\n%s\n" "${delimiter}"
</span><span class='line'>     printf "Running on \e[1m\e[32m%s\e[0m user" "$(whoami)"
</span><span class='line'>@@ -120,19 +117,11 @@
</span><span class='line'> cd "${install_dir}"/"${clone_dir}"/ || { printf "\e[1m\e[31mERROR: Can't cd to %s/%s/, aborting...\e[0m" "${install_dir}" "${clone_dir}"; exit 1; }
</span><span class='line'> if [[ ! -d "${venv_dir}" ]]
</span><span class='line'> then
</span><span class='line'>-    "${python_cmd}" -m venv "${venv_dir}"
</span><span class='line'>+#    "${python_cmd}" -m venv "${venv_dir}"
</span><span class='line'>+    mkdir -p "${venv_dir}"
</span><span class='line'>     first_launch=1
</span><span class='line'> fi
</span><span class='line'> # shellcheck source=/dev/null
</span><span class='line'>-if [[ -f "${venv_dir}"/bin/activate ]]
</span><span class='line'>-then
</span><span class='line'>-    source "${venv_dir}"/bin/activate
</span><span class='line'>-else
</span><span class='line'>-    printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    printf "\e[1m\e[31mERROR: Cannot activate python venv, aborting...\e[0m"
</span><span class='line'>-    printf "\n%s\n" "${delimiter}"
</span><span class='line'>-    exit 1
</span><span class='line'>-fi
</span><span class='line'>
</span><span class='line'> printf "\n%s\n" "${delimiter}"
</span><span class='line'> printf "Launching launch.py..."
</span><span class='line'> 
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# pip install pysocks
</span><span class='line'>
</span><span class='line'>#https://github.com/invoke-ai/InvokeAI/issues/3560#issuecomment-1689474997
</span><span class='line'>#https://blog.csdn.net/shark1357/article/details/131238924
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# pip install tb-nightly -i https://mirrors.aliyun.com/pypi/simple
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# pip install gfpgan==1.3.8
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# apt-get install ffmpeg libsm6 libxext6  -y
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# pip install httpcore httpx==0.24.1 torchmetrics==0.11.4 fastapi==0.90.1
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# vi webui-user.sh
</span><span class='line'>
</span><span class='line'>export COMMANDLINE_ARGS="--lowvram --precision full --no-half --skip-torch-cuda-test"
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~# cd stable-diffusion-webui/repositories/
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui/repositories# ln -s /app/stabilityai/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1/
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui/repositories#  ll Taiyi-Stable-Diffusion-1B-Chinese-v0.1
</span><span class='line'>lrwxrwxrwx 1 root root 69 Jan 16 07:58 Taiyi-Stable-Diffusion-1B-Chinese-v0.1 -&gt; /app/stabilityai/Fengshenbang/Taiyi-Stable-Diffusion-1B-Chinese-v0.1//
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# pip install socksio httpx[socks]
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>#@@ 加代理下载部署时需要的github代码
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# export HTTPS_PROXY=socks5://172.22.240.1:23333
</span><span class='line'>(py3.10) root@c65a73d918b1:~/stable-diffusion-webui# bash webui.sh --port 7860
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>然后在Windows浏览器访问： <a href="http://localhost:7860/">http://localhost:7860/</a></p>

<p><img src="/images/blogs/ai/webui.png" alt="" /></p>

<p><img src="/images/blogs/ai/webui2.png" alt="" /></p>

<h2>TODO</h2>

<p>汉化： <a href="https://github.com/VinsonLaro/stable-diffusion-webui-chinese">https://github.com/VinsonLaro/stable-diffusion-webui-chinese</a></p>

<p>&ndash;END</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Winse Liu</span></span>

      








  


<time datetime="2024-01-15T01:25:22+08:00" pubdate data-updated="true">Mon 2024-01-15 01:25</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/ai/'>ai</a>, <a class='category' href='/blog/categories/wsl/'>wsl</a>
  
</span>


	  <span style="padding: 0 1em;">
<a class="shellExecuteLink" href="npp-windows://e/_posts/2024-01-15-aigc-setup-on-windows-wsl-2.markdown" title="本地编辑"><i class="icon-edit"> </i>编辑</a>
</span>	
    </p>
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2023/11/18/reinstall-redmine-on-respberry2/" title="Previous Post: reinstall redmine on raspberry2">&laquo; reinstall redmine on raspberry2</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
	
	
  
<!-- gitalk评论 start -->
    <div id="gitalk-container"></div> 
<!-- gitalk评论 end -->
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>



</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2024/01/15/aigc-setup-on-windows-wsl-2/">AIGC Setup on Win11 WSL2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/11/18/reinstall-redmine-on-respberry2/">Reinstall Redmine on Raspberry2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/04/09/dingtalk-with-openai/">钉钉群机器人对接ChatGPT</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/26/clash-on-raspberry4/">树莓派4安装Clash</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/25/reinstall-raspberry2/">重新折腾raspberry2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/25/mirror-request/">请求复制/镜像</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/03/18/wechat-on-openai/">微信对接OpenAI</a>
      </li>
    
      <li class="post">
        <a href="/blog/2023/02/01/git-reset-hard/">记git Reset --hard</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

<!-- key -->
	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (68) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/efficity/'>efficity</a> (23) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (16) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (15) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (15) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (13) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blog/'>blog</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/raspberry/'>raspberry</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (237)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
<!--
  <h1>Softs, I'm using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
-->
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2024 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>

<script>

var time=location.pathname.substring(6).substring(0,11);
var eName=location.pathname.substring(17);
var gitalk = new Gitalk({
  clientID: 'c14f68eac6330d15d984',
  clientSecret: '73b7c1fffa98e299ff0cdd332821201933858e6e',
  repo: 'winse.github.com',
  owner: 'winse',
  admin: ['winse'],
  id: eName,
  labels: ['Gitalk', time],
  body: "http://winse.github.io" + location.pathname,
  createIssueManually: true,
  
  // facebook-like distraction free mode
  distractionFreeMode: false
})

gitalk.render('gitalk-container')

</script>



<script>
/*
$.ajax({
  type: "POST",
  url: "http://log.winseliu.com:20000",
  data: JSON.stringify({
    title: document.title,
    location: JSON.stringify(location),
    referrer: document.referrer,
    userAgent: navigator.userAgent
  }),
  contentType: "application/json; charset=utf-8",
  dataType: "json"
});
*/
</script>







  <script type="text/javascript">
  jQuery(document).ready(function() {
    // Put a TOC right before the entry content.
    generateTOC('.entry-content', '目录');
	
	jQuery("#tocBlock").append(jQuery(".toc-icon"))
  });
  </script>


<script type="text/javascript">
    $(function(){  
        $("img").click(function(){  
            var _this = $(this);
			window.open(_this.attr("src"), '_blank');
        });  
    });
</script>

</body>
</html>
