<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tachyon | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/tachyon/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-04-16T20:05:03+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Alluxio入门大全2]]></title>
    <link href="http://winseliu.com/blog/2016/04/15/alluxio-quickstart2/"/>
    <updated>2016-04-15T00:41:12+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/15/alluxio-quickstart2</id>
    <content type="html"><![CDATA[<p>alluxio就是原来的tachyon。老大是华人，文档自然就有福利，把en改成cn就可以查看中文版的文档了。</p>

<p><a href="http://alluxio.org/documentation/master/cn/Architecture.html">http://alluxio.org/documentation/master/cn/Architecture.html</a></p>

<p>注意：docker暂时不能部署alluxio： <strong>mount: permission denied</strong></p>

<p>首先介绍alluxio的编译，然后进行本地和集群两种方式的部署，同时介绍HDFS底层存储系统配置和一些常用命令行的使用，最后通过代码和spark读写Alluxio数据，以及升级到V1.1查看系统的Metrics指标来了解存储系统使用情况。</p>

<h1>编译</h1>

<ul>
<li><a href="http://alluxio.org/documentation/master/en/Building-Alluxio-Master-Branch.html">http://alluxio.org/documentation/master/en/Building-Alluxio-Master-Branch.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Alluxio-Locally.html">http://alluxio.org/documentation/master/en/Running-Alluxio-Locally.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Alluxio-on-a-Cluster.html">http://alluxio.org/documentation/master/en/Running-Alluxio-on-a-Cluster.html</a></li>
</ul>


<pre><code># 下载官网打包的bin.tar.gz。不推荐去github下v1.0.1，编译时findbug检查server有两个bug
http://alluxio.org/downloads/files/1.0.1/alluxio-1.0.1-bin.tar.gz

[hadoop@cu2 ~]$ cd ~/sources/alluxio-1.0.1/
[hadoop@cu2 alluxio-1.0.1]$ export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"
[hadoop@cu2 alluxio-1.0.1]$ mvn clean package assembly:single -Phadoop-2.6 -Dhadoop.version=2.6.3 -Pyarn,spark -Dmaven.test.skip=true -Dmaven.javadoc.skip=true
</code></pre>

<p>编译成功后会生成 assembly/target/alluxio-1.0.1.tar.gz 文件。部署的时刻直接用编译好的 tar.gz 就行了，内容比较简洁和清晰。</p>

<p>还有一个问题，不要加Profile <strong>compileJsp</strong> ，编译没问题但是部署后访问网页抛 ClassNotFound 异常。</p>

<h1>Local部署配置</h1>

<p><a href="http://alluxio.org/documentation/master/cn/Running-Alluxio-Locally.html">http://alluxio.org/documentation/master/cn/Running-Alluxio-Locally.html</a></p>

<pre><code>[hadoop@hadoop-master2 ~]$ tar zxf alluxio-1.0.1.tar.gz  
[hadoop@hadoop-master2 ~]$ cd alluxio-1.0.1/conf/
[hadoop@hadoop-master2 conf]$ cp alluxio-env.sh.template alluxio-env.sh
[hadoop@hadoop-master2 conf]$ vi alluxio-env.sh
...
JAVA_HOME=/opt/jdk1.7.0_60
ALLUXIO_UNDERFS_ADDRESS=/home/hadoop/tmp

[hadoop@hadoop-master2 conf]$ cd ..
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
Connecting to localhost as hadoop...
Formatting Alluxio Worker @ hadoop-master2
Connection to localhost closed.
Formatting Alluxio Master @ localhost
[hadoop@hadoop-master2 alluxio-1.0.1]$ 

# 把hadoop用户加入sudo
[root@hadoop-master2 ~]# visudo 
...
hadoop        ALL=(ALL)       NOPASSWD: ALL

# 机器原来部署过hadoop，localhost已经可以无密钥登录。

# 启动
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh local
Killed 0 processes on hadoop-master2
Killed 0 processes on hadoop-master2
Connecting to localhost as hadoop...
Killed 0 processes on hadoop-master2
Connection to localhost closed.
Formatting RamFS: /mnt/ramdisk (1gb)
Starting master @ localhost. Logging to /home/hadoop/alluxio-1.0.1/logs
Starting worker @ hadoop-master2. Logging to /home/hadoop/alluxio-1.0.1/logs
[hadoop@hadoop-master2 alluxio-1.0.1]$ 
[hadoop@hadoop-master2 alluxio-1.0.1]$ jps
3780 AlluxioMaster
3845 Jps
3807 AlluxioWorker

# localhost:19999 通过web页查看集群状态

# 关闭
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-stop.sh all
Killed 1 processes on hadoop-master2
Killed 1 processes on hadoop-master2
Connecting to localhost as hadoop...
Killed 0 processes on hadoop-master2
Connection to localhost closed.
</code></pre>

<p>这里完全安装官网的步骤来弄，正式环境的时刻可以用 root 来 mount 内存盘。下面集群部署再介绍。</p>

<p><img src="images/blogs/alluxio-local.png" alt="" /></p>

<h1>集群部署</h1>

<ul>
<li><a href="http://alluxio.org/documentation/master/cn/Running-Alluxio-on-a-Cluster.html">http://alluxio.org/documentation/master/cn/Running-Alluxio-on-a-Cluster.html</a></li>
<li>HA <a href="http://alluxio.org/documentation/master/en/Running-Alluxio-Fault-Tolerant.html">http://alluxio.org/documentation/master/en/Running-Alluxio-Fault-Tolerant.html</a></li>
</ul>


<p>步骤和Local类似。把程序部署到workers节点，所有workers节点都 mount 内存盘，然后调用 start.sh 。</p>

<pre><code># master 和 workers 的无密钥登录。部署过apache-hadoop的肯定都已经弄过了

# 修改配置
[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/workers 
bigdata1
[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/alluxio-env.sh
ALLUXIO_MASTER_ADDRESS=hadoop-master2

# 部署程序
# bin/alluxio copyDir &lt;!-- &lt;dirname&gt; --&gt; 慎用，会把logs目录也同步过去的，
# 当然可以修改alluxio的脚本，反正要知道脚本的作用
[hadoop@hadoop-master2 ~]$ rsync -az alluxio-1.0.1 bigdata1:~/ --exclude=logs --exclude=/*/src --exclude=underfs --exclude=journal

# 使用root用户挂载(workers)节点的内存盘
[root@hadoop-master2 ~]# cd /home/hadoop/alluxio-1.0.1
[root@hadoop-master2 alluxio-1.0.1]# bin/alluxio-mount.sh Mount workers
Connecting to bigdata1 as root...
Warning: Permanently added 'bigdata1,192.168.191.133' (RSA) to the list of known hosts.
Formatting RamFS: /mnt/ramdisk (1gb)
Connection to bigdata1 closed.

# worker节点确认
[hadoop@bigdata1 ~]$ mount
/dev/mapper/VolGroup-lv_root on / type ext4 (rw)
proc on /proc type proc (rw)
sysfs on /sys type sysfs (rw)
devpts on /dev/pts type devpts (rw,gid=5,mode=620)
tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
/dev/sda1 on /boot type ext4 (rw)
none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
ramfs on /mnt/ramdisk type ramfs (rw,size=1gb)

# 格式化：主要是清理/创建JOURNAL目录，清理workers本地缓存(tiered-storage)目录数据
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
Connecting to bigdata1 as hadoop...
Formatting Alluxio Worker @ bigdata1
Connection to bigdata1 closed.
Formatting Alluxio Master @ localhost

# 启动
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh all NoMount
Killed 1 processes on hadoop-master2
Killed 1 processes on hadoop-master2
Connecting to bigdata1 as hadoop...
Killed 0 processes on bigdata1
Connection to bigdata1 closed.
Starting master @ localhost. Logging to /home/hadoop/alluxio-1.0.1/logs
Connecting to bigdata1 as hadoop...
Starting worker @ bigdata1. Logging to /home/hadoop/alluxio-1.0.1/logs
Connection to bigdata1 closed.
[hadoop@hadoop-master2 alluxio-1.0.1]$ jps
5164 AlluxioMaster
5219 Jps

[hadoop@bigdata1 alluxio-1.0.1]$ jps
1849 Jps
1829 AlluxioWorker
</code></pre>

<p>通过网页查看，如果 <strong>Running Workers</strong> 为 <strong>0</strong> ，到workers节点 alluxio-1.0.1/logs 下面去看日志然后定位问题。防火墙没开放？还是其他配置不正确，如hosts等等。</p>

<h1>命令行HelloWorld</h1>

<pre><code>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs copyFromLocal conf/alluxio-env.sh /
Copied conf/alluxio-env.sh to /

# worker节点查看内容（当前只有这一个文件啊，查看方便），block-id可以通过网页或者 fs fileInfo查看
[hadoop@bigdata1 alluxio-1.0.1]$ tail -1 /mnt/ramdisk/alluxioworker/117440512 
export ALLUXIO_WORKER_JAVA_OPTS="${ALLUXIO_JAVA_OPTS}"


# 在master机器上调用 persist ，在worker节点没找到对应的数据。竟然直接存储在执行命令的节点了，囧！！！
# alluxio.client.file.FileSystemUtils#persistFile
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs persist /alluxio-env.sh
persisted file /alluxio-env.sh with size 5493
[hadoop@hadoop-master2 alluxio-1.0.1]$ ll /home/hadoop/tmp/
total 28
-rwxrwxrwx  1 hadoop hadoop 5493 Apr 15 03:33 alluxio-env.sh

[hadoop@bigdata1 alluxio-1.0.1]$ bin/alluxio fs persist /alluxio-env.sh
/alluxio-env.sh is already persisted
[hadoop@bigdata1 alluxio-1.0.1]$ ll /home/hadoop/tmp
总用量 0
</code></pre>

<p>在master调用 persist 后，再在worker节点调用 persist 竟然提示 <strong>already persisted</strong> 了。如果在分布式的情况下，本地磁盘 <strong>不适合</strong> 用于做 underfs ！！官网也是说 <strong>单节点</strong> <strong>本地文件系统</strong>。</p>

<blockquote><p>Alluxio提供了通用接口以简化插入不同的底层存储系统。目前我们支持Amazon S3，OpenStack Swift，Apache HDFS，GlusterFS以及单节点本地文件系统</p></blockquote>

<h1>使用HDFS作为底层存储</h1>

<p><a href="http://alluxio.org/documentation/master/en/Configuring-Alluxio-with-HDFS.html">http://alluxio.org/documentation/master/en/Configuring-Alluxio-with-HDFS.html</a></p>

<pre><code>[hadoop@hadoop-master2 alluxio-1.0.1]$ vi conf/alluxio-env.sh
...
JAVA_HOME=/opt/jdk1.7.0_60
HADOOP_HOME=/home/hadoop/hadoop-2.6.3
# source $HADOOP_HOME/libexec/hadoop-config.sh

ALLUXIO_CLASSPATH=$HADOOP_HOME/etc/hadoop:$ALLUXIO_CLASSPATH
ALLUXIO_UNDERFS_ADDRESS=hdfs:///alluxio                       # 配置一个alluxio子路径比较好管理
ALLUXIO_MASTER_ADDRESS=hadoop-master2

# 清理/创建元数据目录和workers节点本地缓冲存储的数据
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio format
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh master

# master启动正常后，启动workers节点
# 上面已经用root mount了内存盘了，没有的用root执行 bin/alluxio-mount.sh Mount workers
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio-start.sh workers NoMount
</code></pre>

<ul>
<li>使用</li>
</ul>


<p><a href="http://alluxio.org/documentation/master/en/Command-Line-Interface.html">http://alluxio.org/documentation/master/en/Command-Line-Interface.html</a></p>

<pre><code>[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs copyFromLocal  ~/hadoop-2.6.3/README.txt /
Copied /home/hadoop/hadoop-2.6.3/README.txt to /
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /
1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs location /README.txt
/README.txt with file id 33554431 is on nodes: 
bigdata1

[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs persist /README.txt
/README.txt is already persisted

# 默认文件只写到 Cache ，可以修改配置来进行修改
# alluxio.client.WriteType
[hadoop@hadoop-master2 alluxio]$ export ALLUXIO_JAVA_OPTS="-Dalluxio.user.file.writetype.default=CACHE_THROUGH"
[hadoop@hadoop-master2 alluxio]$ bin/alluxio fs copyFromLocal ~/hadoop-2.6.3/README.txt /                      
Copied /home/hadoop/hadoop-2.6.3/README.txt to /
[hadoop@hadoop-master2 alluxio]$ bin/alluxio fs fileInfo /README.txt                                           
FileInfo{fileId=452984831, name=README.txt, path=/README.txt, ufsPath=hdfs:///alluxio/README.txt, length=1366, blockSizeBytes=536870912, creationTimeMs=1460765370996, completed=true, folder=false, pinned=false, cacheable=true, persisted=true, blockIds=[436207616], inMemoryPercentage=100, lastModificationTimesMs=1460765372423, ttl=-1, userName=, groupName=, permission=0, persistenceState=PERSISTED, mountPoint=false}
Containing the following blocks: 
BlockInfo{id=436207616, length=1366, locations=[BlockLocation{workerId=1, address=WorkerNetAddress{host=bigdata1, rpcPort=29998, dataPort=29999, webPort=30000}, tierAlias=MEM}]}

# Creates a 0 byte file. The file will be written to the under file system. 
# For example, touch can be used to create a file signifying the compeletion of analysis on a directory.
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs touch /1234.txt    
/1234.txt has been created

# 已经persist的文件，重命名后，hdfs上面的文件也立即改变了
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs mv /1234.txt /4321.txt
Renamed /1234.txt to /4321.txt

# 空文件没有分配实际的存储，只有元数据
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs location /4321.txt    
/4321.txt with file id 67108863 is on nodes: 

# free掉memory，然后删掉underfs目录下的文件
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs free /
/ was successfully freed from memory.
[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs dfs -rmr /alluxio/*

[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /  
1366.00B  04-15-2016 09:30:45:829  Not In Memory  /README.txt
0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs tail /README.txt
File does not exist: /alluxio/README.txt
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:66)
        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1893)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1834)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1814)

# 按照文件名把 README.txt 放到 underfs 目录下面
[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs dfs -put *.txt /alluxio/ 
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs tail /README.txt
...
software:
  Hadoop Core uses the SSL libraries from the Jetty project written 
by mortbay.org.

# 数据载入内存
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs load /
/README.txt loaded
/ loaded
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /  
1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt

# 载入underfs的目录结构
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio loadufs / hdfs:///alluxio 
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /
1366.00B  04-15-2016 09:30:45:829  In Memory      /README.txt
0.00B     04-15-2016 09:37:48:971  In Memory      /4321.txt
15.07KB   04-15-2016 10:12:33:176  Not In Memory  /LICENSE.txt
101.00B   04-15-2016 10:12:33:190  Not In Memory  /NOTICE.txt

# 通过 fileInfo 查看信息； fileId, ufsPath, 和分区blocks信息
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs fileInfo /README.txt

# 通配符要这么写，也是醉鸟
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs rm /\\*
/4321.txt has been removed
/LICENSE.txt has been removed
/NOTICE.txt has been removed
/README.md has been removed
/README.txt has been removed

# alluxio系统中没有的文件，但是underfs包括的文件，读取一遍后元数据会载入alluxio
[hadoop@hadoop-master2 ~]$ alluxio fs ls /
1366.00B  04-16-2016 08:09:30:996  In Memory      /README.txt
[hadoop@hadoop-master2 ~]$ alluxio fs cat /LICENSE.txt
[hadoop@hadoop-master2 ~]$ alluxio fs ls /
1366.00B  04-16-2016 08:09:30:996  In Memory      /README.txt
15.07KB   04-16-2016 08:26:22:495  Not In Memory  /LICENSE.txt
</code></pre>

<p>文件结构大概搞明白了，从 underfs 加载目录结构(loadufs)，文件载入alluxio内存(fs load)，alluxio文件持久化(fs persist)都有对应的命令。
理解 <a href="http://alluxio.org/documentation/master/en/Unified-and-Transparent-Namespace.html">mount</a> 和linux的mount类似，把 underfs 当做一个硬盘设备去理解。</p>

<p>但是好像没有修改文件的API，难道不支持修改？？暂时好像没有(2016-4-15 23:06:20 v1.1)</p>

<blockquote><p><a href="http://alluxio.org/documentation/master/en/Key-Value-System-API.html">http://alluxio.org/documentation/master/en/Key-Value-System-API.html</a>
Like files in Alluxio filesystem, the semantics of key-value system are also write-once</p></blockquote>

<h1>FileSystem API</h1>

<ul>
<li><a href="http://docs.scala-lang.org/tutorials/scala-with-maven.html">http://docs.scala-lang.org/tutorials/scala-with-maven.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/File-System-API.html">http://alluxio.org/documentation/master/en/File-System-API.html</a></li>
</ul>


<pre><code># scala
object App {

  def using[A &lt;: {def close() : Unit}, B](resource: A)(f: A =&gt; B): B =
    try { f(resource) } finally { resource.close() }

  def main(args: Array[String]) {
    // @see alluxio.Configuration.Configuration(boolean)
    System.setProperty(Constants.MASTER_HOSTNAME, "192.168.191.132")
    System.setProperty("HADOOP_USER_NAME", "hadoop")

    val fs = FileSystem.Factory.get();
    val path = new AlluxioURI("/README.md");
    using(fs.createFile(path, CreateFileOptions.defaults().setWriteType(WriteType.THROUGH))){ out =&gt;
      val content =
"""FileSystem API Write.
   -------------------------
   Hello World!
"""
      out.write(content.getBytes)
    }

    using(fs.openFile(path)) { in =&gt;
      val buffer = new Array[Byte](1024)
      val size = in.read(buffer)
      System.out.println(new String(buffer, 0, size))
    }
  }
}

# THROUGH 仅写入到underfs
[hadoop@hadoop-master2 alluxio-1.0.1]$ bin/alluxio fs ls /README.md
115.00B   04-15-2016 20:36:57:345  Not In Memory  /README.md
[hadoop@hadoop-master2 alluxio-1.0.1]$ ~/hadoop-2.6.3/bin/hadoop fs -cat /alluxio/README.md
FileSystem API Write.
   -------------------------
   Hello World!
[hadoop@hadoop-master2 alluxio-1.0.1]$ 
</code></pre>

<p>程序在win10系统运行，需要把 core-site.xml 加到 src/main/resources 下面（前面配置为了省事直接写 <strong>hdfs:///alluxio</strong>, 不加载配置的话程序不知道namenode）</p>

<p>如果<strong>把WriteType设置为 CACHE_THROUGH ，写 underfs 的同时也会写本地缓存</strong>。提交成功后，文件的状态为：</p>

<pre><code>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs ls /README.md
115.00B   04-15-2016 23:48:33:749  In Memory      /README.md
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs fileInfo /README.md
FileInfo{fileId=318767103, name=README.md, path=/README.md, ufsPath=hdfs:///alluxio/README.md, length=115, blockSizeBytes=536870912, creationTimeMs=1460735313749, completed=true, folder=false, pinned=false, cacheable=true, persisted=true, blockIds=[301989888], inMemoryPercentage=100, lastModificationTimesMs=1460735315749, ttl=-1, userName=, groupName=, permission=0, persistenceState=PERSISTED, mountPoint=false}
Containing the following blocks: 
BlockInfo{id=301989888, length=115, locations=[BlockLocation{workerId=1, address=WorkerNetAddress{host=bigdata1, rpcPort=29998, dataPort=29999, webPort=30000}, tierAlias=MEM}]}
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ ~/hadoop-2.6.3/bin/hadoop fs -ls /alluxio/ 
Found 4 items
-rw-r--r--   1 hadoop supergroup      15429 2016-04-15 09:57 /alluxio/LICENSE.txt
-rw-r--r--   1 hadoop supergroup        101 2016-04-15 09:57 /alluxio/NOTICE.txt
-rwxrwxrwx   1 hadoop supergroup        115 2016-04-15 23:48 /alluxio/README.md
</code></pre>

<h1>大数据程序中使用Alluxio</h1>

<p>hadoop2通过 <code>org.apache.hadoop.fs.FileSystem</code> services获取绑定的对象，所以<strong>不需要</strong>在core-site.xml里面配置 <strong>fs.alluxio.impl</strong> 和 <strong>fs.alluxio-ft.impl</strong></p>

<ul>
<li><a href="http://alluxio.org/documentation/master/en/Running-Spark-on-Alluxio.html">http://alluxio.org/documentation/master/en/Running-Spark-on-Alluxio.html</a></li>
<li><a href="http://alluxio.org/documentation/master/en/Running-Hadoop-MapReduce-on-Alluxio.html">http://alluxio.org/documentation/master/en/Running-Hadoop-MapReduce-on-Alluxio.html</a></li>
</ul>


<p>其实都是通过 <strong>Hadoop FileSystem API</strong> 来访问Alluxio的。</p>

<pre><code># .bash_profile加环境变量
[hadoop@hadoop-master2 ~]$ vi ~/.bash_profile 
...
HADOOP_HOME=~/hadoop
SPARK_HOME=~/spark
ALLUXIO_HOME=~/alluxio

PATH=$HADOOP_HOME/bin:$SPARK_HOME/bin:$ALLUXIO_HOME/bin:$MAVEN_HOME/bin:$ANT_HOME/bin:$PATH
# 这里没有 export HADOOP_HOME SPARK_HOME 
# 因为在hadoop/spark的启动脚本也定义了这些变量。如果export，也需要把软链接同步到slaves节点
export PATH ANT_HOME MAVEN_HOME

[hadoop@hadoop-master2 ~]$ ln -s hadoop-2.6.3 hadoop
[hadoop@hadoop-master2 ~]$ ln -s alluxio-1.1.0-SNAPSHOT alluxio
[hadoop@hadoop-master2 ~]$ ln -s spark-1.6.0-bin-2.6.3 spark
[hadoop@hadoop-master2 ~]$ . .bash_profile 

[hadoop@hadoop-master2 ~]$ export SPARK_CLASSPATH=\
&gt; ~/alluxio/core/client/target/alluxio-core-client-1.1.0-SNAPSHOT-jar-with-dependencies.jar 
[hadoop@hadoop-master2 ~]$ 
[hadoop@hadoop-master2 ~]$ spark-shell --master local
scala&gt; val file=sc.textFile("alluxio://hadoop-master2:19998/README.txt")
file: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:27

scala&gt; file.count()
res0: Long = 31

scala&gt; file.take(2)
res1: Array[String] = Array(For the latest information about Hadoop, please visit our website at:, "")

# wordcount
scala&gt; val op = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)
# word sort asc
scala&gt; op.sortByKey().take(10)
# count sort desc
scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).take(10)

scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).saveAsTextFile("alluxio://hadoop-master2:19998/output/")

[hadoop@hadoop-master2 ~]$ alluxio fs cat /output/*
(,18)
(the,8)
(and,6)
(of,5)
(The,4)
(this,3)
(encryption,3)
(for,3)
...
</code></pre>

<p>如果运行在集群，在slave的节点也需要与主节点一样的目录结构。 或者按照<a href="http://spark.apache.org/docs/latest/programming-guide.html#using-the-shell">官网的教程</a>操作。</p>

<pre><code># spark_classpath 会被带到 task 的启动环境变量里面
[hadoop@hadoop-master2 ~]$ rsync -az alluxio bigdata1:~/
[hadoop@hadoop-master2 ~]$ export SPARK_CLASSPATH=\
&gt; ~/alluxio/core/client/target/alluxio-core-client-1.1.0-SNAPSHOT-jar-with-dependencies.jar

[hadoop@hadoop-master2 ~]$ spark-shell --master spark://hadoop-master2:7077
scala&gt; val file=sc.textFile("alluxio://hadoop-master2:19998/README.txt")
file: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at &lt;console&gt;:27

scala&gt; val op = file.flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _)
op: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:29

scala&gt; op.map(kv =&gt; (kv._2, kv._1)).sortByKey(false).map(kv =&gt; (kv._2, kv._1)).saveAsTextFile("alluxio://hadoop-master2:19998/output2/")
</code></pre>

<p><img src="/images/blogs/alluxio-spark-word-count.png" alt="" /></p>

<h1>Metrics</h1>

<p><a href="http://www.alluxio.org/documentation/master/cn/Metrics-System.html">http://www.alluxio.org/documentation/master/cn/Metrics-System.html</a></p>

<p>v1.0.1有对应的api，可以通过 <a href="http://hadoop-master2:19999/metrics/json/">http://hadoop-master2:19999/metrics/json/</a> 查看。当前master主干分支v1.1.0可以在网页上面查看这些指标。</p>

<pre><code># 拷贝配置
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ cd conf
[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/alluxio-env.sh ./
[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/log4j.properties ./
[hadoop@hadoop-master2 conf]$ cp ~/alluxio-1.0.1/conf/workers ./ 

# 启动master（使用原来的元数据）
# 共享元数据，在 alluxio-env.sh 修改环境变量 ALLUXIO_JAVA_OPTS 
# 添加 -Dalluxio.master.journal.folder=${ALLUXIO_JOURNAL_FOLDER} / ALLUXIO_JOURNAL_FOLDER=/home/hadoop/journal
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio-start.sh master
Starting master @ hadoop-master2. Logging to /home/hadoop/alluxio-1.1.0-SNAPSHOT/logs
</code></pre>

<p>v1.1.0 页面多了 Metrics 页签：</p>

<p><img src="/images/blogs/alluxio-metrics.png" alt="" /></p>

<h1>其他文档</h1>

<ul>
<li>配置alluxio-default.properties <a href="http://alluxio.org/documentation/master/en/Configuration-Settings.html">http://alluxio.org/documentation/master/en/Configuration-Settings.html</a></li>
<li>分层本地缓存 <a href="http://alluxio.org/documentation/master/en/Tiered-Storage-on-Alluxio.html">http://alluxio.org/documentation/master/en/Tiered-Storage-on-Alluxio.html</a></li>
<li><a href="https://dzone.com/articles/Accelerate-In-Memory-Processing-with-Spark-from-Hours-to-Seconds-With-Tachyon">https://dzone.com/articles/Accelerate-In-Memory-Processing-with-Spark-from-Hours-to-Seconds-With-Tachyon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tachyon剖析]]></title>
    <link href="http://winseliu.com/blog/2015/04/18/tachyon-deep-source/"/>
    <updated>2015-04-18T23:13:01+08:00</updated>
    <id>http://winseliu.com/blog/2015/04/18/tachyon-deep-source</id>
    <content type="html"><![CDATA[<p>要了解一个框架，一般都是从框架提供/开放的接口入手。先从最直接的方式下手，可以通过<code>tachyon tfs</code>和浏览器19999端口获取集群以及文件的相关信息。</p>

<ul>
<li>要了解tachyon首先就是其文件系统，可以从两个功能开始：命令行tachyon.command.TFsShell和web-servlet。</li>
<li>然后会深入tachyon.client包，了解<strong>TachyonFS</strong>和TachyonFile处理io的方式。以及tachyon.hadoop的包。</li>
<li>io处理：

<ul>
<li>写：BlockOutStream（#getLocalBlockTemporaryPath； MappedByteBuffer）、FileOutStream</li>
<li>读：RemoteBlockInStream、LocalBlockInStream</li>
</ul>
</li>
<li>了解thrift：MasterClient、MasterServiceHandler、WorkerClient、WorkerServiceHandler、ClientBlockInfo、ClientFileInfo。</li>
<li>看tachyon.example，巩固</li>
</ul>


<p>注：MappedByteBuffer在windows存在资源占用的bug！参见<a href="http://www.th7.cn/Program/java/2012/01/31/57401.shtml">http://www.th7.cn/Program/java/2012/01/31/57401.shtml</a>，</p>

<p>把整个io流理清之后，然后需要了解tachyon是怎么维护这些信息的：</p>

<ul>
<li>配置：WorkerConf、MasterConf、UserConf</li>
<li>了解thrift：MasterClient、MasterServiceHandler、ClientWorkerInfo、MasterInfo</li>
<li>TachyonMaster和TachyonWorker的启动</li>
<li>Checkpoint、Image、Journal</li>
<li>内存淘汰策略</li>
<li>DataServer在哪里用到（nio/netty）：TachyonFile#readRemoteByteBuffer、RemoteBlockInStream#read(byte[], int, int)</li>
<li>HA</li>
<li>Dependency（不知道怎么用）</li>
</ul>


<p>远程调试Worker以及tfs：</p>

<pre><code>[hadoop@hadoop-master2 tachyon-0.6.1]$ cat conf/tachyon-env.sh 
export TACHYON_WORKER_JAVA_OPTS="$TACHYON_JAVA_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8070"

[hadoop@hadoop-master2 tachyon-0.6.1]$ export TACHYON_JAVA_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8070"
[hadoop@hadoop-master2 tachyon-0.6.1]$ bin/tachyon tfs lsr /
</code></pre>

<h2>IO/client</h2>

<ul>
<li>TachyonFS是client与Master/Worker的纽带，请求<strong>文件系统和文件</strong>的元数据CRUD操作。其中的WorkerClient仅用于写（保存）文件。</li>
<li>TachyonFile是文件的抽象处理集合，可以获取文件的基本属性（元数据），同时提供了IO的接口用于文件内容的读写。</li>
<li>InStream读、获取文件内容

<ul>
<li>EmptyBlockInStream(文件包括的块为0）</li>
<li>BlockInStream(文件包括的块为1）

<ul>
<li>LocalBlockInStream 仅当是localworker且该块在本机时，通过MappedByteBuffer获取数据（数据在ramdisk也就是内存盘上哦）。</li>
<li>RemoteBlockInStream （通过nio从远程的worker#DataServer机器获取数据#retrieveByteBufferFromRemoteMachine，如果readtype设置为cache同时把数据缓冲到本地worker）</li>
</ul>
</li>
<li>FileInStream(文件包括的块为1+，可以理解为BlocksInStream。通过mCurrentPosition / mBlockCapacity来获取当前的blockindex最终还是调用BlockInStream）</li>
</ul>
</li>
<li>FileOutStream写，写数据入口就是只有FileOutStream

<ul>
<li>BlockOutStream（WriteType设置了需要缓冲，会写到本地localworker。<strong>由于需要进行分块，会复杂些#appendCurrentBuffer</strong>）</li>
<li>UnderFileSystem（如果WriteType设置了Through，则把数据写一份到underfs文件系统）</li>
</ul>
</li>
</ul>


<h2>Master</h2>

<p>TachyonMaster是master的启动类，所有的服务都是在这个类里面初始化启动的。</p>

<ul>
<li>HA：LeaderSelectorClient</li>
<li>EditLog：EditLogProcessor、Journal。

<ul>
<li>如果是HA模式，leader调用setup方法把EditLogProcessor停掉。也就是说在HA模式下，standby才会运行EditLogProcessor实时处理editlog。</li>
<li>leader和非HA master则仅在启动时通过调用MasterInfo#init处理editlog一次。</li>
</ul>
</li>
<li>Thrift: TServer、MasterServiceHandler；与MasterClient对应的服务端。</li>
<li>Web: UIWebServer，使用jetty的内嵌服务器。</li>
<li>MasterInfo</li>
</ul>


<h2>Worker</h2>

<h2>Thrift</h2>

<h2>HA</h2>

<p>当配置<code>tachyon.usezookeeper</code>设置为true时，启动master时会初始化LeaderSelectorClient对象。使用curator连接到zookeeper服务器进行leader的选举。</p>

<p><strong>LeaderSelectorClient</strong>实现了LeaderSelectorListener接口，创建LeaderSelector并传入当前实例作为监听实例，当选举完成后，被选leader触发takeLeadership事件。</p>

<blockquote><p>public void takeLeadership(CuratorFramework client) throws Exception
Called when your instance has been granted leadership. This method should not return until you wish to release leadership</p></blockquote>

<p>takeLeadership方法中把<code>mIsLeader</code>设置为true（master自己判断）、创建<code>mLeaderFolder + mName</code>路径（客户端获取master leader）；然后隔5s的死循环（运行在LeaderSelector单独的线程池）。</p>

<h2>Checkpoint</h2>

<h2>Journal</h2>

<hr />

<h2>问题</h2>

<ul>
<li>程序没有返回内容，没有响应（v1.1.0已经没有这个问题了）</li>
</ul>


<p>tfs 默认是CACHE_THROUGH，会缓冲同时写ufs。如果改成must则只写cache，然后清理内存，再获取数据，一直没有内容返回，不知道为什么？</p>

<pre><code>[eshore@bigdata1 tachyon-0.6.1]$ export TACHYON_JAVA_OPTS="-Dtachyon.user.file.writetype.default=MUST_CACHE "
[eshore@bigdata1 tachyon-0.6.1]$ bin/tachyon tfs copyFromLocal LICENSE /LICENSE2
Copied LICENSE to /LICENSE2
[eshore@bigdata1 tachyon-0.6.1]$ bin/tachyon tfs free /LICENSE2
/LICENSE2 was successfully freed from memory.
[eshore@bigdata1 tachyon-0.6.1]$ bin/tachyon tfs cat /LICENSE2
</code></pre>

<p>v1.1</p>

<pre><code>[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs ls /README.txt                                            
1366.00B  04-16-2016 07:56:24:499  In Memory      /README.txt
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs free /README.txt
/README.txt was successfully freed from memory.
[hadoop@hadoop-master2 alluxio-1.1.0-SNAPSHOT]$ bin/alluxio fs cat /README.txt 
Block 402653184 is not available in Alluxio
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tachyon入门指南]]></title>
    <link href="http://winseliu.com/blog/2015/04/15/tachyon-quickstart/"/>
    <updated>2015-04-15T22:56:09+08:00</updated>
    <id>http://winseliu.com/blog/2015/04/15/tachyon-quickstart</id>
    <content type="html"><![CDATA[<p>tachyon程序是在HDFS与程序之间缓冲，相当于CPU与磁盘设备之间内存的功能。tachyon提供了TachyonFS、TachyonFile等API使操作起来更像一个文件系统；同时实现了HDFS的FileSystem接口，方便原有程序的迁移，只要把url的模式（schema）hdfs改成tachyon。</p>

<p>tachyon和HDFS一样也是master-slaver（worker）结构：master保存元数据，worker节点使用内存盘缓冲数据。</p>

<h2>部署集群</h2>

<p>下载tachyon的编译文件后，按下面的步骤部署：</p>

<ul>
<li>解压</li>
<li>修改conf/tachyon-env.sh（JAVA_HOME，TACHYON_UNDERFS_ADDRESS，TACHYON_MASTER_ADDRESS）</li>
<li>修改conf/worker</li>
<li>同步代码到workers子节点</li>
<li>格式化tachyon（建立master和worker所需的各种目录）</li>
<li>挂载内存盘</li>
<li>启动集群</li>
<li>通过19999端口访问</li>
</ul>


<p>如果hadoop集群的版本不是最新的2.6.0，需要手工编译源码：</p>

<pre><code>$ mvn clean package assembly:single -Dhadoop.version=2.2.0 -DskipTests -Dmaven.javadoc.skip=true
</code></pre>

<p>同步程序的脚本如下：</p>

<pre><code>[eshore@bigdatamgr1 ~]$ for h in `cat slaves ` ; do  rsync -vaz tachyon-0.6.1 $h:~/ --exclude=logs --exclude=underfs --exclude=journal ; done
</code></pre>

<p>用tachyon用户格式化：</p>

<pre><code>bin/tachyon format
</code></pre>

<p>使用root挂载内存盘：</p>

<pre><code>bin/tachyon-mount.sh Mount workers
for h in `cat slaves ` ; do  ssh $h "chmod 777 /mnt/ramdisk; chmod 777 /mnt/tachyon_default_home"  ; done
</code></pre>

<p>确认下worker节点是否有underfs/tmp/tachyon/data，如果没有手动创建下。</p>

<pre><code>[eshore@bigdatamgr1 ~]$ for h in `cat slaves ` ; do ssh $h mkdir -p ~/tachyon-0.6.1/underfs/tmp/tachyon/data ; done
</code></pre>

<p>启动集群：</p>

<pre><code>[eshore@bigdatamgr1 tachyon-0.6.1]$ bin/tachyon-start.sh all NoMount
</code></pre>

<p>上传文件到tachyon：（注意，这里是在worker节点！）</p>

<pre><code>[eshore@bigdata1 tachyon-0.6.1]$ bin/tachyon tfs copyFromLocal README.md /
Copied README.md to /
</code></pre>

<h2>集成到Spark</h2>

<p>注意，这里是在worker节点，使用local本地集群的方式（spark集群资源全部被spark-sql占用了，导致提交的任务分配不到资源！）。</p>

<pre><code>[eshore@bigdata1 spark-1.3.0-bin-2.2.0]$ export SPARK_CLASSPATH=/home/eshore/tachyon-0.6.1/core/target/tachyon-0.6.1-jar-with-dependencies.jar 
[eshore@bigdata1 spark-1.3.0-bin-2.2.0]$ bin/spark-shell --master local[1] -Dspark.ui.port=4041
scala&gt; val s = sc.textFile("tachyon://bigdatamgr1:19998/README.md")
s: org.apache.spark.rdd.RDD[String] = tachyon://bigdatamgr1:19998/README.md MapPartitionsRDD[1] at textFile at &lt;console&gt;:21

scala&gt; s.count()
15/04/03 11:13:09 WARN : tachyon.home is not set. Using /mnt/tachyon_default_home as the default value.
res0: Long = 45

scala&gt; val wordCounts = s.flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_)
wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:23

scala&gt; wordCounts.saveAsTextFile("tachyon://bigdatamgr1:19998/wordcount-README")

[eshore@bigdatamgr1 tachyon-0.6.1]$ bin/tachyon tfs ls /wordcount-README/
1407.00 B 04-03-2015 11:16:05:483  In Memory      /wordcount-README/part-00000
0.00 B    04-03-2015 11:16:05:787  In Memory      /wordcount-README/_SUCCESS
</code></pre>

<p>为啥要在worker节点运行呢？不能在master节点运行？运行肯定是可以的：</p>

<pre><code>[eshore@bigdatamgr1 spark-1.3.0-bin-2.2.0]$ export SPARK_CLASSPATH=/home/eshore/tachyon-0.6.1/core/target/tachyon-0.6.1-jar-with-dependencies.jar
[eshore@bigdatamgr1 spark-1.3.0-bin-2.2.0]$ bin/spark-shell --master local[1] --jars /home/eshore/tachyon-0.6.1/core/target/tachyon-0.6.1-jar-with-dependencies.jar

scala&gt; val s = sc.textFile("tachyon://bigdatamgr1:19998/NOTICE")
s: org.apache.spark.rdd.RDD[String] = tachyon://bigdatamgr1:19998/NOTICE MapPartitionsRDD[1] at textFile at &lt;console&gt;:15

scala&gt; s.count()
15/04/13 16:05:45 WARN BlockReaderLocal: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
15/04/13 16:05:45 WARN : tachyon.home is not set. Using /mnt/tachyon_default_home as the default value.
java.io.IOException: The machine does not have any local worker.
        at tachyon.client.BlockOutStream.&lt;init&gt;(BlockOutStream.java:94)
        at tachyon.client.BlockOutStream.&lt;init&gt;(BlockOutStream.java:65)
        at tachyon.client.RemoteBlockInStream.read(RemoteBlockInStream.java:204)
        at tachyon.hadoop.HdfsFileInputStream.read(HdfsFileInputStream.java:142)
        at java.io.DataInputStream.read(DataInputStream.java:100)
        at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:211)
        at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
        at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
        at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
        at org.apache.spark.rdd.HadoopRDD$$anon$1.getNext(HadoopRDD.scala:245)
        at org.apache.spark.rdd.HadoopRDD$$anon$1.getNext(HadoopRDD.scala:212)
        at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:71)
        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1466)
        at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1006)
        at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1006)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1497)
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1497)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
        at org.apache.spark.scheduler.Task.run(Task.scala:64)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
res0: Long = 2
</code></pre>

<p>两个点：</p>

<ul>
<li>这里是运行的spark local集群；</li>
<li>运行当然没有问题，但是会打印不和谐的<strong>The machine does not have any local worker</strong>警告日志。这与FileSystem的获取输入流<code>ReadType.CACHE</code>实现有关（见源码HdfsFileInputStream）。</li>
</ul>


<pre><code>mTachyonFileInputStream = mTachyonFile.getInStream(ReadType.CACHE);
</code></pre>

<p>如果master为spark集群，spark-driver不管运行在哪台集群都没有问题。因为，此时运行任务的spark-worker就是tachyon-worker节点啊，当然就有local worker了。</p>

<p>为了更深入的了解，还可以试验一下<code>ReadType.CACHE</code>的作用：原本不在内存的数据，计算后就会被载入到缓冲（内存）！！</p>

<p>可以再试一次，先从内存中删掉（此处underfs配置存储在HDFS）</p>

<pre><code>[eshore@bigdatamgr1 spark-1.3.0-bin-2.2.0]$ ~/tachyon-0.6.1/bin/tachyon tfs free /NOTICE
/NOTICE was successfully freed from memory.

[eshore@bigdatamgr1 spark-1.3.0-bin-2.2.0]$ ~/tachyon-0.6.1/bin/tachyon tfs fileinfo /NOTICE
/NOTICE with file id 2 has the following blocks: 
ClientBlockInfo(blockId:2147483648, offset:0, length:62, locations:[NetAddress(mHost:bigdata8, mPort:-1, mSecondaryPort:-1), NetAddress(bigdata6, mPort:-1, mSecondaryPort:-1), NetAddress(mHost:bigdata5, mPort:-1, mSecondaryPort:-1)])
</code></pre>

<p>再次运行count：</p>

<pre><code>scala&gt; s.count()
res1: Long = 2
</code></pre>

<p>再次查看文件状态：</p>

<pre><code>[eshore@bigdatamgr1 spark-1.3.0-bin-2.2.0]$ ~/tachyon-0.6.1/bin/tachyon tfs fileinfo /NOTICE
/NOTICE with file id 2 has the following blocks: 
ClientBlockInfo(blockId:2147483648, offset:0, length:62, locations:[NetAddress(mHost:bigdata1, mPort:29998, mSecondaryPort:29999)])
</code></pre>

<p>此时文件对应的block所在机器变成了bigdata1，也就是spark-worker运行的节点（这里用local，worker和driver都在bigdata1上）。</p>

<p>参考</p>

<ul>
<li><a href="http://tachyon-project.org/Running-Tachyon-on-a-Cluster.html">http://tachyon-project.org/Running-Tachyon-on-a-Cluster.html</a></li>
<li><a href="http://spark.apache.org/docs/latest/configuration.html">http://spark.apache.org/docs/latest/configuration.html</a></li>
<li><a href="http://tachyon-project.org/Running-Spark-on-Tachyon.html">http://tachyon-project.org/Running-Spark-on-Tachyon.html</a></li>
</ul>


<h2>集成到Hadoop集群</h2>

<pre><code>[eshore@bigdatamgr1 ~]$ export HADOOP_CLASSPATH=/home/eshore/tachyon-0.6.1/core/target/tachyon-0.6.1-jar-with-dependencies.jar

[eshore@bigdatamgr1 hadoop-2.2.0]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount -libjars /home/eshore/tachyon-0.6.1/core/target/tachyon-0.6.1-jar-with-dependencies.jar tachyon://bigdatamgr1:19998/NOTICE tachyon://bigdatamgr1:19998/NOTICE-wordcount

[eshore@bigdatamgr1 hadoop-2.2.0]$ ~/tachyon-0.6.1/bin/tachyon tfs cat /NOTICE-wordcount/part-r-00000
2012-2014       1
Berkeley        1
California,     1
Copyright       1
Tachyon 1
University      1
of      1
</code></pre>

<h2>后记</h2>

<p>当前apache开源大部分集群的部署都是同一种模式，源码也基本都是用maven来进行构建。部署其实没有什么难度，如果是应用到spark、hadoop这样的平台，其实只要部署，然后用FileSystem的接口就一切ok了。但是要了解其原理，官网的文档也不是很全，那得需要深入源码。</p>

<p>入门写到这里，差不多了，下一篇从TachyonFS角度解析tachyon。</p>

<h2>附录</h2>

<ul>
<li>spark-env.sh</li>
</ul>


<pre><code>JAVA_HOME=/home/eshore/jdk1.7.0_60

# log4j

__add_to_classpath() {

  root=$1

  if [ -d "$root" ] ; then
    for f in `ls $root/*.jar | grep -v -E '/hive.*.jar'`  ; do
      if [ -n "$SPARK_DIST_CLASSPATH" ] ; then
        export SPARK_DIST_CLASSPATH=$SPARK_DIST_CLASSPATH:$f
      else
        export SPARK_DIST_CLASSPATH=$f
      fi
    done
  fi

}

__add_to_classpath "/home/eshore/tez-0.4.0-incubating"
__add_to_classpath "/home/eshore/tez-0.4.0-incubating/lib"
__add_to_classpath "/home/eshore/apache-hive-0.13.1/lib"

export HADOOP_CONF_DIR=/data/opt/ibm/biginsights/hadoop-2.2.0/etc/hadoop
export SPARK_CLASSPATH=$SPARK_CLASSPATH:/home/eshore/spark-1.3.0-bin-2.2.0/conf:$HADOOP_CONF_DIR

# HA
SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=bi-00-01.bi.domain.com:2181 -Dspark.deploy.zookeeper.dir=/spark"

[eshore@bigdatamgr1 ~]$ for h in `cat slaves ` ; do rsync -vaz spark-1.3.0-bin-2.2.0 $h:~/ --exclude=logs --exclude=metastore_db --exclude=work --delete ; done
</code></pre>
]]></content>
  </entry>
  
</feed>
