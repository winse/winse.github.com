<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tools | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/tools/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-10-13T19:03:29+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Maven创建自己的Archetype]]></title>
    <link href="http://winseliu.com/blog/2016/10/12/maven-create-ourself-archetype/"/>
    <updated>2016-10-12T12:06:53+08:00</updated>
    <id>http://winseliu.com/blog/2016/10/12/maven-create-ourself-archetype</id>
    <content type="html"><![CDATA[<p>最近经常用到scala，创建的小工程也挺多的。每次都的复制一些properties和plugins挺繁琐的。准备自己搞一个archetype，以后直接用archetype生成一步到位（相当于一个模板）。</p>

<ul>
<li><a href="https://my.oschina.net/wangrikui/blog/498807">https://my.oschina.net/wangrikui/blog/498807</a></li>
<li><a href="http://www.cnblogs.com/whitewolf/p/3606034.html">http://www.cnblogs.com/whitewolf/p/3606034.html</a></li>
</ul>


<h2>首先创建一个模板工程</h2>

<p>把需要修改的属性和插件，以及一些常用到的文件都放置好，如log4j.properties等。</p>

<h2>使用命令创建archetype工程</h2>

<pre><code>mvn clean archetype:create-from-project
</code></pre>

<p><strong> 注意：</strong> maven-archetype-plugin插件需要定位mvn.bat，而我的maven-3.3.9的命令名称为mvn.cmd，需要简单暴力的复制一个。</p>

<p>生成后，在 <strong> target\generated-sources\archetype </strong> 目录即为创建archetype工程。</p>

<h2>清理IDE相关文件</h2>

<p>target\generated-sources\archetype\src\main\resources\META-INF\maven 下面的 archetype-metadata.xml 为Archetype的元数据（真正包括那些文件的配置）。可以根据实际情况进行编辑</p>

<p>文件夹 target\generated-sources\archetype\src\main\resources\archetype-resources 下包括所有（新建时）需要拷贝的文件，但同时目录下面也包括了IDE相关文件，可以把这些文件<strong> 删掉 </strong> 。</p>

<h2>本地安装</h2>

<p>清理完文件后，回到 target\generated-sources\archetype 执行 <code>mvn install</code> 把这个原型(Archetype)安装到本地。</p>

<h2>使用</h2>

<ul>
<li><a href="https://my.oschina.net/u/225373/blog/468035">https://my.oschina.net/u/225373/blog/468035</a></li>
</ul>


<pre><code>mvn archetype:generate -B \
-DarchetypeGroupId=com.example -DarchetypeArtifactId=scala-simple-archetype -DarchetypeVersion=1.0 \
-DarchetypeCatalog=local \
-DgroupId=com.github.winse -DartifactId=Hello
</code></pre>

<p>注意 <strong> archetypeCatalog </strong> 属性，如果不配置为本地（local/internal ）的话要等很久（可以用-X输出调试信息查看操作停在哪）。对于intellij idea可以在 Default Settings - Build,Exection,Deployment - Build Tools - Maven - Runner 加上 VM Options 参数。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maven压缩js/css功能实践]]></title>
    <link href="http://winseliu.com/blog/2016/08/19/j2ee-maven-resources-compress/"/>
    <updated>2016-08-19T16:34:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/08/19/j2ee-maven-resources-compress</id>
    <content type="html"><![CDATA[<p>为了节约网络带宽，一般在发布项目时对资源(js/css)文件进行压缩（去掉空行、精简代码等）。但是要做到兼容开发与生产还是的下一番功夫才行。</p>

<pre><code>$ ls -l src/main/webapp/static/assets/js/ | head
total 3120
-rwxrwxr--+ 1 winse None  24804 Aug 10 17:40 bootbox.js
-rwxrwxr--+ 1 winse None  71315 Aug 10 17:40 bootstrap.js
-rwxrwxr--+ 1 winse None  13905 Aug 10 17:40 bootstrap-colorpicker.js
-rwxrwxr--+ 1 winse None  49319 Aug 10 17:40 bootstrap-multiselect.js
...

$ ls -l target/dist/js/ | head
total 1368
-rwxrwx---+ 1 winse None   8943 Aug 19 16:53 bootbox-min.js
-rwxrwx---+ 1 winse None   8057 Aug 19 16:53 bootstrap-colorpicker-min.js
-rwxrwx---+ 1 winse None  38061 Aug 19 16:53 bootstrap-min.js
-rwxrwx---+ 1 winse None  18232 Aug 19 16:53 bootstrap-multiselect-min.js
...
</code></pre>

<p>项目中原本使用dist(压缩)、assets目录放置js/css等资源，在部署的时刻替换dist为assets，有点麻烦。首先想到的<strong>用nginx进行url重写</strong>，但是需要增加一个服务有点麻烦，能不能直接用spring来实现呢？</p>

<ul>
<li>自定义一个handler类</li>
</ul>


<p>查看Spring的 <code>mvc:resources</code> 实现，相当于注册了一个 <code>location -&gt; ResourceHttpRequestHandler</code> 的映射。
第一种尝试自动化的方式就是自定义handler类来进行资源的定位。增加 StaticRequestHandler 的处理类，增加配置 location 和 compressLocation 的配置：首先去查找压缩文件([NAME]-min.js)，找不到然后再找源文件([NAME].js)位置。</p>

<p>主要修改 getResource 方法，具体完整代码如下：</p>

<pre><code>## java
public class StaticRequestHandler extends ResourceHttpRequestHandler {

    private final static Log logger = LogFactory.getLog(ResourceHttpRequestHandler.class);

    private String location;
    private String compressLocation;

    private Resource locationResource;
    private Resource compressLocationResource;

    public void setLocation(String location) {
        this.location = location;
    }

    public void setCompressLocation(String compressLocation) {
        this.compressLocation = compressLocation;
    }

    @Override
    public void afterPropertiesSet() throws Exception {
        super.afterPropertiesSet();

        this.locationResource = getWebApplicationContext().getResource(location);
        super.setLocations(Collections.singletonList(this.locationResource));

        this.compressLocationResource = getWebApplicationContext().getResource(compressLocation);
    }

    @Override
    protected Resource getResource(HttpServletRequest request) {
        String path = (String) request.getAttribute(HandlerMapping.PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE);
        if (path == null) {
            throw new IllegalStateException("Required request attribute '"
                    + HandlerMapping.PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE + "' is not set");
        }

        if (!StringUtils.hasText(path) || isInvalidPath(path)) {
            if (logger.isDebugEnabled()) {
                logger.debug("Ignoring invalid resource path [" + path + "]");
            }
            return null;
        }

        Resource res = null;
        if (path.endsWith(".css")) {
            res = findResource(compressLocationResource, path.substring(0, path.length() - 4) + ".min.css");
        } else if (path.endsWith(".js")) {
            res = findResource(compressLocationResource, path.substring(0, path.length() - 3) + ".min.js");
        }

        if (res == null) {
            res = findResource(locationResource, path);
        }

        return res;
    }

    private Resource findResource(Resource location, String path) {
        try {
            if (logger.isDebugEnabled()) {
                logger.debug("Trying relative path [" + path + "] against base location: " + location);
            }
            Resource resource = location.createRelative(path);
            if (resource.exists() &amp;&amp; resource.isReadable()) {
                if (logger.isDebugEnabled()) {
                    logger.debug("Found matching resource: " + resource);
                }
                return resource;
            } else if (logger.isTraceEnabled()) {
                logger.trace("Relative resource doesn't exist or isn't readable: " + resource);
            }
        } catch (IOException ex) {
            logger.debug("Failed to create relative resource - trying next resource location", ex);
        }

        return null;
    }

}

## spring config
    &lt;!-- 静态资源 --&gt;
    &lt;!-- &lt;mvc:resources mapping="/static/**" location="/static/" /&gt; --&gt;

    &lt;bean class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt;
        &lt;property name="mappings"&gt;
            &lt;value&gt;
                /static/assets/**=staticRequestHandler
            &lt;/value&gt;
        &lt;/property&gt;
    &lt;/bean&gt;
    &lt;bean id="staticRequestHandler" class="com.hotel.servlet.resource.StaticRequestHandler"&gt;
        &lt;property name="location" value="/static/assets/" /&gt;
        &lt;property name="compressLocation" value="/static/dist/" /&gt;
    &lt;/bean&gt;
</code></pre>

<p>这种方式实现了自动定位压缩资源 <code>min.js</code> 的功能，但是压缩还是不能自动化而且不能实时的更新（min要单独压缩产生），并且调试和生产环境还是需要手动的修改配置来切换。</p>

<p>有没有更好的自动化的实现开发环境和生产环境分开呢？</p>

<ul>
<li>Maven打包时压缩然后替换源文件</li>
</ul>


<p>使用 <strong>yuicompressor-maven-plugin</strong> 插件压缩资源，然后把压缩资源<strong>先</strong>打包放置到assets目录下。</p>

<p>注意： yuicomressor 插件的 nosuffix 配置为 true ! 这样压缩后的文件名和源文件名称才一样。</p>

<pre><code>## spring config
    &lt;!-- 静态资源 --&gt;
    &lt;mvc:resources mapping="/static/**" location="/static/" /&gt;

## maven pom.xml
        &lt;profile&gt;
            &lt;id&gt;release&lt;/id&gt;

            &lt;build&gt;
                &lt;plugins&gt;
                    &lt;!-- http://alchim.sourceforge.net/yuicompressor-maven-plugin/compress-mojo.html --&gt;
                    &lt;plugin&gt;
                        &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;
                        &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt;
                        &lt;version&gt;1.3.2&lt;/version&gt;
                        &lt;executions&gt;
                            &lt;execution&gt;
                                &lt;id&gt;compress_js_css&lt;/id&gt;
                                &lt;phase&gt;process-resources&lt;/phase&gt;
                                &lt;goals&gt;
                                    &lt;goal&gt;compress&lt;/goal&gt;
                                &lt;/goals&gt;
                            &lt;/execution&gt;
                        &lt;/executions&gt;
                        &lt;configuration&gt;
                            &lt;encoding&gt;UTF-8&lt;/encoding&gt;
                            &lt;nosuffix&gt;true&lt;/nosuffix&gt;
                            &lt;skip&gt;false&lt;/skip&gt;

                            &lt;jswarn&gt;false&lt;/jswarn&gt;
                            &lt;nomunge&gt;false&lt;/nomunge&gt;
                            &lt;preserveAllSemiColons&gt;false&lt;/preserveAllSemiColons&gt;

                            &lt;sourceDirectory&gt;src/main/webapp/static/assets&lt;/sourceDirectory&gt;
                            &lt;outputDirectory&gt;${project.build.directory}/dist&lt;/outputDirectory&gt;
                        &lt;/configuration&gt;
                    &lt;/plugin&gt;

                    &lt;plugin&gt;
                        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
                        &lt;version&gt;2.6&lt;/version&gt;
                        &lt;configuration&gt;
                            &lt;webResources&gt;
                                &lt;resource&gt;
                                    &lt;directory&gt;${project.build.directory}/dist&lt;/directory&gt;
                                    &lt;targetPath&gt;static/assets&lt;/targetPath&gt;
                                    &lt;filtering&gt;false&lt;/filtering&gt;
                                &lt;/resource&gt;
                            &lt;/webResources&gt;
                        &lt;/configuration&gt;
                    &lt;/plugin&gt;

                &lt;/plugins&gt;
            &lt;/build&gt;
        &lt;/profile&gt;
</code></pre>

<p>war插件添加了自定义webResources资源，首先把压缩的文件拷贝到对应目录，maven发现文件已经存在就不会再拷贝同名的文件。这样源文件就相当于被替换成压缩的资源了。</p>

<h2>总结</h2>

<p>使用maven插件压缩打包，完美的解决js/css压缩导致的开发和生产不兼容问题。</p>

<h2>后记</h2>

<p>jsp使用了tag的地方总是会产生很多的空行，看着挺烦的。其实可以通过在jsp开头添加 trimDirectiveWhitespaces 属性来去掉空行：</p>

<pre><code>&lt;%@ page language="java" trimDirectiveWhitespaces="true" contentType="text/html; charset=utf-8" pageEncoding="utf-8"%&gt;
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Naxsi 处理 XSS]]></title>
    <link href="http://winseliu.com/blog/2016/07/19/xss-blocked-by-naxsi/"/>
    <updated>2016-07-19T19:43:13+08:00</updated>
    <id>http://winseliu.com/blog/2016/07/19/xss-blocked-by-naxsi</id>
    <content type="html"><![CDATA[<p>前台安全检查时出现了【检测到目标URL存在跨站漏洞】，就是可以通过url带js来截取用户的信息。</p>

<pre><code>js/jquery/jquery-1.8.2.min.js/&lt;ScRipt&gt;jovoys(6258);&lt;/ScRipt&gt;
</code></pre>

<p>XSS的一些简单介绍：</p>

<ul>
<li><a href="http://anti-hacker.blogspot.com/2008/01/xsscross-site-script.html">淺析XSS(Cross Site Script)漏洞原理</a></li>
<li><a href="http://www.freebuf.com/articles/web/42727.html">XSS的原理分析与解剖（第二篇）</a></li>
</ul>


<p>搜索到使用 <strong>naxsi</strong> 配合 <strong>nginx</strong> 有现成的解决方案，网上的资料很乱，直接看 <a href="https://github.com/nbs-system/naxsi/wiki">官方文档</a> 清晰一些。</p>

<ol>
<li>编译</li>
</ol>


<pre><code>[hadoop@cu2 sources]$ ll
drwxrwxr-x  6 hadoop hadoop      4096 Sep 10  2015 naxsi-0.54
-rw-r--r--  1 hadoop hadoop    192843 Jul 19 18:42 naxsi-0.54.zip
drwxr-xr-x  9 hadoop hadoop      4096 Nov 11  2015 nginx-1.7.10

[hadoop@cu2 sources]$ ll nginx-1.7.10/
total 3180
drwxr-xr-x  6 hadoop hadoop    4096 Nov 11  2015 auto
-rw-r--r--  1 hadoop hadoop  246649 Feb 10  2015 CHANGES
-rw-r--r--  1 hadoop hadoop  375103 Feb 10  2015 CHANGES.ru
drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 conf
-rwxr-xr-x  1 hadoop hadoop    2463 Feb 10  2015 configure
drwxr-xr-x  4 hadoop hadoop    4096 Nov 11  2015 contrib
drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 html
-rw-r--r--  1 hadoop hadoop    1397 Feb 10  2015 LICENSE
-rw-rw-r--  1 hadoop hadoop     342 Jul 19 18:44 Makefile
drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 man
drwxrwxr-x  4 hadoop hadoop    4096 Jul 19 18:45 objs
-rw-r--r--  1 hadoop hadoop 2009464 Nov 11  2015 pcre-8.36.tar.gz
-rw-r--r--  1 hadoop hadoop      49 Feb 10  2015 README
drwxr-xr-x 10 hadoop hadoop    4096 Nov 11  2015 src
-rw-r--r--  1 hadoop hadoop  571091 Nov 11  2015 zlib-1.2.8.tar.gz

[hadoop@cu2 nginx-1.7.10]$ ./configure --add-module=../naxsi-x.xx/naxsi_src/ --prefix=/opt/nginx
[hadoop@cu2 nginx-1.7.10]$ make &amp;&amp; make install
</code></pre>

<ol>
<li>配置</li>
</ol>


<p>需要在 nginx.conf 的http中引入 <strong>naxsi_core.rules</strong> ，在location中加入规则。</p>

<p>先把 naxsi_core.rules 拷贝到 nginx/conf 目录下。</p>

<pre><code>http {
    include       mime.types;
    include       naxsi_core.rules;
    ...
    server {
    ...
        location /omc {

#Enable naxsi
SecRulesEnabled;

#Enable learning mide
#LearningMode;

#Define where blocked requests go
DeniedUrl "/omc/error.jsp";

#CheckRules, determining when naxsi needs to take action
CheckRule "$SQL &gt;= 8" BLOCK;
CheckRule "$RFI &gt;= 8" BLOCK;
CheckRule "$TRAVERSAL &gt;= 4" BLOCK;
CheckRule "$EVADE &gt;= 4" BLOCK;
CheckRule "$XSS &gt;= 8" BLOCK;

#naxsi logs goes there
error_log logs/foo.log;

                proxy_set_header        X-Real-IP $remote_addr;
                proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header        Host $http_host;

                proxy_pass http://localhost:8888/omc;
        }
        ...
</code></pre>

<ol>
<li>启动生效</li>
</ol>


<pre><code>sbin/nginx -p $PWD
</code></pre>

<p><a href="https://github.com/nbs-system/naxsi/wiki/naxsi-setup">https://github.com/nbs-system/naxsi/wiki/naxsi-setup</a>
<a href="https://github.com/nbs-system/naxsi/wiki/checkrules-bnf">https://github.com/nbs-system/naxsi/wiki/checkrules-bnf</a></p>

<p>检查会比较严格，添加后应用可能会报错，需要对 foo.log 中的情况进行确认，对规则进行一些修改。如不需要监控 cookie 里面的内容：</p>

<pre><code>[omc@cu-omc1 nginx]$ vi conf/naxsi_core.rules 
:%s/|$HEADERS_VAR:Cookie//
</code></pre>

<p>还有一些 <code>%[2|3]</code> 的可能也需要改改。</p>

<pre><code>uri=/omc/Frame/Time.do&amp;learning=0&amp;vers=0.54&amp;total_processed=404&amp;total_blocked=10&amp;block=1&amp;zone0=BODY&amp;id0=16&amp;var_name0=
</code></pre>

<p>根据请求的 id 去规则配置里面找具体的描述，然后 uri 和 var_name 查看具体的请求对症下药：去掉规则或者改请求。</p>

<p>如上面请求的 <strong>id0=16</strong> 对应 <strong>#@MainRule &ldquo;msg:empty POST&rdquo; id:16;</strong> 把请求修改成get即可。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flamegraphs Java Cpu]]></title>
    <link href="http://winseliu.com/blog/2016/05/06/flamegraphs-java-cpu/"/>
    <updated>2016-05-06T21:35:03+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/06/flamegraphs-java-cpu</id>
    <content type="html"><![CDATA[<p>在MacTalk的公众号上读到了agentzh关于火焰图介绍(2016年5月6日07:57 动态追踪技术（中） - Dtrace、SystemTap、火焰图)，挺新奇的，并且应该对于查询热线程还是有作用的。</p>

<p>先了解perf和flamegraphs基础知识：</p>

<ul>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/">https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/</a></li>
<li><a href="http://www.brendangregg.com/perf.html#FlameGraphs">perf Examples</a></li>
<li><a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html">CPU Flame Graphs</a></li>
<li><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">Java in Flames</a></li>
<li><a href="http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html">Java CPU Flame Graphs</a></li>
<li>使用方法<a href="https://randomascii.wordpress.com/2013/03/26/summarizing-xperf-cpu-usage-with-flame-graphs/">xperf - windows perf</a></li>
<li>工具<a href="https://github.com/google/UIforETW/blob/master/bin/xperf_to_collapsedstacks.py">UIforETW</a></li>
</ul>


<p>perf好像有点类似java的btrace，不过perf是操作系统层面的。把操作系统当做服务，客户端通过perf来获取/查询系统的信息。</p>

<h2>安装</h2>

<p>perf包括在linux 2.6.31代码里面，redhat可以通过yum来安装/更新：</p>

<pre><code>[root@hadoop-master2 ~]# yum install perf
...
Installed:
  perf.x86_64 0:2.6.32-573.26.1.el6  

[root@hadoop-master2 ~]# perf stat ls /dev/shm

 Performance counter stats for 'ls /dev/shm':

          0.697115 task-clock                #    0.613 CPUs utilized          
                 0 context-switches          #    0.000 K/sec                  
                 0 cpu-migrations            #    0.000 K/sec                  
               236 page-faults               #    0.339 M/sec                  
   &lt;not supported&gt; cycles                  
   &lt;not supported&gt; stalled-cycles-frontend 
   &lt;not supported&gt; stalled-cycles-backend  
   &lt;not supported&gt; instructions            
   &lt;not supported&gt; branches                
   &lt;not supported&gt; branch-misses           

       0.001137015 seconds time elapsed
</code></pre>

<p>虚拟机可能有一些event不能用，到真正的实体机上面应该是没问题的（网上有同学验证过）。可以通过 <code>perf list</code> 查看支持的event。</p>

<p>补充，实体机效果：</p>

<pre><code>[root@dacs ~]# perf stat ls /dev/shm
...

 Performance counter stats for 'ls /dev/shm':

          1.793297      task-clock (msec)         #    0.677 CPUs utilized          
                 1      context-switches          #    0.558 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
               255      page-faults               #    0.142 M/sec                  
           2765454      cycles                    #    1.542 GHz                     [44.66%]
           1544155      stalled-cycles-frontend   #   55.84% frontend cycles idle    [64.12%]
           1013635      stalled-cycles-backend    #   36.65% backend  cycles idle   
           2692743      instructions              #    0.97  insns per cycle        
                                                  #    0.57  stalled cycles per insn
            603340      branches                  #  336.442 M/sec                  
             12499      branch-misses             #    2.07% of all branches         [98.00%]

       0.002650313 seconds time elapsed
</code></pre>

<p>windows的话直接下载 UIforETW ，运行 UIforETW.exe 就可以用来采样了。把采样产生的etl文件传给xperf_to_collapsedstacks.py，最后用flamegraph.pl画图。</p>

<p>perf的常用命令：</p>

<pre><code># http://www.brendangregg.com/perf.html
perf list

perf stat ./t1 
perf stat -a -A ls

perf top

perf record – e cpu-clock ./t1 
perf report
</code></pre>

<h2>画图</h2>

<ul>
<li><a href="http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html">http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html</a></li>
<li><a href="https://github.com/coderplay/perfj/releases">https://github.com/coderplay/perfj/releases</a></li>
<li><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">http://techblog.netflix.com/2015/07/java-in-flames.html</a></li>
</ul>


<h4>系统火焰图</h4>

<pre><code># http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html
# https://github.com/brendangregg/FlameGraph
# 真实的机器效果还是挺不错的
perf record -F 99 -a -g -- sleep 60
perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
~/FlameGraph/flamegraph.pl out.perf-folded &gt;perf.svg
sz perf.svg

# --
# perf script | ./stackcollapse-perf.pl &gt; out.perf-folded
# grep -v cpu_idle out.perf-folded | ./flamegraph.pl &gt; nonidle.svg
# grep ext4 out.perf-folded | ./flamegraph.pl &gt; ext4internals.svg
# egrep 'system_call.*sys_(read|write)' out.perf-folded | ./flamegraph.pl &gt; rw.svg
</code></pre>

<p>安装的虚拟机中操作没采集到有用的。虚拟机和真实机器两个图：</p>

<p><img src="/images/blogs/flames/flames-real.png" alt="" /></p>

<p><img src="/images/blogs/flames/flames-vm.png" alt="" /></p>

<h4>java</h4>

<p>首先需要jdk8_u60+，直接下载最新的jdk就好了。应用启动带上参数 -XX:+PreserveFramePointer ：</p>

<pre><code>[root@hadoop-master2 ~]# java -version
java version "1.8.0_92"
Java(TM) SE Runtime Environment (build 1.8.0_92-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.92-b14, mixed mode)
[root@hadoop-master2 ~]# cd /home/hadoop/spark-1.6.0-bin-2.6.3/
[root@hadoop-master2 spark-1.6.0-bin-2.6.3]# export SPARK_SUBMIT_OPTS=-XX:+PreserveFramePointer     
[root@hadoop-master2 spark-1.6.0-bin-2.6.3]# bin/spark-shell --master local   
</code></pre>

<p>这里java进程使用root启动的，如果是普通用户如hadoop，为了采样需要把hadoop用户加入sudoer，在采样时使用 <code>sudo -u hadoop CMD</code>。</p>

<p><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">http://techblog.netflix.com/2015/07/java-in-flames.html</a></p>

<ul>
<li>A 使用perfj采样</li>
</ul>


<p><a href="http://greenteajug.cn/2015/07/02/greenteajug%E6%B4%BB%E5%8A%A8-%E7%AC%AC16%E6%9C%9F-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%88%A9%E5%99%A8-perfj/">性能调优利器——PerfJ</a></p>

<p>直接下载release-1.0的版本，解压后给 bin/perfj 加上执行权限。</p>

<pre><code># 测试的时刻可以把-F 99设置大一点
# java和perfj的用户得一致！！
# https://github.com/coderplay/perfj/wiki/CPU-Flame-Graph

[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# wget http://blog.minzhou.info/perfj/leveldb-benchmark.jar
[root@dacs ~]# $JAVA_HOME/bin/java -cp leveldb-benchmark.jar -XX:+PreserveFramePointer org.iq80.leveldb.benchmark.DbBenchmark --benchmarks=fillrandom --num=100000000

[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# perfj-1.0/bin/perfj record -F 999 -g -p `pgrep -f DbBenchmark` 
perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
~/FlameGraph/flamegraph.pl out.perf-folded  --color=java &gt;perf.svg
sz perf.svg
</code></pre>

<p><img src="/images/blogs/flames/flames-java-leveldb.png" alt="" /></p>

<p>还是挺有意思的。</p>

<p><img src="/images/blogs/flames/flames-java-leveldb-vm.png" alt="" /></p>

<p>虚拟机的少了好多信息！一模一样的命令，得出来的东西差好远！！</p>

<pre><code># https://github.com/coderplay/perfj/wiki/Context-Switch-Analysis
# 在vmware虚拟机里面运行啥都看不到！实体机也看不到作者的那些栈信息
[root@dacs ~]# wget http://blog.minzhou.info/perfj/leveldb-benchmark.jar
[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# $JAVA_HOME/bin/javac ContextSwitchTest.java 
[root@dacs ~]# $JAVA_HOME/bin/java -XX:+PreserveFramePointer ContextSwitchTest

[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# perfj-1.0/bin/perfj record  -e sched:sched_switch -F 999 -g -p `pgrep -f ContextSwitchTest` 
[root@dacs ~]# perfj-1.0/bin/perfj report --stdio
</code></pre>

<ul>
<li>B 使用perf-map-agent</li>
</ul>


<pre><code>git clone https://github.com/jrudolph/perf-map-agent.git
cd perf-map-agent/
export JAVA_HOME=/opt/jdk1.8.0_92
cmake .
make

perf record -F 99 -g -p 7661 -- sleep 120
bin/create-java-perf-map.sh 7661

sudo perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
cat out.perf-folded | ~/FlameGraph/flamegraph.pl --color=java &gt;perf.svg
sz perf.svg
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RPM打包]]></title>
    <link href="http://winseliu.com/blog/2016/04/04/rpm-build-your-package/"/>
    <updated>2016-04-04T16:07:21+08:00</updated>
    <id>http://winseliu.com/blog/2016/04/04/rpm-build-your-package</id>
    <content type="html"><![CDATA[<h2>资料</h2>

<ul>
<li><a href="http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html">http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html</a></li>
<li><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn">https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/index.html">用 RPM 打包软件-打包教程</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part3/index.html">用 RPM 打包软件-高级部分：安装前后控制</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-rpm/index.html">RPM 打包技术与典型 SPEC 文件分析-各变量含义</a></li>
<li><a href="http://hlee.iteye.com/blog/343499">http://hlee.iteye.com/blog/343499</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/management/package/rpm/part1/indent-2.spec">案例</a></li>
<li><p><a href="https://github.com/apache/zookeeper/tree/release-3.4.8/src/packages">zookeeper打包案例</a></p></li>
<li><p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html">http://www.ibm.com/developerworks/cn/linux/l-cn-checkinstall/index.html</a></p></li>
</ul>


<h2>实践</h2>

<ul>
<li>系统配置准备</li>
</ul>


<pre><code># 新建一个docker实例，来测试、学习
[root@cu1 ~]# docker run -ti centos:centos6 /bin/bash

[root@bdc25400cc63 mywget]# cat /etc/redhat-release 
CentOS release 6.6 (Final)

# 安装编译环境所需的软件
yum install which tree lrzsz tar gcc rpm-build
# wget编译的依赖
yum install -y gnutls gnutls-devel
</code></pre>

<ul>
<li>步骤</li>
</ul>


<pre><code>[root@bdc25400cc63 home]# mkdir mywget 
[root@bdc25400cc63 home]# cd mywget/
[root@bdc25400cc63 mywget]# mkdir BUILD RPMS SOURCES SPECS SRPMS
[root@bdc25400cc63 mywget]# cd SOURCES/
[root@bdc25400cc63 SOURCES]# mv /home/wget-1.17.tar.gz .
[root@bdc25400cc63 SOURCES]# ls
wget-1.17.tar.gz
[root@bdc25400cc63 SOURCES]# cd ..

[root@bdc25400cc63 mywget]# rpmbuild --showrc
[test@bdc25400cc63 mywget]$ rpm --eval "%{_topdir}"

[test@bdc25400cc63 mywget]$ grep -i _topdir /usr/lib/rpm/rpmrc /usr/lib/rpm/redhat/rpmrc /usr/lib/rpm/macros /usr/lib/rpm/redhat/macros  | less
/usr/lib/rpm/macros:%_builddir          %{_topdir}/BUILD
/usr/lib/rpm/macros:%_rpmdir            %{_topdir}/RPMS
/usr/lib/rpm/macros:%_sourcedir         %{_topdir}/SOURCES
/usr/lib/rpm/macros:%_specdir           %{_topdir}/SPECS
/usr/lib/rpm/macros:%_srcrpmdir         %{_topdir}/SRPMS
/usr/lib/rpm/macros:%_buildrootdir              %{_topdir}/BUILDROOT
/usr/lib/rpm/macros:%_topdir            %{getenv:HOME}/rpmbuild

[test@bdc25400cc63 mywget]$ cat ~/.rpmmacros 
%_topdir /home/mywget/rpm

# 2016-5-12 15:28:35
# spec里面有define和global，应该是这个导致的！用global应该即可以了？

[root@bdc25400cc63 mywget]# vi SPECS/wget.spec
  # this is a sample spec file for wget

  %define _topdir /home/mywget
  %define name    wget
  %define release 2
  %define version 1.17
  # 定义 _buildrootdir 不起作用，不知道为啥??? 在 .rpmmacros 定义了 %_topdir，root转到 /home/mywget/rpm/BUILDROOT 了。

  %define _unpackaged_files_terminate_build 0

  Summary:   GNU wget
  License:   GPL
  Name:      %{name}
  Version:   %{version}
  Release:   %{release}
  Source:    %{name}-%{version}.tar.gz
  Prefix:    /usr/local/wget
  Group:     Development/Tools

  %description
  The GNU wget program downloads files from the Internet using the command-line.

  %prep
  %setup -q

  %build
  ./configure
  make

  %install
  make install prefix=$RPM_BUILD_ROOT/usr/local/wget # or use DESTDIR=$RPM_BUILD_ROOT

  %post
  echo "hello world"

  %preun
  echo "bye"

  %clean
  rm -rf $RPM_BUILD_ROOT

  %files
  %defattr(-, root, root)
  /usr/local/wget/bin/wget

[root@bdc25400cc63 mywget]# rpmbuild -vv -bb --clean SPECS/wget.spec 

[root@bdc25400cc63 mywget]# tree .
.
├── BUILD
├── RPMS
│   └── x86_64
│       ├── wget-1.17-2.x86_64.rpm
│       └── wget-debuginfo-1.17-2.x86_64.rpm
├── SOURCES
│   └── wget-1.17.tar.gz
├── SPECS
│   └── wget.spec
└── SRPMS

6 directories, 4 files

[root@bdc25400cc63 mywget]# rpm -qpl RPMS/x86_64/wget-1.17-2.x86_64.rpm  
/usr/local/wget/bin/wget
</code></pre>

<p>接下来就可以直接拿到这个包到其他机器上安装了，如果自己建立了本地库，使用createrepo更新下，就可以使用yum安装最新打的包了。</p>

<p>注： <code>%pre</code> , <code>%post</code> 和 <code>%preun</code> , <code>%postun</code> 可以在安装前后执行一些脚本。</p>

<pre><code>[root@cu2 ganglia-build]# mkdir BUILD RPMS SOURCES SPECS SRPMS
[root@cu2 ganglia-build]# cd SOURCES/
[root@cu2 SOURCES]# ll
total 1272
-rw-r--r-- 1 root root 1302320 Jan 20 09:35 ganglia-3.7.2.tar.gz
[root@cu2 SOURCES]# cd ..

[root@cu2 ganglia-build]# ll
total 20
drwxr-xr-x 2 root root 4096 Jun 15 10:25 BUILD
drwxr-xr-x 2 root root 4096 Jun 15 10:25 RPMS
drwxr-xr-x 2 root root 4096 Jun 15 10:25 SOURCES
drwxr-xr-x 2 root root 4096 Jun 15 10:25 SPECS
drwxr-xr-x 2 root root 4096 Jun 15 10:25 SRPMS

[root@cu2 ganglia-build]# cd SPECS/
[root@cu2 SPECS]# vi gmetad.spec

[root@cu2 ganglia-build]# rpmbuild --clean -v -ba SPECS/gmetad.spec 

[root@cu2 ganglia-build]# rpm -qpl RPMS/x86_64/ganglia-3.7.2-1.el6.x86_64.rpm 
</code></pre>

<h2>重新打包已有rpm</h2>

<p>下载源码包，再修改内容，最后使用rpm-build重新打包。</p>

<p>这里以puppetserver为例，使用jdk7即可但官网打包的依赖是jdk8，这里修改依赖然后重新打包：</p>

<pre><code>[root@cu2 rpmbuild]# rpm -ivh puppetserver-2.3.1-1.el6.src.rpm 
warning: puppetserver-2.3.1-1.el6.src.rpm: Header V4 RSA/SHA1 Signature, key ID 4bd6ec30: NOKEY
   1:puppetserver           warning: user mockbuild does not exist - using root
warning: group mockbuild does not exist - using root
########################################### [100%]
warning: user mockbuild does not exist - using root
warning: group mockbuild does not exist - using root
[root@cu2 rpmbuild]# ll
total 32904
-rw-r--r-- 1 root root 33681889 May 10 17:44 puppetserver-2.3.1-1.el6.src.rpm
drwxr-xr-x 2 root root     4096 May 10 17:55 SOURCES
drwxr-xr-x 2 root root     4096 May 10 17:55 SPECS

#-- 注释掉jdk8的部分
[root@cu2 rpmbuild]# grep -3 jdk SPECS/puppetserver.spec 

# java 1.8.0 is available starting in fedora 20 and el 6
#%if 0%{?fedora} &gt;= 20 || 0%{?rhel} &gt;= 6
#%global open_jdk          java-1.8.0-openjdk-headless
#%else
%global open_jdk          java-1.7.0-openjdk
#%endif

[root@cu2 rpmbuild]# yum install -y ruby
[root@cu2 rpmbuild]# rpmbuild -v -bb --clean SPECS/puppetserver.spec 

[root@cu2 rpmbuild]# yum deplist RPMS/noarch/puppetserver-2.3.1-1.el6.noarch.rpm 
Loaded plugins: fastestmirror, priorities
Finding dependencies: 
Loading mirror speeds from cached hostfile
 * base: centos.ustc.edu.cn
 * centosplus: centos.ustc.edu.cn
 * epel: mirror01.idc.hinet.net
 * extras: centos.ustc.edu.cn
 * updates: centos.ustc.edu.cn
193 packages excluded due to repository priority protections
package: puppetserver.noarch 2.3.1-1.el6
  dependency: chkconfig
   provider: chkconfig.x86_64 1.3.49.3-5.el6
   provider: chkconfig.x86_64 1.3.49.3-5.el6_7.2
  dependency: /bin/bash
   provider: bash.x86_64 4.1.2-33.el6
   provider: bash.x86_64 4.1.2-33.el6_7.1
  dependency: java-1.7.0-openjdk
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.79-2.5.5.4.el6
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.101-2.6.6.1.el6_7
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.85-2.6.1.3.el6_6
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.85-2.6.1.3.el6_7
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.91-2.6.2.2.el6_7
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.95-2.6.4.0.el6_7
   provider: java-1.7.0-openjdk.x86_64 1:1.7.0.99-2.6.5.0.el6_7
  dependency: puppet-agent &gt;= 1.4.0
   provider: puppet-agent.x86_64 1.4.1-1.el6
  dependency: net-tools
   provider: net-tools.x86_64 1.60-110.el6_2
  dependency: /usr/bin/env
   provider: coreutils.x86_64 8.4-37.el6
   provider: coreutils.x86_64 8.4-37.el6_7.3
  dependency: /bin/sh
   provider: bash.x86_64 4.1.2-33.el6
   provider: bash.x86_64 4.1.2-33.el6_7.1
  dependency: config(puppetserver) = 2.3.1-1.el6
   provider: puppetserver.noarch 2.3.1-1.el6 
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
