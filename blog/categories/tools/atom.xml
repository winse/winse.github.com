<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tools | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/tools/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-10-21T19:57:04+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[红帽6升级SSH]]></title>
    <link href="http://winseliu.com/blog/2016/10/20/ssh-upgrade-on-centos6/"/>
    <updated>2016-10-20T19:29:50+08:00</updated>
    <id>http://winseliu.com/blog/2016/10/20/ssh-upgrade-on-centos6</id>
    <content type="html"><![CDATA[<p>安全检查报告SSH版本太低存在漏洞需要进行升级，但是红帽没有现成的高版本打包好SSH的rpm。自己动手丰衣足食，没有网上一些朋友遇到那么多的问题，但是也是这纠结过程。</p>

<p>搞一台身边的机器测试安装，如果远程机器搞不好就连不上了！！先手动编译安装一遍，把编译需要的依赖都安装好，然后再rpmbuild就会比较顺利。</p>

<h2>运维同事编译安装的步骤</h2>

<pre><code>加载光盘的packages
# mount -o loop disk1.iso /mnt/disk
# vi /etc/yum.repo.d/local.repo

[root@localhost SOURCES]# ll *.tar.gz
-rw-r--r--. 1 root   root   1499808 3月  10 2016 openssh-7.2p2.tar.gz
-rw-r--r--. 1 root   root   5489494 10月 20 16:41 openssl-1.0.2j.tar.gz
-rw-r--r--. 1 root   root     29229 6月  26 2004 x11-ssh-askpass-1.2.4.1.tar.gz

一、升级 Zlib
1、下载最新版本 Zlib
# ./configure --prefix=/usr/local/zlib
本次遇到GCC未安装
yum -y install gcc
./configure --prefix=/usr/local/zlib
# make
# make install
这样，就把 zlib 编译安装在 /usr/local/zilib 中了。
二、升级 OpenSSL
1、下载最新版本 OpenSSL
which openssl    查看到当前是在/usr/bin/openssl
# ./config --prefix=/usr --shared
本次遇到系统时间不对的，修改好系统时间后config正常。
# make
# make test （这一步很重要哦！是进行 SSL 加密协议的完整测试，如果出现错误就要一定先找出哪里的原因，否则一味继续可能导致最终 SSH 不能使用，后果很严重哦！）
# make install
三、升级 OpenSSH
1、下载最新版本 OpenSSH
#  ./configure --prefix=/usr --sysconfdir=/etc/ssh --with-pam --with-zlib=/usr/local/zlib --with-ssl-dir=/usr/bin/openssl --with-md5-passwords 
（注意，如果 configure 时提示 PAM 有错误，那一般是因为系统中没有安装 pam-devel RPM 包，找到安装光盘，安装 pam-devel 就可以解决啦）如果是sshkeygen提示错误，需要make  clean再重新编译
本次安装过程提示了pam问题,cd /opt/cdrom-mirror/Packages
rpm -ivh pam-devel-1.1.1-10.el6_2.1.x86_64.rpm
./configure --prefix=/usr --sysconfdir=/etc/ssh --with-pam --with-zlib=/usr/local/zlib --with-ssl-dir=/usr/bin/openssl --with-md5-passwords 
# make
# make install
ssh -V 
</code></pre>

<h2>编译RPM包</h2>

<p>机器太多，不太可能一台台的编译安装。首先用rpmbuild打包，然后用createrepo制作本地私有仓库。主要是openssl打包比较纠结！OpenSSH完全依赖OpenSSL的，所以OpenSSL的版本一定要先编译安装好，然后再编译OpenSSH。相应的包下面都有对应的spec文件。</p>

<p>实际操作过程是先打包OpenSSH的：</p>

<pre><code> cd
 mkdir rpmbuild
 cd rpmbuild/
 mkdir -pv {BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS}

 cd SOURCES/
 cd ../SPECS/
 cp ~/updatessh/openssh-7.2p2/contrib/redhat/openssh.spec ./
 cd ..
 cd SOURCES/
 vi /etc/resolv.conf
 wget http://pkgs.fedoraproject.org/repo/pkgs/openssh/x11-ssh-askpass-1.2.4.1.tar.gz/8f2e41f3f7eaa8543a2440454637f3c3/x11-ssh-askpass-1.2.4.1.tar.gz
 wget http://pkgs.fedoraproject.org/repo/pkgs/openssh/openssh-7.2p2.tar.gz/13009a9156510d8f27e752659075cced/openssh-7.2p2.tar.gz
 cd ..
 yum groupinstall "X Window System" "Desktop" "Desktop Platform" "General Purpose Desktop"
 yum -y install libX11-devel
 yum install imake
 yum provides \*/Intrinsic.h
 yum install libXt-devel
 yum search gtk
 yum install gtk2 gtk2-devel
 vi SPECS/openssh.spec
 rpmbuild -bb SPECS/openssh.spec
</code></pre>

<p>然后坑就摆在那里了：重启sshd失败。</p>

<pre><code># 在rpmbuild\RPMS\x86_64目录下面创建createrepo私有仓库
# /etc/yum.repo.d/local.repo增加节点

# yum install openssh 

# 重启
[root@localhost ~]# service sshd restart
然后启动了[失败]（具体错没记下来）
</code></pre>

<p>感觉是OpenSSL的问题了。然后打包好OpenSSL后安装竟然报错：找不到libssl的动态链接库</p>

<pre><code>Error: Package: wget-1.12-1.4.el6.x86_64 (@anaconda-RedHatEnterpriseLinux-201206132210.x86_64/6.3)
           Requires: libcrypto.so.10()(64bit)
           Removing: openssl-1.0.0-20.el6_2.5.x86_64 (@cdrom)
               libcrypto.so.10()(64bit)
           Updated By: openssl-1.0.2j-1.x86_64 (upgrade)
               Not found
Error: Package: 1:wpa_supplicant-0.7.3-3.el6.x86_64 (@cdrom)
           Requires: libssl.so.10()(64bit)
           Removing: openssl-1.0.0-20.el6_2.5.x86_64 (@cdrom)
               libssl.so.10()(64bit)
           Updated By: openssl-1.0.2j-1.x86_64 (upgrade)
               Not found
</code></pre>

<p>官方的出的spec打包的rpm安装后竟然会少东西。百思不得其解，通过查看cdrom openssl-1.0.0-20.el6_2.5.x86_64.rpm与rpmbuild openssl-1.0.2j-1.x86_64.rpm的确还不同：</p>

<pre><code>[root@localhost ~]# rpm -qlp /opt/cdrom/Packages/openssl-1.0.0-20.el6_2.5.x86_64.rpm | grep libssl
...
/usr/lib64/libssl.so.1.0.0
/usr/lib64/libssl.so.10

[root@localhost ~]# rpm -qlp /opt/cdrom/Packages/openssl-1.0.0-20.el6_2.5.x86_64.rpm | grep libssl
...
/usr/lib64/libssl.so.1.0.0
</code></pre>

<p>在spec里面增加libssl.so.10软链接也没用。rpm并没有提供libssl.so.10的 <strong> provide </strong> 服务（可以通过<a href="http://stackoverflow.com/questions/25638461/how-can-i-make-rpm-tell-what-libraries-are-provided-inside-it">rpm -qip &ndash;provides RPM</a>查看）。</p>

<p>实在想不出办法了，只能先看下官网怎么打包的。最后通过查看 openssl-1.0.0-20.el6_2.5.src.rpm 的打包spec是进行定制了的，把原来编译生成的动态链接库so.$(SHLIB_MAJOR).$(SHLIB_MINOR)文件名改成so.$(SHLIB_SONAMEVER)。主要的两个patch为：</p>

<ul>
<li>openssl-1.0.0-beta3-soversion.patch</li>
<li>openssl-1.0.0-beta4-redhat.patch</li>
</ul>


<p>参考修改如下：</p>

<pre><code>修改Makefile
diff -u openssl-1.0.2j/Makefile.org rpmbuild/SOURCES/openssl-1.0.2j/Makefile.org
--- openssl-1.0.2j/Makefile.org 2016-09-26 17:49:07.000000000 +0800
+++ rpmbuild/SOURCES/openssl-1.0.2j/Makefile.org        2016-10-20 15:28:32.000000000 +0800
@@ -10,6 +10,7 @@
 SHLIB_MAJOR=
 SHLIB_MINOR=
 SHLIB_EXT=
+SHLIB_SONAMEVER=10
 PLATFORM=dist
 OPTIONS=
 CONFIGURE_ARGS=
@@ -342,10 +343,9 @@
 link-shared:
        @ set -e; for i in $(SHLIBDIRS); do \
                $(MAKE) -f $(HERE)/Makefile.shared -e $(BUILDENV) \
-                       LIBNAME=$$i LIBVERSION=$(SHLIB_MAJOR).$(SHLIB_MINOR) \
+                       LIBNAME=$$i LIBVERSION=$(SHLIB_SONAMEVER) \
                        LIBCOMPATVERSIONS=";$(SHLIB_VERSION_HISTORY)" \
                        symlink.$(SHLIB_TARGET); \
-               libs="$$libs -l$$i"; \
        done

 build-shared: do_$(SHLIB_TARGET) link-shared
@@ -356,7 +356,7 @@
                        libs="$(LIBKRB5) $$libs"; \
                fi; \
                $(CLEARENV) &amp;&amp; $(MAKE) -f Makefile.shared -e $(BUILDENV) \
-                       LIBNAME=$$i LIBVERSION=$(SHLIB_MAJOR).$(SHLIB_MINOR) \
+                       LIBNAME=$$i LIBVERSION=$(SHLIB_SONAMEVER) \
                        LIBCOMPATVERSIONS=";$(SHLIB_VERSION_HISTORY)" \
                        LIBDEPS="$$libs $(EX_LIBS)" \
                        link_a.$(SHLIB_TARGET); \

修改Configure1
diff -u openssl-1.0.2j/Configure rpmbuild/SOURCES/openssl-1.0.2j/Configure
--- openssl-1.0.2j/Configure    2016-09-26 17:49:07.000000000 +0800
+++ rpmbuild/SOURCES/openssl-1.0.2j/Configure   2016-10-20 16:40:33.000000000 +0800
@@ -1781,7 +1781,7 @@
        elsif ($shared_extension ne "" &amp;&amp; $shared_extension =~ /^\.s([ol])\.[^\.]*\.[^\.]*$/)
                {
                my $sotmp = $1;
-               s/^SHARED_LIBS_LINK_EXTS=.*/SHARED_LIBS_LINK_EXTS=.s$sotmp.\$(SHLIB_MAJOR) .s$sotmp/;
+               s/^SHARED_LIBS_LINK_EXTS=.*/SHARED_LIBS_LINK_EXTS=.s$sotmp.\$(SHLIB_SONAMEVER) .s$sotmp/;
                }
        elsif ($shared_extension ne "" &amp;&amp; $shared_extension =~ /^\.[^\.]*\.[^\.]*\.dylib$/)
                {

修改Configure2
rpmbuild/SOURCES/openssl-1.0.2j/Configure 文件中 so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR) 替换成 so.\$(SHLIB_SONAMEVER)

修改spec
[root@localhost ~]# diff openssl-1.0.2j/openssl.spec rpmbuild/SPECS/openssl.spec
110a111,121
&gt; version=%{version}
&gt; soversion=10
&gt; rename so.${soversion} so.${version} $RPM_BUILD_ROOT%{_libdir}/*.so.${soversion}
&gt; for lib in $RPM_BUILD_ROOT/usr/lib64/*.so.${version} ; do
&gt;         chmod 755 ${lib}
&gt;         ln -s -f `basename ${lib}` $RPM_BUILD_ROOT/usr/lib64/`basename ${lib} .${version}`
&gt;         ln -s -f `basename ${lib}` $RPM_BUILD_ROOT/usr/lib64/`basename ${lib} .${version}`.${soversion}
&gt; 
&gt; done
&gt; 
</code></pre>

<p>然后打包OpenSSL，用Yum更新OpenSSL；再打包OpenSSH，最后再用Yum安装OpenSSH。</p>

<h2>配置</h2>

<p>打包好完成后完成大半的任务了，但是重启过程出现了一些问题：</p>

<ol>
<li>error while loading shared libraries: libcrypto.so.10: cannot enable executable stack as shared object requires: Permission denied</li>
</ol>


<p>运行： <code>execstack -c libcrypto.so.10</code> 解决。 <a href="http://www.linuxquestions.org/questions/linux-kernel-70/longterm-and-grsec-on-slackware-13-0-a-903612/">http://www.linuxquestions.org/questions/linux-kernel-70/longterm-and-grsec-on-slackware-13-0-a-903612/</a></p>

<ol>
<li>重启后远程密码登录上不，但是机器重启是可以登录的，而且su通过密码也是可以切换的。</li>
</ol>


<p>由于su切换没问题，应该不是加解密的问题。最后经常是selinux的问题： <code>setenforce 0 ; vi /etc/selinux/config</code> 完成配置。</p>

<p>到此纠结的SSH升级告一段落。后面上百台机器通过puppet就可以搞定了。</p>

<p>最后分享一个牛逼到不能再牛逼升级配置的文章： <a href="http://www.tsingfun.com/html/2016/env_0330/1332.html">http://www.tsingfun.com/html/2016/env_0330/1332.html</a> 包括了升级过程中你遇到和没遇到的所有问题了。</p>

<h2>再记</h2>

<p>在测试机上面搞的都是默认的配置啊，安全级别本来就不高。但是到生产就不同了，本来加了防护的。需要特别注意！</p>

<pre><code>#centos6.8
#直接用openssl-1.0.1e-48.el6
[root@localhost yum.repos.d]# mount -o loop CentOS-6.8-x86_64-bin-DVD1.iso /opt/cdrom
[root@localhost yum.repos.d]# vi local.repo

[root@localhost rpmbuild]#  yum groupinstall "X Window System" "Desktop" "Desktop Platform" "General Purpose Desktop"

[root@localhost yum.repos.d]# yum install -y libX11-devel imake libXt-devel gtk2 gtk2-devel 

[root@localhost rpmbuild]# yum install -y rpm-build
[root@localhost rpmbuild]# yum install -y openssl-devel   krb5-devel pam-devel 

[root@localhost rpmbuild]# yum install gcc

[root@localhost rpmbuild]# rpmbuild -bb SPEC/openssh.spec

自己做的repo：

[root@hadoop-master1 ssh]# ll
total 6192
-rw-r--r-- 1 root root  439708 Oct 21 17:53 openssh-7.2p2-1.x86_64.rpm
-rw-r--r-- 1 root root   41752 Oct 21 17:53 openssh-askpass-7.2p2-1.x86_64.rpm
-rw-r--r-- 1 root root   22684 Oct 21 17:53 openssh-askpass-gnome-7.2p2-1.x86_64.rpm
-rw-r--r-- 1 root root  581836 Oct 21 17:53 openssh-clients-7.2p2-1.x86_64.rpm
-rw-r--r-- 1 root root   16948 Oct 21 17:53 openssh-debuginfo-7.2p2-1.x86_64.rpm
-rw-r--r-- 1 root root  391544 Oct 21 17:53 openssh-server-7.2p2-1.x86_64.rpm
-rw-r--r-- 1 root root 3226970 Oct 21 17:23 openssl-1.0.1e-48.el6.src.rpm
-rw-r--r-- 1 root root 1595916 May 12 18:49 openssl-1.0.1e-48.el6.x86_64.rpm
drwxr-xr-x 2 root root    4096 Oct 21 18:47 repodata

注意点：

1 selinux关掉

2 开个telnet以防万一

yum install telnet-server
chkconfig telnet on
service xinetd restart

3 PAM
vi /etc/ssh/sshd_config
UsePAM no（反正要确认pam，或者看看/etc/pam.d/sshd是否满足要求）
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maven创建自己的Archetype]]></title>
    <link href="http://winseliu.com/blog/2016/10/12/maven-create-ourself-archetype/"/>
    <updated>2016-10-12T12:06:53+08:00</updated>
    <id>http://winseliu.com/blog/2016/10/12/maven-create-ourself-archetype</id>
    <content type="html"><![CDATA[<p>最近经常用到scala，创建的小工程也挺多的。每次都的复制一些properties和plugins挺繁琐的。准备自己搞一个archetype，以后直接用archetype生成一步到位（相当于一个模板）。</p>

<ul>
<li><a href="https://my.oschina.net/wangrikui/blog/498807">https://my.oschina.net/wangrikui/blog/498807</a></li>
<li><a href="http://www.cnblogs.com/whitewolf/p/3606034.html">http://www.cnblogs.com/whitewolf/p/3606034.html</a></li>
</ul>


<h2>首先创建一个模板工程</h2>

<p>把需要修改的属性和插件，以及一些常用到的文件都放置好，如log4j.properties等。</p>

<h2>使用命令创建archetype工程</h2>

<pre><code>mvn clean archetype:create-from-project
</code></pre>

<p><strong> 注意：</strong> maven-archetype-plugin插件需要定位mvn.bat，而我的maven-3.3.9的命令名称为mvn.cmd，需要简单暴力的复制一个。</p>

<p>生成后，在 <strong> target\generated-sources\archetype </strong> 目录即为创建archetype工程。</p>

<h2>清理IDE相关文件</h2>

<p>target\generated-sources\archetype\src\main\resources\META-INF\maven 下面的 archetype-metadata.xml 为Archetype的元数据（真正包括那些文件的配置）。可以根据实际情况进行编辑</p>

<p>文件夹 target\generated-sources\archetype\src\main\resources\archetype-resources 下包括所有（新建时）需要拷贝的文件，但同时目录下面也包括了IDE相关文件，可以把这些文件<strong> 删掉 </strong> 。</p>

<h2>本地安装</h2>

<p>清理完文件后，回到 target\generated-sources\archetype 执行 <code>mvn install</code> 把这个原型(Archetype)安装到本地。</p>

<h2>使用</h2>

<ul>
<li><a href="https://my.oschina.net/u/225373/blog/468035">https://my.oschina.net/u/225373/blog/468035</a></li>
</ul>


<pre><code>mvn archetype:generate -B \
-DarchetypeGroupId=com.example -DarchetypeArtifactId=scala-simple-archetype -DarchetypeVersion=1.0 \
-DarchetypeCatalog=local \
-DgroupId=com.github.winse -DartifactId=Hello
</code></pre>

<p>注意 <strong> archetypeCatalog </strong> 属性，如果不配置为本地（local/internal ）的话要等很久（可以用-X输出调试信息查看操作停在哪）。对于intellij idea可以在 Default Settings - Build,Exection,Deployment - Build Tools - Maven - Runner 加上 VM Options 参数。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maven压缩js/css功能实践]]></title>
    <link href="http://winseliu.com/blog/2016/08/19/j2ee-maven-resources-compress/"/>
    <updated>2016-08-19T16:34:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/08/19/j2ee-maven-resources-compress</id>
    <content type="html"><![CDATA[<p>为了节约网络带宽，一般在发布项目时对资源(js/css)文件进行压缩（去掉空行、精简代码等）。但是要做到兼容开发与生产还是的下一番功夫才行。</p>

<pre><code>$ ls -l src/main/webapp/static/assets/js/ | head
total 3120
-rwxrwxr--+ 1 winse None  24804 Aug 10 17:40 bootbox.js
-rwxrwxr--+ 1 winse None  71315 Aug 10 17:40 bootstrap.js
-rwxrwxr--+ 1 winse None  13905 Aug 10 17:40 bootstrap-colorpicker.js
-rwxrwxr--+ 1 winse None  49319 Aug 10 17:40 bootstrap-multiselect.js
...

$ ls -l target/dist/js/ | head
total 1368
-rwxrwx---+ 1 winse None   8943 Aug 19 16:53 bootbox-min.js
-rwxrwx---+ 1 winse None   8057 Aug 19 16:53 bootstrap-colorpicker-min.js
-rwxrwx---+ 1 winse None  38061 Aug 19 16:53 bootstrap-min.js
-rwxrwx---+ 1 winse None  18232 Aug 19 16:53 bootstrap-multiselect-min.js
...
</code></pre>

<p>项目中原本使用dist(压缩)、assets目录放置js/css等资源，在部署的时刻替换dist为assets，有点麻烦。首先想到的<strong>用nginx进行url重写</strong>，但是需要增加一个服务有点麻烦，能不能直接用spring来实现呢？</p>

<ul>
<li>自定义一个handler类</li>
</ul>


<p>查看Spring的 <code>mvc:resources</code> 实现，相当于注册了一个 <code>location -&gt; ResourceHttpRequestHandler</code> 的映射。
第一种尝试自动化的方式就是自定义handler类来进行资源的定位。增加 StaticRequestHandler 的处理类，增加配置 location 和 compressLocation 的配置：首先去查找压缩文件([NAME]-min.js)，找不到然后再找源文件([NAME].js)位置。</p>

<p>主要修改 getResource 方法，具体完整代码如下：</p>

<pre><code>## java
public class StaticRequestHandler extends ResourceHttpRequestHandler {

    private final static Log logger = LogFactory.getLog(ResourceHttpRequestHandler.class);

    private String location;
    private String compressLocation;

    private Resource locationResource;
    private Resource compressLocationResource;

    public void setLocation(String location) {
        this.location = location;
    }

    public void setCompressLocation(String compressLocation) {
        this.compressLocation = compressLocation;
    }

    @Override
    public void afterPropertiesSet() throws Exception {
        super.afterPropertiesSet();

        this.locationResource = getWebApplicationContext().getResource(location);
        super.setLocations(Collections.singletonList(this.locationResource));

        this.compressLocationResource = getWebApplicationContext().getResource(compressLocation);
    }

    @Override
    protected Resource getResource(HttpServletRequest request) {
        String path = (String) request.getAttribute(HandlerMapping.PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE);
        if (path == null) {
            throw new IllegalStateException("Required request attribute '"
                    + HandlerMapping.PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE + "' is not set");
        }

        if (!StringUtils.hasText(path) || isInvalidPath(path)) {
            if (logger.isDebugEnabled()) {
                logger.debug("Ignoring invalid resource path [" + path + "]");
            }
            return null;
        }

        Resource res = null;
        if (path.endsWith(".css")) {
            res = findResource(compressLocationResource, path.substring(0, path.length() - 4) + ".min.css");
        } else if (path.endsWith(".js")) {
            res = findResource(compressLocationResource, path.substring(0, path.length() - 3) + ".min.js");
        }

        if (res == null) {
            res = findResource(locationResource, path);
        }

        return res;
    }

    private Resource findResource(Resource location, String path) {
        try {
            if (logger.isDebugEnabled()) {
                logger.debug("Trying relative path [" + path + "] against base location: " + location);
            }
            Resource resource = location.createRelative(path);
            if (resource.exists() &amp;&amp; resource.isReadable()) {
                if (logger.isDebugEnabled()) {
                    logger.debug("Found matching resource: " + resource);
                }
                return resource;
            } else if (logger.isTraceEnabled()) {
                logger.trace("Relative resource doesn't exist or isn't readable: " + resource);
            }
        } catch (IOException ex) {
            logger.debug("Failed to create relative resource - trying next resource location", ex);
        }

        return null;
    }

}

## spring config
    &lt;!-- 静态资源 --&gt;
    &lt;!-- &lt;mvc:resources mapping="/static/**" location="/static/" /&gt; --&gt;

    &lt;bean class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt;
        &lt;property name="mappings"&gt;
            &lt;value&gt;
                /static/assets/**=staticRequestHandler
            &lt;/value&gt;
        &lt;/property&gt;
    &lt;/bean&gt;
    &lt;bean id="staticRequestHandler" class="com.hotel.servlet.resource.StaticRequestHandler"&gt;
        &lt;property name="location" value="/static/assets/" /&gt;
        &lt;property name="compressLocation" value="/static/dist/" /&gt;
    &lt;/bean&gt;
</code></pre>

<p>这种方式实现了自动定位压缩资源 <code>min.js</code> 的功能，但是压缩还是不能自动化而且不能实时的更新（min要单独压缩产生），并且调试和生产环境还是需要手动的修改配置来切换。</p>

<p>有没有更好的自动化的实现开发环境和生产环境分开呢？</p>

<ul>
<li>Maven打包时压缩然后替换源文件</li>
</ul>


<p>使用 <strong>yuicompressor-maven-plugin</strong> 插件压缩资源，然后把压缩资源<strong>先</strong>打包放置到assets目录下。</p>

<p>注意： yuicomressor 插件的 nosuffix 配置为 true ! 这样压缩后的文件名和源文件名称才一样。</p>

<pre><code>## spring config
    &lt;!-- 静态资源 --&gt;
    &lt;mvc:resources mapping="/static/**" location="/static/" /&gt;

## maven pom.xml
        &lt;profile&gt;
            &lt;id&gt;release&lt;/id&gt;

            &lt;build&gt;
                &lt;plugins&gt;
                    &lt;!-- http://alchim.sourceforge.net/yuicompressor-maven-plugin/compress-mojo.html --&gt;
                    &lt;plugin&gt;
                        &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;
                        &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt;
                        &lt;version&gt;1.3.2&lt;/version&gt;
                        &lt;executions&gt;
                            &lt;execution&gt;
                                &lt;id&gt;compress_js_css&lt;/id&gt;
                                &lt;phase&gt;process-resources&lt;/phase&gt;
                                &lt;goals&gt;
                                    &lt;goal&gt;compress&lt;/goal&gt;
                                &lt;/goals&gt;
                            &lt;/execution&gt;
                        &lt;/executions&gt;
                        &lt;configuration&gt;
                            &lt;encoding&gt;UTF-8&lt;/encoding&gt;
                            &lt;nosuffix&gt;true&lt;/nosuffix&gt;
                            &lt;skip&gt;false&lt;/skip&gt;

                            &lt;jswarn&gt;false&lt;/jswarn&gt;
                            &lt;nomunge&gt;false&lt;/nomunge&gt;
                            &lt;preserveAllSemiColons&gt;false&lt;/preserveAllSemiColons&gt;

                            &lt;sourceDirectory&gt;src/main/webapp/static/assets&lt;/sourceDirectory&gt;
                            &lt;outputDirectory&gt;${project.build.directory}/dist&lt;/outputDirectory&gt;
                        &lt;/configuration&gt;
                    &lt;/plugin&gt;

                    &lt;plugin&gt;
                        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
                        &lt;version&gt;2.6&lt;/version&gt;
                        &lt;configuration&gt;
                            &lt;webResources&gt;
                                &lt;resource&gt;
                                    &lt;directory&gt;${project.build.directory}/dist&lt;/directory&gt;
                                    &lt;targetPath&gt;static/assets&lt;/targetPath&gt;
                                    &lt;filtering&gt;false&lt;/filtering&gt;
                                &lt;/resource&gt;
                            &lt;/webResources&gt;
                        &lt;/configuration&gt;
                    &lt;/plugin&gt;

                &lt;/plugins&gt;
            &lt;/build&gt;
        &lt;/profile&gt;
</code></pre>

<p>war插件添加了自定义webResources资源，首先把压缩的文件拷贝到对应目录，maven发现文件已经存在就不会再拷贝同名的文件。这样源文件就相当于被替换成压缩的资源了。</p>

<h2>总结</h2>

<p>使用maven插件压缩打包，完美的解决js/css压缩导致的开发和生产不兼容问题。</p>

<h2>后记</h2>

<p>jsp使用了tag的地方总是会产生很多的空行，看着挺烦的。其实可以通过在jsp开头添加 trimDirectiveWhitespaces 属性来去掉空行：</p>

<pre><code>&lt;%@ page language="java" trimDirectiveWhitespaces="true" contentType="text/html; charset=utf-8" pageEncoding="utf-8"%&gt;
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用 Naxsi 处理 XSS]]></title>
    <link href="http://winseliu.com/blog/2016/07/19/xss-blocked-by-naxsi/"/>
    <updated>2016-07-19T19:43:13+08:00</updated>
    <id>http://winseliu.com/blog/2016/07/19/xss-blocked-by-naxsi</id>
    <content type="html"><![CDATA[<p>前台安全检查时出现了【检测到目标URL存在跨站漏洞】，就是可以通过url带js来截取用户的信息。</p>

<pre><code>js/jquery/jquery-1.8.2.min.js/&lt;ScRipt&gt;jovoys(6258);&lt;/ScRipt&gt;
</code></pre>

<p>XSS的一些简单介绍：</p>

<ul>
<li><a href="http://anti-hacker.blogspot.com/2008/01/xsscross-site-script.html">淺析XSS(Cross Site Script)漏洞原理</a></li>
<li><a href="http://www.freebuf.com/articles/web/42727.html">XSS的原理分析与解剖（第二篇）</a></li>
</ul>


<p>搜索到使用 <strong>naxsi</strong> 配合 <strong>nginx</strong> 有现成的解决方案，网上的资料很乱，直接看 <a href="https://github.com/nbs-system/naxsi/wiki">官方文档</a> 清晰一些。</p>

<ol>
<li>编译</li>
</ol>


<pre><code>[hadoop@cu2 sources]$ ll
drwxrwxr-x  6 hadoop hadoop      4096 Sep 10  2015 naxsi-0.54
-rw-r--r--  1 hadoop hadoop    192843 Jul 19 18:42 naxsi-0.54.zip
drwxr-xr-x  9 hadoop hadoop      4096 Nov 11  2015 nginx-1.7.10

[hadoop@cu2 sources]$ ll nginx-1.7.10/
total 3180
drwxr-xr-x  6 hadoop hadoop    4096 Nov 11  2015 auto
-rw-r--r--  1 hadoop hadoop  246649 Feb 10  2015 CHANGES
-rw-r--r--  1 hadoop hadoop  375103 Feb 10  2015 CHANGES.ru
drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 conf
-rwxr-xr-x  1 hadoop hadoop    2463 Feb 10  2015 configure
drwxr-xr-x  4 hadoop hadoop    4096 Nov 11  2015 contrib
drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 html
-rw-r--r--  1 hadoop hadoop    1397 Feb 10  2015 LICENSE
-rw-rw-r--  1 hadoop hadoop     342 Jul 19 18:44 Makefile
drwxr-xr-x  2 hadoop hadoop    4096 Nov 11  2015 man
drwxrwxr-x  4 hadoop hadoop    4096 Jul 19 18:45 objs
-rw-r--r--  1 hadoop hadoop 2009464 Nov 11  2015 pcre-8.36.tar.gz
-rw-r--r--  1 hadoop hadoop      49 Feb 10  2015 README
drwxr-xr-x 10 hadoop hadoop    4096 Nov 11  2015 src
-rw-r--r--  1 hadoop hadoop  571091 Nov 11  2015 zlib-1.2.8.tar.gz

[hadoop@cu2 nginx-1.7.10]$ ./configure --add-module=../naxsi-x.xx/naxsi_src/ --prefix=/opt/nginx
[hadoop@cu2 nginx-1.7.10]$ make &amp;&amp; make install
</code></pre>

<ol>
<li>配置</li>
</ol>


<p>需要在 nginx.conf 的http中引入 <strong>naxsi_core.rules</strong> ，在location中加入规则。</p>

<p>先把 naxsi_core.rules 拷贝到 nginx/conf 目录下。</p>

<pre><code>http {
    include       mime.types;
    include       naxsi_core.rules;
    ...
    server {
    ...
        location /omc {

#Enable naxsi
SecRulesEnabled;

#Enable learning mide
#LearningMode;

#Define where blocked requests go
DeniedUrl "/omc/error.jsp";

#CheckRules, determining when naxsi needs to take action
CheckRule "$SQL &gt;= 8" BLOCK;
CheckRule "$RFI &gt;= 8" BLOCK;
CheckRule "$TRAVERSAL &gt;= 4" BLOCK;
CheckRule "$EVADE &gt;= 4" BLOCK;
CheckRule "$XSS &gt;= 8" BLOCK;

#naxsi logs goes there
error_log logs/foo.log;

                proxy_set_header        X-Real-IP $remote_addr;
                proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header        Host $http_host;

                proxy_pass http://localhost:8888/omc;
        }
        ...
</code></pre>

<ol>
<li>启动生效</li>
</ol>


<pre><code>sbin/nginx -p $PWD
</code></pre>

<p><a href="https://github.com/nbs-system/naxsi/wiki/naxsi-setup">https://github.com/nbs-system/naxsi/wiki/naxsi-setup</a>
<a href="https://github.com/nbs-system/naxsi/wiki/checkrules-bnf">https://github.com/nbs-system/naxsi/wiki/checkrules-bnf</a></p>

<p>检查会比较严格，添加后应用可能会报错，需要对 foo.log 中的情况进行确认，对规则进行一些修改。如不需要监控 cookie 里面的内容：</p>

<pre><code>[omc@cu-omc1 nginx]$ vi conf/naxsi_core.rules 
:%s/|$HEADERS_VAR:Cookie//
</code></pre>

<p>还有一些 <code>%[2|3]</code> 的可能也需要改改。</p>

<pre><code>uri=/omc/Frame/Time.do&amp;learning=0&amp;vers=0.54&amp;total_processed=404&amp;total_blocked=10&amp;block=1&amp;zone0=BODY&amp;id0=16&amp;var_name0=
</code></pre>

<p>根据请求的 id 去规则配置里面找具体的描述，然后 uri 和 var_name 查看具体的请求对症下药：去掉规则或者改请求。</p>

<p>如上面请求的 <strong>id0=16</strong> 对应 <strong>#@MainRule &ldquo;msg:empty POST&rdquo; id:16;</strong> 把请求修改成get即可。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flamegraphs Java Cpu]]></title>
    <link href="http://winseliu.com/blog/2016/05/06/flamegraphs-java-cpu/"/>
    <updated>2016-05-06T21:35:03+08:00</updated>
    <id>http://winseliu.com/blog/2016/05/06/flamegraphs-java-cpu</id>
    <content type="html"><![CDATA[<p>在MacTalk的公众号上读到了agentzh关于火焰图介绍(2016年5月6日07:57 动态追踪技术（中） - Dtrace、SystemTap、火焰图)，挺新奇的，并且应该对于查询热线程还是有作用的。</p>

<p>先了解perf和flamegraphs基础知识：</p>

<ul>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/">https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/</a></li>
<li><a href="http://www.brendangregg.com/perf.html#FlameGraphs">perf Examples</a></li>
<li><a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html">CPU Flame Graphs</a></li>
<li><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">Java in Flames</a></li>
<li><a href="http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html">Java CPU Flame Graphs</a></li>
<li>使用方法<a href="https://randomascii.wordpress.com/2013/03/26/summarizing-xperf-cpu-usage-with-flame-graphs/">xperf - windows perf</a></li>
<li>工具<a href="https://github.com/google/UIforETW/blob/master/bin/xperf_to_collapsedstacks.py">UIforETW</a></li>
</ul>


<p>perf好像有点类似java的btrace，不过perf是操作系统层面的。把操作系统当做服务，客户端通过perf来获取/查询系统的信息。</p>

<h2>安装</h2>

<p>perf包括在linux 2.6.31代码里面，redhat可以通过yum来安装/更新：</p>

<pre><code>[root@hadoop-master2 ~]# yum install perf
...
Installed:
  perf.x86_64 0:2.6.32-573.26.1.el6  

[root@hadoop-master2 ~]# perf stat ls /dev/shm

 Performance counter stats for 'ls /dev/shm':

          0.697115 task-clock                #    0.613 CPUs utilized          
                 0 context-switches          #    0.000 K/sec                  
                 0 cpu-migrations            #    0.000 K/sec                  
               236 page-faults               #    0.339 M/sec                  
   &lt;not supported&gt; cycles                  
   &lt;not supported&gt; stalled-cycles-frontend 
   &lt;not supported&gt; stalled-cycles-backend  
   &lt;not supported&gt; instructions            
   &lt;not supported&gt; branches                
   &lt;not supported&gt; branch-misses           

       0.001137015 seconds time elapsed
</code></pre>

<p>虚拟机可能有一些event不能用，到真正的实体机上面应该是没问题的（网上有同学验证过）。可以通过 <code>perf list</code> 查看支持的event。</p>

<p>补充，实体机效果：</p>

<pre><code>[root@dacs ~]# perf stat ls /dev/shm
...

 Performance counter stats for 'ls /dev/shm':

          1.793297      task-clock (msec)         #    0.677 CPUs utilized          
                 1      context-switches          #    0.558 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
               255      page-faults               #    0.142 M/sec                  
           2765454      cycles                    #    1.542 GHz                     [44.66%]
           1544155      stalled-cycles-frontend   #   55.84% frontend cycles idle    [64.12%]
           1013635      stalled-cycles-backend    #   36.65% backend  cycles idle   
           2692743      instructions              #    0.97  insns per cycle        
                                                  #    0.57  stalled cycles per insn
            603340      branches                  #  336.442 M/sec                  
             12499      branch-misses             #    2.07% of all branches         [98.00%]

       0.002650313 seconds time elapsed
</code></pre>

<p>windows的话直接下载 UIforETW ，运行 UIforETW.exe 就可以用来采样了。把采样产生的etl文件传给xperf_to_collapsedstacks.py，最后用flamegraph.pl画图。</p>

<p>perf的常用命令：</p>

<pre><code># http://www.brendangregg.com/perf.html
perf list

perf stat ./t1 
perf stat -a -A ls

perf top

perf record – e cpu-clock ./t1 
perf report
</code></pre>

<h2>画图</h2>

<ul>
<li><a href="http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html">http://isuru-perera.blogspot.hk/2015/07/java-cpu-flame-graphs.html</a></li>
<li><a href="https://github.com/coderplay/perfj/releases">https://github.com/coderplay/perfj/releases</a></li>
<li><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">http://techblog.netflix.com/2015/07/java-in-flames.html</a></li>
</ul>


<h4>系统火焰图</h4>

<pre><code># http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html
# https://github.com/brendangregg/FlameGraph
# 真实的机器效果还是挺不错的
perf record -F 99 -a -g -- sleep 60
perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
~/FlameGraph/flamegraph.pl out.perf-folded &gt;perf.svg
sz perf.svg

# --
# perf script | ./stackcollapse-perf.pl &gt; out.perf-folded
# grep -v cpu_idle out.perf-folded | ./flamegraph.pl &gt; nonidle.svg
# grep ext4 out.perf-folded | ./flamegraph.pl &gt; ext4internals.svg
# egrep 'system_call.*sys_(read|write)' out.perf-folded | ./flamegraph.pl &gt; rw.svg
</code></pre>

<p>安装的虚拟机中操作没采集到有用的。虚拟机和真实机器两个图：</p>

<p><img src="/images/blogs/flames/flames-real.png" alt="" /></p>

<p><img src="/images/blogs/flames/flames-vm.png" alt="" /></p>

<h4>java</h4>

<p>首先需要jdk8_u60+，直接下载最新的jdk就好了。应用启动带上参数 -XX:+PreserveFramePointer ：</p>

<pre><code>[root@hadoop-master2 ~]# java -version
java version "1.8.0_92"
Java(TM) SE Runtime Environment (build 1.8.0_92-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.92-b14, mixed mode)
[root@hadoop-master2 ~]# cd /home/hadoop/spark-1.6.0-bin-2.6.3/
[root@hadoop-master2 spark-1.6.0-bin-2.6.3]# export SPARK_SUBMIT_OPTS=-XX:+PreserveFramePointer     
[root@hadoop-master2 spark-1.6.0-bin-2.6.3]# bin/spark-shell --master local   
</code></pre>

<p>这里java进程使用root启动的，如果是普通用户如hadoop，为了采样需要把hadoop用户加入sudoer，在采样时使用 <code>sudo -u hadoop CMD</code>。</p>

<p><a href="http://techblog.netflix.com/2015/07/java-in-flames.html">http://techblog.netflix.com/2015/07/java-in-flames.html</a></p>

<ul>
<li>A 使用perfj采样</li>
</ul>


<p><a href="http://greenteajug.cn/2015/07/02/greenteajug%E6%B4%BB%E5%8A%A8-%E7%AC%AC16%E6%9C%9F-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%88%A9%E5%99%A8-perfj/">性能调优利器——PerfJ</a></p>

<p>直接下载release-1.0的版本，解压后给 bin/perfj 加上执行权限。</p>

<pre><code># 测试的时刻可以把-F 99设置大一点
# java和perfj的用户得一致！！
# https://github.com/coderplay/perfj/wiki/CPU-Flame-Graph

[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# wget http://blog.minzhou.info/perfj/leveldb-benchmark.jar
[root@dacs ~]# $JAVA_HOME/bin/java -cp leveldb-benchmark.jar -XX:+PreserveFramePointer org.iq80.leveldb.benchmark.DbBenchmark --benchmarks=fillrandom --num=100000000

[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# perfj-1.0/bin/perfj record -F 999 -g -p `pgrep -f DbBenchmark` 
perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
~/FlameGraph/flamegraph.pl out.perf-folded  --color=java &gt;perf.svg
sz perf.svg
</code></pre>

<p><img src="/images/blogs/flames/flames-java-leveldb.png" alt="" /></p>

<p>还是挺有意思的。</p>

<p><img src="/images/blogs/flames/flames-java-leveldb-vm.png" alt="" /></p>

<p>虚拟机的少了好多信息！一模一样的命令，得出来的东西差好远！！</p>

<pre><code># https://github.com/coderplay/perfj/wiki/Context-Switch-Analysis
# 在vmware虚拟机里面运行啥都看不到！实体机也看不到作者的那些栈信息
[root@dacs ~]# wget http://blog.minzhou.info/perfj/leveldb-benchmark.jar
[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# $JAVA_HOME/bin/javac ContextSwitchTest.java 
[root@dacs ~]# $JAVA_HOME/bin/java -XX:+PreserveFramePointer ContextSwitchTest

[root@dacs ~]# export JAVA_HOME=/usr/java/jdk1.8.0_92 
[root@dacs ~]# perfj-1.0/bin/perfj record  -e sched:sched_switch -F 999 -g -p `pgrep -f ContextSwitchTest` 
[root@dacs ~]# perfj-1.0/bin/perfj report --stdio
</code></pre>

<ul>
<li>B 使用perf-map-agent</li>
</ul>


<pre><code>git clone https://github.com/jrudolph/perf-map-agent.git
cd perf-map-agent/
export JAVA_HOME=/opt/jdk1.8.0_92
cmake .
make

perf record -F 99 -g -p 7661 -- sleep 120
bin/create-java-perf-map.sh 7661

sudo perf script | ~/FlameGraph/stackcollapse-perf.pl &gt;out.perf-folded
cat out.perf-folded | ~/FlameGraph/flamegraph.pl --color=java &gt;perf.svg
sz perf.svg
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
