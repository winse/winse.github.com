<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tools | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/tools/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-01-25T21:01:29+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Pdsh]]></title>
    <link href="http://winseliu.com/blog/2016/01/25/pdsh-simple-usage/"/>
    <updated>2016-01-25T19:50:35+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/25/pdsh-simple-usage</id>
    <content type="html"><![CDATA[<p>弄hadoop总是需要不少的机器，光rsync就挺折腾人的，又是还要排除部分机器，以及查看一堆机器使用内存情况，等等。以前都使用 expect 结合 <code>for in</code> 来实现，总归简单用着也觉得还行。但是最近，升级hadoop、tez、安装ganglia被折腾的不行。拷贝for语句拷贝到累，原来看过pdsh的介绍不过原来就部署4-5台机器也就没放在心上，最近查找Ganglia安装问题的博文里面再次pdsh，觉得非常亲切和简洁。</p>

<p>再次安装使用也就有了本文。</p>

<h2>安装</h2>

<pre><code>[root@bigdatamgr1 pdsh-2.29]# umask 0022
[root@bigdatamgr1 pdsh-2.29]# ./configure -h
[root@bigdatamgr1 pdsh-2.29]# ./configure --with-dshgroups  --with-exec --with-ssh 
[root@bigdatamgr1 pdsh-2.29]# make &amp;&amp; make install
</code></pre>

<p>挺多选项的，以后不够用的时刻慢慢研究。先用ssh和exec差不多够用了。</p>

<h2>简单使用</h2>

<p>方便使用pdsh管理N台机器的前提是已经建立了SSH无密钥登录，而建立这N台机器的无秘钥登录，还是少不了Expect！</p>

<ul>
<li>加载的模块</li>
</ul>


<pre><code># 查看，安装的ssh/exec
[eshore@bigdatamgr1 ~]$ pdsh -L

# 设置默认使用的模块
[eshore@bigdatamgr1 ~]$ export PDSH_RCMD_TYPE=exec
[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2] ssh %h hostname
bigdata2: bigdata2
bigdata1: bigdata1

# 命令行指定模块
[eshore@bigdatamgr1 ~]$ pdsh -R ssh -w bigdata1,bigdata2 hostname
bigdata2: bigdata2
bigdata1: bigdata1

# 一个个的指定
[eshore@bigdatamgr1 ~]$ pdsh -w ssh:bigdata1,ssh:bigdata2 hostname
bigdata2: bigdata2
bigdata1: bigdata1
[eshore@bigdatamgr1 ~]$ pdsh -w ssh:bigdata[1,2] hostname
bigdata2: bigdata2
bigdata1: bigdata1
</code></pre>

<ul>
<li>主机加载</li>
</ul>


<pre><code>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2,5,6-8] -X nodes hostname
bigdata5: bigdata5
bigdata6: bigdata6
bigdata2: bigdata2
bigdata8: bigdata8
bigdata7: bigdata7
</code></pre>

<p>pdsh除了使用 <code>-w</code> 来指定主机列表，还可以通过文件来指定，如编译时的 <code>--with-machines</code> ，同时可以通过读取默认的位置的文件来获取。在编译pdsh时可以通过 <code>--with-dshgroups</code> 参数来激活此选项，默认可以将一组主机列表写入一个文件中并放到本地主机的 <code>~/.dsh/group</code> 或 <code>/etc/dsh/group</code> 目录下，这样就可以通过 <code>-g</code> 参数调用了。同时 <code>-X groupname</code> 可以用来排除主机列表中属于groupname组的主机。</p>

<pre><code>[eshore@bigdatamgr1 ~]$ export PDSH_RCMD_TYPE=ssh

[eshore@bigdatamgr1 ~]$ mkdir -p .dsh/group
[eshore@bigdatamgr1 ~]$ cd .dsh/group/
[eshore@bigdatamgr1 group]$ vi nodes
bigdata1
bigdata3

[eshore@bigdatamgr1 ~]$ pdsh -g nodes hostname
bigdata3: bigdata3
bigdata1: bigdata1

[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-8] -X nodes hostname
bigdata2: bigdata2
bigdata8: bigdata8
bigdata5: bigdata5
bigdata6: bigdata6
bigdata4: bigdata4
bigdata7: bigdata7
</code></pre>

<p><code>-w</code> 参数也可以用来读取特定文件中的主机列表，同时结合其他规则和进行过滤（具体查看man帮助）。<code>-x</code> 在主机列表基础上进行过滤（提供多一种的方式来实现过滤）。</p>

<pre><code>[eshore@bigdatamgr1 ~]$ cat slaves | head -2
bigdata1
bigdata2

[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves hostname | head -5
bigdata8: bigdata8
bigdata6: bigdata6
bigdata5: bigdata5
bigdata2: bigdata2
bigdata3: bigdata3

[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves,-bigdata[2-8]
pdsh&gt; hostname
bigdata1: bigdata1
pdsh&gt; 
pdsh&gt; exit
[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves,-/bigdata.?/
pdsh@bigdatamgr1: no remote hosts specified

[eshore@bigdatamgr1 ~]$ pdsh -w ^slaves -x bigdata[1-7] hostname
bigdata8: bigdata8
</code></pre>

<ul>
<li>输出格式化</li>
</ul>


<p>当一台主机的输出多余一行时，pdsh输出的内容看起来并不和谐。使用dshbak格式化</p>

<pre><code>[eshore@bigdatamgr1 ~]$ pdsh -w bigdata[1-2] free -m  | dshbak -c
----------------
bigdata1
----------------
             total       used       free     shared    buffers     cached
Mem:         64405      59207       5198          0        429      31356
-/+ buffers/cache:      27420      36985
Swap:        65535         57      65478
----------------
bigdata2
----------------
             total       used       free     shared    buffers     cached
Mem:         64405      58192       6213          0        505      29847
-/+ buffers/cache:      27838      36566
Swap:        65535         58      65477
</code></pre>

<h2>参考</h2>

<pre><code>pdsh -w ssh:user00[1-10] "date"
此命令用于在user001到user0010上执行date命令。
pdsh -w ssh:user0[10-31],/1$/ "uptime"
此命令在选择远程主机时使用了正则表达式，表示在user010到user031中选择以1结尾的主机名，即在user011、user021、user031上执行uptime命令

-l  指定在远程主机上使用的用户名称。例如：
pdsh -R ssh -l opsuser -w user00[1-9] "date"

-f  设置同时连接到远程主机的个数
</code></pre>

<ul>
<li><a href="http://ixdba.blog.51cto.com/2895551/1550184">并行分布式运维工具pdsh</a></li>
</ul>


<pre><code>Some quick tips on how to get started using pdsh:
Set up your environment:
export PDSH_SSH_ARGS_APPEND=”-o ConnectTimeout=5 -o CheckHostIP=no -o StrictHostKeyChecking=no” (Add this to your .bashrc to save time.)
</code></pre>

<ul>
<li><a href="https://radfest.wordpress.com/2012/05/24/parallel-remote-shelling-via-pdsh/">Parallel remote &ldquo;shelling&rdquo; via pdsh</a></li>
<li><a href="http://kumu-linux.github.io/blog/2013/06/19/pdsh/">Pdsh使用方法</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[安装配置Ganglia(2)]]></title>
    <link href="http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2/"/>
    <updated>2016-01-23T17:47:28+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/23/install-and-config-ganglia-on-redhat-2</id>
    <content type="html"><![CDATA[<p>前一篇介绍了全部手工安装Ganglia的文章，当时安装测试的环境比较简单。按照网上的步骤安装好，看到图了以为就懂了。Ganglia的基本多播/单播的概念都没弄懂。</p>

<p>这次有机会把Ganglia安装到正式环境，由于网络复杂一些，遇到新的问题。也更进一步的了解了Ganglia。</p>

<p>后端Gmetad(ganglia meta daemon)和Gmond(ganglia monitoring daemon)是Ganglia的两个组件。</p>

<p>Gmetad负责收集各个cluster的数据，并更新到rrd数据库中；Gmond把本机的数据UDP广播（或者单播给某台机），同时收集集群节点的数据供Gmetad读取。Gmetad并不用于监控数据的汇总，是对已经采集好的全部数据处理并存储到rrdtool数据库。</p>

<h2>搭建yum环境</h2>

<p>由于正式环境没有提供外网环境，所以需要把安装光盘拷贝到机器，作为yum的本地源。</p>

<pre><code>mount -t iso9660 -o loop rhel-server-6.4-x86_64-dvd\[ED2000.COM\].iso iso/
ln -s iso rhel6.4

vi /etc/yum.repos.d/rhel.repo 
[os]
name = Linux OS Packages
baseurl = file:///opt/rhel6.4
enabled=1
gpgcheck = 0
</code></pre>

<p>再极端点，yum程序都没有安装。到 Packages 目录用 rpm 安装 <code>yum*</code> 。</p>

<p>安装httpd后，把 rhel6.4 源建一个软链接到 <code>/var/www/html/rhel6.4</code> ，其他机器就可以使用该源来进行安装软件了。</p>

<pre><code>cat /etc/yum.repos.d/rhel.repo
[http]
name=LOCAL YUM server
baseurl = http://cu-omc1/rhel6.4
enabled=1
gpgcheck=0
</code></pre>

<h2>使用yum安装依赖</h2>

<pre><code>yum install -y gcc gd httpd php php-devel php-mysql php-pear php-common php-gd php-mbstring php-cli 

yum install -y rrdtool 

yum install -y apr*

# 编译Ganglia时加 --with-libpcre=no 可以不安装pcre
yum install -y pcre*

# yum install -y zlib-devel
</code></pre>

<h2>(仅)编译安装Ganglia</h2>

<p>下载下面的软件(yum没有这些软件)：</p>

<ul>
<li><a href="http://rpm.pbone.net/index.php3/stat/4/idpl/15992683/dir/scientific_linux_6/com/rrdtool-devel-1.3.8-6.el6.x86_64.rpm.html">rrdtool-devel-1.3.8-6.el6.x86_64.rpm</a></li>
<li><a href="http://download.savannah.gnu.org/releases/confuse/">confuse-2.7.tar.gz</a></li>
<li><a href="http://sourceforge.net/projects/ganglia/files/ganglia%20monitoring%20core/">ganglia</a></li>
<li><a href="http://sourceforge.net/projects/ganglia/files/ganglia-web/">ganglia-web</a></li>
</ul>


<p>安装：</p>

<pre><code>umask 0022 # 临时修改下，不然后面会遇到权限问题

rpm -ivh rrdtool-devel-1.3.8-6.el6.x86_64.rpm 

tar zxf confuse-2.7.tar.gz
cd confuse-2.7
./configure CFLAGS=-fPIC --disable-nls
make &amp;&amp; make install

tar zxf ganglia-3.7.2.tar.gz 
cd ganglia-3.7.2
./configure --with-gmetad --enable-gexec --enable-status --prefix=/usr/local/ganglia
# 可选项，用于指定默认配置位置 `-sysconfdir=/etc/ganglia`
make &amp;&amp; make install

cp gmetad/gmetad.init /etc/init.d/gmetad
chkconfig gmetad on
chkconfig --list | grep gm

df -h # 把rrds目录放到最大的分区，再做个链接到data目录下
mkdir -p /data/ganglia/rrds
chown nobody:nobody /data/ganglia/rrds
ln -s /usr/local/ganglia/sbin/gmetad /usr/sbin/gmetad

gmetad -h # 查看默认的config位置。下面两个步骤二选一根据是否配置 sysconfdir 选项
# cp gmetad/gmetad.conf /etc/ganglia/
vi /etc/init.d/gmetad 
  /usr/local/ganglia/etc/gmetad.conf #修改原来的默认配置路径

cd ganglia-3.7.2/gmond/
ln -s /usr/local/ganglia/sbin/gmond /usr/sbin/gmond
cp gmond.init /etc/init.d/gmond
chkconfig gmond on
chkconfig --list gmond

gmond -h # 查看默认的config位置。
./gmond -t &gt;/usr/local/ganglia/etc/gmond.conf
vi /etc/init.d/gmond 
  /usr/local/ganglia/etc/gmond.conf #修改原来的默认配置路径
</code></pre>

<h2>配置</h2>

<ul>
<li>Ganglia配置</li>
</ul>


<pre><code>vi /usr/local/ganglia/etc/gmetad.conf
  datasource "HADOOP" hadoop-master1
  datasource "CU" cu-ud1
  rrd_rootdir "/data/ganglia/rrds"
  gridname "bigdata"

vi /usr/local/ganglia/etc/gmond.conf
  cluster {
   name = "CU"

  udp_send_channel {
   bind_hostname = yes
</code></pre>

<p><a href="http://ixdba.blog.51cto.com/2895551/1149003">http://ixdba.blog.51cto.com/2895551/1149003</a></p>

<p>Ganglia的收集数据工作可以工作在单播（unicast)或多播(multicast)模式下，默认为多播模式。</p>

<ul>
<li>单播：发送自己 <strong>收集</strong> 到的监控数据到特定的一台或几台机器上，可以跨网段</li>
<li>多播：发送自己收集到的监控数据到同一网段内所有的机器上，同时收集同一网段内的所有机器发送过来的监控数据。因为是以广播包的形式发送，因此需要同一网段内。但同一网段内，又可以定义不同的发送通道。</li>
</ul>


<p>主机多网卡(多IP)情况下需要绑定到特定的IP，设置bind_hostname来设置要绑定的IP地址。单IP情况下可以不需要考虑。</p>

<p>多播情况下只能在单一网段进行，如果集群存在多个网段，可以分拆成多个子集群（data_source)，或者使用单播来进行配置。期望配置简单点的话，配置多个 data_source 。</p>

<ul>
<li><code>data_source "cluster-db" node1 node2</code>  定义集群名称，以及获取集群监控数据的节点。由于采用multicast模式，每台gmond节点都有本集群内节点服务器的所有监控数据，因此不必把所有节点都列出来。node1 node2是or的关系，如果node1无法下载，则才会尝试去node2下载，所以它们应该都是同一个集群的节点，保存着同样的数据。</li>
<li><code>cluster.name</code> 本节点属于哪个cluster，需要与data_source对应。</li>
<li><code>host.location</code> 类似于hostname的作用。</li>
<li><code>udp_send_channel.mcast_join/host</code> 多播地址，工作在239.2.11.71通道下。如果使用单播模式，则要写host=node1，单播模式下可以配置多个upd_send_channel</li>
<li><code>udp_recv_channel.mcast_join</code></li>
</ul>


<p><strong>参考思路</strong> (未具体实践)：多网段情况可以用单播解决，要是单网段要配置多个data_source(集群)那就换个多播的端口吧！</p>

<h2>启动以及测试</h2>

<pre><code>service httpd restart
service gmetad start
service gmond start

service gmond status

netstat -anp | grep -E "gmond|gmetad"

# 启动如果有问题，使用调试模式启动查找问题
/usr/sbin/gmetad -d 10

/usr/local/ganglia/bin/gstat -a
/usr/local/ganglia/bin/gstat -a -i hadoop-master1

telnet localhost 8649
telnet localhost 8651
</code></pre>

<h2>安装GWeb</h2>

<pre><code>cd ~/ganglia-web-3.7.1
vi Makefile # 一次性配置好，不再需要去修改conf_default.php
    GDESTDIR = /var/www/html/ganglia
    GCONFDIR = /usr/local/ganglia/etc/
    GWEB_STATEDIR = /var/www/html/ganglia
    # Gmetad rootdir (parent location of rrd folder)
    GMETAD_ROOTDIR = /data/ganglia
    APACHE_USER = apache
make install

# 注意：内网还是需要改下 conf_default.php 一堆jquery的js。
# 如果Web不能访问，查看下防火墙以及SELinux
</code></pre>

<ul>
<li>httpd登录密码配置</li>
</ul>


<pre><code>htpasswd -c /var/www/html/ganglia/etc/htpasswd.users gangliaadmin 

vi /etc/httpd/conf/httpd.conf 

    &lt;Directory "/var/www/html/ganglia"&gt;
    #  SSLRequireSSL
       Options None
       AllowOverride None
       &lt;IfVersion &gt;= 2.3&gt;
          &lt;RequireAll&gt;
             Require all granted
    #        Require host 127.0.0.1

             AuthName "Ganglia Access"
             AuthType Basic
             AuthUserFile /var/www/html/ganglia/etc/htpasswd.users
             Require valid-user
          &lt;/RequireAll&gt;
       &lt;/IfVersion&gt;
       &lt;IfVersion &lt; 2.3&gt;
          Order allow,deny
          Allow from all
    #     Order deny,allow
    #     Deny from all
    #     Allow from 127.0.0.1

          AuthName "Ganglia Access"
          AuthType Basic
          AuthUserFile /var/www/html/ganglia/etc/htpasswd.users
          Require valid-user
       &lt;/IfVersion&gt;
    &lt;/Directory&gt;

service httpd restart
</code></pre>

<h2>集群配置</h2>

<pre><code>cd /usr/local 
for h in cu-ud1 cu-ud2 hadoop-master1 hadoop-master2 ; do 
    cd /usr/local;
    rsync -vaz  ganglia $h:/usr/local/ ;
    ssh $h ln -s /usr/local/ganglia/sbin/gmond /usr/sbin/gmond ;
    scp /etc/init.d/gmond $h:/etc/init.d/ ;
    ssh $h "chkconfig gmond on" ;
    ssh $h "yum install apr* -y" ; 
    ssh $h "service gmond start" ; 
done

# 不同的集群，cluster.name需要修改

telnet hadoop-master1 8649
netstat -anp | grep gm
</code></pre>

<p>要是集群有变动，添加还好，删除的话，会存在原来的旧数据，页面会提示机器down掉了。可以删除rrds目录下对应集群中节点的数据，然后重庆gmetad/httpd即可。</p>

<h2>参考</h2>

<h3>内容</h3>

<pre><code>防火墙规则设置
iptables -I INPUT 3 -p tcp -m tcp --dport 80 -j ACCEPT
iptables -I INPUT 3 -p udp -m udp --dport 8649 -j ACCEPT

service iptables save
service iptables restart

关闭selinux
vi /etc/selinux/config
SELINUX=disabled
setenforce 0
</code></pre>

<p>实际应用中，需要监控的机器往往在不同的网段内，这个时候，就不能用gmond默认的多播方式（用于同一个网段内）来传送数据，必须使用单播的方法。
gmond可以配置成为一个cluster，这些gmond节点之间相互发送各自的监控数据。所以每个gmond节点上实际上都会有 cluster内的所有节点的监控数据。gmetad只需要去某一个节点获取数据就可以了。
web front-end 一个基于web的监控界面，通常和Gmetad安装在同一个节点上(还需确认是否可以不在一个节点上，因为php的配置文件中ms可配置gmetad的地址及端口)，它从Gmetad取数据，并且读取rrd数据库，生成图片，显示出来。
gmetad周期性的去gmond节点或者gmetad节点poll数据。一个gmetad可以设置多个datasource，每个datasource可以有多个备份，一个失败还可以去其他host取数据。Gmetad只有tcp通道，一方面他向datasource发送请求，另一方面会使用一个tcp端口，发 布自身收集的xml文件，默认使用8651端口。所以gmetad即可以从gmond也可以从其他的gmetad得到xml数据。</p>

<p>对于IO来说，Gmetad默认15秒向gmond取一次xml数据，如果gmond和gmetad都是在同一个节点，这样就相当于本地io请求。同时gmetad请求完xml文件后，还需要对其解析，也就是说按默认设置每15秒需要解析一个10m级别的xml文件，这样cpu的压力就会很大。同时它还有写入RRD数据库，还要处理来自web客户端的解析请求，也会读RRD数据库。这样本身的IO CPU 网络压力就很大，因此这个节点至少应该是个空闲的而且能力比较强的节点。</p>

<ul>
<li>多播模式配置
这个是默认的方式，基本上不需要修改配置文件，且所有节点的配置是一样的。这种模式的好处是所有的节点上的 gmond 都有完备的数据，gmetad 连接其中任意一个就可以获取整个集群的所有监控数据，很方便。
其中可能要修改的是 mcast_if 这个参数，用于指定多播的网络接口。如果有多个网卡，要填写对应的内网接口。</li>
<li>单播模式配置
监控机上的接收 Channel 配置。我们使用 UDP 单播模式，非常简单。我们的集群有部分机器在另一个机房，所以监听了 0.0.0.0，如果整个集群都在一个内网中，建议只 bind 内网地址。如果有防火墙，要打开相关的端口。</li>
<li>最重要的配置项是 data_source: <code>data_source "my-cluster" localhost:8648</code> 如果使用的是默认的 8649 端口，则端口部分可以省略。如果有多个集群，则可以指定多个 data_source，每行一个。</li>
<li>最后是 gridname 配置，用于给整个 Grid 命名</li>
<li><a href="https://github.com/ganglia/gmond_python_modules">https://github.com/ganglia/gmond_python_modules</a></li>
</ul>


<h3>网址</h3>

<ul>
<li><a href="http://yhz.me/blog/Install-Ganglia-On-CentOS.html">在 CentOS 6.5 上安装 Ganglia 3.6.0</a></li>
<li>*<a href="http://ixdba.blog.51cto.com/2895551/1149003">分布式监控系统ganglia配置文档</a></li>
<li><p>*<a href="http://www.3mu.me/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%80%E6%BA%90%E7%9B%91%E6%8E%A7%E8%BD%AF%E4%BB%B6ganglia-%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/">企业级开源监控软件Ganglia 安装与配置</a></p></li>
<li><p>*<a href="http://jerrypeng.me/2014/07/04/server-side-java-monitoring-ganglia/">Java 服务端监控方案（二. Ganglia 篇）</a></p></li>
<li><p><a href="http://jerrypeng.me/2014/07/22/server-side-java-monitoring-nagios/">Java 服务端监控方案（三. Nagios 篇）</a></p></li>
<li><p><a href="https://ganglia.wikimedia.org/latest/">维基百科Ganglia</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Postgresql入门]]></title>
    <link href="http://winseliu.com/blog/2015/12/13/postgresql-start-guide/"/>
    <updated>2015-12-13T23:19:55+08:00</updated>
    <id>http://winseliu.com/blog/2015/12/13/postgresql-start-guide</id>
    <content type="html"><![CDATA[<p>简单介绍下软件的安装，配置。同时实践下从mysql迁移到postgres。</p>

<h2>安装配置</h2>

<p>这里直接使用rpm包来安装。如果是centos6.6以下版本的系统需要更新openssl。</p>

<pre><code>[root@hadoop-master1 postgres]# ll
total 20708
-rw-r--r-- 1 root root  1593932 Dec 11 10:02 openssl-1.0.1e-42.el6.x86_64.rpm
-rw-r--r-- 1 root root  1085208 Dec 11 09:12 postgresql94-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root   541376 Dec 11 09:12 postgresql94-contrib-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root  1600736 Dec 11 09:12 postgresql94-devel-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root 11485008 Dec 11 09:13 postgresql94-docs-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root   198968 Dec 11 09:12 postgresql94-libs-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root    60688 Dec 11 09:12 postgresql94-plperl-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root    68884 Dec 11 09:12 postgresql94-plpython-9.4.5-1PGDG.rhel6.x86_64.rpm
-rw-r--r-- 1 root root  4556880 Dec 11 09:11 postgresql94-server-9.4.5-1PGDG.rhel6.x86_64.rpm
</code></pre>

<ul>
<li>安装命令：</li>
</ul>


<pre><code># yum install -y openssl-1.0.1e-42.el6.x86_64.rpm 

# useradd postgres
# rpm -i postgresql94-*
</code></pre>

<ul>
<li>配置环境变量、初始化数据库、启动数据库：</li>
</ul>


<pre><code># su - postgres
$ vi .bash_profile

export PGDATA=/var/lib/pgsql/9.4/data
PG_HOME=/usr/pgsql-9.4
PATH=$PG_HOME/bin:$PATH
export PATH

$ initdb

$ vi $PGDATA/pg_hba.conf
    host    all             all              192.168.0.0/16          md5

$ vi /var/lib/pgsql/9.4/data/postgresql.conf
    listen_addresses = '*'

# 切回root

# service postgresql-9.4 start
# chkconfig postgresql-9.4 on --level 2345
</code></pre>

<p>pg_hba.conf用来控制什么用于可以被远程访问。而postgresql.conf修改的监听的地址，默认是localhost改成*后就可以所有地址都可以访问了。</p>

<ul>
<li>建立库，创建数据库用户</li>
</ul>


<pre><code>-bash-4.1$ psql 

 create user dpi;
 create database dpi owner dpi;
 alter user dpi with password 'XXXX';
</code></pre>

<p>建表：</p>

<pre><code>CREATE TABLE t_dta_illegalweb (
...
  day varchar(10) DEFAULT NULL,
...
);

create or replace function t_dta_illegalweb_insert_trigger()
returns trigger as $$
begin
    return null;
end; 
$$ language plpgsql;

CREATE TRIGGER trigger_t_dta_illegalweb_insert
    BEFORE INSERT ON t_dta_illegalweb
    FOR EACH ROW EXECUTE PROCEDURE t_dta_illegalweb_insert_trigger();
</code></pre>

<p>后面会使用分区表，先把触发器都建好。把框框搭好，后面修改就行了。</p>

<h2>数据迁移</h2>

<ol>
<li>postgres创建表：</li>
</ol>


<pre><code>CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151211 (check(day = '2015-12-11')) INHERITS (t_dta_illegalweb);
CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151210 (check(day = '2015-12-10')) INHERITS (t_dta_illegalweb);
CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151209 (check(day = '2015-12-09')) INHERITS (t_dta_illegalweb);
CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151208 (check(day = '2015-12-08')) INHERITS (t_dta_illegalweb);
CREATE TABLE IF NOT EXISTS t_dta_illegalweb20151207 (check(day = '2015-12-07')) INHERITS (t_dta_illegalweb);
</code></pre>

<ol>
<li>mysql导出数据：</li>
</ol>


<pre><code>select * from t_dta_illegalweb where day='2015-12-09' into outfile '/tmp/etl/t_dta_illegalweb20151209.sql'  fields terminated by '|';
select * from t_dta_illegalweb where day='2015-12-08' into outfile '/tmp/etl/t_dta_illegalweb20151208.sql'  fields terminated by '|';
select * from t_dta_illegalweb where day='2015-12-07' into outfile '/tmp/etl/t_dta_illegalweb20151207.sql'  fields terminated by '|';
</code></pre>

<p>数据在mysql服务器的/tmp/etl目录下面。如果mysql和postgres不在同一台机，需要把这些文件拷贝到postgres的服务器。</p>

<ol>
<li>导入数据到postgres:</li>
</ol>


<p>用psql登录dpi，然后执行copy命令把数据导入到对应的表。</p>

<pre><code>\copy  t_dta_illegalweb20151209 from  '/tmp/etl/t_dta_illegalweb20151209.sql' using delimiters '|' ;
\copy  t_dta_illegalweb20151208 from  '/tmp/etl/t_dta_illegalweb20151208.sql' using delimiters '|' ;
\copy  t_dta_illegalweb20151207 from  '/tmp/etl/t_dta_illegalweb20151207.sql' using delimiters '|' ;
</code></pre>

<h2>程序修改</h2>

<p>程序修改是一件头痛的事情，虽然大部分都是SQL，但是MYSQL的比较宽泛，很多语句都兼容不报错也能出来想要的结果。但是这些语句在postgres下面执行是会报错的。比如说，select count(*)对所有数据count的时刻不能加order by（提示要groupby）；再比如，mysql遇到字符串字段和数字比较会统一转换成数字比较，等等这些在postgres中都需要在SQL中显示的转换的。</p>

<p>那么postgres的类型转换怎么实现呢？两种形式cast(X as TYPE) 或者 X::TYPE。</p>

<p>由于程序是用hibernate来做数据库访问的，会遇到如下的问题</p>

<ul>
<li>如果用hql的话CAST函数hibernate首先会进行转换。（转换类型与hibernate对象的类型不匹配）</li>
<li>而用X::TYPE会把:TYPE作为一个name parameter。</li>
<li>不用hql用sql的话，要自己做对象转换，这是我们不愿意去做的事情（不然用hibernate干嘛）</li>
</ul>


<p>各种尝试过后，修改PostgreSQLDialect来实现，添加一个自定义的hibernate函数，把字符串转成bigint即可。</p>

<pre><code>import java.sql.Types;

import org.hibernate.Hibernate;
import org.hibernate.dialect.function.SQLFunctionTemplate;


public class PostgreSQLDialect extends org.hibernate.dialect.PostgreSQLDialect {

    public PostgreSQLDialect() {
        super();
        registerFunction( "bigint", new SQLFunctionTemplate(Hibernate.BIG_INTEGER, "cast(?1 as bigint)") );
    }

}
</code></pre>

<p>使用如下：</p>

<pre><code>StringBuilder hql = new StringBuilder("from IllegalWebInfo where 1=1 ");
List&lt;Object&gt; params = new ArrayList&lt;&gt;();

String domain = queryBean.getDomain();
if (StringUtils.isNotBlank(domain)) {
    hql.append(" and ").append("domain=?");
    params.add(domain.toLowerCase());
}
String houseId = queryBean.getHouseId();
if (StringUtils.isNotBlank(houseId)) {
    hql.append(" and ").append("houseId=?");
    params.add(houseId);
}
String day = queryBean.getDay();
if (StringUtils.isNotBlank(day)) {
    hql.append(" and ").append("day=?");
    params.add(day);
}
int threshold = queryBean.getThreshold();
if(threshold &gt; 0){
    hql.append(" and ").append("bigint(visitsCount) &gt;= ?");
    params.add(BigInteger.valueOf(threshold)); // 注意这里的类型转换，把int装成bigint
}

Object[] paramArray = params.toArray();
String detailHQL = hql.toString(); // + " order by bigint(visitsCount) desc ";
List&lt;ActiveResourcesDomainInfo&gt; hist = activeResourcesDomainDao.findPageable(detailHQL, currentPage, pageSize, paramArray);

String countHQL = "select count(*) " + hql;
long count = (long) illegalWebDao.findByHql(countHQL, paramArray).iterator().next();
</code></pre>

<h2>定时任务，创建和更新触发器函数</h2>

<p>函数：</p>

<pre><code>create or replace function create_partition_table_everyday (t TEXT) returns timestamp as $$
declare 
    i int;
    cnt int;
    stmt text;
    select_stmt text;
    day date;
    isInherit BOOLEAN;
begin

    day := now() + interval '-1 day';
    stmt := 'CREATE TABLE IF NOT EXISTS ' || t || to_char(day, 'YYYYMMDD') || '(check(day = ''' || to_char(day, 'YYYY-MM-DD') || ''')) INHERITS (' || t || ')';
    RAISE INFO '[DEBUG] %', stmt;
    EXECUTE stmt;

    day := now() + interval '-183 day';
    stmt := 'DROP TABLE IF EXISTS ' || t || to_char(day, 'YYYYMMDD');
    RAISE INFO '[DEBUG] %', stmt;
    EXECUTE stmt;

BEGIN
    day := now() + interval '-32 day';
    stmt := 'ALTER TABLE IF EXISTS ' || t || to_char(day, 'YYYYMMDD') || ' NO INHERIT ' || t;
    RAISE INFO '[DEBUG] %', stmt;
    EXECUTE stmt;
EXCEPTION WHEN OTHERS THEN
    RAISE INFO '[WARN] % %', SQLERRM, SQLSTATE;
END;

    i := 0;
    cnt := 6; -- 用于生成触发器分发最近几天的insert功能

    day := now() + interval '-1 day';
    stmt :=         ' create or replace function ' || t || '_insert_trigger() returns trigger as $' || '$ ';
    stmt := stmt || ' begin ';
    stmt := stmt || ' if (new.day = ''' || to_char(day, 'YYYY-MM-DD') || ''') then INSERT INTO ' || t || to_char(day, 'YYYYMMDD') || ' VALUES (new.*); ';
    while i &lt; cnt 
    loop
        day := day + interval '-1 day';
        stmt := stmt || ' elsif (new.day = ''' || to_char(day, 'YYYY-MM-DD') || ''') then INSERT INTO ' || t || to_char(day, 'YYYYMMDD') || ' VALUES (new.*); ';

        i := i + 1;
    end loop;
    stmt := stmt || ' else raise exception ''DATE out of range. Fix the ' || t || '_insert_trigger() func!!''; ';
    stmt := stmt || ' end if; ';
    stmt := stmt || ' return null; ';
    stmt := stmt || ' end;  ';
    stmt := stmt || ' $' || '$ language plpgsql; ';
    RAISE INFO '[DEBUG] %', stmt;
    EXECUTE stmt;

    return now();
end;
$$ language plpgsql;
</code></pre>

<p>脚本：</p>

<pre><code>
vi update_dta_postgres.sh

#!/bin/sh

source ~/.bash_profile

psql -d dpi -c "select create_partition_table_everyday('t_dta_illegalweb')"
psql -d dpi -c "select create_partition_table_everyday('t_dta_activeresources_domain')"
psql -d dpi -c "select create_partition_table_everyday('t_dta_activeresources_ip')"

$ 
chmod +x update_dta_postgres.sh 
crontab -e


10 0 * * * sh ~/scripts/update_dta_postgres.sh &gt;~/scripts/update_dta_postgres.log 2&gt;&amp;1
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://stackoverflow.com/questions/22648597/linux-centos-yum-error-package-requires-libcrypto-so-10openssl-1-0-1-ec64bi">http://stackoverflow.com/questions/22648597/linux-centos-yum-error-package-requires-libcrypto-so-10openssl-1-0-1-ec64bi</a></li>
<li><a href="http://twpug.net/docs/postgresql-doc-8.0-zh_TW/functions-comparison.html">http://twpug.net/docs/postgresql-doc-8.0-zh_TW/functions-comparison.html</a></li>
<li><a href="http://stackoverflow.com/questions/7690329/check-if-table-inherits-from-other-table-in-postgresql">http://stackoverflow.com/questions/7690329/check-if-table-inherits-from-other-table-in-postgresql</a></li>
<li><a href="http://www.jaredlog.com/?p=137">http://www.jaredlog.com/?p=137</a></li>
<li><a href="http://www.anicehumble.com/2011/08/postgresql-catch-exception-rocks.html">http://www.anicehumble.com/2011/08/postgresql-catch-exception-rocks.html</a></li>
<li><a href="http://stackoverflow.com/questions/4877637/postgresql-exception-handling">http://stackoverflow.com/questions/4877637/postgresql-exception-handling</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭梯笔记]]></title>
    <link href="http://winseliu.com/blog/2015/11/22/gfw-ladder/"/>
    <updated>2015-11-22T20:51:35+08:00</updated>
    <id>http://winseliu.com/blog/2015/11/22/gfw-ladder</id>
    <content type="html"><![CDATA[<h2>准备一个SSH账号</h2>

<ul>
<li><a href="http://www.99ssh.net/">http://www.99ssh.net/</a></li>
</ul>


<h2>SSH -N -D 或者MyEnTunnel</h2>

<ul>
<li><code>ssh -N -D [PORT] [USER@IP]</code></li>
<li><a href="http://www.99ssh.net/help/newsshow.php?cid=19&amp;id=21">http://www.99ssh.net/help/newsshow.php?cid=19&amp;id=21</a></li>
</ul>


<p>使用MyEnTunel的话，设置程序为【启动软件时自动连接】，同时把程序的快捷方式加到【C:\Users\winse\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup\】目录下。</p>

<h2>Chrome + SwitchyOmega + gfwlist</h2>

<ul>
<li><a href="https://github.com/FelisCatus/SwitchyOmega/releases">https://github.com/FelisCatus/SwitchyOmega/releases</a> SwitchySharp升级版本</li>
<li><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a></li>
</ul>


<p>可以做到智能代理功能，gfwlist的才会走代理。加速访问国内网站，同时减少不必要的流量。</p>

<h2>Firefox + FoxyProxy + gfwlist</h2>

<ul>
<li><a href="http://mozilla.com.cn/thread-230260-1-1.html">http://mozilla.com.cn/thread-230260-1-1.html</a></li>
<li><a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a></li>
</ul>


<p>Chrome的版本速度快一点。配置好后，等待一段时间就智能的适配了，firefox的等的时间略长。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx再折腾---统一访问入口]]></title>
    <link href="http://winseliu.com/blog/2015/11/11/nginx-build-unified-access/"/>
    <updated>2015-11-11T11:04:04+08:00</updated>
    <id>http://winseliu.com/blog/2015/11/11/nginx-build-unified-access</id>
    <content type="html"><![CDATA[<p>快照目录文件太多，准备安装一个方式分目录。但是又要能保证原来的访问方式不变化！使用rewrite和try_files成功实现。</p>

<h2>目录结构:</h2>

<pre><code>winse@Lenovo-PC /cygdrive/f/temp
$ ls -R
.:
1.jpg  snapshot  snapshot-1  snapshot-2  snapshot-3  snapshot-4

./snapshot:
0.html

./snapshot-1:
1.html

./snapshot-2:
2.html

./snapshot-3:
3.html

./snapshot-4:
4.html
</code></pre>

<h2>Nginx配置尝试一:</h2>

<pre><code>        location /snapshot {
            root   /home/hadoop/html-snapshot;
            add_header content-type "text/html";

            rewrite ^/snapshot/.*/(.*)$  /snapshot/$1 break ;

            try_files $uri /snapshot-1/$uri /snapshot-3/$uri;
        }

        location ~ /snapshot-\d+ {
            root   /home/hadoop/html-snapshot;

            rewrite ^/(.*)/.*/(.*)$ /$1/$2 break;
        }
</code></pre>

<p>这种方式是不行的，try_files要求除最后一个配置外其他都是文件！</p>

<blockquote><p>It is possible to check directory’s existence by specifying a slash at the end of a name, e.g. “$uri/”. If none of the files were found, an internal redirect to the uri specified in the last parameter is made.  [<a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files">http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files</a>]</p></blockquote>

<p>也就是说，中间配置路径，nginx只把他们当做本地的去看待！文件存在就返回结果，否则直接重定向到最后一个路径！！</p>

<h2>Nginx配置尝试二：</h2>

<pre><code>        location /snapshot {
            root   F:/temp;
            add_header content-type "text/html";

            rewrite ^/snapshot/.*/(.*)$  /snapshot/$1 break ;

            try_files $uri @backup;
        }

        location ~ /snapshot-\d+ {
            root   F:/temp;

            try_files $uri @backup;
        }

        location @backup {
            # 这里的顺序不能颠倒，[.*]会匹配所有的！
            rewrite ^/(.*)-3/(.*)$ /$1-4/$2 last;
            rewrite ^/(.*)-2/(.*)$ /$1-3/$2 last;
            rewrite ^/(.*)-1/(.*)$ /$1-2/$2 last;
            rewrite ^/(.*)/(.*)$ /$1-1/$2 last;
        }
</code></pre>

<p>这里使用循环的方式在backup的location中进行处理，一个个的循环查找。使用了正则表达式和一个统一rewrite的location。</p>

<h2>Nginx配置尝试三：</h2>

<p>上面发现，其实try_files都是去查找文件，其实目录结构和访问路径是匹配的，只是请求一开始就带snaphost，倒是每次都需要处理。如果请求过来的就没有带snaphost的话！</p>

<pre><code>        location / {
            root   F:/temp;
            add_header content-type "text/html";

            try_files /snapshot/$uri /snapshot-1/$uri  /snapshot-2/$uri  /snapshot-3/$uri  /snapshot-4/$uri;
        }
</code></pre>

<p>一个location配置就行了！</p>

<h2>Nginx配置完善版：</h2>

<p>转变思路后，最开始就把请求的前置snapshot去掉rewrite去掉就行了！</p>

<pre><code>        location /snapshot {
            root   F:/temp;
            add_header content-type "text/html";

            rewrite ^/snapshot/.*/(.*)$  /$1 break ;

            try_files /snapshot/$uri /snapshot-1/$uri  /snapshot-2/$uri  /snapshot-3/$uri  /snapshot-4/$uri;
        }
</code></pre>

<h2>nginx添加模块</h2>

<p>当我们启用 &ndash;with-debug 选项重新构建好调试版的 Nginx 之后，还需要同时在配置文件中通过标准的 error_log 配置指令为错误日志使用 debug 日志级别（这同时也是最低的日志级别）：</p>

<pre><code>error_log logs/error.log debug;
</code></pre>

<p>添加echo模块：</p>

<p>下载zlib、pcre、echo：</p>

<ul>
<li><a href="http://www.zlib.net/">http://www.zlib.net/</a></li>
<li><a href="http://www.pcre.org/">http://www.pcre.org/</a></li>
<li><a href="https://github.com/openresty/echo-nginx-module">https://github.com/openresty/echo-nginx-module</a></li>
</ul>


<pre><code>tar zxvf zlib-1.2.8.tar.gz 
mv zlib-1.2.8 src/zlib
tar zxvf pcre-8.36.tar.gz 
mv pcre-8.36 src/pcre

./configure --prefix=/home/hadoop/nginx --add-module=/home/hadoop/echo-nginx-module-0.58  --with-pcre=src/pcre --with-zlib=src/zlib --with-debug 
#[hadoop@cu2 nginx-1.7.10]$ ./configure --prefix=/home/hadoop/nginx --with-http_ssl_module --with-pcre=src/pcre/ --with-zlib=src/zlib/ --with-debug
make -j2
make install
</code></pre>

<p>编译成功后，就能在location里面直接echo，页面访问时就能看到echo内容了。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.cnblogs.com/cgli/archive/2011/05/16/2047920.html">http://www.cnblogs.com/cgli/archive/2011/05/16/2047920.html</a></li>
<li><a href="http://www.cnblogs.com/tohilary/archive/2012/08/24/2653904.html">http://www.cnblogs.com/tohilary/archive/2012/08/24/2653904.html</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
