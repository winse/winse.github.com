<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: K8s | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/k8s/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2017-03-05T18:31:47+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[k8s在Centos6部署实践]]></title>
    <link href="http://winseliu.com/blog/2017/03/05/k8s-docker-multinode-on-centos6/"/>
    <updated>2017-03-05T08:49:29+08:00</updated>
    <id>http://winseliu.com/blog/2017/03/05/k8s-docker-multinode-on-centos6</id>
    <content type="html"><![CDATA[<p>centos6系统比较"老"啊，既没有systemd，也没有docker-engine。网上各种资料要么是原始安装，要么就是在centos7上装的。不太想在系统上做，按照kube-deploy的docker-multinode的脚本来进行修改安装，版本不兼容需要开推土机填坑啊，centos6上面的docker才1.7还不能用kubernetes-1.3，dashboard也需要自己安装。</p>

<p>环境描述：</p>

<ul>
<li>cu2: bootstrap(etcd, flannel), main(hyperkube, pause, kubernetes-dashboard)</li>
<li>cu4、cu5: bootstrap(flannel), main(hyperkube, pause)</li>
</ul>


<pre><code>[root@cu2 ~]# docker -H unix:///var/run/docker-bootstrap.sock ps | grep -v IMAGE | awk '{print $2}' | sort -u
gcr.io/google_containers/etcd-amd64:3.0.4
quay.io/coreos/flannel:v0.6.1-amd64
[root@cu2 ~]# docker ps | grep -v IMAGE | awk '{print $2}' | sort -u
bigdata:v1
gcr.io/google_containers/hyperkube-amd64:v1.2.7
gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.1
gcr.io/google_containers/pause:2.0
[root@cu2 ~]# ssh cu4
Last login: Sun Mar  5 02:25:14 2017 from 192.168.0.214
[root@cu4 ~]# docker -H unix:///var/run/docker-bootstrap.sock ps | grep -v IMAGE | awk '{print $2}' | sort -u
quay.io/coreos/flannel:v0.6.1-amd64
[root@cu4 ~]# docker ps | grep -v IMAGE | awk '{print $2}' | sort -u
bigdata:v1
gcr.io/google_containers/hyperkube-amd64:v1.2.7
gcr.io/google_containers/pause:2.0
</code></pre>

<ul>
<li>etcd，flannel，和kubernetes-dashboard用的是docker-multinode时的版本。</li>
<li>kubelet是1.2的最新版v1.2.7。</li>
<li>pause:2.0是启动apiserver、controller容器时自动下载的版本。</li>
</ul>


<h2>准备</h2>

<ul>
<li>安装docker，<a href="https://wiki.centos.org/zh/Cloud/Docker">Docker</a> <a href="/blog/2014/09/27/docker-start-guide-on-centos/">Docker入门</a></li>
<li>代理，<a href="/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks/">Privoxy</a></li>
<li>镜像导入导出，<a href="/blog/2017/02/06/docker-http-proxy-and-save-reload/">Docker save/load</a></li>
</ul>


<h2>先看效果（看了菜单再看吃不吃这家）</h2>

<pre><code>## 下载部署脚本 https://github.com/winse/docker-hadoop/tree/master/k8s/docker-multinode-centos6

## 防火墙
# 或者最后面增加 iptables -A INPUT -s 10.0.0.0/8 -j ACCEPT
iptables -I INPUT 1 -s 10.0.0.0/8 -j ACCEPT

## 配置参数增加双引号
sed -i 's/other_args=/other_args="" /' /etc/sysconfig/docker

## 先把镜像全部下载下来 git pull ...
* 在master节点
[root@cu2 ~]# docker images
REPOSITORY                                            TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
gcr.io/google_containers/kubernetes-dashboard-amd64   v1.5.1              9af7d5c61ccf        7 weeks ago         103.6 MB
gcr.io/google_containers/hyperkube-amd64              v1.2.7              1dd7250ed1b3        4 months ago        231.4 MB
quay.io/coreos/flannel                                v0.6.1-amd64        ef86f3a53de0        6 months ago        27.89 MB
gcr.io/google_containers/etcd-amd64                   3.0.4               ef5e89d609f1        6 months ago        39.62 MB
gcr.io/google_containers/pause                        2.0                 9981ca1bbdb5        17 months ago       350.2 kB

## 下载kubectl
https://storage.googleapis.com/kubernetes-release/release/v1.2.7/bin/linux/amd64/kubectl 
https://kubernetes.io/docs/user-guide/prereqs/
https://kubernetes.io/docs/user-guide/kubectl/kubectl_version/

## 环境变量
export KUBECONFIG=/var/lib/kubelet/kubeconfig/kubeconfig.yaml
export PATH=...

## 启动MASTER
./master.sh

## 测试效果
curl -fsSL http://localhost:2379/health
curl -s http://localhost:8080/healthz
curl -s http://localhost:8080/api
kubectl get ns
kubectl create namespace kube-system

* 在worker节点
[root@cu4 ~]# docker images
REPOSITORY                                 TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
gcr.io/google_containers/hyperkube-amd64   v1.2.7              1dd7250ed1b3        4 months ago        231.4 MB
quay.io/coreos/flannel                     v0.6.1-amd64        ef86f3a53de0        6 months ago        27.89 MB
gcr.io/google_containers/pause             2.0                 9981ca1bbdb5        17 months ago       350.2 kB

## 启动WORKER
MASTER_IP=cu2 ./worker.sh
</code></pre>

<p>在第一次启动master脚本可能会有点问题：setup-files容器运行可能不正常，可手动登录kubelet的容器执行一次setup-files.sh脚本临时修复。如果不急的话等上一段时间多run几次后好像也能跑起来（囧）</p>

<pre><code>[root@cu2 ~]# docker exec -ti kube_kubelet_624b2 bash
root@cu2:/# /setup-files.sh IP:10.0.0.1,DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc,DNS:kubernetes.default.svc.cluster.local

然后再次提交dashboard：
[root@cu2 docker-multinode-centos6]# ./dashboard.sh 
</code></pre>

<p>然后启动应用，测试多节点的情况下启动的容器网络能否互通：</p>

<pre><code>## 运行查看容器
[root@cu2 ~]# kubectl run redis --image=bigdata:v1 -r 5 --command -- /usr/sbin/sshd -D

[root@cu2 ~]# kubectl get pods -o wide
NAME                       READY     STATUS    RESTARTS   AGE       NODE
k8s-master-192.168.0.214   4/4       Running   22         1h        192.168.0.214
k8s-proxy-192.168.0.214    1/1       Running   0          1h        192.168.0.214
redis-2212193268-1789v     1/1       Running   0          1h        192.168.0.174
redis-2212193268-1j4ej     1/1       Running   0          1h        192.168.0.174
redis-2212193268-8dbmq     1/1       Running   0          1h        192.168.0.30
redis-2212193268-a447n     1/1       Running   0          1h        192.168.0.30
redis-2212193268-tu5fl     1/1       Running   0          1h        192.168.0.214

https://kubernetes.io/docs/user-guide/jsonpath/
[root@cu2 ~]# kubectl get pods -o wide -l run=redis -o jsonpath={..podIP}
10.1.75.2 10.1.75.3 10.1.58.3 10.1.58.2 10.1.33.3

## 登录容器
# 用ssh登录
[root@cu2 ~]# kubectl describe pods redis-2212193268-tu5fl | grep IP
IP:             10.1.33.3
[root@cu2 ~]# ssh 10.1.33.3
The authenticity of host '10.1.33.3 (10.1.33.3)' can't be established.
RSA key fingerprint is e5:58:ae:3b:54:c9:bb:0d:4c:9b:bc:fd:04:fe:be:cc.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '10.1.33.3' (RSA) to the list of known hosts.
root@10.1.33.3's password: 
Last login: Sat Mar  4 18:17:51 2017 from 10.1.61.1
[root@redis-2212193268-tu5fl ~]# exit
logout
Connection to 10.1.33.3 closed.

# exec登录
[root@cu2 ~]# kubectl exec -ti redis-2212193268-tu5fl bash
[root@redis-2212193268-tu5fl /]# 

## ping五台机器全部节点的机器都是互通的
[root@redis-2212193268-tu5fl /]# ping 10.1.75.2
PING 10.1.75.2 (10.1.75.2) 56(84) bytes of data.
64 bytes from 10.1.75.2: icmp_seq=1 ttl=60 time=1.15 ms
64 bytes from 10.1.75.2: icmp_seq=2 ttl=60 time=0.607 ms
^C
--- 10.1.75.2 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1492ms
rtt min/avg/max/mdev = 0.607/0.880/1.154/0.275 ms
[root@redis-2212193268-tu5fl /]# ping 10.1.75.3
PING 10.1.75.3 (10.1.75.3) 56(84) bytes of data.
64 bytes from 10.1.75.3: icmp_seq=1 ttl=60 time=1.23 ms
64 bytes from 10.1.75.3: icmp_seq=2 ttl=60 time=0.702 ms
^C
--- 10.1.75.3 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1311ms
rtt min/avg/max/mdev = 0.702/0.966/1.231/0.266 ms
[root@redis-2212193268-tu5fl /]# ping 10.1.58.3
PING 10.1.58.3 (10.1.58.3) 56(84) bytes of data.
64 bytes from 10.1.58.3: icmp_seq=1 ttl=60 time=1.60 ms
64 bytes from 10.1.58.3: icmp_seq=2 ttl=60 time=0.521 ms
^C
--- 10.1.58.3 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1510ms
rtt min/avg/max/mdev = 0.521/1.061/1.602/0.541 ms
[root@redis-2212193268-tu5fl /]# ping 10.1.58.2
PING 10.1.58.2 (10.1.58.2) 56(84) bytes of data.
64 bytes from 10.1.58.2: icmp_seq=1 ttl=60 time=1.39 ms
64 bytes from 10.1.58.2: icmp_seq=2 ttl=60 time=0.432 ms
^C
--- 10.1.58.2 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1470ms
rtt min/avg/max/mdev = 0.432/0.915/1.398/0.483 ms
[root@redis-2212193268-tu5fl /]# ping 10.1.33.3         
PING 10.1.33.3 (10.1.33.3) 56(84) bytes of data.
64 bytes from 10.1.33.3: icmp_seq=1 ttl=64 time=0.036 ms
64 bytes from 10.1.33.3: icmp_seq=2 ttl=64 time=0.049 ms
^C
--- 10.1.33.3 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1373ms
rtt min/avg/max/mdev = 0.036/0.042/0.049/0.009 ms
</code></pre>

<p>全部启动好后dashboard的效果图：</p>

<p><img src="/images/blogs/k8s-dashboard.jpg" alt="" /></p>

<h2>从脚本中学习</h2>

<p>官网这份<a href="https://kubernetes.io/docs/getting-started-guides/scratch/#starting-cluster-services">Creating a Custom Cluster from Scratch</a> 看的糊里糊涂，真不是给入门级的同学看的。需要有一定的实践经验才能看的懂。</p>

<p>另辟蹊径，根据docker-multi的启动脚本来拆分学习然后模拟动手实践。在根据 <a href="https://kubernetes.io/docs/getting-started-guides/docker-multinode/">Portable Multi-Node Cluster</a> 文档学习操作的时刻不理解bootstrap docker以及main docker的含义。这次通过单独运行提取每个函数运行后才理解，其实就相当于跑两个docker应用程序，互相不影响。</p>

<pre><code>[root@cu2 ~]# ps aux|grep docker
root      5310  0.0  0.2 645128 19180 pts/1    Sl   13:14   0:01 docker -d -H unix:///var/run/docker-bootstrap.sock -p /var/run/docker-bootstrap.pid --iptables=false --ip-masq=false --bridge=none --graph=/var/lib/docker-bootstrap --exec-root=/var/run/docker-bootstrap
root      5782  1.1  0.5 2788284 43620 pts/1   Sl   13:14   0:23 /usr/bin/docker -d --mtu=1464 --bip=10.1.33.1/24
root     10935  0.0  0.0 103316   896 pts/1    S+   13:47   0:00 grep docker
</code></pre>

<p>bootstrap docker启动后，容器etcd和flannel启动都很顺利。</p>

<ul>
<li>问题1： 执行docker0网卡重置失败（问题都是在自己虚拟机试，弄好后再放到测试环境的）：</li>
</ul>


<pre><code>[root@bigdata1 data]# ip link set docker0 down
[root@bigdata1 data]# ip link del docker0
RTNETLINK answers: Operation not supported

[root@bigdata1 data]# ip addr 

删不掉，但是可以修改ip地址来实现相似的效果

ifconfig docker0 ${FLANNEL_SUBNET}
或者 
[root@bigdata1 data]# ip link set dev docker0 mtu 1460
[root@bigdata1 data]# ip addr del 172.17.42.1/16 dev docker0
[root@bigdata1 data]# ip addr add ${FLANNEL_SUBNET} dev docker0
[root@bigdata1 data]# ip link set dev docker0 up
[root@bigdata1 data]# ifconfig

先添加参数在前端运行
[root@bigdata1 data]# docker -d --mtu=1472 --bip=10.1.42.1/24

启动
[root@bigdata1 data]# sed -i 's/other_args=/other_args="--mtu=1472 --bip=10.1.42.1/24"/' /etc/sysconfig/docker
[root@bigdata1 data]# service docker start
Starting docker:                                           [确定]
[root@bigdata1 data]# service docker status
docker (pid  4542) 正在运行...
</code></pre>

<ul>
<li>问题2：volumns mount不支持shared</li>
</ul>


<pre><code>[root@bigdata1 data]# echo $KUBELET_MOUNTS
-v /sys:/sys:rw -v /var/run:/var/run:rw -v /run:/run:rw -v /var/lib/docker:/var/lib/docker:rw -v /var/lib/kubelet:/var/lib/kubelet:shared -v /var/log/containers:/var/log/containers:rw

[root@bigdata1 data]# mkdir -p /var/lib/kubelet
[root@bigdata1 data]# mount --bind /var/lib/kubelet /var/lib/kubelet
[root@bigdata1 data]# mount --make-shared /var/lib/kubelet

[root@bigdata1 data]# docker run -d \
&gt;     --net=host \
&gt;     --pid=host \
&gt;     --privileged \
&gt;     --name kube_kubelet_$(kube::helpers::small_sha) \
&gt;     ${KUBELET_MOUNTS} \
&gt;     gcr.io/google_containers/hyperkube-${ARCH}:${K8S_VERSION} \
&gt;     /hyperkube kubelet \
&gt;       --allow-privileged \
&gt;       --api-servers=http://localhost:8080 \
&gt;       --config=/etc/kubernetes/manifests-multi \
&gt;       --cluster-dns=10.0.0.10 \
&gt;       --cluster-domain=cluster.local \
&gt;       ${CNI_ARGS} \
&gt;       ${CONTAINERIZED_FLAG} \
&gt;       --hostname-override=${IP_ADDRESS} \
&gt;       --v=2
Error response from daemon: invalid mode for volumes-from: shared

# 改成z
    KUBELET_MOUNT="-v /var/lib/kubelet:/var/lib/kubelet:z"

[root@bigdata1 ~]# echo $KUBELET_MOUNTS
-v /sys:/sys:rw -v /var/run:/var/run:rw -v /run:/run:rw -v /var/lib/docker:/var/lib/docker:rw -v /var/lib/kubelet:/var/lib/kubelet:z -v /var/log/containers:/var/log/containers:rw
</code></pre>

<ul>
<li>问题3：cgroup问题</li>
</ul>


<pre><code>Error: failed to run Kubelet: failed to get mounted cgroup subsystems: failed to find cgroup mounts
failed to run Kubelet: failed to get mounted cgroup subsystems: failed to find cgroup mounts

centos7 
[root@k8s docker.service.d]# ll /sys/fs/cgroup/
blkio/            cpuacct/          cpuset/           freezer/          memory/           net_cls,net_prio/ perf_event/       systemd/          
cpu/              cpu,cpuacct/      devices/          hugetlb/          net_cls/          net_prio/         pids/             

centos6
http://wushank.blog.51cto.com/3489095/1203545
[root@bigdata1 bin]# ls /cgroup/
blkio  cpu  cpuacct  cpuset  devices  freezer  memory  net_cls

把/cgroup加入到卷映射路径
  KUBELET_MOUNTS="\
    ${ROOTFS_MOUNT} \
    -v /sys:/sys:rw \
    -v /cgroup:/cgroup:rw \
    -v /var/run:/var/run:rw \
    -v /run:/run:rw \
    -v /var/lib/docker:/var/lib/docker:rw \
    ${KUBELET_MOUNT} \
    -v /var/log/containers:/var/log/containers:rw"
</code></pre>

<ul>
<li>问题4：再说版本，v1.3+的版本在centos6上运行kubelet报错：</li>
</ul>


<pre><code>[root@bigdata1 ~]# docker logs 7a2f7aec2239
...
E0228 10:56:05.408129    2516 kubelet.go:2049] Container runtime sanity check failed: container runtime version is older than 1.21
</code></pre>

<p>1.3以上的版本都会报这个错。kubernetes用1.2.7的版本即可。</p>

<ul>
<li>问题5：dashboard配置注意点</li>
</ul>


<p>1 imagePullPolicy 就是个坑啊！改成IfNotPresent <a href="https://kubernetes.io/docs/user-guide/images/  ">https://kubernetes.io/docs/user-guide/images/  </a>
2 namespace 也不能改，好像会写数据库然后指定的namespace就是kube-system
3 apiserver 由于没有addon-manager的支持，暂时使用http获取数据</p>

<p>处理完以上问题，K8S集群就跑起来了，然后整合成开始用的脚本。当然后续还有很多工作，不仅仅是怎么用，还有一些其他辅助的软件需要配置和安装。</p>

<h2>后续学习操作</h2>

<ul>
<li>DNS</li>
<li>监控 <a href="https://kubernetes.io/docs/user-guide/monitoring/">https://kubernetes.io/docs/user-guide/monitoring/</a></li>
<li>安全HTTPS <a href="https://kubernetes.io/docs/admin/authentication/#creating-certificates">https://kubernetes.io/docs/admin/authentication/#creating-certificates</a></li>
<li>register</li>
</ul>


<h2>其他参考</h2>

<ul>
<li><a href="http://chenguomin.blog.51cto.com/8794192/1828905">http://chenguomin.blog.51cto.com/8794192/1828905</a></li>
<li><a href="http://www.pangxie.space/docker/618">http://www.pangxie.space/docker/618</a></li>
<li><a href="https://kubernetes.io/docs/user-guide/kubeconfig-file/">https://kubernetes.io/docs/user-guide/kubeconfig-file/</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s集群部署]]></title>
    <link href="http://winseliu.com/blog/2017/02/25/k8s-docker-multinode/"/>
    <updated>2017-02-25T21:25:26+08:00</updated>
    <id>http://winseliu.com/blog/2017/02/25/k8s-docker-multinode</id>
    <content type="html"><![CDATA[<p>前面讲了在本机windows安装方式，最近在linux多机器上尝试部署并操作。</p>

<p>先看官网的文档<a href="https://kubernetes.io/docs/getting-started-guides/docker-multinode/">Portable Multi-Node Cluster</a>。这里根据文章进行实际操作记录下来，k8s是真的好用管理起来很方便。</p>

<h2>安装docker（on centos7）</h2>

<h4>不正确的打开方式</h4>

<p>不要用这种方式安装</p>

<pre><code>[root@k8s ~]# yum install docker

[root@k8s ~]# docker -v
Docker version 1.12.5, build 047e51b/1.12.5
</code></pre>

<p>否则运行报错的daemon语句，报错：</p>

<pre><code>[root@k8s docker-multinode]# docker daemon -H unix:///var/run/docker-bootstrap.sock -p /var/run/docker-bootstrap.pid --iptables=false --ip-masq=false --bridge=none --graph=/var/lib/docker-bootstrap --exec-root=/var/run/docker-bootstrap
exec: "dockerd": executable file not found in $PATH
</code></pre>

<p>先清理旧的软件</p>

<pre><code>yum remove docker -y
yum remove container-selinux -y
yum remove docker-common -y
</code></pre>

<h4>安装docker的正确姿势</h4>

<ul>
<li><a href="https://docs.docker.com/engine/installation/linux/centos/">Get Docker for CentOS</a></li>
</ul>


<pre><code>[root@k8s ~]# yum install -y yum-utils

[root@k8s ~]# yum-config-manager --add-repo https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo
Loaded plugins: fastestmirror, langpacks
Repository base is listed more than once in the configuration
Repository updates is listed more than once in the configuration
Repository extras is listed more than once in the configuration
Repository centosplus is listed more than once in the configuration
adding repo from: https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo
grabbing file https://docs.docker.com/engine/installation/linux/repo_files/centos/docker.repo to /etc/yum.repos.d/docker.repo
repo saved to /etc/yum.repos.d/docker.repo

[root@k8s ~]# yum makecache fast
[root@k8s ~]# yum -y install docker-engine

# 把保存数据的目录转移到大磁盘下面去
先启动服务来产生docker目录
[root@k8s ~]# service docker start
[root@k8s ~]# service docker stop

[root@k8s ~]# rm -rf /var/lib/docker/
[root@k8s ~]# ln -s /data/var/lib/docker /var/lib/
</code></pre>

<h2>安装k8s</h2>

<ul>
<li><a href="https://kubernetes.io/docs/getting-started-guides/docker-multinode/">Portable Multi-Node Cluster</a></li>
</ul>


<h4>准备</h4>

<ul>
<li><a href="https://kubernetes.io/docs/user-guide/prereqs/">Installing and Setting up kubectl</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/kubectl/">https://kubernetes.io/docs/getting-started-guides/kubectl/</a></li>
</ul>


<pre><code># 删除旧的容器
[root@k8s docker-multinode]# docker rm -f `docker ps -a | grep -v IMAGE | awk '{print $1}'`
[root@k8s docker-multinode]# docker ps -a

# 下载部署的工具
[root@k8s ~]# yum install git -y
[root@k8s ~]# git clone https://github.com/kubernetes/kube-deploy

# kubectl安装，需要代理你懂得 
export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8"
export https_proxy=http://k8s:8118/
export http_proxy=http://k8s:8118/

[root@k8s ~]# curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 48.0M  100 48.0M    0     0  1692k      0  0:00:29  0:00:29 --:--:-- 2351k
[root@k8s ~]# chmod +x kubectl 
[root@k8s ~]# mkdir ~/bin
[root@k8s ~]# mv ./kubectl ~/bin/

[root@k8s ~]# source &lt;(kubectl completion bash)
[root@k8s ~]# echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc
== 修改成下面的语句，不然你scp、rsync就不能用了: https://my.oschina.net/leejun2005/blog/342865
== export PATH=~/bin:$PATH
== [[ $- == *i* ]] &amp;&amp; source &lt;(kubectl completion bash)
</code></pre>

<h4>启动master</h4>

<pre><code>[root@k8s ~]# cd kube-deploy/docker-multinode/
[root@k8s docker-multinode]# ./master.sh 
+++ [0206 19:07:23] K8S_VERSION is set to: v1.5.2
+++ [0206 19:07:23] ETCD_VERSION is set to: 3.0.4
+++ [0206 19:07:23] FLANNEL_VERSION is set to: v0.6.1
+++ [0206 19:07:23] FLANNEL_IPMASQ is set to: true
+++ [0206 19:07:23] FLANNEL_NETWORK is set to: 10.1.0.0/16
+++ [0206 19:07:23] FLANNEL_BACKEND is set to: udp
+++ [0206 19:07:23] RESTART_POLICY is set to: unless-stopped
+++ [0206 19:07:23] MASTER_IP is set to: localhost
+++ [0206 19:07:23] ARCH is set to: amd64
+++ [0206 19:07:23] IP_ADDRESS is set to: 192.168.1.112
+++ [0206 19:07:23] USE_CNI is set to: false
+++ [0206 19:07:23] USE_CONTAINERIZED is set to: false
+++ [0206 19:07:23] --------------------------------------------
+++ [0206 19:07:23] Killing docker bootstrap...
+++ [0206 19:07:24] Killing all kubernetes containers...
Do you want to clean /var/lib/kubelet? [Y/n] y
+++ [0206 19:07:27] Launching docker bootstrap...
+++ [0206 19:07:28] Launching etcd...
3ff0f0fd7a08282930449b2f496f786b9857f6290698d612cebc2086d1a1765c
+++ [0206 19:07:31] Launching flannel...
{"action":"set","node":{"key":"/coreos.com/network/config","value":"{ \"Network\": \"10.1.0.0/16\", \"Backend\": {\"Type\": \"udp\"}}","modifiedIndex":4,"createdIndex":4}}
3651d077f453900a898ce6ad9fe67a7422f0c8084ec86b6e6a1a2ab6b9b1c629
+++ [0206 19:07:33] FLANNEL_SUBNET is set to: 10.1.42.1/24
+++ [0206 19:07:33] FLANNEL_MTU is set to: 1472
+++ [0206 19:07:33] Restarting main docker daemon...
+++ [0206 19:07:38] Restarted docker with the new flannel settings
+++ [0206 19:07:38] Launching Kubernetes master components...
d10130677853022fe37742437e39b21b3fcfbb90b3f24075457f469e238b0712
+++ [0206 19:07:42] Done. It may take about a minute before apiserver is up.

[root@k8s docker-multinode]# docker ps -a
...一堆容器列表
</code></pre>

<p>如果有问题基本就是防火墙的问题（我遇到过的啊，下载镜像和本地firewall设置的问题）。</p>

<p>上面安装kubectl时已经配置了代理地址。如果部署master的时刻pull镜像出错，那还得需要给docker配置代理增加配置 /etc/systemd/system/docker.service.d/http-proxy.conf  参考 <a href="https://docs.docker.com/engine/admin/systemd/#http-proxy">https://docs.docker.com/engine/admin/systemd/#http-proxy</a> 。具体错误详情及处理查看下面的【问题及处理】部分</p>

<p><strong>安装启动好</strong>后，就可以通过浏览器图形界面来管理集群了(dashboard启动有问题的话查看后面的问题处理)： <a href="http://k8s:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default">http://k8s:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default</a></p>

<h4>启动worker</h4>

<p>下载安装软件的工作这里就不帖了，和master一样的：安装git、clone kube-deploy、docker。</p>

<p>防火墙配置，master/slaves之间互通</p>

<pre><code>centos7 firewall的add-source不知道怎么用的，反正加了地址也没效果；后面通过rule规则来实现。
[root@bigdata-dev ~]# vi /etc/firewalld/zones/public.xml
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;zone&gt;
  &lt;rule family="ipv4"&gt;
    &lt;source address="192.168.1.112/32"/&gt;
    &lt;accept/&gt;
  &lt;/rule&gt;
  &lt;service name="ssh"/&gt;
  &lt;port protocol="tcp" port="80"/&gt;
  &lt;port protocol="tcp" port="6379"/&gt;
  &lt;port protocol="tcp" port="8080"/&gt;
&lt;/zone&gt;
[root@bigdata-dev ~]# firewall-cmd --complete-reload
success
[root@bigdata-dev ~]# firewall-cmd --list-all
public (active)
  target: default
  icmp-block-inversion: no
  interfaces: p4p1
  sources: 
  services: ssh
  ports: 80/tcp 6379/tcp 8080/tcp
  protocols: 
  masquerade: no
  forward-ports: 
  sourceports: 
  icmp-blocks: 
  rich rules: 
        rule family="ipv4" source address="192.168.1.112/32" accept

[root@k8s ~]# cat /etc/firewalld/zones/public.xml
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;zone&gt;
  &lt;rule family="ipv4"&gt;
    &lt;source address="192.168.1.248"/&gt;
    &lt;accept/&gt;
  &lt;/rule&gt;
  &lt;service name="ssh"/&gt;
  &lt;port protocol="tcp" port="6443"/&gt;
  &lt;port protocol="tcp" port="2379"/&gt;
  &lt;port protocol="tcp" port="8118"/&gt;
&lt;/zone&gt;
</code></pre>

<p>加载已经下载的镜像。从master拷贝过来（save/load）不要浪费VPN流量啦：</p>

<pre><code>[root@bigdata-dev docker-multinode]# docker load &lt;k8s.tar
</code></pre>

<p>运行worker启动脚本：</p>

<pre><code># 设置代理。如果有docker镜像下载失败的话再配置docker环境变量
export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8"
export https_proxy=http://k8s:8118/
export http_proxy=http://k8s:8118/

[root@bigdata-dev docker-multinode]# export MASTER_IP=192.168.1.112 
[root@bigdata-dev docker-multinode]# ./worker.sh 
+++ [0208 08:59:37] K8S_VERSION is set to: v1.5.2
+++ [0208 08:59:37] ETCD_VERSION is set to: 3.0.4
+++ [0208 08:59:37] FLANNEL_VERSION is set to: v0.6.1
+++ [0208 08:59:37] FLANNEL_IPMASQ is set to: true
+++ [0208 08:59:37] FLANNEL_NETWORK is set to: 10.1.0.0/16
+++ [0208 08:59:37] FLANNEL_BACKEND is set to: udp
+++ [0208 08:59:37] RESTART_POLICY is set to: unless-stopped
+++ [0208 08:59:37] MASTER_IP is set to: 192.168.1.112
+++ [0208 08:59:37] ARCH is set to: amd64
+++ [0208 08:59:37] IP_ADDRESS is set to: 192.168.1.248
+++ [0208 08:59:37] USE_CNI is set to: false
+++ [0208 08:59:37] USE_CONTAINERIZED is set to: false
+++ [0208 08:59:37] --------------------------------------------
+++ [0208 08:59:37] Killing all kubernetes containers...
+++ [0208 08:59:37] Launching docker bootstrap...
+++ [0208 08:59:38] Launching flannel...
+++ [0208 08:59:39] FLANNEL_SUBNET is set to: 10.1.42.1/24
+++ [0208 08:59:39] FLANNEL_MTU is set to: 1472
+++ [0208 08:59:39] Restarting main docker daemon...
+++ [0208 08:59:43] Restarted docker with the new flannel settings
+++ [0208 08:59:43] Launching Kubernetes worker components...
1ce6ee6af709485668c9f170b1bc234b34d55d18e53116295c887c88046ca231
+++ [0208 08:59:44] Done. After about a minute the node should be ready.
</code></pre>

<h2>查看集群状态</h2>

<p>安装好了后，需要学习基本的管理操作</p>

<ul>
<li>交互式的学习一些基本概念命令 <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Kubernetes Basics</a></li>
<li>常用的kubectl命令册子 <a href="https://kubernetes.io/docs/user-guide/kubectl-cheatsheet/">kubectl Cheat Sheet</a></li>
</ul>


<pre><code>[root@k8s ~]# kubectl cluster-info
Kubernetes master is running at http://localhost:8080
KubeDNS is running at http://localhost:8080/api/v1/proxy/namespaces/kube-system/services/kube-dns
kubernetes-dashboard is running at http://localhost:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

[root@k8s ~]# kubectl get service
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   10.0.0.1     &lt;none&gt;        443/TCP   16d

[root@k8s ~]# kubectl get nodes
NAME            STATUS    AGE
192.168.1.112   Ready     16d
192.168.1.248   Ready     16d

[root@k8s ~]# kubectl get pods --namespace=kube-system
NAME                                    READY     STATUS    RESTARTS   AGE
k8s-master-192.168.1.112                4/4       Running   9          1d
k8s-proxy-v1-4hp8c                      1/1       Running   0          1d
k8s-proxy-v1-htrrf                      1/1       Running   0          1d
kube-addon-manager-192.168.1.112        2/2       Running   0          1d
kube-dns-4101612645-q0kcw               4/4       Running   0          1d
kubernetes-dashboard-3543765157-hsls9   1/1       Running   0          1d

dashboard运行正常的话，就可以通过浏览器查看以及管理集群
== https://kubernetes.io/docs/user-guide/ui/
== 走socks5代理
http://k8s:8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard/#/workload?namespace=default
</code></pre>

<h2>问题及处理</h2>

<p>镜像或者启动失败的问题可以输出脚本调试信息，获取到出错位置的命令单独重新执行来定位。</p>

<p>另一种情况，脚本启动完成后，服务不能正常运行。重启机器，再次运行master后就不能访问dashboard了，把master机器的防火墙关闭就行了。github上有同样的一个问题<a href="https://github.com/kubernetes/dashboard/issues/916">https://github.com/kubernetes/dashboard/issues/916</a></p>

<p>处理定位问题步骤如下：</p>

<p>清理所有重新弄，无济于事</p>

<pre><code>docker kill $(docker ps -q)
docker rm $(docker ps -aq)
[reboot]
sudo rm -R /var/lib/kubelet
sudo rm -R /var/run/kubernetes

./turndown.sh &amp; ./master.sh 
kubectl get pods --namespace=kube-system # 显示的dashboard容器启动总是失败，可以通过kubectl logs/docker logs查看。
</code></pre>

<p>重新定位问题</p>

<pre><code>既然关闭防火墙能正常运行，下面通过拦截日志查看封堵日志
[root@k8s ~]# firewall-cmd --set-log-denied=all

[root@k8s ~]# less /var/log/messages
Feb 25 00:04:30 k8s kernel: XFS (dm-32): Unmounting Filesystem
Feb 25 00:04:30 k8s kernel: XFS (dm-32): Mounting V5 Filesystem
Feb 25 00:04:30 k8s kernel: XFS (dm-32): Ending clean mount
Feb 25 00:04:32 k8s kernel: FINAL_REJECT: IN=docker0 OUT= PHYSIN=veth2fd9745 MAC=02:42:cf:c5:2c:da:02:42:0a:01:49:03:08:00 SRC=10.1.73.3 DST=192.168.1.112 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=11531 DF PROTO=TCP SPT=38734 DPT=6443 WINDOW=28640 RES=0x00 SYN URGP=0 
Feb 25 00:04:33 k8s kernel: FINAL_REJECT: IN=docker0 OUT= PHYSIN=veth2fd9745 MAC=02:42:cf:c5:2c:da:02:42:0a:01:49:03:08:00 SRC=10.1.73.3 DST=192.168.1.112 LEN=60 TOS=0x00 PREC=0x00 TTL=64 ID=11532 DF PROTO=TCP SPT=38734 DPT=6443 WINDOW=28640 RES=0x00 SYN URGP=0 
Feb 25 00:04:33 k8s dockerd: time="2017-02-25T00:04:33.935301481+08:00" level=error msg="containerd: deleting container" error="exit status 1: \"container dcb4a44031b96470eaef50eb8ac4ee2b9f958906702d94645c3a45c4852b6335 does not exist\\none or more of the container deletions failed\\n\""
Feb 25 00:04:34 k8s kernel: XFS (dm-32): Unmounting Filesystem
Feb 25 00:04:35 k8s systemd-udevd: inotify_add_watch(7, /dev/dm-32, 10) failed: No such file or directory
Feb 25 00:04:36 k8s systemd-udevd: inotify_add_watch(7, /dev/dm-32, 10) failed: No such file or directory
Feb 25 00:04:36 k8s dockerd: time="2017-02-25T00:04:36.406470062+08:00" level=error msg="Handler for GET /v1.25/containers/5bd86339f0dcd513da632ec300d4235d8a09c3f9546f751ac8874de411de3c10/json returned error: No such container: 5bd86339f0dcd513da632ec300d4235d8a09c3f9546f751ac8874de411de3c10"
可以看出访问的端口6443被拦截了
</code></pre>

<p>开放6443端口dashboard启动成功。通过浏览器能正常访问</p>

<p></p>

<pre><code>[root@k8s ~]# firewall-cmd --zone=public --add-port=6443/tcp --permanent
success
[root@k8s ~]# firewall-cmd --reload
success

[root@k8s ~]# kubectl get pods --namespace=kube-system
NAME                                    READY     STATUS    RESTARTS   AGE
k8s-master-192.168.1.112                4/4       Running   1          9m
k8s-proxy-v1-nzkgt                      1/1       Running   0          9m
kube-addon-manager-192.168.1.112        2/2       Running   0          8m
kube-dns-4101612645-k4j0s               4/4       Running   4          9m
kubernetes-dashboard-3543765157-h5g5f   1/1       Running   6          9m
等所有都Running才能通过dashboard查看
</code></pre>

<h2>使用</h2>

<p>使用已有镜像（网上、本地）</p>

<pre><code>[root@k8s ~]# kubectl run hello-nginx --image=nginx --port=80

[root@k8s ~]# kubectl get pods
NAME                           READY     STATUS    RESTARTS   AGE
hello-nginx-2471083592-94pm7   1/1       Running   0          19m
[root@k8s ~]# kubectl describe pod hello-nginx-2471083592-94pm7
Name:           hello-nginx-2471083592-94pm7
Namespace:      default
Node:           192.168.1.248/192.168.1.248
Start Time:     Fri, 24 Feb 2017 12:37:30 +0800
Labels:         pod-template-hash=2471083592
                run=hello-nginx
Status:         Running
IP:             10.1.42.3
Controllers:    ReplicaSet/hello-nginx-2471083592
</code></pre>

<p>查看到pod的ip，登录Node对应的机器就可以直接通过IP访问了。IP与flannel0网卡在同一网段。</p>

<p>定制镜像</p>

<pre><code>[root@k8s ~]# docker pull centos:centos5
[root@k8s ~]# docker pull centos:centos6
[root@k8s ~]# docker pull centos:centos7

把最新的修改提交保存为行的镜像。
登录centos6，安装sshd后，启动sshd服务（产生key）。清理yum缓冲、临时文件/tmp、以及history等。写Dockerfile减小镜像的大小： https://hui.lu/reduce-docker-image-size/  
[root@k8s ~]# docker run -t -i centos:centos6 
...yum install -y openssh-server openssh-clients ; service sshd start ; yum clean all ; history -c ; rm -rf /tmp/*

提交的名字一定要打标签tag
[root@k8s ~]# docker ps -a
[root@k8s ~]# docker commit CONTAINER_ID bigdata:v1
查看下版本的历史
[root@k8s ~]# docker history bigdata:v1

[root@k8s ~]# docker images
[root@k8s ~]# docker save centos:centos5 centos:centos6 centos:centos7 bigdata:v1 &gt;bigdata.tar

拷贝
[root@bigdata-dev ~]# scp k8s:~/bigdata.tar ./
centos.tar                                                                                                                                               100%  668MB  11.1MB/s   01:00    
[root@bigdata-dev ~]# docker load &lt;bigdata.tar
[root@bigdata-dev ~]# docker images

真正的跑自己的镜像
[root@k8s ~]# kubectl run hadoop --image=bigdata:v1 --command -- /usr/sbin/sshd -D
deployment "hadoop" created
</code></pre>

<p>查看运行情况以及一些简单操作</p>

<ul>
<li><a href="https://kubernetes.io/docs/user-guide/debugging-pods-and-replication-controllers/">https://kubernetes.io/docs/user-guide/debugging-pods-and-replication-controllers/</a></li>
</ul>


<pre><code>[root@k8s ~]# kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
hadoop-2607718808-cqx2n   1/1       Running   0          2h
[root@k8s ~]# kubectl describe pods hadoop-2607718808-cqx2n
通过输出信息中Node和IP即可通过登录主机（IP与flannel0网卡在同一网段）

也可以通过kubectl来登录
[root@k8s ~]# kubectl exec hadoop-2607718808-cqx2n -i -t -- bash 
[root@hadoop-2607718808-cqx2n /]# 
[root@hadoop-2607718808-cqx2n /]# ifconfig 
eth0      Link encap:Ethernet  HWaddr 02:42:0A:01:49:02  
          inet addr:10.1.73.2  Bcast:0.0.0.0  Mask:255.255.255.0
          inet6 addr: fe80::42:aff:fe01:4902/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1472  Metric:1
          RX packets:8 errors:0 dropped:0 overruns:0 frame:0
          TX packets:8 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:648 (648.0 b)  TX bytes:648 (648.0 b)

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1 
          RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)

[root@k8s ~]# kubectl scale --replicas=4 deployment/hadoop
[root@k8s ~]# kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
hadoop-2607718808-0dzm6   1/1       Running   0          15s
hadoop-2607718808-9twzq   1/1       Running   0          15s
hadoop-2607718808-cqx2n   1/1       Running   0          6h
hadoop-2607718808-k243d   1/1       Running   0          15s

登上以及启动的机器
[root@k8s ~]# kubectl exec hadoop-2607718808-cqx2n -i -t -- bash
[root@hadoop-2607718808-cqx2n /]# 

改变部署实例个数
[root@k8s ~]# kubectl scale --replicas=2 deployment/hadoop
deployment "hadoop" scaled
[root@k8s ~]# kubectl get pods
NAME                      READY     STATUS    RESTARTS   AGE
hadoop-2607718808-cqx2n   1/1       Running   0          6h
hadoop-2607718808-k243d   1/1       Running   0          9m
</code></pre>

<h2>小结</h2>

<p>通过脚本来安装其实不难，就是要翻墙以及一些防火墙的设置需要特别的注意。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s Minikube on Windows]]></title>
    <link href="http://winseliu.com/blog/2017/02/08/k8s-minikube-on-windows/"/>
    <updated>2017-02-08T22:50:06+08:00</updated>
    <id>http://winseliu.com/blog/2017/02/08/k8s-minikube-on-windows</id>
    <content type="html"><![CDATA[<p>在windows配置minikube需要先安装docker，或者更直接点的说就是需要docker一样的依赖环境（都是通过iso装载到虚拟机，我们这里不考虑iso内部的软件配置）。先安装docker会把这些依赖都配置好。</p>

<p>系统当前的版本不支持直接安装<a href="https://docs.docker.com/docker-for-windows/">Docker</a>（This version of Docker requires Windows 10 Pro, Enterprise or Education edition with a mininum build number of 10586, Please use <a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox</a>），</p>

<ul>
<li><a href="https://docs.docker.com/toolbox/toolbox_install_windows/">https://docs.docker.com/toolbox/toolbox_install_windows/</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226#.qvn9h99l4">Tutorial : Getting Started with Kubernetes on your Windows Laptop with Minikube</a></li>
<li><a href="https://blogs.msdn.microsoft.com/wasimbloch/2017/01/23/setting-up-kubernetes-on-windows10-laptop-with-minikube/">Setting up Kubernetes on Windows10 Laptop with Minikube use Hyper-V</a></li>
</ul>


<p>如果直接全部安装toolbox的VirtualBox、git的应该一切顺利的。由于已有cygwin，想着复用下结果惹了一身骚。</p>

<p>按照自己的安装过程，先介绍下配合cygwin安装docker，然后再介绍全部按官网的工具安装k8s。</p>

<h2>仅尝试Docker，不安装k8s</h2>

<p>但是不想安装git直接使用cygwin来代替。刚刚开始的时刻出现了一些理解上的偏差，后来查询start.sh脚本后大概了解到快捷方式、脚本内容后问题就迎刃而解。</p>

<p>先安装docker toolbox：先禁用windows的Hyper-V；安装时去掉git组件。</p>

<p>安装完成后，启动cygwin的命令行（不要用Docker的快捷图标启动）。然后进行如下配置：</p>

<pre><code>winse@Lenovo-PC ~
$ cd "C:\Program Files\Docker Toolbox"

做一个c盘的映射
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ ll /
...
lrwxrwxrwx   1 winse None               11 Apr  5  2016 c -&gt; /cygdrive/c
...

根据cygwin的路径配置VirtualBox的路径
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ export VBOX_MSI_INSTALL_PATH="/cygdrive/c/Program Files/Oracle/VirtualBox/"

首先下载boot2docker.iso到 C:\Users\winse\.docker\machine\cache\boot2docker.iso
https://github.com/boot2docker/boot2docker/releases/download/v1.13.0/boot2docker.iso...

创建一个空的clear脚本（cygwin没有包括clear脚本）
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ touch ~/bin/clear &amp;&amp; chmod +x ~/bin/clear

# 启动
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ ./start.sh


                        ##         .
                  ## ## ##        ==
               ## ## ## ## ##    ===
           /"""""""""""""""""\___/ ===
      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~
           \______ o           __/
             \    \         __/
              \____\_______/

docker is configured to use the default machine with IP 192.168.99.100
For help getting started, check out the docs at https://docs.docker.com

Start interactive shell

winse@Lenovo-PC ~
$ docker run hello-world
time="2017-02-08T22:48:33+08:00" level=warning msg="Unable to use system certificate pool: crypto/x509: system root pool is not available on Windows"
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
78445dd45222: Pulling fs layer
78445dd45222: Verifying Checksum
78445dd45222: Download complete
78445dd45222: Pull complete
Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://cloud.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/engine/userguide/
</code></pre>

<h2>使用默认安装，并安装k8s</h2>

<p>由于cygwin的路径与windows的不兼容，而git bash则本身依托于windows的命令行的，兼容性方面更优。</p>

<p>重新安装Docker ToolBox，安装时选择git。</p>

<p>下载minikube需要的一些软件：</p>

<ul>
<li><a href="https://github.com/kubernetes/minikube/releases">minikube.exe</a></li>
<li><a href="https://github.com/kubernetes/minikube/blob/v0.16.0/README.md">minikube文档</a></li>
<li><a href="https://storage.googleapis.com/kubernetes-release/release/v1.5.2/bin/windows/amd64/kubectl.exe">kubectl.exe</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226#.pg14q9wst">Tutorial : Getting Started with Kubernetes on your Windows Laptop with Minikube</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/">Hello Minikube On OS X</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/minikube/">Running Kubernetes Locally via Minikube</a></li>
</ul>


<p>下载minikube和kubectl放到PATH路径下（bin目录已经在PATH中）：</p>

<pre><code>E:\local\bin&gt;dir
...
2017-02-08  14:05        50,735,616 kubectl.exe
2017-02-08  11:22        84,239,872 minikube-windows-amd64.exe
2017-02-08  11:25    &lt;SYMLINK&gt;      minikube.exe [minikube-windows-amd64.exe] （mklink minikube.exe minikube-windows-amd64.exe）
</code></pre>

<p>运行 <strong>Docker Quickstart Terminal</strong> (这个快捷方式会先启动docker的虚拟机)，或者直接打开 C:\Program Files\Git\bin\bash.exe 执行如下命令：</p>

<pre><code>查看帮助
winse@Lenovo-PC MINGW64 ~
$ minikube start --help
Starts a local kubernetes cluster using Virtualbox. This command
assumes you already have Virtualbox installed.
...

设置代理: 老外的教程都很简单就成功，但是我们操作一堆问题，主要就是万恶的防火墙！！！
winse@Lenovo-PC MINGW64 ~
$ export HTTPS_PROXY=http://localhost:8118
$ export HTTP_PROXY=http://localhost:8118
$ export NO_PROXY="192.168.0.0/16"

启动
winse@Lenovo-PC MINGW64 ~
$ minikube start --v=7 --logtostderr

winse@Lenovo-PC MINGW64 ~
$ minikube status
minikubeVM: Running
localkube: Running

winse@Lenovo-PC MINGW64 ~
$ kubectl get nodes
NAME       STATUS    AGE
minikube   Ready     3h
</code></pre>

<h4>再次启动，添加代理参数后dashboard才正常运行</h4>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/">https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226">https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226</a></li>
</ul>


<pre><code>winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ minikube start --docker-env HTTP_PROXY=http://192.168.99.1:8118 --docker-env HTTPS_PROXY=http://192.168.99.1:8118
Starting local Kubernetes cluster...
Kubectl is now configured to use the cluster.

winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ minikube status
minikubeVM: Running
localkube: Running

winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ kubectl cluster-info
Kubernetes master is running at https://192.168.99.100:8443
KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns
kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

#open dashboard
https://github.com/kubernetes/minikube/issues/379
https://github.com/kubernetes/minikube/issues/522
winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ minikube dashboard
Opening kubernetes dashboard in default browser...

运行实例
winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl get nodes
NAME       STATUS    AGE
minikube   Ready     8h

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl run hello-nginx --image=nginx --port=80
deployment "hello-nginx" created

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get pods
NAME                           READY     STATUS              RESTARTS   AGE
hello-nginx-2471083592-cgn29   0/1       ContainerCreating   0          19s

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get pods
NAME                           READY     STATUS             RESTARTS   AGE
hello-nginx-2471083592-cgn29   0/1       ImagePullBackOff   0          3m

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe describe pod hello-nginx-2471083592-cgn29

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe expose deployment hello-nginx --type=NodePort
service "hello-nginx" exposed

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get services
NAME          CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE
hello-nginx   10.0.0.145   &lt;nodes&gt;       80:31570/TCP   1m
kubernetes    10.0.0.1     &lt;none&gt;        443/TCP        9h

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe describe service hello-nginx
Name:                   hello-nginx
Namespace:              default
Labels:                 run=hello-nginx
Selector:               run=hello-nginx
Type:                   NodePort
IP:                     10.0.0.145
Port:                   &lt;unset&gt; 80/TCP
NodePort:               &lt;unset&gt; 31570/TCP
Endpoints:              172.17.0.4:80
Session Affinity:       None
No events.

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ minikube service --url=true hello-nginx
http://192.168.99.100:31570

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe logs hello-nginx-2471083592-cgn29
172.17.0.1 - - [10/Feb/2017:02:07:53 +0000] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36" "-"
172.17.0.1 - - [10/Feb/2017:02:07:54 +0000] "GET /favicon.ico HTTP/1.1" 404 571 "http://192.168.99.100:31570/" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36" "-"
2017/02/10 02:07:54 [error] 6#6: *1 open() "/usr/share/nginx/html/favicon.ico" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: "GET /favicon.ico HTTP/1.1", host: "192.168.99.100:31570", referrer: "http://192.168.99.100:31570/"

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe scale --replicas=3 deployment/hello-nginx
deployment "hello-nginx" scaled

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get deployment
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
hello-nginx   3         3         3            1           21m
</code></pre>

<p>暂时还不清楚负载均衡是怎么弄的。这个三个应用pods其实是在一个内网（172.17.0.4/5/6），对外有一个服务（10.0.0.145）。</p>

<p>基本的安装过程先记录这么多。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
