<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Recommend | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/recommend/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2018-01-30T22:43:51+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Gitalk on Octopress]]></title>
    <link href="http://winseliu.com/blog/2018/01/20/gitalk-on-octopress/"/>
    <updated>2018-01-20T15:41:00+08:00</updated>
    <id>http://winseliu.com/blog/2018/01/20/gitalk-on-octopress</id>
    <content type="html"><![CDATA[<p>以前有添加过 多说 ，步骤都类似的。其实就是调用一个第三方的服务，把评论的数据存储在第三方。</p>

<p>可以先看看 <a href="https://github.com/gitalk/gitalk/blob/master/readme-cn.md">gitalk 的文档</a> ，分四步：</p>

<ul>
<li>注册一个github 的 <a href="https://github.com/settings/developers">OAuth Apps</a></li>
<li>添加div容器</li>
<li>加入css，js依赖</li>
<li>调用javascript显示</li>
</ul>


<h2>配置</h2>

<h4>注册一个github应用</h4>

<ul>
<li><a href="https://github.com/gitalk/gitalk/blob/master/readme-cn.md#%E4%BD%BF%E7%94%A8">使用</a></li>
<li><a href="https://github.com/settings/applications/new">https://github.com/settings/applications/new</a></li>
</ul>


<h4>在 <code>_layouts/post.html</code> 的 Comments 下添加一个 gitalk-container 的节点：</h4>

<p>（粘贴后把大括号和百分号之间的空格去掉）</p>

<p>```
{ % if site.disqus_short_name and page.comments == true % }
  <section>
    <h1>Comments</h1></p>

<!-- gitalk评论 start -->


<pre><code>&lt;div id="gitalk-container"&gt;&lt;/div&gt; 
</code></pre>

<!-- gitalk评论 end -->


<p>  </section>
{ % endif % }
```</p>

<h4>在 <code>_includes</code> 目录下增加一个 gitalk.html 的页面，添加依赖并添加初始化代码：</h4>

<p>这里clientID，clientSecret对应第一步注册应用的id和secret。</p>

<p>在官网文档给的例子上调整了一下: id， body, createIssueManually。代码里面是通过 <code>labels + id</code> 来查询对应的issue：<a href="https://github.com/gitalk/gitalk/blob/9a2c6e94281a628a8e0f1ccbdceebd5d17bc1756/src/gitalk.jsx#L174">查询Issue源码</a></p>

<p>（粘贴后把大括号和百分号之间的空格去掉）</p>

<p>```
{ % if site.disqus_short_name and page.comments != false % }</p>

<p><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"></p>

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>




<script>

var gitalk = new Gitalk({
  clientID: 'c14f68eac6330d15d984',
  clientSecret: '73b7c1fffa98e299ff0cdd332821201933858e6e',
  repo: 'winse.github.com',
  owner: 'winse',
  admin: ['winse'],
  id: location.pathname,
  labels: ['Gitalk'],
  body: "http://winseliu.com" + location.pathname,
  createIssueManually: true,
  
  // facebook-like distraction free mode
  distractionFreeMode: false
})

gitalk.render('gitalk-container')

</script>


<p>{ % endif % }
```</p>

<p>然后在同一级目录的 after_footer.html 新增一条 这个新页面一个引用（粘贴后把大括号和百分号之间的空格去掉）:</p>

<pre><code>{ % include gitalk.html % }
</code></pre>

<h2>初始化</h2>

<ul>
<li><a href="https://github.com/gitalk/gitalk/wiki/%E8%AF%84%E8%AE%BA%E5%88%9D%E5%A7%8B%E5%8C%96">https://github.com/gitalk/gitalk/wiki/%E8%AF%84%E8%AE%BA%E5%88%9D%E5%A7%8B%E5%8C%96</a></li>
<li><a href="https://draveness.me/git-comments-initialize">https://draveness.me/git-comments-initialize</a></li>
<li><a href="https://github.com/settings/tokens">https://github.com/settings/tokens</a></li>
</ul>


<p>其实就是在对应的repo下面建一个repo，注意下 <strong>labels</strong> 规则就行了：</p>

<pre><code>username = "winse" # GitHub 用户名

# https://github.com/settings/tokens
new_token = ""  # GitHub Token
repo_name = "winse.github.com" # 存放 issues

sitemap_url = "sitemap.xml" # sitemap
kind = "Gitalk"

# 可以结合git的状态，added的调用命令创建一个issue

# 除了使用Token，也可以手动输入密码
curl -H "Accept: application/json" -X POST -d '{"body": "http://winseliu.com/blog/2017/11/20/sed-debug-sedsed/", "labels": ["Gitalk", "/blog/2017/11/20/sed-debug-sedsed/"], "title": "gitalk 测试" }' -u $username https://api.github.com/repos/$username/$repo_name/issues
Enter host password for user 'winse':

OR

# https://developer.github.com/v3/auth/#basic-authentication
curl -u username:token https://api.github.com/user
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://qiubaiying.top/2017/12/19/%E4%B8%BA%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0-Gitalk-%E8%AF%84%E8%AE%BA%E6%8F%92%E4%BB%B6/">为博客添加 Gitalk 评论插件</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Sphinx生成/管理文档]]></title>
    <link href="http://winseliu.com/blog/2017/11/16/sphinx-generate-docs/"/>
    <updated>2017-11-16T23:23:23+08:00</updated>
    <id>http://winseliu.com/blog/2017/11/16/sphinx-generate-docs</id>
    <content type="html"><![CDATA[<p>很多开源的软件都使用Sphinx来进行文档的管理，其中Ansible就是其中一个。</p>

<p>Sphinx使用 类MarkDown的reStructuredText格式 来进行内容的编写，然后使用 sphinx-build 命令来生成html文件。</p>

<h2>安装、入门</h2>

<ul>
<li><a href="http://www.sphinx-doc.org/en/stable/tutorial.html">http://www.sphinx-doc.org/en/stable/tutorial.html</a></li>
<li><a href="http://www.sphinx-doc.org/en/stable/rest.html">reStructuredText</a></li>
<li><a href="http://zh-sphinx-doc.readthedocs.io/en/latest/rest.html">reStructuredText 简介</a></li>
<li><a href="http://www.sphinx-doc.org/en/stable/markup/index.html">Sphinx Markup Constructs</a></li>
<li><a href="http://rest-sphinx-memo.readthedocs.io/en/latest/ReST.html">ReST – reStructuredText</a> GOOD!</li>
<li><a href="http://www.bijishequ.com/detail/261642">reStructuredText(rst)快速入门语法说明</a></li>
<li><a href="http://sphinx-doc.readthedocs.io/zh_CN/latest/rest.html#id9">章节</a></li>
</ul>


<pre><code>sudo apt-get install python-pip
sudo pip install Sphinx

sphinx-quickstart
</code></pre>

<p>引用：</p>

<pre><code>
*重点(emphasis)通常显示为斜体*
`解释文字(interpreted text)通常显示为斜体`

**重点强调(strong emphasis)通常显示为粗体**

``行内文本(inline literal)通常显示为等宽文本，空格可以保留，但是换行不可以。``

章节头部由下线(也可有上线)和包含标点的标题 组合创建, 其中下线要至少等于标准文本的长度。
可以表示标题的符号有 =、-、`、:、'、"、~、^、_ 、* 、+、 #、&lt;、&gt; 。
对于相同的符号，有上标是一级标题，没有上标是二级标题。
标题最多分六级，可以自由组合使用。

# with overline, for parts
* with overline, for chapters
=, for sections
-, for subsections
^, for subsubsections
", for paragraphs
</code></pre>

<h2>主题</h2>

<ul>
<li><a href="http://www.sphinx-doc.org/en/stable/theming.html">http://www.sphinx-doc.org/en/stable/theming.html</a></li>
<li><a href="https://pypi.python.org/pypi/sphinx_rtd_theme">https://pypi.python.org/pypi/sphinx_rtd_theme</a></li>
</ul>


<pre><code>sudo pip install sphinx_rtd_theme

sed -i "/html_theme/s/.*/html_theme = 'sphinx_rtd_theme'/" conf.py
</code></pre>

<h2>管理历史文档</h2>

<ul>
<li><a href="http://zh-sphinx-doc.readthedocs.io/en/latest/intro.html#id2">不同文档系统的转换</a></li>
<li><a href="https://pypi.python.org/pypi/html2rest">https://pypi.python.org/pypi/html2rest</a></li>
</ul>


<p>先使用 html2rest 把html转成reStructuredText格式。</p>

<pre><code>sudo pip install html2rest

#JSON：原始文档层次结构
  [
  { "id": "a16", "pId": "a", "name": "Administration", "file": "output/AdministrativeDocumentation.html" }, 
  { "id": "a1617", "pId": "a16", "name": "Basic Configuration Guide" },
  { "id": "a161718", "pId": "a1617", "name": "Configuring Deployments", "file": "output/ConfiguringDeployments.html" }
  ]


name=administration
cat $name.json | jq '.[].file' | sed 's/"//g' | while read line ; do cp "$line" $name.origin/  ; done
cd $name.origin
ls | while read f ; do html2rest $f &gt;"../$name.rst/${f%%.*}.rst" ; done
</code></pre>

<p>这仅仅是把html转换成了reStructuredText格式，当然我们还可以做多一些的操作：把文件结构也创建出来。</p>

<p>docs-gen.sh脚本内容如下：</p>

<pre><code>#!/bin/bash

JSON_FILE=~/administration.json

function children(){
local id=$1

local name="$( cat "$JSON_FILE" | jq '.[] | select(.id=="'$id'")' | jq '.name' | sed 's/"//g' )"
echo "id: $id, name: $name"

local filename="$( echo $name | sed 's/[^[:alnum:]]//g' )"

if [ ! -f "$filename.rst" ] ; then
cat &gt; "$filename.rst" &lt;&lt;EOF
$name
======================================

EOF
fi

local nodes="$( cat "$JSON_FILE" | jq '.[] | select(.pId=="'$id'")' )"

if [ "x$nodes" == "x" ] ; then 
  return 1
fi

# if have children, create folder and toc
local foldername="$( echo $name | sed 's/[^[:alnum:]]//g' )"
local names="$( echo "$nodes" | jq ".name" | sed 's/[^[:alnum:]]//g' )"
local ids="$( echo "$nodes" | jq ".id" | sed 's/[^[:alnum:]]//g' )"

if ! grep '.. toctree::' "$foldername.rst" ; then
cat &gt;&gt;"$foldername.rst" &lt;&lt;EOF

Contents:

.. toctree::
   :maxdepth: 3
   :titlesonly:
   :hidden:
   :glob:

$( echo "$names" | sed "s#^#   $foldername/#" ) 

EOF
fi

mkdir -p "$foldername"
pushd "$foldername"

while read cid
do 
  children $cid
done &lt; &lt;(echo "$ids")

popd

}


children a
</code></pre>

<p>然后执行该命令，把目录、目录索引、临时文件创建好：</p>

<pre><code>cd ~/administration
./docs-gen.sh
</code></pre>

<p>然后就是把最开始转换的rst文件拷贝过来：</p>

<pre><code>cd ../administration.rst

ls | while read f ; do 
filename="$(echo $f | sed 's/.rst$//' | sed 's/[^[:alnum:]]//g' ).rst" ; 
find ../administration/ -name "$filename" -exec /bin/cp -f $f {} \;  ;  
done

#再执行一遍docs-gen.sh，把目录的索引再（确认）添加一次文件末尾
cd ../administration
./docs-gen.sh
</code></pre>

<p>完后生成 <code>make html</code> ，直接打开 <strong>_build/html/index.html</strong> 查看下内容。</p>

<p>最后就是根据具体情况，做一些细微的调整了。</p>

<ul>
<li>处理图片，修改 /usr/local/lib/python2.7/dist-packages/html2rest.py</li>
<li>处理文档内互相引用的链接</li>
<li>给标题添加TAG</li>
</ul>


<h2>生成PDF</h2>

<p>除了生成html外，还可以直接编译成PDF，方便携带和查看。（官网是推荐使用latexpdf，但这得安装latex&hellip;）</p>

<ul>
<li><a href="https://www.quora.com/How-to-create-a-PDF-out-of-Sphinx-documentation-tool">https://www.quora.com/How-to-create-a-PDF-out-of-Sphinx-documentation-tool</a></li>
<li>Config value &lsquo;math_number_all&rsquo; already present <a href="https://github.com/sphinx-doc/sphinx/issues/2499">https://github.com/sphinx-doc/sphinx/issues/2499</a></li>
</ul>


<pre><code>[root@ansible workspace]# pip install rst2pdf

[root@ansible workspace]# vi conf.py 
...
#extensions = ['sphinx.ext.doctest', 'sphinx.ext.todo', 'sphinx.ext.pngmath']
extensions = ['sphinx.ext.doctest', 'sphinx.ext.todo', 'rst2pdf.pdfbuilder']

pdf_documents = [('index', u'Workspace', u'Workspace Doc', u'winse'),]

[root@ansible workspace]# sphinx-build -b pdf . _build/pdf
</code></pre>

<p>或者用 singlehtml 临时代替下也行。</p>

<pre><code>make singlehtml
</code></pre>

<p></p>

<h2>MISC</h2>

<ul>
<li><a href="http://www.sphinx-doc.org/en/latest/markup/inline.html">Inline markup</a></li>
<li><a href="http://zh-sphinx-doc.readthedocs.io/en/latest/markup/inline.html">文档引用</a></li>
<li><a href="http://rest-sphinx-memo.readthedocs.io/en/latest/Sphinx.html#sphinx-inline-markup">Sphinx inline markup</a></li>
<li><a href="http://rest-sphinx-memo.readthedocs.io/en/latest/ReST.html#tables">表格</a> GOOD!</li>
<li><a href="http://openalea.gforge.inria.fr/doc/openalea/doc/_build/html/source/sphinx/rest_syntax.html#tables">table</a></li>
<li><a href="http://www.tablesgenerator.com/text_tables#">tablesgenerator</a> <a href="https://stackoverflow.com/questions/26609816/some-online-tool-or-automation-plugin-for-sublimetext-for-generating-sphinx-rst">&lt;-</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[保护/加密JAVA代码]]></title>
    <link href="http://winseliu.com/blog/2017/08/10/java-bytecode-security/"/>
    <updated>2017-08-10T02:10:39+08:00</updated>
    <id>http://winseliu.com/blog/2017/08/10/java-bytecode-security</id>
    <content type="html"><![CDATA[<p>由于Java代码生成的是中间过程字节码，javap以及一些反编译的工具基本能看代码的大概，对于提供给客户的代码需要做一些处理：混淆或者加密。下面分几块把在实际操作过程中参考的内容罗列出来，希望对看到本文并感兴趣的你有所帮助。</p>

<h2>自定义ClassLoader</h2>

<p>混淆+ClassLoader</p>

<ul>
<li><a href="http://www.voidcn.com/blog/zmx729618/article/p-4375840.html">java源代码加密+使用proguard混淆java web项目代码+自定义Classloader</a> 思路不错</li>
</ul>


<p>自定义ClassLoader并用Java实现解密</p>

<ul>
<li><a href="http://www.aspphp.online/bianchen/java/gyjava/201701/112687.html">利用DES加密的算法保護Java源代碼</a> 为啥要加密，以及一般的保护措施（混淆、加密盘、自定义classloader）。实现有点low，用Java写的加密人家调试下就全部请求怎么弄的了。</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-secureclass/index.html">运用加密技术保护Java源代码</a> Java实现加解密通过自定义classloader。2001年的文章啊，牛逼</li>
<li><a href="http://blog.csdn.net/dianacody/article/details/38585209">Java代码加密与反编译（二）：用加密算法DES修改classLoader实现对.class文件加密</a> 有点实践了上一篇ibm文章的意思。</li>
</ul>


<p>自定义ClassLoader（jvmti）用C++实现解密</p>

<ul>
<li><a href="https://wenku.baidu.com/view/587af93767ec102de2bd892c.html">ClassLoader加密技术改进研究pdf</a> 理论派。classloader的实现用C++写（loadClass用JNI实现），但是还是需要对原有代码进行一定的修改</li>
<li><a href="https://www.ibm.com/developerworks/cn/java/l-protectjava/index.html">如何有效的保护 JAVA 程序</a> 这种ClassLoader加密实现有点复杂了，还改java.c的loadClass？2002年的文章啊：解决了 ClassLoader 本身的安全性，其不失为一个比较好安全方案。</li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/]%20%E9%9D%9E%E5%B8%B8%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E4%B8%80%E7%AF%87%E3%80%82%E8%AE%B2%E4%BA%86%E8%87%AA%E5%AE%9A%E4%B9%89classloader%E5%92%8Cjvmti%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%8F%90%E4%BE%9B%E4%BA%86%E6%BA%90%E7%A0%81%E5%B7%A5%E7%A8%8B[JarEncrypt](https://github.com/AloneMonkey/JarEncrypt">jar包加密保护解决方案</a>，参考。</li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a> 用jvmti来实现加解密，牛逼的一篇文章啊！一步步按他的操作可以实现，还附有源码，参考。</li>
<li><a href="http://www.oracle.com/technetwork/articles/java/jvmti-136367.html">http://www.oracle.com/technetwork/articles/java/jvmti-136367.html</a></li>
</ul>


<p>其他一些</p>

<ul>
<li><a href="http://cjnetwork.iteye.com/blog/851544#bc1819690">java源程序加密解决方案(基于Classloader解密)</a> 本身是一篇很棒的文章，多重加密保障ClassLoader安全。又有大神的回复：java的class加密都可以通过dumpclass来还原出来，囧</li>
<li><a href="http://rednaxelafx.iteye.com/blog/727938">如何dump出一个Java进程里的类对应的Class文件？</a> 大神的sun.jvm.hotspot.tools.jcore.ClassDump文章，只要知道类名就无敌了啊</li>
</ul>


<p></p>

<h2>JNI</h2>

<p>javah</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">Calling native functions from Java with JNI and Maven</a> maven搭建native的环境，整体的结构很值得学习</li>
<li><a href="http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html">http://www.mojohaus.org/maven-native/native-maven-plugin/javah-mojo.html</a> maven native插件</li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a> 从生成.h到最后打包一条龙，值得学习。</li>
</ul>


<p>环境部署及入门</p>

<ul>
<li><a href="http://blog.csdn.net/ididcan/article/details/6828982">JNI简单实现Java调用C++/C的HelloWorld</a> 搭开发环境的时刻，可以按照步骤一步步来</li>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a> 直接VS建空项目，不错。思路清晰。中文入门不二之选！</li>
<li><a href="http://www.javamex.com/tutorials/jni/getting_started.shtml">Getting started with JNI</a> 需要小翻个墙啊，有介绍Additional Include Directories的方式配置java的头文件。</li>
<li><a href="https://www.ibm.com/developerworks/java/tutorials/j-jni/j-jni.html">Java programming with JNI</a> 了解JNI没有比这篇更好的文章了，即介绍了java调c++，又介绍了c++调用java。</li>
<li><a href="http://tinggo.iteye.com/blog/1185551">VS项目配置详解</a> VS预定义头：DEBUG，RELEASE的一些头可以定义在配置里面。有点像makefile里面决定打什么版本。</li>
</ul>


<p>配jni.h的 附加目录 的时刻，需要选择 配置 和 平台 的配置！！需要对应好！ jni的.h文件需要放到c++的项目下面去，引用外部的好像找不到，有问题。</p>

<p>java与c++类型之间的转换</p>

<ul>
<li><a href="https://stackoverflow.com/questions/8439233/how-to-convert-jbytearray-to-native-char-in-jni">How to convert jbyteArray to native char* in jni?</a></li>
<li><a href="https://stackoverflow.com/questions/12854333/jni-in-c-to-read-file-to-jbytearray">JNI in C++ to read file to jbyteArray</a></li>
</ul>


<p>JNI调用C++的加密算法</p>

<ul>
<li><a href="http://blog.csdn.net/wtbee/article/details/11658017">Java实现DES对称加密算法（附Android下3DES的JNI源码）</a> 有简单介绍DES的只是。中间换成过他的DES的实现，但是感觉怪怪的，有点不太靠谱。后面换成OPENSSL了。</li>
<li><a href="http://www.cnblogs.com/kolin/p/4256614.html">JNI调用c++实现AES加密解密</a> android的，用的应该也是OPENSSL。可以参考过程</li>
</ul>


<h2>OPENSSL</h2>

<ul>
<li><a href="http://www.qmailer.net/archives/183.html">OpenSSL编程-对称加密及DES/3DES简介</a> 简单的介绍</li>
<li><a href="http://blog.csdn.net/duanxingheng/article/details/11655037">OPENSSL库的使用-DES篇</a> 看看算法还可以。算法介绍，有对OPENSSL DES库的介绍和使用</li>
<li><a href="https://www.madboa.com/geek/openssl/">OpenSSL Command-Line</a></li>
<li><a href="http://www.cnblogs.com/gordon0918/p/5317701.html">openssl 对称加密算法enc命令详解</a> 命令行的使用</li>
<li><a href="https://www.slideshare.net/guanzhi/crypto-with-openssl">https://www.slideshare.net/guanzhi/crypto-with-openssl</a></li>
<li><a href="http://www.linuxjournal.com/article/4822">An Introduction to OpenSSL Programming</a> 2001年的太老了，留个纪念。</li>
</ul>


<p>WINDOWS安装/编译安装OPENSSL然后在VS里面应用：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio">https://stackoverflow.com/questions/11383942/how-to-use-openssl-with-visual-studio</a></li>
<li><a href="https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012">https://stackoverflow.com/questions/17127824/using-openssl-in-visual-studio-2012</a></li>
<li><a href="https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64">https://stackoverflow.com/questions/32156336/how-to-include-openssl-in-visual-studio-expres-2012-windows-7-x64</a></li>
<li><a href="http://slproweb.com/products/Win32OpenSSL.html">http://slproweb.com/products/Win32OpenSSL.html</a></li>
</ul>


<p>NuGet安装OpenSSL on VS2015-1.0.2版本：（我用的这种方式）</p>

<ul>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a> VS2015 安装openssl v1.0.2 才有v140的include。 v1.0.2.1安装不了，参考。</li>
</ul>


<p>GCC</p>

<ul>
<li><a href="https://stackoverflow.com/questions/1894013/how-to-use-openssl-in-gcc">How to use OpenSSL in GCC?</a> 加依赖: -L/usr/lib -lssl -lcrypto -o server</li>
</ul>


<p>DES</p>

<ul>
<li><a href="https://my.oschina.net/mawx/blog/85424">https://my.oschina.net/mawx/blog/85424</a> Java DESede用C++ Openssl实现 参考下他的链接</li>
<li><a href="http://www.open-open.com/solution/view/1320502797546">http://www.open-open.com/solution/view/1320502797546</a> Java与C++通过DES、blowfish互相加解密</li>
<li><a href="http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs">http://blog.fpmurphy.com/2010/04/openssl-des-api.html#sthash.MA71jwqK.dpbs</a> OpenSSL DES APIs</li>
</ul>


<p>AES</p>

<ul>
<li><a href="https://www.lovelucy.info/openssl-aes-encryption.html">AES加密和解密——使用openssl编程</a> 参考他的makefile。AES用的是OPENSSL，写的中规中矩</li>
<li><a href="http://www.cnblogs.com/luop/p/4334160.html">密码算法详解——AES</a></li>
<li><a href="http://www.ssdfans.com/?p=238">AES加密算法图解</a> flash动画很赞</li>
<li><a href="http://yuanshuilee.blog.163.com/blog/static/21769727520140942826137/">openssl之aes加密（AES_cbc_encrypt 与 AES_encrypt 的编程案例）</a> 很棒的一篇，参考。</li>
<li><a href="https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/">https://blog.poxiao.me/p/advanced-encryption-standard-and-block-cipher-mode/</a> 高级加密标准AES的工作模式（ECB、CBC、CFB、OFB），还有接口的介绍，非常好的一篇文章</li>
</ul>


<p>AES CBC 相互加解密 Java/PHP/C++ java和c++加解密，互通</p>

<ul>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a> 非常牛逼的一篇，参考。</li>
<li><a href="http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html">http://blog.sina.com.cn/s/blog_48d4cf2d0101eqdf.html</a> Java和C/C++进行DES/AES密文传输</li>
<li><a href="https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl">https://stackoverflow.com/questions/39128103/how-do-i-decrypt-a-java-des-encrypted-message-using-openssl</a></li>
<li><a href="https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent">https://stackoverflow.com/questions/9038298/java-desede-encrypt-openssl-equivalent</a></li>
<li><a href="http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html">http://www.cnblogs.com/WonKerr/archive/2009/11/11/DES_C_JAVA.html</a> DES 算法的 C++ 与 JAVA 互相加解密</li>
<li><a href="http://juliusdavies.ca/commons-ssl/pbe.html">OpenSSL&rsquo;s &ldquo;enc&rdquo; in Java (PBE / Password Based Encryption)</a></li>
<li><a href="http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html">http://openssl.6102.n7.nabble.com/Compatibility-between-Java-crypto-and-open-ssl-td13992.html</a></li>
<li><a href="https://ruby-china.org/topics/26490">https://ruby-china.org/topics/26490</a></li>
</ul>


<p></p>

<ul>
<li><a href="https://shanetully.com/2012/06/openssl-rsa-aes-and-c/">OpenSSL, RSA, AES and C++</a> 好鬼长复杂没怎么看，搜AES找到了。</li>
</ul>


<h4>OPENSSL MD5： VS + GCC + JAVA + 命令行</h4>

<ul>
<li><a href="http://www.askyb.com/cpp/openssl-md5-hashing-example-in-cpp/">OpenSSL MD5 Hashing Example in C++</a></li>
<li><a href="https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash">https://stackoverflow.com/questions/4583967/how-to-encode-md5-sum-into-base64-in-bash</a> LINUX命令行</li>
<li><a href="https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal">https://askubuntu.com/questions/53846/how-to-get-the-md5-hash-of-a-string-directly-in-the-terminal</a> md5sum</li>
<li><a href="https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files">https://superuser.com/questions/72765/can-you-use-openssl-to-generate-an-md5-or-sha-hash-on-a-directory-of-files</a> 循环算一个目录下文件的MD5</li>
<li><a href="https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC">https://www.codeproject.com/Articles/1016357/OpenSSL-Tour-for-Win-Developer#DESCBC</a> OPENSSL各种算法的使用</li>
</ul>


<pre><code># SHA256, used in chef cookbooks
openssl dgst -sha256 path/to/myfile
# MD5
openssl dgst -md5 path/to/myfile
echo -n 'text to be encrypted' | md5sum -
$ echo -n 123456 | md5sum | awk '{print $1}'
$ echo -n Welcome | md5sum

[root@cu2 ~]# gcc -Wall -lcrypto -lssl opensslmd5.cpp -o md5
[root@cu2 ~]# ./md5
md5 digest: 56ab24c15b72a457069c5ea42fcfc640
</code></pre>

<p>makefile</p>

<pre><code>CC=g++
CFLAGS=-Wall -g -O2
LIBS=-lcrypto

all: aes

aes: aes.cc
    $(CC) $(CFLAGS) aes.cc -o $@ $(LIBS)

clean:
    @rm -f aes
</code></pre>

<h4>OPENSSL命令行</h4>

<pre><code>openssl des3 -nosalt -k abc123 -in file.txt -out file.des3 #不加盐，key为abc123来加密
openssl des3 -d -nosalt -in file.des3 -out f.txt -k abc123#解密

默认是-salt，加盐的，如果不加盐，则根据pass生成的key和iv不变，例：

You can get openssl to base64-encode the message by using the -a
stefano:~$ openssl aes-256-cbc -in attack-plan.txt -a

[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -a -salt -k abcdefghijklmnop
[root@cu2 ~]# echo -n DES | openssl aes-128-cbc -k abcdefghijklmnop |  openssl aes-128-cbc -d -k abcdefghijklmnop
</code></pre>

<h2>其他</h2>

<p>SHELL二进制编码：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script">https://stackoverflow.com/questions/6292645/convert-binary-data-to-hex-in-shell-script</a> hexdump</li>
</ul>


<pre><code>el@defiant ~ $ printf '%x\n' 26
el@defiant ~ $ echo $((0xAA))
printf -v result1 "%x" "$decimal1"
% xxd -l 16 -p /dev/random
193f6c54814f0576bc27d51ab39081dc
$ echo -n $'\x12\x34' | xxd -p

$ echo -n $'\x12\x34' | hexdump -e '"%x"'

od -vt x1|awk '{$1="";print}'
echo "obase=16; 34" | bc
</code></pre>

<p>c++命令行不直接关闭。。。最后用断点的方式替代了，没找到好的方法！！</p>

<p>文件读写</p>

<ul>
<li><a href="http://blog.csdn.net/lightlater/article/details/6364931">C++读写二进制文件</a></li>
<li><a href="http://blog.csdn.net/guyue6670/article/details/6681037">fopen中w w+ wb区别</a> 人家代码写的是w+，加密class后多了0D。后面问了搞C的同事才知道二进制要用wb，C就是一堆坑啊！</li>
</ul>


<p>g++</p>

<ul>
<li><a href="https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope">https://stackoverflow.com/questions/4828228/sprintf-s-was-not-declared-in-this-scope</a> snprintf</li>
</ul>


<p>git</p>

<ul>
<li><a href="https://git-scm.com/docs/git-archive">https://git-scm.com/docs/git-archive</a> GIT打包</li>
</ul>


<h2>重要的参考文章再列一遍</h2>

<ul>
<li><a href="http://blog.csdn.net/wwj_748/article/details/28136061">JNI_最简单的Java调用C/C++代码</a></li>
<li><a href="http://www.alonemonkey.com/2016/05/25/encrypt-jar-class/">jar包加密保护解决方案</a> 源码<a href="https://github.com/AloneMonkey/JarEncrypt">JarEncrypt</a></li>
<li><a href="http://www.codeceo.com/article/jvmti-jni-java.html">通过JVMTI和JNI对JAVA加密</a></li>
<li><a href="https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015">https://stackoverflow.com/questions/40431034/openssl-nuget-package-not-installing-in-vs-2015</a></li>
<li><a href="https://actom.me/blog/aes-cbc-%E7%9B%B8%E4%BA%92%E5%8A%A0%E8%A7%A3%E5%AF%86-javaphpc.html">AES CBC 相互加解密 Java/PHP/C++</a></li>
</ul>


<p>TODO 编译打包</p>

<ul>
<li><a href="http://www.tricoder.net/blog/?p=197">http://www.tricoder.net/blog/?p=197</a></li>
<li><a href="https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name">https://stackoverflow.com/questions/25138413/java-jni-maven-native-maven-plugin-how-to-set-shared-library-final-name</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kubeadm部署kubernetes]]></title>
    <link href="http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/"/>
    <updated>2017-07-30T20:18:33+08:00</updated>
    <id>http://winseliu.com/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7</id>
    <content type="html"><![CDATA[<p>官网文档差，删文档倒是不手软。使用脚本启动、安装的文档（docker-multinode）已经删掉了，现在都推荐使用kubeadm来进行安装。</p>

<p>本文使用代理在master上安装并缓冲rpm、以及下载docker镜像，然后做本地YUM仓库和拷贝镜像到其他worker节点的方式来部署集群。下一篇再介绍在拥有kubelet/kubeadm rpm、以及k8s docker镜像的情况下怎么去部署一个新的k8s集群。</p>

<p>这里使用两台虚拟机做测试：</p>

<ul>
<li>k8s kube-master : 192.168.191.138</li>
<li>woker1 : 192.168.191.139</li>
</ul>


<h2>修改主机名，改时间、时区，防火墙</h2>

<pre><code>hostnamectl --static set-hostname k8s 
hostname k8s 

rm -rf /etc/localtime 
ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 

systemctl disable firewalld ; service firewalld stop
</code></pre>

<h2>安装docker</h2>

<ul>
<li><a href="https://docs.docker.com/v1.12/engine/installation/linux/rhel/">https://docs.docker.com/v1.12/engine/installation/linux/rhel/</a></li>
<li><a href="https://yum.dockerproject.org/repo/main/centos/7/Packages/">https://yum.dockerproject.org/repo/main/centos/7/Packages/</a> 打开看下1.12的具体版本</li>
<li><a href="https://docs.docker.com/v1.12/engine/admin/systemd/">https://docs.docker.com/v1.12/engine/admin/systemd/</a>  *</li>
</ul>


<pre><code>
tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'
[dockerrepo]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/7/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
EOF

yum list docker-engine --showduplicates

yum install docker-engine-1.12.6 docker-engine-selinux-1.12.6 -y
systemctl enable docker ; systemctl start docker
</code></pre>

<h2>翻墙安装配置</h2>

<p>具体操作参考 <a href="/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks">使用Privoxy把shadowsocks转换为Http代理</a></p>

<p></p>

<pre><code>[root@k8s ~]# yum install -y epel-release ; yum install -y python-pip 
[root@k8s ~]# pip install shadowsocks
[root@k8s ~]# vi /etc/shadowsocks.json 
[root@k8s ~]# sslocal -c /etc/shadowsocks.json 
[root@k8s ~]# curl --socks5-hostname 127.0.0.1:1080 www.google.com

[root@k8s ~]# yum install privoxy -y
[root@k8s ~]# vi /etc/privoxy/config 
...
forward-socks5 / 127.0.0.1:1080 .
listen-address 192.168.191.138:8118

[root@k8s ~]# systemctl enable privoxy
[root@k8s ~]# systemctl start privoxy

[root@k8s ~]# curl -x 192.168.191.138:8118 www.google.com

等k8s安装启动好后，把privoxy的服务disable掉
[root@k8s ~]# systemctl disable privoxy.service
</code></pre>

<h2>下载kubectl（怪了，这个竟然可以直接下载）</h2>

<p>变化好快，现在都1.7.2了！ <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>

<p>在master机器（常用的操作机器）安装即可。</p>

<pre><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
chmod +x ./kubectl
mv ./kubectl /usr/local/bin/kubectl

# 启用shell的提示/自动完成autocompletion
echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc

[root@k8s ~]# kubectl version 
Client Version: version.Info{Major:"1", Minor:"7", GitVersion:"v1.7.2", GitCommit:"922a86cfcd65915a9b2f69f3f193b8907d741d9c", GitTreeState:"clean", BuildDate:"2017-07-21T08:23:22Z", GoVersion:"go1.8.3", Compiler:"gc", Platform:"linux/amd64"}
The connection to the server localhost:8080 was refused - did you specify the right host or port?
</code></pre>

<p></p>

<h2>通过VPN安装kubelet和kubeadm</h2>

<p>参考 <a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm">https://kubernetes.io/docs/setup/independent/install-kubeadm/#installing-kubelet-and-kubeadm</a></p>

<p>You will install these packages on all of your machines:</p>

<ul>
<li>kubelet: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</li>
<li>kubeadm: the command to bootstrap the cluster.</li>
</ul>


<p>所有机器都要安装的，我们先在master节点上通过代理安装这两个软件，并把安装的所有rpm缓冲起来。</p>

<ul>
<li>配置kubernetes的仓库源：</li>
</ul>


<pre><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 
setenforce 0

yum-config-manager --enable kubernetes
</code></pre>

<ul>
<li>YUM配置socks5代理： <a href="https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum">https://unix.stackexchange.com/questions/43654/how-to-use-socks-proxy-with-yum</a></li>
</ul>


<p></p>

<p>修改yum的配置，增加代理，并缓冲（用于其他机器安装）</p>

<pre><code>[root@k8s ~]# vi /etc/yum.conf 
keepcache=1
...
proxy=socks5://127.0.0.1:1080
</code></pre>

<ul>
<li>安装并启动kubelet：</li>
</ul>


<pre><code>yum install -y kubelet kubeadm

[root@k8s ~]# systemctl enable kubelet &amp;&amp; systemctl start kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /etc/systemd/system/kubelet.service.
[root@k8s ~]# 
</code></pre>

<h2>通过VPN安装初始化集群（主要是配置代理下载docker容器）</h2>

<p>由于是直接docker去获取镜像的，首先需要修改docker的配置。</p>

<p>参考 <a href="https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy">https://docs.docker.com/v1.12/engine/admin/systemd/#/http-proxy</a></p>

<ul>
<li>配置代理并重启docker、kubelet</li>
</ul>


<pre><code>[root@k8s ~]# systemctl enable docker

[root@k8s ~]# mkdir -p /etc/systemd/system/docker.service.d/
[root@k8s ~]# vi /etc/systemd/system/docker.service.d/http-proxy.conf
[Service]
Environment="HTTP_PROXY=http://192.168.191.138:8118/" "HTTPS_PROXY=http://192.168.191.138:8118/" "NO_PROXY=localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"

[root@k8s ~]# systemctl daemon-reload
[root@k8s ~]# systemctl restart docker
</code></pre>

<p>docker和kubelet的cgroup驱动方式不同，需要修复配置：<a href="https://github.com/kubernetes/kubeadm/issues/103">https://github.com/kubernetes/kubeadm/issues/103</a></p>

<pre><code>前面已经启动了kubelet，有如下的错误日志
[root@k8s ~]# journalctl -xeu kubelet
Jul 29 09:11:24 k8s kubelet[48557]: error: failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: "systemd" is different from docker cgroup driver: "cgr

修改配置
[root@k8s ~]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs"

[root@k8s ~]# systemctl daemon-reload
[root@k8s ~]# service kubelet restart
Redirecting to /bin/systemctl restart  kubelet.service
</code></pre>

<ul>
<li>使用kubeadm进行初始化</li>
</ul>


<p><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a> （可以使用 &ndash;kubernetes-version 来指定k8s的版本）</p>

<pre><code># 配置代理，kubeadm有部分请求应该也是需要走代理的（前面用脚本安装过multinode on docker的经历猜测的）

export NO_PROXY="localhost,127.0.0.1,10.0.0.0/8,192.168.191.138"
export https_proxy=http://192.168.191.138:8118/
export http_proxy=http://192.168.191.138:8118/

# 使用reset重置，网络代理的配置修改了多次（kubeadm初始换过程失败过），还有前几次的初始化没有配置pod地址段

[root@k8s ~]# kubeadm reset
[preflight] Running pre-flight checks
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in "/var/lib/kubelet"
[reset] Removing kubernetes-managed containers
[reset] Deleting contents of stateful directories: [/var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/lib/etcd]
[reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]

# 使用flannel需要指定pod的网卡地址段（文档要整体看一遍才能少踩坑，囧）

[root@k8s ~]# kubeadm init --skip-preflight-checks --pod-network-cidr=10.244.0.0/16
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[init] Using Kubernetes version: v1.7.2
[init] Using Authorization modes: [Node RBAC]
[preflight] Skipping pre-flight checks
[kubeadm] WARNING: starting in 1.8, tokens expire after 24 hours by default (if you require a non-expiring token use --token-ttl 0)
[certificates] Generated CA certificate and key.
[certificates] Generated API server certificate and key.
[certificates] API Server serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.191.138]
[certificates] Generated API server kubelet client certificate and key.
[certificates] Generated service account token signing key and public key.
[certificates] Generated front-proxy CA certificate and key.
[certificates] Generated front-proxy client certificate and key.
[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
[apiclient] Created API client, waiting for the control plane to become ready  
&lt;-&gt; 这里会停的比较久，要去下载镜像，然后还得启动容器
[apiclient] All control plane components are healthy after 293.004469 seconds
[token] Using token: 2af779.b803df0b1effb3d9
[apiconfig] Created RBAC rules
[addons] Applied essential addon: kube-proxy
[addons] Applied essential addon: kube-dns

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run (as a regular user):

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  http://kubernetes.io/docs/admin/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443

[root@k8s ~]# 
</code></pre>

<p>监控安装情况命令有： <code>docker ps</code>, <code>docker images</code>, <code>journalctl -xeu kubelet</code> (/var/log/messages) 。</p>

<p>如果有镜像下载和容器新增，说明安装过程在进行中。否则得检查下你的代理是否正常工作了！</p>

<p>初始化完成后，配置kubectl的kubeconfig。一般都是主节点了，直接在节点执行下面命令：</p>

<pre><code>[root@k8s ~]# mkdir -p $HOME/.kube
[root@k8s ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@k8s ~]# chown $(id -u):$(id -g) $HOME/.kube/config
[root@k8s ~]# 
[root@k8s ~]# ll ~/.kube/
total 8
drwxr-xr-x. 3 root root   23 Jul 29 21:39 cache
-rw-------. 1 root root 5451 Jul 29 22:57 config
</code></pre>

<p></p>

<p><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">使用Kubeadm安装Kubernetes</a> 介绍了很多作者自己安装过程，以及遇到的问题，非常详细。安装的差不多才发现这篇文章，感觉好迟，如果早点找到，至少安装的时刻心安一点啊。</p>

<p>OK，服务启动了，但是 dns容器 还没有正常启动。由于我们的网络组建还没有安装好啊。其实官网也有说明，但是这安装的顺序也是醉了。</p>

<p> <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p>

<h2>安装flannel</h2>

<p>参考： <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network</a></p>

<pre><code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel-rbac.yml
</code></pre>

<p>flannel启动了后，再等一阵，dns才会启动好。</p>

<p></p>

<h2>安装dashboard</h2>

<pre><code>现在就一台机器，得让master也能跑pods。 
https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#master-isolation

[root@k8s ~]# kubectl taint nodes --all node-role.kubernetes.io/master-
node "k8s" untainted

# https://lukemarsden.github.io/docs/user-guide/ui/
# 部署dashboard

[root@k8s ~]# kubectl create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml

[root@k8s ~]# kubectl get pods --all-namespaces 看看dashboard的情况

[root@k8s ~]# kubectl get services --all-namespaces
NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
default       kubernetes             10.96.0.1       &lt;none&gt;        443/TCP         1h
kube-system   kube-dns               10.96.0.10      &lt;none&gt;        53/UDP,53/TCP   1h
kube-system   kubernetes-dashboard   10.107.103.17   &lt;none&gt;        80/TCP          9m
</code></pre>

<p>用 <a href="https://master:6443/ui">https://master:6443/ui</a> 访问不了，可以直接用k8s的service地址访问 <a href="http://10.107.103.17/#!/overview?namespace=kube-system">http://10.107.103.17/#!/overview?namespace=kube-system</a></p>

<p></p>

<p>或者通过 <strong> proxy </strong> 访问UI：<a href="https://github.com/kubernetes/kubernetes/issues/44275">https://github.com/kubernetes/kubernetes/issues/44275</a></p>

<p>先运行proxy，启动代理程序：</p>

<pre><code>[root@k8s ~]# kubectl proxy
Starting to serve on 127.0.0.1:8001
</code></pre>

<p>然后访问： <a href="http://localhost:8001/ui">http://localhost:8001/ui</a></p>

<h2>所有的pods、镜像、容器</h2>

<p>基本的东西都跑起来，还是挺激动啊！！第N次安装部署K8S了啊，每次都还是得像坐过山车一样啊！</p>

<p></p>

<pre><code>[root@k8s ~]# kubectl get pods --all-namespaces -o wide
NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE       IP                NODE
kube-system   etcd-k8s                                1/1       Running   0          9h        192.168.191.138   k8s
kube-system   kube-apiserver-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
kube-system   kube-controller-manager-k8s             1/1       Running   0          9h        192.168.191.138   k8s
kube-system   kube-dns-2425271678-qwx9f               3/3       Running   0          9h        10.244.0.2        k8s
kube-system   kube-flannel-ds-s5f63                   2/2       Running   0          9h        192.168.191.138   k8s
kube-system   kube-proxy-4pjkg                        1/1       Running   0          9h        192.168.191.138   k8s
kube-system   kube-scheduler-k8s                      1/1       Running   0          9h        192.168.191.138   k8s
kube-system   kubernetes-dashboard-3313488171-xl25m   1/1       Running   0          8h        10.244.0.3        k8s
[root@k8s ~]# docker images
REPOSITORY                                               TAG                 IMAGE ID            CREATED             SIZE
gcr.io/google_containers/kubernetes-dashboard-amd64      v1.6.3              691a82db1ecd        35 hours ago        139 MB
gcr.io/google_containers/kube-apiserver-amd64            v1.7.2              4935105a20b1        8 days ago          186.1 MB
gcr.io/google_containers/kube-proxy-amd64                v1.7.2              13a7af96c7e8        8 days ago          114.7 MB
gcr.io/google_containers/kube-controller-manager-amd64   v1.7.2              2790e95830f6        8 days ago          138 MB
gcr.io/google_containers/kube-scheduler-amd64            v1.7.2              5db1f9874ae0        8 days ago          77.18 MB
quay.io/coreos/flannel                                   v0.8.0-amd64        9db3bab8c19e        2 weeks ago         50.73 MB
gcr.io/google_containers/k8s-dns-sidecar-amd64           1.14.4              38bac66034a6        4 weeks ago         41.81 MB
gcr.io/google_containers/k8s-dns-kube-dns-amd64          1.14.4              a8e00546bcf3        4 weeks ago         49.38 MB
gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64     1.14.4              f7f45b9cb733        4 weeks ago         41.41 MB
gcr.io/google_containers/etcd-amd64                      3.0.17              243830dae7dd        5 months ago        168.9 MB
gcr.io/google_containers/pause-amd64                     3.0                 99e59f495ffa        15 months ago       746.9 kB
[root@k8s ~]# docker ps 
CONTAINER ID        IMAGE                                                                                                                            COMMAND                  CREATED             STATUS              PORTS               NAMES
631dc2cab02e        gcr.io/google_containers/kubernetes-dashboard-amd64@sha256:2c4421ed80358a0ee97b44357b6cd6dc09be6ccc27dfe9d50c9bfc39a760e5fe      "/dashboard --insecur"   7 hours ago         Up 7 hours                              k8s_kubernetes-dashboard_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
8f5e4d044a6e        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 8 hours ago         Up 8 hours                              k8s_POD_kubernetes-dashboard-3313488171-xl25m_kube-system_0e41b8ce-747a-11e7-befb-000c2944b96c_0
65881f9dd2dd        gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:97074c951046e37d3cbb98b82ae85ed15704a290cce66a8314e7f846404edde9           "/sidecar --v=2 --log"   9 hours ago         Up 9 hours                              k8s_sidecar_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
994c2ec99663        gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64@sha256:aeeb994acbc505eabc7415187cd9edb38cbb5364dc1c2fc748154576464b3dc2     "/dnsmasq-nanny -v=2 "   9 hours ago         Up 9 hours                              k8s_dnsmasq_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
5b181a0ed809        gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344          "/kube-dns --domain=c"   9 hours ago         Up 9 hours                              k8s_kubedns_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
a0d3f166e992        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-dns-2425271678-qwx9f_kube-system_ebffa28d-746d-11e7-befb-000c2944b96c_0
9cc7d6faf0b0        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/bin/sh -c 'set -e -"   9 hours ago         Up 9 hours                              k8s_install-cni_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
2f41276df8e1        quay.io/coreos/flannel@sha256:a8116d095a1a2c4e5a47d5fea20ef82bd556bafe15bb2e6aa2c79f8f22f9586f                                   "/opt/bin/flanneld --"   9 hours ago         Up 9 hours                              k8s_kube-flannel_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
bc25b0c70264        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-flannel-ds-s5f63_kube-system_7ba88f5a-7470-11e7-befb-000c2944b96c_0
dc3e5641c273        gcr.io/google_containers/kube-proxy-amd64@sha256:d455480e81d60e0eff3415675278fe3daec6f56c79cd5b33a9b76548d8ab4365                "/usr/local/bin/kube-"   9 hours ago         Up 9 hours                              k8s_kube-proxy_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
6b8b9515f562        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-proxy-4pjkg_kube-system_ebee4211-746d-11e7-befb-000c2944b96c_0
72418ca8e94f        gcr.io/google_containers/kube-apiserver-amd64@sha256:a9ccc205760319696d2ef0641de4478ee90fb0b75fbe6c09b1d64058c8819f97            "kube-apiserver --ser"   9 hours ago         Up 9 hours                              k8s_kube-apiserver_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
9c9a3f5d8919        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-apiserver-k8s_kube-system_b69ae39bcc54d7b75c2e7325359f8f87_0
43a1751ff2bb        gcr.io/google_containers/etcd-amd64@sha256:d83d3545e06fb035db8512e33bd44afb55dea007a3abd7b17742d3ac6d235940                      "etcd --listen-client"   9 hours ago         Up 9 hours                              k8s_etcd_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
b110fff29f66        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_etcd-k8s_kube-system_9fb4ea9ba2043e46f75eec93827c4ce3_0
66ae85500128        gcr.io/google_containers/kube-scheduler-amd64@sha256:b2e897138449e7a00508dc589b1d4b71e56498a4d949ff30eb07b1e9d665e439            "kube-scheduler --add"   9 hours ago         Up 9 hours                              k8s_kube-scheduler_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
d4343be2f2d0        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-scheduler-k8s_kube-system_16c371efb8946190c917cd90c2ede8ca_0
9934cd83f6b3        gcr.io/google_containers/kube-controller-manager-amd64@sha256:2b268ab9017fadb006ee994f48b7222375fe860dc7bd14bf501b98f0ddc2961b   "kube-controller-mana"   9 hours ago         Up 9 hours                              k8s_kube-controller-manager_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
acc1d7d90180        gcr.io/google_containers/pause-amd64:3.0                                                                                         "/pause"                 9 hours ago         Up 9 hours                              k8s_POD_kube-controller-manager-k8s_kube-system_6b826c4e872a9635472113953c4538f0_0
[root@k8s ~]# 
</code></pre>

<h2>Woker节点部署</h2>

<p>时间，主机名，/etc/hosts，防火墙，selinux, 无密钥登录，安装docker-1.12.6就不再赘述了。</p>

<p>直接用master的yum缓冲，还有docker镜像直接拷贝：</p>

<pre><code># master机器已安装httpd服务

[root@k8s html]# ln -s /var/cache/yum/x86_64/7/kubernetes/packages/ k8s 
[root@k8s k8s]# createrepo .          

# 把镜像全部拷到worker节点

[root@k8s ~]# docker save $( echo $( docker images | grep -v REPOSITORY | awk '{print $1}' ) ) | ssh worker1 docker load 

# 配置私有仓库源

[root@worker1 yum.repos.d]# vi k8s.repo
[k8s]
name=Kubernetes
baseurl=http://master/k8s
enabled=1
gpgcheck=0
[root@worker1 yum.repos.d]# yum list | grep k8s 
kubeadm.x86_64                             1.7.2-0                     k8s      
kubectl.x86_64                             1.7.2-0                     k8s      
kubelet.x86_64                             1.7.2-0                     k8s      
kubernetes-cni.x86_64                      0.5.1-0                     k8s      

[root@worker1 yum.repos.d]# yum install -y kubelet kubeadm                          

# 修改cgroup-driver

[root@worker1 yum.repos.d]# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf  
[root@worker1 yum.repos.d]# 
[root@worker1 yum.repos.d]# service docker restart
Redirecting to /bin/systemctl restart  docker.service

[root@worker1 yum.repos.d]# systemctl daemon-reload
[root@worker1 yum.repos.d]# systemctl enable kubelet.service
[root@worker1 yum.repos.d]# service kubelet restart
Redirecting to /bin/systemctl restart  kubelet.service

# worker节点加入集群（初始化）

[root@worker1 yum.repos.d]# kubeadm join --token 2af779.b803df0b1effb3d9 192.168.191.138:6443 --skip-preflight-checks
[kubeadm] WARNING: kubeadm is in beta, please do not use it for production clusters.
[preflight] Skipping pre-flight checks
[discovery] Trying to connect to API Server "192.168.191.138:6443"
[discovery] Created cluster-info discovery client, requesting info from "https://192.168.191.138:6443"
[discovery] Cluster info signature and contents are valid, will use API Server "https://192.168.191.138:6443"
[discovery] Successfully established connection with API Server "192.168.191.138:6443"
[bootstrap] Detected server version: v1.7.2
[bootstrap] The server supports the Certificates API (certificates.k8s.io/v1beta1)
[csr] Created API client to obtain unique certificate for this node, generating keys and certificate signing request
[csr] Received signed certificate from the API server, generating KubeConfig...
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"

Node join complete:
* Certificate signing request sent to master and response
  received.
* Kubelet informed of new secure connection details.

Run 'kubectl get nodes' on the master to see this machine join.

[root@k8s ~]# kubectl get nodes
NAME      STATUS    AGE       VERSION
k8s       Ready     10h       v1.7.2
worker1   Ready     57s       v1.7.2
</code></pre>

<p>主节点运行的flannel网络组件是个 daemonset 的pod，只要加入到集群就会在每个节点上启动。不需要额外的操作。</p>

<h2>关于重启：</h2>

<p>使用RPM安装的好处是：程序系统都帮你管理了：</p>

<ul>
<li>worker节点重启后，kubelet会把所有的服务都带起来。</li>
<li>master重启后，需要等一段时间，因为pods启动有顺序/依赖：dns需要等flannel，dashboard需要等dns。</li>
</ul>


<h2>POD间连通性测试</h2>

<pre><code>[root@k8s ~]# kubectl run hello-nginx --image=nginx --port=80
deployment "hello-nginx" created
[root@k8s ~]# kubectl get pods
NAME                           READY     STATUS              RESTARTS   AGE
hello-nginx-1507731416-qh3fx   0/1       ContainerCreating   0          8s

# 脚本启动新的dockerd并配置加速器，下载好然后save导入都本地docker实例
# https://github.com/winse/docker-hadoop/blob/master/kube-deploy/hadoop/docker-download-mirror.sh

[root@k8s ~]# ./docker-download-mirror.sh nginx 
Using default tag: latest
latest: Pulling from library/nginx

94ed0c431eb5: Pull complete 
9406c100a1c3: Pull complete 
aa74daafd50c: Pull complete 
Digest: sha256:788fa27763db6d69ad3444e8ba72f947df9e7e163bad7c1f5614f8fd27a311c3
Status: Downloaded newer image for nginx:latest
eb78099fbf7f: Loading layer [==================================================&gt;] 58.42 MB/58.42 MB
29f11c413898: Loading layer [==================================================&gt;] 52.74 MB/52.74 MB
af5bd3938f60: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB
Loaded image: nginx:latest

# 拷贝镜像到其他的worker节点，就几台机器搭建register服务感觉太重了

[root@k8s ~]# docker save nginx | ssh worker1 docker load
Loaded image: nginx:latest

# 查看效果

[root@k8s ~]# kubectl get pods
NAME                           READY     STATUS    RESTARTS   AGE
hello-nginx-1507731416-qh3fx   1/1       Running   0          1m

# 扩容

[root@k8s ~]# kubectl scale --replicas=4 deployment/hello-nginx  
deployment "hello-nginx" scaled
[root@k8s ~]# kubectl get pods -o wide
NAME                           READY     STATUS    RESTARTS   AGE       IP           NODE
hello-nginx-1507731416-h39f0   1/1       Running   0          34s       10.244.0.6   k8s
hello-nginx-1507731416-mnj3m   1/1       Running   0          34s       10.244.1.3   worker1
hello-nginx-1507731416-nsdr2   1/1       Running   0          34s       10.244.0.7   k8s
hello-nginx-1507731416-qh3fx   1/1       Running   0          5m        10.244.1.2   worker1
[root@k8s ~]# kubectl delete deployment hello-nginx

这容器太简洁了，PING都没有啊！！搞个熟悉的linux版本，再跑一遍

kubectl run centos --image=centos:centos6 --command -- vi 
kubectl scale --replicas=4 deployment/centos

[root@k8s ~]# kubectl get pods  -o wide 
NAME                      READY     STATUS    RESTARTS   AGE       IP            NODE
centos-3024873821-4490r   1/1       Running   0          49s       10.244.1.6    worker1
centos-3024873821-k74gn   1/1       Running   0          11s       10.244.0.11   k8s
centos-3024873821-l27xs   1/1       Running   0          11s       10.244.0.10   k8s
centos-3024873821-pbg52   1/1       Running   0          11s       10.244.1.7    worker1

[root@k8s ~]# kubectl exec -ti centos-3024873821-4490r bash
[root@centos-3024873821-4490r /]# yum install -y iputils
[root@centos-3024873821-4490r /]# ping 10.244.0.11 -c 1

以上IP都是互通的，从master节点PING这些IP也是通的。

# 查看pod状态的命令
kubectl -n ${NAMESPACE} describe pod ${POD_NAME}
kubectl -n ${NAMESPACE} logs ${POD_NAME} -c ${CONTAINER_NAME}
</code></pre>

<h2>源IP问题</h2>

<p>原来部署hadoop的时刻，已经遇到过了。知道根源所在，但是这次使用的cni（直接改 <code>dockerd --ip-masq=false</code> 配置仅修改的是docker0）。</p>

<p>先来重现下源ip问题：</p>

<pre><code>./pod_bash centos-3024873821-t3k3r 

yum install epel-release -y ; yum install nginx -y ;
service nginx start

ifconfig

# nginx安装后，访问查看access_log

less /var/log/nginx/access.log 
</code></pre>

<p>在 kube-flannel.yml 中添加 cni-conf.json 网络配置为 <code>"ipMasq": false,</code>，没啥效果，在iptables上面还是有cni的cbr0的MASQUERADE（SNAT）。</p>

<p>注意：重启后，发现一切都正常了。可能是通过apply修改的，没有生效！在配置flannel之前就修改属性应该就ok了！！后面的可以不要看了，方法还比较挫。</p>

<p></p>

<p>用比较极端点的方式，删掉docker0，替换成cni0。 <a href="https://kubernetes.io/docs/getting-started-guides/scratch/#docker">https://kubernetes.io/docs/getting-started-guides/scratch/#docker</a></p>

<p></p>

<p>把docker的网卡设置成cni0(flannel会创建cni0的网卡) :</p>

<pre><code># 清空原来的策略
iptables -t nat -F
ip link set docker0 down
ip link delete docker0

[root@worker1 ~]# cat /usr/lib/systemd/system/docker.service  | grep dockerd
ExecStart=/usr/bin/dockerd --bridge=cni0 --ip-masq=false 
</code></pre>

<p>但是机器重启后cni0这个网卡设备就没有了，导致机器重启后docker启动失败！（cni-conf.json的"ipMasq": false是有效果的，但是好像得是新建的网卡设备才行！）</p>

<p></p>

<pre><code>&gt; Aug 01 08:36:10 k8s dockerd[943]: time="2017-08-01T08:36:10.017266292+08:00" level=fatal msg="Error starting daemon: Error initializing network controller: Error creating default \"bridge\" network: bridge device with non default name cni0 must be created manually"

ip link add name cni0 type bridge
ip link set dev cni0 mtu 1460
# 让flannel来设置IP地址
# ip addr add $NODE_X_BRIDGE_ADDR dev cni0
ip link set dev cni0 up

systemctl restart docker kubelet
</code></pre>

<p></p>

<p>另一种网络部署方式 kubenet + hostroutes ： <a href="https://jishu.io/kubernetes/deploy-production-ready-kubernetes-cluster-on-aliyun/">https://jishu.io/kubernetes/deploy-production-ready-kubernetes-cluster-on-aliyun/</a></p>

<h2>DNS</h2>

<p><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</a></p>

<pre><code># cat busybox.yaml
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - image: busybox
    command:
      - sleep
      - "3600"
    imagePullPolicy: IfNotPresent
    name: busybox
  restartPolicy: Always

kubectl create -f busybox.yaml
kubectl exec -ti busybox -- nslookup kubernetes.default
kubectl exec busybox cat /etc/resolv.conf
</code></pre>

<p></p>

<h2>DNS问题</h2>

<p>在master节点上的POD容器内访问DNS（service）服务，但是返回数据却是域名服务内部POD的IP，而不是Service服务的IP地址。</p>

<pre><code>[root@k8s ~]# kubectl describe services kube-dns -n kube-system
Name:                   kube-dns
Namespace:              kube-system
Labels:                 k8s-app=kube-dns
                        kubernetes.io/cluster-service=true
                        kubernetes.io/name=KubeDNS
Annotations:            &lt;none&gt;
Selector:               k8s-app=kube-dns
Type:                   ClusterIP
IP:                     10.96.0.10
Port:                   dns     53/UDP
Endpoints:              10.244.0.30:53
Port:                   dns-tcp 53/TCP
Endpoints:              10.244.0.30:53
Session Affinity:       None
Events:                 &lt;none&gt;

[root@k8s ~]# kubectl exec -ti centos-3024873821-b6d48 -- nslookup kubernetes.default
;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
;; reply from unexpected source: 10.244.0.30#53, expected 10.96.0.10#53
</code></pre>

<p></p>

<h4>相关问题的一些资源：</h4>

<ul>
<li>*<a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">kubernetes pods replying with unexpected source for DNS queries</a></li>
<li><a href="https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477">https://stackoverflow.com/questions/34001758/kube-proxy-in-iptables-mode-is-not-working/34008477#34008477</a></li>
<li><p><a href="https://github.com/coreos/coreos-kubernetes/issues/572">cni plugin + flannel on v1.3: pods can&rsquo;t route to service IPs</a></p></li>
<li><p><a href="https://www.slideshare.net/kubecon/container-network-interface-network-plugins-for-kubernetes-and-beyond">Container Network Interface: Network Plugins for Kubernetes and beyond</a></p></li>
<li><a href="http://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/">Understanding CNI (Container Networking Interface)</a></li>
<li><a href="https://feisky.gitbooks.io/kubernetes/network/flannel/">Kubernetes指南 - flannel</a></li>
<li>Pod to external traffic is not masqueraded <a href="https://github.com/kubernetes/kubernetes/issues/40761">https://github.com/kubernetes/kubernetes/issues/40761</a></li>
</ul>


<h4>解决方法：</h4>

<p><strong> kube-proxy加上 &ndash;masquerade-all 解决了。</strong></p>

<h4>处理方法：</h4>

<blockquote><p><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a>
kubeadm installs add-on components via the API server. Right now this is the internal DNS server and the kube-proxy DaemonSet.</p></blockquote>

<p>修改有技巧，正如官网文档所说：kube-proxy是内部容器启动的。没找到yaml配置，不能直接改配置文件，这里有如下两种方式修改：</p>

<ul>
<li>通过Dashboard页面的编辑对配置进行修改</li>
<li>通过edit命令对配置进行修改：<code>kubectl edit daemonset kube-proxy -n=kube-system</code> 命令添加 <code>- --masquerade-all</code></li>
</ul>


<h2>Heapster</h2>

<p>参考</p>

<ul>
<li><a href="https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md">https://github.com/kubernetes/heapster/blob/master/docs/influxdb.md</a></li>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/">https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/</a></li>
</ul>


<pre><code>[root@k8s ~]# git clone https://github.com/kubernetes/heapster.git
Cloning into 'heapster'...
remote: Counting objects: 26084, done.
remote: Total 26084 (delta 0), reused 0 (delta 0), pack-reused 26084
Receiving objects: 100% (26084/26084), 36.33 MiB | 2.66 MiB/s, done.
Resolving deltas: 100% (13084/13084), done.
Checking out files: 100% (2531/2531), done.

[root@k8s ~]# cd heapster/
[root@k8s heapster]# kubectl create -f deploy/kube-config/influxdb/
deployment "monitoring-grafana" created
service "monitoring-grafana" created
serviceaccount "heapster" created
deployment "heapster" created
service "heapster" created
deployment "monitoring-influxdb" created
service "monitoring-influxdb" created
[root@k8s heapster]# kubectl create -f deploy/kube-config/rbac/heapster-rbac.yaml 
clusterrolebinding "heapster" created
</code></pre>

<p>其他资源：</p>

<ul>
<li><a href="http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/">http://codingwater.org/2016/08/18/Kubernetes%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7-Heapster/</a></li>
<li><a href="http://www.pangxie.space/docker/727">http://www.pangxie.space/docker/727</a></li>
<li><a href="http://jerrymin.blog.51cto.com/3002256/1904460">http://jerrymin.blog.51cto.com/3002256/1904460</a></li>
<li><a href="http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">http://blog.takipi.com/graphite-vs-grafana-build-the-best-monitoring-architecture-for-your-application/?utm_content=buffer607cd&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer</a></li>
</ul>


<p>DNS的问题耗了比较多的时间。弄好了DNS后，以及heapster的docker镜像的下载都OK的话，就万事俱备了。最后重新启动下dashboard就行了：</p>

<pre><code>[root@k8s ~]# kubectl delete -f kubernetes-dashboard.yaml 
[root@k8s ~]# kubectl create -f kubernetes-dashboard.yaml 
</code></pre>

<p>然后就可以在dashboard上看到美美的曲线图了。</p>

<p></p>

<h2>harbor</h2>

<p>参考 <a href="https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md">https://github.com/vmware/harbor/blob/master/docs/kubernetes_deployment.md</a></p>

<p>日新月异啊，1.1.2版本了！！ 用迅雷直接下载 <a href="https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz">https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz</a>  这个地址。</p>

<p>操作方式还是和原来的版本一样。也就是说可以用原来简化的脚本来安装！</p>

<p>搭建好了后，会基本的使用就差不多了。测试环境资源有限，并且其实用save和load也能解决（咔咔）。</p>

<h2>livenessProbe - Nexus的无响应处理</h2>

<p>在 <a href="https://github.com/winse/docker-hadoop/blob/master/kube-deploy/nexus-rc.yaml">github仓库</a> 上有一份开发环境的NEXUS的启动脚本，从一开始的单pods，改成replicationcontroller。觉得万事大吉了。</p>

<p>但，现在又出现一个问题，就是容器还在，但是8081不提供服务了。这很尴尬，其他开发人员说nexus又不能访问了，我想不对，不是已经改成rc了么，容器应该不会挂才对啊。上环境一看，容器是在，但是服务是真没响应。</p>

<p>怎么办？</p>

<p>搞定时任务，觉得有点low。后面想如果判断一下服务不能访问了就重启，其实k8s已经想到了这一点了，提供了<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-a-liveness-http-request">存活探针livenessProbe</a> 。直接按照官网给的http的例子写就行了。等过几天看效果。</p>

<h2>参考</h2>

<p>官方的一些资源</p>

<ul>
<li><a href="https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy">https://kubernetes.io/docs/getting-started-guides/scratch/#kube-proxy</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/">https://kubernetes.io/docs/admin/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></li>
<li><a href="https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/">https://lukemarsden.github.io/docs/getting-started-guides/kubeadm/</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection">https://kubernetes.io/docs/admin/kubeadm/#running-kubeadm-without-an-internet-connection</a></li>
<li><a href="https://kubernetes.io/docs/admin/kubeadm/#environment-variables">https://kubernetes.io/docs/admin/kubeadm/#environment-variables</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm-upgrade-1-7/</a> 怎么升级，以及如何制定特定的k8s版本</li>
</ul>


<p>使用kubeadm安装集群</p>

<ul>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/</a> 参考</li>
<li><a href="http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/">http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm-2/</a>  weave net网络</li>
<li><a href="https://www.kubernetes.org.cn/1165.html">https://www.kubernetes.org.cn/1165.html</a> 就是上面第一篇，但是排版看起来跟舒服点</li>
<li><a href="http://hairtaildai.com/blog/11">http://hairtaildai.com/blog/11</a> 安装似乎太顺利了，都没有遇到啥问题？</li>
<li><a href="https://my.oschina.net/xdatk/blog/895645">https://my.oschina.net/xdatk/blog/895645</a> 这篇不推荐，太繁琐了。很多贴的是内容，不知道改过啥！</li>
</ul>


<p>DNS问题参考</p>

<ul>
<li><a href="https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries">https://stackoverflow.com/questions/41574846/kubernetes-pods-replying-with-unexpected-source-for-dns-queries</a></li>
<li><a href="https://kubernetes.io/docs/admin/kube-proxy/">https://kubernetes.io/docs/admin/kube-proxy/</a></li>
<li><p><a href="https://docs.docker.com/engine/admin/systemd/#httphttps-proxy">https://docs.docker.com/engine/admin/systemd/#httphttps-proxy</a></p></li>
<li><p><a href="https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html">https://coreos.com/matchbox/docs/latest/bootkube-upgrades.html</a> 命令行编辑的方法在这里看到的
</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/34101">https://github.com/kubernetes/kubernetes/issues/34101</a>
Ok, so it turns out that this flag is not enough, we still have an issue reaching kubernetes service IP. The simplest solution to this is to run kube-proxy with &ndash;proxy-mode=userspace. To enable this, you can use kubectl -n kube-system edit ds kube-proxy-amd64 &amp;&amp; kubectl -n kube-system delete pods -l name=kube-proxy-amd64.</p></li>
<li><p><a href="https://github.com/kubernetes/kubernetes/issues/36835">https://github.com/kubernetes/kubernetes/issues/36835</a> To enable off-cluster bridging when &ndash;proxy-mode=iptables, also set &ndash;cluster-cidr.</p></li>
<li><a href="https://github.com/kubernetes/kubeadm/issues/102">https://github.com/kubernetes/kubeadm/issues/102</a> proxy: clusterCIDR not specified, unable to distinguish between internal and external traffic</li>
</ul>


<p>其他一些资源</p>

<ul>
<li><a href="https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md">https://github.com/cookeem/kubeadm-ha/blob/master/README_CN.md</a></li>
<li><p><a href="https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/">https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/</a>
</p></li>
<li><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/">https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/</a> Replication Controllers</p></li>
<li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy</a> RestartPolicy</li>
</ul>


<p>&mdash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[爬虫之CasperJS]]></title>
    <link href="http://winseliu.com/blog/2017/07/08/casperjs-crawler/"/>
    <updated>2017-07-08T23:56:06+08:00</updated>
    <id>http://winseliu.com/blog/2017/07/08/casperjs-crawler</id>
    <content type="html"><![CDATA[<p>用jsoup(java, scala, groovy)爬过数据，用cheerio(nodejs)爬过数据，每次爬取都要对页面HTML结构，数据来源URL进行研究。还要对网站的反扒做一些HEADER的设置。各种繁琐，主要还有一些数据型的网站验证复杂，很难通过简单的方式来破解它的那套反扒流程。</p>

<p><a href="http://docs.casperjs.org/en/latest/modules/casper.html">CasperJS</a>是在<a href="http://phantomjs.org/quick-start.html">phantomjs</a>基础上的一套工具库用来简化phantomjs的操作，降低使用和入门的门槛。而PhantomJS是类似浏览器的一个工具（headless browsers），你可以把它看做浏览器。所以可以通过CasperJS来操作浏览器访问地址，然后加载完页面后再提取数据，这样就不要考虑被反扒的风险，并且获取数据的方式相对容易和简单。</p>

<h2>先从官网的案例体验下HelloWorld以及如何调试</h2>

<p>下载最新的<a href="http://docs.casperjs.org/en/latest/installation.html#installing-from-npm">CasperJS（npm install）</a>即可，PhantomJS下载<a href="https://bitbucket.org/ariya/phantomjs/downloads/">1.9.8</a>版本，不推荐2+版本，有些功能有问题。</p>

<pre><code>
R:\test&gt;set PATH=C:\Users\winse\AppData\Roaming\npm\node_modules\casperjs\bin;E:\phantomjs-1.9.8-windows;%PATH

R:\test&gt;cat hello.js
var casper = require('casper').create();
// debugger

casper.start('http://casperjs.org/', function() {
    this.echo(this.getTitle());

    this.echo("Star: " + this.evaluate(function () { 
        return $(".octicon-star").parent().text().trim()
    }) )
});

casper.thenOpen('http://phantomjs.org', function() {
    this.echo(this.getTitle());

    this.echo("Intro: " + this.evaluate(function () { 
        return $(".intro h1").innerHTML
        // return document.querySelector(".intro h1").innerHTML
    }) )
});

casper.run();

R:\test&gt;casperjs  hello.js
CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
Star: 6,337 Stargazers
PhantomJS | PhantomJS
Intro: null
</code></pre>

<p></p>

<p>用js的方式来获取页面数据，非常完美，相比直接通过URL请求来获取数据，CasperJS就是慢了点（有点像我们每次都打开浏览器然后再访问，可以通过建立服务，然后在常驻PhantomJS访问页面）。</p>

<p>上面第二次获取的数据不是我们想要的，这里我们通过调试看看到底是什么原因导致的。在start前增加一行 <code>debugger</code> 。然后执行：</p>

<pre><code>casperjs hello.js --verbose --log-level=debug --remote-debugger-port=9000
</code></pre>

<p>打开浏览器方式 localhost:9000 点击 <strong>about:blank</strong> 链接，然后在Console窗口执行 <code>__run()</code> ，等一下下会停在debugger那一行，再然后就是愉快的debug就好了。</p>

<p>在 <a href="http://phantomjs.org">http://phantomjs.org</a> 那一段的evaluate代码处增加一个断点，运行到该断点后，再次打开 localhost:9000 会多出一个当前访问页面的链接，点击进去就像平时F12看到的调式窗口了。</p>

<ul>
<li><a href="http://phantomjs.org/troubleshooting.html#remote-debugging">http://phantomjs.org/troubleshooting.html#remote-debugging</a></li>
<li><a href="https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs">https://drupalize.me/blog/201410/using-remote-debugger-casperjs-and-phantomjs</a></li>
<li><a href="https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper">https://stackoverflow.com/questions/15645371/setting-up-js-debugging-with-intellij-webstorm-and-phantomjs-casper</a></li>
<li><a href="https://github.com/ariya/phantomjs/issues/12064">https://github.com/ariya/phantomjs/issues/12064</a></li>
</ul>


<p>注意: <a href="https://www.portablesoft.org/google-chrome-legacy-versions/">Chrome浏览器要用V54版本以下</a> 的。</p>

<p>调试详情如下：</p>

<pre><code>&gt; $(".intro h1")
null
&gt; $
bound: function () {
        return document.getElementById.apply(document, arguments);
    }
&gt; document.querySelector(".intro h1").innerHTML
"
        Full web stack&lt;br&gt;
        No browser required
      "
</code></pre>

<p>那我们把js脚本修改成querySelector来获取数据。再次执行：</p>

<pre><code>R:\test&gt;casperjs  hello.js
CasperJS, a navigation scripting and testing utility for PhantomJS and SlimerJS
Star: 6,337 Stargazers
PhantomJS | PhantomJS
Intro:
        Full web stack&lt;br&gt;
        No browser required
</code></pre>

<h2>功能特性</h2>

<ul>
<li>截图</li>
</ul>


<p>有现成的方法，但是需要自己<a href="https://uggedal.com/journal/phantomjs-default-background-color/">处理下背景颜色</a> <a href="http://phantomjs.org/tips-and-tricks.html">Tips and Tricks</a>。</p>

<pre><code>&gt; cat capture.js
var casper = require('casper').create({
    waitTimeout: 120000,
    logLevel: "debug",
    verbose: true
});
casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')

casper.start('https://xueqiu.com/2054435398/32283614', function () {
    this.waitForSelector("div.status-content a[title*=xueqiu]");
}).then(function () {
    // white background
    this.evaluate(function () {
        var style = document.createElement('style'),
            text = document.createTextNode('body { background: #fff }');
        style.setAttribute('type', 'text/css');
        style.appendChild(text);
        document.head.insertBefore(style, document.head.firstChild);
    });
}).then(function () {
    this.capture('结庐问山.jpg');
});

casper.run()

&gt; casperjs capture.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk
</code></pre>

<p></p>

<p>用来截全屏的图片相当厉害，Chrome等自带的截图工具如果内容长了后很慢很麻烦，这种方式毫无压力啊。</p>

<ul>
<li>抓取层次页面</li>
</ul>


<p>一般抓数据有个列表页，然后根据列表页的详情地址，根据详情地址再获取数据。</p>

<pre><code>&gt; cat xueqiu.js
debugger

var fs = require('fs');
var casper = require('casper').create({
    waitTimeout: 120000,
    logLevel: "debug",
    verbose: true
});
casper.userAgent('Mozilla/5.0 (Windows NT 10.0; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0')

var links = []
var basedir = '.'
casper.start('https://xueqiu.com/2054435398/32283614', function () {
    this.waitForSelector("div.status-content a[title*=xueqiu]");
}).then(function () {
    var items = this.evaluate(function () {
        return $("div.status-content a[title*=xueqiu]").map(function (i, a) {
            return $(a).attr('href')
        })
    })

    for (var i = 0; i &lt; items.length; i++) {
        links.push(items[i]);
    }

    fs.write('all.html', this.getHTML(), 'w');
}).then(function () {
    this.eachThen(links, function (link) {
        var pathname = undefined;
        var url = link.data;

        this.thenOpen(url, function () {
            this.waitForSelector("div.status-content .detail");
        }).then(function () {
            pathname = this.evaluate(function () {
                var style = document.createElement('style'),
                    text = document.createTextNode('body { background: #fff }');
                style.setAttribute('type', 'text/css');
                style.appendChild(text);
                document.head.insertBefore(style, document.head.firstChild);

                return window.location.pathname;
            });
        }).then(function () {
            if (url.indexOf(pathname))
                this.capture(basedir + pathname + ".jpg");
            else
                this.echo(url);
        });

    })

});

casper.run()

&gt; casperjs xueqiu.js --load-images=yes --disk-cache=yes --ignore-ssl-errors=true --output-encoding=gbk --remote-debugger-port=9000
</code></pre>

<p>然后一堆堆的图片就生成出来了。由于访问的速度有限，有利有弊，慢一点还不要做时间上面的控制了，有点像人在操作的感觉。然后处理下异常的个别再导一次就可以了(错误的那一篇还是404的&hellip;哭笑)。</p>

<pre><code>$("div.status-content a[title*=xueqiu]").map(function(i, a){ return $(a).attr('href') }).length
177

$ find . -name '*.jpg' | wc -l
176
</code></pre>

<p>注意：Windows的命令窗口，多按几次Enter，有时一不小心就进入编辑模式了。</p>

<p>压缩后100多M啊！CasperJS足够强大，更多的模式等待你的开启。就写到此。</p>

<h2>后记</h2>

<p>关于爬虫获取数据 <a href="http://webmagic.io/docs/zh/posts/chx-cases/js-render-page.html">抓取前端渲染的页面</a> 这篇文章讲的挺中肯的，如果可能的话，用作者写的 <a href="https://github.com/code4craft/webmagic/blob/master/README-zh.md">WebMagic</a> 也是一个不错的选择。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
