<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Redis | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/redis/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-05-06T11:26:47+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Build redis-2.8]]></title>
    <link href="http://winseliu.com/blog/2015/01/22/build-redis/"/>
    <updated>2015-01-22T09:59:13+08:00</updated>
    <id>http://winseliu.com/blog/2015/01/22/build-redis</id>
    <content type="html"><![CDATA[<h2>jemalloc</h2>

<p>默认make使用的libc，在内存方面会产生比较多的碎片。可以使用jemalloc要进行内存的分配管理。</p>

<p>如果报<code>make cc Command not found</code>，需要先安装gcc。</p>

<pre><code>tar zxvf redis-2.8.13.bin.tar.gz 
cd redis-2.8.13
cd deps/jemalloc/
# 用于产生h头文件
./configure 

cd redis-2.8.13
make MALLOC=jemalloc
src/redis-server 
</code></pre>

<p>查看jemalloc的include的内容如下：</p>

<pre><code>[hadoop@localhost jemalloc]$ cd include/jemalloc/
internal/              jemalloc_defs.h.in     jemalloc_macros.h      jemalloc_mangle.h      jemalloc_mangle.sh     jemalloc_protos.h.in   jemalloc_rename.h      jemalloc.sh
jemalloc_defs.h        jemalloc.h             jemalloc_macros.h.in   jemalloc_mangle_jet.h  jemalloc_protos.h      jemalloc_protos_jet.h  jemalloc_rename.sh  
</code></pre>

<p>查看内存使用：</p>

<pre><code>[hadoop@localhost redis-2.8.13]$ src/redis-cli info
...
# Memory
used_memory:503576
used_memory_human:491.77K
used_memory_rss:2158592
used_memory_peak:503576
used_memory_peak_human:491.77K
used_memory_lua:33792
mem_fragmentation_ratio:4.29
mem_allocator:jemalloc-3.6.0
...
</code></pre>

<p>redis在使用过程中，会产生碎片。重启以及libc和jemalloc的对比如下：</p>

<pre><code># 运行中实例
# Memory
used_memory:4623527744
used_memory_human:4.31G
used_memory_rss:48304705536
used_memory_peak:38217543280
used_memory_peak_human:35.59G
used_memory_lua:33792
mem_fragmentation_ratio:10.45
mem_allocator:libc

51616 hadoop    20   0 45.1g  44g 1136 S  0.0 35.7   3410:42 /home/hadoop/redis-2.8.13/src/redis-server *:6371

# 序列化为rdb的文件大小
[hadoop@hadoop-master1 18111]$ ll
总用量 1183116
-rw-rw-r--. 1 hadoop hadoop 1210319541 1月  14 11:28 dump.rdb

# 重启后的实例
[hadoop@hadoop-master1 18111]$  ~/redis-2.8.13/src/redis-server --port 18111
[77484] 14 Jan 14:33:17.910 * DB loaded from disk: 218.337 seconds

# Memory
used_memory:4763158704
used_memory_human:4.44G
used_memory_rss:6217580544
used_memory_peak:4763158704
used_memory_peak_human:4.44G
used_memory_lua:33792
mem_fragmentation_ratio:1.31
mem_allocator:libc

77484 hadoop    20   0 6052m 5.8g 1200 S  0.0  4.6   3:38.39 /home/hadoop/redis-2.8.13/src/redis-server *:18111

# 使用jemalloc替换libc的实例
[hadoop@hadoop-master1 18111]$ ~/redis-jemalloc/redis-2.8.13/src/redis-server --port 18888
[14793] 14 Jan 14:50:11.250 * DB loaded from disk: 209.839 seconds

# Memory
used_memory:4527760088
used_memory_human:4.22G
used_memory_rss:4625887232
used_memory_peak:4527760088
used_memory_peak_human:4.22G
used_memory_lua:33792
mem_fragmentation_ratio:1.02
mem_allocator:jemalloc-3.6.0

14793 hadoop    20   0 4538m 4.3g 1360 S  0.0  3.4   3:28.10 /home/hadoop/redis-jemalloc/redis-2.8.13/src/redis-server *:18888                                                                                                                       
</code></pre>

<h2>tcmalloc</h2>

<ul>
<li>root安装</li>
</ul>


<p>如果有root用户的话操作比较简单。现在<a href="https://code.google.com/p/gperftools/">gperftools</a>和<a href="http://download.savannah.gnu.org/releases/libunwind/libunwind-0.99-beta.tar.gz">libunwind-0.99-beta</a></p>

<pre><code>cd libunwind-0.99-beta
./configure 
make &amp;&amp; make install
cd /home/hadoop/gperftools-2.4
./configure 
make &amp;&amp; make install

cd redis-2.8.13
make MALLOC=tcmalloc
</code></pre>

<p>如果出现<strong>./libtool: line 1125: g++: command not found</strong>的错误，缺少编译环境；</p>

<pre><code>[root@localhost gperftools-2.4]# yum -y install gcc+ gcc-c++
</code></pre>

<p>编译后，运行报错<strong>src/redis-server: error while loading shared libraries: libtcmalloc.so.4: cannot open shared object file: No such file or directory</strong>，需要配置环境变量：</p>

<pre><code>[hadoop@localhost redis-2.8.13]$ export LD_LIBRARY_PATH=/usr/local/lib
[hadoop@localhost redis-2.8.13]$ src/redis-server 
</code></pre>

<p>或者按照网上的做法：</p>

<pre><code>echo "/usr/local/lib" &gt; /etc/ld.so.conf.d/usr_local_lib.conf  
/sbin/ldconfig  
</code></pre>

<p>检查tcmalloc是否生效<code>lsof -n | grep tcmalloc</code>，出现以下信息说明生效</p>

<pre><code>redis-ser 1716    hadoop  mem       REG  253,0  2201976  936349 /usr/local/lib/libtcmalloc.so.4.2.6
</code></pre>

<p>修改配置文件找到daemonize，将后面的no改为yes，让其可以以服务方式运行。</p>

<ul>
<li>普通用户安装</li>
</ul>


<p>考虑到可以各台机器上面复制，指定编译目录这种方式会比较方便。</p>

<pre><code>cd libunwind-0.99-beta
CFLAGS=-fPIC ./configure --prefix=/home/hadoop/redis
make &amp;&amp; make install

cd gperftools-2.4
./configure -h
export LDFLAGS="-L/home/hadoop/redis/lib"
export CPPFLAGS="-I/home/hadoop/redis/include"
./configure --prefix=/home/hadoop/redis
make &amp;&amp; make install
</code></pre>

<p>编译好后，把东西redis目录内容移到redis-2.8.13/src下。然后修改src/Makefile：</p>

<pre><code>[hadoop@master1 redis-2.8.13]$ vi src/Makefile
# Include paths to dependencies
FINAL_CFLAGS+= -I../deps/hiredis -I../deps/linenoise -I../deps/lua/src

ifeq ($(MALLOC),tcmalloc)
        #FINAL_CFLAGS+= -DUSE_TCMALLOC
        #FINAL_LIBS+= -ltcmalloc
        FINAL_CFLAGS+= -DUSE_TCMALLOC -I./include
        FINAL_LIBS+= -L./lib  -ltcmalloc -ldl

endif

ifeq ($(MALLOC),tcmalloc_minimal)
        FINAL_CFLAGS+= -DUSE_TCMALLOC
        FINAL_LIBS+= -ltcmalloc_minimal
endif
</code></pre>

<p>然后编译：</p>

<pre><code>[hadoop@master1 redis-2.8.13]$ export LD_LIBRARY_PATH=/home/hadoop/redis-2.8.13/src/lib
[hadoop@master1 redis-2.8.13]$ make MALLOC=tcmalloc
cd src &amp;&amp; make all
make[1]: Entering directory `/home/hadoop/redis-2.8.13/src'
    LINK redis-server
    INSTALL redis-sentinel
    CC redis-cli.o
In file included from zmalloc.h:40,
                 from redis-cli.c:50:
./include/google/tcmalloc.h:35:2: warning: #warning is a GCC extension
./include/google/tcmalloc.h:35:2: warning: #warning "google/tcmalloc.h is deprecated. Use gperftools/tcmalloc.h instead"
    LINK redis-cli
    CC redis-benchmark.o
In file included from zmalloc.h:40,
                 from redis-benchmark.c:47:
./include/google/tcmalloc.h:35:2: warning: #warning is a GCC extension
./include/google/tcmalloc.h:35:2: warning: #warning "google/tcmalloc.h is deprecated. Use gperftools/tcmalloc.h instead"
    LINK redis-benchmark
    CC redis-check-dump.o
    LINK redis-check-dump
    CC redis-check-aof.o
    LINK redis-check-aof

Hint: To run 'make test' is a good idea ;)

make[1]: Leaving directory `/home/hadoop/redis-2.8.13/src'
[hadoop@master1 redis-2.8.13]$ 
</code></pre>

<h2>redis3集群安装cluster</h2>

<p>编译安装和2.8一样，configuration/make/makeinstall即可。</p>

<pre><code>[hadoop@umcc97-44 cluster-test]$ cat cluster.conf 
port .
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes
</code></pre>

<p>比较苦逼的是需要安装ruby，服务器不能上网！其实ruby在能访问的机器上面安装就可以了！初始化集群的脚本其实就是客户端连接服务端，初始化集群而已。
还有就是在调用命令的时刻要加上<code>-c</code>，这样才是使用集群模式，不然仅仅连单机，读写其他集群服务会报错！</p>

<p><img src="http://file.bmob.cn/M00/04/DB/wKhkA1PVx5-Ab4jaAAA9_Lg7l-I862.png" alt="" /></p>

<p><img src="http://file.bmob.cn/M00/04/DB/wKhkA1PVyXSAC5iEAABfrrHCfuI114.png" alt="" /></p>

<p><img src="http://file.bmob.cn/M00/04/DB/wKhkA1PVzBSAc3KOAADvQfFIPrs908.png" alt="" /></p>

<p><img src="http://file.bmob.cn/M00/04/DF/wKhkA1PWCc-AXZ3EAAHoKZnb1nQ426.png" alt="" /></p>

<p><img src="http://file.bmob.cn/M00/04/DF/wKhkA1PWCkWAZYuLAAAWM5VoXJI861.png" alt="" /></p>

<p><img src="http://file.bmob.cn/M00/04/DF/wKhkA1PWCuSAAuXxAABB-LpH1nQ340.png" alt="" /></p>

<p><img src="http://file.bmob.cn/M00/05/5F/wKhkA1PZBrSAPaMTAAAcSnjmhXE093.png" alt="" /></p>

<h2>Cygwin</h2>

<p>开发环境系统都是在windows，想调试一步步的看源码就得编译下redis。由于cygwin环境，模拟的linux，有部分的变量没有定义，需要进行修改。修改如下:</p>

<pre><code>$ git log -1
commit 0c211a1953afeda3d0d45126653e2d4c38bd88cb
Author: antirez &lt;antirez@gmail.com&gt;
Date:   Fri Dec 5 10:51:09 2014 +010

$ git branch
* 2.8

$ git diff
diff --git a/deps/hiredis/net.c b/deps/hiredis/net.c
index bdb84ce..6e95f22 100644
--- a/deps/hiredis/net.c
+++ b/deps/hiredis/net.c
@@ -51,6 +51,13 @@
 #include "net.h"
 #include "sds.h"

+/* Cygwin Fix */
+#ifdef __CYGWIN__
+#define TCP_KEEPCNT 8
+#define TCP_KEEPINTVL 150
+#define TCP_KEEPIDLE 14400
+#endif
+
 /* Defined in hiredis.c */
 void __redisSetError(redisContext *c, int type, const char *str);

diff --git a/src/Makefile b/src/Makefile
index 8b3e959..a72b2f2 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -63,6 +63,9 @@ else
 ifeq ($(uname_S),Darwin)
        # Darwin (nothing to do)
 else
+ifeq ($(uname_S),CYGWIN_NT-6.3-WOW64)
+       # cygwin (nothing to do)
+else
 ifeq ($(uname_S),AIX)
         # AIX
         FINAL_LDFLAGS+= -Wl,-bexpall
@@ -75,6 +78,7 @@ else
 endif
 endif
 endif
+endif
 # Include paths to dependencies
 FINAL_CFLAGS+= -I../deps/hiredis -I../deps/linenoise -I../deps/lua/src
</code></pre>

<p>然后编译：</p>

<pre><code>cd deps/
make lua hiredis linenoise

cd ..
make
</code></pre>

<p>编译成功后，把程序导入eclipse CDT环境进行运行调试。导入后需要重新构建一下，不然调试的时刻会按照/cygwin的路径来查找源码。</p>

<ul>
<li>Import，然后选择C/C++目录下的[Existing Code as Makefile project]</li>
<li>在[Existing Code Location]填入redis程序对应的目录，在[Toolchain for Indexer Settings]选择<strong>Cygwin GCC</strong></li>
<li>导入完成后，右键选择[Build Configuration]->[Build All]</li>
<li>Run然后选择执行redis-server即可。</li>
</ul>


<p>好像也可以远程调试</p>

<pre><code>[root@Frankzfz]$gdbserver 10.27.10.48:9000 ./test_seg_fault
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://blog.sina.com.cn/s/blog_71954d8a0100nixe.html">tcp Keepalive</a></li>
<li><a href="http://jiangzhixiang123.blog.163.com/blog/static/2780206220115643822896/">setsockopt之 TCP_KEEPIDLE/TCP_KEEPINTVL/TCP_KEEPCNT - [Linux]</a></li>
<li><a href="http://blog.csdn.net/ce123_zhouwei/article/details/6625486">GDB+GdbServer: ARM程序调试</a></li>
<li><a href="http://my.oschina.net/shelllife/blog/167914">使用gdbserver远程调试</a></li>
<li><p><a href="http://qingfengju.com/article.asp?id=303">用gdb,gdbserver,eclipse+cdt在windows上远程调试linux程序</a></p></li>
<li><p><a href="http://www.cnblogs.com/kernel_hcy/archive/2011/05/15/2046963.html">redis源码分析（1）内存管理</a></p></li>
<li><a href="http://blog.csdn.net/unix21/article/details/12119059">利用TCMalloc替换Nginx和Redis默认glibc库的malloc内存分配</a>)</li>
<li><a href="http://blog.nosqlfan.com/html/3490.html">Redis采用不同内存分配器碎片率对比</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis维护]]></title>
    <link href="http://winseliu.com/blog/2014/12/31/redis-operations/"/>
    <updated>2014-12-31T23:14:57+08:00</updated>
    <id>http://winseliu.com/blog/2014/12/31/redis-operations</id>
    <content type="html"><![CDATA[<p>在使用过程中，接触最多的就是它的commands。除了string/hashmap/set/sortedlist的基本使用方式外，下面总结平时会经常使用的命令：</p>

<h2>启动，客户端连接</h2>

<pre><code>[root@docker redis-2.8.13]# nohup src/redis-server --port 6370 &amp;

[root@docker redis-2.8.13]# src/redis-cli -p 6370
127.0.0.1:6370&gt; 
</code></pre>

<h2>获取redis的整体状态</h2>

<pre><code>127.0.0.1:6370&gt; info
...
# Memory
used_memory:1415161160
used_memory_human:1.32G
used_memory_rss:0
used_memory_peak:1415161160
used_memory_peak_human:1.32G
used_memory_lua:33792
mem_fragmentation_ratio:0.00
mem_allocator:jemalloc-3.6.0
...
# CPU
used_cpu_sys:52.47
used_cpu_user:10.07
used_cpu_sys_children:0.00
used_cpu_user_children:0.00

# Keyspace
db0:keys=4253125,expires=0,avg_ttl=0
</code></pre>

<p>列出的信息，包括了版本、内存/CPU使用、请求数、键值对等信息。通过这些基本了解redis运行情况。</p>

<h2>清空数据库</h2>

<p>对于数据量少的情况下，可以使用flushall来清理记录。</p>

<pre><code>127.0.0.1:6370&gt; set abc 1234
OK
127.0.0.1:6370&gt; keys *
1) "abc"
127.0.0.1:6370&gt; flushall
OK
127.0.0.1:6370&gt; keys *
(empty list or set)
</code></pre>

<p>数据量大的情况不建议使用flushall，可以直接把rdb数据文件干掉，然后重启redis服务就可以了（找不到数据文件后，就是一个新的库）。</p>

<h2>随机获取一个键</h2>

<pre><code>127.0.0.1:6370&gt; mset a 1 b 2 c 3 d 4 e 5 f 6 
OK
127.0.0.1:6370&gt; RANDOMKEY
"a"
127.0.0.1:6370&gt; RANDOMKEY
"f"
127.0.0.1:6370&gt; RANDOMKEY
"e"
127.0.0.1:6370&gt; RANDOMKEY
"a"
</code></pre>

<h2>遍历获取键值</h2>

<p>一般情况下，我们会使用<code>keys PATTERN</code>来查找匹配的键值。但是，如果数据量很大，keys操作会很消耗系统资源，<code>stop the world</code>的事情不是我们想看到的！此时，可以通过scan/hscan/zscan/ssan命令依次获取。</p>

<ul>
<li>获取库中的键值</li>
</ul>


<pre><code>127.0.0.1:6370&gt; eval "for i=1,100000 do redis.call('set', 'a' .. i, i) end" 0
(nil)
(0.98s)
</code></pre>

<p>正式环境我们无法预估匹配的键的数量，一根筋的使用keys命令可能并不明智。如果数据量很多，等不到结束应该就会ctrl+c了。这种情况下，可以使用scan命令：</p>

<pre><code>127.0.0.1:6370&gt; scan 0 match ismi:domain:*.upaiyun.com
1) "6553600"
2) 1) "ismi:domain:KunMing:1415646303170928524.test.b0.upaiyun.com"
   2) "ismi:domain:KunMing:1415392926002699280.test.b0.upaiyun.com"
   3) "ismi:domain:KunMing:141489373375899237.test.b0.upaiyun.com"
127.0.0.1:6370&gt; scan 0 match ismi:domain:*.upaiyun.com count 10
1) "6553600"
2) 1) "ismi:domain:KunMing:1415646303170928524.test.b0.upaiyun.com"
   2) "ismi:domain:KunMing:1415392926002699280.test.b0.upaiyun.com"
   3) "ismi:domain:KunMing:141489373375899237.test.b0.upaiyun.com"
</code></pre>

<p>Basically with COUNT the user specified the amount of work that should be done at every call in order to retrieve elements from the collection. This is just an hint for the implementation, however generally speaking this is what you could expect most of the times from the implementation.</p>

<p>COUNT数值的意思应该是匹配操作的次数，而不是查询结果的个数。通过和<code>scan 0</code>对比可以得出来。</p>

<p>同理，对于set（smembers）可以使用sscan，sortedlist可以使用zcan等。</p>

<h2>lua脚本</h2>

<p>redis内置的脚本语言，直接使用脚本可以减少客户端和服务端连接（多次请求）的压力。例如要批量删除一些键值：</p>

<pre><code>src/redis-cli keys 'v2:*' | awk '{print $1}' | while read line; do src/redis-cli del $line ; done
</code></pre>

<p>先获取匹配的key，然后使用shell再次调用redis的客户端进行删除。表面上看起来没啥问题，如果匹配的key很多，会产生很多的tcp连接，占用redis服务器的端口！最终端口不够用，请求报错。</p>

<p>此时，如果使用lua脚本的方式，就可以轻松处理。无需考虑端口等问题。</p>

<pre><code># 量少时可以使用
eval "local aks=redis.call('keys', 'v2:*'); if #aks &gt;0 then redis.call('del', unpack(aks)) end" 0

# 优美
eval "local aks=redis.call('keys', 'v2:*'); for _,r in ipairs(aks) do redis.call('del', r) end" 0
</code></pre>

<p>当然，如果键不多，还可以使用一次性全部删除：</p>

<pre><code>src/redis-cli -p $PORT del `~/redis-2.8.13/src/redis-cli -p $PORT 'keys' 'v2:*' | grep -v 'v2:ci:' | grep -v 'v2:ff' | grep -v "$(date +%Y-%m-%d)" | grep -v "$(date +%Y-%m-%d -d '-1 day')"`
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[读读书]Redis入门指南]]></title>
    <link href="http://winseliu.com/blog/2014/07/27/start-redis/"/>
    <updated>2014-07-27T01:20:44+08:00</updated>
    <id>http://winseliu.com/blog/2014/07/27/start-redis</id>
    <content type="html"><![CDATA[<p>《Redis入门指南》的基本使用笔记，<a href="/blog/categories/redis/">jemalloc/tcmalloc功能和redis3集群的安装参考</a>。</p>

<h2>第一章 简介</h2>

<ul>
<li>讲了redis的产生的缘由</li>
<li>Salvtore Sanfilippo/Pieter Noordhuis被招到VMware专门负责redis</li>
<li>redis的源码可以从github下载编译。</li>
</ul>


<p>redis相比keyvalue，提供了更加丰富的值类型：字符串/散列/列表/集合/有序集合，数据提供多种持久化(RDB/AOF)的方式。</p>

<p>在一台普通的笔记本电脑上，Redis可以在一秒内读写超过十万个键值。</p>

<p>功能丰富，提供TTL，可以做(阻塞)队列、缓冲系统、发布/订阅消息模式。redis是单线程模型，相比memcached的多线程，可以启动多个redis实例。</p>

<h2>第二章 准备</h2>

<p>默认的生产环境使用linux，windows操作系统下也有对应的版本但是版本比较旧。
在linux下，下载完成后直接<code>make</code>就可以使用src目录下生成的命令了，<code>make install</code>会把命令拷贝到/usr/local/bin目录下。同时有介绍iOS和Windows下怎么安装redis。</p>

<h3>启动Redis2.8.3</h3>

<pre><code>src/redis-server # default port 6379
src/redis-server --port 6380
</code></pre>

<p>初始化脚本启动Redis</p>

<pre><code>    #!/bin/sh
    #
    # Simple Redis init.d script conceived to work on linux systems
    # as it does use of the /proc filesystem.

    REDISPORT=6379
    EXEC=/usr/local/bin/redis-server
    CLIEXEC=/usr/local/bin/redis-cli

    PIDFILE=/var/run/redis_${REDISPORT}.pid
    CONF=/etc/redis/${REDISPORT}.conf

    case "$1" in
    start)
        if [ -f $PIDFILE ]
        then
            echo "$PIDFILE exists, process is already running or crashed"
        else
            echo "Starting Redis server..."
            $EXEC $CONF
        fi
        ::
    stop)
        if [ ! -f $PIDFILE ]
        then
            echo "$PIDFILE does not exists, process is not running"
        else
            PID=$(cat $PIDFILE)
            echo "Stopping..."
            $CLIEXEC -p $REDISPORT shutdown
            while [ -x /proc/$PID ]
            do 
                echo "Waiting for Redis to shutdown..."
                sleep 1
            done
            echo "Redis stopped"
        fi
        ::
    *)
        echo "Please use start or stop as first argument"
        ::
    esac
</code></pre>

<h3>停止Redis</h3>

<p>不要直接强制终止程序(<code>kill -9</code>)。使用redis提供的shutdown来停，会等所有操作都flush到磁盘后再关闭。保证数据不会丢失。
当然也可以使用SIGTERM信号来处理，使用<code>kill PID</code>命令，Redis妥善的处理与发送shutdown命令效果一样。</p>

<pre><code>src/redis-cli shutdown
</code></pre>

<h3>命令行客户端(cli Command-Line-Interface)</h3>

<pre><code>redis-cli -h IP -p PORT

[hadoop@master1 src]$ ./redis-cli PING
PONG

[hadoop@master1 src]$ ./redis-cli
127.0.0.1:6379&gt; PING
PONG
127.0.0.1:6379&gt; echo hi
"hi"
</code></pre>

<p>各种返回值</p>

<pre><code>127.0.0.1:6379&gt; errorcommand
(error) ERR unknown command 'errorcommand'
127.0.0.1:6379&gt; incr foo
(integer) 1
127.0.0.1:6379&gt; get foo
"1"
127.0.0.1:6379&gt; get noexists
(nil)
127.0.0.1:6379&gt; keys *
1) "foo"
</code></pre>

<h3>配置</h3>

<pre><code>redis-server CONFPATH --loglevel warning
</code></pre>

<p>也可以通过客户端设置值</p>

<pre><code>127.0.0.1:6379&gt; config set loglevel warning
OK
127.0.0.1:6379&gt; config get loglevel
1) "loglevel"
2) "warning"
</code></pre>

<h3>多数据库</h3>

<p>默认启动的程序启用了16个库（0-15，<code>databases 16</code>），客户端与Redis建立连接后，会自动选择0号数据库，不过可以通过SELECT命令更换数据库:</p>

<pre><code>127.0.0.1:6379&gt; select 1
OK
127.0.0.1:6379[1]&gt; get foo
(nil)
127.0.0.1:6379[1]&gt; set foo 1
OK
127.0.0.1:6379[1]&gt; get foo
"1"
</code></pre>

<p>redis不支持为每个数据库设置不同的访问密码，一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库并不是完全的隔离，比如flushall命令可以清空Redis实例中所有的数据库中的数据。所以这些数据库更像是一个命名空间，而不是适合存储不同应用的数据。</p>

<p>但是可以使用0号数据库存储A应用的生产数据而使用1号数据库存储A应用的测试数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis非常轻量级，一个空Redis实例占用内存只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。</p>

<h2>第三章 入门</h2>

<h3>热身</h3>

<p>获取符合规则的键名（glob风格 ?/*/\X/[]） : <code>KEYS pattern</code></p>

<pre><code>127.0.0.1:6379[1]&gt; KEYS *
1) "foq"
2) "foo"
3) "fop"
127.0.0.1:6379[1]&gt; keys fo[a-p]
1) "foo"
2) "fop"

127.0.0.1:6379[1]&gt; exists foa
(integer) 0 #不存在
127.0.0.1:6379[1]&gt; exists foo
(integer) 1 #存在

127.0.0.1:6379[1]&gt; del foo
(integer) 1
127.0.0.1:6379[1]&gt; del foa
(integer) 0
127.0.0.1:6379[1]&gt; keys *
1) "fop"
</code></pre>

<p>keys会遍历Redis中的所有键，当数量比较多是会影响性能，不建议在生产环境使用。</p>

<p>del可以删除多个键值，返回值为删除的个数。del命令的参数不支持通配符，但可以通过linux的实现批量删除<code>redis-cli DEL $(redis-cli KEYS "user:*")</code>（有长度限制）来达到效果，效果比xargs效果更好。</p>

<p>获取keyvalue值的类型</p>

<pre><code>127.0.0.1:6379&gt; set foo 1
OK
127.0.0.1:6379&gt; lpush foo 1
(error) WRONGTYPE Operation against a key holding the wrong kind of value
127.0.0.1:6379&gt; lpush foa 1
(integer) 1
127.0.0.1:6379&gt; type foo
string
127.0.0.1:6379&gt; type foa
list
</code></pre>

<h3>字符串类型</h3>

<pre><code>set key value
get key

incr key # 对应的值需为数值

set foo 1
incr foo
set foo b
incr foo
# (error) ERR value is not an integer or out of range

# 增加指定的整数

incrby key increment
decr key 
decr key decrement
increbyfloat key increment

append key value
strlen key # 字节数，和java字符串的length不同

mget key [key ...]
mset key value [key value ...]

getbit key offset
setbit key offset value
bitcount key [start] [end]
bitop operation destkey key [key ...] # AND OR XOR NOT

set foo1 bar
set foo2 aar
BITOP OR res foo1 foo2 # 位操作命令可以非常紧凑地存储布尔值
GET res
</code></pre>

<h3>散列值</h3>

<pre><code>hset key field value
hget key field
hmset key field value [field value ...]
hmget key field [field ...]
hgetall key

hexists key field
hsetnx key field value # 当字段不存在时赋值 if not exists

hincrby key field increment

hdel key field [field ...]

hkeys key # 仅key
hvals key # 仅value
hlen key  # 字段数量
</code></pre>

<h3>列表</h3>

<p>双端队列型列表</p>

<pre><code>lpush key value [value ...]
rpush key value [value ...]
lpop key
rpop key
llen key
lrange key start stop # 可以使用负索引，从0开始，包括最右边的元素

lrem key count value 
# 删除列表中前count个值为value的元素，返回的是实际删除的元素个数。
# count为负数是从右边开始删除
# count为0时删除所有值为value的元素

# 获得/设置指定索引的元素值

lindex key index # index为负数是从右边开始
lset key index value

ltrim key start end # 只保留列表指定的片段
linsert key BEFORE/AFTER pivotvalue value

poplpush source destination # 将元素从给一个列表转到另一个列表
</code></pre>

<h3>集合类型</h3>

<pre><code>sadd key member [member ...]
srem key member [member ...]
smembers key # 获取集合中的元素
sismember key member # 判断元素是否在集合中

sdiff key [key ...] # 差集 A-B
sinter key [key ...] # A ∩ B
sunion key [key ...] # A ∪ B

scard key # 获取集合中元素个数

sdiffstore destination key [key ...]
sinterstore destination key [key ...]
sunionstore destination key [key ...]

srandmember key [count] 
# 随机获取集合中的元素，count参数来一次性获取多个元素
# count为负数时，会随机从集合里获得|count|个的元素，这里元素有可能相同。

spop key # 从集合中随机弹出一个元素
</code></pre>

<h3>有序集合</h3>

<p>列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现和“新鲜事”或“日志”这样很少访问中间元素的应用。有序集合类型是使用散列和跳跃表（Skip list）实现的，所以即使读取位于中间的数据也很快（时间复杂度是O(log(N))）。列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数）。有序集合要比列表类型更耗费内存。</p>

<pre><code>zadd key score member [score member ...]
# 如果该元素已经存在则会用新的分数替换原有的分数。zadd命令的返回值是新加入到集合中的元素个数（不包含之前已经存在的元素）。
# 其中+inf和-inf分别表示正无穷和负无穷

zscore key member

zrange key start stop [withscores] # 获取排名在某个范围的元素列表
zrevrange key start stop [withscores] 
# 负数代表从后向前查找（-1表示最后一个元素），O(logn+m)

zrangebyscore key min max [withscores] [limit offset  count]

# 命令按照元素分数从小到大的顺序返回分数的min和max之间（包含min和max）的元素。
# 如果希望分数范围不包含端点值，可以在分数前加上"("符号。例如，希望返回80分到100分的数据，可以含80分，但不包含100分。则稍微修改一下上面的命令即可：
zrangebyscore scoreboard 80 (100
zrangebyscore scoreboard (80 +inf
# 本命令中LIMIT offset count与SQL中的用法基本相同。获取分数低于或等于100的前3个人
zrevrangebyscore scoreboard 100 0 limit 0 3

zincrby key increment memeber # 增加某个元素的分数

zcard key # 获取集合中元素的数量
zcount key min max # 获得指定分数范围内的元素个数
zrem key member [memeber ...] # 删除一个或多个元素，返回成功删除的元素数量

# 按照排名范围删除元素, 并返回删除的元素数量
zremrangebyrank key start stop
# 按照分数范围删除元素
zremrangebyscore key min max

zrank key member
zrevrank key memeber

zinterstore destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [aggregate sum|min|max]
zunionstore ...
</code></pre>

<h2>第四章 进阶</h2>

<h3>事务</h3>

<pre><code>multi
sadd "user:1:following" 2
sadd "user:2:followers" 1
exec
</code></pre>

<p>脚本语法有错，命令不能执行。但是当数据类型等逻辑运行错误时，事务里面的命令会被redis接受并执行。</p>

<p>如果事务里的一条命令出现错误，事务里的其他命令依然会继续执行（包括出错到最后的命令）。对应的返回值会返回错误信息。</p>

<pre><code>127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; set key 1
QUEUED
127.0.0.1:6379&gt; sadd key 2
QUEUED
127.0.0.1:6379&gt; set key 3
QUEUED
127.0.0.1:6379&gt; exec
1) OK
2) (error) WRONGTYPE Operation against a key holding the wrong kind of value
3) OK
127.0.0.1:6379&gt; get key
"3"
</code></pre>

<p>redis的事务没有回滚的功能，出现错误事务时必须自己负责收拾剩下的摊子（将数据库复原事务执行前的状态等）。不过由于redis不支持回滚功能，也使得redis在事务上可以保持简洁和快速。其中语法错误完全可以再开发时找出并解决。另外如果能够很好的规划数据库（保证键名规范等）的使用，是不会出现命令与数据类型不匹配这样的错误的。</p>

<p><strong>watch命令</strong></p>

<p>在一个事务中只有当所有命令都依次执行完后才能得到每个结果的返回值。可是有些情况下需要先获得一条命令的返回值，然后再根据这个值执行下一条命令。
如increment的操作，在增加1的是时刻没法保证数据还是原来的数据。为了解决这个问题，可以在GET获取值后保证该键值不会被其他客户端修改，知道函数执行完成后才允许其他客户端修改该键值，这样也可以防止竞态条件。watch命令可以监控一个或多个键，一旦其中一个键被修改（或删除），之后的事务就不会被执行。监控一直持续到exec命令。</p>

<pre><code>127.0.0.1:6379&gt; watch key
OK
127.0.0.1:6379&gt; set key 2
OK
127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; set key 3
QUEUED
127.0.0.1:6379&gt; exec
(nil)
127.0.0.1:6379&gt; get key
"2"
</code></pre>

<p>执行exec命令会取消对所有键的监控，如果不想执行事务中的命令也可以使用unwatch命令来取消监控。</p>

<h3>生存时间TTL</h3>

<pre><code>expire key seconds

ttl key

127.0.0.1:6379&gt; get key
"2"
127.0.0.1:6379&gt; ttl key
(integer) -1
127.0.0.1:6379&gt; expire key 10
(integer) 1
127.0.0.1:6379&gt; ttl key
(integer) 6
127.0.0.1:6379&gt; ttl key
(integer) 1
127.0.0.1:6379&gt; ttl key
(integer) -2

pexpire milliseconds #时间的单位为毫秒
expireat UTC
pexpireat 毫秒（UTC*1000）
</code></pre>

<p>除了persist命令之外，使用set和getset命令为键赋值也会同时清除键的生存时间。使用expire命令会重新设置键的生存时间。其他对键值进行操作的命令（如incr、lpush、hset、zrem）均不会影响键的生存时间。</p>

<p>提示： 如果使用watch命令监测一个拥有生存时间的键，该键时间到期自动删除并不会被watch命令认为该键被改变。</p>

<h3>缓冲</h3>

<p>expire + maxmemory maxmemory-policy(LRU)</p>

<h3>排序</h3>

<p>可以使用multi, zintestore, zrange, del, exec来实现，但太麻烦！<a href="https://gist.github.com/winse/30f9db38a4c41aaf5f9d">实际操作日志</a>。</p>

<p>sort命令，可用于集合、列表类型和有序集合类型</p>

<pre><code>sort key [ALPHA] [BY PREFIXKYE:*-&gt;property] [DESC] [LIMIT offset count] 

127.0.0.1:6379&gt; lpush mylist 7 1 3 9 0
(integer) 5
127.0.0.1:6379&gt; sort mylist
1) "0"
2) "1"
3) "3"
4) "7"
5) "9"
</code></pre>

<p>针对有序集合排序时会忽略元素的分数，只针对元素自身的值进行排序。
集合类型中所有元素是无序的，但经常被用于存储对象的ID，很多情况下都是整数。所以redis多这种情况进行了特殊的优化，元素的顺序是有序的。</p>

<pre><code>127.0.0.1:6379&gt; sadd myset 5 2 6 1 8 1 9 0
(integer) 7
127.0.0.1:6379&gt; smembers myset
1) "0"
2) "1"
3) "2"
4) "5"
5) "6"
6) "8"
7) "9"
</code></pre>

<p>除了直接对元素排序排序外，还可以通过BY操作来获取关联值来进行排序。BY参数的语法为“BY参考键”，其中参考键可以使字符串类型或者是散列类型键的某个字段（表示为键名->字段名）。如果提供了BY参数，sort命令将不再依据元素自身的值进行排序，而是对每个元素使用元素的值替换参考键中的第一个<code>*</code>并获取取值，然后依据该值对元素排序。</p>

<pre><code>sort tag:ruby:posts BY post:*-&gt;time desc
sort sortbylist BY itemsore:* desc
</code></pre>

<p>当参考键不包括<code>*</code>时（即常量键名，与元素值无关）。SORT命令将不会执行排序操作，因为redis认为这种情况没有意义（因为所有要比较的值都一样）。没有执行排序操作，在不需要排序但需要借组sort命令获得与元素相关联的数据时，常量键名是很有用的！</p>

<p>如果几个元素的参考键值相同，则SORT命令会在比较元素本身的值来决定元素的顺序。
当某个元素的参考键不存在时，会默认参考键的值为0。
参考键虽然支持散列类型，但是<code>*</code>只能在<code>-&gt;</code>符号前面（即键名部分）才有用，在<code>-&gt;</code>后（即字段名部分）会被当成字段名本身名本身而不会作为占位符被元素的值替换，即常量键名。但是实际运行时会发现一个有趣的结果。</p>

<pre><code>sort sortbylist BY somekey-&gt;somefield:* 
</code></pre>

<p>上面提到了当参考键名是常量键名时SORT命令将不会执行排序操作，然而上例中却是进行了排序，而且只是对元素本身进行排序。这是因为Redis判断参考键名是不是常量键名的方式是判断参考键名中是否包含<code>*</code>，而<code>somekey-&gt;somefield:*</code>中包含<code>*</code>所以不是常量键名。所以在排序的时刻Redis对每个元素都会读取键somekey中的<code>somefield:*</code>字段（<code>*</code>不会被替换）。无论能否获得其值，每个元素的参考键值是相同的，所以redis被按照元素本身的大小排序。</p>

<p>GET参考不影响排序，它的作用是使SORT命令的返回结果不在是元素自身的值。而是GET参数中指定的键值。GET参数的规则和BY参数一样，GET参数也支持字符串类型和散列类型的值，并使用<code>*</code>作为占位符。要实现在排序后直接返回ID对应的违章标题，可以这样写：</p>

<pre><code>127.0.0.1:6379&gt; lpush tag:ruby:posts 1 2 3
(integer) 3
127.0.0.1:6379&gt; hmset post:1 time 140801 name HelloWorld
OK
127.0.0.1:6379&gt; hmset post:2 time 140802 name HelloWorld2
OK
127.0.0.1:6379&gt; hmset post:3 time 140803 name HelloWorld3
OK
127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc
1) "3"
2) "2"
3) "1"
127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time DESC GET post:*-&gt;name
1) "HelloWorld3"
2) "HelloWorld2"
3) "HelloWorld"
</code></pre>

<p>一个sort命令中可以有多个GET参数（而BY参数只能有一个），所以还可以这样用：</p>

<pre><code>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc GET post:*-&gt;name GET post:*-&gt;time
1) "HelloWorld3"
2) "140803"
3) "HelloWorld2"
4) "140802"
5) "HelloWorld"
6) "140801"
</code></pre>

<p>如果还需要返回文章ID，可以使用<code>GET #</code>获得，也就是返回元素本身的值。</p>

<pre><code>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc GET post:*-&gt;name GET post:*-&gt;time GET #
1) "HelloWorld3"
2) "140803"
3) "3"
4) "HelloWorld2"
5) "140802"
6) "2"
7) "HelloWorld"
8) "140801"
9) "1"
</code></pre>

<p>默认情况下SORT会直接返回排序结果，如果希望保存排序结果，可以使用STORE参数。保存后的键的类型为列表类型，如果键已经存在则会覆盖它，加上STORE参数后的SORT命令的返回值的结果的个数。</p>

<pre><code>127.0.0.1:6379&gt; sort tag:ruby:posts BY post:*-&gt;time desc GET post:*-&gt;name GET post:*-&gt;time GET # STORE tag.ruby.posts.sort
(integer) 9
127.0.0.1:6379&gt; lrange tag.ruby.posts.sort 0 -1
1) "HelloWorld3"
2) "140803"
3) "3"
4) "HelloWorld2"
5) "140802"
6) "2"
7) "HelloWorld"
8) "140801"
9) "1"
</code></pre>

<p>SORT命令的时间复杂度是O(n+mlogm)，其中n表示要排序的列表（集合或有序集合）中的元素个数，m表示要返回的元素个数。当n较大时SORT命令的性能相对较低，并且redis在排序前会建立一个长度为n的容器来存储排序的元素（当键类型为有序集合且参考键为常量键名时容器大小为m而不是n），虽然是一个临时的过程，但如果同时进行较多的大数据量排序操作则会严重影响性能。</p>

<h3>消息通知</h3>

<p>producer/consumer，松耦合，易于扩展，而且可以分布在不同的服务器中！</p>

<pre><code>BLPOP key [key ...] timeout
BRPOP key [key ...] timeoutseconds
# 超时时间设置为0时，表示不限制等待的时间，即如果没有新元素加入列表就会永远阻塞下去。
</code></pre>

<p>BRPOP可以同时接收多个键，同时检测多个键，如果所有键都没有元素则阻塞，其中有一个键有元素则会从该键中弹出元素。如果存在键都有元素则从左到右的顺序取第一个键中的一个元素。借此特性可以实现优先级的队列任务。</p>

<p>publish/subscribe模式，发布/订阅模式同样可以实现进程间的消息传递。</p>

<pre><code>PUBLISH channel.1 hi
SUBSCRIBE channel.1
</code></pre>

<p>执行SUBSCRIBE命令后，客户端会进入订阅状态，处于此状态下客户端不能使用SUBSCRIBE/UNSUBSCRIBE/PSUBSCRIBE（支持glob风格通配符格式）/PUNSUBSCRIBE这4个属于发布/订阅模式的命令之外的命令，否则会报错。</p>

<p>消息类型： subscribe/message/unsubscribe</p>

<pre><code>psubscribe channel.?*
</code></pre>

<h3>管道pipelining</h3>

<p>在执行多个命令时每条命令都需要等待上一条命令执行完才能执行，即使命令不需要上一条命令的执行结果。通过管道可以一次性发送多条命令并在执行完后一次性将结果返回，当一组命令中每条命令都不依赖与之前命令的执行结果就可以将这一组命令一起通过管道发出。管道通过减少客户端与redis的通信次数来实现降低往返时延。（</p>

<h3>节省空间</h3>

<ul>
<li>精简键名和键值 <code>VIP&lt;-very.important.person</code></li>
<li>内部编码优化（存储和效率的取舍）</li>
</ul>


<p>如果想查看一个键的内部编码方式可以使用<code>OBJECT ENCODING foo</code></p>

<h2>第五章 实践</h2>

<ul>
<li>php用户登录，忘记密码邮件发送队列</li>
<li>ruby自动完成</li>
<li>python在线好友</li>
<li>nodejs的IP段地址查询</li>
</ul>


<h2>第六章 脚本</h2>

<p>代码块多次请求，以及事务竞态等问题，需要用到WATCH，多次请求在网络传输上浪费很多时间。redis的脚本类似于数据库的function，在服务端执行。这种方式不仅代码简单、没有竞态条件（redis的命令都是原子的），而且减少了通过网络发送和接收命令的传输开销。</p>

<p>从2.6开始，允许开发者使用Lua语言编写脚本传到redis中执行。在Lua脚本中可以调用大部分的redis命令。减少网络传输时延，原子操作，复用（发送的脚本永久存储在redis中，其他客户端可以复用）。</p>

<p><strong>访问频率</strong></p>

<pre><code>localtimes=redis.call('incr', KEYS[1])
if times==1 then
redis.call('expire', KEYS[1], ARGV[1])
end

if times&gt;tonumber(ARGV[2]) then
return 0
end

return 1
# redis-cli --eval ratelimiting.lua rate.limiting:127.0.0.1 , 10 3 逗号前的是键，后面的是参数
</code></pre>

<h3>lua语法（和shell脚本有点像，更简洁）</h3>

<pre><code>本地变量 local x=10
注释 --xxx
多行注释 --[[xxxx]]
赋值 local a,b=1,2 # a=1, b=2
   local a={1,2,3}
   a[1]=5
数字操作符的操作数如果是字符串会自动转成数字
tonumber
tostring
只要操作数不是nil或者false，逻辑操作符就认为操作数为真，否则为假！
用..来实现字符串连接
取长度 print(#"hello") -- 5
</code></pre>

<h3>使用脚本</h3>

<pre><code>EVAL script numkeys key [key ...] arg [arg ...]

redis&gt; eval "return redis.call('SET', KEYS[1], ARGV[1])" 1 foo bar

EVALSHA sha1 numkeys key [key ...] arg [arg ...]
</code></pre>

<p>同时获取多个散列类型键的键值</p>

<pre><code>local result={}
for i,v in ipairs(KEYS) do
result[i]=redis.call("HGETALL", v)
end
return result
</code></pre>

<p>获取并删除有序集合中分数最小的元素</p>

<pre><code>local element=redis.call("ZRANGE", KEY[1], 0, 0)[1]
if element the
redis.call('ZREM', KEYS[1], element)
end
return element
</code></pre>

<p>处理JSON</p>

<pre><code>local sum=0
local users=redis.call('mget', unpack(KEYS))
for _,user in ipairs(users) do 
local courses=cjson.decode(user).course
for _,score in pairs(courses) do
sum=sum+score
end
end
return sum
</code></pre>

<p>redis脚本禁用使用lua标准库中与文件或系统调用相关的函数，在脚本中只允许对redis的数据进行处理。并且redis还通过禁用脚本的全局变量的方式保证每个脚本都是相对隔离的们不会互相干扰。
使用沙盒不仅是为了保证服务器的安全性，而且还确保了脚本的执行结果值和脚本本身和执行时传递的参数有关，不依赖外界条件（如系统时间、系统中某个文件的内存。。）。这是因为在执行复制和AOF持久化操作时记录的是脚本的内容而不是脚本调用的命令，所以必须保证在脚本内容和参数一样的前提下脚本的执行进行特殊的处理。</p>

<pre><code>script load 'return 1'
script exists sha1
script flush #清空脚本缓冲

script kill
script nosave
</code></pre>

<p>为了限制某个脚本执行时间过长导致redis无法提供服务（如死循环），redis提供了lua-time-limit参数限制脚本的最长运行时间，默认5s。</p>

<h2>第七章 管理</h2>

<ul>
<li>持久化 rdb/AOF
```
save 900 1
save 300 10
save 60 10000
SAVE
BGSAVE
appendonly yes
appendfilename appendonly.aof
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
BGREWRITEAOF

<h1>appendfsync always</h1>

appendfsync everysec

<h1>appendfsync no</h1>

<p>```</p></li>
<li>复制
<code>
redis-server --port 6380 --slaveof 127.0.0.1 6379
SLAVEOF 127.0.0.1 6379
SLAVEOF NO ONE
</code></li>
<li>读写分离</li>
<li>耗时日志查询
<code>
SLOWLOG GET # slowlog-log-slower-than slowlog-max-len
MONITOR
</code></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
