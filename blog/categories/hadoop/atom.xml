<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hadoop | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-01-09T19:39:24+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(4)HA升级]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade/"/>
    <updated>2016-01-07T23:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-4-ha-upgrade</id>
    <content type="html"><![CDATA[<p>官网的文档[HDFSHighAvailabilityWithQJM.html]和[HdfsRollingUpgrade.html]（Note that rolling upgrade is supported only from Hadoop-2.4.0 onwards.）很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<ol>
<li>关闭所有的namenode，部署新版本的hadoop</li>
<li>启动所有的journalnode，是所有！！升级namenode的同时，也会升级所有journalnode！！</li>
<li>使用-upgrade选项启动一台namenode。启动的这台namenode会直接进入active状态，升级本地的元数据，同时会升级shared edit log（也就是journalnode的数据）</li>
<li>使用-bootstrapStandby启动其他namenode，同步更新。不能使用-upgrade选项！（我也没试，不知道试了是啥效果）</li>
</ol>


<h2>关闭集群，部署新版本的hadoop</h2>

<pre><code>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
16/01/08 09:10:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Stopping namenodes on [hadoop-master1 hadoop-master2]
hadoop-master2: stopping namenode
hadoop-master1: stopping namenode
hadoop-slaver1: stopping datanode
hadoop-slaver2: stopping datanode
hadoop-slaver3: stopping datanode
Stopping journal nodes [hadoop-master1]
hadoop-master1: stopping journalnode
16/01/08 09:10:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
hadoop-master1: stopping zkfc
hadoop-master2: stopping zkfc
[hadoop@hadoop-master1 hadoop-2.2.0]$ 

[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ~/hadoop-2.6.3
[hadoop@hadoop-master1 hadoop-2.6.3]$ ll
total 52
drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 bin
lrwxrwxrwx 1 hadoop hadoop    32 Jan  8 06:05 etc -&gt; /home/hadoop/hadoop-2.2.0/ha-etc
drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 include
drwxr-xr-x 3 hadoop hadoop  4096 Dec 18 01:52 lib
drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 libexec
-rw-r--r-- 1 hadoop hadoop 15429 Dec 18 01:52 LICENSE.txt
drwxrwxr-x 2 hadoop hadoop  4096 Jan  8 03:37 logs
-rw-r--r-- 1 hadoop hadoop   101 Dec 18 01:52 NOTICE.txt
-rw-r--r-- 1 hadoop hadoop  1366 Dec 18 01:52 README.txt
drwxr-xr-x 2 hadoop hadoop  4096 Dec 18 01:52 sbin
drwxr-xr-x 3 hadoop hadoop  4096 Jan  7 08:00 share

#// 同步
[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs ~/hadoop-2.6.3 $h:~/ ; done
</code></pre>

<h2>启动所有Journalnode</h2>

<p>2.6和2.2用的是一份配置！etc通过软链接到2.2的ha-etc配置。</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/hadoop-daemons.sh --hostnames "hadoop-master1" --script /home/hadoop/hadoop-2.2.0/bin/hdfs start journalnode
hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-journalnode-hadoop-master1.out
[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
31047 JournalNode
244 QuorumPeerMain
31097 Jps
</code></pre>

<h2>升级一台namenode</h2>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ bin/hdfs namenode -upgrade
...
16/01/08 09:13:54 INFO namenode.NameNode: createNameNode [-upgrade]
...
16/01/08 09:13:57 INFO namenode.FSImage: Starting upgrade of local storage directories.
   old LV = -47; old CTime = 0.
   new LV = -60; new CTime = 1452244437060
16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/tmp/dfs/name
16/01/08 09:13:57 INFO namenode.FSImageTransactionalStorageInspector: No version file in /data/tmp/dfs/name
16/01/08 09:13:57 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
16/01/08 09:13:57 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
...
</code></pre>

<p>官网文档上说，除了升级了namenode的本地元数据外，sharededitlog也被升级了的。</p>

<p>查看journalnode的日志，确实journalnode也升级了：</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-journalnode-hadoop-master1.log 
...
2016-01-08 09:13:57,070 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Starting upgrade of edits directory /data/journal/zfcluster
2016-01-08 09:13:57,072 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Starting upgrade of storage directory /data/journal/zfcluster
2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Starting upgrade of edits directory: .
   old LV = -47; old CTime = 0.
   new LV = -60; new CTime = 1452244437060
2016-01-08 09:13:57,185 INFO org.apache.hadoop.hdfs.server.namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/journal/zfcluster
2016-01-08 09:13:57,222 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastWriterEpoch from 2 to 3 for client /172.17.0.1
2016-01-08 09:16:57,731 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Updating lastPromisedEpoch from 3 to 4 for client /172.17.0.1
2016-01-08 09:16:57,735 INFO org.apache.hadoop.hdfs.qjournal.server.Journal: Scanning storage FileJournalManager(root=/data/journal/zfcluster)
...
</code></pre>

<p>升级的namenode是前台运行的，不要关闭这个进程。接下来把另一台namenode同步一下。</p>

<h2>同步另一台namenode</h2>

<pre><code>[hadoop@hadoop-master2 hadoop-2.6.3]$ bin/hdfs namenode -bootstrapStandby
...
=====================================================
About to bootstrap Standby ID nn2 from:
           Nameservice ID: zfcluster
        Other Namenode ID: nn1
  Other NN's HTTP address: http://hadoop-master1:50070
  Other NN's IPC  address: hadoop-master1/172.17.0.1:8020
             Namespace ID: 639021326
            Block pool ID: BP-1695500896-172.17.0.1-1452152050513
               Cluster ID: CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
           Layout version: -60
       isUpgradeFinalized: false
=====================================================
16/01/08 09:15:19 INFO ha.BootstrapStandby: The active NameNode is in Upgrade. Prepare the upgrade for the standby NameNode as well.
16/01/08 09:15:19 INFO common.Storage: Lock on /data/tmp/dfs/name/in_use.lock acquired by nodename 5008@hadoop-master2
16/01/08 09:15:21 INFO namenode.TransferFsImage: Opening connection to http://hadoop-master1:50070/imagetransfer?getimage=1&amp;txid=1126&amp;storageInfo=-60:639021326:1452244437060:CID-7d5c31d8-5cd4-46c8-8e04-49151578e5bb
16/01/08 09:15:21 INFO namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
16/01/08 09:15:21 INFO namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
16/01/08 09:15:21 INFO namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001126 size 977 bytes.
16/01/08 09:15:21 INFO namenode.NNUpgradeUtil: Performing upgrade of storage directory /data/tmp/dfs/name
...
</code></pre>

<h2>重新启动集群</h2>

<p>ctrl+c关闭hadoop-master1 upgrade的namenode。启动整个集群。</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
16/01/08 09:16:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting namenodes on [hadoop-master1 hadoop-master2]
hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master1.out
hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-namenode-hadoop-master2.out
hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
Starting journal nodes [hadoop-master1]
hadoop-master1: journalnode running as process 31047. Stop it first.
16/01/08 09:16:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master2.out
hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.6.3/logs/hadoop-hadoop-zkfc-hadoop-master1.out
[hadoop@hadoop-master1 hadoop-2.6.3]$ jps
31047 JournalNode
244 QuorumPeerMain
31596 DFSZKFailoverController
31655 Jps
31294 NameNode
</code></pre>

<h2>后记：Journalnode重置</h2>

<p>在HA和non-HA环境来回的切换，最后启动HA时master起不来，执行bootstrapStandby也不行。</p>

<pre><code>2016-01-08 06:15:36,746 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [172.17.0.1:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 1/1. 1 exceptions thrown:
172.17.0.1:8485: Asked for firstTxId 1022 which is in the middle of file /data/journal/zfcluster/current/edits_0000000000000001021-0000000000000001022
        at org.apache.hadoop.hdfs.server.namenode.FileJournalManager.getRemoteEditLogs(FileJournalManager.java:198)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:640)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:181)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:203)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:17453)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
</code></pre>

<p>关闭集群，启动journalnode，跳转到没有问题的namenode机器，执行initializeSharedEdits命令。然后在有问题的namenode上重新初始化！</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode

[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits

[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode

[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby

[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
</code></pre>

<p>后话（谨慎，没有试验过，猜想而已）： 其实上面HA升级的步骤，如果upgrade时没用启动journalnode，导致了问题的话，把journalnode重置应该也是可以的。</p>

<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#HDFS_UpgradeFinalizationRollback_with_HA_Enabled</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html#Upgrade_and_Rollback</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(3)HA配置]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha/"/>
    <updated>2016-01-07T23:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-3-ha</id>
    <content type="html"><![CDATA[<p>官网的文档[HDFSHighAvailabilityWithQJM.html]很详细，但是没有一个整体的案例。这里整理下操作记录下来。</p>

<h2>配置</h2>

<p>hadoop-master1和hadoop-master2之间无密钥登录（failover要用到）：</p>

<pre><code>[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-keygen
[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master2
[hadoop@hadoop-master2 hadoop-2.2.0]$ ssh-copy-id hadoop-master1
</code></pre>

<p>配置文件修改：</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/core-site.xml 

&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://zfcluster&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
&lt;value&gt;hadoop-master1&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/data/tmp&lt;/value&gt;
&lt;/property&gt;

[hadoop@hadoop-master1 hadoop-2.2.0]$ vi etc/hadoop/hdfs-site.xml 

&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
&lt;value&gt; &lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.nameservices&lt;/name&gt;
&lt;value&gt;zfcluster&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.ha.namenodes.zfcluster&lt;/name&gt;
&lt;value&gt;nn1,nn2&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn1&lt;/name&gt;
&lt;value&gt;hadoop-master1:8020&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.rpc-address.zfcluster.nn2&lt;/name&gt;
&lt;value&gt;hadoop-master2:8020&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.http-address.zfcluster.nn1&lt;/name&gt;
&lt;value&gt;hadoop-master1:50070&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.http-address.zfcluster.nn2&lt;/name&gt;
&lt;value&gt;hadoop-master2:50070&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
&lt;value&gt;qjournal://hadoop-master1:8485/zfcluster&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.client.failover.proxy.provider.zfcluster&lt;/name&gt;
&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
&lt;value&gt;/data/journal&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
&lt;value&gt;sshfence&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
&lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h2>启动</h2>

<pre><code>[hadoop@hadoop-master1 hadoop-2.2.0]$ cd ..
[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.2.0 $h:~/ ; done

[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/

[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start journalnode

[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start namenode
[hadoop@hadoop-master2 hadoop-2.2.0]$ bin/hdfs namenode -bootstrapStandby

[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs namenode -initializeSharedEdits

#// 此时可以启动datanode，通过50070端口看namenode的状态

#// Automatic failover，zkfc和namenode没有启动顺序的问题！
[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs zkfc -formatZK
[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc
[hadoop@hadoop-master2 hadoop-2.2.0]$ sbin/hadoop-daemon.sh start zkfc

[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hdfs haadmin -failover nn1 nn2

#// 测试failover，把一个active的namenode直接kill掉，看看另一个是否变成active！

# 重启
[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
16/01/07 10:57:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Stopping namenodes on [hadoop-master1 hadoop-master2]
hadoop-master1: stopping namenode
hadoop-master2: stopping namenode
hadoop-slaver1: stopping datanode
hadoop-slaver2: stopping datanode
hadoop-slaver3: stopping datanode
Stopping journal nodes [hadoop-master1]
hadoop-master1: stopping journalnode
16/01/07 10:58:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Stopping ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
hadoop-master2: no zkfc to stop
hadoop-master1: no zkfc to stop

[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
16/01/07 10:59:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting namenodes on [hadoop-master1 hadoop-master2]
hadoop-master2: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master2.out
hadoop-master1: starting namenode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-namenode-hadoop-master1.out
hadoop-slaver1: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver1.out
hadoop-slaver3: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver3.out
hadoop-slaver2: starting datanode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-datanode-hadoop-slaver2.out
Starting journal nodes [hadoop-master1]
hadoop-master1: starting journalnode, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-journalnode-hadoop-master1.out
16/01/07 10:59:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting ZK Failover Controllers on NN hosts [hadoop-master1 hadoop-master2]
hadoop-master2: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master2.out
hadoop-master1: starting zkfc, logging to /home/hadoop/hadoop-2.2.0/logs/hadoop-hadoop-zkfc-hadoop-master1.out

[hadoop@hadoop-master1 ~]$ jps
15241 DFSZKFailoverController
14882 NameNode
244 QuorumPeerMain
18715 Jps
15076 JournalNode
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html</a></li>
<li><a href="http://www.xlgps.com/article/40993.html">http://www.xlgps.com/article/40993.html</a></li>
<li><a href="http://hbase.apache.org/book.html#basic.prerequisites">http://hbase.apache.org/book.html#basic.prerequisites</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-(2)2.2升级到2.6]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade/"/>
    <updated>2016-01-07T22:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-2-hadoop-upgrade</id>
    <content type="html"><![CDATA[<p>升级的命令很简单，但是不要瞎整！升级就一个命令就搞定了！</p>

<h2>部署2.6.3</h2>

<pre><code>[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.6.3.tar.gz 

[hadoop@hadoop-master1 ~]$ cd hadoop-2.6.3/share/
[hadoop@hadoop-master1 share]$ rm -rf doc/

[hadoop@hadoop-master1 hadoop-2.6.3]$ rm -rf lib/native/*

#// 拷贝四个配置文件到hadoop-2.6.3
[hadoop@hadoop-master1 hadoop-2.6.3]$ cd etc/hadoop/
[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/*-site.xml ./
[hadoop@hadoop-master1 hadoop]$ cp -f ~/hadoop-2.2.0/etc/hadoop/slaves ./

[hadoop@hadoop-master1 hadoop]$ cd 
[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do rsync -vaz --delete --exclude=logs hadoop-2.6.3 $h:~/ ; done
</code></pre>

<h2>升级（最佳方式）</h2>

<p>直接使用upgrade选项启动dfs即可。（secondarynamenode不要单独操作来升级，反正就是执行upgrade启动dfs就好了）。</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade

// 2.2和2.6都没有这个命令
// hadoop dfsadmin -upgradeProgress status
hadoop dfsadmin -finalizeUpgrade
</code></pre>

<p>参考[Hadoop: The Definitive Guide/Chapter 10. Administering Hadoop/Maintenance/Upgrades]</p>

<h2>瞎整1</h2>

<pre><code># 先停集群
[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh

[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh
</code></pre>

<p>直接在原来的2.2基础上启动，datanode启动没问题，但是namenode报错：</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ less logs/hadoop-hadoop-namenode-hadoop-master1.log 
...
2016-01-07 08:05:23,582 FATAL org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.io.IOException: 
File system image contains an old layout version -47.
An upgrade to version -60 is required.
Please restart NameNode with the "-rollingUpgrade started" option if a rolling upgrade is already started; or restart NameNode with the "-upgrade" option to start a new upgrade.
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:232)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1022)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:741)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:538)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:597)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:764)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:748)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1441)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1507)
2016-01-07 08:05:23,583 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2016-01-07 08:05:23,585 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at hadoop-master1/172.17.0.1
************************************************************/
</code></pre>

<p>重新启动，使用upgrade选项启动：</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/stop-dfs.sh
[hadoop@hadoop-master1 hadoop-2.6.3]$ sbin/start-dfs.sh -upgrade
</code></pre>

<p>或者还原到2.2：</p>

<pre><code># **所有**slaver节点的VERSION改回47
[hadoop@hadoop-slaver3 ~]$ vi /data/tmp/dfs/data/current/VERSION 
...
layoutVersion=-47

[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh -rollback
</code></pre>

<h2>原理</h2>

<p>升级的时刻，首先备份原来的数据到previous目录下，升级后的放置到current目录下。namenode这样没啥大问题，但是datanode也是这样结构current和previous，那相当有问题，那数据量不是翻倍了？</p>

<p>查看数据后，发现一个名字的文件current和previous里面使用的是一个inode。也就是说用的是硬链接，数据只有一份！</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop fs -put *.txt /

[hadoop@hadoop-slaver3 ~]$ cd /data/tmp/dfs/data/

[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ test current/finalized/subdir0/subdir0/blk_1073741825 -ef previous/finalized/blk_1073741825
[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ echo $?
0
[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i current/finalized/subdir0/subdir0/blk_1073741825 
142510 current/finalized/subdir0/subdir0/blk_1073741825
[hadoop@hadoop-slaver3 BP-1695500896-172.17.0.1-1452152050513]$ ls -i previous/finalized/blk_1073741825
142510 previous/finalized/blk_1073741825
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop安装与升级-Docker中安装(1)]]></title>
    <link href="http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker/"/>
    <updated>2016-01-07T21:04:27+08:00</updated>
    <id>http://winseliu.com/blog/2016/01/07/hadoop-install-and-upgrade-1-install-in-docker</id>
    <content type="html"><![CDATA[<h2>集群机器准备</h2>

<pre><code>[root@cu2 ~]# docker -v
Docker version 1.6.2, build 7c8fca2/1.6.2

[root@cu2 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
centos              centos6             62068de82c82        4 months ago        250.7 MB

[root@cu2 ~]# docker run -d --name hadoop-master1 -h hadoop-master1 centos:centos6 /usr/sbin/sshd -D
c975b0e41429a3c214e86552f2a9f599ba8ee7487e8fbdc25fd59d29adacca4f
[root@cu2 ~]# docker run -d --name hadoop-master2 -h hadoop-master2 centos:centos6 /usr/sbin/sshd -D
fac1d2ee4a05ab8457f4bd6756622ac8236f64423544150d355f9e3091764d8f
[root@cu2 ~]# docker run -d --name hadoop-slaver1 -h hadoop-slaver1 centos:centos6 /usr/sbin/sshd -D
cc8734f2a0963a030b994f69be697308a13e511557eaefc7d4aca7e300950ded
[root@cu2 ~]# docker run -d --name hadoop-slaver2 -h hadoop-slaver2 centos:centos6 /usr/sbin/sshd -D
7e4b5410a7cb8585436775f15609708b309a5b83930da74d6571533251c26355
[root@cu2 ~]# docker run -d --name hadoop-slaver3 -h hadoop-slaver3 centos:centos6 /usr/sbin/sshd -D
26018b256403d956b4272b6bda09a58d1fc6938591d18f9892ba72782c41880b

[root@cu2 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND               CREATED              STATUS              PORTS               NAMES
26018b256403        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver3      
7e4b5410a7cb        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver2      
cc8734f2a096        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-slaver1      
fac1d2ee4a05        centos:centos6      "/usr/sbin/sshd -D"   About a minute ago   Up About a minute                       hadoop-master2      
c975b0e41429        centos:centos6      "/usr/sbin/sshd -D"   8 minutes ago        Up 8 minutes                            hadoop-master1      

[root@cu2 ~]# docker ps | grep hadoop | awk '{print $1}' | xargs -I{} docker inspect -f ' ' {}
172.17.0.6 hadoop-slaver3
172.17.0.5 hadoop-slaver2
172.17.0.4 hadoop-slaver1
172.17.0.3 hadoop-master2
172.17.0.2 hadoop-master1
</code></pre>

<p>重启docker后，可以直接通过名称启动即可：</p>

<pre><code>[root@cu2 ~]# service docker start
Starting docker:                                           [  OK  ]
[root@cu2 ~]# docker start hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3
hadoop-master1
hadoop-master2
hadoop-slaver1
hadoop-slaver2
hadoop-slaver3
</code></pre>

<p>重启后，hosts文件会被重置！最好就是测试好之前不要重启docker！</p>

<h2>机器配置</h2>

<pre><code>[root@cu2 ~]# ssh root@172.17.0.2
root@172.17.0.2's password: 
Last login: Thu Jan  7 06:17:11 2016 from 172.17.42.1
[root@hadoop-master1 ~]# 
[root@hadoop-master1 ~]# vi /etc/hosts
127.0.0.1       localhost
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters

172.17.0.6 hadoop-slaver3
172.17.0.5 hadoop-slaver2
172.17.0.4 hadoop-slaver1
172.17.0.3 hadoop-master2
172.17.0.2 hadoop-master1

[root@hadoop-master1 ~]# ssh-keygen
[root@hadoop-master1 ~]# 
[root@hadoop-master1 ~]# ssh-copy-id hadoop-master1
[root@hadoop-master1 ~]# ssh-copy-id hadoop-master2
[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver1
[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver2
[root@hadoop-master1 ~]# ssh-copy-id hadoop-slaver3

# 拷贝hosts
[root@hadoop-master1 ~]# for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp /etc/hosts $h:/etc/ ; done

# 安装需要的软件
[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h "yum install man rsync curl wget tar" ; done

# 创建用户
[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h useradd hadoop ; done

#// 把要设置的密码拷贝一下，接下来直接右键（CRT）粘贴弄5次就可以了。如果是几十几百台机器可以使用expect来实现
[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h passwd hadoop ; done
New password: hadoop
BAD PASSWORD: it is based on a dictionary word
BAD PASSWORD: is too simple
Retype new password: hadoop
Changing password for user hadoop.
passwd: all authentication tokens updated successfully.
...

# 建立数据目录，赋权给hadoop用户
[root@hadoop-master1 ~]# for h in hadoop-master1 hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do ssh $h "mkdir /data; chown hadoop:hadoop /data" ; done

[root@hadoop-master1 ~]# su - hadoop
[hadoop@hadoop-master1 ~]$ ssh-keygen 
[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-master1
[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-master2
[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver1
[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver2
[hadoop@hadoop-master1 ~]$ ssh-copy-id hadoop-slaver3

[hadoop@hadoop-master1 ~]$ ll
total 139036
drwxr-xr-x 9 hadoop hadoop      4096 Oct  7  2013 hadoop-2.2.0
-rw-r--r-- 1 hadoop hadoop 142362384 Jan  7 07:14 jdk-7u60-linux-x64.gz
drwxr-xr-x 8 hadoop hadoop      4096 Jan  7 07:11 zookeeper-3.4.6
[hadoop@hadoop-master1 ~]$ tar zxvf jdk-7u60-linux-x64.gz 
[hadoop@hadoop-master1 ~]$ tar zxvf hadoop-2.2.0.tar.gz 
[hadoop@hadoop-master1 ~]$ tar zxvf zookeeper-3.4.6.tar.gz 

# 清理生产上无用的数据
[hadoop@hadoop-master1 ~]$ rm hadoop-2.2.0.tar.gz zookeeper-3.4.6.tar.gz jdk-7u60-linux-x64.gz 

[hadoop@hadoop-master1 ~]$ cd zookeeper-3.4.6/
[hadoop@hadoop-master1 zookeeper-3.4.6]$ rm -rf docs/ src/

[hadoop@hadoop-master1 zookeeper-3.4.6]$ cd ../hadoop-2.2.0/
[hadoop@hadoop-master1 hadoop-2.2.0]$ cd share/
[hadoop@hadoop-master1 share]$ rm -rf doc/
</code></pre>

<h2>程序配置与启动</h2>

<ul>
<li>java</li>
</ul>


<pre><code>[hadoop@hadoop-master1 ~]$ cd
[hadoop@hadoop-master1 ~]$ vi .bashrc 
...
JAVA_HOME=~/jdk1.7.0_60
PATH=$JAVA_HOME/bin:$PATH

export JAVA_HOME PATH
</code></pre>

<p>退出shell再登录，或者source .bashrc！</p>

<ul>
<li>zookeeper</li>
</ul>


<pre><code>[hadoop@hadoop-master1 ~]$ cd zookeeper-3.4.6/conf
[hadoop@hadoop-master1 conf]$ cp zoo_sample.cfg zoo.cfg
[hadoop@hadoop-master1 conf]$ vi zoo.cfg 
...
dataDir=/data/zookeeper

[hadoop@hadoop-master1 ~]$ mkdir /data/zookeeper

[hadoop@hadoop-master1 ~]$ cd ~/zookeeper-3.4.6/
[hadoop@hadoop-master1 zookeeper-3.4.6]$ bin/zkServer.sh start
JMX enabled by default
Using config: /home/hadoop/zookeeper-3.4.6/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[hadoop@hadoop-master1 zookeeper-3.4.6]$ 
[hadoop@hadoop-master1 zookeeper-3.4.6]$ jps
244 QuorumPeerMain
265 Jps

[hadoop@hadoop-master1 zookeeper-3.4.6]$ less zookeeper.out 
</code></pre>

<ul>
<li>hadoop</li>
</ul>


<pre><code>[hadoop@hadoop-master1 ~]$ cd ~/hadoop-2.2.0/etc/hadoop/
[hadoop@hadoop-master1 hadoop]$ rm *.cmd
[hadoop@hadoop-master1 hadoop]$ vi hadoop-env.sh 
# 修改java_home和pid

[hadoop@hadoop-master1 hadoop]$ vi core-site.xml 

&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://hadoop-master1:9000&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/data/tmp&lt;/value&gt;
&lt;/property&gt;

[hadoop@hadoop-master1 hadoop]$ vi hdfs-site.xml 

&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
&lt;value&gt; &lt;/value&gt;
&lt;/property&gt;

[hadoop@hadoop-master1 hadoop]$ vi mapred-site.xml

&lt;property&gt;
&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:10020&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:19888&lt;/value&gt;
&lt;/property&gt;

[hadoop@hadoop-master1 hadoop]$ vi yarn-site.xml 

&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:8032&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:8030&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:8031&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:8033&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
&lt;value&gt;hadoop-master1:8080&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>启动Hadoop</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop version
Hadoop 2.2.0
Subversion https://svn.apache.org/repos/asf/hadoop/common -r 1529768
Compiled by hortonmu on 2013-10-07T06:28Z
Compiled with protoc 2.5.0
From source with checksum 79e53ce7994d1628b240f09af91e1af4
This command was run using /home/hadoop/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar

[hadoop@hadoop-master1 hadoop-2.2.0]$ bin/hadoop namenode -format

# 默认自带的libhadoop有点问题，start-dfs.sh通过hdfs getconf -namenodes输出信息导致执行错误
[hadoop@hadoop-master1 hadoop-2.2.0]$ rm lib/native/libh*

[hadoop@hadoop-master1 ~]$ cd 
[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r jdk1.7.0_60 $h:~/ ; done
[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r hadoop-2.2.0 $h:~/ ; done
[hadoop@hadoop-master1 ~]$ for h in hadoop-master2 hadoop-slaver1 hadoop-slaver2 hadoop-slaver3 ; do scp -r .bashrc $h:~/ ; done

[hadoop@hadoop-master1 ~]$ cd hadoop-2.2.0/
[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh

[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/stop-dfs.sh
[hadoop@hadoop-master1 hadoop-2.2.0]$ sbin/start-dfs.sh
[hadoop@hadoop-master1 hadoop-2.2.0]$ jps
244 QuorumPeerMain
3995 NameNode
4187 Jps
</code></pre>

<p>通过CRT的Port Forwarding的dynamic socket5，浏览器配置socket5代理就可以通过50070端口查看hadoop hdfs集群的状态了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Oozie Start Guide]]></title>
    <link href="http://winseliu.com/blog/2015/09/08/oozie-start-guide/"/>
    <updated>2015-09-08T11:15:14+08:00</updated>
    <id>http://winseliu.com/blog/2015/09/08/oozie-start-guide</id>
    <content type="html"><![CDATA[<h2>步骤记录</h2>

<p>说明：cu2就是hadoop-master2</p>

<ol>
<li>打包</li>
</ol>


<pre><code>[hadoop@cu2 oozie-4.2.0]$ vi bin/mkdistro.sh 
MVN_OPTS="-Dbuild.time=${DATETIME} -Dvc.revision=${VC_REV} -Dvc.url=${VC_URL} "

[hadoop@cu2 oozie-4.2.0]$ bin/mkdistro.sh -DskipTests -Dmaven.javadoc.skip=true
</code></pre>

<ol>
<li>依赖</li>
</ol>


<pre><code>打包后，文件的位置
[hadoop@cu2 ~]$ tar zxvf sources/oozie-4.2.0/distro/target/oozie-4.2.0-distro.tar.gz

下载 &lt;http://dev.sencha.com/deploy/ext-2.2.zip&gt;

yum install zip

[hadoop@cu2 oozie-4.2.0]$ mkdir libext
[hadoop@cu2 oozie-4.2.0]$ cd libext/
[hadoop@cu2 libext]$ ll
total 7584
-rw-rw-r-- 1 hadoop hadoop 6800612 Sep  7 16:00 ext-2.2.zip
-rw-rw-r-- 1 hadoop hadoop  960372 Feb 28  2015 mysql-connector-java-5.1.34.jar
</code></pre>

<ol>
<li>安装</li>
</ol>


<pre><code>[hadoop@cu2 oozie-4.2.0]$ bin/oozie-setup.sh prepare-war

setup后，生成的war的位置：/home/hadoop/oozie-4.2.0/oozie-server/webapps/oozie.war
</code></pre>

<ol>
<li>初始化数据库</li>
</ol>


<pre><code>创建数据库用户

CREATE DATABASE oozie;
GRANT ALL ON oozie.* TO 'oozie'@'%' IDENTIFIED BY 'oozie';
FLUSH PRIVILEGES;
GRANT ALL ON oozie.* TO 'oozie'@'localhost'  IDENTIFIED BY 'oozie';
FLUSH PRIVILEGES;

show grants for oozie;

[hadoop@cu2 oozie-4.2.0]$ vi conf/oozie-site.xml 

&lt;property&gt;
&lt;name&gt;oozie.service.JPAService.jdbc.driver&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;oozie.service.JPAService.jdbc.url&lt;/name&gt;&lt;value&gt;jdbc:mysql://localhost:3306/oozie&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;oozie.service.JPAService.jdbc.username&lt;/name&gt;&lt;value&gt;oozie&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;oozie.service.JPAService.jdbc.password&lt;/name&gt;&lt;value&gt;oozie&lt;/value&gt;
&lt;/property&gt;

这里直接把hadoop的jar添加到脚本中，不拷贝到libext下面
[hadoop@cu2 oozie-4.2.0]$ vi bin/ooziedb.sh
OOZIECPPATH=""
if [ ! -z ${HADOOP_HOME} ] ; then
  OOZIECPPATH="${OOZIECPPATH}:$($HADOOP_HOME/bin/hadoop classpath)"
fi

照着写就行了，不必考虑sql文件的存在与否
[hadoop@cu2 oozie-4.2.0]$ bin/ooziedb.sh create -sqlfile oozie.sql -run
  setting CATALINA_OPTS="$CATALINA_OPTS -Xmx1024m"

Validate DB Connection
DONE
DB schema does not exist
Check OOZIE_SYS table does not exist
DONE
Create SQL schema
DONE
Create OOZIE_SYS table
DONE

Oozie DB has been created for Oozie version '4.2.0'


The SQL commands have been written to: oozie.sql
</code></pre>

<ol>
<li>启动服务</li>
</ol>


<pre><code>由于war中没有hadoop的jar，所以这里也需要把它们添加到tomcat
[hadoop@cu2 oozie-4.2.0]$ $HADOOP_HOME/bin/hadoop classpath | sed 's/:/,/g'
/home/hadoop/hadoop-2.7.1/etc/hadoop,/home/hadoop/hadoop-2.7.1/share/hadoop/common/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/common/*,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/*,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/*,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/lib/*,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/*,/home/hadoop/hadoop-2.7.1/contrib/capacity-scheduler/*.jar

处理下把*改成*.jar

[hadoop@cu2 oozie-4.2.0]$ vi oozie-server/conf/catalina.properties 
common.loader=${catalina.base}/lib,${catalina.base}/lib/*.jar,${catalina.home}/lib,${catalina.home}/lib/*.jar,/home/hadoop/hadoop-2.7.1/etc/hadoop,/home/hadoop/hadoop-2.7.1/share/hadoop/common/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/common/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/hdfs/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/yarn/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/lib/*.jar,/home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/*.jar,/home/hadoop/hadoop-2.7.1/contrib/capacity-scheduler/*.jar

# 前台运行 bin/oozied.sh run
[hadoop@cu2 oozie-4.2.0]$ bin/oozied.sh start

http://localhost:11000/
</code></pre>

<ol>
<li>测试</li>
</ol>


<pre><code>[hadoop@cu2 oozie-4.2.0]$ vi bin/oozie
OOZIECPPATH=""
if [ ! -z ${HADOOP_HOME} ] ; then
  OOZIECPPATH="${OOZIECPPATH}:$($HADOOP_HOME/bin/hadoop classpath)"
fi

[hadoop@cu2 oozie-4.2.0]$ bin/oozie admin -oozie http://localhost:11000/oozie -status
System mode: NORMAL
</code></pre>

<ol>
<li>跑个helloworld</li>
</ol>


<pre><code>[hadoop@cu2 oozie-4.2.0]$ tar zxvf oozie-sharelib-4.2.0.tar.gz 
[hadoop@cu2 oozie-4.2.0]$ ~/hadoop-2.7.1/bin/hadoop fs -rmr share
[hadoop@cu2 oozie-4.2.0]$ ~/hadoop-2.7.1/bin/hadoop fs -put share share
[hadoop@cu2 oozie-4.2.0]$ tar zxvf oozie-examples.tar.gz 
[hadoop@cu2 oozie-4.2.0]$ ~/hadoop-2.7.1/bin/hadoop fs -put examples examples

修改share后重启下oozie，sharelib在应用中会缓冲，中间上传程序不能识别，会报`Could not locate Oozie sharelib`的错。

[hadoop@cu2 oozie-4.2.0]$ vi examples/apps/map-reduce/job.properties 
nameNode=hdfs://hadoop-master2:9000
jobTracker=hadoop-master2:8032
queueName=default
examplesRoot=examples

oozie.wf.application.path=${nameNode}/user/${user.name}/${examplesRoot}/apps/map-reduce/workflow.xml
outputDir=map-reduce

[hadoop@cu2 oozie-4.2.0]$ bin/oozie job -oozie http://localhost:11000/oozie -config examples/apps/map-reduce/job.properties -run
Error: E0501 : E0501: Could not perform authorization operation, User: hadoop is not allowed to impersonate hadoop

[hadoop@cu2 hadoop-2.7.1]$ vi etc/hadoop/core-site.xml 
&lt;property&gt;
&lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;

[hadoop@cu2 ~]$ for h in `cat /etc/hosts | grep slaver | awk '{print $2}' ` ; do rsync -vaz hadoop-2.7.1 $h:~/ --exclude=logs ; done

同步重启集群

注：增加以上配置后，无需重启集群，可以直接用hadoop管理员账号重新加载这两个属性值，命令为：
    hdfs dfsadmin -refreshSuperUserGroupsConfiguration
    yarn rmadmin -refreshSuperUserGroupsConfiguration

[hadoop@cu2 oozie-4.2.0]$ bin/oozie job -oozie http://localhost:11000/oozie -config examples/apps/map-reduce/job.properties -run
job: 0000000-150908082015741-oozie-hado-W

[hadoop@cu2 hadoop-2.7.1]$ bin/hadoop fs -cat /user/hadoop/examples/output-data/map-reduce/part-00000

尽管能看到结果了，但是不算任务执行成功。任务是有报错的`JA006: Call From cu2/192.168.0.214 to hadoop-master2:10020 failed on connection exception`

[hadoop@cu2 hadoop-2.7.1]$ sbin/mr-jobhistory-daemon.sh start historyserver

在运行一次就ok了。
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="https://oozie.apache.org/docs/4.2.0/DG_QuickStart.html">https://oozie.apache.org/docs/4.2.0/DG_QuickStart.html</a></li>
<li><a href="http://ju.outofmemory.cn/entry/65688">http://ju.outofmemory.cn/entry/65688</a></li>
<li><a href="http://stackoverflow.com/questions/30926357/oozie-on-yarn-oozie-is-not-allowed-to-impersonate-hadoop">http://stackoverflow.com/questions/30926357/oozie-on-yarn-oozie-is-not-allowed-to-impersonate-hadoop</a></li>
<li><a href="http://oozie.apache.org/docs/4.0.0/DG_QuickStart.html#Oozie_Share_Lib_Installation">http://oozie.apache.org/docs/4.0.0/DG_QuickStart.html#Oozie_Share_Lib_Installation</a></li>
<li><a href="https://oozie.apache.org/docs/4.2.0/DG_Examples.html">https://oozie.apache.org/docs/4.2.0/DG_Examples.html</a></li>
<li><p><a href="http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html">http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></p></li>
<li><p><a href="http://blog.csdn.net/wngn123/article/details/41380013">http://blog.csdn.net/wngn123/article/details/41380013</a></p></li>
</ul>

]]></content>
  </entry>
  
</feed>
