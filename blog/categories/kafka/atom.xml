<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Kafka | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/kafka/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-10-25T08:52:52+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用 Flume+kafka+elasticsearch 处理数据]]></title>
    <link href="http://winseliu.com/blog/2016/06/28/flume-kafka-elasticsearch-for-analyse/"/>
    <updated>2016-06-28T09:50:05+08:00</updated>
    <id>http://winseliu.com/blog/2016/06/28/flume-kafka-elasticsearch-for-analyse</id>
    <content type="html"><![CDATA[<p>flume-1.6依赖的kafka、elasticsearch的版本与我这使用程序的版本不一致，部分jar依赖需要替换，flume-elasticsearch-sink源码需要进行一些修改来适配elasticsearch-2.2。</p>

<ul>
<li>flume-1.6.0</li>
<li>kafka_2.11-0.9.0.1(可以与0.8.2客户端通信, flume-kafka-channel-1.6.0不改)</li>
<li>elasticsearch-2.2.0</li>
</ul>


<p>由于版本的差异，需要替换/添加以下jar到 <code>flume/lib</code> 下：</p>

<p>使用 <code>mvn dependecy:copy-dependencies</code> 导出所需依赖的包</p>

<p>jackson一堆，hppc-0.7.1.jar，t-digest-3.0.jar，jsr166e-1.1.0.jar，guava-18.0.jar，lucene一堆，elasticsearch-2.2.0.jar。</p>

<p>远程调试配置：</p>

<p>source由于项目上的一些特殊规则，需要自己编写。通过远程DEBUG来打断点来排查BUG。</p>

<pre><code>[hadoop@cu2 flume]$ vi conf/flume-env.sh
export JAVA_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8092"
</code></pre>

<h2>实战1</h2>

<p>KafkaChannel：考虑到其他功能也需要用到这些数据。</p>

<p>先写一个配置把flume自带功能跑通，这里用 netcat 作为输入运行：</p>

<pre><code>[hadoop@cu2 flumebin]$ cat dta.flume 
dta.sources=s1
dta.channels=c1
dta.sinks=k1

dta.channels.c1.type=org.apache.flume.channel.kafka.KafkaChannel
dta.channels.c1.capacity=10000
dta.channels.c1.transactionCapacity=1000
dta.channels.c1.brokerList=cu5:9093
dta.channels.c1.topic=flume_cmdid_1234
dta.channels.c1.groupId=flume_dta
dta.channels.c1.zookeeperConnect=cu3:2181/kafka_0_9
dta.channels.c1.parseAsFlumeEvent=false

dta.sources.s1.channels=c1
dta.sources.s1.type=netcat
dta.sources.s1.bind=0.0.0.0
dta.sources.s1.port=6666
dta.sources.s1.max-line-length=88888888

dta.sinks.k1.channel=c1
dta.sinks.k1.type=elasticsearch
dta.sinks.k1.hostNames=cu2:9300
dta.sinks.k1.indexName=foo_index
dta.sinks.k1.indexType=idcisp
dta.sinks.k1.clusterName=eshore-cu
dta.sinks.k1.batchSize=500
dta.sinks.k1.ttl=5d
dta.sinks.k1.serializer=com.eshore.zhfx.collector.InfoSecurityLogIndexRequestBuilderFactory
dta.sinks.k1.serializer.idcispUrlBase64=true

[hadoop@cu2 flumebin]$ bin/flume-ng agent --classpath flume-dta-source-2.1.jar  -n dta -c conf -f dta.flume

# 新开一个窗口
[hadoop@cu2 ~]$ nc localhost 6666
</code></pre>

<p>kafka的主题、ES的索引可以不要手动建，当然为了更好的控制ES索引创建可以添加一个索引名的template。</p>

<p>InfoSecurityLogIndexRequestBuilderFactory 实现 ElasticSearchIndexRequestBuilderFactory 把原始记录转换成 ES 的JSON对象。</p>

<pre><code>  private Counter allRecordMetric = MetricManager.getInstance().counter("all_infosecurity");
  private Counter errorRecordMetric = MetricManager.getInstance().counter("error_infosecurity");

  public IndexRequestBuilder createIndexRequest(Client client, String indexPrefix, String indexType, Event event)
      throws IOException {
    allRecordMetric.inc();

    String record = new String(event.getBody(), outputCharset);

    context.put(ElasticSearchSinkConstants.INDEX_NAME, indexPrefix);
    indexNameBuilder.configure(context);
    IndexRequestBuilder indexRequestBuilder = client.prepareIndex(indexNameBuilder.getIndexName(event), indexType);

    try {
      Gson gson = new Gson();
      IdcIspLog log = parseRecord(record);
      BytesArray data = new BytesArray(gson.toJson(log));

      indexRequestBuilder.setSource(data);
      indexRequestBuilder.setRouting(log.commandld);
    } catch (Exception e) {
      LOG.error(e.getMessage(), e);
      errorRecordMetric.inc();

      indexRequestBuilder.setSource(record.getBytes(outputCharset));
      // 保留错误的数据
      indexRequestBuilder.setRouting("error");
    }

    return indexRequestBuilder;
  }
</code></pre>

<h2>实战2</h2>

<p>测试自定义的Source：</p>

<pre><code>dta.sources=s1
dta.channels=c1
dta.sinks=k1

dta.channels.c1.type=memory
dta.channels.c1.capacity=1000000
dta.channels.c1.transactionCapacity=1000000
dta.channels.c1.byteCapacity=7000000000

dta.sources.s1.channels=c1
dta.sources.s1.type=com.eshore.zhfx.collector.CollectSource
dta.sources.s1.spoolDir=/home/hadoop/flume/data/
dta.sources.s1.trackerDir=/tmp/dtaspool

dta.sinks.k1.channel=c1
dta.sinks.k1.type=logger
</code></pre>

<p>CollectSource 实现PollableSource 继承AbstractSource类。参考Flume开发文档: <a href="http://flume.apache.org/FlumeDeveloperGuide.html#source">http://flume.apache.org/FlumeDeveloperGuide.html#source</a>  <code>org.apache.flume.source.SequenceGeneratorSource</code> 类。</p>

<p>方法process主逻辑代码如下：</p>

<pre><code>  public Status process() throws EventDeliveryException {
    Status status = Status.READY;

    try {
      List&lt;Event&gt; events = readEvent(batchSize);
      if (!events.isEmpty()) {
        sourceCounter.addToEventReceivedCount(events.size());
        sourceCounter.incrementAppendBatchReceivedCount();

        getChannelProcessor().processEventBatch(events);
        // 记录文件已经处理的位置
        commit();

        sourceCounter.addToEventAcceptedCount(events.size());
        sourceCounter.incrementAppendBatchAcceptedCount();
      }
    } catch (ChannelException | IOException e) {
      status = Status.BACKOFF;
      Throwables.propagate(e);
    }

    return status;
  }
</code></pre>

<h2>实例：Flume+Kafka+ES</h2>

<p>把两个实例整合起来，把实例1的Source替换下即可。</p>

<h2>附-kafka基本操作</h2>

<pre><code>[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-server-start.sh config/server1.properties 

[hadoop@cu5 kafka_2.11-0.9.0.1]$ cat config/server1.properties 
listeners=PLAINTEXT://:9093
log.dirs=/tmp/kafka-logs1
num.partitions=1
zookeeper.connect=cu3,cu4,cu5/kafka_0_9

[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-topics.sh --create --zookeeper cu3:2181/kafka_0_9 --replication 1 --partitions 1 --topic flume
Created topic "flume".

[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-topics.sh --list --zookeeper cu3:2181/kafka_0_9
flume

[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-console-producer.sh --broker-list cu5:9093 --topic flume

[hadoop@cu5 kafka_2.11-0.9.0.1]$ bin/kafka-console-consumer.sh --zookeeper cu3:2181/kafka_0_9 --topic flume --from-beginning

##添加kafka-manager：

启动kafka添加JMX
export JMX_PORT=19999
nohup bin/kafka-server-start.sh config/server.properties &amp;

# https://github.com/yahoo/kafka-manager/tree/1.3.1.8
nohup bin/kafka-manager -Dhttp.port=9090 &amp;
</code></pre>

<h2>附-Flume操作</h2>

<pre><code>https://flume.apache.org/FlumeUserGuide.html#fan-out-flow

#conf/flume-env.sh
export FLUME_JAVA_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8092"
bin/flume-ng agent --classpath "flume-dta-libs/*" -Dflume.root.logger=DEBUG,console  -n dta -c conf -f accesslog.flume

# with ganglia
[ud@cu-ud1 apache-flume-1.6.0-bin]$ bin/flume-ng agent --classpath "/home/ud/collector/common-lib/*"  -Dflume.root.logger=Debug,console -Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=239.2.11.71:8649 -n dta -c conf -f accesslog.flume 

# windows
bin\flume-ng.cmd agent -n agent -c conf -f helloworld.flume -property "flume.root.logger=INFO,console"
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kafka快速入门]]></title>
    <link href="http://winseliu.com/blog/2015/01/08/kafka-guide/"/>
    <updated>2015-01-08T22:02:21+08:00</updated>
    <id>http://winseliu.com/blog/2015/01/08/kafka-guide</id>
    <content type="html"><![CDATA[<p>年前的时刻就听过kafka的大名，但是一直没有机会亲手尝试。数据写入HDFS然后再MapReduce去处理数据，这样会多出很多中间过程，浪费系统资源。实践下kafka+spark分析是否会更高效。首先了解kafka的基本操作。</p>

<p><a href="http://kafka.apache.org/documentation.html">文档</a>先进行简单的介绍。kafka是一个分布式的、分区的、冗余的日志服务，提供消息系统类似的功能。主要的概念： Topic，Producers，Consumers，Partition，Distribution（replicated）；producers通过TCP发送消息给Kafka集群，然后consumer从Kafka集群获取信息。</p>

<p>Kafka遵循：</p>

<ul>
<li>对于同一个生产者产生的消息有序。</li>
<li>消费者看到的消息顺序和消息存储的顺序一致</li>
<li>一个主题冗余为N的，可以容忍N-1个服务器失败而不会丢失任何消息。</li>
</ul>


<p>下载<a href="http://kafka.apache.org/downloads.html">kafka</a>，当前稳定版本为<a href="https://archive.apache.org/dist/kafka/0.8.1.1/RELEASE_NOTES.html">kafka_2.10-0.8.1.1</a>。下载后解压就可以运行了。</p>

<h2>启动单实例</h2>

<p>由于windows运行的程序放在<code>bin\windows</code>下面。需要对kafka-run-class.bat批处理文件进行稍稍修改：</p>

<pre><code>rem set BASE_DIR=%CD%\..
set BASE_DIR=%CD%\..\..

rem for %%i in (%BASE_DIR%\core\lib\*.jar) do (
for %%i in (%BASE_DIR%\libs\*.jar) do (
</code></pre>

<p>运行程序：</p>

<pre><code>bin\windows&gt;zookeeper-server-start.bat ..\..\config\zookeeper.properties

rem 再打开一个cmd窗口运行
bin\windows&gt;kafka-server-start.bat ..\..\config\server.properties
</code></pre>

<p>整合成一个脚本<code>start-all.bat</code>，方便以后使用：</p>

<pre><code>start zookeeper-server-start.bat ..\..\config\zookeeper.properties
timeout 5
start kafka-server-start.bat ..\..\config\server.properties
exit
</code></pre>

<h2>Topic</h2>

<pre><code>bin\windows&gt;kafka-run-class.bat kafka.admin.TopicCommand --create --zookeeper localhost:2181 --replication 1 --partitions 1 --topic hello
Created topic "hello".

bin\windows&gt;kafka-run-class.bat kafka.admin.TopicCommand --list --zookeeper localhost:2181
hello

bin\windows&gt;kafka-run-class.bat kafka.admin.TopicCommand  --describe --zookeeper localhost:2181 --topic hello
Topic:hello     PartitionCount:1        ReplicationFactor:1     Configs:
        Topic: hello    Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</code></pre>

<p>如果是在linux下，可以运行kafka-topics.sh来创建和查询。如果觉得打印的日志很不爽，可以修改config目录下的log4j.properties（在脚本中通过环境变量log4j.configuration指定为该文件）。</p>

<h2>发送接受消息</h2>

<pre><code>rem 生产者
bin\windows&gt;kafka-console-producer.bat --broker-list localhost:9092 --topic hello

rem 消费者（新开一个窗口）
bin\windows&gt;kafka-console-consumer.bat --zookeeper localhost:2181 --topic hello --from-beginning
</code></pre>

<p>都启动后，在producer的窗口输入信息。同一时刻，consumer也会打印输入的内容。</p>

<p>这个两个命令都有很多参数，直接输入命令不加任何参数可以输出帮助，了解各个参数的含义及其用法。</p>

<h2>Kafka集群</h2>

<p>集群的配置和zookeeper的集群配置方式很类似。只要修改broker.id和数据存储目录即可。</p>

<p>拷贝server.properties，然后修改下面的三个属性：</p>

<pre><code>broker.id=1
port=9192
log.dir=/tmp/kafka-logs-1
</code></pre>

<p>然后启动：</p>

<pre><code>set JMX_PORT=19999
start kafka-server-start.bat ..\..\config\server-1.properties
set JMX_PORT=29999
start kafka-server-start.bat ..\..\config\server-2.properties
set JMX_PORT=39999
start kafka-server-start.bat ..\..\config\server-3.properties
</code></pre>

<p>创建Topic</p>

<pre><code>bin\windows&gt;kafka-run-class.bat kafka.admin.TopicCommand --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic mhello
Created topic "mhello".

bin\windows&gt;kafka-run-class.bat kafka.admin.TopicCommand --describe --zookeeper localhost:2181 --topic mhello
Topic:mhello    PartitionCount:1        ReplicationFactor:3     Configs:
        Topic: mhello   Partition: 0    Leader: 0       Replicas: 0,3,1 Isr: 0,3,1

bin\windows&gt;kafka-console-producer.bat --broker-list localhost:9092 --topic mhello
bin\windows&gt;kafka-console-consumer.bat --zookeeper localhost:2181 --topic mhello --from-beginning
</code></pre>

<p>描述命令的第一行是所有分区的概要信息，接下来的每一行是每一个分区的信息。Leader后面的数字表示对应的broker-id的进程为当前分区的主节点，后面的Replicas是数据分布的情况（不管数据存在与否），Isr是当前存活的节点的数据分布情况。</p>

<p>把刚刚启动的1，2，3的节点都停掉，再查描述信息。</p>

<pre><code>bin\windows&gt;kafka-run-class.bat kafka.admin.TopicCommand --describe --zookeeper localhost:2181 --topic mhello
Topic:mhello    PartitionCount:1        ReplicationFactor:3     Configs:
        Topic: mhello   Partition: 0    Leader: 0       Replicas: 0,3,1 Isr: 0

bin\windows&gt;kafka-console-consumer.bat --zookeeper localhost:2181 --topic mhello --from-beginning
hello1
hello2
hello3      
</code></pre>

<p>只要有一个节点存在，获取数据都没有问题。如果全部停了，就不能提供服务，但是查询describe命令，显示的还是0，囧！！</p>

<p>开启1，2，3节点后，mhello分区的状态：</p>

<pre><code>Topic:mhello    PartitionCount:1        ReplicationFactor:3     Configs:
        Topic: mhello   Partition: 0    Leader: 3       Replicas: 0,3,1 Isr: 3,1
</code></pre>

<p>问题：当broker-id修改后，原来的数据，并不能透明的过渡。把broker-id为0的节点修改为1000，然后重启。mhello的数据仍然找不到。再次改回0，存活节点才都回来。</p>

<pre><code>        Topic: mhello   Partition: 0    Leader: 3       Replicas: 0,3,1 Isr: 3,1,0
</code></pre>

<h2>小结</h2>

<p>把基本的功能操作了一遍，都是使用命令行操作，接下来学习下和<a href="https://github.com/linkedin/camus/">hadoop结合</a>，使用java-api来操作Kafka。</p>

<h2>参考</h2>

<ul>
<li><a href="http://kafka.apache.org/documentation.html#gettingStarted">kafka gettingStarted</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
