<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2017-02-13T15:10:58+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[K8s Minikube on Windows]]></title>
    <link href="http://winseliu.com/blog/2017/02/08/k8s-minikube-on-windows/"/>
    <updated>2017-02-08T22:50:06+08:00</updated>
    <id>http://winseliu.com/blog/2017/02/08/k8s-minikube-on-windows</id>
    <content type="html"><![CDATA[<p>在windows配置minikube需要先安装docker，或者更直接点的说就是需要docker一样的依赖环境（都是通过iso装载到虚拟机，我们这里不考虑iso内部的软件配置）。先安装docker会把这些依赖都配置好。</p>

<p>系统当前的版本不支持直接安装<a href="https://docs.docker.com/docker-for-windows/">Docker</a>（This version of Docker requires Windows 10 Pro, Enterprise or Education edition with a mininum build number of 10586, Please use <a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox</a>），</p>

<ul>
<li><a href="https://docs.docker.com/toolbox/toolbox_install_windows/">https://docs.docker.com/toolbox/toolbox_install_windows/</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226#.qvn9h99l4">Tutorial : Getting Started with Kubernetes on your Windows Laptop with Minikube</a></li>
<li><a href="https://blogs.msdn.microsoft.com/wasimbloch/2017/01/23/setting-up-kubernetes-on-windows10-laptop-with-minikube/">Setting up Kubernetes on Windows10 Laptop with Minikube use Hyper-V</a></li>
</ul>


<p>如果直接全部安装toolbox的VirtualBox、git的应该一切顺利的。由于已有cygwin，想着复用下结果惹了一身骚。</p>

<p>按照自己的安装过程，先介绍下配合cygwin安装docker，然后再介绍全部按官网的工具安装k8s。</p>

<h2>仅尝试Docker，不安装k8s</h2>

<p>但是不想安装git直接使用cygwin来代替。刚刚开始的时刻出现了一些理解上的偏差，后来查询start.sh脚本后大概了解到快捷方式、脚本内容后问题就迎刃而解。</p>

<p>先安装docker toolbox：先禁用windows的Hyper-V；安装时去掉git组件。</p>

<p>安装完成后，启动cygwin的命令行（不要用Docker的快捷图标启动）。然后进行如下配置：</p>

<pre><code>winse@Lenovo-PC ~
$ cd "C:\Program Files\Docker Toolbox"

做一个c盘的映射
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ ll /
...
lrwxrwxrwx   1 winse None               11 Apr  5  2016 c -&gt; /cygdrive/c
...

根据cygwin的路径配置VirtualBox的路径
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ export VBOX_MSI_INSTALL_PATH="/cygdrive/c/Program Files/Oracle/VirtualBox/"

首先下载boot2docker.iso到 C:\Users\winse\.docker\machine\cache\boot2docker.iso
https://github.com/boot2docker/boot2docker/releases/download/v1.13.0/boot2docker.iso...

创建一个空的clear脚本（cygwin没有包括clear脚本）
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ touch ~/bin/clear &amp;&amp; chmod +x ~/bin/clear

# 启动
winse@Lenovo-PC /cygdrive/c/Program Files/Docker Toolbox
$ ./start.sh


                        ##         .
                  ## ## ##        ==
               ## ## ## ## ##    ===
           /"""""""""""""""""\___/ ===
      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~
           \______ o           __/
             \    \         __/
              \____\_______/

docker is configured to use the default machine with IP 192.168.99.100
For help getting started, check out the docs at https://docs.docker.com

Start interactive shell

winse@Lenovo-PC ~
$ docker run hello-world
time="2017-02-08T22:48:33+08:00" level=warning msg="Unable to use system certificate pool: crypto/x509: system root pool is not available on Windows"
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
78445dd45222: Pulling fs layer
78445dd45222: Verifying Checksum
78445dd45222: Download complete
78445dd45222: Pull complete
Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://cloud.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/engine/userguide/
</code></pre>

<h2>使用默认安装，并安装k8s</h2>

<p>由于cygwin的路径与windows的不兼容，而git bash则本身依托于windows的命令行的，兼容性方面更优。</p>

<p>重新安装Docker ToolBox，安装时选择git。</p>

<p>下载minikube需要的一些软件：</p>

<ul>
<li><a href="https://github.com/kubernetes/minikube/releases">minikube.exe</a></li>
<li><a href="https://github.com/kubernetes/minikube/blob/v0.16.0/README.md">minikube文档</a></li>
<li><a href="https://storage.googleapis.com/kubernetes-release/release/v1.5.2/bin/windows/amd64/kubectl.exe">kubectl.exe</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226#.pg14q9wst">Tutorial : Getting Started with Kubernetes on your Windows Laptop with Minikube</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/">Hello Minikube On OS X</a></li>
<li><a href="https://kubernetes.io/docs/getting-started-guides/minikube/">Running Kubernetes Locally via Minikube</a></li>
</ul>


<p>下载minikube和kubectl放到PATH路径下（bin目录已经在PATH中）：</p>

<pre><code>E:\local\bin&gt;dir
...
2017-02-08  14:05        50,735,616 kubectl.exe
2017-02-08  11:22        84,239,872 minikube-windows-amd64.exe
2017-02-08  11:25    &lt;SYMLINK&gt;      minikube.exe [minikube-windows-amd64.exe] （mklink minikube.exe minikube-windows-amd64.exe）
</code></pre>

<p>运行 <strong>Docker Quickstart Terminal</strong> (这个快捷方式会先启动docker的虚拟机)，或者直接打开 C:\Program Files\Git\bin\bash.exe 执行如下命令：</p>

<pre><code>查看帮助
winse@Lenovo-PC MINGW64 ~
$ minikube start --help
Starts a local kubernetes cluster using Virtualbox. This command
assumes you already have Virtualbox installed.
...

设置代理: 老外的教程都很简单就成功，但是我们操作一堆问题，主要就是万恶的防火墙！！！
winse@Lenovo-PC MINGW64 ~
$ export HTTPS_PROXY=http://localhost:8118
$ export HTTP_PROXY=http://localhost:8118
$ export NO_PROXY="192.168.0.0/16"

启动
winse@Lenovo-PC MINGW64 ~
$ minikube start --v=7 --logtostderr

winse@Lenovo-PC MINGW64 ~
$ minikube status
minikubeVM: Running
localkube: Running

winse@Lenovo-PC MINGW64 ~
$ kubectl get nodes
NAME       STATUS    AGE
minikube   Ready     3h
</code></pre>

<h4>再次启动，添加代理参数后dashboard才正常运行</h4>

<ul>
<li><a href="https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/">https://kubernetes.io/docs/tutorials/stateless-application/hello-minikube/</a></li>
<li><a href="https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226">https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226</a></li>
</ul>


<pre><code>winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ minikube start --docker-env HTTP_PROXY=http://192.168.99.1:8118 --docker-env HTTPS_PROXY=http://192.168.99.1:8118
Starting local Kubernetes cluster...
Kubectl is now configured to use the cluster.

winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ minikube status
minikubeVM: Running
localkube: Running

winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ kubectl cluster-info
Kubernetes master is running at https://192.168.99.100:8443
KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns
kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

#open dashboard
https://github.com/kubernetes/minikube/issues/379
https://github.com/kubernetes/minikube/issues/522
winse@Lenovo-PC MINGW64 /c/Program Files/Git/bin
$ minikube dashboard
Opening kubernetes dashboard in default browser...

运行实例
winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl get nodes
NAME       STATUS    AGE
minikube   Ready     8h

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl run hello-nginx --image=nginx --port=80
deployment "hello-nginx" created

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get pods
NAME                           READY     STATUS              RESTARTS   AGE
hello-nginx-2471083592-cgn29   0/1       ContainerCreating   0          19s

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get pods
NAME                           READY     STATUS             RESTARTS   AGE
hello-nginx-2471083592-cgn29   0/1       ImagePullBackOff   0          3m

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe describe pod hello-nginx-2471083592-cgn29

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe expose deployment hello-nginx --type=NodePort
service "hello-nginx" exposed

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get services
NAME          CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE
hello-nginx   10.0.0.145   &lt;nodes&gt;       80:31570/TCP   1m
kubernetes    10.0.0.1     &lt;none&gt;        443/TCP        9h

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe describe service hello-nginx
Name:                   hello-nginx
Namespace:              default
Labels:                 run=hello-nginx
Selector:               run=hello-nginx
Type:                   NodePort
IP:                     10.0.0.145
Port:                   &lt;unset&gt; 80/TCP
NodePort:               &lt;unset&gt; 31570/TCP
Endpoints:              172.17.0.4:80
Session Affinity:       None
No events.

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ minikube service --url=true hello-nginx
http://192.168.99.100:31570

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe logs hello-nginx-2471083592-cgn29
172.17.0.1 - - [10/Feb/2017:02:07:53 +0000] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36" "-"
172.17.0.1 - - [10/Feb/2017:02:07:54 +0000] "GET /favicon.ico HTTP/1.1" 404 571 "http://192.168.99.100:31570/" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36" "-"
2017/02/10 02:07:54 [error] 6#6: *1 open() "/usr/share/nginx/html/favicon.ico" failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: "GET /favicon.ico HTTP/1.1", host: "192.168.99.100:31570", referrer: "http://192.168.99.100:31570/"

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe scale --replicas=3 deployment/hello-nginx
deployment "hello-nginx" scaled

winse@Lenovo-PC MINGW64 /e/local/home/k8s
$ kubectl.exe get deployment
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
hello-nginx   3         3         3            1           21m
</code></pre>

<p>暂时还不清楚负载均衡是怎么弄的。这个三个应用pods其实是在一个内网（172.17.0.4/5/6），对外有一个服务（10.0.0.145）。</p>

<p>基本的安装过程先记录这么多。</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker代理配置以及导入导出]]></title>
    <link href="http://winseliu.com/blog/2017/02/06/docker-http-proxy-and-save-reload/"/>
    <updated>2017-02-06T08:40:09+08:00</updated>
    <id>http://winseliu.com/blog/2017/02/06/docker-http-proxy-and-save-reload</id>
    <content type="html"><![CDATA[<h2>代理</h2>

<p>关于http代理服务器的搭建，如果有外（国）网机器，直接用squid建就行了 <a href="http://dockone.io/article/1380">使用Squid3搭建Docker镜像下载代理</a> 。如果已有shadowsocks的代理，可以用privoxy转成http代理服务器。</p>

<ul>
<li>网上参考</li>
</ul>


<p><a href="http://nknu.net/proxy-configuration-for-docker-on-centos-7/">http://nknu.net/proxy-configuration-for-docker-on-centos-7/</a></p>

<pre><code>Edit /etc/sysconfig/docker and add the following lines:
HTTP_PROXY='http://user:password@proxy-host:proxy-port'
HTTPS_PROXY='http://user:password@proxy-host:proxy-port'

For those settings to be taken into account, you’ll need to restart your docker daemon:
# systemctl restart docker
</code></pre>

<ul>
<li>官网文档</li>
</ul>


<p><a href="https://docs.docker.com/engine/admin/systemd/#http-proxy">https://docs.docker.com/engine/admin/systemd/#http-proxy</a></p>

<pre><code>[root@k8s docker.service.d]# pwd
/etc/systemd/system/docker.service.d
[root@k8s docker.service.d]# cat http-proxy.conf 
[Service]
Environment="HTTP_PROXY=http://127.0.0.1:8118/"

查看配置的环境变量是否生效
$ sudo systemctl show --property Environment docker

配置代理后下载google容器杠杠的
[root@k8s docker-multinode]# docker pull gcr.io/google_containers/etcd-amd64:3.0.4
</code></pre>

<p>如果是自己编译的docker，自启动配置可以参考：<a href="https://github.com/docker/docker/blob/master/contrib/init/systemd/docker.socket">https://github.com/docker/docker/blob/master/contrib/init/systemd/docker.socket</a></p>

<h2>导入导出</h2>

<p><a href="https://tuhrig.de/difference-between-save-and-export-in-docker/">https://tuhrig.de/difference-between-save-and-export-in-docker/</a></p>

<p>对于已经通过代理下载的docker，可以通过导入导出到另外的机器。</p>

<pre><code>[root@k8s ~]# docker save `docker images | grep -v TAG | awk '{print $1}'` &gt;k8s.tar

[root@k8s data]# docker load &lt;k8s.tar
0341ae9b0004: Loading layer [==================================================&gt;]  89.1 MB/89.1 MB
Loaded image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.5.0
011b303988d2: Loading layer [==================================================&gt;]  5.05 MB/5.05 MB
5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
596242791254: Loading layer [==================================================&gt;] 792.1 kB/792.1 kB
4e504f64df23: Loading layer [==================================================&gt;]  5.29 MB/5.29 MB
2897536d1f1f: Loading layer [==================================================&gt;] 3.584 kB/3.584 kB
ae11e34e71e6: Loading layer [==================================================&gt;] 10.75 kB/10.75 kB
81620de5436f: Loading layer [==================================================&gt;]  2.56 kB/2.56 kB
77cb0f2fbaed: Loading layer [==================================================&gt;] 50.33 MB/50.33 MB
Loaded image: gcr.io/google_containers/kube-addon-manager-amd64:v6.1
9007f5987db3: Loading layer [==================================================&gt;]  5.05 MB/5.05 MB
5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
d41159f2130e: Loading layer [==================================================&gt;] 9.201 MB/9.201 MB
Loaded image: gcr.io/google_containers/dnsmasq-metrics-amd64:1.0
2c84284818d1: Loading layer [==================================================&gt;] 1.312 MB/1.312 MB
5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
5e47621858b3: Loading layer [==================================================&gt;] 38.51 MB/38.51 MB
Loaded image: gcr.io/google_containers/etcd-amd64:3.0.4
b6ca02dfe5e6: Loading layer [==================================================&gt;] 128.9 MB/128.9 MB
c2c974a0ae12: Loading layer [==================================================&gt;] 231.6 MB/231.6 MB
88e4c6b7e766: Loading layer [==================================================&gt;] 25.09 kB/25.09 kB
96257390754d: Loading layer [==================================================&gt;] 10.75 kB/10.75 kB
36bd77066b3a: Loading layer [==================================================&gt;]  7.68 kB/7.68 kB
6e833518b289: Loading layer [==================================================&gt;] 28.16 kB/28.16 kB
88d2c1399894: Loading layer [==================================================&gt;] 11.78 kB/11.78 kB
b857f858f4ad: Loading layer [==================================================&gt;] 46.08 kB/46.08 kB
13da16246a77: Loading layer [==================================================&gt;] 56.58 MB/56.58 MB
98a8cc89f2d0: Loading layer [==================================================&gt;] 4.608 kB/4.608 kB
1b7eeaac3364: Loading layer [==================================================&gt;]  5.12 kB/5.12 kB
c85758bfcfdf: Loading layer [==================================================&gt;] 153.9 MB/153.9 MB
Loaded image: gcr.io/google_containers/hyperkube-amd64:v1.5.2
3fc666989c1d: Loading layer [==================================================&gt;] 5.046 MB/5.046 MB
5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
9eed5e14d7fb: Loading layer [==================================================&gt;] 348.7 kB/348.7 kB
00dc4ffe8624: Loading layer [==================================================&gt;]  2.56 kB/2.56 kB
Loaded image: gcr.io/google_containers/kube-dnsmasq-amd64:1.4
8ac8bfaff55a: Loading layer [==================================================&gt;] 1.293 MB/1.293 MB
5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
dc978cfc3e09: Loading layer [==================================================&gt;] 7.279 MB/7.279 MB
99740866972b: Loading layer [==================================================&gt;] 7.168 kB/7.168 kB
Loaded image: gcr.io/google_containers/exechealthz-amd64:1.2
5f70bf18a086: Loading layer [==================================================&gt;] 1.024 kB/1.024 kB
41ff149e94f2: Loading layer [==================================================&gt;] 748.5 kB/748.5 kB
Loaded image: gcr.io/google_containers/pause-amd64:3.0
b79219965469: Loading layer [==================================================&gt;] 45.91 MB/45.91 MB
Loaded image: gcr.io/google_containers/kubedns-amd64:1.9
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Privoxy把shadowsocks转换为Http代理]]></title>
    <link href="http://winseliu.com/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks/"/>
    <updated>2017-02-04T15:36:08+08:00</updated>
    <id>http://winseliu.com/blog/2017/02/04/privoxy-http-proxy-for-shadowsocks</id>
    <content type="html"><![CDATA[<p><a href="https://program-think.blogspot.com/2014/12/gfw-privoxy.html">https://program-think.blogspot.com/2014/12/gfw-privoxy.html</a></p>

<p>Privoxy是一个代理辅助工具，这里用Privoxy把Shadowsocks socks5代理转换为http代理。</p>

<p>kubernetes的docker容器需要访问google的服务，docker暂时只支持http代理，而我手上有的代理是 <a href="http://99ss.in">shadowsocks</a> 的。这里通过Privoxy把socks5转成http代理。</p>

<h2>安装Shadowsocks</h2>

<ul>
<li><a href="http://blog.lxx1.com/1420">http://blog.lxx1.com/1420</a></li>
<li><a href="https://shadowsocks.org/en/download/clients.html">https://shadowsocks.org/en/download/clients.html</a></li>
</ul>


<pre><code>[root@k8s ~]# yum install epel-release
[root@k8s ~]# yum install python-pip

[root@k8s ~]# pip install shadowsocks
Collecting shadowsocks
  Downloading shadowsocks-2.8.2.tar.gz
Installing collected packages: shadowsocks
  Running setup.py install for shadowsocks ... done
Successfully installed shadowsocks-2.8.2
You are using pip version 8.1.2, however version 9.0.1 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.

上面软件已经安装好了, 推荐更新下pip.
[root@k8s ~]# pip install --upgrade pip
Collecting pip
  Downloading pip-9.0.1-py2.py3-none-any.whl (1.3MB)
    100% |████████████████████████████████| 1.3MB 46kB/s 
Installing collected packages: pip
  Found existing installation: pip 8.1.2
    Uninstalling pip-8.1.2:
      Successfully uninstalled pip-8.1.2
Successfully installed pip-9.0.1
</code></pre>

<p>填写shadowsocks服务端信息以及本地映射端口，启动客户端</p>

<pre><code>[root@k8s ~]# cat /etc/shadowsocks.json 
{
"server": "xxxxxx",
"server_port": xxx,
"local_port": 1080,
"password": "xxxxxxxx",
"timeout": 600,
"method": "rc4-md5",
"fast_open": false,
"workers": 1
}
[root@k8s ~]# sslocal -c /etc/shadowsocks.json 
</code></pre>

<p></p>

<p>配置防火墙，如果其他主机也需要用这个代理的话</p>

<p><a href="https://havee.me/linux/2015-01/using-firewalls-on-centos-7.html">https://havee.me/linux/2015-01/using-firewalls-on-centos-7.html</a></p>

<pre><code>[root@bigdata-dev ~]# firewall-cmd --zone=public --add-port=1080/tcp --permanent
[root@bigdata-dev ~]# firewall-cmd --reload
</code></pre>

<h2>安装privoxy</h2>

<ul>
<li><a href="https://www.privoxy.org/sf-download-mirror/Win32/3.0.26%20%28stable%29/">windows版本下载地址</a></li>
<li><a href="http://www.ttlsa.com/linux/privoxy-convert-socks-proxy-to-http/">http://www.ttlsa.com/linux/privoxy-convert-socks-proxy-to-http/</a></li>
<li><a href="https://blog.phpgao.com/privoxy-shadowsocks.html">https://blog.phpgao.com/privoxy-shadowsocks.html</a></li>
</ul>


<pre><code>[root@k8s ~]# yum install privoxy -y

查找listen-address行注释掉，在最后添加如下两行
[root@k8s docker.service.d]# cat /etc/privoxy/config 
...
forward-socks5 / 127.0.0.1:1080 .
listen-address k8s:8118

# 启动
[root@k8s ~]# systemctl start privoxy
# 查看状态
[root@k8s ~]# systemctl status privoxy

[root@k8s ~]# systemctl enable privoxy
Created symlink from /etc/systemd/system/multi-user.target.wants/privoxy.service to /usr/lib/systemd/system/privoxy.service.

如果其他机器需要用到代理的话，需要配置防火墙开放端口
[root@k8s ~]# firewall-cmd --zone=public --add-port=8118/tcp --permanent
[root@k8s ~]# firewall-cmd --reload 
</code></pre>

<p>在本机调试会方便点，安装桌面环境</p>

<p><a href="http://unix.stackexchange.com/questions/181503/how-to-install-desktop-environments-on-centos-7">http://unix.stackexchange.com/questions/181503/how-to-install-desktop-environments-on-centos-7</a></p>

<pre><code>yum -y groups install "GNOME Desktop" 
</code></pre>

<p>然后firefox安装autoproxy，配置http代理。（firefox自带的代理有点抽风，不太好用）</p>

<p>或者通过curl加代理参数：</p>

<p>```
[root@k8s ~]# curl google.com
curl: (7) Failed to connect to 2404:6800:4008:802::200e: Network is unreachable
[root@k8s ~]#
[root@k8s ~]# curl -x localhost:8118 google.com
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>301 Moved</TITLE></HEAD><BODY></p>

<H1>301 Moved</H1>


<p>The document has moved
<A HREF="http://www.google.com/">here</A>.
</BODY></HTML>
```</p>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VMware-Centos6 Build hadoop-2.6]]></title>
    <link href="http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6/"/>
    <updated>2015-03-08T08:22:14+08:00</updated>
    <id>http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6</id>
    <content type="html"><![CDATA[<p>每次编译hadoop（-common）都是惊心动魄，没一次顺顺当当的！由于作者的偷懒(vmware共享windows目录)，引发的又一起血案~~~</p>

<p>同时，有时生产环境不是自己能选择的，需要适应各种环境来编译相应的hadoop，此时在已有的linux开发环境使用docker搭建各种linux及其方便的事情。这里在centos6上搭建docker-centos5实例来编译hadoop。</p>

<h2>环境说明</h2>

<ul>
<li>操作系统</li>
</ul>


<pre><code>[root@localhost ~]# uname -a
Linux localhost.localdomain 2.6.32-431.el6.x86_64 #1 SMP Fri Nov 22 03:15:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
[root@localhost ~]# cat /etc/redhat-release 
CentOS release 6.5 (Final)
</code></pre>

<ul>
<li>使用VMware的<strong>Shared Folders</strong>建立了maven和hadoop-2.6.0-src到宿主机器的映射：(不要直接在源码映射的目录下编译，先拷贝到linux的硬盘下！！)</li>
</ul>


<pre><code>[root@localhost ~]# ll -a hadoop-2.6.0-src maven
lrwxrwxrwx. 1 root root 26 Mar  7 22:47 hadoop-2.6.0-src -&gt; /mnt/hgfs/hadoop-2.6.0-src
lrwxrwxrwx. 1 root root 15 Mar  7 22:47 maven -&gt; /mnt/hgfs/maven
</code></pre>

<h2>具体操作</h2>

<pre><code># 安装maven，jdk
cat apache-maven-3.2.3-bin.tar.gz | ssh root@192.168.154.130 "cat - | tar zxv "

tar zxvf jdk-7u60-linux-x64.gz -C ~/
vi .bash_profile 

# 开发环境
yum install gcc glibc-headers gcc-c++ zlib-devel
yum install openssl-devel

# 安装protobuf
tar zxvf protobuf-2.5.0.tar.gz 
cd protobuf-2.5.0
./configure 
make &amp;&amp; make install

## 编译hadoop-common
# 从映射文件中拷贝hadoop-common到linux文件系统，然后在编译hadoop-common
cd hadoop-2.6.0-src/hadoop-common-project/hadoop-common/
cd ..
cp -r  hadoop-common ~/  #Q:为啥要拷贝一份，【遇到的问题】中有进行解析
cd ~/hadoop-common
mvn install
mvn -X clean package -Pdist,native -Dmaven.test.skip=true -Dmaven.javadoc.skip=true

## 编译全部，耗时比较久，可以先去吃个饭^v^
cp -r /mnt/hgfs/hadoop-2.6.0-src ~/
mvn package -Pdist,native -DskipTests -Dmaven.javadoc.skip=true #Q:这里为啥不能用maven.test.skip?
</code></pre>

<p>$$TAG centos5 20160402</p>

<ul>
<li>docker build hadoop-2.6.3(比自己搞个虚拟机更快)</li>
</ul>


<p>实际生产需要使用centos5，这里在centos5编译。其他下载<a href="https://github.com/CentOS/sig-cloud-instance-images">Centos</a>特定版本，步骤是一样的。</p>

<pre><code>[hadoop@cu2 ~]$ cat /etc/redhat-release 
CentOS release 6.6 (Final)

[root@cu2 shm]# unzip sig-cloud-instance-images-centos-5.zip 
[root@cu2 shm]# cd sig-cloud-instance-images-c8d1a81b0516bca0f20434be8d0fac4f7d58a04a/docker/
[root@cu2 docker]# cat centos-5-20150304_1234-docker.tar.xz | docker import - centos:centos5
[root@cu2 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
centos              centos5             a3f6a632c5ec        27 seconds ago      284.1 MB

# 把本机原有资源利用起来，如：maven/repo/jdk/hadoop等
[root@cu2 ~]# docker run -ti -v /home/hadoop:/home/hadoop -v /opt:/opt -v /data:/data centos:centos5 /bin/bash

export JAVA_HOME=/opt/jdk1.7.0_17
export MAVEN_HOME=/opt/apache-maven-3.3.9
export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH

yum install lrzsz zlib-devel make which gcc gcc-c++ cmake openssl openssl-devel -y

cd protobuf-2.5.0
./configure 
make &amp;&amp; make install
which protoc

cd hadoop-2.6.3-src/
mvn clean package -Dmaven.javadoc.skip=true -DskipTests -Pdist,native 

cd hadoop-dist/target/hadoop-2.6.3/lib/native/
cd ..
tar zcvf native-hadoop2.6.3-centos5.tar.gz native

----

在centos5编译snappy-1.1.3死都过不去，**Makefile.am:4: Libtool library used but `LIBTOOL' is undefined** 
网上资料都差了，最后直接用centos6编译好的snappy可以。哎，有的用就好。

[root@8fb11f6b3ced hadoop-2.6.3-src]# mvn package -Dmaven.javadoc.skip=true -DskipTests -Pdist,native  -Drequire.snappy=true  -Dsnappy.prefix=/home/hadoop/snappy
[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-dist/target/hadoop-2.6.3/
[root@8fb11f6b3ced hadoop-2.6.3]# pwd
/home/hadoop/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3
[root@8fb11f6b3ced hadoop-2.6.3]# cd lib/native/
[root@8fb11f6b3ced native]# tar zxvf /home/hadoop/snappy/snappy-libs.tar.gz 

[root@8fb11f6b3ced native]# cd /home/hadoop/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3
[root@8fb11f6b3ced hadoop-2.6.3]# bin/hadoop checknative -a

# 打包到正式环境
[root@8fb11f6b3ced hadoop-2.6.3]# cd lib/
[root@8fb11f6b3ced lib]# tar zcvf native-hadoop2.6.3-centos5-with-snappy.tar.gz native
</code></pre>

<p>$$END TAG centos5 20160402</p>

<h2>遇到的问题</h2>

<ul>
<li><p>第一个问题肯定是没有<strong>c</strong>的编译环境，安装gcc即可。</p></li>
<li><p><code>configure: error: C++ preprocessor "/lib/cpp" fails sanity check</code>，安装c++。</p></li>
</ul>


<p>-> <a href="http://www.cnblogs.com/niocai/archive/2011/11/04/2236458.html">configure: error: C++ preprocessor &ldquo;/lib/cpp&rdquo; fails sanity check</a></p>

<ul>
<li><code>Unknown lifecycle phase "c"</code>，点击错误提示最后的链接查看解决方法，即执行<code>mvn install</code>。</li>
</ul>


<p>-> <a href="http://blog.csdn.net/kamemo/article/details/6523992">执行第一maven用例出错：Unknown lifecycle phase &ldquo;complile&rdquo;.</a>
-> <a href="https://cwiki.apache.org/confluence/display/MAVEN/LifecyclePhaseNotFoundException">LifecyclePhaseNotFoundException</a></p>

<ul>
<li><code>CMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:108 (message): Could NOT find ZLIB (missing: ZLIB_INCLUDE_DIR)</code>， 缺少zlib-devel。</li>
</ul>


<p>-> <a href="http://ask.csdn.net/questions/62307">Cmake时报错：Could NOT find ImageMagick</a></p>

<ul>
<li><code>cmake_symlink_library: System Error: Operation not supported</code>， 共享的windows目录下不能创建linux的软链接。</li>
</ul>


<p>-> <a href="http://bbs.chinaunix.net/forum.php?mod=viewthread&amp;tid=3595245&amp;fromuid=26971268">参见9楼回复</a></p>

<blockquote><p>创建链接不成功，要确认当前帐户下是否有权限在编译的目录中有创建链接的权限</p>

<p>比如，你如果是在一个WINDOWS机器上的共享目录中编译，就没法创建链接，就会失败。把源码复制到本地的目录中再编译就不会有这问题。</p></blockquote>

<ul>
<li>全部编译时仅能用skipTests，不能maven.test.skip。</li>
</ul>


<pre><code>main:
     [echo] Running test_libhdfs_threaded
     [exec] nmdCreate: NativeMiniDfsCluster#Builder#Builder error:
     [exec] java.lang.NoClassDefFoundError: org/apache/hadoop/hdfs/MiniDFSCluster$Builder
     [exec] Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hdfs.MiniDFSCluster$Builder
     [exec]     at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
     [exec]     at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
     [exec]     at java.security.AccessController.doPrivileged(Native Method)
     [exec]     at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
     [exec]     at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
     [exec]     at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
     [exec]     at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
     [exec] TEST_ERROR: failed on /root/hadoop-2.6.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/test_libhdfs_threaded.c:326 (errno: 2): got NULL from tlhCluster
</code></pre>

<ul>
<li><code>Could NOT find OpenSSL, try to set the path to OpenSSL root folder in the</code>，安装openssl-devel。</li>
</ul>


<pre><code>main:
    [mkdir] Created dir: /root/hadoop-2.6.0-src/hadoop-tools/hadoop-pipes/target/native
     [exec] -- The C compiler identification is GNU 4.4.7
     [exec] -- The CXX compiler identification is GNU 4.4.7
     [exec] -- Check for working C compiler: /usr/bin/cc
     [exec] -- Check for working C compiler: /usr/bin/cc -- works
     [exec] -- Detecting C compiler ABI info
     [exec] -- Detecting C compiler ABI info - done
     [exec] -- Check for working CXX compiler: /usr/bin/c++
     [exec] -- Check for working CXX compiler: /usr/bin/c++ -- works
     [exec] -- Detecting CXX compiler ABI info
     [exec] -- Detecting CXX compiler ABI info - done
     [exec] -- Configuring incomplete, errors occurred!
     [exec] See also "/root/hadoop-2.6.0-src/hadoop-tools/hadoop-pipes/target/native/CMakeFiles/CMakeOutput.log".
     [exec] CMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:108 (message):
     [exec]   Could NOT find OpenSSL, try to set the path to OpenSSL root folder in the
     [exec]   system variable OPENSSL_ROOT_DIR (missing: OPENSSL_LIBRARIES
     [exec]   OPENSSL_INCLUDE_DIR)
     [exec] Call Stack (most recent call first):
     [exec]   /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:315 (_FPHSA_FAILURE_MESSAGE)
     [exec]   /usr/share/cmake/Modules/FindOpenSSL.cmake:313 (find_package_handle_standard_args)
     [exec]   CMakeLists.txt:20 (find_package)
     [exec] 
     [exec] 
</code></pre>

<h2>成功</h2>

<pre><code>[INFO] Executed tasks
[INFO] 
[INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---
[INFO] Skipping javadoc generation
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Apache Hadoop Main ................................. SUCCESS [ 43.005 s]
[INFO] Apache Hadoop Project POM .......................... SUCCESS [ 25.511 s]
[INFO] Apache Hadoop Annotations .......................... SUCCESS [ 21.177 s]
[INFO] Apache Hadoop Assemblies ........................... SUCCESS [ 11.728 s]
[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [ 51.274 s]
[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 35.625 s]
[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [ 21.936 s]
[INFO] Apache Hadoop Auth ................................. SUCCESS [ 24.665 s]
[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 17.058 s]
[INFO] Apache Hadoop Common ............................... SUCCESS [06:07 min]
[INFO] Apache Hadoop NFS .................................. SUCCESS [ 41.279 s]
[INFO] Apache Hadoop KMS .................................. SUCCESS [ 59.186 s]
[INFO] Apache Hadoop Common Project ....................... SUCCESS [  7.216 s]
[INFO] Apache Hadoop HDFS ................................. SUCCESS [04:29 min]
[INFO] Apache Hadoop HttpFS ............................... SUCCESS [ 52.883 s]
[INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 28.972 s]
[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [ 24.901 s]
[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  7.486 s]
[INFO] hadoop-yarn ........................................ SUCCESS [  7.466 s]
[INFO] hadoop-yarn-api .................................... SUCCESS [ 32.970 s]
[INFO] hadoop-yarn-common ................................. SUCCESS [ 25.549 s]
[INFO] hadoop-yarn-server ................................. SUCCESS [  6.709 s]
[INFO] hadoop-yarn-server-common .......................... SUCCESS [ 25.292 s]
[INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 29.555 s]
[INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [ 12.800 s]
[INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [ 14.025 s]
[INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 21.121 s]
[INFO] hadoop-yarn-server-tests ........................... SUCCESS [ 24.019 s]
[INFO] hadoop-yarn-client ................................. SUCCESS [ 18.949 s]
[INFO] hadoop-yarn-applications ........................... SUCCESS [  7.586 s]
[INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  8.428 s]
[INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [ 12.671 s]
[INFO] hadoop-yarn-site ................................... SUCCESS [  7.518 s]
[INFO] hadoop-yarn-registry ............................... SUCCESS [ 18.518 s]
[INFO] hadoop-yarn-project ................................ SUCCESS [ 38.781 s]
[INFO] hadoop-mapreduce-client ............................ SUCCESS [ 13.133 s]
[INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 23.772 s]
[INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 22.815 s]
[INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [ 16.810 s]
[INFO] hadoop-mapreduce-client-app ........................ SUCCESS [ 14.404 s]
[INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [ 18.157 s]
[INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 14.637 s]
[INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  9.190 s]
[INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  9.037 s]
[INFO] hadoop-mapreduce ................................... SUCCESS [ 59.280 s]
[INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [ 26.724 s]
[INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 31.503 s]
[INFO] Apache Hadoop Archives ............................. SUCCESS [ 19.867 s]
[INFO] Apache Hadoop Rumen ................................ SUCCESS [ 27.401 s]
[INFO] Apache Hadoop Gridmix .............................. SUCCESS [ 20.102 s]
[INFO] Apache Hadoop Data Join ............................ SUCCESS [ 20.382 s]
[INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [ 12.207 s]
[INFO] Apache Hadoop Extras ............................... SUCCESS [ 24.069 s]
[INFO] Apache Hadoop Pipes ................................ SUCCESS [ 31.975 s]
[INFO] Apache Hadoop OpenStack support .................... SUCCESS [ 32.225 s]
[INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [02:45 min]
[INFO] Apache Hadoop Client ............................... SUCCESS [01:38 min]
[INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [ 15.450 s]
[INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [ 46.489 s]
[INFO] Apache Hadoop Tools Dist ........................... SUCCESS [01:31 min]
[INFO] Apache Hadoop Tools ................................ SUCCESS [  7.603 s]
[INFO] Apache Hadoop Distribution ......................... SUCCESS [ 32.967 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 39:30 min
[INFO] Finished at: 2015-03-08T10:55:47+08:00
[INFO] Final Memory: 102M/340M
[INFO] ------------------------------------------------------------------------
</code></pre>

<p>把src编译出来的native下面的文件拷贝到hadoop集群程序目录下：</p>

<pre><code>[hadoop@hadoop-master1 lib]$ scp -r root@172.17.42.1:~/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/lib/native ./
[hadoop@hadoop-master1 lib]$ cd native/
[hadoop@hadoop-master1 native]$ ll
total 4356
-rw-r--r--. 1 hadoop hadoop 1119518 Mar  8 03:11 libhadoop.a
-rw-r--r--. 1 hadoop hadoop 1486964 Mar  8 03:11 libhadooppipes.a
lrwxrwxrwx. 1 hadoop hadoop      18 Mar  3 21:08 libhadoop.so -&gt; libhadoop.so.1.0.0
-rwxr-xr-x. 1 hadoop hadoop  671237 Mar  8 03:11 libhadoop.so.1.0.0
-rw-r--r--. 1 hadoop hadoop  581944 Mar  8 03:11 libhadooputils.a
-rw-r--r--. 1 hadoop hadoop  359490 Mar  8 03:11 libhdfs.a
lrwxrwxrwx. 1 hadoop hadoop      16 Mar  3 21:08 libhdfs.so -&gt; libhdfs.so.0.0.0
-rwxr-xr-x. 1 hadoop hadoop  228451 Mar  8 03:11 libhdfs.so.0.0.0
</code></pre>

<p>添加编译的native包前后对比：</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.0]$ hadoop fs -ls /
15/03/08 03:09:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-r--r--   1 hadoop supergroup       1366 2015-03-06 16:49 /README.txt
drwx------   - hadoop supergroup          0 2015-03-06 16:54 /tmp
drwxr-xr-x   - hadoop supergroup          0 2015-03-06 16:54 /user

# 编译好后，警告提示没有了
[hadoop@hadoop-master1 hadoop-2.6.0]$ hadoop fs -ls /
Found 3 items
-rw-r--r--   1 hadoop supergroup       1366 2015-03-06 16:49 /README.txt
drwx------   - hadoop supergroup          0 2015-03-06 16:54 /tmp
drwxr-xr-x   - hadoop supergroup          0 2015-03-06 16:54 /user
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dnsmasq解决docker集群节点互通问题]]></title>
    <link href="http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster/"/>
    <updated>2014-10-18T04:19:21+08:00</updated>
    <id>http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster</id>
    <content type="html"><![CDATA[<p>上个星期学习了一下docker，写了一个<a href="https://github.com/winse/docker-hadoop/tree/Pseudo-Distributed">伪分布式的Dockerfile</a>。</p>

<p>通过<code>--link</code>的方式master能访问slaver，毕竟slaver的相关信息已经被写入到master的hosts文件里面去了嘛！理所当然认为，直接把master的hosts文件全部复制一份到所有slaver节点问题就解决了。</p>

<p>等真正操作的时刻，发现不是那么回事，docker容器不给修改hosts文件！！（2016-1-7 14:18:11 注： Docker 1.6.2已经可以修改/etc/hosts了！重启后hosts的变更也没了，囧）</p>

<h2>错误实现</h2>

<p>首先，看下不当的操作：</p>

<pre><code># 注意：没有填写image，会去找Dockerfile
[root@docker hadoop]# docker run -d --name slaver1 -h slaver1 hadoop
[root@docker hadoop]# docker run -d --name slaver2 -h slaver2 hadoop
[root@docker hadoop]# docker run -d --name master -h master --link slaver1:slaver1 --link slaver2:slaver2 hadoop

[root@docker ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES
dafc82678811        hadoop:latest       /bin/sh -c '/usr/sbi   40 seconds ago      Up 40 seconds       22/tcp              master
86d2da5209c5        hadoop:latest       /bin/sh -c '/usr/sbi   49 seconds ago      Up 48 seconds       22/tcp              master/slaver2,slaver2
7b9761fb05a8        hadoop:latest       /bin/sh -c '/usr/sbi   56 seconds ago      Up 55 seconds       22/tcp              master/slaver1,slaver1
</code></pre>

<p>此时，通过<code>--link</code>连接方式，master的hosts中已经包括了slaver1和slaver2，按照正常的路子，登录master拷贝其hosts到slaver节点，一切就妥妥的了。现实是残酷的：</p>

<pre><code>-bash-4.1# scp /etc/hosts slaver1:/etc/
scp: /etc//hosts: Read-only file system
</code></pre>

<h2>DNS完美解决问题</h2>

<p>首先需要在宿主机器上安装dns服务器，bind不多说比较麻烦。这里参考网上人家解决方式，使用dnsmasq来搭建DNS服务器。</p>

<pre><code>[root@docker ~]# yum install dnsmasq -y

[root@docker ~]# cp /etc/resolv.conf /etc/resolv.dnsmasq.conf 
[root@docker ~]# touch /etc/dnsmasq.hosts

[root@docker ~]# vi /etc/resolv.conf
[root@docker ~]# cat /etc/resolv.conf
; generated by /sbin/dhclient-script
nameserver 127.0.0.1 

[root@docker ~]# vi /etc/dnsmasq.conf
[root@docker ~]# cat /etc/dnsmasq.conf
...
resolv-file=/etc/resolv.dnsmasq.conf
...
addn-hosts=/etc/dnsmasq.hosts

[root@docker ~]# service dnsmasq restart

[root@docker ~]# dig www.baidu.com
...
;; SERVER: 127.0.0.1#53(127.0.0.1)
...
</code></pre>

<p>通过dig可以查看当前的DNS服务器你已经修改为localhost了。然后启动docker容器来搭建环境。</p>

<pre><code># 注意：没有填写image，会去找Dockerfile

[root@docker hadoop]# docker run -d  --dns 172.17.42.1 --name slaver1 -h slaver1 hadoop
[root@docker hadoop]# docker run -d  --dns 172.17.42.1 --name slaver2 -h slaver2 hadoop
[root@docker hadoop]# docker run -d  --dns 172.17.42.1 --name master -h master hadoop

[root@docker ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES
f6e63b311e60        hadoop:latest       /bin/sh -c '/usr/sbi   6 seconds ago       Up 5 seconds        22/tcp              master
454ae2c3e435        hadoop:latest       /bin/sh -c '/usr/sbi   13 seconds ago      Up 12 seconds       22/tcp              slaver2
7698230a03fb        hadoop:latest       /bin/sh -c '/usr/sbi   21 seconds ago      Up 20 seconds       22/tcp              slaver1

[root@docker ~]# docker ps | grep hadoop | awk '{print $1}' | xargs -I{} docker inspect -f '{{.NetworkSettings.IPAddress}} {{.Config.Hostname}}' {} &gt; /etc/dnsmasq.hosts
[root@docker ~]# service dnsmasq restart

[root@docker ~]# ssh hadoop@master
hadoop@master's password: 
[hadoop@master ~]$ ping slaver1
PING slaver1 (172.17.0.9) 56(84) bytes of data.
64 bytes from slaver1 (172.17.0.9): icmp_seq=1 ttl=64 time=1.79 ms
...
[hadoop@master ~]$ ping slaver2
PING slaver2 (172.17.0.10) 56(84) bytes of data.
64 bytes from slaver2 (172.17.0.10): icmp_seq=1 ttl=64 time=1.96 ms
...


</code></pre>

<p>节点互通后，后面的步骤都类似了，ssh无密钥通信，格式化namenode，启动等等。</p>

<h2>遇到的问题</h2>

<ul>
<li>一开始我把配置文件放在/root目录下，dnsmasq总是不起作用。最后放到/etc目录就可以，不知道啥子问题。</li>
<li>配置dns启动docker容器后，如果不起作用看下<code>/etc/resolv.conf</code>。如果互ping不同，去掉resolv的<code>search localhost</code>再试下。</li>
</ul>


<p>DNS可以正常工作的配置：</p>

<pre><code>-bash-4.1# ping slaver
PING slaver (172.17.0.7) 56(84) bytes of data.
64 bytes from slaver (172.17.0.7): icmp_seq=1 ttl=64 time=0.095 ms

-bash-4.1# cat /etc/resolv.conf 
nameserver 172.17.42.1
search localdomain

-bash-4.1# cat /etc/resolv.conf 
nameserver 172.17.42.1
</code></pre>

<p>如果还是不行的话，关掉防火墙然后重启下docker服务: <code>service iptables stop; service docker restart</code></p>

<p>如果要访问外网，也可以条件其他的DNS服务解析：</p>

<pre><code>-bash-4.1# vi /etc/resolv.conf 
nameserver 172.17.42.1
nameserver 8.8.8.8
</code></pre>

<h2>常用命令</h2>

<pre><code>~]# docker run -d --dns 172.17.42.1 --name puppet -h puppet winse/hadoop:2.6.0 /usr/sbin/sshd -D
~]# docker inspect `docker ps -a | grep centos | awk '{print $1}'` | grep IPAddress
~]# docker stop `docker ps -a | grep centos | awk '{print $1}'`
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://top.jobbole.com/7904/">DNS和Docker的小技巧</a></li>
<li><a href="http://www.07net01.com/linux/zuixindnsmasqanzhuangbushuxiangjie_centos6__653221_1381214991.html">dnsmasq安装部署详解-centos6</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
