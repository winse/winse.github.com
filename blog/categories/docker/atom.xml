<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Winse Blog]]></title>
  <link href="http://winseliu.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://winseliu.com/"/>
  <updated>2016-10-27T08:50:42+08:00</updated>
  <id>http://winseliu.com/</id>
  <author>
    <name><![CDATA[Winse Liu]]></name>
    <email><![CDATA[winseliu@foxmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[VMware-Centos6 Build hadoop-2.6]]></title>
    <link href="http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6/"/>
    <updated>2015-03-08T08:22:14+08:00</updated>
    <id>http://winseliu.com/blog/2015/03/08/vmware-build-hadoop2-dot-6</id>
    <content type="html"><![CDATA[<p>每次编译hadoop（-common）都是惊心动魄，没一次顺顺当当的！由于作者的偷懒(vmware共享windows目录)，引发的又一起血案~~~</p>

<p>同时，有时生产环境不是自己能选择的，需要适应各种环境来编译相应的hadoop，此时在已有的linux开发环境使用docker搭建各种linux及其方便的事情。这里在centos6上搭建docker-centos5实例来编译hadoop。</p>

<h2>环境说明</h2>

<ul>
<li>操作系统</li>
</ul>


<pre><code>[root@localhost ~]# uname -a
Linux localhost.localdomain 2.6.32-431.el6.x86_64 #1 SMP Fri Nov 22 03:15:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
[root@localhost ~]# cat /etc/redhat-release 
CentOS release 6.5 (Final)
</code></pre>

<ul>
<li>使用VMware的<strong>Shared Folders</strong>建立了maven和hadoop-2.6.0-src到宿主机器的映射：(不要直接在源码映射的目录下编译，先拷贝到linux的硬盘下！！)</li>
</ul>


<pre><code>[root@localhost ~]# ll -a hadoop-2.6.0-src maven
lrwxrwxrwx. 1 root root 26 Mar  7 22:47 hadoop-2.6.0-src -&gt; /mnt/hgfs/hadoop-2.6.0-src
lrwxrwxrwx. 1 root root 15 Mar  7 22:47 maven -&gt; /mnt/hgfs/maven
</code></pre>

<h2>具体操作</h2>

<pre><code># 安装maven，jdk
cat apache-maven-3.2.3-bin.tar.gz | ssh root@192.168.154.130 "cat - | tar zxv "

tar zxvf jdk-7u60-linux-x64.gz -C ~/
vi .bash_profile 

# 开发环境
yum install gcc glibc-headers gcc-c++ zlib-devel
yum install openssl-devel

# 安装protobuf
tar zxvf protobuf-2.5.0.tar.gz 
cd protobuf-2.5.0
./configure 
make &amp;&amp; make install

## 编译hadoop-common
# 从映射文件中拷贝hadoop-common到linux文件系统，然后在编译hadoop-common
cd hadoop-2.6.0-src/hadoop-common-project/hadoop-common/
cd ..
cp -r  hadoop-common ~/  #Q:为啥要拷贝一份，【遇到的问题】中有进行解析
cd ~/hadoop-common
mvn install
mvn -X clean package -Pdist,native -Dmaven.test.skip=true -Dmaven.javadoc.skip=true

## 编译全部，耗时比较久，可以先去吃个饭^v^
cp -r /mnt/hgfs/hadoop-2.6.0-src ~/
mvn package -Pdist,native -DskipTests -Dmaven.javadoc.skip=true #Q:这里为啥不能用maven.test.skip?
</code></pre>

<p>$$TAG centos5 20160402</p>

<ul>
<li>docker build hadoop-2.6.3(比自己搞个虚拟机更快)</li>
</ul>


<p>实际生产需要使用centos5，这里在centos5编译。其他下载<a href="https://github.com/CentOS/sig-cloud-instance-images">Centos</a>特定版本，步骤是一样的。</p>

<pre><code>[hadoop@cu2 ~]$ cat /etc/redhat-release 
CentOS release 6.6 (Final)

[root@cu2 shm]# unzip sig-cloud-instance-images-centos-5.zip 
[root@cu2 shm]# cd sig-cloud-instance-images-c8d1a81b0516bca0f20434be8d0fac4f7d58a04a/docker/
[root@cu2 docker]# cat centos-5-20150304_1234-docker.tar.xz | docker import - centos:centos5
[root@cu2 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
centos              centos5             a3f6a632c5ec        27 seconds ago      284.1 MB

# 把本机原有资源利用起来，如：maven/repo/jdk/hadoop等
[root@cu2 ~]# docker run -ti -v /home/hadoop:/home/hadoop -v /opt:/opt -v /data:/data centos:centos5 /bin/bash

export JAVA_HOME=/opt/jdk1.7.0_17
export MAVEN_HOME=/opt/apache-maven-3.3.9
export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH

yum install lrzsz zlib-devel make which gcc gcc-c++ cmake openssl openssl-devel -y

cd protobuf-2.5.0
./configure 
make &amp;&amp; make install
which protoc

cd hadoop-2.6.3-src/
mvn clean package -Dmaven.javadoc.skip=true -DskipTests -Pdist,native 

cd hadoop-dist/target/hadoop-2.6.3/lib/native/
cd ..
tar zcvf native-hadoop2.6.3-centos5.tar.gz native

----

在centos5编译snappy-1.1.3死都过不去，**Makefile.am:4: Libtool library used but `LIBTOOL' is undefined** 
网上资料都差了，最后直接用centos6编译好的snappy可以。哎，有的用就好。

[root@8fb11f6b3ced hadoop-2.6.3-src]# mvn package -Dmaven.javadoc.skip=true -DskipTests -Pdist,native  -Drequire.snappy=true  -Dsnappy.prefix=/home/hadoop/snappy
[root@8fb11f6b3ced hadoop-2.6.3-src]# cd hadoop-dist/target/hadoop-2.6.3/
[root@8fb11f6b3ced hadoop-2.6.3]# pwd
/home/hadoop/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3
[root@8fb11f6b3ced hadoop-2.6.3]# cd lib/native/
[root@8fb11f6b3ced native]# tar zxvf /home/hadoop/snappy/snappy-libs.tar.gz 

[root@8fb11f6b3ced native]# cd /home/hadoop/sources/hadoop-2.6.3-src/hadoop-dist/target/hadoop-2.6.3
[root@8fb11f6b3ced hadoop-2.6.3]# bin/hadoop checknative -a

# 打包到正式环境
[root@8fb11f6b3ced hadoop-2.6.3]# cd lib/
[root@8fb11f6b3ced lib]# tar zcvf native-hadoop2.6.3-centos5-with-snappy.tar.gz native
</code></pre>

<p>$$END TAG centos5 20160402</p>

<h2>遇到的问题</h2>

<ul>
<li><p>第一个问题肯定是没有<strong>c</strong>的编译环境，安装gcc即可。</p></li>
<li><p><code>configure: error: C++ preprocessor "/lib/cpp" fails sanity check</code>，安装c++。</p></li>
</ul>


<p>-> <a href="http://www.cnblogs.com/niocai/archive/2011/11/04/2236458.html">configure: error: C++ preprocessor &ldquo;/lib/cpp&rdquo; fails sanity check</a></p>

<ul>
<li><code>Unknown lifecycle phase "c"</code>，点击错误提示最后的链接查看解决方法，即执行<code>mvn install</code>。</li>
</ul>


<p>-> <a href="http://blog.csdn.net/kamemo/article/details/6523992">执行第一maven用例出错：Unknown lifecycle phase &ldquo;complile&rdquo;.</a>
-> <a href="https://cwiki.apache.org/confluence/display/MAVEN/LifecyclePhaseNotFoundException">LifecyclePhaseNotFoundException</a></p>

<ul>
<li><code>CMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:108 (message): Could NOT find ZLIB (missing: ZLIB_INCLUDE_DIR)</code>， 缺少zlib-devel。</li>
</ul>


<p>-> <a href="http://ask.csdn.net/questions/62307">Cmake时报错：Could NOT find ImageMagick</a></p>

<ul>
<li><code>cmake_symlink_library: System Error: Operation not supported</code>， 共享的windows目录下不能创建linux的软链接。</li>
</ul>


<p>-> <a href="http://bbs.chinaunix.net/forum.php?mod=viewthread&amp;tid=3595245&amp;fromuid=26971268">参见9楼回复</a></p>

<blockquote><p>创建链接不成功，要确认当前帐户下是否有权限在编译的目录中有创建链接的权限</p>

<p>比如，你如果是在一个WINDOWS机器上的共享目录中编译，就没法创建链接，就会失败。把源码复制到本地的目录中再编译就不会有这问题。</p></blockquote>

<ul>
<li>全部编译时仅能用skipTests，不能maven.test.skip。</li>
</ul>


<pre><code>main:
     [echo] Running test_libhdfs_threaded
     [exec] nmdCreate: NativeMiniDfsCluster#Builder#Builder error:
     [exec] java.lang.NoClassDefFoundError: org/apache/hadoop/hdfs/MiniDFSCluster$Builder
     [exec] Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hdfs.MiniDFSCluster$Builder
     [exec]     at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
     [exec]     at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
     [exec]     at java.security.AccessController.doPrivileged(Native Method)
     [exec]     at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
     [exec]     at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
     [exec]     at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
     [exec]     at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
     [exec] TEST_ERROR: failed on /root/hadoop-2.6.0-src/hadoop-hdfs-project/hadoop-hdfs/src/main/native/libhdfs/test_libhdfs_threaded.c:326 (errno: 2): got NULL from tlhCluster
</code></pre>

<ul>
<li><code>Could NOT find OpenSSL, try to set the path to OpenSSL root folder in the</code>，安装openssl-devel。</li>
</ul>


<pre><code>main:
    [mkdir] Created dir: /root/hadoop-2.6.0-src/hadoop-tools/hadoop-pipes/target/native
     [exec] -- The C compiler identification is GNU 4.4.7
     [exec] -- The CXX compiler identification is GNU 4.4.7
     [exec] -- Check for working C compiler: /usr/bin/cc
     [exec] -- Check for working C compiler: /usr/bin/cc -- works
     [exec] -- Detecting C compiler ABI info
     [exec] -- Detecting C compiler ABI info - done
     [exec] -- Check for working CXX compiler: /usr/bin/c++
     [exec] -- Check for working CXX compiler: /usr/bin/c++ -- works
     [exec] -- Detecting CXX compiler ABI info
     [exec] -- Detecting CXX compiler ABI info - done
     [exec] -- Configuring incomplete, errors occurred!
     [exec] See also "/root/hadoop-2.6.0-src/hadoop-tools/hadoop-pipes/target/native/CMakeFiles/CMakeOutput.log".
     [exec] CMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:108 (message):
     [exec]   Could NOT find OpenSSL, try to set the path to OpenSSL root folder in the
     [exec]   system variable OPENSSL_ROOT_DIR (missing: OPENSSL_LIBRARIES
     [exec]   OPENSSL_INCLUDE_DIR)
     [exec] Call Stack (most recent call first):
     [exec]   /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:315 (_FPHSA_FAILURE_MESSAGE)
     [exec]   /usr/share/cmake/Modules/FindOpenSSL.cmake:313 (find_package_handle_standard_args)
     [exec]   CMakeLists.txt:20 (find_package)
     [exec] 
     [exec] 
</code></pre>

<h2>成功</h2>

<pre><code>[INFO] Executed tasks
[INFO] 
[INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---
[INFO] Skipping javadoc generation
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Apache Hadoop Main ................................. SUCCESS [ 43.005 s]
[INFO] Apache Hadoop Project POM .......................... SUCCESS [ 25.511 s]
[INFO] Apache Hadoop Annotations .......................... SUCCESS [ 21.177 s]
[INFO] Apache Hadoop Assemblies ........................... SUCCESS [ 11.728 s]
[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [ 51.274 s]
[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 35.625 s]
[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [ 21.936 s]
[INFO] Apache Hadoop Auth ................................. SUCCESS [ 24.665 s]
[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 17.058 s]
[INFO] Apache Hadoop Common ............................... SUCCESS [06:07 min]
[INFO] Apache Hadoop NFS .................................. SUCCESS [ 41.279 s]
[INFO] Apache Hadoop KMS .................................. SUCCESS [ 59.186 s]
[INFO] Apache Hadoop Common Project ....................... SUCCESS [  7.216 s]
[INFO] Apache Hadoop HDFS ................................. SUCCESS [04:29 min]
[INFO] Apache Hadoop HttpFS ............................... SUCCESS [ 52.883 s]
[INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 28.972 s]
[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [ 24.901 s]
[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  7.486 s]
[INFO] hadoop-yarn ........................................ SUCCESS [  7.466 s]
[INFO] hadoop-yarn-api .................................... SUCCESS [ 32.970 s]
[INFO] hadoop-yarn-common ................................. SUCCESS [ 25.549 s]
[INFO] hadoop-yarn-server ................................. SUCCESS [  6.709 s]
[INFO] hadoop-yarn-server-common .......................... SUCCESS [ 25.292 s]
[INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 29.555 s]
[INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [ 12.800 s]
[INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [ 14.025 s]
[INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 21.121 s]
[INFO] hadoop-yarn-server-tests ........................... SUCCESS [ 24.019 s]
[INFO] hadoop-yarn-client ................................. SUCCESS [ 18.949 s]
[INFO] hadoop-yarn-applications ........................... SUCCESS [  7.586 s]
[INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  8.428 s]
[INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [ 12.671 s]
[INFO] hadoop-yarn-site ................................... SUCCESS [  7.518 s]
[INFO] hadoop-yarn-registry ............................... SUCCESS [ 18.518 s]
[INFO] hadoop-yarn-project ................................ SUCCESS [ 38.781 s]
[INFO] hadoop-mapreduce-client ............................ SUCCESS [ 13.133 s]
[INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 23.772 s]
[INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 22.815 s]
[INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [ 16.810 s]
[INFO] hadoop-mapreduce-client-app ........................ SUCCESS [ 14.404 s]
[INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [ 18.157 s]
[INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 14.637 s]
[INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  9.190 s]
[INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  9.037 s]
[INFO] hadoop-mapreduce ................................... SUCCESS [ 59.280 s]
[INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [ 26.724 s]
[INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 31.503 s]
[INFO] Apache Hadoop Archives ............................. SUCCESS [ 19.867 s]
[INFO] Apache Hadoop Rumen ................................ SUCCESS [ 27.401 s]
[INFO] Apache Hadoop Gridmix .............................. SUCCESS [ 20.102 s]
[INFO] Apache Hadoop Data Join ............................ SUCCESS [ 20.382 s]
[INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [ 12.207 s]
[INFO] Apache Hadoop Extras ............................... SUCCESS [ 24.069 s]
[INFO] Apache Hadoop Pipes ................................ SUCCESS [ 31.975 s]
[INFO] Apache Hadoop OpenStack support .................... SUCCESS [ 32.225 s]
[INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [02:45 min]
[INFO] Apache Hadoop Client ............................... SUCCESS [01:38 min]
[INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [ 15.450 s]
[INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [ 46.489 s]
[INFO] Apache Hadoop Tools Dist ........................... SUCCESS [01:31 min]
[INFO] Apache Hadoop Tools ................................ SUCCESS [  7.603 s]
[INFO] Apache Hadoop Distribution ......................... SUCCESS [ 32.967 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 39:30 min
[INFO] Finished at: 2015-03-08T10:55:47+08:00
[INFO] Final Memory: 102M/340M
[INFO] ------------------------------------------------------------------------
</code></pre>

<p>把src编译出来的native下面的文件拷贝到hadoop集群程序目录下：</p>

<pre><code>[hadoop@hadoop-master1 lib]$ scp -r root@172.17.42.1:~/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/lib/native ./
[hadoop@hadoop-master1 lib]$ cd native/
[hadoop@hadoop-master1 native]$ ll
total 4356
-rw-r--r--. 1 hadoop hadoop 1119518 Mar  8 03:11 libhadoop.a
-rw-r--r--. 1 hadoop hadoop 1486964 Mar  8 03:11 libhadooppipes.a
lrwxrwxrwx. 1 hadoop hadoop      18 Mar  3 21:08 libhadoop.so -&gt; libhadoop.so.1.0.0
-rwxr-xr-x. 1 hadoop hadoop  671237 Mar  8 03:11 libhadoop.so.1.0.0
-rw-r--r--. 1 hadoop hadoop  581944 Mar  8 03:11 libhadooputils.a
-rw-r--r--. 1 hadoop hadoop  359490 Mar  8 03:11 libhdfs.a
lrwxrwxrwx. 1 hadoop hadoop      16 Mar  3 21:08 libhdfs.so -&gt; libhdfs.so.0.0.0
-rwxr-xr-x. 1 hadoop hadoop  228451 Mar  8 03:11 libhdfs.so.0.0.0
</code></pre>

<p>添加编译的native包前后对比：</p>

<pre><code>[hadoop@hadoop-master1 hadoop-2.6.0]$ hadoop fs -ls /
15/03/08 03:09:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-r--r--   1 hadoop supergroup       1366 2015-03-06 16:49 /README.txt
drwx------   - hadoop supergroup          0 2015-03-06 16:54 /tmp
drwxr-xr-x   - hadoop supergroup          0 2015-03-06 16:54 /user

# 编译好后，警告提示没有了
[hadoop@hadoop-master1 hadoop-2.6.0]$ hadoop fs -ls /
Found 3 items
-rw-r--r--   1 hadoop supergroup       1366 2015-03-06 16:49 /README.txt
drwx------   - hadoop supergroup          0 2015-03-06 16:54 /tmp
drwxr-xr-x   - hadoop supergroup          0 2015-03-06 16:54 /user
</code></pre>

<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dnsmasq解决docker集群节点互通问题]]></title>
    <link href="http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster/"/>
    <updated>2014-10-18T04:19:21+08:00</updated>
    <id>http://winseliu.com/blog/2014/10/18/docker-dnsmasq-handler-hosts-build-hadoop-cluster</id>
    <content type="html"><![CDATA[<p>上个星期学习了一下docker，写了一个<a href="https://github.com/winse/docker-hadoop/tree/Pseudo-Distributed">伪分布式的Dockerfile</a>。</p>

<p>通过<code>--link</code>的方式master能访问slaver，毕竟slaver的相关信息已经被写入到master的hosts文件里面去了嘛！理所当然认为，直接把master的hosts文件全部复制一份到所有slaver节点问题就解决了。</p>

<p>等真正操作的时刻，发现不是那么回事，docker容器不给修改hosts文件！！（2016-1-7 14:18:11 注： Docker 1.6.2已经可以修改/etc/hosts了！重启后hosts的变更也没了，囧）</p>

<h2>错误实现</h2>

<p>首先，看下不当的操作：</p>

<pre><code># 注意：没有填写image，会去找Dockerfile
[root@docker hadoop]# docker run -d --name slaver1 -h slaver1 hadoop
[root@docker hadoop]# docker run -d --name slaver2 -h slaver2 hadoop
[root@docker hadoop]# docker run -d --name master -h master --link slaver1:slaver1 --link slaver2:slaver2 hadoop

[root@docker ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES
dafc82678811        hadoop:latest       /bin/sh -c '/usr/sbi   40 seconds ago      Up 40 seconds       22/tcp              master
86d2da5209c5        hadoop:latest       /bin/sh -c '/usr/sbi   49 seconds ago      Up 48 seconds       22/tcp              master/slaver2,slaver2
7b9761fb05a8        hadoop:latest       /bin/sh -c '/usr/sbi   56 seconds ago      Up 55 seconds       22/tcp              master/slaver1,slaver1
</code></pre>

<p>此时，通过<code>--link</code>连接方式，master的hosts中已经包括了slaver1和slaver2，按照正常的路子，登录master拷贝其hosts到slaver节点，一切就妥妥的了。现实是残酷的：</p>

<pre><code>-bash-4.1# scp /etc/hosts slaver1:/etc/
scp: /etc//hosts: Read-only file system
</code></pre>

<h2>DNS完美解决问题</h2>

<p>首先需要在宿主机器上安装dns服务器，bind不多说比较麻烦。这里参考网上人家解决方式，使用dnsmasq来搭建DNS服务器。</p>

<pre><code>[root@docker ~]# yum install dnsmasq -y

[root@docker ~]# cp /etc/resolv.conf /etc/resolv.dnsmasq.conf 
[root@docker ~]# touch /etc/dnsmasq.hosts

[root@docker ~]# vi /etc/resolv.conf
[root@docker ~]# cat /etc/resolv.conf
; generated by /sbin/dhclient-script
nameserver 127.0.0.1 

[root@docker ~]# vi /etc/dnsmasq.conf
[root@docker ~]# cat /etc/dnsmasq.conf
...
resolv-file=/etc/resolv.dnsmasq.conf
...
addn-hosts=/etc/dnsmasq.hosts

[root@docker ~]# service dnsmasq restart

[root@docker ~]# dig www.baidu.com
...
;; SERVER: 127.0.0.1#53(127.0.0.1)
...
</code></pre>

<p>通过dig可以查看当前的DNS服务器你已经修改为localhost了。然后启动docker容器来搭建环境。</p>

<pre><code># 注意：没有填写image，会去找Dockerfile

[root@docker hadoop]# docker run -d  --dns 172.17.42.1 --name slaver1 -h slaver1 hadoop
[root@docker hadoop]# docker run -d  --dns 172.17.42.1 --name slaver2 -h slaver2 hadoop
[root@docker hadoop]# docker run -d  --dns 172.17.42.1 --name master -h master hadoop

[root@docker ~]# docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES
f6e63b311e60        hadoop:latest       /bin/sh -c '/usr/sbi   6 seconds ago       Up 5 seconds        22/tcp              master
454ae2c3e435        hadoop:latest       /bin/sh -c '/usr/sbi   13 seconds ago      Up 12 seconds       22/tcp              slaver2
7698230a03fb        hadoop:latest       /bin/sh -c '/usr/sbi   21 seconds ago      Up 20 seconds       22/tcp              slaver1

[root@docker ~]# docker ps | grep hadoop | awk '{print $1}' | xargs -I{} docker inspect -f '{{.NetworkSettings.IPAddress}} {{.Config.Hostname}}' {} &gt; /etc/dnsmasq.hosts
[root@docker ~]# service dnsmasq restart

[root@docker ~]# ssh hadoop@master
hadoop@master's password: 
[hadoop@master ~]$ ping slaver1
PING slaver1 (172.17.0.9) 56(84) bytes of data.
64 bytes from slaver1 (172.17.0.9): icmp_seq=1 ttl=64 time=1.79 ms
...
[hadoop@master ~]$ ping slaver2
PING slaver2 (172.17.0.10) 56(84) bytes of data.
64 bytes from slaver2 (172.17.0.10): icmp_seq=1 ttl=64 time=1.96 ms
...


</code></pre>

<p>节点互通后，后面的步骤都类似了，ssh无密钥通信，格式化namenode，启动等等。</p>

<h2>遇到的问题</h2>

<ul>
<li>一开始我把配置文件放在/root目录下，dnsmasq总是不起作用。最后放到/etc目录就可以，不知道啥子问题。</li>
<li>配置dns启动docker容器后，如果不起作用看下<code>/etc/resolv.conf</code>。如果互ping不同，去掉resolv的<code>search localhost</code>再试下。</li>
</ul>


<p>DNS可以正常工作的配置：</p>

<pre><code>-bash-4.1# ping slaver
PING slaver (172.17.0.7) 56(84) bytes of data.
64 bytes from slaver (172.17.0.7): icmp_seq=1 ttl=64 time=0.095 ms

-bash-4.1# cat /etc/resolv.conf 
nameserver 172.17.42.1
search localdomain

-bash-4.1# cat /etc/resolv.conf 
nameserver 172.17.42.1
</code></pre>

<p>如果还是不行的话，关掉防火墙然后重启下docker服务: <code>service iptables stop; service docker restart</code></p>

<p>如果要访问外网，也可以条件其他的DNS服务解析：</p>

<pre><code>-bash-4.1# vi /etc/resolv.conf 
nameserver 172.17.42.1
nameserver 8.8.8.8
</code></pre>

<h2>常用命令</h2>

<pre><code>~]# docker run -d --dns 172.17.42.1 --name puppet -h puppet winse/hadoop:2.6.0 /usr/sbin/sshd -D
~]# docker inspect `docker ps -a | grep centos | awk '{print $1}'` | grep IPAddress
~]# docker stop `docker ps -a | grep centos | awk '{print $1}'`
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://top.jobbole.com/7904/">DNS和Docker的小技巧</a></li>
<li><a href="http://www.07net01.com/linux/zuixindnsmasqanzhuangbushuxiangjie_centos6__653221_1381214991.html">dnsmasq安装部署详解-centos6</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[配置ssh登录docker-centos]]></title>
    <link href="http://winseliu.com/blog/2014/09/30/docker-ssh-on-centos/"/>
    <updated>2014-09-30T00:10:02+08:00</updated>
    <id>http://winseliu.com/blog/2014/09/30/docker-ssh-on-centos</id>
    <content type="html"><![CDATA[<p>上一篇写的是docker的入门知识，并没有进行实战。这些记录下使用ssh登录centos容器。</p>

<p>前文中参考的博客介绍了使用ssh登录tutorial容器（ubuntu），然后进行tomcat的安装，以及通过端口映射在客户机进行访问的例子。</p>

<h1>尝试</h1>

<pre><code>docker pull learn/tutorial
docker run -i -t learn/tutorial /bin/bash
    apt-get update
    apt-get install openssh-server
    which sshd
    /usr/sbin/sshd
    mkdir /var/run/sshd
    passwd #输入用户密码，我这里设置为123456，便于SSH客户端登陆使用
    exit #退出
docker ps -l
docker commit 51774a81beb3 learn/tutorial # 提交后，下次启动就可以基于容器更改的系统
docker run -d -p 49154:22 -p 80:8080 learn/tutorial /usr/sbin/sshd -D
ssh root@127.0.0.1 -p 49154
    # 在ubuntu 12.04上安装oracle jdk 7
    apt-get install python-software-properties
    add-apt-repository ppa:webupd8team/java
    apt-get update
    apt-get install -y wget
    apt-get install oracle-java7-installer
    java -version
    # 下载tomcat 7.0.47
    wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.47/bin/apache-tomcat-7.0.47.tar.gz
    # 解压，运行
    tar xvf apache-tomcat-7.0.47.tar.gz
    cd apache-tomcat-7.0.47
    bin/startup.sh
</code></pre>

<p>然而在centos上，运行是不成功的。总结操作如下：</p>

<pre><code>[root@docker ~]# docker pull centos:centos6
[root@docker ~]# docker run -i -t  centos:centos6 /bin/bash
    yum install which openssh-server openssh-clients

    /usr/sbin/sshd # 这里会报错，需要手动生成key
    ssh-keygen -f /etc/ssh/ssh_host_rsa_key
    ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key

    vi /etc/pam.d/sshd  # 修改pam_loginuid.so为optional
    # /bin/sed -i 's/.*session.*required.*pam_loginuid.so.*/session optional pam_loginuid.so/g' /etc/pam.d/sshd

    passwd # 添加密码

    rm -rf /etc/localtime
    ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
    cat &gt; /etc/sysconfig/clock  &lt;&lt;EOF
    ZONE="Asia/Shanghai"
    UTC=True
    EOF
</code></pre>

<ul>
<li>提交保存成果</li>
</ul>


<pre><code>[root@docker ~]# docker ps -l
[root@docker ~]# docker commit 3a7b6994bb2a winse/hadoop # 保存为自己使用的版本

[root@docker ~]# docker run -d winse/hadoop /usr/sbin/sshd
f5cb57f6ec22dd9d257bf610322e2bd547ea0064262fcad63308b932c0490670
[root@docker ~]# docker ps -l
CONTAINER ID        IMAGE                 COMMAND             CREATED             STATUS                     PORTS               NAMES
f5cb57f6ec22        winse/hadoop:latest   /usr/sbin/sshd      2 seconds ago       Exited (0) 2 seconds ago                       sharp_rosalind      

[root@docker ~]# docker run -d -p 8888:22 winse/hadoop /usr/sbin/sshd -D
f9814253159373e8a8df3261904200a733b41c63f55708db3cb56a7ebf650cef
[root@docker ~]# docker ps -l
CONTAINER ID        IMAGE                 COMMAND             CREATED             STATUS              PORTS                  NAMES
f98142531593        winse/hadoop:latest   /usr/sbin/sshd -D   5 seconds ago       Up 4 seconds        0.0.0.0:8888-&gt;22/tcp   boring_bell         
[root@docker ~]# ssh localhost -p 8888
The authenticity of host '[localhost]:8888 ([::1]:8888)' can't be established.
RSA key fingerprint is f5:5e:be:ae:ea:b1:ed:e8:49:43:28:9e:80:87:0d:86.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '[localhost]:8888' (RSA) to the list of known hosts.
root@localhost's password: 
Last login: Mon Sep 29 14:48:23 2014 from localhost
-bash-4.1# 
</code></pre>

<p>参数<code>-D</code>表示sshd运行在前台。这样当前的docker容器就会一直有程序在运行，不至于执行完指定的任务就被关闭掉了。</p>

<p>在centos配置ssh登录需要进行额外参数的设置。这个还是挺折腾人的。关于把<code>/etc/pam.d/sshd</code>中的<code>pam_loginuid.so</code>修改为optional，<a href="(http://stackoverflow.com/questions/21391142/why-is-it-needed-to-set-pam-loginuid-to-its-optional-value-with-docker">stackoverflow</a>)上的回答还是挺中肯的。</p>

<p>连上ssh后，下一步就和你远程操作服务器一样了。其实docker运行一个容器后，就会分配一个ip，你也可以根据这个ip来连接。</p>

<pre><code>[root@docker ~]# docker run -t -i winse/hadoop /bin/bash
bash-4.1# ssh localhost
ssh: connect to host localhost port 22: Connection refused
bash-4.1# service sshd start
Starting sshd:                                             [  OK  ]
bash-4.1# ifconfig
eth0      Link encap:Ethernet  HWaddr 1E:2B:23:16:98:7E  
          inet addr:172.17.0.31  Bcast:0.0.0.0  Mask:255.255.0.0
          inet6 addr: fe80::1c2b:23ff:fe16:987e/64 Scope:Link

# 新开一个终端
[root@docker ~]# ssh 172.17.0.31
The authenticity of host '172.17.0.31 (172.17.0.31)' can't be established.
RSA key fingerprint is f5:5e:be:ae:ea:b1:ed:e8:49:43:28:9e:80:87:0d:86.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.17.0.31' (RSA) to the list of known hosts.
root@172.17.0.31's password: 
Last login: Mon Sep 29 14:48:23 2014 from localhost
-bash-4.1#           
</code></pre>

<h2>使用Dockerfile脚本安装</h2>

<pre><code>[root@docker ~]# mkdir hadoop
[root@docker ~]# cd hadoop/
[root@docker hadoop]# touch Dockerfile
[root@docker hadoop]# vi Dockerfile
    # hadoop2 on docker-centos
    FROM centos:centos6
    MAINTAINER Winse &lt;fuqiuliu2006@qq.com&gt;
    RUN yum install -y which openssh-clients openssh-server #-y表示交互都输入yes

    RUN ssh-keygen -f /etc/ssh/ssh_host_rsa_key
    RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key

    RUN echo 'root:hadoop' |chpasswd

    RUN sed -i '/pam_loginuid.so/c session    optional     pam_loginuid.so'  /etc/pam.d/sshd

    EXPOSE 22
    CMD /usr/sbin/sshd -D

[root@docker hadoop]# docker build -t="winse/hadoop" .

[root@docker hadoop]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
winse/hadoop        latest              9d7f115ef0ec        5 minutes ago       289.1 MB
...

[root@docker hadoop]# docker run -d --name slaver1 winse/hadoop
[root@docker hadoop]# docker run -d --name slaver2 winse/hadoop
[root@docker hadoop]# docker run -d --name master1 -P --link slaver1:slaver1 --link slaver2:slaver2  winse/hadoop

[root@docker hadoop]# docker restart slaver1 slaver2 master1
slaver1
slaver2
master1

[root@docker hadoop]# docker port master1 22
0.0.0.0:49159
[root@docker hadoop]# ssh localhost -p 49159
... 
-bash-4.1# cat /etc/hosts
172.17.0.31     7ef63f98e2d1
127.0.0.1       localhost
::1     localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.29     slaver1
172.17.0.30     slaver2
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://www.blogjava.net/yongboy/archive/2013/12/12/407498.html">Docker学习笔记之一，搭建一个JAVA Tomcat运行环境</a></li>
<li><a href="http://www.csdn123.com/html/topnews201408/36/1236.htm">Docker之配置Centos_ssh</a></li>
<li><a href="http://linux.die.net/man/8/pam_loginuid">pam_loginuid(8) - Linux man page</a></li>
<li><a href="http://stackoverflow.com/questions/21391142/why-is-it-needed-to-set-pam-loginuid-to-its-optional-value-with-docker">Why is it needed to set <code>pam_loginuid</code> to its <code>optional</code> value with docker?</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker入门]]></title>
    <link href="http://winseliu.com/blog/2014/09/27/docker-start-guide-on-centos/"/>
    <updated>2014-09-27T20:28:24+08:00</updated>
    <id>http://winseliu.com/blog/2014/09/27/docker-start-guide-on-centos</id>
    <content type="html"><![CDATA[<p>docker进一年来火热，发现挺适合用来做运维系统发布的。如果用来捣鼓hadoop的系统部署感觉还是挺不错的。下面一起来学习下docker吧。</p>

<p>docker中提供了<a href="https://docs.docker.com/installation/windows/">windows的安装文档</a>，但是其实很坑爹啊。尽管<a href="https://github.com/boot2docker/windows-installer/releases">提供exe安装</a>，但是最终还是安装visualbox，然后启动带了docker的linux系统（iso）。</p>

<p>如果你已经安装了vmware，但没有安装linux，可以直接<a href="https://github.com/boot2docker/boot2docker/releases">下载iso</a>，然后通过iso来启动。</p>

<h2>安装</h2>

<p>如果你同时安装了vmware，又已经安装了linux，那下面简单列出安装配置docker中使用的命令。docker需要64位的linux操作系统，我这里使用的是centos6，具体的安装步骤看<a href="https://docs.docker.com/installation/centos/">官网的安装教程</a>。</p>

<pre><code>[root@docker ~]# yum install epel-release

[root@docker ~]# yum install docker-io
[root@docker ~]# service docker start

[root@docker ~]# docker run learn/tutorial /bin/echo hello world
Unable to find image 'learn/tutorial' locally
Pulling repository learn/tutorial
8dbd9e392a96: Pulling fs layer 
8dbd9e392a96: Download complete 
hello world

[root@docker ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
learn/tutorial      latest              8dbd9e392a96        17 months ago       128 MB
[root@docker ~]# docker images learn/tutorial 
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
learn/tutorial      latest              8dbd9e392a96        17 months ago       128 MB
</code></pre>

<p>docker执行run命令时，如果指定的image本地不存在，会从<a href="https://registry.hub.docker.com/">hub服务器</a>获取。也可以先从服务器获取image，然后在执行。</p>

<pre><code>docker pull centos
</code></pre>

<p>【注】：如果启动失败，1：重装一下docker； 2：还是不行，启动报<code>docker: relocation error: docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference</code>，更新<code>yum upgrade device-mapper-libs</code>，然后启动<code>service docker start</code>（具体描述见文章末）</p>

<h2>简单入门</h2>

<p><a href="https://docs.docker.com/userguide/dockerizing/">HelloWorld教程</a></p>

<h4>单次执行</h4>

<pre><code>[root@docker ~]# docker run learn/tutorial /bin/echo 'hello world'
hello world
</code></pre>

<p>命令执行完后，容器就会关闭。</p>

<h4>交互式执行方式</h4>

<pre><code>[root@docker ~]# docker run -t -i learn/tutorial /bin/bash
root@274ede23baad:/# uptime
 12:36:02 up  5:59,  0 users,  load average: 0.00, 0.00, 0.00
root@9db219d2e98b:/# cat /etc/issue
Ubuntu 12.04 LTS \n \l
root@274ede23baad:/# pwd
/
root@274ede23baad:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  selinux  srv  sys  tmp  usr  var
root@274ede23baad:/# exit
exit
</code></pre>

<ul>
<li>-t flag assigns a pseudo-tty or terminal inside our new container。</li>
<li>-i flag allows us to make an interactive connection by grabbing the standard in (STDIN) of the container.</li>
</ul>


<h4>后台任务</h4>

<pre><code>[root@docker ~]# docker run -d learn/tutorial /bin/sh -c "while true; do echo hello world; sleep 1; done" 
17e28b56e0cc4ddb5522736e2bcfd752d849a5b1d0b598478ee66b255801aa7c

[root@docker ~]# docker ps
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS              PORTS               NAMES
17e28b56e0cc        learn/tutorial:latest   /bin/sh -c 'while tr   2 minutes ago       Up 2 minutes                            trusting_wozniak    
</code></pre>

<ul>
<li>-d flag tells Docker to run the container and put it in the background, to daemonize it.</li>
</ul>


<p>执行返回的是containter id(唯一ID)。通过ps可以查看当前的后台任务列表。ps列表中的containter id对应，可以查看相应的信息，最后的字段是一个随机指定的名字（也可以指定，后面再讲）。</p>

<pre><code>[root@docker ~]# docker logs trusting_wozniak
hello world
hello world
...

[root@docker ~]# docker stop trusting_wozniak
trusting_wozniak
[root@docker ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre>

<p>可以通过logs查看容器的标准输出，通过stop来停止容器。</p>

<h2>深入容器</h2>

<p><a href="https://docs.docker.com/userguide/usingdocker/">Working with Containers</a></p>

<p>可以交互式的方式运行container，也可以后台任务的方式运行。</p>

<p>docker的命令：</p>

<pre><code># Usage:  [sudo] docker [flags] [command] [arguments] ..
# Example:
$ sudo docker run -i -t ubuntu /bin/bash
</code></pre>

<p>每个命令可以指定跟一系列的开关标识(flags)和参数(arguments)。</p>

<h4>各种参数</h4>

<pre><code>$ docker version

$ docker run -d -P training/webapp python app.py

$ docker ps -l
CONTAINER ID  IMAGE                   COMMAND       CREATED        STATUS        PORTS                    NAMES
bc533791f3f5  training/webapp:latest  python app.py 5 seconds ago  Up 2 seconds  0.0.0.0:49155-&gt;5000/tcp  nostalgic_morse

# docker run -d -p 6379 -v /home/hadoop/redis-2.8.13:/opt/redis-2.8.13 learn/tutorial /opt/redis-2.8.13/src/redis-server 
be0b410f3601ea36070b3e519d9cc7cbe259caa2392f468c2dd2baebef42c4a8

# docker ps -l
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS              PORTS                     NAMES
be0b410f3601        learn/tutorial:latest   /opt/redis-2.8.13/sr   10 seconds ago      Up 10 seconds       0.0.0.0:49153-&gt;6379/tcp   sad_colden          

# /home/hadoop/redis-2.8.13/src/redis-cli -p 49153
127.0.0.1:49153&gt; keys *
(empty list or set)
127.0.0.1:49153&gt; 
</code></pre>

<ul>
<li>-P flag is new and tells Docker to map any required network ports inside our container to our host. This lets us view our web application.</li>
<li>-l tells the docker ps command to return the details of the last container started.</li>
<li>-a the docker ps command only shows information about running containers. If you want to see stopped containers too use the -a flag.</li>
<li>-p Network port bindings are very configurable in Docker. In our last example the -P flag is a shortcut for -p 5000 that maps port 5000 inside the container to a high port (from the range 49153 to 65535) on the local Docker host. We can also bind Docker containers to specific ports using the -p flag。</li>
<li>-v flag you can also mount a directory from your own host into a container.</li>
</ul>


<pre><code>[root@docker redis-2.8.13]# docker run -d -p 6379:6379 -v /home/hadoop/redis-2.8.13:/opt/redis-2.8.13 learn/tutorial /opt/redis-2.8.13/src/redis-server 
2c50850c9437698769e54281a9f4154dc4120da2e113802454f1a23c83ab91fe

[root@docker redis-2.8.13]# docker ps
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS              PORTS                    NAMES
2c50850c9437        learn/tutorial:latest   /opt/redis-2.8.13/sr   29 seconds ago      Up 28 seconds       0.0.0.0:6379-&gt;6379/tcp   naughty_yonath  

[root@docker redis-2.8.13]# docker port naughty_yonath 6379
0.0.0.0:6379

[root@docker redis-2.8.13]# docker logs -f naughty_yonath
...
[1] 27 Sep 13:48:12.192 * The server is now ready to accept connections on port 6379
[1] 27 Sep 13:50:33.228 * DB saved on disk
[1] 27 Sep 13:50:43.730 * DB saved on disk
</code></pre>

<ul>
<li>-f This time though we&rsquo;ve added a new flag, -f. This causes the docker logs command to act like the tail -f command and watch the container&rsquo;s standard out. We can see here the logs from Flask showing the application running on port 5000 and the access log entries for it.</li>
</ul>


<pre><code>[root@docker redis-2.8.13]# docker top naughty_yonath
UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
root                5015                1433                0                   21:48               ?                   00:00:00            /opt/redis-2.8.13/src/redis-server *:6379
[root@docker redis-2.8.13]# docker inspect naughty_yonath
...
    "Volumes": {
        "/opt/redis-2.8.13": "/home/hadoop/redis-2.8.13"
    },
    "VolumesRW": {
        "/opt/redis-2.8.13": true
    }
}

[root@docker redis-2.8.13]# docker inspect -f '' naughty_yonath
map[/opt/redis-2.8.13:/home/hadoop/redis-2.8.13]
</code></pre>

<h4>重启</h4>

<pre><code>[root@docker redis-2.8.13]# docker stop naughty_yonath
naughty_yonath
[root@docker redis-2.8.13]# docker ps -l
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS                     PORTS               NAMES
2c50850c9437        learn/tutorial:latest   /opt/redis-2.8.13/sr   8 minutes ago       Exited (0) 5 seconds ago                       naughty_yonath      
[root@docker redis-2.8.13]# docker start naughty_yonath
naughty_yonath
[root@docker redis-2.8.13]# docker ps -l
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS              PORTS                    NAMES
2c50850c9437        learn/tutorial:latest   /opt/redis-2.8.13/sr   8 minutes ago       Up 1 seconds        0.0.0.0:6379-&gt;6379/tcp   naughty_yonath
</code></pre>

<h4>删除</h4>

<pre><code>docker stop naughty_yonath
docker rm naughty_yonath
</code></pre>

<h2>Images</h2>

<p><a href="https://docs.docker.com/userguide/dockerimages/">Working with Docker Images</a></p>

<h4>列出本地的images</h4>

<pre><code>docker images
# REPO[:TAG]
docker run -t -i ubuntu:14.04 /bin/bash
docker run -t -i ubuntu:latest /bin/bash
</code></pre>

<h4>从Hub获取镜像Image</h4>

<pre><code>docker pull centos
docker run -t -i centos /bin/bash
docker search sinatra 
docker pull training/sinatra
</code></pre>

<h4>创建自己的images</h4>

<p>直接更新image</p>

<pre><code>$ docker run -t -i training/sinatra /bin/bash
root@0b2616b0e5a8:/# gem install json
$ sudo docker commit -m="Added json gem" -a="Kate Smith" \
    0b2616b0e5a8 ouruser/sinatra:v2
$ docker images
$ docker run -t -i ouruser/sinatra:v2 /bin/bash
root@78e82f680994:/#
</code></pre>

<p>通过DockerFile来添加功能，进行更新。</p>

<pre><code>$ mkdir sinatra
$ cd sinatra
$ touch Dockerfile
    # This is a comment
    FROM ubuntu:14.04
    MAINTAINER Kate Smith &lt;ksmith@example.com&gt;
    RUN apt-get update &amp;&amp; apt-get install -y ruby ruby-dev
    RUN gem install sinatra

$ docker build -t="ouruser/sinatra:v2" .
$ docker run -t -i ouruser/sinatra:v2 /bin/bash
</code></pre>

<p>具体的DockerFile中各个指令的含义及其使用方法，参考<a href="https://docs.docker.com/userguide/dockerimages/">Building an image from a Dockerfile</a>和<a href="https://docs.docker.com/articles/dockerfile_best-practices/">Best Practices for Writing Dockerfiles</a>，以及<a href="https://docs.docker.com/reference/builder/">Dockerfile Reference</a>。具体例子<a href="https://github.com/perl/docker-perl/blob/r20140922.0/5.020.001-64bit,threaded/Dockerfile">docker-perl</a></p>

<h4>添加新标签Tag</h4>

<pre><code>$ docker tag 5db5f8471261 ouruser/sinatra:devel
$ docker images ouruser/sinatra
REPOSITORY          TAG     IMAGE ID      CREATED        VIRTUAL SIZE
ouruser/sinatra     latest  5db5f8471261  11 hours ago   446.7 MB
ouruser/sinatra     devel   5db5f8471261  11 hours ago   446.7 MB
</code></pre>

<h4>上传分享到<a href="https://hub.docker.com/">hub</a></h4>

<pre><code>docker push ouruser/sinatra
</code></pre>

<h4>从本地删除</h4>

<pre><code>docker rmi training/sinatra
</code></pre>

<h2>多container结合使用</h2>

<p><a href="https://docs.docker.com/userguide/dockerlinks/">Linking Containers Together</a></p>

<h4>端口映射</h4>

<pre><code>docker run -d -P training/webapp python app.py

docker ps nostalgic_morse
CONTAINER ID  IMAGE                   COMMAND       CREATED        STATUS        PORTS                    NAMES
bc533791f3f5  training/webapp:latest  python app.py 5 seconds ago  Up 2 seconds  0.0.0.0:49155-&gt;5000/tcp  nostalgic_morse

docker run -d -p 5000:5000 training/webapp python app.py

docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py

docker run -d -p 127.0.0.1::5000 training/webapp python app.py

# The -p flag can be used multiple times to configure multiple ports.
docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py

docker port nostalgic_morse 5000
127.0.0.1:49155
</code></pre>

<h4>Container Linking</h4>

<p>docker想的还是很周到的。面临两个container互相访问，一个db，一个web，哪web怎么访问db的数据呢？</p>

<p>指定container的名称：</p>

<pre><code>$ docker run -d -P --name web training/webapp python app.py

$ docker ps -l
CONTAINER ID  IMAGE                  COMMAND        CREATED       STATUS       PORTS                    NAMES
aed84ee21bde  training/webapp:latest python app.py  12 hours ago  Up 2 seconds 0.0.0.0:49154-&gt;5000/tcp  web

$ docker inspect -f "" aed84ee21bde
/web
</code></pre>

<p>容器互通：</p>

<pre><code>$ docker run -d --name db training/postgres

$ docker rm -f web
$ docker run -d -P --name web --link db:db training/webapp python app.py

$ docker ps
CONTAINER ID  IMAGE                     COMMAND               CREATED             STATUS             PORTS                    NAMES
349169744e49  training/postgres:latest  su postgres -c '/usr  About a minute ago  Up About a minute  5432/tcp                 db, web/db
aed84ee21bde  training/webapp:latest    python app.py         16 hours ago        Up 2 minutes       0.0.0.0:49154-&gt;5000/tcp  web
</code></pre>

<p>链接后，在web容器会添加DB的环境变量，同时把db的ip加入到/etc/hosts中。</p>

<pre><code>
$ docker run --rm --name web2 --link db:db training/webapp env
    . . .
    DB_NAME=/web2/db
    DB_PORT=tcp://172.17.0.5:5432
    DB_PORT_5432_TCP=tcp://172.17.0.5:5432
    DB_PORT_5432_TCP_PROTO=tcp
    DB_PORT_5432_TCP_PORT=5432
    DB_PORT_5432_TCP_ADDR=172.17.0.5

$ docker run -t -i --rm --link db:db training/webapp /bin/bash
root@aed84ee21bde:/opt/webapp# cat /etc/hosts
172.17.0.7  aed84ee21bde
. . .
172.17.0.5  db    
</code></pre>

<p>You can see that Docker has created a series of environment variables with useful information about the source db container. Each variable is prefixed with <code>DB_</code>, which is populated from the alias you specified above. If the alias were db1, the variables would be prefixed with <code>DB1_</code>.</p>

<h2>存储</h2>

<p><a href="https://docs.docker.com/userguide/dockervolumes/">Managing Data in Containers</a></p>

<pre><code># Adding a data volume
docker run -d -P --name web -v /webapp training/webapp python app.py

# Mount a Host Directory as a Data Volume
docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py
# 只读
docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py

# Mount a Host File as a Data Volume
docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash

# Creating and mounting a Data Volume Container
docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres
docker run -d --volumes-from dbdata --name db1 training/postgres
docker run -d --volumes-from dbdata --name db2 training/postgres
docker run -d --name db3 --volumes-from db1 training/postgres

# Backup, restore, or migrate data volumes
docker run --volumes-from dbdata -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata
docker run -v /dbdata --name dbdata2 ubuntu /bin/bash
docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar
</code></pre>

<h2>回顾</h2>

<p>管理docker主要使用其提供的各种命令、以及参数来进行。</p>

<ul>
<li>本地的镜像管理: docker images / docker rmi [image identify]</li>
<li>容器管理： docker ps -a|-l / docker start|stop|rm|restart [image identify]</li>
<li>运行容器：docker run [images] [command]

<ul>
<li>-d 后台运行</li>
<li>-ti tty交互式运行</li>
<li>-P 把容器expose的端口映射到宿主机器端口。可以通过<code>docker port [container-name]</code>来查看端口映射关系。</li>
<li>-p [host-machine-port:container-machine-port]手动指定端口映射关系</li>
<li>-h [hostname] 实例操作系统的hostname</li>
<li>&ndash;name [name] 容器实例标识</li>
<li>-v [path] 建立目录</li>
<li>-v [host-machine-path:container-machine-path] 把宿主的文件路径映射到容器操作系统的指定目录</li>
<li>&ndash;link [container-name:name] 多容器之间互相访问。</li>
</ul>
</li>
</ul>


<p>还有很多辅助命令如：<code>top</code>, <code>logs</code>, <code>port</code>, <code>inspect</code>。以及进行版本管理的<code>pull</code>, <code>push</code>, <code>commit</code>, <code>tag</code>等等。</p>

<h2>更新</h2>

<ul>
<li>2015年3月3日00:29:44</li>
</ul>


<p>docker官网连不上，巨坑！从原来的docker导出</p>

<pre><code>[root@docker ~]# docker ps -a
CONTAINER ID        IMAGE                   COMMAND                CREATED             STATUS                      PORTS               NAMES
4a1ba5605868        learn/tutorial:latest   /bin/bash              15 seconds ago      Exited (0) 11 seconds ago                       loving_wilson        
6e8a77ff8c26        centos:centos6          /bin/bash              10 minutes ago      Exited (0) 10 minutes ago                       determined_almeida  
[root@docker ~]# docker export loving_wilson &gt; learn_tutorial.tar

#===

[root@localhost ~]# cat centos6.tar | docker import - centos:centos6
876f82e7032a2ed567421298c6dd12a74ac7b37fc28ef4fd062ebb4678bd6821
[root@localhost ~]# cat learn_tutorial.tar | docker import - learn/tutorial
dc574b587de3479ecc3622c7b4f12227d894aa1461737612130122092a72bdb4
[root@localhost ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED              VIRTUAL SIZE
learn/tutorial      latest              dc574b587de3        23 seconds ago       128.2 MB
centos              centos6             876f82e7032a        About a minute ago   212.7 MB
</code></pre>

<ul>
<li>2015年8月5日11:04:14</li>
</ul>


<p>1 看看国内网站是否有对应的镜像： <a href="http://dockerpool.com/downloads">http://dockerpool.com/downloads</a></p>

<p>2 连不上可以<a href="https://registry.hub.docker.com/_/centos/">https://registry.hub.docker.com/_/centos/</a> , 直接到github上面下载对应的<a href="https://github.com/CentOS/sig-cloud-instance-images/tree/CentOS-6/docker">dockerfile</a></p>

<pre><code>[root@localhost ~]# git clone -b CentOS-6  https://github.com/CentOS/sig-cloud-instance-images.git
[root@localhost docker]# docker build . 

[root@localhost docker]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
&lt;none&gt;              &lt;none&gt;              437c8a32e0c6        27 seconds ago      203.1 MB

# 启动登陆容器，安装sshd
[root@localhost docker]# docker run -ti 437c8a32e0c6 /bin/bash
[root@077cd71ff08f /]# yum install which openssh-server openssh-clients
[root@077cd71ff08f /]# chkconfig --list
iptables        0:off   1:off   2:on    3:on    4:on    5:on    6:off
netconsole      0:off   1:off   2:off   3:off   4:off   5:off   6:off
netfs           0:off   1:off   2:off   3:on    4:on    5:on    6:off
network         0:off   1:off   2:on    3:on    4:on    5:on    6:off
rdisc           0:off   1:off   2:off   3:off   4:off   5:off   6:off
restorecond     0:off   1:off   2:off   3:off   4:off   5:off   6:off
sshd            0:off   1:off   2:on    3:on    4:on    5:on    6:off
udev-post       0:off   1:on    2:on    3:on    4:on    5:on    6:off
[root@077cd71ff08f /]# service sshd status
openssh-daemon is stopped
[root@077cd71ff08f /]# service sshd start
Generating SSH2 RSA host key:                              [  OK  ]
Generating SSH1 RSA host key:                              [  OK  ]
Generating SSH2 DSA host key:                              [  OK  ]
Starting sshd:                                             [  OK  ]
[root@077cd71ff08f /]# vi /etc/ssh/sshd_config 
#UsePAM no
#或者 sed -i '/pam_loginuid.so/c session    optional     pam_loginuid.so'  /etc/pam.d/sshd
[root@077cd71ff08f /]# which sshd
/usr/sbin/sshd
[root@077cd71ff08f /]# passwd 记得添加密码

# 提交更新镜像
[root@localhost ~]# docker ps -a
CONTAINER ID        IMAGE                 COMMAND             CREATED             STATUS                      PORTS               NAMES
077cd71ff08f        bigdata:latest        "/bin/bash"         4 minutes ago       Exited (0) 11 seconds ago                       desperate_bell       
7195847a0166        437c8a32e0c6:latest   "/bin/bash"         3 hours ago         Up 5 minutes                                    determined_feynman   
[root@localhost ~]# docker commit 077cd71ff08f bigdata
[root@localhost ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
bigdata             latest              c2a336f22ff8        4 minutes ago       261.3 MB

# 启动新容器，使用ssh远程登陆
[root@localhost ~]# docker run -d --dns 172.17.42.1 --name master -h master bigdata /usr/sbin/sshd -D
[root@localhost ~]# docker run -d  --dns 172.17.42.1 --name slaver1 -h slaver1 bigdata /usr/sbin/sshd -D
[root@localhost ~]# docker inspect master
[root@localhost ~]# vi /etc/hosts
[root@localhost ~]# service dnsmasq restart
</code></pre>

<p>3 <a href="http://www.cnblogs.com/2018/p/4633940.html">自己制作</a></p>

<pre><code>[root@localhost docker]# wget --no-check-certificate  https://raw.githubusercontent.com/docker/docker/master/contrib/mkimage-yum.sh
[root@localhost docker]# chmod +x mkimage-yum.sh
[root@localhost docker]# ./mkimage-yum.sh centos6
</code></pre>

<ul>
<li>2015年3月2日16:13:12</li>
</ul>


<p>再在centos6.5上安装最新的，启动后报错：</p>

<pre><code>[root@localhost ~]# docker -d
INFO[0000] +job serveapi(unix:///var/run/docker.sock)   
INFO[0000] WARNING: You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.8.0. 
INFO[0000] Listening for HTTP on unix (/var/run/docker.sock) 
docker: relocation error: docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference
</code></pre>

<p>需要再安装新的依赖（囧，md，用yum安装还要自己安装其他依赖！！）</p>

<pre><code>[root@localhost ~]#  yum install device-mapper-event-libs
</code></pre>

<ul>
<li>报错2：<code>cgroup.procs: invalid argument</code>[2015年8月6日11:11:49]</li>
</ul>


<pre><code>[root@localhost ~]# docker start 5ed45ce5ad3d
Error response from daemon: Cannot start container 5ed45ce5ad3d: [8] System error: write /cgroup/freezer/docker/5ed45ce5ad3d085fe3c004f90eef7c774a722e84cf0c9d18c197cc5900bbc8ae/cgroup.procs: invalid argument
FATA[0000] Error: failed to start one or more containers 
</code></pre>

<p>修改配置：<a href="http://blog.csdn.net/jollypigclub/article/details/40428095">http://blog.csdn.net/jollypigclub/article/details/40428095</a></p>

<pre><code>[root@localhost ~]# vi /etc/sysconfig/docker
...
other_args="--exec-driver=lxc"
#other_args=""
...
</code></pre>

<ul>
<li>docker本地存储的路径[@ 2015年8月5日11:19:17]</li>
</ul>


<pre><code>[root@localhost docker]# cd /var/lib/docker/
[root@localhost docker]# ls
containers  devicemapper  graph  init  linkgraph.db  repositories-devicemapper  tmp  trust  volumes
[root@localhost docker]# cd graph/
[root@localhost graph]# ll
总用量 16
drwx------ 2 root root 4096 8月   5 10:39 d5d33a6a321ae20a3ae4805b5643560ce9c16a49d2f1d32541b39e04ad083983
drwx------ 2 root root 4096 8月   5 10:39 d8ed1be0a39bcc741aa1e95e59b844140d9294afc75082697184cdfbf2bc6a2d
drwx------ 2 root root 4096 8月   5 09:48 f1b10cd842498c23d206ee0cbeaa9de8d2ae09ff3c7af2723a9e337a6965d639
drwx------ 2 root root 4096 8月   5 10:39 _tmp

[root@localhost docker]# cd devicemapper/devicemapper/
[root@localhost devicemapper]# ll
总用量 976024
-rw------- 1 root root 107374182400 8月   5 09:38 data
-rw------- 1 root root   2147483648 8月   5 09:38 metadata
</code></pre>

<h2>参考</h2>

<ul>
<li><a href="http://www.blogjava.net/yongboy/archive/2013/12/12/407498.html">Docker学习笔记之一，搭建一个JAVA Tomcat运行环境</a></li>
<li><a href="http://www.inspires.cn/note/36">You are running linux kernel version 2.6.32-431.el6.x86_64(centos 6.5)</a></li>
<li><a href="http://blog.thoward37.me/articles/where-are-docker-images-stored/">Where are Docker images stored?(老版本，也值得一看)</a></li>
<li><a href="http://blog.csdn.net/xu470438000/article/details/43704469">Docker启动报错 relocation error libdevmapper</a></li>
<li><a href="http://www.programfish.com/blog/?p=9">docker镜像与容器存储结构分析</a></li>
</ul>


<p>&ndash;END</p>
]]></content>
  </entry>
  
</feed>
