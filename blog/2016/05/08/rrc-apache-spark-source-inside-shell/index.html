
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>[读读书]Apache Spark源码剖析-Shell - Winse Blog</title>
  <meta name="author" content="Winse Liu">

  
  <meta name="description" content="本来第二篇应该是与 [第1章 初识Spark] 有关，但我们运行helloworld、以及提交任务都是通过脚本 bin/spark-shell ，完全不知道那些脚本是干啥的？而且，在开发环境运行shell来启动应用总觉得怪怪的，这篇先来简单了解脚本的功能、以及Launcher模块。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://winse.github.io/blog/2016/05/08/rrc-apache-spark-source-inside-shell">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="/atom.xml" rel="alternate" title="Winse Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//cdn.bootcss.com/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/libs/jquery.toc.min.js" type="text/javascript"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
-->

<script src="/javascripts/generate-toc.js" type="text/javascript"></script>


  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43198550-1', 'auto');
  ga('send', 'pageview');

</script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Winse Blog</a></h1>
  
    <h2>走走停停, 熙熙攘攘, 忙忙碌碌, 不知何畏.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:winse.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="站内搜索"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/archives/updated.html">Updated</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">[读读书]Apache Spark源码剖析-Shell</h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2016-05-08T21:41:01+08:00" pubdate data-updated="true">Sun 2016-05-08 21:41</time>
		
        
		
      </p>
    
  </header>


<div class="entry-content"><p>本来第二篇应该是与 [第1章 初识Spark] 有关，但我们运行helloworld、以及提交任务都是通过脚本 <code>bin/spark-shell</code> ，完全不知道那些脚本是干啥的？而且，在开发环境运行shell来启动应用总觉得怪怪的，这篇先来简单了解脚本的功能、以及Launcher模块。</p>

<p><strong> 其实每个大数据的框架，shell脚本都是通用入口，也是研读源码的第一个突破口 </strong>。掌握脚本功能相当于熟悉了基本的API功能，把 spark/bin 目录下面的脚本理清楚，然后再去写搭建开发环境、编写调试helloworld就事半功倍了。</p>

<p>官网 <strong> Quick Start </strong> 提供的简短例子都是通过 bin/spark-shell 来运行的。Submit页面提供了 bin/spark-submit 提交jar发布任务的方式。 spark-shell，spark-submit 就是两个非常重要的脚本，这里就来看下这两个脚本。</p>

<h2>spark-shell - 对应[3.1 spark-shell]章节</h2>

<p>spark-shell 脚本的内容相对多一些，主要代码如下（其他代码都是为了兼容cygwin弄的，我们这里不关注）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SPARK_SUBMIT_OPTS="$SPARK_SUBMIT_OPTS -Dscala.usejavacp=true"
</span><span class='line'>trap onExit INT     # 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl + C)时触发
</span><span class='line'>
</span><span class='line'>export SPARK_SUBMIT_OPTS
</span><span class='line'>"${SPARK_HOME}"/bin/spark-submit --class org.apache.spark.repl.Main --name "Spark shell" "$@"</span></code></pre></td></tr></table></div></figure>


<p>最终调用 bin/spark-submit 脚本。其实和我们自己提交 helloworld.jar 命令一样：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ bin/spark-submit \
</span><span class='line'>  --class "HelloWorld" \
</span><span class='line'>  --master local[2] \
</span><span class='line'>  target/scala-2.10/helloworld_2.10-1.0.jar</span></code></pre></td></tr></table></div></figure>


<p>不过通过 bin/spark-shell 提交运行的类是spark自带，没有附加（不需要）额外的jar。这个后面再讲，我们也可以通过这种方式类运行公共位置的jar，可以减少一些不必要的网络带宽。</p>

<h2>spark-submit</h2>

<p>submit脚本更简单。就是把 <strong>org.apache.spark.deploy.SparkSubmit</strong> 和 <strong>输入参数</strong> 全部传递给脚本 bin/spark-class 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>exec "${SPARK_HOME}"/bin/spark-class org.apache.spark.deploy.SparkSubmit "$@"</span></code></pre></td></tr></table></div></figure>


<h2>spark-class</h2>

<p>主要的功能都集中在 bin/spark-class。bin/spark-class脚本最终启动java、调用 <strong>Launcher模块</strong> 。而 <strong>Launcher模块</strong> 解析输入参数并输出 <strong>最终输出Driver启动的命令</strong>，然后shell再通过 <strong>exec</strong> 来运行Driver程序。</p>

<p>要讲清楚 bin/spark-class 相对复杂点：通过脚本传递参数，调用java处理参数，又输出脚本，最后运行脚本才真正运行了Driver。所以这里通过 <strong>脚本</strong> 和 <strong>程序</strong> 来进行说明。</p>

<h4>脚本</h4>

<ul>
<li>先加载环境变量配置文件</li>
<li>再获取 assembly.jar 位置</li>
<li>然后调用 <code>org.apache.spark.launcher.Main</code> ， Main类根据环境变量和传入参数算出真正执行的命令(具体在【程序】部分讲)。</li>
</ul>


<p>下面是核心脚本的内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>. "${SPARK_HOME}"/bin/load-spark-env.sh 
</span><span class='line'>  # 把load-spark-env.sh展开
</span><span class='line'>  . "${user_conf_dir}/spark-env.sh"
</span><span class='line'>  
</span><span class='line'>  ASSEMBLY_DIR1="${SPARK_HOME}/assembly/target/scala-2.10"  # 通过ASSEMBLY路径来判断SPARK_SCALA_VERSION，编译打包成tar的不需要这个变量
</span><span class='line'>  export SPARK_SCALA_VERSION="2.10"
</span><span class='line'>
</span><span class='line'>RUNNER="${JAVA_HOME}/bin/java"
</span><span class='line'>
</span><span class='line'>SPARK_ASSEMBLY_JAR=
</span><span class='line'>if [ -f "${SPARK_HOME}/RELEASE" ]; then
</span><span class='line'>  ASSEMBLY_DIR="${SPARK_HOME}/lib"
</span><span class='line'>else
</span><span class='line'>  ASSEMBLY_DIR="${SPARK_HOME}/assembly/target/scala-$SPARK_SCALA_VERSION"
</span><span class='line'>fi
</span><span class='line'>ASSEMBLY_JARS="$(ls -1 "$ASSEMBLY_DIR" | grep "^spark-assembly.*hadoop.*\.jar$" || true)"
</span><span class='line'>SPARK_ASSEMBLY_JAR="${ASSEMBLY_DIR}/${ASSEMBLY_JARS}"
</span><span class='line'>LAUNCH_CLASSPATH="$SPARK_ASSEMBLY_JAR"
</span><span class='line'>
</span><span class='line'>export _SPARK_ASSEMBLY="$SPARK_ASSEMBLY_JAR"
</span><span class='line'>
</span><span class='line'>CMD=()
</span><span class='line'>while IFS= read -d '' -r ARG; do
</span><span class='line'>  CMD+=("$ARG")
</span><span class='line'>done &lt; &lt;("$RUNNER" -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@")
</span><span class='line'>exec "${CMD[@]}"</span></code></pre></td></tr></table></div></figure>


<p>大部分内容都是准备环境变量，就最后几行代码比较复杂。这里设置DEBUG在脚本 <code>while</code> 循环打印每个输出的值看下输出的是什么。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 修改后的效果
</span><span class='line'>CMD=()
</span><span class='line'>while IFS= read -d '' -r ARG; do
</span><span class='line'>  echo "[DEBUG] $ARG"
</span><span class='line'>  CMD+=("$ARG")
</span><span class='line'>done &lt; &lt;(set -x; "$RUNNER" -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@")
</span><span class='line'>echo "${CMD[@]}"
</span><span class='line'>exec "${CMD[@]}"</span></code></pre></td></tr></table></div></figure>


<p>启动 bin/spark-shell（最终会调用 bin/spark-class，上面已经讲过脚本之间的关系），查看输出的调试信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[hadoop@cu2 spark-1.6.0-bin-2.6.3]$ bin/spark-shell 
</span><span class='line'>++ /opt/jdk1.8.0/bin/java -cp /home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar org.apache.spark.launcher.Main org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name 'Spark shell'
</span><span class='line'>[DEBUG] /opt/jdk1.8.0/bin/java
</span><span class='line'>[DEBUG] -cp
</span><span class='line'>[DEBUG] /home/hadoop/spark/lib/mysql-connector-java-5.1.34.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/conf/:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-rdbms-3.2.9.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-core-3.2.10.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/hadoop/etc/hadoop/
</span><span class='line'>[DEBUG] -Dscala.usejavacp=true
</span><span class='line'>[DEBUG] -Xms512m
</span><span class='line'>[DEBUG] -Xmx512m
</span><span class='line'>[DEBUG] org.apache.spark.deploy.SparkSubmit
</span><span class='line'>[DEBUG] --class
</span><span class='line'>[DEBUG] org.apache.spark.repl.Main
</span><span class='line'>[DEBUG] --name
</span><span class='line'>[DEBUG] Spark shell
</span><span class='line'>[DEBUG] spark-shell
</span><span class='line'>/opt/jdk1.8.0/bin/java -cp /home/hadoop/spark/lib/mysql-connector-java-5.1.34.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/conf/:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/spark-assembly-1.6.0-hadoop2.6.3-ext-2.1.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-rdbms-3.2.9.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-core-3.2.10.jar:/home/hadoop/spark-1.6.0-bin-2.6.3/lib/datanucleus-api-jdo-3.2.6.jar:/home/hadoop/hadoop/etc/hadoop/ -Dscala.usejavacp=true -Xms512m -Xmx512m org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name 'Spark shell' spark-shell
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>从上面的调试信息可以看出：</p>

<ul>
<li><code>org.apache.spark.launcher.Main</code> 把传入参数整理后重新输出</li>
<li>脚本把java输出内容保存到 <code>CMD[@]</code> 数组中</li>
<li>最后使用exec来执行。</li>
</ul>


<p>根据上面 bin/spark-class 产生的启动命令可以直接在idea里面运行，效果与直接运行 bin/spark-shell 一样：</p>

<p><img src="/images/blogs/rrc-spark/idea-spark-shell.png" alt="" /></p>

<p><strong>注意：</strong> 这里的 spark-shell 是一个特殊的字符串，代码中会对其进行特殊处理不额外加载jar。类似的字符串还有： pyspark-shell, sparkr-shell, spark-internal（参看SparkSubmit），如果调用类就在SPARK_CLASSPATH可以使用它们减少不必要的网络传输。</p>

<h4>Launcher模块</h4>

<p>发现 shell 和 launcher的java代码 功能逻辑非常类似。比如说获取java程序路径的代码：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>List&lt;String&gt; buildJavaCommand(String extraClassPath) throws IOException {
</span><span class='line'>  ...
</span><span class='line'>  if (javaHome != null) {
</span><span class='line'>      cmd.add(join(File.separator, javaHome, "bin", "java"));
</span><span class='line'>  } else if ((envJavaHome = System.getenv("JAVA_HOME")) != null) {
</span><span class='line'>      cmd.add(join(File.separator, envJavaHome, "bin", "java"));
</span><span class='line'>  } else {
</span><span class='line'>      cmd.add(join(File.separator, System.getProperty("java.home"), "bin", "java"));
</span><span class='line'>  }
</span><span class='line'>  ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>在shell脚本里面的处理是：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Find the java binary
</span><span class='line'>if [ -n "${JAVA_HOME}" ]; then
</span><span class='line'>  RUNNER="${JAVA_HOME}/bin/java"
</span><span class='line'>else
</span><span class='line'>  if [ `command -v java` ]; then
</span><span class='line'>  RUNNER="java"
</span><span class='line'>  else
</span><span class='line'>  echo "JAVA_HOME is not set" &gt;&2
</span><span class='line'>  exit 1
</span><span class='line'>  fi
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<p>对比两者，其实是用脚本更加直观。但是使用java编写一个模块更便于管理和扩展，稍微调整下就能复用代码。比如说要添加windows的cmd脚本、又或者为了兼容多个操作系统/多语言(python，r 等)。所以提取一个公共的 <strong>Launcher模块</strong> 出来其实是个挺不错的选择。同时对于不是很熟悉shell的程序员来说也更方便了解系统运作。</p>

<p><strong>Launcher模块</strong> 按功能可以分为 CommandBuilder 和 SparkLauncher 两个部分。</p>

<ol>
<li><p>CommandBuilder</p></li>
<li><p>SparkSubmitCommandBuilder: 解析用户输入的参数并输出命令给脚本使用</p></li>
<li>SparkClassCommandBuilder: 主要为后台进程产生启动命令（sbin目录下面的脚本）。</li>
</ol>


<p>1.1 公共类</p>

<ul>
<li>Main ： 统一入口</li>
<li>AbstractCommandBuilder : 提供构造命令的公共基类

<ul>
<li>buildJavaCommand

<ul>
<li>buildClassPath

<ul>
<li>SPARK_CLASSPATH</li>
<li>extraClassPath</li>
<li>getConfDir : 等于环境变量 $SPARK_CONF_DIR 或者 $SPARK_HOME/conf 的值</li>
<li>classes

<ul>
<li>SPARK_PREPEND_CLASSES</li>
<li>SPARK_TESTING</li>
</ul>
</li>
<li>findAssembly : 获取 spark-assembly-1.6.0-hadoop2.6.3.jar 的路径，lib 或者 assembly/target/scala-$SPARK_SCALA_VERSION 路径下

<ul>
<li>_SPARK_ASSEMBLY</li>
</ul>
</li>
<li>datanucleus-* : 从 lib / lib_managed/jars 目录下获取</li>
<li>HADOOP_CONF_DIR</li>
<li>YARN_CONF_DIR</li>
<li>SPARK_DIST_CLASSPATH</li>
</ul>
</li>
</ul>
</li>
<li>getEffectiveConfig : 获取 spark-defaults.conf 的内容</li>
</ul>
</li>
</ul>


<p>1.2 SparkSubmitCommandBuilder</p>

<p>主要的类以及参数：</p>

<ul>
<li>SparkSubmitCommandBuilder

<ul>
<li>构造函数调用OptionParser解析参数，解析handle有处理specialClasses！</li>
<li>buildSparkSubmitCommand

<ul>
<li>getEffectiveConfig</li>
<li>extraClassPath : spark.driver.extraClassPath</li>
<li>SPARK_SUBMIT_OPTS</li>
<li>SPARK_JAVA_OPTS</li>
<li>client模式下加载配置

<ul>
<li>spark.driver.memory / SPARK_DRIVER_MEMORY / SPARK_MEM / DEFAULT_MEM(1g)</li>
<li>DRIVER_EXTRA_JAVA_OPTIONS</li>
<li>DRIVER_EXTRA_LIBRARY_PATH</li>
</ul>
</li>
<li>buildSparkSubmitArgs</li>
</ul>
</li>
</ul>
</li>
<li>SparkSubmitOptionParser(子类需要实现handle方法)</li>
<li>SparkSubmitCommandBuilder$OptionParser 命令参数

<ul>
<li><code>bin/spark-submit -h</code> 查看可以<strong>设置的参数</strong></li>
<li>直接查看<a href="http://spark.apache.org/docs/latest/submitting-applications.html">官网文档</a></li>
</ul>
</li>
</ul>


<p>1.3 SparkClassCommandBuilder</p>

<p>主要CommandBuilder的功能上面已经都覆盖了，SparkClassCommandBuilder主要关注命令行可以设置哪些环境变量：</p>

<ul>
<li>org.apache.spark.deploy.master.Master

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_MASTER_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.worker.Worker

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_WORKER_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.history.HistoryServer

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_HISTORY_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.executor.CoarseGrainedExecutorBackend

<ul>
<li>SPARK_JAVA_OPTS</li>
<li>SPARK_EXECUTOR_OPTS</li>
<li>SPARK_EXECUTOR_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.executor.MesosExecutorBackend

<ul>
<li>SPARK_EXECUTOR_OPTS</li>
<li>SPARK_EXECUTOR_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.deploy.ExternalShuffleService / org.apache.spark.deploy.mesos.MesosExternalShuffleService

<ul>
<li>SPARK_DAEMON_JAVA_OPTS</li>
<li>SPARK_SHUFFLE_OPTS</li>
<li>SPARK_DAEMON_MEMORY</li>
</ul>
</li>
<li>org.apache.spark.tools.

<ul>
<li>extraClassPath : spark-tools_.*.jar</li>
<li>SPARK_JAVA_OPTS</li>
<li>DEFAULT_MEM(1g)</li>
</ul>
</li>
<li>other

<ul>
<li>SPARK_JAVA_OPTS</li>
<li>SPARK_DRIVER_MEMORY</li>
</ul>
</li>
</ul>


<h4>SparkLauncher</h4>

<p>SparkLauncher提供了在程序中提交任务的方式。通过Driver端的支持获取程序执行动态（通过socket与Driver交互），为实现后端管理应用提供一种可行的方式。</p>

<p>SparkLauncher提交任务其中一部分还是使用spark-submit脚本，绕一圈又回到上面的参数解析生成命令然后exec执行。另外SparkLauncher通过启动 SocketServer(LauncherServer)接收来自Driver(LauncherBackend)任务执行情况的最新状态。</p>

<p><img src="/images/blogs/rrc-spark/spark-launcher.jpg" alt="" /></p>

<p>代码包括：</p>

<ul>
<li>SparkLauncher 主要是startApplication。其他都是解析设置参数，相当于把shell的工作用java重写了一遍</li>
<li>LauncherServer 服务SocketServer类</li>
<li>LauncherServer$ServerConnection 状态处理类</li>
<li>LauncherConnection 通信基类：接收、发送消息</li>
<li>LauncherProtocol 通信协议</li>
<li>ChildProcAppHandle : SparkAppHandle 接收到Driver的状态后，请求分发类</li>
</ul>


<p>具体功能的流转请下载代码 <a href="https://github.com/winse/spark-examples/blob/master/src/main/scala/com/github/winse/spark/HelloWorldLauncher.scala">HelloWorldLauncher.scala</a> ，然后本地调试一步步的追踪学习。</p>

<p>&ndash;END</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Winse Liu</span></span>

      








  



  
<time datetime="2016-09-27T05:50:13+08:00" class="updated">Updated Tue 2016-09-27 05:50</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/books/'>books</a>, <a class='category' href='/blog/categories/spark/'>spark</a>
  
</span>


	  <span style="padding: 0 1em;">
<a class="shellExecuteLink" href="npp-windows://e/_posts/2016-05-08-rrc-apache-spark-source-inside-shell.markdown" title="本地编辑"><i class="icon-edit"> </i>编辑</a>
</span>	
    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2016/05/07/rrc-apache-spark-source-inside-preface/" title="Previous Post: [读读书]Apache Spark源码剖析-序">&laquo; [读读书]Apache Spark源码剖析-序</a>
      
      
        <a class="basic-alignment right" href="/blog/2016/06/15/elasticsearch-startguide/" title="Next Post: elasticsearch startguide">elasticsearch startguide &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
	
	
  
  
<!-- gitalk评论 start -->
    <div id="gitalk-container"></div> 
<!-- gitalk评论 end -->
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>佛爷</h1>
  <p>来之不易, 且等且珍惜. <br>得之我幸; 不得<span style="display:none">-争-复争-且不得</span>, 命也, 乐享天命, 福也. </p>
  <p><a href="https://github.com/winse"><i class="fa fa-github-alt">winse</i></a>&nbsp;&nbsp;<a href="http://weibo.com/winseliu"><i class="fa fa-weibo">winseliu</i></a></p>
</section>
<section>
  <h1><a class='category' href='/blog/categories/recommend/'>Recommend</a></h1>
	<ul role="list">
		
			<li class="post">
				<a href="/blog/2019/04/10/try-k8s/">Try K8s</a>
			</li>
		
			<li class="post">
				<a href="/blog/2018/08/25/video-auto-translate/">视频自动翻译</a>
			</li>
		
			<li class="post">
				<a href="/blog/2018/06/09/reasonable-way-to-access-the-internet/">科学上网（续）</a>
			</li>
		
			<li class="post">
				<a href="/blog/2018/01/20/gitalk-on-octopress/">Gitalk on Octopress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/11/16/sphinx-generate-docs/">使用Sphinx生成/管理文档</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/10/30/windows-run-ubuntu/">Windows Run Ubuntu</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/07/30/kubeadm-install-kubenetes-on-centos7/">Kubeadm部署kubernetes</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/07/08/casperjs-crawler/">爬虫之CasperJS</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/05/23/spark-on-hive-speculation-shit-bug/">Hive on Spark预测性执行BUG一枚</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/01/27/vnc-server-on-centos7/">在Centos7上安装VNC Server</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/01/25/develop-environment-prepare/">[整理] 环境准备工具集</a>
			</li>
		
			<li class="post">
				<a href="/blog/2017/01/19/nginx-https/">Nginx配置https</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/09/19/163-open-movies-download/">批量下载163-open的视频</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/04/23/hadoop-guide-catalog/">[整理] Hadoop入门</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/04/04/rpm-build-your-package/">RPM打包</a>
			</li>
		
			<li class="post">
				<a href="/blog/2016/03/28/hive-on-spark/">Hive on Spark</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/11/22/gfw-ladder/">搭梯笔记</a>
			</li>
		
			<li class="post">
				<a href="/blog/2015/08/24/manual-install-supervisor/">Supervisor安装配置</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/10/16/spark-build-and-configuration/">编译/搭建Spark环境</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/08/25/step-by-step-found-java-oom-error/">查找逐步定位Java程序OOM的异常实践</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/30/hadoop2-snappy-compress/">Hadoop2 Snappy Compress</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/07/27/start-redis/">[读读书]Redis入门指南</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/04/21/hadoop2-windows-startguide/">Windows下部署/配置/调试hadoop2</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/30/git-cheatsheet/">GIT操作记录手册</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/03/18/jekyll-edit-link-in-web-page/">Jekyll页面添加编辑按钮</a>
			</li>
		
			<li class="post">
				<a href="/blog/2014/02/23/quickly-open-program-in-windows/">[Windows运行]快速打开程序</a>
			</li>
		
			<li class="post">
				<a href="/blog/2013/09/19/let-shell-command-efficient/">让敲Shell命令高效起来</a>
			</li>
		
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2021/12/08/octopress-generate-toc/">octopress生成TOC</a>
      </li>
    
      <li class="post">
        <a href="/blog/2021/12/08/recommand-blogs/">认真的博客</a>
      </li>
    
      <li class="post">
        <a href="/blog/2021/09/15/k2-again/">斐讯K2刷机padavan</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/05/11/redmine-on-arm-pi/">在树莓派上部署redmine</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/04/12/appium-android-auto-test/">appium-Android自动化测试</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/26/android-linux-via-termux/">Android Linux via Termux</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/04/10/try-bk-dot-tencent-dot-com/">Try bk.tencent.com</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/04/10/try-k8s/">Try K8s</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>

	 
	<ul role="list">
		
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/0/'>0</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/alluxio/'>alluxio</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/android/'>android</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/bigdata/'>bigdata</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/blabla/'>blabla</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/books/'>books</a> (6) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/debug/'>debug</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/deprecated/'>deprecated</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/devops/'>devops</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/docker/'>docker</a> (15) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/elasticsearch/'>elasticsearch</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/es/'>es</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/flume/'>flume</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/ganglia/'>ganglia</a> (5) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/git/'>git</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hadoop/'>hadoop</a> (44) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hbase/'>hbase</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hive/'>hive</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/hole/'>hole</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/java/'>java</a> (13) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jekyll/'>jekyll</a> (8) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jenkins/'>jenkins</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/jeykll/'>jeykll</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k2/'>k2</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/k8s/'>k8s</a> (9) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kafka/'>kafka</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/kubeadm/'>kubeadm</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/logstash/'>logstash</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/map/'>map</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/nginx/'>nginx</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/puppet/'>puppet</a> (11) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/recommend/'>recommend</a> (27) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/redis/'>redis</a> (7) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/scala/'>scala</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/shell/'>shell</a> (4) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/spark/'>spark</a> (12) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/staf/'>staf</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tachyon/'>tachyon</a> (3) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tez/'>tez</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/tools/'>tools</a> (69) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/topics/'>topics</a> (2) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/vagrant/'>vagrant</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/wsl/'>wsl</a> (1) 
		</li>
		 
		<li style="float:left; width:120px"> 
			<a class='category' href='/blog/categories/zookeeper/'>zookeeper</a> (1) 
		</li>
		
		
		<li style="clear:both; width: 1px; margin: 0; padding: 0;"></li>
		<li class="category"><a href="/blog/archives">All categories</a> (219)</li>
	</ul>
	
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/winse">@winse</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'winse',
            count: 4,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
<!--
  <h1>Softs, I'm using</h1>
  <ul>
    <li class="post">
		<a href="http://hadoop.apache.org/releases.html">hadoop-2.6.3</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/HBASE/?selectedTab=com.atlassian.jira.jira-projects-plugin:changelog-panel">hbase-0.96.0</a>
	</li>
	<li class="post">
		<a href="https://hive.apache.org/downloads.html">hive-1.2.1</a>
	</li>
	<li class="post">
		<a href="https://issues.apache.org/jira/browse/TEZ/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel">tez-0.7.0</a>
    </li>
  </ul>
-->
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2021 - Winse Liu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  <script type="text/javascript">document.write(unescape("%3Cspan id='cnzz_stat_icon_1253103971'%3E%3C/span%3E%3Cscript src='https://s19.cnzz.com/z_stat.php%3Fid%3D1253103971%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>

</footer>
  


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>

<script>

var time=location.pathname.substring(6).substring(0,11);
var eName=location.pathname.substring(17);
var gitalk = new Gitalk({
  clientID: 'c14f68eac6330d15d984',
  clientSecret: '73b7c1fffa98e299ff0cdd332821201933858e6e',
  repo: 'winse.github.com',
  owner: 'winse',
  admin: ['winse'],
  id: eName,
  labels: ['Gitalk', time],
  body: "http://winse.github.io" + location.pathname,
  createIssueManually: true,
  
  // facebook-like distraction free mode
  distractionFreeMode: false
})

gitalk.render('gitalk-container')

</script>



<script>
/*
$.ajax({
  type: "POST",
  url: "http://log.winseliu.com:20000",
  data: JSON.stringify({
    title: document.title,
    location: JSON.stringify(location),
    referrer: document.referrer,
    userAgent: navigator.userAgent
  }),
  contentType: "application/json; charset=utf-8",
  dataType: "json"
});
*/
</script>











</body>
</html>
